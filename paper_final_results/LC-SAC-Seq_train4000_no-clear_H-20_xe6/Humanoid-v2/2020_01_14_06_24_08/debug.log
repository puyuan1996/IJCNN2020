---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0027023102
Z variance train             0.6934819
KL Divergence                0.14884156
KL Loss                      0.014884156
QF Loss                      1092.181
VF Loss                      129.22769
Policy Loss                  -11.3660965
Q Predictions Mean           0.0101819355
Q Predictions Std            0.013294154
Q Predictions Max            0.043898728
Q Predictions Min            -0.020737184
V Predictions Mean           0.03226183
V Predictions Std            0.015181439
V Predictions Max            0.07544238
V Predictions Min            -0.00023006322
Log Pis Mean                 -11.262682
Log Pis Std                  0.8770752
Log Pis Max                  -8.90138
Log Pis Min                  -13.399538
Policy mu Mean               0.0011287653
Policy mu Std                0.0078295
Policy mu Max                0.023558576
Policy mu Min                -0.023645563
Policy log std Mean          -0.0027119347
Policy log std Std           0.008069115
Policy log std Max           0.021377334
Policy log std Min           -0.03208867
Z mean eval                  0.006873959
Z variance eval              0.669368
total_rewards                [247.60309518 324.41621614 310.57997375 281.01107055 286.61967441
 200.93198013 248.60843662 207.38117704 317.1085423  457.1625057 ]
total_rewards_mean           288.14226718159784
total_rewards_std            69.72348564062662
total_rewards_max            457.1625056985507
total_rewards_min            200.93198013428218
Number of train steps total  4000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               133.98667664593086
(Previous) Eval Time (s)     0
Sample Time (s)              19.74982857517898
Epoch Time (s)               153.73650522110984
Total Train Time (s)         155.55228492897004
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:26:44.673818 UTC | [2020_01_14_06_24_08] Iteration #0 | Epoch Duration: 155.55606365203857
2020-01-14 06:26:44.674051 UTC | [2020_01_14_06_24_08] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0069779544
Z variance train             0.669404
KL Divergence                0.17898604
KL Loss                      0.017898604
QF Loss                      9758.496
VF Loss                      3164.823
Policy Loss                  -111.61059
Q Predictions Mean           131.4848
Q Predictions Std            214.48521
Q Predictions Max            747.92737
Q Predictions Min            16.098083
V Predictions Mean           136.86862
V Predictions Std            204.85759
V Predictions Max            724.06165
V Predictions Min            25.078281
Log Pis Mean                 -8.480665
Log Pis Std                  5.9929023
Log Pis Max                  8.001421
Log Pis Min                  -14.292459
Policy mu Mean               0.12568223
Policy mu Std                0.50027966
Policy mu Max                2.0305784
Policy mu Min                -1.7000115
Policy log std Mean          -0.18841001
Policy log std Std           0.12078119
Policy log std Max           -0.05824981
Policy log std Min           -0.74579346
Z mean eval                  0.024377327
Z variance eval              0.58545053
total_rewards                [358.26458505 358.00433468 342.44586907 309.18459176 316.62051381
 261.04016428 252.83422455 239.91367492 421.25304928 344.80004722]
total_rewards_mean           320.43610546200085
total_rewards_std            53.672490606328275
total_rewards_max            421.2530492770911
total_rewards_min            239.9136749204354
Number of train steps total  8000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               128.0917671797797
(Previous) Eval Time (s)     1.8191205221228302
Sample Time (s)              14.133279995527118
Epoch Time (s)               144.04416769742966
Total Train Time (s)         299.64188627898693
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:29:08.762767 UTC | [2020_01_14_06_24_08] Iteration #1 | Epoch Duration: 144.0885727405548
2020-01-14 06:29:08.762927 UTC | [2020_01_14_06_24_08] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024395516
Z variance train             0.5854673
KL Divergence                0.30666482
KL Loss                      0.030666484
QF Loss                      2883.0269
VF Loss                      792.888
Policy Loss                  -203.51302
Q Predictions Mean           195.16814
Q Predictions Std            366.13016
Q Predictions Max            1264.0352
Q Predictions Min            16.058231
V Predictions Mean           204.31456
V Predictions Std            360.01852
V Predictions Max            1230.1088
V Predictions Min            25.480745
Log Pis Mean                 -7.460787
Log Pis Std                  8.238624
Log Pis Max                  23.022224
Log Pis Min                  -13.481676
Policy mu Mean               0.0739446
Policy mu Std                0.5925219
Policy mu Max                2.3388343
Policy mu Min                -2.2883058
Policy log std Mean          -0.19271435
Policy log std Std           0.13595983
Policy log std Max           0.039658904
Policy log std Min           -0.74386287
Z mean eval                  0.017575912
Z variance eval              0.5257198
total_rewards                [ 82.95191716  77.19118837  76.78144231  98.10931644  76.87845676
  76.50276433  76.75085718 104.80215536  82.29090488  76.72487569]
total_rewards_mean           82.89838784653037
total_rewards_std            9.667245656287413
total_rewards_max            104.80215536058013
total_rewards_min            76.50276432774405
Number of train steps total  12000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               118.91654365230352
(Previous) Eval Time (s)     1.8632664042524993
Sample Time (s)              14.108370839618146
Epoch Time (s)               134.88818089617416
Total Train Time (s)         433.0840148590505
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:31:22.206986 UTC | [2020_01_14_06_24_08] Iteration #2 | Epoch Duration: 133.44391560554504
2020-01-14 06:31:22.207247 UTC | [2020_01_14_06_24_08] Iteration #2 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017550085
Z variance train             0.52576244
KL Divergence                0.42874926
KL Loss                      0.04287493
QF Loss                      4525.7637
VF Loss                      926.86536
Policy Loss                  -195.26602
Q Predictions Mean           182.00064
Q Predictions Std            439.38837
Q Predictions Max            1853.0773
Q Predictions Min            17.666569
V Predictions Mean           202.42606
V Predictions Std            450.8436
V Predictions Max            1884.9547
V Predictions Min            23.791826
Log Pis Mean                 -8.194143
Log Pis Std                  8.657001
Log Pis Max                  24.96702
Log Pis Min                  -14.291193
Policy mu Mean               0.045593683
Policy mu Std                0.55423784
Policy mu Max                2.5648813
Policy mu Min                -2.4755352
Policy log std Mean          -0.19179347
Policy log std Std           0.12939404
Policy log std Max           -0.09974964
Policy log std Min           -0.8012078
Z mean eval                  0.01705574
Z variance eval              0.47267437
total_rewards                [186.81541976 114.54884157  94.24998184  87.22400227 124.2788167
  87.51964846  88.38091936  80.42885582  95.36880539  79.60576524]
total_rewards_mean           103.84210564005988
total_rewards_std            30.818634909842586
total_rewards_max            186.81541975561464
total_rewards_min            79.60576523532292
Number of train steps total  16000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               113.7874314612709
(Previous) Eval Time (s)     0.41873761592432857
Sample Time (s)              14.203036423772573
Epoch Time (s)               128.4092055009678
Total Train Time (s)         561.7435479285195
Epoch                        3
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:33:30.866674 UTC | [2020_01_14_06_24_08] Iteration #3 | Epoch Duration: 128.65926027297974
2020-01-14 06:33:30.866826 UTC | [2020_01_14_06_24_08] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017048936
Z variance train             0.47264934
KL Divergence                0.56947565
KL Loss                      0.056947567
QF Loss                      3351.6392
VF Loss                      602.671
Policy Loss                  -254.12457
Q Predictions Mean           240.62222
Q Predictions Std            552.6371
Q Predictions Max            2416.0635
Q Predictions Min            13.193474
V Predictions Mean           254.14467
V Predictions Std            559.1843
V Predictions Max            2468.8977
V Predictions Min            26.017921
Log Pis Mean                 -7.6046925
Log Pis Std                  9.381697
Log Pis Max                  26.91961
Log Pis Min                  -16.584446
Policy mu Mean               0.061918244
Policy mu Std                0.60566694
Policy mu Max                2.6223712
Policy mu Min                -2.6602683
Policy log std Mean          -0.189994
Policy log std Std           0.13978589
Policy log std Max           -0.07472932
Policy log std Min           -0.7751761
Z mean eval                  0.01743752
Z variance eval              0.43366438
total_rewards                [300.55995113 290.56767907 264.82517667 267.29718204 267.14269621
 252.4895177  261.9700099  214.96106042 291.23513618 213.14376662]
total_rewards_mean           262.41921759374594
total_rewards_std            28.12196740421519
total_rewards_max            300.55995113154097
total_rewards_min            213.1437666218258
Number of train steps total  20000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               113.00972509011626
(Previous) Eval Time (s)     0.6685399920679629
Sample Time (s)              14.048384943511337
Epoch Time (s)               127.72665002569556
Total Train Time (s)         690.1080219722353
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:35:39.231789 UTC | [2020_01_14_06_24_08] Iteration #4 | Epoch Duration: 128.36484909057617
2020-01-14 06:35:39.231989 UTC | [2020_01_14_06_24_08] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017434817
Z variance train             0.43368325
KL Divergence                0.69962907
KL Loss                      0.06996291
QF Loss                      1997.251
VF Loss                      1450.8835
Policy Loss                  -252.44164
Q Predictions Mean           240.41821
Q Predictions Std            553.6747
Q Predictions Max            2078.4048
Q Predictions Min            12.108139
V Predictions Mean           259.93744
V Predictions Std            564.5043
V Predictions Max            2144.5107
V Predictions Min            22.234053
Log Pis Mean                 -7.8823967
Log Pis Std                  9.107565
Log Pis Max                  29.762325
Log Pis Min                  -13.625278
Policy mu Mean               0.106088005
Policy mu Std                0.5633033
Policy mu Max                2.8642912
Policy mu Min                -2.6762085
Policy log std Mean          -0.18716897
Policy log std Std           0.1359777
Policy log std Max           -0.023357712
Policy log std Min           -0.81098855
Z mean eval                  0.017324213
Z variance eval              0.39536518
total_rewards                [293.70588346 310.65011583 325.82884823 426.00044692 400.82099207
 354.69080679 355.05322233 512.06001629 262.79791558 352.62462143]
total_rewards_mean           359.4232868941172
total_rewards_std            68.33346405448421
total_rewards_max            512.060016293475
total_rewards_min            262.7979155816616
Number of train steps total  24000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               114.30654213624075
(Previous) Eval Time (s)     1.3064756128005683
Sample Time (s)              14.172181781381369
Epoch Time (s)               129.7851995304227
Total Train Time (s)         820.9281979044899
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:37:50.053261 UTC | [2020_01_14_06_24_08] Iteration #5 | Epoch Duration: 130.8211534023285
2020-01-14 06:37:50.053423 UTC | [2020_01_14_06_24_08] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01742292
Z variance train             0.3953755
KL Divergence                0.8401178
KL Loss                      0.084011786
QF Loss                      6410.1
VF Loss                      1375.589
Policy Loss                  -319.68622
Q Predictions Mean           299.91846
Q Predictions Std            604.2848
Q Predictions Max            2483.6206
Q Predictions Min            17.26806
V Predictions Mean           312.23788
V Predictions Std            602.7298
V Predictions Max            2356.4863
V Predictions Min            19.474344
Log Pis Mean                 -6.0632977
Log Pis Std                  11.065178
Log Pis Max                  27.915012
Log Pis Min                  -13.342528
Policy mu Mean               0.030598227
Policy mu Std                0.707784
Policy mu Max                2.8318992
Policy mu Min                -2.7061808
Policy log std Mean          -0.21372235
Policy log std Std           0.16086067
Policy log std Max           -0.05635254
Policy log std Min           -0.800838
Z mean eval                  0.017758112
Z variance eval              0.35846552
total_rewards                [214.05557572 147.56295944 211.02714222 188.63243165 185.91655199
 126.42820148 123.38673428 173.8765055  154.34040823 142.98428267]
total_rewards_mean           166.8210793178724
total_rewards_std            31.126173823420174
total_rewards_max            214.05557571572064
total_rewards_min            123.38673427836854
Number of train steps total  28000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               115.67322434810922
(Previous) Eval Time (s)     2.342209257185459
Sample Time (s)              15.8710258747451
Epoch Time (s)               133.88645948003978
Total Train Time (s)         953.5675750076771
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:40:02.695447 UTC | [2020_01_14_06_24_08] Iteration #6 | Epoch Duration: 132.64186191558838
2020-01-14 06:40:02.695741 UTC | [2020_01_14_06_24_08] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01779825
Z variance train             0.35850948
KL Divergence                1.0080523
KL Loss                      0.10080524
QF Loss                      1830.1895
VF Loss                      925.5725
Policy Loss                  -285.32898
Q Predictions Mean           270.37317
Q Predictions Std            544.23694
Q Predictions Max            1944.924
Q Predictions Min            16.912792
V Predictions Mean           281.3907
V Predictions Std            545.84283
V Predictions Max            1984.7965
V Predictions Min            24.902103
Log Pis Mean                 -7.0814915
Log Pis Std                  9.327436
Log Pis Max                  28.376858
Log Pis Min                  -14.021876
Policy mu Mean               0.045463745
Policy mu Std                0.6286628
Policy mu Max                3.0696964
Policy mu Min                -2.6757956
Policy log std Mean          -0.20780125
Policy log std Std           0.14763182
Policy log std Max           -0.0736051
Policy log std Min           -0.8302015
Z mean eval                  0.016359445
Z variance eval              0.33573073
total_rewards                [307.66660227 330.02913377 527.04102808 561.15231874 493.45275687
 316.24108053 350.01762219 242.3216564  465.44737693 574.27847622]
total_rewards_mean           416.7648052010153
total_rewards_std            114.2306014525931
total_rewards_max            574.2784762204735
total_rewards_min            242.32165640185704
Number of train steps total  32000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               116.10420847591013
(Previous) Eval Time (s)     1.0972700151614845
Sample Time (s)              13.772927276790142
Epoch Time (s)               130.97440576786175
Total Train Time (s)         1085.874167310074
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:42:15.002529 UTC | [2020_01_14_06_24_08] Iteration #7 | Epoch Duration: 132.3064739704132
2020-01-14 06:42:15.002740 UTC | [2020_01_14_06_24_08] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016366575
Z variance train             0.3357015
KL Divergence                1.1424524
KL Loss                      0.114245236
QF Loss                      3540.8071
VF Loss                      714.16815
Policy Loss                  -284.50885
Q Predictions Mean           271.34796
Q Predictions Std            539.0319
Q Predictions Max            2610.4949
Q Predictions Min            19.964067
V Predictions Mean           284.6114
V Predictions Std            540.1478
V Predictions Max            2346.103
V Predictions Min            27.977942
Log Pis Mean                 -5.8757906
Log Pis Std                  10.704129
Log Pis Max                  31.38923
Log Pis Min                  -14.816872
Policy mu Mean               0.06645144
Policy mu Std                0.69129044
Policy mu Max                2.963473
Policy mu Min                -2.6861289
Policy log std Mean          -0.21777669
Policy log std Std           0.160485
Policy log std Max           -0.07619214
Policy log std Min           -0.8530322
Z mean eval                  0.017766338
Z variance eval              0.3099267
total_rewards                [207.05447928 346.43139286 295.88491019 603.26057327 381.93688049
 203.18034414 324.03886562 324.98819924 222.68732359 333.41148459]
total_rewards_mean           324.28744532567185
total_rewards_std            110.11966485078355
total_rewards_max            603.2605732703614
total_rewards_min            203.18034413727398
Number of train steps total  36000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               113.86219431878999
(Previous) Eval Time (s)     2.4290927052497864
Sample Time (s)              15.426720328629017
Epoch Time (s)               131.7180073526688
Total Train Time (s)         1217.4978239657357
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:44:26.628400 UTC | [2020_01_14_06_24_08] Iteration #8 | Epoch Duration: 131.62545561790466
2020-01-14 06:44:26.628687 UTC | [2020_01_14_06_24_08] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017778687
Z variance train             0.30999967
KL Divergence                1.2897568
KL Loss                      0.12897567
QF Loss                      1891.8546
VF Loss                      2483.5476
Policy Loss                  -227.6772
Q Predictions Mean           213.7601
Q Predictions Std            438.99762
Q Predictions Max            1830.6855
Q Predictions Min            9.511971
V Predictions Mean           222.05887
V Predictions Std            437.4225
V Predictions Max            1797.4354
V Predictions Min            15.72211
Log Pis Mean                 -7.764145
Log Pis Std                  8.337085
Log Pis Max                  25.817665
Log Pis Min                  -14.126526
Policy mu Mean               0.08544301
Policy mu Std                0.5915848
Policy mu Max                2.5223694
Policy mu Min                -2.317391
Policy log std Mean          -0.19704092
Policy log std Std           0.13289915
Policy log std Max           -0.052286103
Policy log std Min           -0.7891623
Z mean eval                  0.021756444
Z variance eval              0.29295275
total_rewards                [411.25470873 465.26864153 232.15511891 444.34823859 271.58159328
 297.03716464 292.78409461 303.80409885 289.98461656 286.80298034]
total_rewards_mean           329.5021256032627
total_rewards_std            75.88433022558212
total_rewards_max            465.2686415305949
total_rewards_min            232.15511890599814
Number of train steps total  40000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               114.11792880296707
(Previous) Eval Time (s)     2.3362761582247913
Sample Time (s)              15.344535818323493
Epoch Time (s)               131.79874077951536
Total Train Time (s)         1348.7542998795398
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:46:37.885883 UTC | [2020_01_14_06_24_08] Iteration #9 | Epoch Duration: 131.25698113441467
2020-01-14 06:46:37.886117 UTC | [2020_01_14_06_24_08] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021637168
Z variance train             0.29303348
KL Divergence                1.3945287
KL Loss                      0.13945287
QF Loss                      697.1189
VF Loss                      478.69208
Policy Loss                  -167.77612
Q Predictions Mean           155.96387
Q Predictions Std            326.2069
Q Predictions Max            1671.5746
Q Predictions Min            13.388846
V Predictions Mean           164.02658
V Predictions Std            322.1993
V Predictions Max            1636.8373
V Predictions Min            20.734785
Log Pis Mean                 -8.247753
Log Pis Std                  7.6193733
Log Pis Max                  20.566912
Log Pis Min                  -13.314852
Policy mu Mean               0.04531552
Policy mu Std                0.5325013
Policy mu Max                2.681838
Policy mu Min                -2.5845485
Policy log std Mean          -0.1876503
Policy log std Std           0.12217904
Policy log std Max           0.0627303
Policy log std Min           -0.85722375
Z mean eval                  0.022592593
Z variance eval              0.2905808
total_rewards                [293.50766388 303.12389735 434.47758976 231.22317096 275.30336298
 322.06949328 322.57775442 294.84773585 352.90885782 451.25801777]
total_rewards_mean           328.1297544087996
total_rewards_std            65.01167210926226
total_rewards_max            451.2580177738978
total_rewards_min            231.2231709608606
Number of train steps total  44000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               116.28387169865891
(Previous) Eval Time (s)     1.7942808750085533
Sample Time (s)              14.717043988406658
Epoch Time (s)               132.79519656207412
Total Train Time (s)         1481.7929332763888
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:48:50.926524 UTC | [2020_01_14_06_24_08] Iteration #10 | Epoch Duration: 133.04020977020264
2020-01-14 06:48:50.926785 UTC | [2020_01_14_06_24_08] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022633523
Z variance train             0.29060572
KL Divergence                1.4366335
KL Loss                      0.14366335
QF Loss                      1112.834
VF Loss                      392.86395
Policy Loss                  -200.12714
Q Predictions Mean           190.19318
Q Predictions Std            351.60275
Q Predictions Max            1349.5737
Q Predictions Min            14.860786
V Predictions Mean           196.77455
V Predictions Std            341.1448
V Predictions Max            1375.2448
V Predictions Min            20.729557
Log Pis Mean                 -8.324617
Log Pis Std                  6.586464
Log Pis Max                  18.62253
Log Pis Min                  -13.79916
Policy mu Mean               0.075337395
Policy mu Std                0.51269656
Policy mu Max                2.205309
Policy mu Min                -1.933813
Policy log std Mean          -0.19263494
Policy log std Std           0.12260269
Policy log std Max           0.035499185
Policy log std Min           -0.7637045
Z mean eval                  0.02077097
Z variance eval              0.27272683
total_rewards                [411.46207674 348.28053683 415.15869183 517.42358092 423.59503394
 364.59075694 479.69458959 593.44482325 359.88028236 389.82088253]
total_rewards_mean           430.33512549445686
total_rewards_std            74.1067072083029
total_rewards_max            593.4448232549504
total_rewards_min            348.28053682851197
Number of train steps total  48000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               115.5698748738505
(Previous) Eval Time (s)     2.03903416916728
Sample Time (s)              15.060828746762127
Epoch Time (s)               132.6697377897799
Total Train Time (s)         1614.8447799524292
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:51:03.977957 UTC | [2020_01_14_06_24_08] Iteration #11 | Epoch Duration: 133.05099153518677
2020-01-14 06:51:03.978161 UTC | [2020_01_14_06_24_08] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020772612
Z variance train             0.27276292
KL Divergence                1.5505196
KL Loss                      0.15505196
QF Loss                      535.8646
VF Loss                      149.61967
Policy Loss                  -188.78192
Q Predictions Mean           175.81348
Q Predictions Std            307.653
Q Predictions Max            1142.6605
Q Predictions Min            16.24
V Predictions Mean           185.09145
V Predictions Std            305.0467
V Predictions Max            1136.3154
V Predictions Min            26.810509
Log Pis Mean                 -7.845979
Log Pis Std                  7.2512107
Log Pis Max                  31.729958
Log Pis Min                  -13.197092
Policy mu Mean               0.085912764
Policy mu Std                0.55295795
Policy mu Max                2.373367
Policy mu Min                -2.3792737
Policy log std Mean          -0.19635528
Policy log std Std           0.12482462
Policy log std Max           -0.05665306
Policy log std Min           -0.7814379
Z mean eval                  0.01974918
Z variance eval              0.26237893
total_rewards                [341.13735393 372.35837631 375.44247234 436.69856712 399.28630305
 361.21329852 346.73471188 305.07181554 301.76943318 434.86435688]
total_rewards_mean           367.45766887496177
total_rewards_std            44.50497797290287
total_rewards_max            436.698567122455
total_rewards_min            301.7694331769563
Number of train steps total  52000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               121.2215821519494
(Previous) Eval Time (s)     2.420058620162308
Sample Time (s)              15.325843735132366
Epoch Time (s)               138.96748450724408
Total Train Time (s)         1753.5238122837618
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:53:22.660054 UTC | [2020_01_14_06_24_08] Iteration #12 | Epoch Duration: 138.68173122406006
2020-01-14 06:53:22.660340 UTC | [2020_01_14_06_24_08] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019749776
Z variance train             0.26238704
KL Divergence                1.6133728
KL Loss                      0.16133729
QF Loss                      382.75452
VF Loss                      191.82074
Policy Loss                  -215.34583
Q Predictions Mean           206.5369
Q Predictions Std            335.43726
Q Predictions Max            1136.974
Q Predictions Min            6.6798444
V Predictions Mean           214.90955
V Predictions Std            330.7879
V Predictions Max            1123.7212
V Predictions Min            19.562897
Log Pis Mean                 -8.18071
Log Pis Std                  6.559806
Log Pis Max                  17.525892
Log Pis Min                  -14.425809
Policy mu Mean               0.07995321
Policy mu Std                0.5178717
Policy mu Max                2.1598496
Policy mu Min                -2.1282141
Policy log std Mean          -0.19828196
Policy log std Std           0.12207356
Policy log std Max           -0.08936924
Policy log std Min           -0.7544074
Z mean eval                  0.023169916
Z variance eval              0.2562507
total_rewards                [279.54217248 463.82057669 429.36455316 380.18694826 342.47085593
 346.64791624 373.5529791  527.27505078 370.18768795 392.17600754]
total_rewards_mean           390.52247481318136
total_rewards_std            65.53180366422087
total_rewards_max            527.2750507751839
total_rewards_min            279.5421724829466
Number of train steps total  56000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               118.23663679230958
(Previous) Eval Time (s)     2.1339986361563206
Sample Time (s)              14.430919088888913
Epoch Time (s)               134.80155451735482
Total Train Time (s)         1888.2492104219273
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:55:37.386471 UTC | [2020_01_14_06_24_08] Iteration #13 | Epoch Duration: 134.7259078025818
2020-01-14 06:55:37.386745 UTC | [2020_01_14_06_24_08] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023082659
Z variance train             0.25624222
KL Divergence                1.647496
KL Loss                      0.1647496
QF Loss                      173.1966
VF Loss                      287.37558
Policy Loss                  -194.06596
Q Predictions Mean           185.9458
Q Predictions Std            317.11844
Q Predictions Max            1116.3341
Q Predictions Min            14.432302
V Predictions Mean           196.47879
V Predictions Std            315.208
V Predictions Max            1107.1373
V Predictions Min            27.40085
Log Pis Mean                 -8.543664
Log Pis Std                  5.5202665
Log Pis Max                  16.000637
Log Pis Min                  -13.707472
Policy mu Mean               0.09375194
Policy mu Std                0.49997494
Policy mu Max                2.379177
Policy mu Min                -2.0895102
Policy log std Mean          -0.19229351
Policy log std Std           0.11577224
Policy log std Max           -0.09032435
Policy log std Min           -0.7799672
Z mean eval                  0.02470545
Z variance eval              0.24825561
total_rewards                [356.06027974 462.15248194 387.61127026 502.95095922 405.36910839
 413.71983617 362.02442219 424.42653513 372.12625565 604.74693417]
total_rewards_mean           429.11880828531895
total_rewards_std            72.81557164007316
total_rewards_max            604.7469341727086
total_rewards_min            356.06027973957146
Number of train steps total  60000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               116.70804511103779
(Previous) Eval Time (s)     2.0581174110993743
Sample Time (s)              15.630326699465513
Epoch Time (s)               134.39648922160268
Total Train Time (s)         2023.0310879708268
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:57:52.168668 UTC | [2020_01_14_06_24_08] Iteration #14 | Epoch Duration: 134.78171300888062
2020-01-14 06:57:52.168893 UTC | [2020_01_14_06_24_08] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024676153
Z variance train             0.2482473
KL Divergence                1.6848607
KL Loss                      0.16848607
QF Loss                      274.03424
VF Loss                      112.18915
Policy Loss                  -220.46799
Q Predictions Mean           212.8627
Q Predictions Std            352.99924
Q Predictions Max            1151.4921
Q Predictions Min            18.247986
V Predictions Mean           220.28333
V Predictions Std            347.81134
V Predictions Max            1138.0359
V Predictions Min            26.946651
Log Pis Mean                 -8.362849
Log Pis Std                  6.2422876
Log Pis Max                  31.864754
Log Pis Min                  -14.23606
Policy mu Mean               0.06273168
Policy mu Std                0.51300037
Policy mu Max                2.7969394
Policy mu Min                -2.6481042
Policy log std Mean          -0.19656172
Policy log std Std           0.12765048
Policy log std Max           -0.02606988
Policy log std Min           -1.0669003
Z mean eval                  0.027496327
Z variance eval              0.23873325
total_rewards                [285.34527134 393.281868   428.0141527  211.24552044 459.23562836
 432.32385347 296.75620555 473.96550954 316.3888065  366.05127892]
total_rewards_mean           366.2608094816825
total_rewards_std            81.88270442964749
total_rewards_max            473.9655095448728
total_rewards_min            211.24552044117772
Number of train steps total  64000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               113.36017687106505
(Previous) Eval Time (s)     2.4430723609402776
Sample Time (s)              14.446247337851673
Epoch Time (s)               130.249496569857
Total Train Time (s)         2152.995012022555
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:00:02.132839 UTC | [2020_01_14_06_24_08] Iteration #15 | Epoch Duration: 129.96379780769348
2020-01-14 07:00:02.132996 UTC | [2020_01_14_06_24_08] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027515497
Z variance train             0.23872797
KL Divergence                1.7374433
KL Loss                      0.17374434
QF Loss                      283.17828
VF Loss                      179.79984
Policy Loss                  -273.8406
Q Predictions Mean           263.60782
Q Predictions Std            397.5826
Q Predictions Max            1196.4758
Q Predictions Min            15.282914
V Predictions Mean           275.66138
V Predictions Std            397.4943
V Predictions Max            1221.0583
V Predictions Min            25.817297
Log Pis Mean                 -7.8915796
Log Pis Std                  6.304888
Log Pis Max                  20.50835
Log Pis Min                  -15.050962
Policy mu Mean               0.09187115
Policy mu Std                0.54563916
Policy mu Max                2.2480588
Policy mu Min                -2.237861
Policy log std Mean          -0.20547068
Policy log std Std           0.12687312
Policy log std Max           -0.040202066
Policy log std Min           -0.83582103
Z mean eval                  0.028181497
Z variance eval              0.23015368
total_rewards                [352.06054735 577.98651813 506.47865467 664.38077323 349.16516371
 335.59228281 362.65184271 361.7445454  421.02579476 368.60013907]
total_rewards_mean           429.96862618380175
total_rewards_std            108.28205665869557
total_rewards_max            664.3807732282941
total_rewards_min            335.5922828080436
Number of train steps total  68000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               114.04255933593959
(Previous) Eval Time (s)     2.157145252916962
Sample Time (s)              15.210030396934599
Epoch Time (s)               131.40973498579115
Total Train Time (s)         2284.653657224495
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:02:13.792385 UTC | [2020_01_14_06_24_08] Iteration #16 | Epoch Duration: 131.65927600860596
2020-01-14 07:02:13.792549 UTC | [2020_01_14_06_24_08] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028114269
Z variance train             0.2301496
KL Divergence                1.7881718
KL Loss                      0.17881718
QF Loss                      212.19302
VF Loss                      143.79636
Policy Loss                  -234.22054
Q Predictions Mean           225.14706
Q Predictions Std            368.89108
Q Predictions Max            1224.4973
Q Predictions Min            14.5612545
V Predictions Mean           236.50952
V Predictions Std            370.52084
V Predictions Max            1238.9655
V Predictions Min            24.619856
Log Pis Mean                 -8.857378
Log Pis Std                  5.029889
Log Pis Max                  9.233383
Log Pis Min                  -13.210012
Policy mu Mean               0.09820086
Policy mu Std                0.48531583
Policy mu Max                2.1621199
Policy mu Min                -1.7645102
Policy log std Mean          -0.19083141
Policy log std Std           0.1145163
Policy log std Max           0.00221771
Policy log std Min           -0.7071524
Z mean eval                  0.034901064
Z variance eval              0.22338447
total_rewards                [634.0036001  279.61879727 687.98360989 263.35598698 442.06345365
 382.48043735 409.64135992 509.48045523 405.52669126 263.89086099]
total_rewards_mean           427.8045252644324
total_rewards_std            139.94141116315797
total_rewards_max            687.9836098925289
total_rewards_min            263.35598698478094
Number of train steps total  72000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               115.01195954112336
(Previous) Eval Time (s)     2.4064338570460677
Sample Time (s)              14.02017774246633
Epoch Time (s)               131.43857114063576
Total Train Time (s)         2416.076490450185
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:04:25.217949 UTC | [2020_01_14_06_24_08] Iteration #17 | Epoch Duration: 131.42524981498718
2020-01-14 07:04:25.218211 UTC | [2020_01_14_06_24_08] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034761153
Z variance train             0.22338662
KL Divergence                1.8497488
KL Loss                      0.1849749
QF Loss                      132.69829
VF Loss                      80.525246
Policy Loss                  -214.54326
Q Predictions Mean           208.12442
Q Predictions Std            345.44666
Q Predictions Max            1205.8069
Q Predictions Min            17.44765
V Predictions Mean           216.8779
V Predictions Std            341.35953
V Predictions Max            1215.1915
V Predictions Min            26.661974
Log Pis Mean                 -8.729848
Log Pis Std                  5.302208
Log Pis Max                  15.93249
Log Pis Min                  -13.341297
Policy mu Mean               0.08873268
Policy mu Std                0.46716097
Policy mu Max                2.2544115
Policy mu Min                -2.0246742
Policy log std Mean          -0.18840131
Policy log std Std           0.11198783
Policy log std Max           0.0059300363
Policy log std Min           -0.7887212
Z mean eval                  0.04000581
Z variance eval              0.2283328
total_rewards                [420.03032072 412.94501663 539.09464139 469.97367181 667.11666281
 624.10653158 391.57178646 391.78460155 587.6445616  366.94017384]
total_rewards_mean           487.12079683798845
total_rewards_std            103.40652735643062
total_rewards_max            667.1166628076246
total_rewards_min            366.9401738426975
Number of train steps total  76000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               112.40777530102059
(Previous) Eval Time (s)     2.3928484339267015
Sample Time (s)              15.063926490489393
Epoch Time (s)               129.8645502254367
Total Train Time (s)         2546.1847744458355
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:06:35.326029 UTC | [2020_01_14_06_24_08] Iteration #18 | Epoch Duration: 130.10764908790588
2020-01-14 07:06:35.326181 UTC | [2020_01_14_06_24_08] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039923448
Z variance train             0.22834007
KL Divergence                1.8082836
KL Loss                      0.18082836
QF Loss                      215.29787
VF Loss                      132.93253
Policy Loss                  -247.9192
Q Predictions Mean           240.126
Q Predictions Std            379.7492
Q Predictions Max            1208.7476
Q Predictions Min            8.257486
V Predictions Mean           250.57361
V Predictions Std            377.95032
V Predictions Max            1215.7922
V Predictions Min            23.364859
Log Pis Mean                 -8.745705
Log Pis Std                  5.0341864
Log Pis Max                  8.548819
Log Pis Min                  -13.663636
Policy mu Mean               0.088129744
Policy mu Std                0.47988567
Policy mu Max                2.0879834
Policy mu Min                -2.018219
Policy log std Mean          -0.1935985
Policy log std Std           0.11578944
Policy log std Max           -0.02796784
Policy log std Min           -0.9483516
Z mean eval                  0.045938503
Z variance eval              0.22558442
total_rewards                [340.44039715 302.24845629 614.68156177 589.26493538 352.99252088
 382.54753295 508.19917633 330.30898591 371.26261425 379.34527436]
total_rewards_mean           417.1291455273225
total_rewards_std            106.022954584067
total_rewards_max            614.6815617732465
total_rewards_min            302.2484562896695
Number of train steps total  80000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               115.92554308800027
(Previous) Eval Time (s)     2.6356841321103275
Sample Time (s)              15.95608147745952
Epoch Time (s)               134.51730869757012
Total Train Time (s)         2680.6238891603425
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:08:49.767120 UTC | [2020_01_14_06_24_08] Iteration #19 | Epoch Duration: 134.4408142566681
2020-01-14 07:08:49.767329 UTC | [2020_01_14_06_24_08] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045692574
Z variance train             0.22559933
KL Divergence                1.8315492
KL Loss                      0.18315493
QF Loss                      218.23636
VF Loss                      249.56377
Policy Loss                  -231.61224
Q Predictions Mean           225.96649
Q Predictions Std            372.80533
Q Predictions Max            1224.2329
Q Predictions Min            16.009974
V Predictions Mean           238.755
V Predictions Std            374.54474
V Predictions Max            1230.2798
V Predictions Min            26.590078
Log Pis Mean                 -8.949375
Log Pis Std                  4.878669
Log Pis Max                  19.03806
Log Pis Min                  -14.6896515
Policy mu Mean               0.08275614
Policy mu Std                0.46807048
Policy mu Max                2.1977158
Policy mu Min                -2.3762279
Policy log std Mean          -0.18621613
Policy log std Std           0.107109405
Policy log std Max           0.026207492
Policy log std Min           -0.7330001
Z mean eval                  0.049584806
Z variance eval              0.2209069
total_rewards                [305.68862283 260.84106358 429.16237218 406.7541201  343.86947876
 478.71287662 362.02594396 372.38534049 360.23776941 311.16451358]
total_rewards_mean           363.0842101504648
total_rewards_std            60.4581520378262
total_rewards_max            478.71287661758834
total_rewards_min            260.8410635751104
Number of train steps total  84000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               118.72012183209881
(Previous) Eval Time (s)     2.558941970113665
Sample Time (s)              15.688112331088632
Epoch Time (s)               136.9671761333011
Total Train Time (s)         2817.2735137967393
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:11:06.419157 UTC | [2020_01_14_06_24_08] Iteration #20 | Epoch Duration: 136.65164375305176
2020-01-14 07:11:06.419412 UTC | [2020_01_14_06_24_08] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049501717
Z variance train             0.22093149
KL Divergence                1.8670408
KL Loss                      0.18670408
QF Loss                      238.43298
VF Loss                      249.9252
Policy Loss                  -260.77756
Q Predictions Mean           251.69502
Q Predictions Std            407.68964
Q Predictions Max            1437.0181
Q Predictions Min            13.505402
V Predictions Mean           266.2285
V Predictions Std            411.39346
V Predictions Max            1422.0383
V Predictions Min            20.905575
Log Pis Mean                 -8.6035
Log Pis Std                  5.320071
Log Pis Max                  17.71619
Log Pis Min                  -13.324663
Policy mu Mean               0.07688645
Policy mu Std                0.47265783
Policy mu Max                2.3049586
Policy mu Min                -1.9922051
Policy log std Mean          -0.18874252
Policy log std Std           0.10869047
Policy log std Max           -0.054478064
Policy log std Min           -0.71997577
Z mean eval                  0.053080954
Z variance eval              0.22227049
total_rewards                [400.7739926  487.36334242 477.56291381 536.72918644 342.43390961
 420.49419664 471.78913504 430.77241334 407.47155805 440.85530607]
total_rewards_mean           441.6245954022006
total_rewards_std            51.55310627743611
total_rewards_max            536.7291864438953
total_rewards_min            342.433909612184
Number of train steps total  88000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               114.37944457726553
(Previous) Eval Time (s)     2.243134126998484
Sample Time (s)              15.142061879392713
Epoch Time (s)               131.76464058365673
Total Train Time (s)         2948.9988920227624
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:13:18.146023 UTC | [2020_01_14_06_24_08] Iteration #21 | Epoch Duration: 131.72639298439026
2020-01-14 07:13:18.146275 UTC | [2020_01_14_06_24_08] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053229965
Z variance train             0.222279
KL Divergence                1.8579642
KL Loss                      0.18579642
QF Loss                      208.65625
VF Loss                      239.36987
Policy Loss                  -255.2621
Q Predictions Mean           243.59087
Q Predictions Std            382.62466
Q Predictions Max            1267.9393
Q Predictions Min            16.585539
V Predictions Mean           250.16
V Predictions Std            378.76962
V Predictions Max            1257.8103
V Predictions Min            26.679071
Log Pis Mean                 -8.348267
Log Pis Std                  5.855638
Log Pis Max                  16.87599
Log Pis Min                  -14.99964
Policy mu Mean               0.0771595
Policy mu Std                0.49795923
Policy mu Max                2.6121511
Policy mu Min                -2.2356837
Policy log std Mean          -0.19354284
Policy log std Std           0.11791984
Policy log std Max           -0.011762895
Policy log std Min           -0.9431691
Z mean eval                  0.05916171
Z variance eval              0.22721569
total_rewards                [428.60841585 635.25270988 525.7943334  543.88144718 530.33488341
 642.99850852 537.17197917 355.51811174 687.02811476 414.0590894 ]
total_rewards_mean           530.0647593301549
total_rewards_std            101.45589771372671
total_rewards_max            687.0281147603712
total_rewards_min            355.51811173870215
Number of train steps total  92000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               117.50276179006323
(Previous) Eval Time (s)     2.2046474902890623
Sample Time (s)              15.204639432951808
Epoch Time (s)               134.9120487133041
Total Train Time (s)         3084.7456758106127
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:15:33.893009 UTC | [2020_01_14_06_24_08] Iteration #22 | Epoch Duration: 135.74655318260193
2020-01-14 07:15:33.893205 UTC | [2020_01_14_06_24_08] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0590976
Z variance train             0.22725919
KL Divergence                1.8075035
KL Loss                      0.18075036
QF Loss                      303.87872
VF Loss                      100.44563
Policy Loss                  -213.41438
Q Predictions Mean           205.38419
Q Predictions Std            349.94
Q Predictions Max            1235.2997
Q Predictions Min            14.455002
V Predictions Mean           216.36214
V Predictions Std            349.10803
V Predictions Max            1248.3855
V Predictions Min            23.119978
Log Pis Mean                 -8.955519
Log Pis Std                  4.767409
Log Pis Max                  8.857241
Log Pis Min                  -13.32411
Policy mu Mean               0.08676694
Policy mu Std                0.45043987
Policy mu Max                2.0435688
Policy mu Min                -1.8773469
Policy log std Mean          -0.18547815
Policy log std Std           0.105537035
Policy log std Max           -0.010642275
Policy log std Min           -0.6818379
Z mean eval                  0.061695088
Z variance eval              0.22592112
total_rewards                [ 425.00458604  388.06769262  475.48924784  536.4394982   527.96657212
  411.25314056 1027.84462611  441.99221467  390.61457905  380.90627315]
total_rewards_mean           500.5578430354054
total_rewards_std            183.540221324117
total_rewards_max            1027.8446261054635
total_rewards_min            380.9062731497109
Number of train steps total  96000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               114.64498323388398
(Previous) Eval Time (s)     3.0389159261249006
Sample Time (s)              16.622684532776475
Epoch Time (s)               134.30658369278535
Total Train Time (s)         3219.0174797605723
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:17:48.166304 UTC | [2020_01_14_06_24_08] Iteration #23 | Epoch Duration: 134.2729594707489
2020-01-14 07:17:48.166498 UTC | [2020_01_14_06_24_08] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061532788
Z variance train             0.2259517
KL Divergence                1.8197284
KL Loss                      0.18197285
QF Loss                      282.687
VF Loss                      130.51549
Policy Loss                  -287.4166
Q Predictions Mean           282.88693
Q Predictions Std            443.2478
Q Predictions Max            1284.6605
Q Predictions Min            12.063944
V Predictions Mean           289.01212
V Predictions Std            436.9471
V Predictions Max            1293.3956
V Predictions Min            19.640772
Log Pis Mean                 -8.703351
Log Pis Std                  5.0898376
Log Pis Max                  13.862919
Log Pis Min                  -14.773941
Policy mu Mean               0.08676307
Policy mu Std                0.48528272
Policy mu Max                2.3794725
Policy mu Min                -1.9978718
Policy log std Mean          -0.19251275
Policy log std Std           0.113375865
Policy log std Max           -0.06230265
Policy log std Min           -0.7543193
Z mean eval                  0.060264915
Z variance eval              0.222513
total_rewards                [429.38448098 357.8333803  278.13631244 361.54282506 271.72428847
 306.64273538 510.66716752 474.4478117  311.40316447 293.54452628]
total_rewards_mean           359.53266925978403
total_rewards_std            80.45945465218793
total_rewards_max            510.6671675228193
total_rewards_min            271.7242884676076
Number of train steps total  100000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               118.17006148770452
(Previous) Eval Time (s)     3.0050091953016818
Sample Time (s)              14.743069688789546
Epoch Time (s)               135.91814037179574
Total Train Time (s)         3354.0537841795012
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:20:03.204196 UTC | [2020_01_14_06_24_08] Iteration #24 | Epoch Duration: 135.03751754760742
2020-01-14 07:20:03.204423 UTC | [2020_01_14_06_24_08] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060225636
Z variance train             0.22252539
KL Divergence                1.8550246
KL Loss                      0.18550245
QF Loss                      336.75
VF Loss                      194.60838
Policy Loss                  -284.449
Q Predictions Mean           274.93683
Q Predictions Std            425.8282
Q Predictions Max            1310.738
Q Predictions Min            7.0377116
V Predictions Mean           285.33118
V Predictions Std            425.30795
V Predictions Max            1323.2915
V Predictions Min            25.443779
Log Pis Mean                 -8.556888
Log Pis Std                  5.2749987
Log Pis Max                  11.275469
Log Pis Min                  -13.609483
Policy mu Mean               0.071161225
Policy mu Std                0.49608433
Policy mu Max                2.1962938
Policy mu Min                -2.1018407
Policy log std Mean          -0.19713545
Policy log std Std           0.11658018
Policy log std Max           -0.010190964
Policy log std Min           -0.7342037
Z mean eval                  0.056135617
Z variance eval              0.21891704
total_rewards                [557.92175937 597.22253679 281.31746264 407.87963599 369.97234633
 405.20453307 475.53027114 332.21607564 289.33451061 333.29181067]
total_rewards_mean           404.98909422458667
total_rewards_std            102.79095111182369
total_rewards_max            597.2225367921956
total_rewards_min            281.31746263554186
Number of train steps total  104000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               118.5247662179172
(Previous) Eval Time (s)     2.1241453527472913
Sample Time (s)              14.954892520792782
Epoch Time (s)               135.60380409145728
Total Train Time (s)         3490.331371216569
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:22:19.485689 UTC | [2020_01_14_06_24_08] Iteration #25 | Epoch Duration: 136.28095269203186
2020-01-14 07:22:19.486123 UTC | [2020_01_14_06_24_08] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056105483
Z variance train             0.21895042
KL Divergence                1.8845326
KL Loss                      0.18845326
QF Loss                      279.58923
VF Loss                      103.01338
Policy Loss                  -296.08295
Q Predictions Mean           285.10046
Q Predictions Std            417.5155
Q Predictions Max            1336.8685
Q Predictions Min            18.146803
V Predictions Mean           294.32977
V Predictions Std            415.49832
V Predictions Max            1339.9525
V Predictions Min            22.566734
Log Pis Mean                 -8.559044
Log Pis Std                  5.3407474
Log Pis Max                  23.81354
Log Pis Min                  -15.487097
Policy mu Mean               0.08464342
Policy mu Std                0.5137634
Policy mu Max                2.3984807
Policy mu Min                -2.0874367
Policy log std Mean          -0.20079663
Policy log std Std           0.11426408
Policy log std Max           -0.028639361
Policy log std Min           -0.7376447
Z mean eval                  0.057840347
Z variance eval              0.21455422
total_rewards                [518.51823477 367.02072553 365.59471275 581.18116243 999.34499491
 496.35387377 490.48011585 745.49411308 432.60106066 585.39789505]
total_rewards_mean           558.1986888793347
total_rewards_std            181.75885793761833
total_rewards_max            999.344994908508
total_rewards_min            365.5947127534272
Number of train steps total  108000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               123.53730787010863
(Previous) Eval Time (s)     2.8010163260623813
Sample Time (s)              15.764744113199413
Epoch Time (s)               142.10306830937043
Total Train Time (s)         3633.537545525003
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:24:42.690961 UTC | [2020_01_14_06_24_08] Iteration #26 | Epoch Duration: 143.20460414886475
2020-01-14 07:24:42.691158 UTC | [2020_01_14_06_24_08] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057996847
Z variance train             0.21454604
KL Divergence                1.918692
KL Loss                      0.1918692
QF Loss                      390.24347
VF Loss                      160.26819
Policy Loss                  -256.2267
Q Predictions Mean           244.81848
Q Predictions Std            381.8617
Q Predictions Max            1282.9741
Q Predictions Min            17.390856
V Predictions Mean           254.82034
V Predictions Std            380.15118
V Predictions Max            1289.0796
V Predictions Min            18.9034
Log Pis Mean                 -8.670269
Log Pis Std                  5.214234
Log Pis Max                  17.825085
Log Pis Min                  -13.800797
Policy mu Mean               0.08119901
Policy mu Std                0.483386
Policy mu Max                2.6176496
Policy mu Min                -2.3647244
Policy log std Mean          -0.1922295
Policy log std Std           0.11157103
Policy log std Max           -0.02225604
Policy log std Min           -0.8235748
Z mean eval                  0.0628852
Z variance eval              0.21535973
total_rewards                [496.80603931 695.23466391 504.47594967 494.53018319 800.55334476
 600.4730569  606.05547869 996.94212407 655.25351682 387.04226248]
total_rewards_mean           623.7366619790611
total_rewards_std            167.49883749201726
total_rewards_max            996.9421240662307
total_rewards_min            387.0422624804933
Number of train steps total  112000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               117.88696196535602
(Previous) Eval Time (s)     3.902314138133079
Sample Time (s)              16.243824377655983
Epoch Time (s)               138.03310048114508
Total Train Time (s)         3771.4415206294507
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:27:00.597448 UTC | [2020_01_14_06_24_08] Iteration #27 | Epoch Duration: 137.90612626075745
2020-01-14 07:27:00.597712 UTC | [2020_01_14_06_24_08] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062884316
Z variance train             0.21533985
KL Divergence                1.9220266
KL Loss                      0.19220267
QF Loss                      389.97882
VF Loss                      180.41652
Policy Loss                  -323.90607
Q Predictions Mean           319.6731
Q Predictions Std            458.9357
Q Predictions Max            1336.2139
Q Predictions Min            12.753024
V Predictions Mean           321.16544
V Predictions Std            449.39685
V Predictions Max            1325.1089
V Predictions Min            18.06827
Log Pis Mean                 -8.217253
Log Pis Std                  5.2333183
Log Pis Max                  13.510148
Log Pis Min                  -13.085771
Policy mu Mean               0.09031513
Policy mu Std                0.508798
Policy mu Max                1.9491094
Policy mu Min                -1.9432212
Policy log std Mean          -0.19870412
Policy log std Std           0.11134204
Policy log std Max           -0.06203506
Policy log std Min           -0.66494054
Z mean eval                  0.06340216
Z variance eval              0.20580506
total_rewards                [532.52748414 483.86996846 467.67382764 471.33491763 562.81079236
 423.45748862 564.26942137 383.75305991 342.82670866 755.19730395]
total_rewards_mean           498.77209727340016
total_rewards_std            109.74824590967253
total_rewards_max            755.1973039538395
total_rewards_min            342.8267086598963
Number of train steps total  116000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               119.41883534099907
(Previous) Eval Time (s)     3.775054327212274
Sample Time (s)              16.514985845424235
Epoch Time (s)               139.70887551363558
Total Train Time (s)         3910.5111300568096
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:29:19.668694 UTC | [2020_01_14_06_24_08] Iteration #28 | Epoch Duration: 139.07078003883362
2020-01-14 07:29:19.668955 UTC | [2020_01_14_06_24_08] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06342368
Z variance train             0.20581865
KL Divergence                1.9999264
KL Loss                      0.19999264
QF Loss                      292.78644
VF Loss                      174.46498
Policy Loss                  -345.37637
Q Predictions Mean           336.79788
Q Predictions Std            454.78128
Q Predictions Max            1370.8508
Q Predictions Min            15.703273
V Predictions Mean           342.26385
V Predictions Std            450.14966
V Predictions Max            1360.6545
V Predictions Min            14.881287
Log Pis Mean                 -8.003806
Log Pis Std                  5.2973847
Log Pis Max                  9.021219
Log Pis Min                  -13.201298
Policy mu Mean               0.094120845
Policy mu Std                0.5391875
Policy mu Max                2.101792
Policy mu Min                -2.914516
Policy log std Mean          -0.2070303
Policy log std Std           0.12029077
Policy log std Max           -0.039104804
Policy log std Min           -0.7277852
Z mean eval                  0.06533672
Z variance eval              0.20872772
total_rewards                [496.01667399 516.27458586 532.98271317 407.25686157 764.44821661
 494.41886278 903.62463723 895.21753262 511.47669294 353.22949292]
total_rewards_mean           587.494626967884
total_rewards_std            185.51653055650849
total_rewards_max            903.6246372268682
total_rewards_min            353.22949291658676
Number of train steps total  120000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               119.37288893107325
(Previous) Eval Time (s)     3.1366881672292948
Sample Time (s)              16.08116666926071
Epoch Time (s)               138.59074376756325
Total Train Time (s)         4049.757277491968
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:31:38.916757 UTC | [2020_01_14_06_24_08] Iteration #29 | Epoch Duration: 139.24752402305603
2020-01-14 07:31:38.917085 UTC | [2020_01_14_06_24_08] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06534959
Z variance train             0.20872553
KL Divergence                1.9765415
KL Loss                      0.19765416
QF Loss                      241.50597
VF Loss                      114.97468
Policy Loss                  -315.97437
Q Predictions Mean           310.16187
Q Predictions Std            454.84604
Q Predictions Max            1400.1896
Q Predictions Min            13.95531
V Predictions Mean           316.79028
V Predictions Std            449.4136
V Predictions Max            1378.3601
V Predictions Min            24.300917
Log Pis Mean                 -9.162986
Log Pis Std                  4.2725577
Log Pis Max                  5.4531894
Log Pis Min                  -15.327078
Policy mu Mean               0.07827108
Policy mu Std                0.46610245
Policy mu Max                1.8938437
Policy mu Min                -1.8416607
Policy log std Mean          -0.19388033
Policy log std Std           0.107899
Policy log std Max           -0.06763589
Policy log std Min           -0.69897616
Z mean eval                  0.06559697
Z variance eval              0.20630161
total_rewards                [646.86597023 789.6613531  276.33536891 599.29143134 434.12751109
 495.72573865 470.92280584 495.74297863 509.7449729  399.00418799]
total_rewards_mean           511.74223186846194
total_rewards_std            133.97587328935194
total_rewards_max            789.6613531044992
total_rewards_min            276.3353689098955
Number of train steps total  124000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               120.42273596301675
(Previous) Eval Time (s)     3.7932429891079664
Sample Time (s)              15.741446937434375
Epoch Time (s)               139.9574258895591
Total Train Time (s)         4188.9431160544045
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:33:58.102650 UTC | [2020_01_14_06_24_08] Iteration #30 | Epoch Duration: 139.18538904190063
2020-01-14 07:33:58.102835 UTC | [2020_01_14_06_24_08] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.065738924
Z variance train             0.2063405
KL Divergence                1.9909922
KL Loss                      0.19909923
QF Loss                      236.72763
VF Loss                      126.4727
Policy Loss                  -330.6366
Q Predictions Mean           321.64844
Q Predictions Std            461.38608
Q Predictions Max            1403.8049
Q Predictions Min            13.883407
V Predictions Mean           329.76715
V Predictions Std            456.2222
V Predictions Max            1388.5703
V Predictions Min            24.251022
Log Pis Mean                 -8.310923
Log Pis Std                  5.1711392
Log Pis Max                  7.62125
Log Pis Min                  -13.664564
Policy mu Mean               0.08586973
Policy mu Std                0.49871534
Policy mu Max                2.2412071
Policy mu Min                -1.951338
Policy log std Mean          -0.20507818
Policy log std Std           0.12126628
Policy log std Max           -0.060716912
Policy log std Min           -0.8233588
Z mean eval                  0.06598246
Z variance eval              0.20286694
total_rewards                [556.99251655 658.53934732 484.73427133 863.14594191 619.03712038
 390.64112515 761.85496075 699.13755116 440.30869891 624.83861356]
total_rewards_mean           609.9230147000992
total_rewards_std            138.98234158449554
total_rewards_max            863.1459419065569
total_rewards_min            390.64112514948687
Number of train steps total  128000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               119.05895269522443
(Previous) Eval Time (s)     3.0208914349786937
Sample Time (s)              16.038778800982982
Epoch Time (s)               138.1186229311861
Total Train Time (s)         4327.732330639847
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:36:16.893046 UTC | [2020_01_14_06_24_08] Iteration #31 | Epoch Duration: 138.79007935523987
2020-01-14 07:36:16.893238 UTC | [2020_01_14_06_24_08] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.065833665
Z variance train             0.20285246
KL Divergence                2.0330496
KL Loss                      0.20330496
QF Loss                      381.8598
VF Loss                      278.12997
Policy Loss                  -348.8738
Q Predictions Mean           338.79797
Q Predictions Std            466.82007
Q Predictions Max            1391.2784
Q Predictions Min            15.110644
V Predictions Mean           352.78882
V Predictions Std            468.7457
V Predictions Max            1409.7886
V Predictions Min            26.857521
Log Pis Mean                 -8.450252
Log Pis Std                  5.075706
Log Pis Max                  13.680756
Log Pis Min                  -15.2963915
Policy mu Mean               0.08236691
Policy mu Std                0.5108047
Policy mu Max                2.471173
Policy mu Min                -2.3071737
Policy log std Mean          -0.2030227
Policy log std Std           0.11494105
Policy log std Max           0.020578846
Policy log std Min           -0.7719193
Z mean eval                  0.06454376
Z variance eval              0.20397346
total_rewards                [552.54757379 597.98756495 569.22039681 805.70888904 702.11070013
 426.95606058 436.05667227 733.42182649 515.18435054 667.60235164]
total_rewards_mean           600.6796386229527
total_rewards_std            119.3013266669569
total_rewards_max            805.7088890383089
total_rewards_min            426.95606058286745
Number of train steps total  132000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               121.1760105220601
(Previous) Eval Time (s)     3.692046444863081
Sample Time (s)              15.720131327398121
Epoch Time (s)               140.5881882943213
Total Train Time (s)         4468.3128691529855
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:38:37.476315 UTC | [2020_01_14_06_24_08] Iteration #32 | Epoch Duration: 140.58292937278748
2020-01-14 07:38:37.476578 UTC | [2020_01_14_06_24_08] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0644259
Z variance train             0.2040234
KL Divergence                2.0252376
KL Loss                      0.20252375
QF Loss                      383.653
VF Loss                      189.68338
Policy Loss                  -306.9256
Q Predictions Mean           303.88373
Q Predictions Std            455.75458
Q Predictions Max            1429.7948
Q Predictions Min            10.543324
V Predictions Mean           309.93982
V Predictions Std            451.9934
V Predictions Max            1439.9128
V Predictions Min            20.59765
Log Pis Mean                 -8.59708
Log Pis Std                  5.1016603
Log Pis Max                  15.135097
Log Pis Min                  -13.997646
Policy mu Mean               0.06677771
Policy mu Std                0.49659327
Policy mu Max                1.9949054
Policy mu Min                -2.0073485
Policy log std Mean          -0.19784139
Policy log std Std           0.112088114
Policy log std Max           -0.031172387
Policy log std Min           -0.70830667
Z mean eval                  0.059799958
Z variance eval              0.19813254
total_rewards                [597.98698149 732.68949899 610.01118662 522.75726547 584.74862343
 288.40745826 426.8261492  900.5971408  450.48693052 722.26161024]
total_rewards_mean           583.6772845022803
total_rewards_std            166.12805553707173
total_rewards_max            900.5971407961192
total_rewards_min            288.4074582567751
Number of train steps total  136000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               114.59418766200542
(Previous) Eval Time (s)     3.686465617734939
Sample Time (s)              15.692946183960885
Epoch Time (s)               133.97359946370125
Total Train Time (s)         4602.069803637918
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:40:51.235952 UTC | [2020_01_14_06_24_08] Iteration #33 | Epoch Duration: 133.75904417037964
2020-01-14 07:40:51.236320 UTC | [2020_01_14_06_24_08] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059764218
Z variance train             0.1981476
KL Divergence                2.085139
KL Loss                      0.2085139
QF Loss                      503.41037
VF Loss                      267.00974
Policy Loss                  -368.47952
Q Predictions Mean           359.0072
Q Predictions Std            488.41635
Q Predictions Max            1444.888
Q Predictions Min            18.27155
V Predictions Mean           369.96533
V Predictions Std            489.22745
V Predictions Max            1450.3523
V Predictions Min            21.127579
Log Pis Mean                 -8.379918
Log Pis Std                  4.7107053
Log Pis Max                  9.674784
Log Pis Min                  -13.912294
Policy mu Mean               0.069123715
Policy mu Std                0.51033896
Policy mu Max                1.9853526
Policy mu Min                -1.8716248
Policy log std Mean          -0.20630962
Policy log std Std           0.11322026
Policy log std Max           0.048293278
Policy log std Min           -0.62616163
Z mean eval                  0.05652809
Z variance eval              0.19889268
total_rewards                [477.36133553 635.60795017 716.71447775 349.26486734 638.338445
 532.60916984 511.84950093 537.83085756 519.93420496 645.82533862]
total_rewards_mean           556.5336147713164
total_rewards_std            100.03131712742409
total_rewards_max            716.7144777500113
total_rewards_min            349.2648673397047
Number of train steps total  140000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               115.99062850372866
(Previous) Eval Time (s)     3.4716424173675478
Sample Time (s)              15.76428468618542
Epoch Time (s)               135.22655560728163
Total Train Time (s)         4736.933258086909
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:43:06.098843 UTC | [2020_01_14_06_24_08] Iteration #34 | Epoch Duration: 134.86232995986938
2020-01-14 07:43:06.099023 UTC | [2020_01_14_06_24_08] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056641925
Z variance train             0.19888923
KL Divergence                2.0863051
KL Loss                      0.20863052
QF Loss                      322.2185
VF Loss                      303.36597
Policy Loss                  -312.64728
Q Predictions Mean           303.702
Q Predictions Std            465.87875
Q Predictions Max            1477.5295
Q Predictions Min            16.544096
V Predictions Mean           303.49725
V Predictions Std            453.48444
V Predictions Max            1440.921
V Predictions Min            21.476646
Log Pis Mean                 -9.221793
Log Pis Std                  4.2285385
Log Pis Max                  10.911144
Log Pis Min                  -13.727016
Policy mu Mean               0.061844673
Policy mu Std                0.45328733
Policy mu Max                2.113643
Policy mu Min                -2.1018157
Policy log std Mean          -0.19030678
Policy log std Std           0.10598714
Policy log std Max           -0.020178407
Policy log std Min           -0.6727792
Z mean eval                  0.05799262
Z variance eval              0.19560066
total_rewards                [ 946.51216345  760.85225431 1307.64677884  506.07055251  459.09826268
  558.95504924  743.2358792   748.29254516  445.57307623  522.08516461]
total_rewards_mean           699.8321726215129
total_rewards_std            254.9175915654882
total_rewards_max            1307.6467788351304
total_rewards_min            445.5730762266088
Number of train steps total  144000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               120.12604329874739
(Previous) Eval Time (s)     3.107164617162198
Sample Time (s)              16.80140572041273
Epoch Time (s)               140.03461363632232
Total Train Time (s)         4877.944610171486
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:45:27.112261 UTC | [2020_01_14_06_24_08] Iteration #35 | Epoch Duration: 141.01303100585938
2020-01-14 07:45:27.112506 UTC | [2020_01_14_06_24_08] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05793315
Z variance train             0.19557817
KL Divergence                2.1070018
KL Loss                      0.21070018
QF Loss                      518.0377
VF Loss                      229.63864
Policy Loss                  -480.02405
Q Predictions Mean           473.7163
Q Predictions Std            544.08636
Q Predictions Max            1475.1942
Q Predictions Min            16.070374
V Predictions Mean           477.90634
V Predictions Std            537.58307
V Predictions Max            1471.6469
V Predictions Min            19.388603
Log Pis Mean                 -7.314503
Log Pis Std                  5.379782
Log Pis Max                  17.252443
Log Pis Min                  -13.165033
Policy mu Mean               0.095924616
Policy mu Std                0.58196604
Policy mu Max                2.7703013
Policy mu Min                -2.0139623
Policy log std Mean          -0.22683835
Policy log std Std           0.12707022
Policy log std Max           0.027857795
Policy log std Min           -0.7929447
Z mean eval                  0.05756526
Z variance eval              0.18891245
total_rewards                [429.46345192 640.67824251 659.9169931  664.44691324 423.95502661
 605.80146669 617.90675085 503.25504266 814.69326305 593.47403538]
total_rewards_mean           595.3591186012623
total_rewards_std            111.85124948516196
total_rewards_max            814.6932630543771
total_rewards_min            423.95502661380056
Number of train steps total  148000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               116.98113383492455
(Previous) Eval Time (s)     4.085293906275183
Sample Time (s)              16.41877809818834
Epoch Time (s)               137.48520583938807
Total Train Time (s)         5014.593212123495
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:47:43.761058 UTC | [2020_01_14_06_24_08] Iteration #36 | Epoch Duration: 136.64840459823608
2020-01-14 07:47:43.761205 UTC | [2020_01_14_06_24_08] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05746122
Z variance train             0.18889478
KL Divergence                2.182417
KL Loss                      0.21824169
QF Loss                      762.9506
VF Loss                      240.48016
Policy Loss                  -421.70062
Q Predictions Mean           415.29398
Q Predictions Std            516.3628
Q Predictions Max            1504.6348
Q Predictions Min            12.472503
V Predictions Mean           426.25372
V Predictions Std            516.8603
V Predictions Max            1513.3317
V Predictions Min            24.663599
Log Pis Mean                 -7.689702
Log Pis Std                  5.470982
Log Pis Max                  20.009777
Log Pis Min                  -14.087316
Policy mu Mean               0.10017023
Policy mu Std                0.5805844
Policy mu Max                2.479844
Policy mu Min                -2.1578112
Policy log std Mean          -0.22405075
Policy log std Std           0.12922041
Policy log std Max           -0.05818224
Policy log std Min           -0.7549039
Z mean eval                  0.054354668
Z variance eval              0.18800698
total_rewards                [ 558.29583882  553.56708633  623.88427646  684.88111836  482.38668649
  576.76318052  538.80793874  965.65828211 1298.70090943  483.75099726]
total_rewards_mean           676.6696314528334
total_rewards_std            246.25358312026228
total_rewards_max            1298.7009094338873
total_rewards_min            482.38668648598366
Number of train steps total  152000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               123.41652962798253
(Previous) Eval Time (s)     3.2482449100352824
Sample Time (s)              16.013750246260315
Epoch Time (s)               142.67852478427812
Total Train Time (s)         5158.192065637559
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:50:07.361684 UTC | [2020_01_14_06_24_08] Iteration #37 | Epoch Duration: 143.60034680366516
2020-01-14 07:50:07.361928 UTC | [2020_01_14_06_24_08] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054380257
Z variance train             0.18800405
KL Divergence                2.2014425
KL Loss                      0.22014426
QF Loss                      368.91547
VF Loss                      256.80832
Policy Loss                  -431.9491
Q Predictions Mean           427.0614
Q Predictions Std            539.5058
Q Predictions Max            1510.4519
Q Predictions Min            11.571263
V Predictions Mean           434.18597
V Predictions Std            536.0264
V Predictions Max            1513.3746
V Predictions Min            13.332996
Log Pis Mean                 -7.7080283
Log Pis Std                  5.528813
Log Pis Max                  15.528622
Log Pis Min                  -13.385176
Policy mu Mean               0.08044836
Policy mu Std                0.55433804
Policy mu Max                2.3550189
Policy mu Min                -2.1734016
Policy log std Mean          -0.22239326
Policy log std Std           0.12787277
Policy log std Max           0.012509182
Policy log std Min           -0.7897313
Z mean eval                  0.051882397
Z variance eval              0.18635401
total_rewards                [ 538.57535539  644.80848375  576.70348984  720.39974288  519.59901931
 1828.41256406  528.3981627   667.30612867  678.03311865 1080.06180571]
total_rewards_mean           778.2297870962299
total_rewards_std            382.7307448809679
total_rewards_max            1828.4125640592697
total_rewards_min            519.5990193127896
Number of train steps total  156000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               121.67310834908858
(Previous) Eval Time (s)     4.16979523608461
Sample Time (s)              15.666729875840247
Epoch Time (s)               141.50963346101344
Total Train Time (s)         5299.997413824312
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:52:29.167124 UTC | [2020_01_14_06_24_08] Iteration #38 | Epoch Duration: 141.8050410747528
2020-01-14 07:52:29.167298 UTC | [2020_01_14_06_24_08] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051909257
Z variance train             0.18635736
KL Divergence                2.2152853
KL Loss                      0.22152853
QF Loss                      276.48096
VF Loss                      166.4936
Policy Loss                  -338.79575
Q Predictions Mean           329.98065
Q Predictions Std            491.13107
Q Predictions Max            1514.8876
Q Predictions Min            15.818638
V Predictions Mean           335.30432
V Predictions Std            486.08112
V Predictions Max            1503.1976
V Predictions Min            22.465492
Log Pis Mean                 -8.6816635
Log Pis Std                  4.8247886
Log Pis Max                  9.997182
Log Pis Min                  -13.584268
Policy mu Mean               0.08131772
Policy mu Std                0.49050775
Policy mu Max                1.928279
Policy mu Min                -2.1731513
Policy log std Mean          -0.19981636
Policy log std Std           0.112931654
Policy log std Max           -0.059952497
Policy log std Min           -0.73928064
Z mean eval                  0.051136076
Z variance eval              0.17830983
total_rewards                [ 751.8003136  1608.29617462  702.11407356  549.0384211   854.98346198
  434.83551939  637.16725227  608.80762224  600.2993721  1201.27183706]
total_rewards_mean           794.8614047922944
total_rewards_std            335.90206441683625
total_rewards_max            1608.296174624436
total_rewards_min            434.83551938596804
Number of train steps total  160000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               113.78094770992175
(Previous) Eval Time (s)     4.464940568897873
Sample Time (s)              15.599451627582312
Epoch Time (s)               133.84533990640193
Total Train Time (s)         5433.876791238319
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:54:43.047631 UTC | [2020_01_14_06_24_08] Iteration #39 | Epoch Duration: 133.88021993637085
2020-01-14 07:54:43.047782 UTC | [2020_01_14_06_24_08] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05116427
Z variance train             0.17829768
KL Divergence                2.328741
KL Loss                      0.23287411
QF Loss                      377.67126
VF Loss                      171.22415
Policy Loss                  -395.35248
Q Predictions Mean           390.06952
Q Predictions Std            539.0006
Q Predictions Max            1523.0002
Q Predictions Min            12.859972
V Predictions Mean           391.58704
V Predictions Std            528.172
V Predictions Max            1511.9995
V Predictions Min            20.718353
Log Pis Mean                 -8.462784
Log Pis Std                  4.9651904
Log Pis Max                  6.94484
Log Pis Min                  -13.90741
Policy mu Mean               0.0744483
Policy mu Std                0.5014748
Policy mu Max                1.8802502
Policy mu Min                -2.0723798
Policy log std Mean          -0.20823187
Policy log std Std           0.122414336
Policy log std Max           -0.061025307
Policy log std Min           -0.7979676
Z mean eval                  0.050400246
Z variance eval              0.17942165
total_rewards                [759.38271818 937.58783804 552.63493391 487.36194099 778.92875648
 633.70867514 696.9946459  718.70017058 765.91418578 657.24940229]
total_rewards_mean           698.8463267307154
total_rewards_std            120.01987152158274
total_rewards_max            937.5878380420112
total_rewards_min            487.361940994941
Number of train steps total  164000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               117.76673579588532
(Previous) Eval Time (s)     4.49955562595278
Sample Time (s)              16.43713273946196
Epoch Time (s)               138.70342416130006
Total Train Time (s)         5572.155410956126
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:57:01.329197 UTC | [2020_01_14_06_24_08] Iteration #40 | Epoch Duration: 138.28124737739563
2020-01-14 07:57:01.329422 UTC | [2020_01_14_06_24_08] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050404824
Z variance train             0.17944372
KL Divergence                2.3093662
KL Loss                      0.23093663
QF Loss                      504.29175
VF Loss                      194.04823
Policy Loss                  -390.1881
Q Predictions Mean           381.48425
Q Predictions Std            541.50006
Q Predictions Max            1534.6504
Q Predictions Min            17.12632
V Predictions Mean           392.46875
V Predictions Std            541.5324
V Predictions Max            1549.6495
V Predictions Min            25.568457
Log Pis Mean                 -8.231012
Log Pis Std                  4.974447
Log Pis Max                  6.740237
Log Pis Min                  -13.038516
Policy mu Mean               0.0833605
Policy mu Std                0.51466924
Policy mu Max                1.9783102
Policy mu Min                -2.1862772
Policy log std Mean          -0.20682392
Policy log std Std           0.117742084
Policy log std Max           -0.032929488
Policy log std Min           -0.7103683
Z mean eval                  0.05042826
Z variance eval              0.17409082
total_rewards                [ 434.67812133 1116.23361368  476.57351533  417.66575792  733.81908635
  470.83416594  489.69576313 1162.92322412  366.0425339   818.65480867]
total_rewards_mean           648.7120590354182
total_rewards_std            280.136869449652
total_rewards_max            1162.9232241245463
total_rewards_min            366.0425338969716
Number of train steps total  168000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               114.92019140906632
(Previous) Eval Time (s)     4.077083624899387
Sample Time (s)              16.559841951821
Epoch Time (s)               135.5571169857867
Total Train Time (s)         5707.532141066622
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:59:16.708124 UTC | [2020_01_14_06_24_08] Iteration #41 | Epoch Duration: 135.3784966468811
2020-01-14 07:59:16.708404 UTC | [2020_01_14_06_24_08] Iteration #41 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050494812
Z variance train             0.17411025
KL Divergence                2.3742123
KL Loss                      0.23742123
QF Loss                      358.7796
VF Loss                      274.6291
Policy Loss                  -472.03073
Q Predictions Mean           461.87357
Q Predictions Std            567.4001
Q Predictions Max            1532.3646
Q Predictions Min            16.212347
V Predictions Mean           470.3256
V Predictions Std            564.9646
V Predictions Max            1545.9635
V Predictions Min            25.131447
Log Pis Mean                 -7.791973
Log Pis Std                  5.149858
Log Pis Max                  8.914503
Log Pis Min                  -12.958881
Policy mu Mean               0.09582364
Policy mu Std                0.57116294
Policy mu Max                2.5203648
Policy mu Min                -2.4094107
Policy log std Mean          -0.22357686
Policy log std Std           0.12784484
Policy log std Max           -0.06884043
Policy log std Min           -0.77010393
Z mean eval                  0.051024757
Z variance eval              0.17164186
total_rewards                [925.8548413  591.6114154  550.07409815 829.54426391 526.5867912
 552.03638806 630.21113407 647.50037699 715.73957843 803.20229737]
total_rewards_mean           677.2361184852875
total_rewards_std            129.35476803544083
total_rewards_max            925.8548412982715
total_rewards_min            526.5867911962637
Number of train steps total  172000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               118.58932943735272
(Previous) Eval Time (s)     3.8981643063016236
Sample Time (s)              17.33316725399345
Epoch Time (s)               139.8206609976478
Total Train Time (s)         5847.499438176863
Epoch                        42
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:01:36.676170 UTC | [2020_01_14_06_24_08] Iteration #42 | Epoch Duration: 139.96757125854492
2020-01-14 08:01:36.676383 UTC | [2020_01_14_06_24_08] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050954062
Z variance train             0.1716387
KL Divergence                2.3934948
KL Loss                      0.23934948
QF Loss                      446.33997
VF Loss                      200.33644
Policy Loss                  -452.9694
Q Predictions Mean           446.82538
Q Predictions Std            557.0698
Q Predictions Max            1570.6823
Q Predictions Min            14.088581
V Predictions Mean           452.36444
V Predictions Std            550.6642
V Predictions Max            1552.7147
V Predictions Min            25.908306
Log Pis Mean                 -8.012337
Log Pis Std                  4.8515983
Log Pis Max                  11.81018
Log Pis Min                  -13.753094
Policy mu Mean               0.103185475
Policy mu Std                0.5395145
Policy mu Max                2.441858
Policy mu Min                -2.0448208
Policy log std Mean          -0.21832822
Policy log std Std           0.12134216
Policy log std Max           -0.036791913
Policy log std Min           -0.80646956
Z mean eval                  0.050314862
Z variance eval              0.17060211
total_rewards                [464.66527892 707.19535073 570.03955346 838.29419116 438.08326209
 613.97236688 542.39060511 451.27915613 980.53879771 574.45311333]
total_rewards_mean           618.0911675521127
total_rewards_std            167.787539828997
total_rewards_max            980.5387977064441
total_rewards_min            438.0832620916539
Number of train steps total  176000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               118.84819727297872
(Previous) Eval Time (s)     4.044787625782192
Sample Time (s)              17.220050542615354
Epoch Time (s)               140.11303544137627
Total Train Time (s)         5987.018952960614
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:03:56.198014 UTC | [2020_01_14_06_24_08] Iteration #43 | Epoch Duration: 139.521470785141
2020-01-14 08:03:56.198237 UTC | [2020_01_14_06_24_08] Iteration #43 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050460793
Z variance train             0.17061603
KL Divergence                2.3998613
KL Loss                      0.23998614
QF Loss                      526.76965
VF Loss                      201.90948
Policy Loss                  -460.22513
Q Predictions Mean           454.25687
Q Predictions Std            567.4674
Q Predictions Max            1574.6837
Q Predictions Min            19.011557
V Predictions Mean           457.09613
V Predictions Std            560.60895
V Predictions Max            1570.5315
V Predictions Min            28.2063
Log Pis Mean                 -8.109038
Log Pis Std                  4.916206
Log Pis Max                  11.740952
Log Pis Min                  -19.581772
Policy mu Mean               0.095444486
Policy mu Std                0.52874905
Policy mu Max                2.1579983
Policy mu Min                -2.8263679
Policy log std Mean          -0.21101677
Policy log std Std           0.117072724
Policy log std Max           -0.0040909946
Policy log std Min           -0.7193829
Z mean eval                  0.04793524
Z variance eval              0.16791649
total_rewards                [ 955.36346348  717.93821166  828.55122066  713.7564417   602.3588058
 1227.03471845  760.63270956  811.42137974  996.21164001  849.83294298]
total_rewards_mean           846.3101534055355
total_rewards_std            167.85768290835497
total_rewards_max            1227.0347184513082
total_rewards_min            602.3588058037512
Number of train steps total  180000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               116.23002570075914
(Previous) Eval Time (s)     3.4529595258645713
Sample Time (s)              16.351166038308293
Epoch Time (s)               136.034151264932
Total Train Time (s)         6124.678125302307
Epoch                        44
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:06:13.857508 UTC | [2020_01_14_06_24_08] Iteration #44 | Epoch Duration: 137.65911078453064
2020-01-14 08:06:13.857690 UTC | [2020_01_14_06_24_08] Iteration #44 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047921676
Z variance train             0.16794468
KL Divergence                2.433992
KL Loss                      0.24339919
QF Loss                      548.028
VF Loss                      346.31845
Policy Loss                  -512.42236
Q Predictions Mean           510.6766
Q Predictions Std            606.8823
Q Predictions Max            1586.1543
Q Predictions Min            17.913155
V Predictions Mean           518.7781
V Predictions Std            605.45856
V Predictions Max            1591.2817
V Predictions Min            22.935434
Log Pis Mean                 -7.6019807
Log Pis Std                  5.414369
Log Pis Max                  7.7833586
Log Pis Min                  -15.20154
Policy mu Mean               0.07765329
Policy mu Std                0.57501733
Policy mu Max                1.9726783
Policy mu Min                -2.5299478
Policy log std Mean          -0.22626579
Policy log std Std           0.13032742
Policy log std Max           -0.013302885
Policy log std Min           -0.7007275
Z mean eval                  0.047535058
Z variance eval              0.16524282
total_rewards                [ 598.32712921  608.88371551  509.49388452  579.87441257  400.7224783
  504.99231149  569.74239356  446.77959982  698.40911688 1073.1146815 ]
total_rewards_mean           599.0339723360829
total_rewards_std            177.57270185934084
total_rewards_max            1073.1146815004556
total_rewards_min            400.7224783030306
Number of train steps total  184000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               118.82170533994213
(Previous) Eval Time (s)     5.07764791790396
Sample Time (s)              18.010168937034905
Epoch Time (s)               141.909522194881
Total Train Time (s)         6264.946264712606
Epoch                        45
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:08:34.127385 UTC | [2020_01_14_06_24_08] Iteration #45 | Epoch Duration: 140.26956272125244
2020-01-14 08:08:34.127609 UTC | [2020_01_14_06_24_08] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047594216
Z variance train             0.16525027
KL Divergence                2.4789245
KL Loss                      0.24789245
QF Loss                      291.58655
VF Loss                      135.6201
Policy Loss                  -410.6549
Q Predictions Mean           402.2619
Q Predictions Std            558.9999
Q Predictions Max            1590.8318
Q Predictions Min            15.732924
V Predictions Mean           409.85953
V Predictions Std            556.02216
V Predictions Max            1580.4742
V Predictions Min            28.278606
Log Pis Mean                 -8.259663
Log Pis Std                  4.989274
Log Pis Max                  11.003005
Log Pis Min                  -13.888067
Policy mu Mean               0.08054938
Policy mu Std                0.5155015
Policy mu Max                2.20899
Policy mu Min                -2.0426776
Policy log std Mean          -0.20819613
Policy log std Std           0.11625238
Policy log std Max           -0.045019604
Policy log std Min           -0.7864168
Z mean eval                  0.04621999
Z variance eval              0.15530111
total_rewards                [ 482.04520557  737.68922793  473.2274224   488.73067744 1009.85717853
  424.81854431  393.03488708  630.76683279  520.1857616   270.00959469]
total_rewards_mean           543.0365332344426
total_rewards_std            196.61943585300077
total_rewards_max            1009.8571785283489
total_rewards_min            270.0095946943023
Number of train steps total  188000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               117.06727235903963
(Previous) Eval Time (s)     3.4374253200367093
Sample Time (s)              17.028924986254424
Epoch Time (s)               137.53362266533077
Total Train Time (s)         6402.098214952275
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:10:51.281887 UTC | [2020_01_14_06_24_08] Iteration #46 | Epoch Duration: 137.1541042327881
2020-01-14 08:10:51.282139 UTC | [2020_01_14_06_24_08] Iteration #46 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046211425
Z variance train             0.15532106
KL Divergence                2.602233
KL Loss                      0.2602233
QF Loss                      536.21985
VF Loss                      191.88751
Policy Loss                  -429.15155
Q Predictions Mean           424.54843
Q Predictions Std            567.7451
Q Predictions Max            1613.7296
Q Predictions Min            12.76705
V Predictions Mean           429.57898
V Predictions Std            561.9353
V Predictions Max            1608.2039
V Predictions Min            5.938371
Log Pis Mean                 -8.344009
Log Pis Std                  4.9019003
Log Pis Max                  9.373205
Log Pis Min                  -15.099993
Policy mu Mean               0.10293955
Policy mu Std                0.5243881
Policy mu Max                2.5986986
Policy mu Min                -2.283987
Policy log std Mean          -0.21072969
Policy log std Std           0.11816813
Policy log std Max           0.16167875
Policy log std Min           -0.7900421
Z mean eval                  0.042218845
Z variance eval              0.15200572
total_rewards                [673.90334385 753.51123546 775.30177096 614.55469967 974.24472632
 731.52664464 569.31566145 412.50502535 824.85036899 718.08099831]
total_rewards_mean           704.779447499623
total_rewards_std            144.26978402352262
total_rewards_max            974.2447263207414
total_rewards_min            412.50502534854445
Number of train steps total  192000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               123.16270468989387
(Previous) Eval Time (s)     3.0576298888772726
Sample Time (s)              15.996423352975398
Epoch Time (s)               142.21675793174654
Total Train Time (s)         6545.373164286371
Epoch                        47
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:13:14.556609 UTC | [2020_01_14_06_24_08] Iteration #47 | Epoch Duration: 143.27430057525635
2020-01-14 08:13:14.556746 UTC | [2020_01_14_06_24_08] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042222578
Z variance train             0.15201537
KL Divergence                2.6543684
KL Loss                      0.26543686
QF Loss                      449.84094
VF Loss                      574.9868
Policy Loss                  -480.712
Q Predictions Mean           474.6875
Q Predictions Std            583.80035
Q Predictions Max            1606.2191
Q Predictions Min            11.555829
V Predictions Mean           492.60535
V Predictions Std            591.3285
V Predictions Max            1635.5603
V Predictions Min            23.210161
Log Pis Mean                 -7.4449234
Log Pis Std                  5.562875
Log Pis Max                  12.405228
Log Pis Min                  -15.590426
Policy mu Mean               0.11630442
Policy mu Std                0.57257766
Policy mu Max                2.156924
Policy mu Min                -2.195701
Policy log std Mean          -0.22783028
Policy log std Std           0.12917386
Policy log std Max           -0.039804414
Policy log std Min           -0.7746007
Z mean eval                  0.03836232
Z variance eval              0.14724532
total_rewards                [ 866.24402035  835.79323038  993.34357007  741.68245071  696.78909012
 1061.60751934  625.92119413  598.15230443  704.99909552  593.38922778]
total_rewards_mean           771.7921702823733
total_rewards_std            155.03076263981816
total_rewards_max            1061.607519339764
total_rewards_min            593.389227784482
Number of train steps total  196000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               119.46253682114184
(Previous) Eval Time (s)     4.114871341735125
Sample Time (s)              16.630283117759973
Epoch Time (s)               140.20769128063694
Total Train Time (s)         6685.938229583204
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:15:35.122942 UTC | [2020_01_14_06_24_08] Iteration #48 | Epoch Duration: 140.566086769104
2020-01-14 08:15:35.123110 UTC | [2020_01_14_06_24_08] Iteration #48 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038333226
Z variance train             0.14724815
KL Divergence                2.7089882
KL Loss                      0.27089882
QF Loss                      553.4614
VF Loss                      457.80768
Policy Loss                  -458.94257
Q Predictions Mean           445.96918
Q Predictions Std            552.8723
Q Predictions Max            1614.3262
Q Predictions Min            17.136444
V Predictions Mean           448.1203
V Predictions Std            545.83594
V Predictions Max            1616.6334
V Predictions Min            17.293865
Log Pis Mean                 -7.2360916
Log Pis Std                  5.731086
Log Pis Max                  16.88927
Log Pis Min                  -13.809435
Policy mu Mean               0.10360533
Policy mu Std                0.5915648
Policy mu Max                2.476976
Policy mu Min                -2.287992
Policy log std Mean          -0.22434025
Policy log std Std           0.12658805
Policy log std Max           -0.022369243
Policy log std Min           -0.7401348
Z mean eval                  0.037684094
Z variance eval              0.14398399
total_rewards                [1198.58450603  440.06639848  674.63334242 1286.40680053  768.4138477
  613.06997095  898.86421214 1014.71035965 1536.5528639  1034.63159223]
total_rewards_mean           946.593389403058
total_rewards_std            318.6238000160324
total_rewards_max            1536.5528639007075
total_rewards_min            440.0663984803512
Number of train steps total  200000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               120.56604559114203
(Previous) Eval Time (s)     4.473004627041519
Sample Time (s)              17.42263114033267
Epoch Time (s)               142.46168135851622
Total Train Time (s)         6829.714404932689
Epoch                        49
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:17:58.901527 UTC | [2020_01_14_06_24_08] Iteration #49 | Epoch Duration: 143.7782759666443
2020-01-14 08:17:58.901734 UTC | [2020_01_14_06_24_08] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037709907
Z variance train             0.14400701
KL Divergence                2.7570224
KL Loss                      0.27570224
QF Loss                      470.23898
VF Loss                      206.87674
Policy Loss                  -500.3718
Q Predictions Mean           497.347
Q Predictions Std            606.30054
Q Predictions Max            1650.3881
Q Predictions Min            17.461142
V Predictions Mean           503.6354
V Predictions Std            602.75287
V Predictions Max            1647.8406
V Predictions Min            26.321972
Log Pis Mean                 -7.939437
Log Pis Std                  5.2725234
Log Pis Max                  19.307442
Log Pis Min                  -12.943962
Policy mu Mean               0.07644623
Policy mu Std                0.5566766
Policy mu Max                2.3824277
Policy mu Min                -2.9909406
Policy log std Mean          -0.22257754
Policy log std Std           0.12766045
Policy log std Max           -0.06503884
Policy log std Min           -0.7778597
Z mean eval                  0.03536905
Z variance eval              0.13918227
total_rewards                [ 770.08619481  799.04921569 1063.8700179   545.64677633  696.12072563
  653.03216516 1372.6326843   894.17716172  767.37127618  412.06106548]
total_rewards_mean           797.4047283205481
total_rewards_std            256.1016520228392
total_rewards_max            1372.6326842965616
total_rewards_min            412.0610654775552
Number of train steps total  204000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               119.80584205128253
(Previous) Eval Time (s)     5.78928826097399
Sample Time (s)              17.280427674762905
Epoch Time (s)               142.87555798701942
Total Train Time (s)         6971.651887290645
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:20:20.840125 UTC | [2020_01_14_06_24_08] Iteration #50 | Epoch Duration: 141.93822717666626
2020-01-14 08:20:20.840324 UTC | [2020_01_14_06_24_08] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03534136
Z variance train             0.13916655
KL Divergence                2.8110566
KL Loss                      0.28110567
QF Loss                      504.81625
VF Loss                      194.8907
Policy Loss                  -521.766
Q Predictions Mean           515.8569
Q Predictions Std            590.43774
Q Predictions Max            1668.4652
Q Predictions Min            13.81302
V Predictions Mean           524.1033
V Predictions Std            586.30023
V Predictions Max            1646.8147
V Predictions Min            26.516563
Log Pis Mean                 -6.9311395
Log Pis Std                  6.271878
Log Pis Max                  36.193455
Log Pis Min                  -14.456438
Policy mu Mean               0.085148945
Policy mu Std                0.60943836
Policy mu Max                2.656475
Policy mu Min                -2.9853868
Policy log std Mean          -0.24550124
Policy log std Std           0.14338502
Policy log std Max           -0.041994438
Policy log std Min           -0.9091681
Z mean eval                  0.031951748
Z variance eval              0.13849446
total_rewards                [ 812.4566942  1466.18921276 1495.64978645  816.40979902 1447.91140171
  784.86685453  961.15578368 1057.80881362 1040.911778    649.52948198]
total_rewards_mean           1053.288960594729
total_rewards_std            296.6045847325005
total_rewards_max            1495.6497864471262
total_rewards_min            649.5294819791324
Number of train steps total  208000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               119.19685875624418
(Previous) Eval Time (s)     4.851665803231299
Sample Time (s)              17.290117553435266
Epoch Time (s)               141.33864211291075
Total Train Time (s)         7114.3930183467455
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:22:43.583254 UTC | [2020_01_14_06_24_08] Iteration #51 | Epoch Duration: 142.74277591705322
2020-01-14 08:22:43.583483 UTC | [2020_01_14_06_24_08] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031946972
Z variance train             0.1384803
KL Divergence                2.8060627
KL Loss                      0.28060627
QF Loss                      690.63824
VF Loss                      200.44038
Policy Loss                  -466.95993
Q Predictions Mean           458.71176
Q Predictions Std            585.0716
Q Predictions Max            1651.2021
Q Predictions Min            13.440389
V Predictions Mean           468.23193
V Predictions Std            582.20715
V Predictions Max            1639.7656
V Predictions Min            26.48015
Log Pis Mean                 -7.8912764
Log Pis Std                  5.7108517
Log Pis Max                  13.758814
Log Pis Min                  -14.652945
Policy mu Mean               0.059325416
Policy mu Std                0.56207716
Policy mu Max                2.6416204
Policy mu Min                -2.4432397
Policy log std Mean          -0.2223373
Policy log std Std           0.12948097
Policy log std Max           -0.038126633
Policy log std Min           -0.72887474
Z mean eval                  0.029606957
Z variance eval              0.13651721
total_rewards                [1073.88575575  751.25468523  990.68843017 1311.19298826 1063.65794669
 1189.65008653  549.9088638  1196.90264786  976.84930305 1481.47538072]
total_rewards_mean           1058.546608805265
total_rewards_std            253.71455100073823
total_rewards_max            1481.4753807166583
total_rewards_min            549.9088638003393
Number of train steps total  212000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               117.03714587213472
(Previous) Eval Time (s)     6.255521910730749
Sample Time (s)              17.811024957802147
Epoch Time (s)               141.1036927406676
Total Train Time (s)         7255.490229664836
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:25:04.681850 UTC | [2020_01_14_06_24_08] Iteration #52 | Epoch Duration: 141.09819507598877
2020-01-14 08:25:04.682060 UTC | [2020_01_14_06_24_08] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029579032
Z variance train             0.13653307
KL Divergence                2.828937
KL Loss                      0.28289372
QF Loss                      1040.8784
VF Loss                      295.43616
Policy Loss                  -531.30426
Q Predictions Mean           525.6006
Q Predictions Std            608.2677
Q Predictions Max            1680.5869
Q Predictions Min            16.518333
V Predictions Mean           533.36084
V Predictions Std            604.02954
V Predictions Max            1654.346
V Predictions Min            27.074032
Log Pis Mean                 -7.518135
Log Pis Std                  5.4733677
Log Pis Max                  13.639252
Log Pis Min                  -13.750909
Policy mu Mean               0.07350373
Policy mu Std                0.611655
Policy mu Max                2.4547973
Policy mu Min                -2.539976
Policy log std Mean          -0.23287056
Policy log std Std           0.13445383
Policy log std Max           -0.044697538
Policy log std Min           -0.81789255
Z mean eval                  0.029573226
Z variance eval              0.13335207
total_rewards                [1704.96918625 1705.1016589  1655.66637081 1680.58744307 1105.32740393
 1417.07133534  818.37221971 1463.6618428  1214.65023709 1007.41649899]
total_rewards_mean           1377.2824196899066
total_rewards_std            307.07822503682604
total_rewards_max            1705.1016589028036
total_rewards_min            818.372219712098
Number of train steps total  216000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               119.2449134029448
(Previous) Eval Time (s)     6.249738892074674
Sample Time (s)              17.960763921495527
Epoch Time (s)               143.455416216515
Total Train Time (s)         7400.836644013412
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:27:30.029467 UTC | [2020_01_14_06_24_08] Iteration #53 | Epoch Duration: 145.34724950790405
2020-01-14 08:27:30.029659 UTC | [2020_01_14_06_24_08] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029590786
Z variance train             0.13334154
KL Divergence                2.8828173
KL Loss                      0.28828174
QF Loss                      603.78723
VF Loss                      227.26831
Policy Loss                  -539.7028
Q Predictions Mean           530.26917
Q Predictions Std            623.3874
Q Predictions Max            1685.0366
Q Predictions Min            17.724571
V Predictions Mean           539.59644
V Predictions Std            623.3553
V Predictions Max            1680.568
V Predictions Min            28.387318
Log Pis Mean                 -7.350361
Log Pis Std                  5.7622185
Log Pis Max                  12.615576
Log Pis Min                  -13.923233
Policy mu Mean               0.07114751
Policy mu Std                0.59633213
Policy mu Max                2.3095512
Policy mu Min                -2.182342
Policy log std Mean          -0.2339688
Policy log std Std           0.1345873
Policy log std Max           -0.054684475
Policy log std Min           -0.80995643
Z mean eval                  0.029760113
Z variance eval              0.12965222
total_rewards                [1124.3806107  1285.76521947  662.67878007  883.08042419  871.78048532
 2862.50957542 1344.00667417 1674.550843   1304.05775596  869.4965752 ]
total_rewards_mean           1288.2306943486858
total_rewards_std            596.8285025814945
total_rewards_max            2862.5095754187037
total_rewards_min            662.6787800656284
Number of train steps total  220000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               119.14668398862705
(Previous) Eval Time (s)     8.141310947015882
Sample Time (s)              18.25707720220089
Epoch Time (s)               145.54507213784382
Total Train Time (s)         7545.91488667205
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:29:55.108358 UTC | [2020_01_14_06_24_08] Iteration #54 | Epoch Duration: 145.07856345176697
2020-01-14 08:29:55.108505 UTC | [2020_01_14_06_24_08] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029648826
Z variance train             0.1296551
KL Divergence                2.9417157
KL Loss                      0.29417157
QF Loss                      815.6703
VF Loss                      244.00533
Policy Loss                  -518.8299
Q Predictions Mean           514.2459
Q Predictions Std            627.6612
Q Predictions Max            1683.9646
Q Predictions Min            12.8417425
V Predictions Mean           520.10895
V Predictions Std            622.4518
V Predictions Max            1675.7577
V Predictions Min            27.731655
Log Pis Mean                 -7.3092246
Log Pis Std                  6.0207987
Log Pis Max                  10.404034
Log Pis Min                  -13.201582
Policy mu Mean               0.09883369
Policy mu Std                0.57530075
Policy mu Max                2.3586602
Policy mu Min                -2.4619203
Policy log std Mean          -0.22997148
Policy log std Std           0.13272901
Policy log std Max           -0.027617715
Policy log std Min           -0.7665435
Z mean eval                  0.030306619
Z variance eval              0.12578468
total_rewards                [1248.01733445 1526.83016647 1247.40900821  514.03882292 1260.87309519
  626.61373446 1455.16673415 1732.81536003  801.54406219 1306.3306652 ]
total_rewards_mean           1171.9638983278733
total_rewards_std            377.5720726889952
total_rewards_max            1732.8153600300561
total_rewards_min            514.0388229208187
Number of train steps total  224000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               121.10306817479432
(Previous) Eval Time (s)     7.67455134075135
Sample Time (s)              18.086635001003742
Epoch Time (s)               146.8642545165494
Total Train Time (s)         7692.260687458795
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:32:21.456492 UTC | [2020_01_14_06_24_08] Iteration #55 | Epoch Duration: 146.34785795211792
2020-01-14 08:32:21.456709 UTC | [2020_01_14_06_24_08] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030295556
Z variance train             0.12578481
KL Divergence                3.0046892
KL Loss                      0.30046892
QF Loss                      699.5047
VF Loss                      359.78955
Policy Loss                  -626.71936
Q Predictions Mean           618.6908
Q Predictions Std            661.73694
Q Predictions Max            1707.3718
Q Predictions Min            11.967229
V Predictions Mean           619.83624
V Predictions Std            655.4759
V Predictions Max            1697.8121
V Predictions Min            15.341759
Log Pis Mean                 -6.5898523
Log Pis Std                  6.272472
Log Pis Max                  17.432785
Log Pis Min                  -16.499405
Policy mu Mean               0.06590152
Policy mu Std                0.6341706
Policy mu Max                2.4701936
Policy mu Min                -2.3462021
Policy log std Mean          -0.24625506
Policy log std Std           0.13932194
Policy log std Max           0.08140823
Policy log std Min           -0.7583509
Z mean eval                  0.028839398
Z variance eval              0.12683792
total_rewards                [1316.85847762  708.9191829   795.31963297 1798.819647    507.34599034
 1184.21982261  918.34759014  680.48792271  793.38196724 1638.5989572 ]
total_rewards_mean           1034.229919071184
total_rewards_std            411.0130148600384
total_rewards_max            1798.8196469955767
total_rewards_min            507.3459903412535
Number of train steps total  228000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               121.31879907986149
(Previous) Eval Time (s)     7.157847562804818
Sample Time (s)              18.593634619843215
Epoch Time (s)               147.07028126250952
Total Train Time (s)         7838.681094873231
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:34:47.878831 UTC | [2020_01_14_06_24_08] Iteration #56 | Epoch Duration: 146.42194604873657
2020-01-14 08:34:47.879121 UTC | [2020_01_14_06_24_08] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028793037
Z variance train             0.1268399
KL Divergence                2.984614
KL Loss                      0.2984614
QF Loss                      959.7689
VF Loss                      234.24454
Policy Loss                  -604.1434
Q Predictions Mean           600.8971
Q Predictions Std            654.49194
Q Predictions Max            1738.1447
Q Predictions Min            15.922234
V Predictions Mean           605.4886
V Predictions Std            649.1407
V Predictions Max            1725.0217
V Predictions Min            26.35013
Log Pis Mean                 -6.2388906
Log Pis Std                  6.709551
Log Pis Max                  21.389881
Log Pis Min                  -15.006866
Policy mu Mean               0.10126689
Policy mu Std                0.6556211
Policy mu Max                2.4554894
Policy mu Min                -2.844283
Policy log std Mean          -0.24780773
Policy log std Std           0.14455996
Policy log std Max           0.0005323142
Policy log std Min           -0.79442215
Z mean eval                  0.028127015
Z variance eval              0.12051535
total_rewards                [1848.95208938 1043.01487525  849.85787316 1334.14786678  505.38672835
 1051.87481815 1437.27955636 1722.93540418 1002.19735273  885.63676504]
total_rewards_mean           1168.1283329384992
total_rewards_std            393.49232437946944
total_rewards_max            1848.9520893769707
total_rewards_min            505.3867283480457
Number of train steps total  232000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               119.04449238209054
(Previous) Eval Time (s)     6.509210274089128
Sample Time (s)              18.325033685658127
Epoch Time (s)               143.8787363418378
Total Train Time (s)         7983.046443672851
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:37:12.245078 UTC | [2020_01_14_06_24_08] Iteration #57 | Epoch Duration: 144.36576390266418
2020-01-14 08:37:12.245302 UTC | [2020_01_14_06_24_08] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028249752
Z variance train             0.12051938
KL Divergence                3.0958219
KL Loss                      0.3095822
QF Loss                      612.3645
VF Loss                      290.15674
Policy Loss                  -655.7101
Q Predictions Mean           650.0769
Q Predictions Std            692.00885
Q Predictions Max            1770.6744
Q Predictions Min            15.072893
V Predictions Mean           654.4229
V Predictions Std            689.1673
V Predictions Max            1747.7814
V Predictions Min            24.316029
Log Pis Mean                 -6.4858866
Log Pis Std                  5.689996
Log Pis Max                  9.360493
Log Pis Min                  -15.097401
Policy mu Mean               0.089532346
Policy mu Std                0.63589466
Policy mu Max                2.5360236
Policy mu Min                -2.4527957
Policy log std Mean          -0.2538543
Policy log std Std           0.14403763
Policy log std Max           -0.015631929
Policy log std Min           -0.72228634
Z mean eval                  0.028056687
Z variance eval              0.11587002
total_rewards                [ 857.97996254 1034.43177698 2494.48497126  960.44738197  848.14950793
 1088.53235394 1828.15885149  959.52281288 1210.16130062 1629.42063457]
total_rewards_mean           1291.1289554189582
total_rewards_std            506.71140045288786
total_rewards_max            2494.4849712565165
total_rewards_min            848.1495079304799
Number of train steps total  236000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               120.83254027413204
(Previous) Eval Time (s)     6.995945194270462
Sample Time (s)              18.675583211239427
Epoch Time (s)               146.50406867964193
Total Train Time (s)         8130.594885763712
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:39:39.795405 UTC | [2020_01_14_06_24_08] Iteration #58 | Epoch Duration: 147.54989433288574
2020-01-14 08:39:39.795672 UTC | [2020_01_14_06_24_08] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028102417
Z variance train             0.11585486
KL Divergence                3.1890223
KL Loss                      0.31890222
QF Loss                      1000.82635
VF Loss                      370.46985
Policy Loss                  -744.2223
Q Predictions Mean           736.13293
Q Predictions Std            696.80566
Q Predictions Max            1778.9783
Q Predictions Min            17.461748
V Predictions Mean           742.66034
V Predictions Std            692.5899
V Predictions Max            1766.9612
V Predictions Min            21.177315
Log Pis Mean                 -5.4792852
Log Pis Std                  6.324436
Log Pis Max                  13.5931
Log Pis Min                  -13.520213
Policy mu Mean               0.12537432
Policy mu Std                0.6934273
Policy mu Max                2.6316736
Policy mu Min                -2.4197476
Policy log std Mean          -0.27021527
Policy log std Std           0.14514779
Policy log std Max           -0.04406347
Policy log std Min           -0.7925754
Z mean eval                  0.026331374
Z variance eval              0.11399569
total_rewards                [2287.01824923 1141.94388502 1769.28228172 1595.65451578 1111.43222313
 2166.31425427  979.8475045  1378.83535142 1425.65053449 1566.26831019]
total_rewards_mean           1542.2247109746802
total_rewards_std            412.4989457952946
total_rewards_max            2287.0182492288745
total_rewards_min            979.8475045008457
Number of train steps total  240000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               114.43309286795557
(Previous) Eval Time (s)     8.04140164423734
Sample Time (s)              19.838932069484144
Epoch Time (s)               142.31342658167705
Total Train Time (s)         8274.300015919842
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:42:03.501240 UTC | [2020_01_14_06_24_08] Iteration #59 | Epoch Duration: 143.70541763305664
2020-01-14 08:42:03.501406 UTC | [2020_01_14_06_24_08] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026282435
Z variance train             0.11399214
KL Divergence                3.2234874
KL Loss                      0.32234874
QF Loss                      788.50494
VF Loss                      338.3369
Policy Loss                  -710.4503
Q Predictions Mean           703.09534
Q Predictions Std            714.8421
Q Predictions Max            1817.5518
Q Predictions Min            10.53037
V Predictions Mean           710.5231
V Predictions Std            710.40063
V Predictions Max            1795.6066
V Predictions Min            25.590097
Log Pis Mean                 -6.532605
Log Pis Std                  5.8320565
Log Pis Max                  11.624472
Log Pis Min                  -15.04512
Policy mu Mean               0.097911224
Policy mu Std                0.6432443
Policy mu Max                2.234945
Policy mu Min                -2.5040874
Policy log std Mean          -0.25857407
Policy log std Std           0.14599437
Policy log std Max           0.008720681
Policy log std Min           -0.8039704
Z mean eval                  0.025567904
Z variance eval              0.107070684
total_rewards                [ 853.51841931  750.45138097 1152.43656186 1109.49897913  766.52103236
 1043.38977118  802.77973118 1123.73885659 1198.26371075  965.84153573]
total_rewards_mean           976.6439979074306
total_rewards_std            162.65940167750512
total_rewards_max            1198.2637107498113
total_rewards_min            750.451380971476
Number of train steps total  244000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               116.72710501914844
(Previous) Eval Time (s)     9.433132597245276
Sample Time (s)              19.160444003064185
Epoch Time (s)               145.3206816194579
Total Train Time (s)         8416.033285304438
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:44:25.237891 UTC | [2020_01_14_06_24_08] Iteration #60 | Epoch Duration: 141.73626232147217
2020-01-14 08:44:25.238221 UTC | [2020_01_14_06_24_08] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025625343
Z variance train             0.10706595
KL Divergence                3.3705134
KL Loss                      0.33705136
QF Loss                      1204.6135
VF Loss                      361.44714
Policy Loss                  -609.2549
Q Predictions Mean           602.55835
Q Predictions Std            690.73096
Q Predictions Max            1816.3472
Q Predictions Min            16.448
V Predictions Mean           611.4225
V Predictions Std            687.9152
V Predictions Max            1805.4681
V Predictions Min            31.233818
Log Pis Mean                 -6.9660835
Log Pis Std                  5.8835406
Log Pis Max                  21.016651
Log Pis Min                  -12.708774
Policy mu Mean               0.088966906
Policy mu Std                0.6193514
Policy mu Max                2.8444016
Policy mu Min                -2.4745398
Policy log std Mean          -0.23678398
Policy log std Std           0.13396522
Policy log std Max           -0.04282058
Policy log std Min           -0.778231
Z mean eval                  0.027484458
Z variance eval              0.10318252
total_rewards                [ 683.30192317 1766.68808619 1330.02745304 1027.34898048 1590.51516161
  479.65722147 1073.44724412 2417.96309199 1287.1775854   969.91459306]
total_rewards_mean           1262.6041340522154
total_rewards_std            531.6972593570121
total_rewards_max            2417.963091985188
total_rewards_min            479.6572214670974
Number of train steps total  248000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               119.79889511596411
(Previous) Eval Time (s)     5.848410491831601
Sample Time (s)              19.37367668095976
Epoch Time (s)               145.02098228875548
Total Train Time (s)         8562.94819975458
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:46:52.152476 UTC | [2020_01_14_06_24_08] Iteration #61 | Epoch Duration: 146.91408848762512
2020-01-14 08:46:52.152629 UTC | [2020_01_14_06_24_08] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027512992
Z variance train             0.10318129
KL Divergence                3.4570491
KL Loss                      0.3457049
QF Loss                      1232.1101
VF Loss                      377.84726
Policy Loss                  -692.358
Q Predictions Mean           683.2538
Q Predictions Std            716.73346
Q Predictions Max            1817.0671
Q Predictions Min            15.005991
V Predictions Mean           694.21985
V Predictions Std            717.80536
V Predictions Max            1826.6256
V Predictions Min            27.621708
Log Pis Mean                 -5.88317
Log Pis Std                  6.7192254
Log Pis Max                  22.9342
Log Pis Min                  -13.105587
Policy mu Mean               0.10977567
Policy mu Std                0.6758347
Policy mu Max                3.0888484
Policy mu Min                -2.9876547
Policy log std Mean          -0.26468754
Policy log std Std           0.15725906
Policy log std Max           -0.045023367
Policy log std Min           -1.1392833
Z mean eval                  0.02602759
Z variance eval              0.10292797
total_rewards                [ 916.07423637 3474.75334648 1603.78886499  683.63901646  731.18867542
 1571.84456248  652.9160373  1200.31687131 2097.04364462  613.00694874]
total_rewards_mean           1354.457220419274
total_rewards_std            851.6350128970946
total_rewards_max            3474.753346482009
total_rewards_min            613.0069487413404
Number of train steps total  252000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               118.19705599779263
(Previous) Eval Time (s)     7.741229366976768
Sample Time (s)              19.299943832680583
Epoch Time (s)               145.23822919744998
Total Train Time (s)         8708.762438315898
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:49:17.967835 UTC | [2020_01_14_06_24_08] Iteration #62 | Epoch Duration: 145.81508135795593
2020-01-14 08:49:17.967991 UTC | [2020_01_14_06_24_08] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026119005
Z variance train             0.10292058
KL Divergence                3.468536
KL Loss                      0.34685358
QF Loss                      769.0946
VF Loss                      349.65573
Policy Loss                  -726.8374
Q Predictions Mean           718.57153
Q Predictions Std            752.5856
Q Predictions Max            1860.7195
Q Predictions Min            9.83214
V Predictions Mean           726.0974
V Predictions Std            749.35114
V Predictions Max            1866.1871
V Predictions Min            25.594873
Log Pis Mean                 -6.2676764
Log Pis Std                  6.2936945
Log Pis Max                  12.312212
Log Pis Min                  -13.584624
Policy mu Mean               0.09359144
Policy mu Std                0.6401065
Policy mu Max                2.7498577
Policy mu Min                -2.2496898
Policy log std Mean          -0.26082093
Policy log std Std           0.15104403
Policy log std Max           -0.052081674
Policy log std Min           -0.84679264
Z mean eval                  0.026636565
Z variance eval              0.10026409
total_rewards                [2088.39022712 1602.22392814 2378.98799871 1852.3627982  2696.98135573
 1158.02743274 4843.12804348 1552.93649187 3902.88850935  992.52103916]
total_rewards_mean           2306.8447824488753
total_rewards_std            1162.061628258903
total_rewards_max            4843.12804348209
total_rewards_min            992.5210391603442
Number of train steps total  256000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               121.23412592988461
(Previous) Eval Time (s)     8.317770231049508
Sample Time (s)              19.010511711239815
Epoch Time (s)               148.56240787217394
Total Train Time (s)         8863.54219232034
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:51:52.751770 UTC | [2020_01_14_06_24_08] Iteration #63 | Epoch Duration: 154.78361320495605
2020-01-14 08:51:52.752090 UTC | [2020_01_14_06_24_08] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026686529
Z variance train             0.100273564
KL Divergence                3.5249653
KL Loss                      0.35249653
QF Loss                      735.0856
VF Loss                      327.20416
Policy Loss                  -713.2409
Q Predictions Mean           705.53296
Q Predictions Std            720.4511
Q Predictions Max            1878.0928
Q Predictions Min            16.964252
V Predictions Mean           710.8465
V Predictions Std            718.2019
V Predictions Max            1872.5168
V Predictions Min            23.198141
Log Pis Mean                 -6.408945
Log Pis Std                  5.9524474
Log Pis Max                  18.469715
Log Pis Min                  -13.046498
Policy mu Mean               0.09498084
Policy mu Std                0.6521156
Policy mu Max                2.4618444
Policy mu Min                -2.6035538
Policy log std Mean          -0.26617062
Policy log std Std           0.14526036
Policy log std Max           -0.070938006
Policy log std Min           -0.8405123
Z mean eval                  0.02656528
Z variance eval              0.096109755
total_rewards                [2701.14309272 1577.33058728  886.134776    785.23539072 1866.45488947
 2018.77429859 1929.12989393 2317.78783081 1091.71414018 3619.04333375]
total_rewards_mean           1879.2748233450668
total_rewards_std            825.308254362714
total_rewards_max            3619.0433337462746
total_rewards_min            785.2353907243398
Number of train steps total  260000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               124.90373734617606
(Previous) Eval Time (s)     14.53864938300103
Sample Time (s)              20.87164740776643
Epoch Time (s)               160.31403413694352
Total Train Time (s)         9021.043677126057
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:54:30.254499 UTC | [2020_01_14_06_24_08] Iteration #64 | Epoch Duration: 157.5021939277649
2020-01-14 08:54:30.254761 UTC | [2020_01_14_06_24_08] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026605612
Z variance train             0.09611772
KL Divergence                3.6292167
KL Loss                      0.36292168
QF Loss                      1067.1194
VF Loss                      483.9944
Policy Loss                  -769.88806
Q Predictions Mean           757.1528
Q Predictions Std            732.4353
Q Predictions Max            1881.5415
Q Predictions Min            15.853556
V Predictions Mean           761.37646
V Predictions Std            726.362
V Predictions Max            1876.743
V Predictions Min            11.953332
Log Pis Mean                 -5.295151
Log Pis Std                  7.0459514
Log Pis Max                  17.868849
Log Pis Min                  -16.00898
Policy mu Mean               0.06912694
Policy mu Std                0.7208471
Policy mu Max                2.3810356
Policy mu Min                -2.5727155
Policy log std Mean          -0.27855498
Policy log std Std           0.16330212
Policy log std Max           -0.026302285
Policy log std Min           -1.0279508
Z mean eval                  0.026667261
Z variance eval              0.092383966
total_rewards                [2269.5097538  1386.87008243 2205.53541267 1359.19677365 4950.71777178
 2799.59749021 1210.33377075  772.53755553 2346.70873587 1619.48136523]
total_rewards_mean           2092.0488711917374
total_rewards_std            1120.6264827009718
total_rewards_max            4950.717771779662
total_rewards_min            772.5375555266547
Number of train steps total  264000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               120.2556202779524
(Previous) Eval Time (s)     11.726443672087044
Sample Time (s)              20.324379340279847
Epoch Time (s)               152.3064432903193
Total Train Time (s)         9174.543674466666
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:57:03.754926 UTC | [2020_01_14_06_24_08] Iteration #65 | Epoch Duration: 153.49998259544373
2020-01-14 08:57:03.755089 UTC | [2020_01_14_06_24_08] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026664611
Z variance train             0.09237325
KL Divergence                3.7391038
KL Loss                      0.3739104
QF Loss                      827.11694
VF Loss                      362.1399
Policy Loss                  -730.0104
Q Predictions Mean           723.68445
Q Predictions Std            756.6802
Q Predictions Max            1943.5471
Q Predictions Min            19.189642
V Predictions Mean           729.9492
V Predictions Std            751.8999
V Predictions Max            1916.7872
V Predictions Min            27.62679
Log Pis Mean                 -6.3384595
Log Pis Std                  6.2380934
Log Pis Max                  15.527118
Log Pis Min                  -12.960861
Policy mu Mean               0.0962731
Policy mu Std                0.6437504
Policy mu Max                2.4460196
Policy mu Min                -3.322218
Policy log std Mean          -0.2648237
Policy log std Std           0.1554335
Policy log std Max           -0.043308124
Policy log std Min           -0.8882766
Z mean eval                  0.024711417
Z variance eval              0.08670601
total_rewards                [ 734.30374525 1181.01596852  835.82519386 2046.60173137  981.34742693
 2470.42473114 1614.70405714 1587.99730957 1518.7086512  1835.56652419]
total_rewards_mean           1480.6495339192393
total_rewards_std            526.1918747675172
total_rewards_max            2470.42473114306
total_rewards_min            734.3037452549568
Number of train steps total  268000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               120.85228789784014
(Previous) Eval Time (s)     12.919701131992042
Sample Time (s)              19.406882177107036
Epoch Time (s)               153.17887120693922
Total Train Time (s)         9323.528626046143
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:59:32.743361 UTC | [2020_01_14_06_24_08] Iteration #66 | Epoch Duration: 148.98809337615967
2020-01-14 08:59:32.743656 UTC | [2020_01_14_06_24_08] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024702217
Z variance train             0.086710095
KL Divergence                3.8866909
KL Loss                      0.3886691
QF Loss                      936.66376
VF Loss                      501.75128
Policy Loss                  -785.9671
Q Predictions Mean           776.204
Q Predictions Std            756.3674
Q Predictions Max            1946.549
Q Predictions Min            15.516048
V Predictions Mean           780.63983
V Predictions Std            750.44934
V Predictions Max            1957.5387
V Predictions Min            29.05574
Log Pis Mean                 -4.7823877
Log Pis Std                  7.4068084
Log Pis Max                  16.487307
Log Pis Min                  -15.5061655
Policy mu Mean               0.09677452
Policy mu Std                0.7480936
Policy mu Max                2.6858597
Policy mu Min                -3.3454523
Policy log std Mean          -0.28904903
Policy log std Std           0.16632481
Policy log std Max           -0.084181644
Policy log std Min           -0.90881866
Z mean eval                  0.024855081
Z variance eval              0.0883594
total_rewards                [4809.4509675  3618.12332777 2597.37008862 4975.40427325 1642.83896347
 1768.03070766 4975.95755424 5006.71725694 4959.37790823 1995.38024474]
total_rewards_mean           3634.8651292419695
total_rewards_std            1408.1677555910944
total_rewards_max            5006.717256936633
total_rewards_min            1642.8389634724222
Number of train steps total  272000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               122.06367948511615
(Previous) Eval Time (s)     8.728600484784693
Sample Time (s)              20.0694986237213
Epoch Time (s)               150.86177859362215
Total Train Time (s)         9488.664020855445
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:02:17.881904 UTC | [2020_01_14_06_24_08] Iteration #67 | Epoch Duration: 165.1379930973053
2020-01-14 09:02:17.882216 UTC | [2020_01_14_06_24_08] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024891138
Z variance train             0.088361286
KL Divergence                3.8447382
KL Loss                      0.38447383
QF Loss                      705.60144
VF Loss                      200.1314
Policy Loss                  -782.48206
Q Predictions Mean           776.33984
Q Predictions Std            780.3678
Q Predictions Max            1984.2886
Q Predictions Min            13.843019
V Predictions Mean           780.57294
V Predictions Std            777.5206
V Predictions Max            1975.526
V Predictions Min            24.614134
Log Pis Mean                 -5.7306547
Log Pis Std                  6.5533347
Log Pis Max                  13.46237
Log Pis Min                  -13.487543
Policy mu Mean               0.08487501
Policy mu Std                0.69008064
Policy mu Max                2.47303
Policy mu Min                -3.7054489
Policy log std Mean          -0.27112365
Policy log std Std           0.15528636
Policy log std Max           -0.022420377
Policy log std Min           -0.78918266
Z mean eval                  0.02442117
Z variance eval              0.08440049
total_rewards                [1468.62749255 1943.30273009 1323.40430781 2175.95530987 1429.04942804
 3656.04197411 1009.14915444 2377.25433644 1048.61880104 1924.4164062 ]
total_rewards_mean           1835.5819940580968
total_rewards_std            748.8247719334646
total_rewards_max            3656.041974111142
total_rewards_min            1009.1491544368552
Number of train steps total  276000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               120.53686559014022
(Previous) Eval Time (s)     23.004532728809863
Sample Time (s)              20.62266391981393
Epoch Time (s)               164.16406223876402
Total Train Time (s)         9641.529255136847
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:04:50.748164 UTC | [2020_01_14_06_24_08] Iteration #68 | Epoch Duration: 152.8657088279724
2020-01-14 09:04:50.748441 UTC | [2020_01_14_06_24_08] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024442106
Z variance train             0.08440715
KL Divergence                3.935847
KL Loss                      0.3935847
QF Loss                      749.15967
VF Loss                      391.1507
Policy Loss                  -824.45233
Q Predictions Mean           815.3651
Q Predictions Std            802.5622
Q Predictions Max            2016.9886
Q Predictions Min            17.3035
V Predictions Mean           817.8147
V Predictions Std            796.4148
V Predictions Max            2004.9415
V Predictions Min            24.767
Log Pis Mean                 -5.0175133
Log Pis Std                  7.3613753
Log Pis Max                  32.20472
Log Pis Min                  -13.759395
Policy mu Mean               0.11313013
Policy mu Std                0.72288156
Policy mu Max                2.3542051
Policy mu Min                -3.312176
Policy log std Mean          -0.28450274
Policy log std Std           0.16252111
Policy log std Max           0.031092599
Policy log std Min           -0.96123254
Z mean eval                  0.023205
Z variance eval              0.08233921
total_rewards                [1566.04420938 5008.9172377  1589.61112238 4059.84172765 1771.60487549
 4514.19311993 2293.61448233 2564.00898298 1583.13366297 2369.01367939]
total_rewards_mean           2731.9983100216887
total_rewards_std            1240.2680314949598
total_rewards_max            5008.917237699761
total_rewards_min            1566.0442093843244
Number of train steps total  280000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               119.33006857521832
(Previous) Eval Time (s)     11.705901259090751
Sample Time (s)              20.27459436515346
Epoch Time (s)               151.31056419946253
Total Train Time (s)         9797.353156823665
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:07:26.574447 UTC | [2020_01_14_06_24_08] Iteration #69 | Epoch Duration: 155.82578945159912
2020-01-14 09:07:26.574716 UTC | [2020_01_14_06_24_08] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023170065
Z variance train             0.08233775
KL Divergence                3.9782772
KL Loss                      0.3978277
QF Loss                      820.2407
VF Loss                      486.63522
Policy Loss                  -842.50134
Q Predictions Mean           835.3339
Q Predictions Std            796.3539
Q Predictions Max            2049.0576
Q Predictions Min            15.881052
V Predictions Mean           841.45374
V Predictions Std            794.58466
V Predictions Max            2042.3221
V Predictions Min            21.126411
Log Pis Mean                 -5.331455
Log Pis Std                  6.889157
Log Pis Max                  25.242325
Log Pis Min                  -13.6973715
Policy mu Mean               0.103046335
Policy mu Std                0.69882226
Policy mu Max                2.7731762
Policy mu Min                -2.6839726
Policy log std Mean          -0.27717137
Policy log std Std           0.15750492
Policy log std Max           -0.0012826174
Policy log std Min           -0.8877981
Z mean eval                  0.025978962
Z variance eval              0.0792386
total_rewards                [4953.90472139 3074.37052109 2973.12620878 3669.84353707 3131.47038897
 4981.11451852 4935.86169671 1093.70821339 4085.14830126 3701.59805443]
total_rewards_mean           3660.014616160411
total_rewards_std            1136.216925277132
total_rewards_max            4981.114518516179
total_rewards_min            1093.708213392587
Number of train steps total  284000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               117.5060878880322
(Previous) Eval Time (s)     16.22083356883377
Sample Time (s)              20.307619934901595
Epoch Time (s)               154.03454139176756
Total Train Time (s)         9957.630580680445
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:10:06.852963 UTC | [2020_01_14_06_24_08] Iteration #70 | Epoch Duration: 160.27804470062256
2020-01-14 09:10:06.853186 UTC | [2020_01_14_06_24_08] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025793865
Z variance train             0.079226896
KL Divergence                4.0655975
KL Loss                      0.40655977
QF Loss                      856.26465
VF Loss                      471.26282
Policy Loss                  -855.6897
Q Predictions Mean           853.77905
Q Predictions Std            815.7738
Q Predictions Max            2045.7709
Q Predictions Min            11.540635
V Predictions Mean           862.171
V Predictions Std            815.8114
V Predictions Max            2049.3357
V Predictions Min            18.311462
Log Pis Mean                 -5.2750807
Log Pis Std                  6.82486
Log Pis Max                  19.169266
Log Pis Min                  -12.609744
Policy mu Mean               0.06574219
Policy mu Std                0.7139018
Policy mu Max                2.580265
Policy mu Min                -2.9477377
Policy log std Mean          -0.2879359
Policy log std Std           0.16164227
Policy log std Max           -0.005673215
Policy log std Min           -0.98651993
Z mean eval                  0.027901068
Z variance eval              0.07867949
total_rewards                [ 990.52587735 1709.0573164  4435.69091884 3186.12620179 1235.49724055
 5027.32630656 4984.95910813 1175.0596674  1672.84679661 2918.81563988]
total_rewards_mean           2733.590507352104
total_rewards_std            1528.1540762340544
total_rewards_max            5027.3263065598185
total_rewards_min            990.5258773458039
Number of train steps total  288000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               124.25401547783986
(Previous) Eval Time (s)     22.46403022389859
Sample Time (s)              18.955690805334598
Epoch Time (s)               165.67373650707304
Total Train Time (s)         10117.708569373935
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:12:46.932963 UTC | [2020_01_14_06_24_08] Iteration #71 | Epoch Duration: 160.0796127319336
2020-01-14 09:12:46.933170 UTC | [2020_01_14_06_24_08] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027903765
Z variance train             0.07868755
KL Divergence                4.083308
KL Loss                      0.40833083
QF Loss                      1161.0637
VF Loss                      343.792
Policy Loss                  -852.0337
Q Predictions Mean           847.02386
Q Predictions Std            824.148
Q Predictions Max            2056.8752
Q Predictions Min            15.041673
V Predictions Mean           851.48456
V Predictions Std            819.8493
V Predictions Max            2029.064
V Predictions Min            27.051443
Log Pis Mean                 -5.0584154
Log Pis Std                  7.4709373
Log Pis Max                  24.873426
Log Pis Min                  -13.393637
Policy mu Mean               0.061833087
Policy mu Std                0.7262876
Policy mu Max                3.665001
Policy mu Min                -2.814638
Policy log std Mean          -0.28116715
Policy log std Std           0.16050898
Policy log std Max           -0.0011638254
Policy log std Min           -0.88597906
Z mean eval                  0.028280716
Z variance eval              0.07804793
total_rewards                [1920.51314789 2352.23341126 4355.84114601 5045.99454683  433.68651186
 1084.46873914  851.88652985 1049.0059868  1207.03628903 1605.92090052]
total_rewards_mean           1990.6587209187098
total_rewards_std            1457.935649987356
total_rewards_max            5045.994546830666
total_rewards_min            433.68651186366776
Number of train steps total  292000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               120.89612245373428
(Previous) Eval Time (s)     16.86960639199242
Sample Time (s)              19.822749339975417
Epoch Time (s)               157.58847818570212
Total Train Time (s)         10270.671792434063
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:15:19.897150 UTC | [2020_01_14_06_24_08] Iteration #72 | Epoch Duration: 152.96383023262024
2020-01-14 09:15:19.897334 UTC | [2020_01_14_06_24_08] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028266381
Z variance train             0.078043126
KL Divergence                4.1045537
KL Loss                      0.41045538
QF Loss                      1248.9651
VF Loss                      439.52826
Policy Loss                  -917.1955
Q Predictions Mean           908.2971
Q Predictions Std            833.39526
Q Predictions Max            2083.2388
Q Predictions Min            18.0071
V Predictions Mean           912.3646
V Predictions Std            827.62195
V Predictions Max            2088.2017
V Predictions Min            26.179466
Log Pis Mean                 -5.0968494
Log Pis Std                  6.4804544
Log Pis Max                  14.23
Log Pis Min                  -13.45373
Policy mu Mean               0.07682566
Policy mu Std                0.7174443
Policy mu Max                2.7568817
Policy mu Min                -3.131476
Policy log std Mean          -0.28475642
Policy log std Std           0.16388243
Policy log std Max           -0.03595689
Policy log std Min           -0.9776887
Z mean eval                  0.028858935
Z variance eval              0.076182224
total_rewards                [2459.64738645 3629.51504204 2626.80429788 4910.7654686  1677.38609435
 2146.83015733 4985.6787347  4953.86460506 4298.03816487  877.69477837]
total_rewards_mean           3256.6224729659675
total_rewards_std            1422.9130224395071
total_rewards_max            4985.678734703863
total_rewards_min            877.6947783736604
Number of train steps total  296000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               119.85496942093596
(Previous) Eval Time (s)     12.244668245315552
Sample Time (s)              19.274802365340292
Epoch Time (s)               151.3744400315918
Total Train Time (s)         10429.46531886654
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:17:58.693096 UTC | [2020_01_14_06_24_08] Iteration #73 | Epoch Duration: 158.79562258720398
2020-01-14 09:17:58.693297 UTC | [2020_01_14_06_24_08] Iteration #73 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02883792
Z variance train             0.076181866
KL Divergence                4.1518025
KL Loss                      0.41518027
QF Loss                      973.23456
VF Loss                      376.30295
Policy Loss                  -928.153
Q Predictions Mean           923.97754
Q Predictions Std            824.4843
Q Predictions Max            2101.8086
Q Predictions Min            15.014436
V Predictions Mean           931.4408
V Predictions Std            821.4673
V Predictions Max            2089.2341
V Predictions Min            26.474222
Log Pis Mean                 -5.2439804
Log Pis Std                  6.8100185
Log Pis Max                  27.867496
Log Pis Min                  -13.750647
Policy mu Mean               0.09114777
Policy mu Std                0.7435071
Policy mu Max                3.0775344
Policy mu Min                -2.6482527
Policy log std Mean          -0.28387278
Policy log std Std           0.15312675
Policy log std Max           0.04716827
Policy log std Min           -1.1806117
Z mean eval                  0.029173533
Z variance eval              0.07149483
total_rewards                [5104.59931075 2575.46865355 5040.93434457 1707.61815723 4569.92344
 5131.41171509 5044.27408745 4990.30866848 4459.53777707 2327.62291438]
total_rewards_mean           4095.1699068582325
total_rewards_std            1272.0676010148768
total_rewards_max            5131.411715088404
total_rewards_min            1707.6181572342816
Number of train steps total  300000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               121.3226494579576
(Previous) Eval Time (s)     19.665553339291364
Sample Time (s)              20.088124714326113
Epoch Time (s)               161.07632751157507
Total Train Time (s)         10594.767034916673
Epoch                        74
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:20:43.995480 UTC | [2020_01_14_06_24_08] Iteration #74 | Epoch Duration: 165.30204319953918
2020-01-14 09:20:43.995639 UTC | [2020_01_14_06_24_08] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029171798
Z variance train             0.071499534
KL Divergence                4.2934318
KL Loss                      0.4293432
QF Loss                      691.33264
VF Loss                      271.70477
Policy Loss                  -904.35443
Q Predictions Mean           896.17957
Q Predictions Std            871.79156
Q Predictions Max            2109.3628
Q Predictions Min            18.032528
V Predictions Mean           907.27783
V Predictions Std            870.6508
V Predictions Max            2097.656
V Predictions Min            22.374475
Log Pis Mean                 -5.570244
Log Pis Std                  6.674946
Log Pis Max                  26.115604
Log Pis Min                  -13.29702
Policy mu Mean               0.103436716
Policy mu Std                0.68009233
Policy mu Max                2.8804016
Policy mu Min                -2.8453774
Policy log std Mean          -0.27056384
Policy log std Std           0.152971
Policy log std Max           -0.026918225
Policy log std Min           -0.92598486
Z mean eval                  0.028104614
Z variance eval              0.06958743
total_rewards                [3831.50609308 5040.00887941 5077.3618489  5051.0335176  5071.42870342
 4495.51517163 5029.23855709 1958.40510773 5042.60347634 2721.690128  ]
total_rewards_mean           4331.879148321111
total_rewards_std            1077.7748180710878
total_rewards_max            5077.3618488984475
total_rewards_min            1958.4051077341917
Number of train steps total  304000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               118.4341990808025
(Previous) Eval Time (s)     23.89097409369424
Sample Time (s)              19.159398704301566
Epoch Time (s)               161.4845718787983
Total Train Time (s)         10758.446181573905
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:23:27.676002 UTC | [2020_01_14_06_24_08] Iteration #75 | Epoch Duration: 163.68024468421936
2020-01-14 09:23:27.676203 UTC | [2020_01_14_06_24_08] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028157294
Z variance train             0.069598794
KL Divergence                4.359059
KL Loss                      0.4359059
QF Loss                      901.2456
VF Loss                      405.8484
Policy Loss                  -971.01514
Q Predictions Mean           968.6852
Q Predictions Std            871.6689
Q Predictions Max            2139.1633
Q Predictions Min            -4.21033
V Predictions Mean           974.795
V Predictions Std            867.935
V Predictions Max            2123.3723
V Predictions Min            21.878485
Log Pis Mean                 -5.088787
Log Pis Std                  7.1713142
Log Pis Max                  35.548107
Log Pis Min                  -13.817936
Policy mu Mean               0.08561673
Policy mu Std                0.7193258
Policy mu Max                2.9826305
Policy mu Min                -3.1477675
Policy log std Mean          -0.2901786
Policy log std Std           0.16302659
Policy log std Max           -0.011575997
Policy log std Min           -0.9719431
Z mean eval                  0.028994273
Z variance eval              0.06741248
total_rewards                [1626.74046528 1170.29932439 1409.1239813  1853.44531956 1944.07467562
  607.84235438 5128.07775391 5076.6375145  1750.21033783 2013.6151454 ]
total_rewards_mean           2258.006687216838
total_rewards_std            1476.0434871146892
total_rewards_max            5128.077753907792
total_rewards_min            607.8423543812812
Number of train steps total  308000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               116.51779901282862
(Previous) Eval Time (s)     26.086377941071987
Sample Time (s)              20.02484898455441
Epoch Time (s)               162.62902593845502
Total Train Time (s)         10908.069731422234
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:25:57.300623 UTC | [2020_01_14_06_24_08] Iteration #76 | Epoch Duration: 149.62427639961243
2020-01-14 09:25:57.300789 UTC | [2020_01_14_06_24_08] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028896263
Z variance train             0.06741064
KL Divergence                4.424533
KL Loss                      0.4424533
QF Loss                      1087.4366
VF Loss                      468.8084
Policy Loss                  -1054.9453
Q Predictions Mean           1049.1177
Q Predictions Std            871.9096
Q Predictions Max            2135.417
Q Predictions Min            17.556822
V Predictions Mean           1062.0017
V Predictions Std            869.1396
V Predictions Max            2139.474
V Predictions Min            26.678295
Log Pis Mean                 -4.500668
Log Pis Std                  7.350937
Log Pis Max                  26.554178
Log Pis Min                  -19.966011
Policy mu Mean               0.11914458
Policy mu Std                0.7548859
Policy mu Max                3.0323784
Policy mu Min                -2.8205147
Policy log std Mean          -0.29807347
Policy log std Std           0.15927085
Policy log std Max           -0.041241422
Policy log std Min           -0.946789
Z mean eval                  0.024958353
Z variance eval              0.064630635
total_rewards                [3311.5631449  5035.12490837 2141.86862615 4415.51547764 5071.03307932
 1362.75345138 1034.32981166 2661.64802976 1809.37259674 4428.17031256]
total_rewards_mean           3127.1379438479025
total_rewards_std            1456.7977765386497
total_rewards_max            5071.033079321322
total_rewards_min            1034.3298116569865
Number of train steps total  312000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               123.78279289789498
(Previous) Eval Time (s)     13.081307729240507
Sample Time (s)              20.90487899351865
Epoch Time (s)               157.76897962065414
Total Train Time (s)         11071.3774886881
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:28:40.612459 UTC | [2020_01_14_06_24_08] Iteration #77 | Epoch Duration: 163.31152033805847
2020-01-14 09:28:40.612742 UTC | [2020_01_14_06_24_08] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024937248
Z variance train             0.06463125
KL Divergence                4.5194216
KL Loss                      0.45194218
QF Loss                      1005.2719
VF Loss                      437.3426
Policy Loss                  -984.25366
Q Predictions Mean           972.84656
Q Predictions Std            865.24396
Q Predictions Max            2143.1943
Q Predictions Min            11.665239
V Predictions Mean           985.7584
V Predictions Std            866.67957
V Predictions Max            2133.4272
V Predictions Min            16.795164
Log Pis Mean                 -5.124514
Log Pis Std                  7.1350436
Log Pis Max                  30.191517
Log Pis Min                  -12.915054
Policy mu Mean               0.088624924
Policy mu Std                0.72764456
Policy mu Max                2.9878464
Policy mu Min                -3.3041177
Policy log std Mean          -0.29578513
Policy log std Std           0.1668323
Policy log std Max           -0.05381339
Policy log std Min           -1.013334
Z mean eval                  0.02300192
Z variance eval              0.061092697
total_rewards                [4998.58448611 5011.5889933  4644.19160321 2071.79689223 5000.87907848
 4965.93159053 5045.48849067 5056.44713112 1245.95495237 2636.32122637]
total_rewards_mean           4067.7184444398335
total_rewards_std            1403.4197109506013
total_rewards_max            5056.447131123337
total_rewards_min            1245.9549523727037
Number of train steps total  316000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               121.56398483086377
(Previous) Eval Time (s)     18.62353903101757
Sample Time (s)              19.59673062665388
Epoch Time (s)               159.78425448853523
Total Train Time (s)         11236.83188281348
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:31:26.068310 UTC | [2020_01_14_06_24_08] Iteration #78 | Epoch Duration: 165.45536828041077
2020-01-14 09:31:26.068527 UTC | [2020_01_14_06_24_08] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023098093
Z variance train             0.061094444
KL Divergence                4.6533313
KL Loss                      0.46533313
QF Loss                      1300.5796
VF Loss                      477.5905
Policy Loss                  -1094.4865
Q Predictions Mean           1081.9971
Q Predictions Std            904.22595
Q Predictions Max            2182.1997
Q Predictions Min            18.572102
V Predictions Mean           1092.6375
V Predictions Std            899.8982
V Predictions Max            2162.2405
V Predictions Min            30.685322
Log Pis Mean                 -4.214679
Log Pis Std                  7.7549925
Log Pis Max                  38.31842
Log Pis Min                  -13.116874
Policy mu Mean               0.056831002
Policy mu Std                0.78232527
Policy mu Max                3.1863332
Policy mu Min                -3.1571875
Policy log std Mean          -0.30760166
Policy log std Std           0.17299002
Policy log std Max           -0.051424183
Policy log std Min           -0.97384524
Z mean eval                  0.02018668
Z variance eval              0.058688574
total_rewards                [5027.77413719 3975.31100232 2154.36815475  654.67391087 1864.30680017
 1113.26016944  587.88297344  601.66285424 1048.78401567  988.71205043]
total_rewards_mean           1801.6736068533405
total_rewards_std            1455.724033602722
total_rewards_max            5027.774137192817
total_rewards_min            587.8829734445663
Number of train steps total  320000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               121.2688583638519
(Previous) Eval Time (s)     24.294361423235387
Sample Time (s)              20.538293668068945
Epoch Time (s)               166.10151345515624
Total Train Time (s)         11389.30210795626
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:33:58.541626 UTC | [2020_01_14_06_24_08] Iteration #79 | Epoch Duration: 152.4729061126709
2020-01-14 09:33:58.541934 UTC | [2020_01_14_06_24_08] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020233516
Z variance train             0.05868573
KL Divergence                4.7616677
KL Loss                      0.47616678
QF Loss                      1072.0603
VF Loss                      679.3555
Policy Loss                  -924.4633
Q Predictions Mean           916.2958
Q Predictions Std            907.12024
Q Predictions Max            2185.082
Q Predictions Min            13.433182
V Predictions Mean           923.6595
V Predictions Std            902.0623
V Predictions Max            2183.0012
V Predictions Min            27.966808
Log Pis Mean                 -5.4458904
Log Pis Std                  7.136042
Log Pis Max                  20.014517
Log Pis Min                  -13.376024
Policy mu Mean               0.065263346
Policy mu Std                0.70560896
Policy mu Max                2.6571295
Policy mu Min                -3.0149364
Policy log std Mean          -0.2738905
Policy log std Std           0.1589467
Policy log std Max           -0.031094983
Policy log std Min           -1.0633928
Z mean eval                  0.019533029
Z variance eval              0.057127547
total_rewards                [1033.05731479 4621.55016708 4931.06694027 5001.01342931 3691.35810495
  757.77736148  585.71255686 4203.92736597 1052.15699829 4983.39984277]
total_rewards_mean           3086.1020081772926
total_rewards_std            1861.9601991310174
total_rewards_max            5001.013429313911
total_rewards_min            585.7125568559483
Number of train steps total  324000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               119.16376575501636
(Previous) Eval Time (s)     10.665436965413392
Sample Time (s)              20.455490035470575
Epoch Time (s)               150.28469275590032
Total Train Time (s)         11547.811327967793
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:36:37.050982 UTC | [2020_01_14_06_24_08] Iteration #80 | Epoch Duration: 158.50884413719177
2020-01-14 09:36:37.051194 UTC | [2020_01_14_06_24_08] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019506302
Z variance train             0.057146646
KL Divergence                4.812113
KL Loss                      0.48121127
QF Loss                      1797.1526
VF Loss                      380.992
Policy Loss                  -1060.0126
Q Predictions Mean           1058.7211
Q Predictions Std            904.8159
Q Predictions Max            2203.174
Q Predictions Min            14.691782
V Predictions Mean           1061.4038
V Predictions Std            898.7589
V Predictions Max            2211.2554
V Predictions Min            28.36557
Log Pis Mean                 -4.2578773
Log Pis Std                  7.1091185
Log Pis Max                  19.961546
Log Pis Min                  -12.720372
Policy mu Mean               0.06962214
Policy mu Std                0.7583688
Policy mu Max                3.107812
Policy mu Min                -2.6278079
Policy log std Mean          -0.3048275
Policy log std Std           0.17051198
Policy log std Max           -0.012358636
Policy log std Min           -0.954991
Z mean eval                  0.019494385
Z variance eval              0.054615837
total_rewards                [1928.36936925 5054.45559801 4520.78062323 2542.54130728 3199.04119342
 5083.70045774 5120.50025249 2762.7255214  5067.61814701 4818.19369805]
total_rewards_mean           4009.792616788305
total_rewards_std            1192.0373107431137
total_rewards_max            5120.50025248679
total_rewards_min            1928.3693692453253
Number of train steps total  328000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               119.40392438089475
(Previous) Eval Time (s)     18.88932372396812
Sample Time (s)              19.36255948897451
Epoch Time (s)               157.65580759383738
Total Train Time (s)         11710.653382788878
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:39:19.894403 UTC | [2020_01_14_06_24_08] Iteration #81 | Epoch Duration: 162.8430781364441
2020-01-14 09:39:19.894623 UTC | [2020_01_14_06_24_08] Iteration #81 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019392874
Z variance train             0.054611884
KL Divergence                4.926425
KL Loss                      0.4926425
QF Loss                      1115.8107
VF Loss                      403.8422
Policy Loss                  -1105.4316
Q Predictions Mean           1102.1957
Q Predictions Std            917.4098
Q Predictions Max            2232.1985
Q Predictions Min            4.4080286
V Predictions Mean           1105.563
V Predictions Std            912.34247
V Predictions Max            2240.6685
V Predictions Min            19.280117
Log Pis Mean                 -4.151056
Log Pis Std                  7.095293
Log Pis Max                  27.966244
Log Pis Min                  -12.956438
Policy mu Mean               0.09235693
Policy mu Std                0.7592123
Policy mu Max                3.16456
Policy mu Min                -2.9942675
Policy log std Mean          -0.29590535
Policy log std Std           0.15952742
Policy log std Max           -0.016457923
Policy log std Min           -1.1003345
Z mean eval                  0.018020663
Z variance eval              0.05472073
total_rewards                [2991.84845147 4980.64055809 1802.40702107 5044.38010614 1296.5565104
 1446.47829992 5042.29748851 4342.032659   1000.02861549 5087.61332817]
total_rewards_mean           3303.4283038274334
total_rewards_std            1681.1076736835141
total_rewards_max            5087.61332817361
total_rewards_min            1000.0286154860502
Number of train steps total  332000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               121.16478252410889
(Previous) Eval Time (s)     24.0763241937384
Sample Time (s)              19.905145714525133
Epoch Time (s)               165.14625243237242
Total Train Time (s)         11871.182790350635
Epoch                        82
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:42:00.427160 UTC | [2020_01_14_06_24_08] Iteration #82 | Epoch Duration: 160.53239107131958
2020-01-14 09:42:00.427441 UTC | [2020_01_14_06_24_08] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018120643
Z variance train             0.054722346
KL Divergence                4.9372787
KL Loss                      0.4937279
QF Loss                      1025.5422
VF Loss                      1070.7385
Policy Loss                  -1067.1643
Q Predictions Mean           1054.3677
Q Predictions Std            933.7817
Q Predictions Max            2224.9915
Q Predictions Min            17.816883
V Predictions Mean           1047.0988
V Predictions Std            921.76624
V Predictions Max            2211.9287
V Predictions Min            24.253675
Log Pis Mean                 -5.371905
Log Pis Std                  6.2956753
Log Pis Max                  17.414238
Log Pis Min                  -13.207043
Policy mu Mean               0.061592102
Policy mu Std                0.70742476
Policy mu Max                2.6699827
Policy mu Min                -3.4951887
Policy log std Mean          -0.28565115
Policy log std Std           0.15180425
Policy log std Max           0.017148614
Policy log std Min           -1.0828087
Z mean eval                  0.018526603
Z variance eval              0.053754915
total_rewards                [2841.28103909 5051.92952571 5026.0486724  4383.69912525 2062.30076875
 4960.1078385  2177.02195872 5017.21620853 5065.01633067 1372.59671903]
total_rewards_mean           3795.72181866374
total_rewards_std            1424.9161874381184
total_rewards_max            5065.01633066575
total_rewards_min            1372.5967190306865
Number of train steps total  336000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               118.83408420393243
(Previous) Eval Time (s)     19.46214545192197
Sample Time (s)              19.870902808383107
Epoch Time (s)               158.1671324642375
Total Train Time (s)         12032.723578847013
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:44:41.971212 UTC | [2020_01_14_06_24_08] Iteration #83 | Epoch Duration: 161.54354119300842
2020-01-14 09:44:41.971514 UTC | [2020_01_14_06_24_08] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01850226
Z variance train             0.05374799
KL Divergence                4.983247
KL Loss                      0.4983247
QF Loss                      1138.3405
VF Loss                      498.73938
Policy Loss                  -1006.62616
Q Predictions Mean           1002.8045
Q Predictions Std            945.7034
Q Predictions Max            2237.609
Q Predictions Min            17.608534
V Predictions Mean           1010.0575
V Predictions Std            943.80597
V Predictions Max            2241.2883
V Predictions Min            30.630436
Log Pis Mean                 -4.884286
Log Pis Std                  7.8100243
Log Pis Max                  24.722334
Log Pis Min                  -13.01701
Policy mu Mean               0.06489678
Policy mu Std                0.7479548
Policy mu Max                3.335867
Policy mu Min                -2.9505336
Policy log std Mean          -0.28197515
Policy log std Std           0.16330883
Policy log std Max           -0.0038147867
Policy log std Min           -1.0972649
Z mean eval                  0.017093815
Z variance eval              0.051286448
total_rewards                [1905.25987257 5115.87700076 3358.56539825 2889.16103324 1125.55601751
  876.33241361  614.50087147 2114.16358694 3442.72635334 3776.17443815]
total_rewards_mean           2521.831698584453
total_rewards_std            1372.1175784826244
total_rewards_max            5115.877000763398
total_rewards_min            614.5008714673047
Number of train steps total  340000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               124.8277387698181
(Previous) Eval Time (s)     22.838228312321007
Sample Time (s)              19.846233599819243
Epoch Time (s)               167.51220068195835
Total Train Time (s)         12191.53092572093
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:47:20.778384 UTC | [2020_01_14_06_24_08] Iteration #84 | Epoch Duration: 158.80668473243713
2020-01-14 09:47:20.778535 UTC | [2020_01_14_06_24_08] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017144447
Z variance train             0.051287025
KL Divergence                5.092173
KL Loss                      0.5092173
QF Loss                      1223.3215
VF Loss                      559.50653
Policy Loss                  -1097.722
Q Predictions Mean           1091.596
Q Predictions Std            927.9832
Q Predictions Max            2261.8015
Q Predictions Min            16.137987
V Predictions Mean           1087.6248
V Predictions Std            918.13666
V Predictions Max            2246.9966
V Predictions Min            25.13913
Log Pis Mean                 -3.8748398
Log Pis Std                  7.767853
Log Pis Max                  20.120737
Log Pis Min                  -12.814459
Policy mu Mean               0.06939735
Policy mu Std                0.7864608
Policy mu Max                3.115718
Policy mu Min                -2.6303422
Policy log std Mean          -0.3027097
Policy log std Std           0.16326821
Policy log std Max           0.2253969
Policy log std Min           -0.92244595
Z mean eval                  0.018217664
Z variance eval              0.05119594
total_rewards                [5059.45857445 5141.51304061 5120.32838385 5011.10065155 3084.38523047
 4584.32957413 5073.9987232  5057.5107314  2449.33577003 5113.82037246]
total_rewards_mean           4569.5781052141765
total_rewards_std            924.9606243916252
total_rewards_max            5141.513040608675
total_rewards_min            2449.335770027434
Number of train steps total  344000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               121.22490448970348
(Previous) Eval Time (s)     14.132440219633281
Sample Time (s)              20.69617021875456
Epoch Time (s)               156.05351492809132
Total Train Time (s)         12360.132973949425
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:50:09.382869 UTC | [2020_01_14_06_24_08] Iteration #85 | Epoch Duration: 168.60420942306519
2020-01-14 09:50:09.383075 UTC | [2020_01_14_06_24_08] Iteration #85 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018207137
Z variance train             0.05119592
KL Divergence                5.100008
KL Loss                      0.5100008
QF Loss                      1233.2888
VF Loss                      616.13306
Policy Loss                  -1144.2638
Q Predictions Mean           1141.2285
Q Predictions Std            947.3879
Q Predictions Max            2266.2688
Q Predictions Min            15.604236
V Predictions Mean           1146.967
V Predictions Std            948.6926
V Predictions Max            2277.2861
V Predictions Min            22.890516
Log Pis Mean                 -4.9138193
Log Pis Std                  7.1541033
Log Pis Max                  29.555813
Log Pis Min                  -13.804938
Policy mu Mean               0.097927034
Policy mu Std                0.74065316
Policy mu Max                2.6291575
Policy mu Min                -2.7928054
Policy log std Mean          -0.30373886
Policy log std Std           0.16870113
Policy log std Max           0.00055262446
Policy log std Min           -1.1250283
Z mean eval                  0.015442011
Z variance eval              0.04967072
total_rewards                [5120.93385169 5103.28256205 5106.65304038 5103.85827741 2943.9373238
 1066.9953341  5050.70530841 5038.30116666 5092.16182755 5092.29977242]
total_rewards_mean           4471.912846447096
total_rewards_std            1302.906894906763
total_rewards_max            5120.933851687918
total_rewards_min            1066.9953341046735
Number of train steps total  348000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               121.19131801789626
(Previous) Eval Time (s)     26.682798464782536
Sample Time (s)              20.187609338667244
Epoch Time (s)               168.06172582134604
Total Train Time (s)         12527.245545934886
Epoch                        86
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:52:56.499971 UTC | [2020_01_14_06_24_08] Iteration #86 | Epoch Duration: 167.11671686172485
2020-01-14 09:52:56.500266 UTC | [2020_01_14_06_24_08] Iteration #86 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015567216
Z variance train             0.04966519
KL Divergence                5.1696997
KL Loss                      0.51697
QF Loss                      1452.8634
VF Loss                      811.5023
Policy Loss                  -1080.6306
Q Predictions Mean           1071.8484
Q Predictions Std            964.8435
Q Predictions Max            2282.0051
Q Predictions Min            13.503143
V Predictions Mean           1070.2019
V Predictions Std            951.0625
V Predictions Max            2254.423
V Predictions Min            26.022253
Log Pis Mean                 -4.8492336
Log Pis Std                  7.2272315
Log Pis Max                  23.371466
Log Pis Min                  -19.117859
Policy mu Mean               0.08410858
Policy mu Std                0.7305798
Policy mu Max                2.8521566
Policy mu Min                -2.8127012
Policy log std Mean          -0.29606757
Policy log std Std           0.16699764
Policy log std Max           -0.035752498
Policy log std Min           -1.0458394
Z mean eval                  0.01637642
Z variance eval              0.047390725
total_rewards                [2563.48042203 5088.44091583 5133.97809171 5066.07606962 5109.8643486
 5113.26261176 5063.60251591 5121.96206878 5109.37273523 1195.66140269]
total_rewards_mean           4456.570118215195
total_rewards_std            1324.4764414690144
total_rewards_max            5133.978091713079
total_rewards_min            1195.6614026877708
Number of train steps total  352000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               124.19559058593586
(Previous) Eval Time (s)     25.737430786248296
Sample Time (s)              20.36814885120839
Epoch Time (s)               170.30117022339255
Total Train Time (s)         12698.281022891402
Epoch                        87
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:55:47.537262 UTC | [2020_01_14_06_24_08] Iteration #87 | Epoch Duration: 171.03679752349854
2020-01-14 09:55:47.537508 UTC | [2020_01_14_06_24_08] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016411837
Z variance train             0.047384065
KL Divergence                5.2755556
KL Loss                      0.5275556
QF Loss                      958.50134
VF Loss                      344.05258
Policy Loss                  -1147.6294
Q Predictions Mean           1140.4248
Q Predictions Std            968.6196
Q Predictions Max            2299.9995
Q Predictions Min            19.335846
V Predictions Mean           1143.0659
V Predictions Std            963.7188
V Predictions Max            2291.2202
V Predictions Min            27.798517
Log Pis Mean                 -4.7360296
Log Pis Std                  6.8788395
Log Pis Max                  21.552082
Log Pis Min                  -12.515387
Policy mu Mean               0.06564112
Policy mu Std                0.74340117
Policy mu Max                3.3736649
Policy mu Min                -3.9246972
Policy log std Mean          -0.2997842
Policy log std Std           0.16140953
Policy log std Max           -0.022965223
Policy log std Min           -1.0639361
Z mean eval                  0.013797356
Z variance eval              0.046091508
total_rewards                [3216.39168498 1567.3643202  4762.02598209 5176.40292271 1963.01481588
 1925.18185878 5181.32145741 4759.74900521 4673.64363481 1523.3650925 ]
total_rewards_mean           3474.8460774570062
total_rewards_std            1508.4075530252505
total_rewards_max            5181.321457408782
total_rewards_min            1523.365092495325
Number of train steps total  356000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               119.75197427393869
(Previous) Eval Time (s)     26.472737343981862
Sample Time (s)              19.92604828067124
Epoch Time (s)               166.1507598985918
Total Train Time (s)         12857.422499080654
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:58:26.681378 UTC | [2020_01_14_06_24_08] Iteration #88 | Epoch Duration: 159.14367771148682
2020-01-14 09:58:26.681672 UTC | [2020_01_14_06_24_08] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013836628
Z variance train             0.046093233
KL Divergence                5.336403
KL Loss                      0.5336403
QF Loss                      1118.8977
VF Loss                      306.38528
Policy Loss                  -1203.9639
Q Predictions Mean           1198.0386
Q Predictions Std            962.9108
Q Predictions Max            2307.8398
Q Predictions Min            16.992579
V Predictions Mean           1207.0715
V Predictions Std            958.5043
V Predictions Max            2297.577
V Predictions Min            23.23931
Log Pis Mean                 -4.3976526
Log Pis Std                  7.136843
Log Pis Max                  22.174702
Log Pis Min                  -13.646442
Policy mu Mean               0.11283172
Policy mu Std                0.7549123
Policy mu Max                3.3174865
Policy mu Min                -3.4338865
Policy log std Mean          -0.30188775
Policy log std Std           0.16485794
Policy log std Max           -0.020962209
Policy log std Min           -1.0334232
Z mean eval                  0.012431299
Z variance eval              0.04601669
total_rewards                [2448.76801774 5107.03494437  420.94339063 5168.58319795 5003.90550764
 5135.19831144 4049.03919608 5158.33782823 5160.51996059 5192.31501734]
total_rewards_mean           4284.46453720124
total_rewards_std            1529.9331268501044
total_rewards_max            5192.315017337169
total_rewards_min            420.94339063019186
Number of train steps total  360000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               116.60032204492018
(Previous) Eval Time (s)     19.465298225171864
Sample Time (s)              18.71501369215548
Epoch Time (s)               154.78063396224752
Total Train Time (s)         13017.617620454635
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:01:06.878237 UTC | [2020_01_14_06_24_08] Iteration #89 | Epoch Duration: 160.19635725021362
2020-01-14 10:01:06.878444 UTC | [2020_01_14_06_24_08] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012381849
Z variance train             0.046011426
KL Divergence                5.3349915
KL Loss                      0.5334992
QF Loss                      1387.6399
VF Loss                      556.9262
Policy Loss                  -1249.7374
Q Predictions Mean           1235.6791
Q Predictions Std            980.11426
Q Predictions Max            2312.714
Q Predictions Min            12.509452
V Predictions Mean           1243.8417
V Predictions Std            977.841
V Predictions Max            2324.248
V Predictions Min            26.731096
Log Pis Mean                 -4.976058
Log Pis Std                  6.71812
Log Pis Max                  17.474121
Log Pis Min                  -13.465148
Policy mu Mean               0.09795976
Policy mu Std                0.73549014
Policy mu Max                2.8004317
Policy mu Min                -2.774144
Policy log std Mean          -0.29992455
Policy log std Std           0.16205582
Policy log std Max           -0.06482076
Policy log std Min           -0.9532246
Z mean eval                  0.012559107
Z variance eval              0.04442469
total_rewards                [2224.24699536 5131.15808963 1978.56430094 2291.04733572 2992.76852265
 5097.62844132 5049.37013227 5088.10925107 5057.64199879 5094.75932994]
total_rewards_mean           4000.52943976846
total_rewards_std            1351.3365049965437
total_rewards_max            5131.158089625826
total_rewards_min            1978.5643009409573
Number of train steps total  364000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               117.3563778642565
(Previous) Eval Time (s)     24.88073920784518
Sample Time (s)              19.7249824879691
Epoch Time (s)               161.96209956007078
Total Train Time (s)         13178.095564140473
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:03:47.356103 UTC | [2020_01_14_06_24_08] Iteration #90 | Epoch Duration: 160.47752261161804
2020-01-14 10:03:47.356285 UTC | [2020_01_14_06_24_08] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012569761
Z variance train             0.044423513
KL Divergence                5.4337482
KL Loss                      0.54337484
QF Loss                      969.2366
VF Loss                      562.0346
Policy Loss                  -1131.2839
Q Predictions Mean           1120.6367
Q Predictions Std            967.96063
Q Predictions Max            2321.5693
Q Predictions Min            14.911592
V Predictions Mean           1142.3356
V Predictions Std            973.45703
V Predictions Max            2344.393
V Predictions Min            30.066149
Log Pis Mean                 -4.5527096
Log Pis Std                  7.8147087
Log Pis Max                  24.055126
Log Pis Min                  -15.23875
Policy mu Mean               0.09531177
Policy mu Std                0.76600695
Policy mu Max                2.920053
Policy mu Min                -3.1266189
Policy log std Mean          -0.30286598
Policy log std Std           0.17144163
Policy log std Max           -0.014650047
Policy log std Min           -0.9602051
Z mean eval                  0.013325036
Z variance eval              0.04404186
total_rewards                [2664.16490696 2973.15588058  710.31214334 1507.41591714 1497.05226613
 1791.56993347 1206.31322421 1250.97925479 1452.95104627 1614.30579583]
total_rewards_mean           1666.8220368714203
total_rewards_std            641.8254088196136
total_rewards_max            2973.155880576644
total_rewards_min            710.3121433384279
Number of train steps total  368000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               121.88027009600773
(Previous) Eval Time (s)     23.395858000032604
Sample Time (s)              19.869160640984774
Epoch Time (s)               165.1452887370251
Total Train Time (s)         13328.869358159602
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:06:18.131451 UTC | [2020_01_14_06_24_08] Iteration #91 | Epoch Duration: 150.77504229545593
2020-01-14 10:06:18.131594 UTC | [2020_01_14_06_24_08] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013596016
Z variance train             0.044047363
KL Divergence                5.456393
KL Loss                      0.5456393
QF Loss                      1403.0383
VF Loss                      585.2495
Policy Loss                  -1208.8341
Q Predictions Mean           1200.7542
Q Predictions Std            982.0475
Q Predictions Max            2342.6265
Q Predictions Min            9.224083
V Predictions Mean           1202.0569
V Predictions Std            971.5905
V Predictions Max            2327.7324
V Predictions Min            19.82205
Log Pis Mean                 -4.9944096
Log Pis Std                  6.711735
Log Pis Max                  20.480696
Log Pis Min                  -13.764128
Policy mu Mean               0.08486398
Policy mu Std                0.7288838
Policy mu Max                2.6285498
Policy mu Min                -2.8110962
Policy log std Mean          -0.29227793
Policy log std Std           0.16143246
Policy log std Max           -0.061594673
Policy log std Min           -1.159091
Z mean eval                  0.012414651
Z variance eval              0.045456894
total_rewards                [5078.4416526  5081.69395411  889.82837413 5028.20622072 5060.67571425
 5071.49977686 5063.4534414  5095.34733188 5051.0965647  5106.74217718]
total_rewards_mean           4652.698520782937
total_rewards_std            1254.4666663538176
total_rewards_max            5106.74217717609
total_rewards_min            889.828374133424
Number of train steps total  372000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               122.98220251593739
(Previous) Eval Time (s)     9.025318500120193
Sample Time (s)              18.190253249835223
Epoch Time (s)               150.1977742658928
Total Train Time (s)         13497.761174858548
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:09:07.024719 UTC | [2020_01_14_06_24_08] Iteration #92 | Epoch Duration: 168.8930151462555
2020-01-14 10:09:07.024878 UTC | [2020_01_14_06_24_08] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012447315
Z variance train             0.045456022
KL Divergence                5.398301
KL Loss                      0.53983015
QF Loss                      939.68976
VF Loss                      488.58618
Policy Loss                  -1213.1838
Q Predictions Mean           1208.1428
Q Predictions Std            989.0649
Q Predictions Max            2340.9392
Q Predictions Min            15.121407
V Predictions Mean           1206.0533
V Predictions Std            979.5453
V Predictions Max            2323.5955
V Predictions Min            28.44208
Log Pis Mean                 -4.4291034
Log Pis Std                  7.2328634
Log Pis Max                  22.619234
Log Pis Min                  -13.454735
Policy mu Mean               0.028233975
Policy mu Std                0.7617222
Policy mu Max                3.3716404
Policy mu Min                -2.9438453
Policy log std Mean          -0.29508692
Policy log std Std           0.15961358
Policy log std Max           0.015209436
Policy log std Min           -0.963225
Z mean eval                  0.013678643
Z variance eval              0.043998584
total_rewards                [5163.83125127 5042.96802594 5152.02967312 3215.74232495 5143.31109009
 5147.11111061 5139.98096969 4386.42572983 4345.04972822 2897.16582747]
total_rewards_mean           4563.361573117144
total_rewards_std            813.5086640166726
total_rewards_max            5163.831251266742
total_rewards_min            2897.1658274668243
Number of train steps total  376000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               117.85804745787755
(Previous) Eval Time (s)     27.72029097005725
Sample Time (s)              19.862608848139644
Epoch Time (s)               165.44094727607444
Total Train Time (s)         13661.712753770407
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:11:50.979233 UTC | [2020_01_14_06_24_08] Iteration #93 | Epoch Duration: 163.95421433448792
2020-01-14 10:11:50.979472 UTC | [2020_01_14_06_24_08] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013679522
Z variance train             0.04400628
KL Divergence                5.4811563
KL Loss                      0.5481157
QF Loss                      1230.862
VF Loss                      334.2106
Policy Loss                  -1251.5933
Q Predictions Mean           1244.1841
Q Predictions Std            975.1894
Q Predictions Max            2354.0344
Q Predictions Min            18.61826
V Predictions Mean           1250.5441
V Predictions Std            974.2054
V Predictions Max            2359.3613
V Predictions Min            29.831516
Log Pis Mean                 -4.7696996
Log Pis Std                  6.3207016
Log Pis Max                  16.808594
Log Pis Min                  -14.469856
Policy mu Mean               0.10441416
Policy mu Std                0.750136
Policy mu Max                3.131997
Policy mu Min                -2.312142
Policy log std Mean          -0.3013912
Policy log std Std           0.1596275
Policy log std Max           0.009017602
Policy log std Min           -0.9666319
Z mean eval                  0.015064886
Z variance eval              0.044273145
total_rewards                [5048.70270054 5143.85683124 5030.02300319 1085.43669984 2234.31742298
 3014.15594265 5092.49730353 5103.72591187 5107.44216747 5125.00807371]
total_rewards_mean           4198.516605700659
total_rewards_std            1433.9832645462245
total_rewards_max            5143.856831237958
total_rewards_min            1085.4366998403477
Number of train steps total  380000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               122.14197737397626
(Previous) Eval Time (s)     26.233265451155603
Sample Time (s)              18.97137404885143
Epoch Time (s)               167.3466168739833
Total Train Time (s)         13827.346944973338
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:14:36.613847 UTC | [2020_01_14_06_24_08] Iteration #94 | Epoch Duration: 165.63421201705933
2020-01-14 10:14:36.614005 UTC | [2020_01_14_06_24_08] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014956784
Z variance train             0.044273175
KL Divergence                5.4606853
KL Loss                      0.54606855
QF Loss                      1315.2397
VF Loss                      290.66916
Policy Loss                  -1252.8125
Q Predictions Mean           1246.689
Q Predictions Std            977.7413
Q Predictions Max            2341.9075
Q Predictions Min            17.40765
V Predictions Mean           1253.2103
V Predictions Std            972.4137
V Predictions Max            2340.9485
V Predictions Min            26.438587
Log Pis Mean                 -3.5750477
Log Pis Std                  7.2839303
Log Pis Max                  21.238861
Log Pis Min                  -13.909911
Policy mu Mean               0.06813685
Policy mu Std                0.79788864
Policy mu Max                2.8108068
Policy mu Min                -3.3610146
Policy log std Mean          -0.31733394
Policy log std Std           0.17017911
Policy log std Max           -0.036772206
Policy log std Min           -1.0028232
Z mean eval                  0.015667789
Z variance eval              0.042501584
total_rewards                [5187.61934634 5120.8967716  5158.22612249 1862.22645045 3135.45957609
 1332.19445185 1143.81241791 5120.40312774 1357.21237095 4158.81976939]
total_rewards_mean           3357.68704047952
total_rewards_std            1695.2884956900823
total_rewards_max            5187.619346343217
total_rewards_min            1143.8124179073316
Number of train steps total  384000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               118.02515772962943
(Previous) Eval Time (s)     24.520607125014067
Sample Time (s)              20.21628145268187
Epoch Time (s)               162.76204630732536
Total Train Time (s)         13985.223162245005
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:17:14.494108 UTC | [2020_01_14_06_24_08] Iteration #95 | Epoch Duration: 157.87995028495789
2020-01-14 10:17:14.494412 UTC | [2020_01_14_06_24_08] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015797207
Z variance train             0.042499933
KL Divergence                5.5358458
KL Loss                      0.5535846
QF Loss                      740.40314
VF Loss                      392.7786
Policy Loss                  -1335.7668
Q Predictions Mean           1326.1624
Q Predictions Std            998.924
Q Predictions Max            2368.5088
Q Predictions Min            17.603039
V Predictions Mean           1333.4729
V Predictions Std            998.5284
V Predictions Max            2374.53
V Predictions Min            17.79184
Log Pis Mean                 -4.567281
Log Pis Std                  6.980549
Log Pis Max                  25.684196
Log Pis Min                  -17.286282
Policy mu Mean               0.10511038
Policy mu Std                0.7547129
Policy mu Max                3.2519922
Policy mu Min                -3.3041084
Policy log std Mean          -0.30489743
Policy log std Std           0.15997447
Policy log std Max           0.08109823
Policy log std Min           -1.1426533
Z mean eval                  0.015420611
Z variance eval              0.042263485
total_rewards                [ 667.60640516 5095.96922894 5087.0148821  1336.04641576 5082.06285742
 1353.86306212 5081.76997592 2869.10318838 5094.94578146 1178.81754815]
total_rewards_mean           3284.719934540596
total_rewards_std            1877.4456382514115
total_rewards_max            5095.969228940553
total_rewards_min            667.60640515917
Number of train steps total  388000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               120.30314629431814
(Previous) Eval Time (s)     19.638180691748857
Sample Time (s)              20.068337411619723
Epoch Time (s)               160.00966439768672
Total Train Time (s)         14144.694402180612
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:19:53.968266 UTC | [2020_01_14_06_24_08] Iteration #96 | Epoch Duration: 159.47362327575684
2020-01-14 10:19:53.968557 UTC | [2020_01_14_06_24_08] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015428552
Z variance train             0.042259306
KL Divergence                5.5390625
KL Loss                      0.55390626
QF Loss                      1303.7852
VF Loss                      383.2404
Policy Loss                  -1344.4685
Q Predictions Mean           1338.0076
Q Predictions Std            999.0954
Q Predictions Max            2357.6594
Q Predictions Min            15.052464
V Predictions Mean           1344.7197
V Predictions Std            995.0082
V Predictions Max            2373.9976
V Predictions Min            30.712898
Log Pis Mean                 -4.168749
Log Pis Std                  6.7478595
Log Pis Max                  20.627003
Log Pis Min                  -12.588055
Policy mu Mean               0.06387849
Policy mu Std                0.76228994
Policy mu Max                2.7731452
Policy mu Min                -2.7303843
Policy log std Mean          -0.30906513
Policy log std Std           0.15992267
Policy log std Max           -0.018026762
Policy log std Min           -1.0850282
Z mean eval                  0.014208014
Z variance eval              0.040204726
total_rewards                [2683.76097796 5102.44727213 4972.21175749 3872.61577887 1457.78076247
 3040.20386558 5097.006722   2205.07179643 5029.99574898 2541.8427198 ]
total_rewards_mean           3600.2937401706135
total_rewards_std            1315.6001984952516
total_rewards_max            5102.4472721259035
total_rewards_min            1457.7807624657203
Number of train steps total  392000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               123.50597766274586
(Previous) Eval Time (s)     19.101847358979285
Sample Time (s)              19.059349426999688
Epoch Time (s)               161.66717444872484
Total Train Time (s)         14308.337317600846
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:22:37.611978 UTC | [2020_01_14_06_24_08] Iteration #97 | Epoch Duration: 163.64322090148926
2020-01-14 10:22:37.612175 UTC | [2020_01_14_06_24_08] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014101535
Z variance train             0.040203642
KL Divergence                5.6498604
KL Loss                      0.56498605
QF Loss                      1408.1428
VF Loss                      626.80646
Policy Loss                  -1380.0486
Q Predictions Mean           1379.1963
Q Predictions Std            990.411
Q Predictions Max            2371.0935
Q Predictions Min            17.970598
V Predictions Mean           1390.7853
V Predictions Std            990.35956
V Predictions Max            2384.773
V Predictions Min            27.12325
Log Pis Mean                 -3.7926154
Log Pis Std                  6.8587065
Log Pis Max                  20.85754
Log Pis Min                  -12.644846
Policy mu Mean               0.06923752
Policy mu Std                0.77739096
Policy mu Max                3.0207806
Policy mu Min                -2.6836028
Policy log std Mean          -0.31536093
Policy log std Std           0.16392234
Policy log std Max           -0.009016231
Policy log std Min           -1.1933013
Z mean eval                  0.011954707
Z variance eval              0.03965884
total_rewards                [5141.33218504 5113.28121144 5147.93124049 5070.11824772 5106.17508893
 5127.88785466 5067.14629653 5095.67211967 5092.65985884 5084.93703372]
total_rewards_mean           5104.714113705241
total_rewards_std            26.547251303503348
total_rewards_max            5147.931240492212
total_rewards_min            5067.146296529093
Number of train steps total  396000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               118.84852300584316
(Previous) Eval Time (s)     21.077643021009862
Sample Time (s)              19.33766901632771
Epoch Time (s)               159.26383504318073
Total Train Time (s)         14477.000752742402
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:25:26.279212 UTC | [2020_01_14_06_24_08] Iteration #98 | Epoch Duration: 168.66686487197876
2020-01-14 10:25:26.279492 UTC | [2020_01_14_06_24_08] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012000601
Z variance train             0.039659597
KL Divergence                5.6889076
KL Loss                      0.56889075
QF Loss                      911.0211
VF Loss                      804.9339
Policy Loss                  -1269.886
Q Predictions Mean           1264.9578
Q Predictions Std            1011.35547
Q Predictions Max            2372.5632
Q Predictions Min            15.323306
V Predictions Mean           1272.1226
V Predictions Std            1008.32184
V Predictions Max            2384.7437
V Predictions Min            27.664701
Log Pis Mean                 -4.6630335
Log Pis Std                  6.792982
Log Pis Max                  32.33017
Log Pis Min                  -15.77192
Policy mu Mean               0.08288958
Policy mu Std                0.7491555
Policy mu Max                2.6687915
Policy mu Min                -2.7966514
Policy log std Mean          -0.30434626
Policy log std Std           0.15901011
Policy log std Max           -0.04340799
Policy log std Min           -1.1294813
Z mean eval                  0.013908806
Z variance eval              0.039100047
total_rewards                [5096.4927088  5008.54780997 5028.08385165 5044.42897551 5007.41008827
 5019.7607673  5022.80003332 4992.31586577 3501.14659671 1619.89790974]
total_rewards_mean           4534.08846070286
total_rewards_std            1073.0371321568598
total_rewards_max            5096.492708797458
total_rewards_min            1619.897909742402
Number of train steps total  400000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               120.32023221021518
(Previous) Eval Time (s)     30.48037315811962
Sample Time (s)              19.904476057738066
Epoch Time (s)               170.70508142607287
Total Train Time (s)         14644.667317760643
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:28:13.945964 UTC | [2020_01_14_06_24_08] Iteration #99 | Epoch Duration: 167.6662917137146
2020-01-14 10:28:13.946129 UTC | [2020_01_14_06_24_08] Iteration #99 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013707179
Z variance train             0.039103553
KL Divergence                5.724768
KL Loss                      0.5724768
QF Loss                      1221.0258
VF Loss                      494.20078
Policy Loss                  -1240.1385
Q Predictions Mean           1237.939
Q Predictions Std            1026.6898
Q Predictions Max            2390.344
Q Predictions Min            13.947179
V Predictions Mean           1249.8079
V Predictions Std            1029.6798
V Predictions Max            2414.212
V Predictions Min            23.464563
Log Pis Mean                 -5.2088327
Log Pis Std                  6.651382
Log Pis Max                  18.657942
Log Pis Min                  -16.509474
Policy mu Mean               0.065976165
Policy mu Std                0.7219468
Policy mu Max                3.068271
Policy mu Min                -2.8993084
Policy log std Mean          -0.28725907
Policy log std Std           0.1573073
Policy log std Max           -0.014980733
Policy log std Min           -0.925616
Z mean eval                  0.013624096
Z variance eval              0.03862719
total_rewards                [5099.62418285 5085.10567721 2141.97831274  615.18143717 5131.8757293
 5166.23014955 5134.85775137 5163.6836755  5114.44553932 1980.79389399]
total_rewards_mean           4063.377634900558
total_rewards_std            1669.077024021837
total_rewards_max            5166.2301495464935
total_rewards_min            615.1814371707567
Number of train steps total  404000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               124.00898808427155
(Previous) Eval Time (s)     27.4412938519381
Sample Time (s)              19.26152892736718
Epoch Time (s)               170.71181086357683
Total Train Time (s)         14811.32165365573
Epoch                        100
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:31:00.603302 UTC | [2020_01_14_06_24_08] Iteration #100 | Epoch Duration: 166.65702939033508
2020-01-14 10:31:00.603520 UTC | [2020_01_14_06_24_08] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013632533
Z variance train             0.038626257
KL Divergence                5.7462573
KL Loss                      0.57462573
QF Loss                      1345.1335
VF Loss                      548.98047
Policy Loss                  -1296.1935
Q Predictions Mean           1291.534
Q Predictions Std            1008.1061
Q Predictions Max            2410.1035
Q Predictions Min            18.692112
V Predictions Mean           1295.1836
V Predictions Std            1002.0759
V Predictions Max            2407.2683
V Predictions Min            28.589624
Log Pis Mean                 -4.868497
Log Pis Std                  6.880013
Log Pis Max                  26.91073
Log Pis Min                  -13.5737095
Policy mu Mean               0.061244123
Policy mu Std                0.77294195
Policy mu Max                2.9223933
Policy mu Min                -3.5458646
Policy log std Mean          -0.3009805
Policy log std Std           0.17056093
Policy log std Max           0.09411761
Policy log std Min           -1.0909543
Z mean eval                  0.0127404975
Z variance eval              0.03796544
total_rewards                [5147.78099037 4608.02612281 5137.98710341 4078.29557121  893.85541636
 3495.71494148 1058.63219595 3513.90023986  675.78829945  976.49580418]
total_rewards_mean           2958.6476685099856
total_rewards_std            1764.2684379453567
total_rewards_max            5147.780990374553
total_rewards_min            675.7882994497763
Number of train steps total  408000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               118.7715334710665
(Previous) Eval Time (s)     23.386212645098567
Sample Time (s)              20.210570093709975
Epoch Time (s)               162.36831620987505
Total Train Time (s)         14968.61463699909
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:33:37.896931 UTC | [2020_01_14_06_24_08] Iteration #101 | Epoch Duration: 157.29324388504028
2020-01-14 10:33:37.897104 UTC | [2020_01_14_06_24_08] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012679124
Z variance train             0.03796675
KL Divergence                5.784792
KL Loss                      0.57847923
QF Loss                      1433.0894
VF Loss                      709.98804
Policy Loss                  -1318.9432
Q Predictions Mean           1309.6558
Q Predictions Std            1030.3699
Q Predictions Max            2399.8982
Q Predictions Min            19.935175
V Predictions Mean           1304.889
V Predictions Std            1019.25104
V Predictions Max            2384.1736
V Predictions Min            23.820377
Log Pis Mean                 -4.7755203
Log Pis Std                  6.8393006
Log Pis Max                  18.073818
Log Pis Min                  -15.153286
Policy mu Mean               0.090107754
Policy mu Std                0.72481585
Policy mu Max                2.8201587
Policy mu Min                -2.6671627
Policy log std Mean          -0.28890514
Policy log std Std           0.15696134
Policy log std Max           -0.06126836
Policy log std Min           -1.0557851
Z mean eval                  0.010727738
Z variance eval              0.037508614
total_rewards                [4887.54333082 2714.55199724 1774.95350398 1153.86375765 4088.23125424
 4924.2886414   898.87408857 1055.8571028   784.51603446 1859.64197438]
total_rewards_mean           2414.232168553237
total_rewards_std            1562.4455246147656
total_rewards_max            4924.2886414025015
total_rewards_min            784.5160344576744
Number of train steps total  412000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               122.43130961433053
(Previous) Eval Time (s)     18.310840017162263
Sample Time (s)              19.496724117547274
Epoch Time (s)               160.23887374904007
Total Train Time (s)         15125.68237876892
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:36:14.968607 UTC | [2020_01_14_06_24_08] Iteration #102 | Epoch Duration: 157.0713288784027
2020-01-14 10:36:14.968899 UTC | [2020_01_14_06_24_08] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010762023
Z variance train             0.037506096
KL Divergence                5.809553
KL Loss                      0.5809553
QF Loss                      1211.304
VF Loss                      526.9318
Policy Loss                  -1308.2076
Q Predictions Mean           1298.6404
Q Predictions Std            1012.1967
Q Predictions Max            2392.5698
Q Predictions Min            17.617487
V Predictions Mean           1299.3479
V Predictions Std            1008.25476
V Predictions Max            2393.826
V Predictions Min            22.078033
Log Pis Mean                 -5.393939
Log Pis Std                  6.5347743
Log Pis Max                  21.669662
Log Pis Min                  -15.145491
Policy mu Mean               0.06292271
Policy mu Std                0.7059473
Policy mu Max                2.6395893
Policy mu Min                -3.5293887
Policy log std Mean          -0.28967926
Policy log std Std           0.14799428
Policy log std Max           0.0010728389
Policy log std Min           -0.99753773
Z mean eval                  0.0125566255
Z variance eval              0.037351
total_rewards                [5138.26861665 5145.74303649 5088.57745791 5087.84263048 5075.24274706
 5125.22994094 5117.57853612 5152.71128033 5076.19140245 5101.97609264]
total_rewards_mean           5110.936174108767
total_rewards_std            27.471620314409474
total_rewards_max            5152.711280334333
total_rewards_min            5075.242747062578
Number of train steps total  416000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               120.04666482983157
(Previous) Eval Time (s)     15.142996940761805
Sample Time (s)              19.128654504194856
Epoch Time (s)               154.31831627478823
Total Train Time (s)         15294.461663190275
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:39:03.750027 UTC | [2020_01_14_06_24_08] Iteration #103 | Epoch Duration: 168.78091311454773
2020-01-14 10:39:03.750261 UTC | [2020_01_14_06_24_08] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012500835
Z variance train             0.03734652
KL Divergence                5.8223114
KL Loss                      0.58223116
QF Loss                      1004.58215
VF Loss                      729.35846
Policy Loss                  -1329.2906
Q Predictions Mean           1325.5745
Q Predictions Std            1035.4326
Q Predictions Max            2408.1333
Q Predictions Min            18.22046
V Predictions Mean           1339.2451
V Predictions Std            1039.1973
V Predictions Max            2412.168
V Predictions Min            17.581133
Log Pis Mean                 -5.2448697
Log Pis Std                  6.206067
Log Pis Max                  16.000793
Log Pis Min                  -15.996889
Policy mu Mean               0.07093132
Policy mu Std                0.7230362
Policy mu Max                3.0448258
Policy mu Min                -2.9720724
Policy log std Mean          -0.29705697
Policy log std Std           0.15579534
Policy log std Max           0.007686436
Policy log std Min           -0.98430663
Z mean eval                  0.0118835345
Z variance eval              0.03794892
total_rewards                [5149.67104066 5089.65556593 5157.92677509 5230.30902068 5166.87281242
 4195.99271998  760.66633273 5178.84519581 4109.8460941  5154.04412007]
total_rewards_mean           4519.382967747895
total_rewards_std            1315.0212428228297
total_rewards_max            5230.309020677313
total_rewards_min            760.6663327322009
Number of train steps total  420000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               122.82804988930002
(Previous) Eval Time (s)     29.60532060591504
Sample Time (s)              20.28391014924273
Epoch Time (s)               172.7172806444578
Total Train Time (s)         15464.092585739214
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:41:53.384541 UTC | [2020_01_14_06_24_08] Iteration #104 | Epoch Duration: 169.63408088684082
2020-01-14 10:41:53.384860 UTC | [2020_01_14_06_24_08] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01199612
Z variance train             0.03794084
KL Divergence                5.784812
KL Loss                      0.5784812
QF Loss                      1078.6814
VF Loss                      369.91748
Policy Loss                  -1173.9257
Q Predictions Mean           1163.9135
Q Predictions Std            1054.606
Q Predictions Max            2398.6965
Q Predictions Min            17.584934
V Predictions Mean           1171.3298
V Predictions Std            1048.0446
V Predictions Max            2391.057
V Predictions Min            29.345818
Log Pis Mean                 -5.813031
Log Pis Std                  6.937863
Log Pis Max                  22.46705
Log Pis Min                  -14.342544
Policy mu Mean               0.04052175
Policy mu Std                0.68259525
Policy mu Max                2.609315
Policy mu Min                -2.9512491
Policy log std Mean          -0.2727196
Policy log std Std           0.15501142
Policy log std Max           -0.054829516
Policy log std Min           -1.0883975
Z mean eval                  0.014024158
Z variance eval              0.03742071
total_rewards                [4678.56428517 1090.18669976 5034.46097948  907.08322814 2034.66886953
 1344.02900573 5079.56554119 4957.99336117 5065.88599184  746.28879785]
total_rewards_mean           3093.872675985399
total_rewards_std            1899.3606893117105
total_rewards_max            5079.56554119375
total_rewards_min            746.2887978546586
Number of train steps total  424000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               122.32564286002889
(Previous) Eval Time (s)     26.521815434563905
Sample Time (s)              19.961818042211235
Epoch Time (s)               168.80927633680403
Total Train Time (s)         15624.46868456481
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:44:33.760621 UTC | [2020_01_14_06_24_08] Iteration #105 | Epoch Duration: 160.37556099891663
2020-01-14 10:44:33.760782 UTC | [2020_01_14_06_24_08] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0139471665
Z variance train             0.037416834
KL Divergence                5.8152633
KL Loss                      0.58152634
QF Loss                      1501.0039
VF Loss                      590.9135
Policy Loss                  -1432.7385
Q Predictions Mean           1428.3645
Q Predictions Std            989.4178
Q Predictions Max            2403.7708
Q Predictions Min            12.949828
V Predictions Mean           1439.1554
V Predictions Std            989.7632
V Predictions Max            2404.1528
V Predictions Min            26.957527
Log Pis Mean                 -4.032956
Log Pis Std                  6.9409657
Log Pis Max                  30.332417
Log Pis Min                  -15.06932
Policy mu Mean               0.06228332
Policy mu Std                0.79546416
Policy mu Max                2.7913032
Policy mu Min                -3.6470437
Policy log std Mean          -0.3172598
Policy log std Std           0.16124596
Policy log std Max           0.13611327
Policy log std Min           -1.2343819
Z mean eval                  0.012031424
Z variance eval              0.036174178
total_rewards                [2626.74538589 5220.26781454 1654.60121598 5168.1529419  5175.03570457
 4141.55436099 5169.2922188  3356.80978449 5111.10693491 4755.52204625]
total_rewards_mean           4237.908840831298
total_rewards_std            1210.843054827445
total_rewards_max            5220.267814543165
total_rewards_min            1654.6012159795878
Number of train steps total  428000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               123.56165281496942
(Previous) Eval Time (s)     18.08782517304644
Sample Time (s)              19.951510751619935
Epoch Time (s)               161.6009887396358
Total Train Time (s)         15791.545847052708
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:47:20.840741 UTC | [2020_01_14_06_24_08] Iteration #106 | Epoch Duration: 167.07980823516846
2020-01-14 10:47:20.840990 UTC | [2020_01_14_06_24_08] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0120366495
Z variance train             0.036179516
KL Divergence                5.8957314
KL Loss                      0.58957314
QF Loss                      1821.9822
VF Loss                      348.21634
Policy Loss                  -1355.8219
Q Predictions Mean           1350.0203
Q Predictions Std            1034.5919
Q Predictions Max            2422.431
Q Predictions Min            9.395356
V Predictions Mean           1359.135
V Predictions Std            1032.4991
V Predictions Max            2438.2856
V Predictions Min            25.459488
Log Pis Mean                 -5.0133343
Log Pis Std                  7.0959105
Log Pis Max                  25.994265
Log Pis Min                  -15.428604
Policy mu Mean               0.07338596
Policy mu Std                0.75804996
Policy mu Max                3.7808838
Policy mu Min                -3.8227363
Policy log std Mean          -0.29523495
Policy log std Std           0.15991254
Policy log std Max           -0.02071853
Policy log std Min           -1.0515544
Z mean eval                  0.012526813
Z variance eval              0.034901343
total_rewards                [3914.69575286  841.09465847 3821.73763533 2152.82689427 5149.46733537
 5171.32805615 2824.19157137 5130.10194049 4618.77765285 1475.83837859]
total_rewards_mean           3510.0059875761317
total_rewards_std            1521.054321975561
total_rewards_max            5171.328056149571
total_rewards_min            841.0946584724026
Number of train steps total  432000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               120.75103684514761
(Previous) Eval Time (s)     23.56633133813739
Sample Time (s)              19.758484083227813
Epoch Time (s)               164.0758522665128
Total Train Time (s)         15952.624429756775
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:50:01.922207 UTC | [2020_01_14_06_24_08] Iteration #107 | Epoch Duration: 161.08101344108582
2020-01-14 10:50:01.922517 UTC | [2020_01_14_06_24_08] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012594302
Z variance train             0.034907557
KL Divergence                5.988077
KL Loss                      0.59880775
QF Loss                      1432.6914
VF Loss                      619.6697
Policy Loss                  -1420.013
Q Predictions Mean           1411.5096
Q Predictions Std            1031.479
Q Predictions Max            2444.7275
Q Predictions Min            15.988583
V Predictions Mean           1407.3267
V Predictions Std            1018.1301
V Predictions Max            2420.9497
V Predictions Min            20.414919
Log Pis Mean                 -4.2147484
Log Pis Std                  7.5540895
Log Pis Max                  31.63991
Log Pis Min                  -13.745102
Policy mu Mean               0.058334947
Policy mu Std                0.7909792
Policy mu Max                3.3380983
Policy mu Min                -2.9926338
Policy log std Mean          -0.31076035
Policy log std Std           0.16754422
Policy log std Max           0.015596941
Policy log std Min           -1.0959034
Z mean eval                  0.008883913
Z variance eval              0.034387544
total_rewards                [3642.38342747 4165.68796034 1552.16952268 5187.66477865 3470.65073244
  689.07141218 2939.44079187 5225.08371827 3084.23006973 4075.50051386]
total_rewards_mean           3403.1882927490965
total_rewards_std            1367.7840198796212
total_rewards_max            5225.0837182687865
total_rewards_min            689.0714121777322
Number of train steps total  436000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               118.39495659293607
(Previous) Eval Time (s)     20.57119466504082
Sample Time (s)              20.229190258774906
Epoch Time (s)               159.1953415167518
Total Train Time (s)         16110.732443788555
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:52:40.030883 UTC | [2020_01_14_06_24_08] Iteration #108 | Epoch Duration: 158.10816526412964
2020-01-14 10:52:40.031084 UTC | [2020_01_14_06_24_08] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008924579
Z variance train             0.034394838
KL Divergence                6.0192547
KL Loss                      0.6019255
QF Loss                      1159.3607
VF Loss                      444.187
Policy Loss                  -1327.8843
Q Predictions Mean           1321.8486
Q Predictions Std            1024.5613
Q Predictions Max            2426.1333
Q Predictions Min            15.858355
V Predictions Mean           1327.6259
V Predictions Std            1022.3266
V Predictions Max            2433.1987
V Predictions Min            25.973564
Log Pis Mean                 -4.721882
Log Pis Std                  7.4146543
Log Pis Max                  29.010654
Log Pis Min                  -14.217346
Policy mu Mean               0.062151097
Policy mu Std                0.75657946
Policy mu Max                3.1273649
Policy mu Min                -2.9339564
Policy log std Mean          -0.30017352
Policy log std Std           0.1691419
Policy log std Max           0.108232394
Policy log std Min           -1.2518479
Z mean eval                  0.0076167495
Z variance eval              0.034367904
total_rewards                [5095.45399789 5028.02145147 4553.41562106 5070.76355037 5130.47027873
 5040.96861573 5069.83921045 5094.12010436 5107.09817543 5089.82794942]
total_rewards_mean           5027.997895492053
total_rewards_std            160.7728346645863
total_rewards_max            5130.470278728816
total_rewards_min            4553.415621055724
Number of train steps total  440000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               119.66320199985057
(Previous) Eval Time (s)     19.483681726269424
Sample Time (s)              19.05909674335271
Epoch Time (s)               158.2059804694727
Total Train Time (s)         16278.414262681268
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:55:27.713981 UTC | [2020_01_14_06_24_08] Iteration #109 | Epoch Duration: 167.68276262283325
2020-01-14 10:55:27.714166 UTC | [2020_01_14_06_24_08] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0076532527
Z variance train             0.034366734
KL Divergence                6.020554
KL Loss                      0.60205543
QF Loss                      1311.2773
VF Loss                      434.4495
Policy Loss                  -1451.0205
Q Predictions Mean           1444.8126
Q Predictions Std            1019.1046
Q Predictions Max            2428.615
Q Predictions Min            20.8722
V Predictions Mean           1449.3594
V Predictions Std            1012.6427
V Predictions Max            2422.7798
V Predictions Min            26.334858
Log Pis Mean                 -4.564642
Log Pis Std                  6.660082
Log Pis Max                  29.39588
Log Pis Min                  -13.592015
Policy mu Mean               0.04891887
Policy mu Std                0.7506312
Policy mu Max                3.3184276
Policy mu Min                -2.7941685
Policy log std Mean          -0.3116053
Policy log std Std           0.15653168
Policy log std Max           0.019753024
Policy log std Min           -1.1187924
Z mean eval                  0.009211799
Z variance eval              0.03489781
total_rewards                [4880.18546426 5070.67704571 4556.48516128 5065.09382182 3548.11868999
 5199.68278206 5145.70864241 2134.59828318 5077.34263446 5020.84749893]
total_rewards_mean           4569.87400240951
total_rewards_std            935.7465847064458
total_rewards_max            5199.68278205579
total_rewards_min            2134.5982831756355
Number of train steps total  444000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               121.86293268064037
(Previous) Eval Time (s)     28.960112288128585
Sample Time (s)              20.024831926450133
Epoch Time (s)               170.8478768952191
Total Train Time (s)         16447.836886378005
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:58:17.138080 UTC | [2020_01_14_06_24_08] Iteration #110 | Epoch Duration: 169.42378449440002
2020-01-14 10:58:17.138238 UTC | [2020_01_14_06_24_08] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009318436
Z variance train             0.03490125
KL Divergence                5.983431
KL Loss                      0.5983431
QF Loss                      1201.2875
VF Loss                      775.3252
Policy Loss                  -1412.2605
Q Predictions Mean           1405.6168
Q Predictions Std            1014.25946
Q Predictions Max            2431.3022
Q Predictions Min            17.515057
V Predictions Mean           1398.8729
V Predictions Std            1006.89886
V Predictions Max            2440.2905
V Predictions Min            25.300688
Log Pis Mean                 -4.125625
Log Pis Std                  7.4236636
Log Pis Max                  28.101814
Log Pis Min                  -13.530302
Policy mu Mean               0.07851316
Policy mu Std                0.7849811
Policy mu Max                2.9726515
Policy mu Min                -3.1272821
Policy log std Mean          -0.31533477
Policy log std Std           0.17761943
Policy log std Max           -0.0010519773
Policy log std Min           -1.3641336
Z mean eval                  0.0080923885
Z variance eval              0.03544976
total_rewards                [4985.97575558 4891.73429071 3957.15408827 4985.70170094 2060.22754277
 4932.00899421 4941.4534504  5029.72860081 5089.71749212 4907.16309851]
total_rewards_mean           4578.086501432828
total_rewards_std            893.7228016277809
total_rewards_max            5089.717492121542
total_rewards_min            2060.2275427677428
Number of train steps total  448000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               125.22930014971644
(Previous) Eval Time (s)     27.535716275218874
Sample Time (s)              20.200568060856313
Epoch Time (s)               172.96558448579162
Total Train Time (s)         16621.179205740802
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:01:10.482295 UTC | [2020_01_14_06_24_08] Iteration #111 | Epoch Duration: 173.34392404556274
2020-01-14 11:01:10.482511 UTC | [2020_01_14_06_24_08] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008042553
Z variance train             0.03545057
KL Divergence                5.9403925
KL Loss                      0.59403926
QF Loss                      1745.832
VF Loss                      644.4475
Policy Loss                  -1442.3118
Q Predictions Mean           1440.7085
Q Predictions Std            1013.3534
Q Predictions Max            2423.615
Q Predictions Min            17.784403
V Predictions Mean           1446.891
V Predictions Std            1012.84985
V Predictions Max            2441.2495
V Predictions Min            31.636732
Log Pis Mean                 -4.1337185
Log Pis Std                  7.306617
Log Pis Max                  30.409956
Log Pis Min                  -13.805555
Policy mu Mean               0.062226
Policy mu Std                0.77672535
Policy mu Max                3.7732882
Policy mu Min                -3.0654676
Policy log std Mean          -0.3100191
Policy log std Std           0.15832284
Policy log std Max           -0.0010857284
Policy log std Min           -1.1001948
Z mean eval                  0.010720235
Z variance eval              0.03529076
total_rewards                [5100.92875506 1594.90796258 2995.62911295 4536.76233146 2760.14303362
 3348.36401445  747.20398238 5119.80360396 2480.71159573 3651.48406724]
total_rewards_mean           3233.5938459437434
total_rewards_std            1365.496978789761
total_rewards_max            5119.803603964722
total_rewards_min            747.2039823781688
Number of train steps total  452000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               127.36046779807657
(Previous) Eval Time (s)     27.91372468881309
Sample Time (s)              20.863169697113335
Epoch Time (s)               176.137362184003
Total Train Time (s)         16787.773093344644
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:03:57.078669 UTC | [2020_01_14_06_24_08] Iteration #112 | Epoch Duration: 166.59600496292114
2020-01-14 11:03:57.078885 UTC | [2020_01_14_06_24_08] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010832472
Z variance train             0.035291135
KL Divergence                5.9529734
KL Loss                      0.59529734
QF Loss                      1100.5977
VF Loss                      816.5718
Policy Loss                  -1542.0287
Q Predictions Mean           1535.3755
Q Predictions Std            985.23883
Q Predictions Max            2439.4556
Q Predictions Min            17.591719
V Predictions Mean           1536.6846
V Predictions Std            981.8463
V Predictions Max            2450.1455
V Predictions Min            29.193668
Log Pis Mean                 -3.6048841
Log Pis Std                  7.86935
Log Pis Max                  34.39888
Log Pis Min                  -14.895885
Policy mu Mean               0.0800558
Policy mu Std                0.7979118
Policy mu Max                4.1728287
Policy mu Min                -3.1341012
Policy log std Mean          -0.31752688
Policy log std Std           0.16219571
Policy log std Max           0.013647005
Policy log std Min           -1.0319587
Z mean eval                  0.011917117
Z variance eval              0.03406498
total_rewards                [3920.68368125 5176.75208125 1952.83438943  709.62732929 3210.62621311
 5168.2557386  1284.32008573 5162.19753424 2859.79608005 1204.51164123]
total_rewards_mean           3064.960477418186
total_rewards_std            1658.1272537160085
total_rewards_max            5176.752081251223
total_rewards_min            709.6273292908757
Number of train steps total  456000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               123.77428148174658
(Previous) Eval Time (s)     18.372016155160964
Sample Time (s)              21.331932574976236
Epoch Time (s)               163.47823021188378
Total Train Time (s)         16950.6991704111
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:06:40.006817 UTC | [2020_01_14_06_24_08] Iteration #113 | Epoch Duration: 162.92777562141418
2020-01-14 11:06:40.007006 UTC | [2020_01_14_06_24_08] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011810394
Z variance train             0.034062922
KL Divergence                6.0374794
KL Loss                      0.60374796
QF Loss                      1312.1523
VF Loss                      699.3786
Policy Loss                  -1427.5393
Q Predictions Mean           1426.9857
Q Predictions Std            1031.3723
Q Predictions Max            2454.9744
Q Predictions Min            19.976295
V Predictions Mean           1436.0669
V Predictions Std            1025.8851
V Predictions Max            2452.5789
V Predictions Min            26.774479
Log Pis Mean                 -4.78375
Log Pis Std                  6.890274
Log Pis Max                  30.805378
Log Pis Min                  -14.958869
Policy mu Mean               0.0443864
Policy mu Std                0.75821126
Policy mu Max                4.0135145
Policy mu Min                -3.06619
Policy log std Mean          -0.29813117
Policy log std Std           0.15340036
Policy log std Max           0.014456421
Policy log std Min           -0.9068218
Z mean eval                  0.011634286
Z variance eval              0.03344288
total_rewards                [5063.67615069 5067.10047412 3604.51886277 1501.84999939 1907.04456159
 5037.02838342 3879.68051177 5059.95922328 5082.52722285 5021.53669697]
total_rewards_mean           4122.492208685393
total_rewards_std            1316.3019714313516
total_rewards_max            5082.527222851287
total_rewards_min            1501.8499993900914
Number of train steps total  460000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               124.0632885391824
(Previous) Eval Time (s)     17.821221901103854
Sample Time (s)              20.133925184141845
Epoch Time (s)               162.0184356244281
Total Train Time (s)         17119.141678221524
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:09:28.452796 UTC | [2020_01_14_06_24_08] Iteration #114 | Epoch Duration: 168.44562315940857
2020-01-14 11:09:28.453065 UTC | [2020_01_14_06_24_08] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01170663
Z variance train             0.03343668
KL Divergence                6.0893784
KL Loss                      0.60893786
QF Loss                      1417.1152
VF Loss                      628.2434
Policy Loss                  -1479.6438
Q Predictions Mean           1465.1854
Q Predictions Std            1027.4434
Q Predictions Max            2468.4976
Q Predictions Min            19.564981
V Predictions Mean           1469.5026
V Predictions Std            1014.7262
V Predictions Max            2459.4392
V Predictions Min            21.110619
Log Pis Mean                 -4.480459
Log Pis Std                  7.422224
Log Pis Max                  34.987984
Log Pis Min                  -13.222204
Policy mu Mean               0.057269868
Policy mu Std                0.7743949
Policy mu Max                3.265248
Policy mu Min                -3.611786
Policy log std Mean          -0.3050394
Policy log std Std           0.15963453
Policy log std Max           -0.06422913
Policy log std Min           -1.2945021
Z mean eval                  0.013758482
Z variance eval              0.034209803
total_rewards                [5135.12035945 5197.13273262 5113.75800618 5140.71272995 5045.75738349
 5103.53935677 5169.28240486 5176.38308594 4782.34309772 5112.35920526]
total_rewards_mean           5097.638836223399
total_rewards_std            112.74180192742988
total_rewards_max            5197.132732619581
total_rewards_min            4782.343097718625
Number of train steps total  464000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               116.33176003862172
(Previous) Eval Time (s)     24.248068946879357
Sample Time (s)              20.797280456405133
Epoch Time (s)               161.3771094419062
Total Train Time (s)         17285.68913860107
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:12:15.004369 UTC | [2020_01_14_06_24_08] Iteration #115 | Epoch Duration: 166.55099821090698
2020-01-14 11:12:15.004770 UTC | [2020_01_14_06_24_08] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013803812
Z variance train             0.034209426
KL Divergence                6.036333
KL Loss                      0.60363334
QF Loss                      1041.3413
VF Loss                      594.202
Policy Loss                  -1619.9829
Q Predictions Mean           1611.0208
Q Predictions Std            986.68195
Q Predictions Max            2463.9844
Q Predictions Min            17.883858
V Predictions Mean           1608.6223
V Predictions Std            978.44476
V Predictions Max            2457.9663
V Predictions Min            31.057058
Log Pis Mean                 -3.6531072
Log Pis Std                  6.452042
Log Pis Max                  18.039787
Log Pis Min                  -13.619772
Policy mu Mean               0.06918485
Policy mu Std                0.7923294
Policy mu Max                3.0260632
Policy mu Min                -2.9574502
Policy log std Mean          -0.31813917
Policy log std Std           0.15244345
Policy log std Max           -0.05902417
Policy log std Min           -1.0779346
Z mean eval                  0.015086189
Z variance eval              0.033715624
total_rewards                [4991.10904911 3338.20078928 5002.10654457 4036.08006514 1231.98003725
 4959.06584211 5090.91613212 1238.26246858 5050.10254477 4159.01042443]
total_rewards_mean           3909.6833897363076
total_rewards_std            1444.6888042918097
total_rewards_max            5090.916132121183
total_rewards_min            1231.9800372520365
Number of train steps total  468000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               120.72721172962338
(Previous) Eval Time (s)     29.42164438404143
Sample Time (s)              19.679873913526535
Epoch Time (s)               169.82873002719134
Total Train Time (s)         17449.252669945825
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:14:58.567196 UTC | [2020_01_14_06_24_08] Iteration #116 | Epoch Duration: 163.56222128868103
2020-01-14 11:14:58.567367 UTC | [2020_01_14_06_24_08] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015007408
Z variance train             0.033720773
KL Divergence                6.0834966
KL Loss                      0.6083497
QF Loss                      1729.0815
VF Loss                      738.8666
Policy Loss                  -1487.4409
Q Predictions Mean           1485.5474
Q Predictions Std            1023.04724
Q Predictions Max            2468.5522
Q Predictions Min            15.763837
V Predictions Mean           1500.7502
V Predictions Std            1023.2345
V Predictions Max            2490.2239
V Predictions Min            29.506306
Log Pis Mean                 -3.9166117
Log Pis Std                  7.22906
Log Pis Max                  23.048485
Log Pis Min                  -13.437771
Policy mu Mean               0.063631594
Policy mu Std                0.79379594
Policy mu Max                3.5686517
Policy mu Min                -2.8915741
Policy log std Mean          -0.31818676
Policy log std Std           0.1673763
Policy log std Max           0.016126424
Policy log std Min           -1.2416208
Z mean eval                  0.011864826
Z variance eval              0.03370155
total_rewards                [4615.74232604 5060.81968381 4460.36221571 5068.48426084 5039.33039988
 5141.06873765 5112.89450275 4994.41920576 5100.86043648 4927.99818766]
total_rewards_mean           4952.197995656651
total_rewards_std            217.7113643568256
total_rewards_max            5141.0687376461265
total_rewards_min            4460.362215707802
Number of train steps total  472000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               126.82364822318777
(Previous) Eval Time (s)     23.154839009046555
Sample Time (s)              19.67992744129151
Epoch Time (s)               169.65841467352584
Total Train Time (s)         17625.41086653387
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:17:54.728014 UTC | [2020_01_14_06_24_08] Iteration #117 | Epoch Duration: 176.16046738624573
2020-01-14 11:17:54.728328 UTC | [2020_01_14_06_24_08] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011882347
Z variance train             0.033700366
KL Divergence                6.092425
KL Loss                      0.6092425
QF Loss                      1170.1558
VF Loss                      967.23303
Policy Loss                  -1523.4885
Q Predictions Mean           1516.5049
Q Predictions Std            1010.3753
Q Predictions Max            2474.7761
Q Predictions Min            13.1476555
V Predictions Mean           1515.1641
V Predictions Std            999.73987
V Predictions Max            2465.9226
V Predictions Min            30.877563
Log Pis Mean                 -3.7673187
Log Pis Std                  7.465364
Log Pis Max                  26.723137
Log Pis Min                  -16.81483
Policy mu Mean               0.07248027
Policy mu Std                0.7983186
Policy mu Max                2.7299938
Policy mu Min                -2.8924494
Policy log std Mean          -0.3207929
Policy log std Std           0.16085042
Policy log std Max           -0.0074342713
Policy log std Min           -1.0850679
Z mean eval                  0.010600333
Z variance eval              0.031768493
total_rewards                [5137.40324874 4902.23394081 5143.4706846  5186.57976579 5148.94751907
 5201.95298167 1469.54828732 5131.56726614 2767.94935858 5163.79263895]
total_rewards_mean           4525.344569166517
total_rewards_std            1240.3267161109607
total_rewards_max            5201.95298166555
total_rewards_min            1469.548287322859
Number of train steps total  476000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               119.76322219893336
(Previous) Eval Time (s)     29.656552969943732
Sample Time (s)              19.877234533429146
Epoch Time (s)               169.29700970230624
Total Train Time (s)         17791.169712877367
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:20:40.488814 UTC | [2020_01_14_06_24_08] Iteration #118 | Epoch Duration: 165.76033687591553
2020-01-14 11:20:40.489063 UTC | [2020_01_14_06_24_08] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010689098
Z variance train             0.0317673
KL Divergence                6.2358694
KL Loss                      0.62358695
QF Loss                      1980.5557
VF Loss                      548.5534
Policy Loss                  -1440.772
Q Predictions Mean           1435.8655
Q Predictions Std            1045.8782
Q Predictions Max            2479.6462
Q Predictions Min            18.002905
V Predictions Mean           1435.9675
V Predictions Std            1037.9036
V Predictions Max            2469.4084
V Predictions Min            21.84455
Log Pis Mean                 -4.1606255
Log Pis Std                  7.4135456
Log Pis Max                  29.914787
Log Pis Min                  -18.660446
Policy mu Mean               0.059240896
Policy mu Std                0.7704652
Policy mu Max                2.9341702
Policy mu Min                -3.2333934
Policy log std Mean          -0.3044751
Policy log std Std           0.1612243
Policy log std Max           0.008765876
Policy log std Min           -1.1169357
Z mean eval                  0.013380149
Z variance eval              0.031518072
total_rewards                [5131.74820013 5026.55148609 3919.4891093  4214.87132583 5097.70315723
 5165.30929371 3493.7700053  5169.51361648 5168.6971653  5021.71062981]
total_rewards_mean           4740.936398918622
total_rewards_std            591.1108790389719
total_rewards_max            5169.513616481392
total_rewards_min            3493.770005296593
Number of train steps total  480000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               119.87353085028008
(Previous) Eval Time (s)     26.11953618377447
Sample Time (s)              20.299212012905627
Epoch Time (s)               166.29227904696018
Total Train Time (s)         17958.23752785893
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:23:27.559406 UTC | [2020_01_14_06_24_08] Iteration #119 | Epoch Duration: 167.07016229629517
2020-01-14 11:23:27.559641 UTC | [2020_01_14_06_24_08] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013410712
Z variance train             0.031516854
KL Divergence                6.2393737
KL Loss                      0.62393737
QF Loss                      1002.49207
VF Loss                      413.3356
Policy Loss                  -1554.8467
Q Predictions Mean           1550.1797
Q Predictions Std            1019.5264
Q Predictions Max            2487.5427
Q Predictions Min            18.90732
V Predictions Mean           1554.417
V Predictions Std            1015.35205
V Predictions Max            2480.8005
V Predictions Min            26.540936
Log Pis Mean                 -5.037716
Log Pis Std                  5.99165
Log Pis Max                  15.2016945
Log Pis Min                  -16.055395
Policy mu Mean               0.08471189
Policy mu Std                0.74074745
Policy mu Max                3.033783
Policy mu Min                -2.8488393
Policy log std Mean          -0.3048163
Policy log std Std           0.15188949
Policy log std Max           -0.038856737
Policy log std Min           -1.1681913
Z mean eval                  0.013786947
Z variance eval              0.031397752
total_rewards                [3234.60338624 4984.4404311  4961.29938189 5026.27229677 2973.71536562
 4905.92286864 4869.0260665  2589.77839228 4973.94495892 4935.84314686]
total_rewards_mean           4345.484629482175
total_rewards_std            937.0671713252749
total_rewards_max            5026.272296773157
total_rewards_min            2589.7783922812964
Number of train steps total  484000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               121.36318593611941
(Previous) Eval Time (s)     26.897136175073683
Sample Time (s)              20.436193894129246
Epoch Time (s)               168.69651600532234
Total Train Time (s)         18126.731027886737
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:26:16.056699 UTC | [2020_01_14_06_24_08] Iteration #120 | Epoch Duration: 168.49685668945312
2020-01-14 11:26:16.057017 UTC | [2020_01_14_06_24_08] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01366772
Z variance train             0.03139606
KL Divergence                6.2524357
KL Loss                      0.6252436
QF Loss                      1218.3479
VF Loss                      551.0277
Policy Loss                  -1488.2903
Q Predictions Mean           1485.2218
Q Predictions Std            1049.7695
Q Predictions Max            2499.0574
Q Predictions Min            21.479586
V Predictions Mean           1499.3268
V Predictions Std            1051.0798
V Predictions Max            2502.7913
V Predictions Min            24.396246
Log Pis Mean                 -4.2205844
Log Pis Std                  6.9629455
Log Pis Max                  20.885017
Log Pis Min                  -12.968821
Policy mu Mean               0.062881924
Policy mu Std                0.7674318
Policy mu Max                2.9384875
Policy mu Min                -2.752191
Policy log std Mean          -0.3112168
Policy log std Std           0.15860868
Policy log std Max           -0.0022495538
Policy log std Min           -0.96978116
Z mean eval                  0.016686618
Z variance eval              0.031957768
total_rewards                [5130.98225994 2805.69657914 5077.59678521 5082.74515091 1582.38137052
 3645.95399403 5113.55781592 5119.2907328  5147.20971965 5073.61474334]
total_rewards_mean           4377.902915146983
total_rewards_std            1205.931889362493
total_rewards_max            5147.209719652498
total_rewards_min            1582.3813705155128
Number of train steps total  488000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               115.8287777369842
(Previous) Eval Time (s)     26.69716016203165
Sample Time (s)              19.596317796967924
Epoch Time (s)               162.12225569598377
Total Train Time (s)         18287.57581715146
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:28:56.901428 UTC | [2020_01_14_06_24_08] Iteration #121 | Epoch Duration: 160.8442187309265
2020-01-14 11:28:56.901587 UTC | [2020_01_14_06_24_08] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016774748
Z variance train             0.031959
KL Divergence                6.2220926
KL Loss                      0.62220925
QF Loss                      1676.7668
VF Loss                      480.12228
Policy Loss                  -1689.8282
Q Predictions Mean           1688.9192
Q Predictions Std            965.51776
Q Predictions Max            2491.6182
Q Predictions Min            20.19468
V Predictions Mean           1686.4948
V Predictions Std            957.19965
V Predictions Max            2494.4583
V Predictions Min            29.15196
Log Pis Mean                 -3.1629653
Log Pis Std                  7.6967216
Log Pis Max                  26.398663
Log Pis Min                  -14.628974
Policy mu Mean               0.08506023
Policy mu Std                0.828258
Policy mu Max                3.657223
Policy mu Min                -3.469713
Policy log std Mean          -0.32546782
Policy log std Std           0.16893774
Policy log std Max           0.0722785
Policy log std Min           -1.3432883
Z mean eval                  0.0140901
Z variance eval              0.032443937
total_rewards                [5169.09747321 5149.28188115 5126.87367751 1438.28926978 5112.47865242
 1433.78327661 5137.01633965 5114.73586425 5119.58417061 5139.01253612]
total_rewards_mean           4394.015314131374
total_rewards_std            1479.0774393716083
total_rewards_max            5169.09747321387
total_rewards_min            1433.7832766132424
Number of train steps total  492000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               120.2492506140843
(Previous) Eval Time (s)     25.418858387041837
Sample Time (s)              19.345967575907707
Epoch Time (s)               165.01407657703385
Total Train Time (s)         18453.064413238782
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:31:42.394607 UTC | [2020_01_14_06_24_08] Iteration #122 | Epoch Duration: 165.49286699295044
2020-01-14 11:31:42.394902 UTC | [2020_01_14_06_24_08] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014038903
Z variance train             0.032447077
KL Divergence                6.192848
KL Loss                      0.6192848
QF Loss                      1059.279
VF Loss                      450.8278
Policy Loss                  -1516.2117
Q Predictions Mean           1512.2607
Q Predictions Std            1051.6002
Q Predictions Max            2490.7754
Q Predictions Min            14.017691
V Predictions Mean           1512.674
V Predictions Std            1049.0061
V Predictions Max            2497.8977
V Predictions Min            27.57307
Log Pis Mean                 -4.628657
Log Pis Std                  6.644068
Log Pis Max                  21.924906
Log Pis Min                  -14.352715
Policy mu Mean               0.06681145
Policy mu Std                0.7451441
Policy mu Max                3.1073618
Policy mu Min                -3.0860863
Policy log std Mean          -0.3020153
Policy log std Std           0.1544578
Policy log std Max           -0.009044059
Policy log std Min           -1.2023873
Z mean eval                  0.013351729
Z variance eval              0.032323863
total_rewards                [5070.32709428 5092.84514932 5124.04276316 5030.62678769 4933.98293301
 5087.52124577 4824.45645312 5082.43860843 5093.56062595 5078.32406347]
total_rewards_mean           5041.812572422294
total_rewards_std            87.70743941518093
total_rewards_max            5124.0427631638295
total_rewards_min            4824.456453122081
Number of train steps total  496000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               119.50017547560856
(Previous) Eval Time (s)     25.89733716007322
Sample Time (s)              20.356280157808214
Epoch Time (s)               165.75379279349
Total Train Time (s)         18622.48147778865
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:34:31.814573 UTC | [2020_01_14_06_24_08] Iteration #123 | Epoch Duration: 169.4194531440735
2020-01-14 11:34:31.814832 UTC | [2020_01_14_06_24_08] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013317044
Z variance train             0.032319803
KL Divergence                6.1858797
KL Loss                      0.618588
QF Loss                      1457.5825
VF Loss                      578.42847
Policy Loss                  -1571.9429
Q Predictions Mean           1565.1191
Q Predictions Std            1021.4145
Q Predictions Max            2498.597
Q Predictions Min            16.488976
V Predictions Mean           1569.4403
V Predictions Std            1017.24615
V Predictions Max            2495.82
V Predictions Min            27.12504
Log Pis Mean                 -4.375381
Log Pis Std                  6.7771907
Log Pis Max                  22.407274
Log Pis Min                  -12.565466
Policy mu Mean               0.05641262
Policy mu Std                0.7767722
Policy mu Max                2.9729478
Policy mu Min                -2.9193697
Policy log std Mean          -0.29858077
Policy log std Std           0.1571257
Policy log std Max           0.0331147
Policy log std Min           -1.1125333
Z mean eval                  0.013477875
Z variance eval              0.03197481
total_rewards                [5108.84221598 1177.32335441 5131.944648   5115.68078422 5129.97376378
 3165.86127998 2755.78881873 5081.68734749 5085.54807746 5133.63566531]
total_rewards_mean           4288.628595535323
total_rewards_std            1343.290500408064
total_rewards_max            5133.635665311205
total_rewards_min            1177.3233544062853
Number of train steps total  500000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               119.48620236199349
(Previous) Eval Time (s)     29.562658094335347
Sample Time (s)              20.251799689605832
Epoch Time (s)               169.30066014593467
Total Train Time (s)         18787.7604073151
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:37:17.094616 UTC | [2020_01_14_06_24_08] Iteration #124 | Epoch Duration: 165.2795958518982
2020-01-14 11:37:17.094822 UTC | [2020_01_14_06_24_08] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013473886
Z variance train             0.031972133
KL Divergence                6.2116404
KL Loss                      0.621164
QF Loss                      1061.5143
VF Loss                      468.85587
Policy Loss                  -1606.3956
Q Predictions Mean           1599.2412
Q Predictions Std            1050.592
Q Predictions Max            2501.6636
Q Predictions Min            15.381247
V Predictions Mean           1611.5671
V Predictions Std            1050.831
V Predictions Max            2512.6865
V Predictions Min            26.047243
Log Pis Mean                 -4.716548
Log Pis Std                  6.6879745
Log Pis Max                  33.40712
Log Pis Min                  -15.962141
Policy mu Mean               0.080404446
Policy mu Std                0.74102724
Policy mu Max                3.4635506
Policy mu Min                -2.9836183
Policy log std Mean          -0.29407787
Policy log std Std           0.14922214
Policy log std Max           -0.013541192
Policy log std Min           -1.0945592
Z mean eval                  0.012019897
Z variance eval              0.03390369
total_rewards                [5117.68903893 2260.46310146 4290.33903228 2902.10297013 5134.60817787
 5116.24559395 2158.28617769 2742.24385663 5145.29702035 5131.33509339]
total_rewards_mean           3999.8610062671787
total_rewards_std            1251.5477010061136
total_rewards_max            5145.29702034835
total_rewards_min            2158.2861776875707
Number of train steps total  504000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               120.37404362484813
(Previous) Eval Time (s)     25.541295485105366
Sample Time (s)              20.653757002670318
Epoch Time (s)               166.5690961126238
Total Train Time (s)         18951.636093248148
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:40:00.972867 UTC | [2020_01_14_06_24_08] Iteration #125 | Epoch Duration: 163.87783885002136
2020-01-14 11:40:00.973138 UTC | [2020_01_14_06_24_08] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012086402
Z variance train             0.033900626
KL Divergence                6.0681586
KL Loss                      0.6068159
QF Loss                      1207.6063
VF Loss                      554.9359
Policy Loss                  -1528.2374
Q Predictions Mean           1525.0469
Q Predictions Std            1048.8894
Q Predictions Max            2526.498
Q Predictions Min            15.234823
V Predictions Mean           1522.133
V Predictions Std            1035.6444
V Predictions Max            2506.9822
V Predictions Min            28.071781
Log Pis Mean                 -5.018307
Log Pis Std                  6.4450235
Log Pis Max                  22.027412
Log Pis Min                  -13.770634
Policy mu Mean               0.05433092
Policy mu Std                0.7368121
Policy mu Max                2.9702153
Policy mu Min                -2.7284758
Policy log std Mean          -0.30429065
Policy log std Std           0.15332699
Policy log std Max           -0.042098977
Policy log std Min           -1.0184227
Z mean eval                  0.012108771
Z variance eval              0.035108566
total_rewards                [5103.51092707 5043.26982741 5068.85543142 5070.63062215 5074.63705334
 1372.41077063 5066.50651064 5038.74809693 5058.3873107  5053.11174747]
total_rewards_mean           4695.006829775367
total_rewards_std            1107.6658783183657
total_rewards_max            5103.51092707001
total_rewards_min            1372.4107706271077
Number of train steps total  508000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               126.37084436696023
(Previous) Eval Time (s)     22.849742102902383
Sample Time (s)              19.70328970719129
Epoch Time (s)               168.9238761770539
Total Train Time (s)         19125.504825728945
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:42:54.843152 UTC | [2020_01_14_06_24_08] Iteration #126 | Epoch Duration: 173.86985445022583
2020-01-14 11:42:54.843341 UTC | [2020_01_14_06_24_08] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012111397
Z variance train             0.03510546
KL Divergence                5.974695
KL Loss                      0.5974695
QF Loss                      1569.217
VF Loss                      474.6954
Policy Loss                  -1661.0536
Q Predictions Mean           1654.0513
Q Predictions Std            999.6068
Q Predictions Max            2511.3833
Q Predictions Min            15.268805
V Predictions Mean           1654.1799
V Predictions Std            994.22424
V Predictions Max            2512.7542
V Predictions Min            24.750023
Log Pis Mean                 -4.2076454
Log Pis Std                  7.1459904
Log Pis Max                  25.00335
Log Pis Min                  -15.239918
Policy mu Mean               0.05448714
Policy mu Std                0.7874381
Policy mu Max                3.2872574
Policy mu Min                -3.094369
Policy log std Mean          -0.31659442
Policy log std Std           0.15904826
Policy log std Max           0.002590865
Policy log std Min           -1.0699004
Z mean eval                  0.013777269
Z variance eval              0.036152493
total_rewards                [2910.42647689 5052.14978585 5053.60735605 5013.24320861 5020.92589415
 5031.23013745 5040.99836138 5055.39291993 5024.21618868 4977.07929612]
total_rewards_mean           4817.926962511775
total_rewards_std            636.2275197017948
total_rewards_max            5055.3929199316135
total_rewards_min            2910.426476887447
Number of train steps total  512000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               122.8055348820053
(Previous) Eval Time (s)     27.79545900085941
Sample Time (s)              20.07806692318991
Epoch Time (s)               170.67906080605462
Total Train Time (s)         19297.412214397453
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:45:46.753773 UTC | [2020_01_14_06_24_08] Iteration #127 | Epoch Duration: 171.91028094291687
2020-01-14 11:45:46.753986 UTC | [2020_01_14_06_24_08] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013699859
Z variance train             0.03614998
KL Divergence                5.916222
KL Loss                      0.59162223
QF Loss                      1155.6382
VF Loss                      427.3748
Policy Loss                  -1631.5507
Q Predictions Mean           1630.0289
Q Predictions Std            1038.7206
Q Predictions Max            2539.67
Q Predictions Min            16.52859
V Predictions Mean           1635.8018
V Predictions Std            1034.6376
V Predictions Max            2529.284
V Predictions Min            23.086977
Log Pis Mean                 -4.33833
Log Pis Std                  7.3806243
Log Pis Max                  26.824774
Log Pis Min                  -15.24304
Policy mu Mean               0.0993399
Policy mu Std                0.7657807
Policy mu Max                3.5152037
Policy mu Min                -2.8620815
Policy log std Mean          -0.31155473
Policy log std Std           0.16335027
Policy log std Max           0.021674693
Policy log std Min           -1.1636763
Z mean eval                  0.014482799
Z variance eval              0.035193387
total_rewards                [5095.94480188 5104.38256259 5093.47322368 5119.47202053 5151.39927615
 5094.95789734 5134.75893518 5116.99004363 5106.18757554 5026.13336422]
total_rewards_mean           5104.369970073385
total_rewards_std            31.504226721900704
total_rewards_max            5151.399276152462
total_rewards_min            5026.133364216646
Number of train steps total  516000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               119.6546781109646
(Previous) Eval Time (s)     29.026335820090026
Sample Time (s)              20.108523486182094
Epoch Time (s)               168.78953741723672
Total Train Time (s)         19466.775562681723
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:48:36.120334 UTC | [2020_01_14_06_24_08] Iteration #128 | Epoch Duration: 169.3661015033722
2020-01-14 11:48:36.120661 UTC | [2020_01_14_06_24_08] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014319276
Z variance train             0.035196144
KL Divergence                5.975259
KL Loss                      0.5975259
QF Loss                      983.9394
VF Loss                      652.87024
Policy Loss                  -1683.3638
Q Predictions Mean           1681.6254
Q Predictions Std            1027.1006
Q Predictions Max            2531.5037
Q Predictions Min            19.042086
V Predictions Mean           1695.6655
V Predictions Std            1028.8206
V Predictions Max            2544.0332
V Predictions Min            27.639477
Log Pis Mean                 -4.527891
Log Pis Std                  6.010764
Log Pis Max                  22.85358
Log Pis Min                  -17.980366
Policy mu Mean               0.07804983
Policy mu Std                0.745285
Policy mu Max                3.493921
Policy mu Min                -2.6461914
Policy log std Mean          -0.30663538
Policy log std Std           0.15077877
Policy log std Max           -0.031676628
Policy log std Min           -1.0497301
Z mean eval                  0.016258787
Z variance eval              0.034013104
total_rewards                [5033.20447828 3098.68859731 4942.27280271  825.62769772 4981.01616033
  567.57082556 5043.1803681  3771.16315716 4937.87474481 4969.9787084 ]
total_rewards_mean           3817.057754038171
total_rewards_std            1679.7242241003903
total_rewards_max            5043.180368101388
total_rewards_min            567.5708255629141
Number of train steps total  520000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               120.97198417037725
(Previous) Eval Time (s)     29.60260779596865
Sample Time (s)              19.797211330849677
Epoch Time (s)               170.37180329719558
Total Train Time (s)         19629.992278032936
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:51:19.340731 UTC | [2020_01_14_06_24_08] Iteration #129 | Epoch Duration: 163.21984839439392
2020-01-14 11:51:19.341090 UTC | [2020_01_14_06_24_08] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016280904
Z variance train             0.03400812
KL Divergence                6.056834
KL Loss                      0.60568345
QF Loss                      1208.0575
VF Loss                      238.14816
Policy Loss                  -1623.9849
Q Predictions Mean           1615.3262
Q Predictions Std            1039.9149
Q Predictions Max            2531.9058
Q Predictions Min            16.18405
V Predictions Mean           1619.7521
V Predictions Std            1038.3074
V Predictions Max            2527.7847
V Predictions Min            13.19714
Log Pis Mean                 -4.6348925
Log Pis Std                  6.6896725
Log Pis Max                  24.37997
Log Pis Min                  -13.508208
Policy mu Mean               0.055351827
Policy mu Std                0.74205273
Policy mu Max                2.9176931
Policy mu Min                -2.9571497
Policy log std Mean          -0.2990238
Policy log std Std           0.14917397
Policy log std Max           -0.016481526
Policy log std Min           -1.1330785
Z mean eval                  0.016535908
Z variance eval              0.033272512
total_rewards                [5079.75664015 5033.11758343 2008.69571201 5082.4567665  5079.93668806
 4998.29494099 5047.6294185  4964.00143588 5084.13708284 5055.22364573]
total_rewards_mean           4743.324991410461
total_rewards_std            912.327994558507
total_rewards_max            5084.137082843802
total_rewards_min            2008.695712006834
Number of train steps total  524000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               120.37253239005804
(Previous) Eval Time (s)     22.450337778776884
Sample Time (s)              19.595542706083506
Epoch Time (s)               162.41841287491843
Total Train Time (s)         19797.802614988293
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:54:07.154753 UTC | [2020_01_14_06_24_08] Iteration #130 | Epoch Duration: 167.81331539154053
2020-01-14 11:54:07.155181 UTC | [2020_01_14_06_24_08] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016600732
Z variance train             0.03326748
KL Divergence                6.1146736
KL Loss                      0.61146736
QF Loss                      1435.2654
VF Loss                      711.561
Policy Loss                  -1639.0669
Q Predictions Mean           1632.6086
Q Predictions Std            1034.4596
Q Predictions Max            2524.1367
Q Predictions Min            18.3734
V Predictions Mean           1626.9215
V Predictions Std            1026.7358
V Predictions Max            2514.5479
V Predictions Min            27.78528
Log Pis Mean                 -3.9861722
Log Pis Std                  7.3927197
Log Pis Max                  27.14629
Log Pis Min                  -15.549053
Policy mu Mean               0.05417943
Policy mu Std                0.770377
Policy mu Max                2.9211485
Policy mu Min                -3.2704298
Policy log std Mean          -0.31698158
Policy log std Std           0.16322002
Policy log std Max           -0.071537375
Policy log std Min           -1.2750543
Z mean eval                  0.018182931
Z variance eval              0.033824302
total_rewards                [5105.7561788  5077.04173613 5064.13364855 5066.15622923 5041.52821533
 5167.42051902 5125.08596036 5128.17765622 5096.21860289 5068.23193283]
total_rewards_mean           5093.975067936119
total_rewards_std            36.111333617633605
total_rewards_max            5167.4205190175835
total_rewards_min            5041.528215328623
Number of train steps total  528000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               119.85587351024151
(Previous) Eval Time (s)     27.844910006970167
Sample Time (s)              20.354665535967797
Epoch Time (s)               168.05544905317947
Total Train Time (s)         19967.7626063372
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:56:57.117550 UTC | [2020_01_14_06_24_08] Iteration #131 | Epoch Duration: 169.96211433410645
2020-01-14 11:56:57.117844 UTC | [2020_01_14_06_24_08] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017940845
Z variance train             0.033824056
KL Divergence                6.0706725
KL Loss                      0.6070673
QF Loss                      981.9632
VF Loss                      630.3481
Policy Loss                  -1616.5546
Q Predictions Mean           1609.6302
Q Predictions Std            1074.6188
Q Predictions Max            2537.362
Q Predictions Min            17.53775
V Predictions Mean           1619.645
V Predictions Std            1068.3406
V Predictions Max            2540.104
V Predictions Min            32.73949
Log Pis Mean                 -4.840697
Log Pis Std                  6.8069983
Log Pis Max                  31.571812
Log Pis Min                  -14.708336
Policy mu Mean               0.07701725
Policy mu Std                0.72609276
Policy mu Max                2.922993
Policy mu Min                -4.055505
Policy log std Mean          -0.29713464
Policy log std Std           0.15112391
Policy log std Max           0.007632166
Policy log std Min           -0.9156929
Z mean eval                  0.01780836
Z variance eval              0.033625312
total_rewards                [3822.69961329 5110.73693558 5089.53585576 4334.8474262  5135.41617433
 5114.0784274  5066.06901052 5110.91225142 5122.92571472 5103.59654323]
total_rewards_mean           4901.081795243801
total_rewards_std            427.17167715997124
total_rewards_max            5135.416174327104
total_rewards_min            3822.699613288389
Number of train steps total  532000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               121.95152115216479
(Previous) Eval Time (s)     29.751294089946896
Sample Time (s)              20.15382401412353
Epoch Time (s)               171.8566392562352
Total Train Time (s)         20138.786574149504
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:59:48.144889 UTC | [2020_01_14_06_24_08] Iteration #132 | Epoch Duration: 171.02681398391724
2020-01-14 11:59:48.145199 UTC | [2020_01_14_06_24_08] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01776609
Z variance train             0.033623103
KL Divergence                6.0888877
KL Loss                      0.6088888
QF Loss                      1141.9083
VF Loss                      434.9701
Policy Loss                  -1576.5795
Q Predictions Mean           1571.77
Q Predictions Std            1060.9407
Q Predictions Max            2542.311
Q Predictions Min            18.48963
V Predictions Mean           1575.9564
V Predictions Std            1054.6675
V Predictions Max            2540.069
V Predictions Min            31.348328
Log Pis Mean                 -4.416169
Log Pis Std                  7.12456
Log Pis Max                  24.03835
Log Pis Min                  -14.173151
Policy mu Mean               0.071741484
Policy mu Std                0.776327
Policy mu Max                3.2570193
Policy mu Min                -3.054019
Policy log std Mean          -0.3127559
Policy log std Std           0.1620149
Policy log std Max           -0.029382274
Policy log std Min           -1.0828489
Z mean eval                  0.018866325
Z variance eval              0.033956677
total_rewards                [4947.83484447 5041.82429844 4971.42481595 5041.40905073 4983.63401039
 5097.76907607 5051.93980467 2608.00639113 5045.96487207 5023.79336686]
total_rewards_mean           4781.360053077279
total_rewards_std            725.6586085691466
total_rewards_max            5097.76907606769
total_rewards_min            2608.006391133001
Number of train steps total  536000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               116.96860841335729
(Previous) Eval Time (s)     28.9211725150235
Sample Time (s)              20.31043804762885
Epoch Time (s)               166.20021897600964
Total Train Time (s)         20304.32541280985
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:02:33.686083 UTC | [2020_01_14_06_24_08] Iteration #133 | Epoch Duration: 165.54066252708435
2020-01-14 12:02:33.686341 UTC | [2020_01_14_06_24_08] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018898461
Z variance train             0.03395436
KL Divergence                6.0479755
KL Loss                      0.60479754
QF Loss                      997.82043
VF Loss                      366.78116
Policy Loss                  -1700.5364
Q Predictions Mean           1692.1823
Q Predictions Std            1030.4883
Q Predictions Max            2563.4675
Q Predictions Min            20.366285
V Predictions Mean           1695.4224
V Predictions Std            1024.1025
V Predictions Max            2553.6675
V Predictions Min            30.704493
Log Pis Mean                 -4.274246
Log Pis Std                  6.674901
Log Pis Max                  27.786127
Log Pis Min                  -13.664024
Policy mu Mean               0.07570214
Policy mu Std                0.7582702
Policy mu Max                3.328822
Policy mu Min                -3.0916705
Policy log std Mean          -0.30178
Policy log std Std           0.1474536
Policy log std Max           0.13326168
Policy log std Min           -1.0715129
Z mean eval                  0.020996481
Z variance eval              0.032641318
total_rewards                [5090.45835004 5127.22524203 5147.58690058 2078.67285792 5023.78488908
 5027.85166938 4999.07163662 4922.26582158 5048.83974725 2044.98592605]
total_rewards_mean           4451.074304054063
total_rewards_std            1196.2017949239982
total_rewards_max            5147.586900583458
total_rewards_min            2044.9859260512164
Number of train steps total  540000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               120.46194417402148
(Previous) Eval Time (s)     28.261319737881422
Sample Time (s)              20.11461797216907
Epoch Time (s)               168.83788188407198
Total Train Time (s)         20472.274824203458
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:05:21.636633 UTC | [2020_01_14_06_24_08] Iteration #134 | Epoch Duration: 167.95003414154053
2020-01-14 12:05:21.636893 UTC | [2020_01_14_06_24_08] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020846395
Z variance train             0.032636203
KL Divergence                6.143216
KL Loss                      0.61432165
QF Loss                      933.28186
VF Loss                      500.8904
Policy Loss                  -1648.2312
Q Predictions Mean           1644.3115
Q Predictions Std            1054.4099
Q Predictions Max            2550.1067
Q Predictions Min            19.147442
V Predictions Mean           1657.8301
V Predictions Std            1057.9346
V Predictions Max            2568.0325
V Predictions Min            26.370241
Log Pis Mean                 -3.9878378
Log Pis Std                  6.9434257
Log Pis Max                  27.05671
Log Pis Min                  -15.065574
Policy mu Mean               0.07316832
Policy mu Std                0.775311
Policy mu Max                3.5357523
Policy mu Min                -3.2028325
Policy log std Mean          -0.31501457
Policy log std Std           0.16177022
Policy log std Max           -0.014606141
Policy log std Min           -1.39908
Z mean eval                  0.018993232
Z variance eval              0.032283876
total_rewards                [5083.79973551 4970.00911    5022.13301078 5026.6981848  5104.01180645
 5155.9748654  5140.97303203 5064.31840819 5044.00152059 5069.00062766]
total_rewards_mean           5068.092030141414
total_rewards_std            53.49145263284262
total_rewards_max            5155.974865404632
total_rewards_min            4970.009109998996
Number of train steps total  544000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               122.46554662287235
(Previous) Eval Time (s)     27.373178894165903
Sample Time (s)              20.353605683892965
Epoch Time (s)               170.19233120093122
Total Train Time (s)         20645.31092776172
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:08:14.676276 UTC | [2020_01_14_06_24_08] Iteration #135 | Epoch Duration: 173.03921341896057
2020-01-14 12:08:14.676548 UTC | [2020_01_14_06_24_08] Iteration #135 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018911922
Z variance train             0.03229127
KL Divergence                6.1677904
KL Loss                      0.616779
QF Loss                      1387.508
VF Loss                      518.49207
Policy Loss                  -1717.1191
Q Predictions Mean           1715.7975
Q Predictions Std            1020.071
Q Predictions Max            2566.6091
Q Predictions Min            15.700962
V Predictions Mean           1719.6985
V Predictions Std            1018.6456
V Predictions Max            2573.6606
V Predictions Min            25.051977
Log Pis Mean                 -4.1588144
Log Pis Std                  6.9023705
Log Pis Max                  19.580873
Log Pis Min                  -13.620285
Policy mu Mean               0.08701584
Policy mu Std                0.7771367
Policy mu Max                3.6111386
Policy mu Min                -4.9420977
Policy log std Mean          -0.31790483
Policy log std Std           0.15877202
Policy log std Max           -0.03807424
Policy log std Min           -1.1628631
Z mean eval                  0.018168459
Z variance eval              0.032181315
total_rewards                [4881.11528782 3479.82197736 3711.33077051 4865.01138748 2968.8652619
 4971.72069637 4787.69916389  405.16365508 2760.09156434 4913.04430771]
total_rewards_mean           3774.3864072457086
total_rewards_std            1388.9323285875314
total_rewards_max            4971.720696374796
total_rewards_min            405.16365507679166
Number of train steps total  548000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               120.64928741985932
(Previous) Eval Time (s)     30.219716017134488
Sample Time (s)              19.635668796952814
Epoch Time (s)               170.50467223394662
Total Train Time (s)         20808.649263338186
Epoch                        136
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:10:58.015090 UTC | [2020_01_14_06_24_08] Iteration #136 | Epoch Duration: 163.33835625648499
2020-01-14 12:10:58.015240 UTC | [2020_01_14_06_24_08] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018182572
Z variance train             0.03218039
KL Divergence                6.1770506
KL Loss                      0.61770505
QF Loss                      1327.8723
VF Loss                      338.06906
Policy Loss                  -1722.1222
Q Predictions Mean           1719.7294
Q Predictions Std            1030.4612
Q Predictions Max            2565.322
Q Predictions Min            18.705868
V Predictions Mean           1722.1882
V Predictions Std            1025.4409
V Predictions Max            2570.9133
V Predictions Min            27.784887
Log Pis Mean                 -4.582301
Log Pis Std                  6.3845334
Log Pis Max                  29.999908
Log Pis Min                  -12.836266
Policy mu Mean               0.090007596
Policy mu Std                0.7598466
Policy mu Max                3.0172534
Policy mu Min                -2.946677
Policy log std Mean          -0.29791552
Policy log std Std           0.14687864
Policy log std Max           0.13124974
Policy log std Min           -1.002263
Z mean eval                  0.01643012
Z variance eval              0.030853052
total_rewards                [1009.30602949 5036.26434636 5078.32047406 5073.99883943 4974.87866952
 5113.62601401 1671.8624543  5064.11889876 5136.78783506 5067.42348022]
total_rewards_mean           4322.658704121797
total_rewards_std            1498.934976209718
total_rewards_max            5136.787835057625
total_rewards_min            1009.3060294852214
Number of train steps total  552000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               119.78259048704058
(Previous) Eval Time (s)     23.05308332806453
Sample Time (s)              20.013051336165518
Epoch Time (s)               162.84872515127063
Total Train Time (s)         20974.835513958707
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:13:44.209025 UTC | [2020_01_14_06_24_08] Iteration #137 | Epoch Duration: 166.1936433315277
2020-01-14 12:13:44.209314 UTC | [2020_01_14_06_24_08] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01620332
Z variance train             0.030854687
KL Divergence                6.2778935
KL Loss                      0.6277894
QF Loss                      1064.9254
VF Loss                      576.1527
Policy Loss                  -1889.2075
Q Predictions Mean           1885.78
Q Predictions Std            982.8051
Q Predictions Max            2575.458
Q Predictions Min            16.071947
V Predictions Mean           1901.2467
V Predictions Std            982.1942
V Predictions Max            2594.059
V Predictions Min            25.206017
Log Pis Mean                 -4.3963633
Log Pis Std                  6.538497
Log Pis Max                  17.014042
Log Pis Min                  -16.350998
Policy mu Mean               0.098618634
Policy mu Std                0.75534934
Policy mu Max                3.1117651
Policy mu Min                -2.5779135
Policy log std Mean          -0.32223046
Policy log std Std           0.14265418
Policy log std Max           -0.030269027
Policy log std Min           -0.8915974
Z mean eval                  0.01816167
Z variance eval              0.032650124
total_rewards                [4929.75993345 5055.86778093 5039.33885124 5067.91026878 5041.17793493
 5100.86806136 5079.42948301 5072.49151022 5026.77332477 5069.81717475]
total_rewards_mean           5048.343432342361
total_rewards_std            44.574263843543264
total_rewards_max            5100.868061356382
total_rewards_min            4929.75993344607
Number of train steps total  556000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               121.76476015103981
(Previous) Eval Time (s)     26.39767094887793
Sample Time (s)              19.673286178149283
Epoch Time (s)               167.83571727806702
Total Train Time (s)         21145.9175125272
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:16:35.295182 UTC | [2020_01_14_06_24_08] Iteration #138 | Epoch Duration: 171.0856430530548
2020-01-14 12:16:35.295477 UTC | [2020_01_14_06_24_08] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018097822
Z variance train             0.032650046
KL Divergence                6.1455574
KL Loss                      0.6145558
QF Loss                      1328.3008
VF Loss                      593.17584
Policy Loss                  -1809.6825
Q Predictions Mean           1808.3671
Q Predictions Std            1001.63416
Q Predictions Max            2581.9392
Q Predictions Min            16.203472
V Predictions Mean           1817.0269
V Predictions Std            1000.1623
V Predictions Max            2582.9624
V Predictions Min            23.049309
Log Pis Mean                 -3.332246
Log Pis Std                  8.181093
Log Pis Max                  36.815674
Log Pis Min                  -13.681255
Policy mu Mean               0.09246175
Policy mu Std                0.8311283
Policy mu Max                3.5170703
Policy mu Min                -3.2924638
Policy log std Mean          -0.32719982
Policy log std Std           0.16305642
Policy log std Max           0.0072256476
Policy log std Min           -1.4407274
Z mean eval                  0.017985418
Z variance eval              0.03355162
total_rewards                [5140.87566324 5149.80144312 5148.71314584 5070.53732371 5164.29609856
 5128.45487524 5172.91297048 5127.65283323 5137.2175904  5171.92606283]
total_rewards_mean           5141.238800666042
total_rewards_std            28.229050400987276
total_rewards_max            5172.912970482643
total_rewards_min            5070.537323707059
Number of train steps total  560000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               119.01609851699322
(Previous) Eval Time (s)     29.647334559820592
Sample Time (s)              19.466287618037313
Epoch Time (s)               168.12972069485113
Total Train Time (s)         21314.211920444854
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:19:23.591391 UTC | [2020_01_14_06_24_08] Iteration #139 | Epoch Duration: 168.29568362236023
2020-01-14 12:19:23.591670 UTC | [2020_01_14_06_24_08] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017914345
Z variance train             0.033550173
KL Divergence                6.0949965
KL Loss                      0.60949963
QF Loss                      1048.4508
VF Loss                      609.2781
Policy Loss                  -1796.1685
Q Predictions Mean           1790.9048
Q Predictions Std            1020.2116
Q Predictions Max            2573.7466
Q Predictions Min            18.647175
V Predictions Mean           1800.21
V Predictions Std            1015.8034
V Predictions Max            2584.478
V Predictions Min            26.807468
Log Pis Mean                 -4.254072
Log Pis Std                  5.6706877
Log Pis Max                  15.601795
Log Pis Min                  -13.655594
Policy mu Mean               0.08748997
Policy mu Std                0.76851577
Policy mu Max                2.7654126
Policy mu Min                -2.910613
Policy log std Mean          -0.30352312
Policy log std Std           0.15160076
Policy log std Max           0.02041699
Policy log std Min           -1.0781842
Z mean eval                  0.02076688
Z variance eval              0.03233671
total_rewards                [5163.62986721 5190.65246934 5058.5458253  4717.9462433  5126.19984669
 5171.23274303 5065.72759039 5123.12483768 5094.81635201 5095.98164729]
total_rewards_mean           5080.785742223905
total_rewards_std            127.97311591879573
total_rewards_max            5190.652469341609
total_rewards_min            4717.946243299038
Number of train steps total  564000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               120.13652046211064
(Previous) Eval Time (s)     29.81304109003395
Sample Time (s)              20.084755655843765
Epoch Time (s)               170.03431720798835
Total Train Time (s)         21483.930927725974
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:22:13.312900 UTC | [2020_01_14_06_24_08] Iteration #140 | Epoch Duration: 169.7210087776184
2020-01-14 12:22:13.313120 UTC | [2020_01_14_06_24_08] Iteration #140 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020900493
Z variance train             0.03233469
KL Divergence                6.1795855
KL Loss                      0.61795855
QF Loss                      870.4265
VF Loss                      315.56543
Policy Loss                  -1694.1035
Q Predictions Mean           1690.6263
Q Predictions Std            1071.4542
Q Predictions Max            2578.8342
Q Predictions Min            15.226652
V Predictions Mean           1690.4155
V Predictions Std            1063.4353
V Predictions Max            2575.0735
V Predictions Min            31.245575
Log Pis Mean                 -4.8939037
Log Pis Std                  6.989476
Log Pis Max                  23.755447
Log Pis Min                  -13.321812
Policy mu Mean               0.09555596
Policy mu Std                0.7411657
Policy mu Max                2.8930743
Policy mu Min                -3.3995442
Policy log std Mean          -0.3045902
Policy log std Std           0.15465842
Policy log std Max           0.14124423
Policy log std Min           -1.019113
Z mean eval                  0.02074347
Z variance eval              0.033089608
total_rewards                [5163.34220108 5087.37217112 5100.96270762 5103.12485011 5103.082852
 3193.31663779 5101.01219838 5129.89183004 1950.8499025  5156.50507427]
total_rewards_mean           4608.946042490488
total_rewards_std            1055.9132137581814
total_rewards_max            5163.342201076604
total_rewards_min            1950.8499024994926
Number of train steps total  568000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               124.04073058906943
(Previous) Eval Time (s)     29.499473673757166
Sample Time (s)              19.73853196343407
Epoch Time (s)               173.27873622626066
Total Train Time (s)         21654.143894618377
Epoch                        141
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:25:03.526462 UTC | [2020_01_14_06_24_08] Iteration #141 | Epoch Duration: 170.2131543159485
2020-01-14 12:25:03.526666 UTC | [2020_01_14_06_24_08] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020693034
Z variance train             0.033088468
KL Divergence                6.133192
KL Loss                      0.6133192
QF Loss                      1140.5353
VF Loss                      482.1471
Policy Loss                  -1750.2886
Q Predictions Mean           1744.2268
Q Predictions Std            1055.922
Q Predictions Max            2593.5403
Q Predictions Min            16.475409
V Predictions Mean           1759.8086
V Predictions Std            1054.539
V Predictions Max            2607.849
V Predictions Min            28.060854
Log Pis Mean                 -4.647777
Log Pis Std                  7.46676
Log Pis Max                  40.65214
Log Pis Min                  -14.270253
Policy mu Mean               0.066737235
Policy mu Std                0.77549154
Policy mu Max                3.327207
Policy mu Min                -3.393551
Policy log std Mean          -0.30919513
Policy log std Std           0.15661012
Policy log std Max           0.035281688
Policy log std Min           -1.432807
Z mean eval                  0.021056099
Z variance eval              0.031850737
total_rewards                [5057.14699465 5083.57398633 5111.12525803 5005.15306634 5109.62595154
 3228.52642293 5078.28546988 5113.0008061  4965.25852139 5052.45082254]
total_rewards_mean           4880.414729972652
total_rewards_std            552.504455981688
total_rewards_max            5113.0008061009885
total_rewards_min            3228.5264229257186
Number of train steps total  572000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               124.57444778410718
(Previous) Eval Time (s)     26.433613006956875
Sample Time (s)              19.847360686864704
Epoch Time (s)               170.85542147792876
Total Train Time (s)         21827.273120773956
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:27:56.660016 UTC | [2020_01_14_06_24_08] Iteration #142 | Epoch Duration: 173.13316369056702
2020-01-14 12:27:56.660323 UTC | [2020_01_14_06_24_08] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021022128
Z variance train             0.03185036
KL Divergence                6.2294655
KL Loss                      0.62294656
QF Loss                      1067.8588
VF Loss                      390.83606
Policy Loss                  -1783.916
Q Predictions Mean           1776.1719
Q Predictions Std            1029.693
Q Predictions Max            2592.897
Q Predictions Min            15.9537525
V Predictions Mean           1787.0898
V Predictions Std            1027.9774
V Predictions Max            2599.293
V Predictions Min            26.753239
Log Pis Mean                 -4.8281765
Log Pis Std                  6.351088
Log Pis Max                  20.002296
Log Pis Min                  -17.407684
Policy mu Mean               0.064198494
Policy mu Std                0.75870293
Policy mu Max                2.8056881
Policy mu Min                -3.2161872
Policy log std Mean          -0.3181319
Policy log std Std           0.15758152
Policy log std Max           -0.0135905
Policy log std Min           -1.010892
Z mean eval                  0.01825059
Z variance eval              0.032180198
total_rewards                [2263.28064635 5038.32448925 4955.47523455 5012.2096349  5040.52994601
 5077.15487954 4937.22872049 4973.55752624 4945.83496015 1865.23171301]
total_rewards_mean           4410.882775050504
total_rewards_std            1177.4796441656126
total_rewards_max            5077.154879542841
total_rewards_min            1865.2317130148128
Number of train steps total  576000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               118.57709864899516
(Previous) Eval Time (s)     28.711055065970868
Sample Time (s)              19.979917616117746
Epoch Time (s)               167.26807133108377
Total Train Time (s)         21992.8624328929
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:30:42.252587 UTC | [2020_01_14_06_24_08] Iteration #143 | Epoch Duration: 165.592036485672
2020-01-14 12:30:42.252866 UTC | [2020_01_14_06_24_08] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018373113
Z variance train             0.032185502
KL Divergence                6.196721
KL Loss                      0.6196721
QF Loss                      1500.9424
VF Loss                      687.325
Policy Loss                  -1899.3926
Q Predictions Mean           1891.3053
Q Predictions Std            980.38245
Q Predictions Max            2599.1125
Q Predictions Min            16.057547
V Predictions Mean           1891.6768
V Predictions Std            971.7346
V Predictions Max            2591.7188
V Predictions Min            32.063248
Log Pis Mean                 -3.9895985
Log Pis Std                  6.858092
Log Pis Max                  30.926954
Log Pis Min                  -14.229944
Policy mu Mean               0.0797513
Policy mu Std                0.79158705
Policy mu Max                2.762283
Policy mu Min                -3.3526516
Policy log std Mean          -0.31985003
Policy log std Std           0.15088296
Policy log std Max           0.060325056
Policy log std Min           -1.2077947
Z mean eval                  0.018669821
Z variance eval              0.031846844
total_rewards                [5123.6691271  5062.83146688 4893.18884242 2330.89259935 5076.65476924
 5093.02465115 5012.68327178 4962.46333146 4396.07502888 5050.43967114]
total_rewards_mean           4700.192275941203
total_rewards_std            814.8194284099293
total_rewards_max            5123.669127102774
total_rewards_min            2330.892599354992
Number of train steps total  580000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               121.5342596648261
(Previous) Eval Time (s)     27.034720827825367
Sample Time (s)              19.976975452154875
Epoch Time (s)               168.54595594480634
Total Train Time (s)         22162.03410923388
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:33:31.428182 UTC | [2020_01_14_06_24_08] Iteration #144 | Epoch Duration: 169.17508721351624
2020-01-14 12:33:31.428505 UTC | [2020_01_14_06_24_08] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01904181
Z variance train             0.031849056
KL Divergence                6.20469
KL Loss                      0.62046903
QF Loss                      1146.1614
VF Loss                      627.262
Policy Loss                  -1919.4543
Q Predictions Mean           1911.0337
Q Predictions Std            979.01996
Q Predictions Max            2607.3384
Q Predictions Min            18.907482
V Predictions Mean           1904.657
V Predictions Std            969.2217
V Predictions Max            2595.3047
V Predictions Min            28.785488
Log Pis Mean                 -4.569133
Log Pis Std                  6.036404
Log Pis Max                  22.97359
Log Pis Min                  -18.867914
Policy mu Mean               0.06258327
Policy mu Std                0.75939
Policy mu Max                2.998291
Policy mu Min                -2.667666
Policy log std Mean          -0.30341408
Policy log std Std           0.14884898
Policy log std Max           0.016696692
Policy log std Min           -1.1602027
Z mean eval                  0.021667844
Z variance eval              0.03156071
total_rewards                [5097.27424906 4951.19134693 5079.51140196 5003.16503298 2326.83792361
 2491.07469002 5106.97675562 5015.29683798 5051.15062104 5008.28937718]
total_rewards_mean           4513.076823638226
total_rewards_std            1053.6650162558833
total_rewards_max            5106.976755624395
total_rewards_min            2326.8379236123146
Number of train steps total  584000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               120.81652645161375
(Previous) Eval Time (s)     27.663575268816203
Sample Time (s)              19.74839246738702
Epoch Time (s)               168.22849418781698
Total Train Time (s)         22328.576503327582
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:36:17.976585 UTC | [2020_01_14_06_24_08] Iteration #145 | Epoch Duration: 166.54784536361694
2020-01-14 12:36:17.976876 UTC | [2020_01_14_06_24_08] Iteration #145 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021461
Z variance train             0.031563204
KL Divergence                6.227487
KL Loss                      0.62274873
QF Loss                      1306.8066
VF Loss                      343.15234
Policy Loss                  -1751.0472
Q Predictions Mean           1742.9724
Q Predictions Std            1058.0901
Q Predictions Max            2612.6797
Q Predictions Min            17.865389
V Predictions Mean           1753.3339
V Predictions Std            1060.7074
V Predictions Max            2616.7063
V Predictions Min            18.038355
Log Pis Mean                 -4.688224
Log Pis Std                  6.2395244
Log Pis Max                  23.860725
Log Pis Min                  -15.613501
Policy mu Mean               0.0912419
Policy mu Std                0.74601454
Policy mu Max                2.831085
Policy mu Min                -3.5953722
Policy log std Mean          -0.3105252
Policy log std Std           0.15469155
Policy log std Max           0.011435911
Policy log std Min           -1.103969
Z mean eval                  0.01788969
Z variance eval              0.031550672
total_rewards                [5155.64080085 5179.55721744 1665.55513777 5215.51255504 5179.1745152
 5169.22814833 5092.92416713 5167.34311209 5151.69322156 5173.92505221]
total_rewards_mean           4815.055392763697
total_rewards_std            1050.2394500642968
total_rewards_max            5215.512555044434
total_rewards_min            1665.5551377741285
Number of train steps total  588000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               124.22306497162208
(Previous) Eval Time (s)     25.982632759027183
Sample Time (s)              19.544346525799483
Epoch Time (s)               169.75004425644875
Total Train Time (s)         22501.179405450355
Epoch                        146
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:39:10.581604 UTC | [2020_01_14_06_24_08] Iteration #146 | Epoch Duration: 172.60451698303223
2020-01-14 12:39:10.581843 UTC | [2020_01_14_06_24_08] Iteration #146 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01806156
Z variance train             0.031553723
KL Divergence                6.2299566
KL Loss                      0.6229957
QF Loss                      954.1712
VF Loss                      484.30176
Policy Loss                  -1860.5994
Q Predictions Mean           1856.1726
Q Predictions Std            1006.1033
Q Predictions Max            2615.0159
Q Predictions Min            18.766562
V Predictions Mean           1858.0219
V Predictions Std            999.5361
V Predictions Max            2605.7336
V Predictions Min            26.92332
Log Pis Mean                 -3.7686095
Log Pis Std                  6.922933
Log Pis Max                  29.602497
Log Pis Min                  -13.218341
Policy mu Mean               0.041435543
Policy mu Std                0.7852784
Policy mu Max                2.9804263
Policy mu Min                -3.0211337
Policy log std Mean          -0.31201547
Policy log std Std           0.14591245
Policy log std Max           -0.04836224
Policy log std Min           -1.3546202
Z mean eval                  0.018891685
Z variance eval              0.03122946
total_rewards                [4542.63332652 5169.13670478 5053.3553859  5087.8483342  3372.9757055
 5154.90596977 2479.33744829 5120.85229461 2904.51938845 3413.04999324]
total_rewards_mean           4229.861455125225
total_rewards_std            1013.2235711500092
total_rewards_max            5169.136704777013
total_rewards_min            2479.337448287619
Number of train steps total  592000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               123.03421133384109
(Previous) Eval Time (s)     28.836800071876496
Sample Time (s)              20.518981776200235
Epoch Time (s)               172.38999318191782
Total Train Time (s)         22668.72650516499
Epoch                        147
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:41:58.130610 UTC | [2020_01_14_06_24_08] Iteration #147 | Epoch Duration: 167.54854273796082
2020-01-14 12:41:58.130875 UTC | [2020_01_14_06_24_08] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019053772
Z variance train             0.031227225
KL Divergence                6.260812
KL Loss                      0.62608117
QF Loss                      1054.7246
VF Loss                      570.3571
Policy Loss                  -1708.0469
Q Predictions Mean           1700.1886
Q Predictions Std            1096.6436
Q Predictions Max            2604.6936
Q Predictions Min            18.155174
V Predictions Mean           1707.178
V Predictions Std            1092.6409
V Predictions Max            2609.0059
V Predictions Min            27.304522
Log Pis Mean                 -4.8579187
Log Pis Std                  7.1187716
Log Pis Max                  28.040314
Log Pis Min                  -14.046062
Policy mu Mean               0.07596487
Policy mu Std                0.7339354
Policy mu Max                3.4903529
Policy mu Min                -3.5225348
Policy log std Mean          -0.3038674
Policy log std Std           0.1567549
Policy log std Max           -0.0057106316
Policy log std Min           -1.105281
Z mean eval                  0.018572602
Z variance eval              0.032093346
total_rewards                [5127.15888276 5092.69265578 5123.27498997 5164.15012143 5131.46165732
 5129.42073791 5095.59206013 1509.54838144 5121.61032827 5061.46101651]
total_rewards_mean           4755.637083151456
total_rewards_std            1082.3474354759064
total_rewards_max            5164.150121429984
total_rewards_min            1509.548381440492
Number of train steps total  596000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               121.14528423594311
(Previous) Eval Time (s)     23.995036469772458
Sample Time (s)              19.294526672922075
Epoch Time (s)               164.43484737863764
Total Train Time (s)         22836.24748487817
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:44:45.653004 UTC | [2020_01_14_06_24_08] Iteration #148 | Epoch Duration: 167.52197885513306
2020-01-14 12:44:45.653174 UTC | [2020_01_14_06_24_08] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018360589
Z variance train             0.032095253
KL Divergence                6.2032537
KL Loss                      0.6203254
QF Loss                      2238.5486
VF Loss                      390.58774
Policy Loss                  -1787.7031
Q Predictions Mean           1789.3198
Q Predictions Std            1052.7758
Q Predictions Max            2628.915
Q Predictions Min            12.896066
V Predictions Mean           1797.9167
V Predictions Std            1051.9083
V Predictions Max            2630.2473
V Predictions Min            20.516829
Log Pis Mean                 -4.1374693
Log Pis Std                  6.1962132
Log Pis Max                  20.280264
Log Pis Min                  -12.520196
Policy mu Mean               0.055525057
Policy mu Std                0.7473031
Policy mu Max                3.0914612
Policy mu Min                -3.5541794
Policy log std Mean          -0.31325454
Policy log std Std           0.15269962
Policy log std Max           0.09148307
Policy log std Min           -1.1586189
Z mean eval                  0.017779296
Z variance eval              0.03177225
total_rewards                [5144.8922744  1508.68202125 5145.34259697 2783.60626528 5173.17085335
 5131.33689134 5139.9647687  5175.68599315 2681.30546466 5182.30915902]
total_rewards_mean           4306.629628811473
total_rewards_std            1335.7945256335283
total_rewards_max            5182.309159017517
total_rewards_min            1508.6820212515552
Number of train steps total  600000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               118.20892417896539
(Previous) Eval Time (s)     27.08189390413463
Sample Time (s)              19.773974813055247
Epoch Time (s)               165.06479289615527
Total Train Time (s)         22999.03304468002
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:47:28.440755 UTC | [2020_01_14_06_24_08] Iteration #149 | Epoch Duration: 162.78744626045227
2020-01-14 12:47:28.440967 UTC | [2020_01_14_06_24_08] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017766874
Z variance train             0.031768985
KL Divergence                6.2173147
KL Loss                      0.62173146
QF Loss                      1080.3914
VF Loss                      281.57184
Policy Loss                  -1838.6833
Q Predictions Mean           1832.919
Q Predictions Std            1035.4696
Q Predictions Max            2631.6067
Q Predictions Min            23.165356
V Predictions Mean           1843.7618
V Predictions Std            1037.101
V Predictions Max            2625.1626
V Predictions Min            29.791245
Log Pis Mean                 -4.7825546
Log Pis Std                  6.589424
Log Pis Max                  24.722095
Log Pis Min                  -13.832125
Policy mu Mean               0.08933627
Policy mu Std                0.744154
Policy mu Max                3.6620574
Policy mu Min                -2.664277
Policy log std Mean          -0.31480166
Policy log std Std           0.1544526
Policy log std Max           -0.0015756786
Policy log std Min           -1.1344554
Z mean eval                  0.017373338
Z variance eval              0.031596802
total_rewards                [5127.27034653 3507.71796094 5131.53559521 2011.2031368  1870.21119219
 1695.45587782 1217.53699837 4748.09628422 5117.68987454 4142.94046093]
total_rewards_mean           3456.9657727573513
total_rewards_std            1523.7532313571771
total_rewards_max            5131.535595214051
total_rewards_min            1217.5369983741377
Number of train steps total  604000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               128.89052846003324
(Previous) Eval Time (s)     24.80426487326622
Sample Time (s)              19.88836225774139
Epoch Time (s)               173.58315559104085
Total Train Time (s)         23168.002951462287
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:50:17.413009 UTC | [2020_01_14_06_24_08] Iteration #150 | Epoch Duration: 168.97187972068787
2020-01-14 12:50:17.413215 UTC | [2020_01_14_06_24_08] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017305499
Z variance train             0.031596012
KL Divergence                6.2240524
KL Loss                      0.62240523
QF Loss                      1402.0471
VF Loss                      508.0018
Policy Loss                  -1710.4615
Q Predictions Mean           1701.3221
Q Predictions Std            1088.2168
Q Predictions Max            2619.7402
Q Predictions Min            16.580475
V Predictions Mean           1707.8833
V Predictions Std            1081.4805
V Predictions Max            2625.7524
V Predictions Min            32.767982
Log Pis Mean                 -5.0375357
Log Pis Std                  6.550081
Log Pis Max                  20.59915
Log Pis Min                  -16.511566
Policy mu Mean               0.058828607
Policy mu Std                0.7506328
Policy mu Max                3.5012605
Policy mu Min                -3.3582914
Policy log std Mean          -0.29552963
Policy log std Std           0.14893505
Policy log std Max           0.050222874
Policy log std Min           -1.1196791
Z mean eval                  0.015202743
Z variance eval              0.032186866
total_rewards                [5137.93033032 5154.08591737 5020.01454452 5032.74885555 5036.21202563
 5080.20860749 5075.43155099 5124.53081688 5050.23146476 5043.70812321]
total_rewards_mean           5075.510223671919
total_rewards_std            45.38562717052032
total_rewards_max            5154.08591736543
total_rewards_min            5020.014544515604
Number of train steps total  608000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               121.73780973581597
(Previous) Eval Time (s)     20.192687338218093
Sample Time (s)              19.327868805266917
Epoch Time (s)               161.25836587930098
Total Train Time (s)         23338.64038138371
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:53:08.055853 UTC | [2020_01_14_06_24_08] Iteration #151 | Epoch Duration: 170.64234447479248
2020-01-14 12:53:08.056253 UTC | [2020_01_14_06_24_08] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015166329
Z variance train             0.0321827
KL Divergence                6.1814346
KL Loss                      0.6181435
QF Loss                      1307.0851
VF Loss                      596.547
Policy Loss                  -1800.6361
Q Predictions Mean           1799.5334
Q Predictions Std            1062.2893
Q Predictions Max            2633.0327
Q Predictions Min            18.801517
V Predictions Mean           1802.0278
V Predictions Std            1059.823
V Predictions Max            2640.9216
V Predictions Min            27.83295
Log Pis Mean                 -4.940018
Log Pis Std                  6.637388
Log Pis Max                  30.233406
Log Pis Min                  -14.570584
Policy mu Mean               0.095139205
Policy mu Std                0.73309946
Policy mu Max                3.600804
Policy mu Min                -3.7361941
Policy log std Mean          -0.31010634
Policy log std Std           0.15637645
Policy log std Max           0.12717456
Policy log std Min           -1.2354895
Z mean eval                  0.017384643
Z variance eval              0.03190857
total_rewards                [5057.78058318 5079.95454921 5045.7050362  5055.91052428 5035.39775318
 5062.60620129 5131.90649408 5088.87736541 1721.79849807 1327.62341291]
total_rewards_mean           4360.756041780594
total_rewards_std            1420.9871151025707
total_rewards_max            5131.906494077968
total_rewards_min            1327.6234129114503
Number of train steps total  612000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               122.46667414996773
(Previous) Eval Time (s)     29.5763528351672
Sample Time (s)              20.30191157013178
Epoch Time (s)               172.3449385552667
Total Train Time (s)         23506.946752986405
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:55:56.364266 UTC | [2020_01_14_06_24_08] Iteration #152 | Epoch Duration: 168.30778169631958
2020-01-14 12:55:56.364525 UTC | [2020_01_14_06_24_08] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017564338
Z variance train             0.03190551
KL Divergence                6.21021
KL Loss                      0.621021
QF Loss                      1068.4736
VF Loss                      420.23294
Policy Loss                  -1825.075
Q Predictions Mean           1814.9916
Q Predictions Std            1050.0597
Q Predictions Max            2618.5962
Q Predictions Min            22.684517
V Predictions Mean           1820.2925
V Predictions Std            1046.5186
V Predictions Max            2622.057
V Predictions Min            7.671523
Log Pis Mean                 -4.4179387
Log Pis Std                  6.578839
Log Pis Max                  25.333725
Log Pis Min                  -17.40665
Policy mu Mean               0.060192313
Policy mu Std                0.75661623
Policy mu Max                4.112732
Policy mu Min                -3.352956
Policy log std Mean          -0.29971203
Policy log std Std           0.1482775
Policy log std Max           0.011518598
Policy log std Min           -1.0212548
Z mean eval                  0.01694087
Z variance eval              0.030775582
total_rewards                [5162.97744061 5132.57255021 5121.17391422 5148.98536206 5134.03980872
 5125.66626379 5077.72518365 5080.43240641 5068.64174299 5147.65696844]
total_rewards_mean           5119.987164111052
total_rewards_std            31.35476496603425
total_rewards_max            5162.977440606409
total_rewards_min            5068.6417429896765
Number of train steps total  616000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               127.96183990081772
(Previous) Eval Time (s)     25.538905472029
Sample Time (s)              19.974227324593812
Epoch Time (s)               173.47497269744053
Total Train Time (s)         23685.907707485836
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:58:55.327311 UTC | [2020_01_14_06_24_08] Iteration #153 | Epoch Duration: 178.96261596679688
2020-01-14 12:58:55.327491 UTC | [2020_01_14_06_24_08] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016967898
Z variance train             0.030773738
KL Divergence                6.3031282
KL Loss                      0.63031286
QF Loss                      1431.7263
VF Loss                      347.53387
Policy Loss                  -1940.7249
Q Predictions Mean           1940.2311
Q Predictions Std            981.0396
Q Predictions Max            2644.1477
Q Predictions Min            19.269938
V Predictions Mean           1943.1758
V Predictions Std            976.1481
V Predictions Max            2649.4006
V Predictions Min            30.885172
Log Pis Mean                 -4.1481547
Log Pis Std                  6.887841
Log Pis Max                  34.5141
Log Pis Min                  -12.983314
Policy mu Mean               0.1317875
Policy mu Std                0.76955986
Policy mu Max                3.0255735
Policy mu Min                -3.7681222
Policy log std Mean          -0.3204706
Policy log std Std           0.14857288
Policy log std Max           0.12727368
Policy log std Min           -1.1317347
Z mean eval                  0.018737579
Z variance eval              0.030566376
total_rewards                [5027.98915368 4987.628024   4930.68819376 5089.3628877  4979.14384304
 5084.01844153 4978.4859426  4997.36553199 5093.38266067 4934.29863588]
total_rewards_mean           5010.236331485319
total_rewards_std            58.03391191676174
total_rewards_max            5093.382660674463
total_rewards_min            4930.688193763316
Number of train steps total  620000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               120.176968078129
(Previous) Eval Time (s)     31.026257222052664
Sample Time (s)              20.144522320944816
Epoch Time (s)               171.34774762112647
Total Train Time (s)         23855.748884798493
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 13:01:45.173243 UTC | [2020_01_14_06_24_08] Iteration #154 | Epoch Duration: 169.84558987617493
2020-01-14 13:01:45.173506 UTC | [2020_01_14_06_24_08] Iteration #154 | Started Training: True
