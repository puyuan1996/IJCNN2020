---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020373582
Z variance train             0.69316137
KL Divergence                0.1491503
KL Loss                      0.0149150295
QF Loss                      41.844635
VF Loss                      4.1575303
Policy Loss                  -2.0067728
Q Predictions Mean           -0.002030336
Q Predictions Std            0.0010015042
Q Predictions Max            0.00088432594
Q Predictions Min            -0.0047235806
V Predictions Mean           0.0088374205
V Predictions Std            0.0010507002
V Predictions Max            0.011276517
V Predictions Min            0.00592901
Log Pis Mean                 -2.0010917
Log Pis Std                  0.40722224
Log Pis Max                  -0.89716256
Log Pis Min                  -2.734147
Policy mu Mean               -1.1658136e-05
Policy mu Std                0.0008658147
Policy mu Max                0.0013646667
Policy mu Min                -0.0023973477
Policy log std Mean          -0.00052310526
Policy log std Std           0.0009255489
Policy log std Max           0.0015727843
Policy log std Min           -0.0021036905
Z mean eval                  0.0931399
Z variance eval              0.002758995
total_rewards                [38.5899366  40.4661808  46.08207291 38.53484196 40.23700742 44.58214619
 35.93852762 36.0708086  44.13885471 34.36105182]
total_rewards_mean           39.90014286368063
total_rewards_std            3.7836276487878617
total_rewards_max            46.082072906647035
total_rewards_min            34.361051824457384
Number of train steps total  4000
Number of env steps total    4282
Number of rollouts total     0
Train Time (s)               139.30388085497543
(Previous) Eval Time (s)     0
Sample Time (s)              7.879813099745661
Epoch Time (s)               147.1836939547211
Total Train Time (s)         147.6167526151985
Epoch                        0
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:32:07.802071 UTC | [2020_01_10_09_29_40] Iteration #0 | Epoch Duration: 147.62332153320312
2020-01-10 09:32:07.802475 UTC | [2020_01_10_09_29_40] Iteration #0 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09709163
Z variance train             0.0027200773
KL Divergence                12.365311
KL Loss                      1.2365311
QF Loss                      1787.655
VF Loss                      167.9004
Policy Loss                  -218.6693
Q Predictions Mean           214.79839
Q Predictions Std            77.58755
Q Predictions Max            429.86237
Q Predictions Min            14.965176
V Predictions Mean           225.59247
V Predictions Std            70.05335
V Predictions Max            420.7493
V Predictions Min            41.984077
Log Pis Mean                 2.2620406
Log Pis Std                  2.033056
Log Pis Max                  8.548376
Log Pis Min                  -4.704245
Policy mu Mean               1.2355472
Policy mu Std                0.6784858
Policy mu Max                2.5937145
Policy mu Min                -0.8625603
Policy log std Mean          -0.55866814
Policy log std Std           0.12618065
Policy log std Max           -0.16308783
Policy log std Min           -0.8644196
Z mean eval                  0.09638598
Z variance eval              0.0007157485
total_rewards                [ 9.37467759  9.0781716   8.97154523  9.13770417  8.86982953  7.6536232
  8.97809295  9.05466475  9.08823518 10.71440138]
total_rewards_mean           9.092094558903344
total_rewards_std            0.6972483526323874
total_rewards_max            10.714401379350972
total_rewards_min            7.653623201542656
Number of train steps total  8000
Number of env steps total    6577
Number of rollouts total     0
Train Time (s)               137.13571728393435
(Previous) Eval Time (s)     0.1386769711971283
Sample Time (s)              4.513551512733102
Epoch Time (s)               141.78794576786458
Total Train Time (s)         289.4845671886578
Epoch                        1
---------------------------  -------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:34:29.667835 UTC | [2020_01_10_09_29_40] Iteration #1 | Epoch Duration: 141.86508512496948
2020-01-10 09:34:29.668004 UTC | [2020_01_10_09_29_40] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.095656715
Z variance train             0.0007154938
KL Divergence                16.578215
KL Loss                      1.6578215
QF Loss                      24603.312
VF Loss                      11877.974
Policy Loss                  -545.5221
Q Predictions Mean           553.97424
Q Predictions Std            167.26434
Q Predictions Max            820.226
Q Predictions Min            -41.056087
V Predictions Mean           590.24286
V Predictions Std            101.971664
V Predictions Max            766.4953
V Predictions Min            66.13968
Log Pis Mean                 3.992459
Log Pis Std                  2.6341872
Log Pis Max                  12.441334
Log Pis Min                  -3.6222696
Policy mu Mean               0.37853336
Policy mu Std                1.6652558
Policy mu Max                4.0681777
Policy mu Min                -3.5400422
Policy log std Mean          -0.7376809
Policy log std Std           0.22466025
Policy log std Max           -0.1490742
Policy log std Min           -1.62234
Z mean eval                  0.087335624
Z variance eval              0.0010059384
total_rewards                [111.25260974 114.35165356 117.56202436 105.79399982 124.11500788
 119.68718807 128.09655017 119.52534495 106.78308431 122.52042713]
total_rewards_mean           116.96878899810388
total_rewards_std            6.986718796233595
total_rewards_max            128.0965501652559
total_rewards_min            105.79399982164333
Number of train steps total  12000
Number of env steps total    8868
Number of rollouts total     0
Train Time (s)               137.98745780205354
(Previous) Eval Time (s)     1.3385360562242568
Sample Time (s)              4.350397589150816
Epoch Time (s)               143.6763914474286
Total Train Time (s)         433.32297094073147
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:36:53.507289 UTC | [2020_01_10_09_29_40] Iteration #2 | Epoch Duration: 143.83917140960693
2020-01-10 09:36:53.507425 UTC | [2020_01_10_09_29_40] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.087000415
Z variance train             0.0010079646
KL Divergence                16.608932
KL Loss                      1.6608933
QF Loss                      3321.13
VF Loss                      2646.998
Policy Loss                  -829.5113
Q Predictions Mean           793.8423
Q Predictions Std            256.10422
Q Predictions Max            1237.944
Q Predictions Min            -97.274086
V Predictions Mean           859.8612
V Predictions Std            173.00034
V Predictions Max            1218.8137
V Predictions Min            -138.1025
Log Pis Mean                 3.6512465
Log Pis Std                  2.883851
Log Pis Max                  14.897381
Log Pis Min                  -3.723968
Policy mu Mean               0.6979196
Policy mu Std                1.3985199
Policy mu Max                3.7735934
Policy mu Min                -3.1219115
Policy log std Mean          -1.053887
Policy log std Std           0.39206535
Policy log std Max           0.092119224
Policy log std Min           -2.4108253
Z mean eval                  0.03662374
Z variance eval              0.0010326125
total_rewards                [163.8790539  168.23766373 161.74845024 164.18537117 171.54673944
 160.02363601 169.69051925 172.10863782 172.65239561 169.64183377]
total_rewards_mean           167.37143009384573
total_rewards_std            4.324371090978062
total_rewards_max            172.65239561183117
total_rewards_min            160.02363600601532
Number of train steps total  16000
Number of env steps total    11310
Number of rollouts total     0
Train Time (s)               137.7746853348799
(Previous) Eval Time (s)     1.7553400420583785
Sample Time (s)              5.255012975074351
Epoch Time (s)               144.78503835201263
Total Train Time (s)         578.1870468831621
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:39:18.374046 UTC | [2020_01_10_09_29_40] Iteration #3 | Epoch Duration: 144.86649298667908
2020-01-10 09:39:18.374279 UTC | [2020_01_10_09_29_40] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0352007
Z variance train             0.0010326109
KL Divergence                15.927528
KL Loss                      1.5927528
QF Loss                      18670.373
VF Loss                      1192.4435
Policy Loss                  -1010.84186
Q Predictions Mean           970.8656
Q Predictions Std            246.69351
Q Predictions Max            1461.5425
Q Predictions Min            -33.271286
V Predictions Mean           1019.43616
V Predictions Std            147.50342
V Predictions Max            1330.282
V Predictions Min            41.551483
Log Pis Mean                 3.183744
Log Pis Std                  3.016352
Log Pis Max                  17.385986
Log Pis Min                  -5.7039633
Policy mu Mean               0.7047233
Policy mu Std                1.2521725
Policy mu Max                3.8750901
Policy mu Min                -3.3297222
Policy log std Mean          -1.0546128
Policy log std Std           0.41797608
Policy log std Max           -0.13424665
Policy log std Min           -3.068793
Z mean eval                  0.02687997
Z variance eval              0.001339854
total_rewards                [113.8551147   96.83294208 124.33385383  98.87595364  98.04220693
  34.90506293 103.04359966 111.41122137  63.07734133 110.27224788]
total_rewards_mean           95.46495443448188
total_rewards_std            25.375565129937357
total_rewards_max            124.33385383212466
total_rewards_min            34.90506293101034
Number of train steps total  20000
Number of env steps total    13718
Number of rollouts total     0
Train Time (s)               139.0090230810456
(Previous) Eval Time (s)     0.9300171616487205
Sample Time (s)              5.606650455854833
Epoch Time (s)               145.54569069854915
Total Train Time (s)         723.8235574867576
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:41:44.009574 UTC | [2020_01_10_09_29_40] Iteration #4 | Epoch Duration: 145.63513255119324
2020-01-10 09:41:44.009685 UTC | [2020_01_10_09_29_40] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------
Z mean train                 0.028580928
Z variance train             0.0013392892
KL Divergence                15.230099
KL Loss                      1.5230099
QF Loss                      10134.369
VF Loss                      3095.743
Policy Loss                  -1044.7423
Q Predictions Mean           1006.7795
Q Predictions Std            237.41156
Q Predictions Max            1839.7523
Q Predictions Min            -5.117249
V Predictions Mean           1060.1476
V Predictions Std            166.82649
V Predictions Max            1593.6329
V Predictions Min            192.84352
Log Pis Mean                 3.032282
Log Pis Std                  3.031839
Log Pis Max                  16.598867
Log Pis Min                  -3.956532
Policy mu Mean               0.6737175
Policy mu Std                1.3593096
Policy mu Max                4.3075533
Policy mu Min                -3.3666928
Policy log std Mean          -0.89553475
Policy log std Std           0.36418062
Policy log std Max           -0.15028462
Policy log std Min           -2.2374928
Z mean eval                  0.012370828
Z variance eval              0.0027732225
total_rewards                [4.16372561 2.96321435 2.6878974  0.23042054 2.38079781 5.58385138
 0.74978372 5.12807952 1.02747511 2.29920367]
total_rewards_mean           2.7214449105601433
total_rewards_std            1.7141039803386016
total_rewards_max            5.583851381706206
total_rewards_min            0.23042053881602675
Number of train steps total  24000
Number of env steps total    16118
Number of rollouts total     0
Train Time (s)               139.0728890458122
(Previous) Eval Time (s)     0.31568946223706007
Sample Time (s)              4.543463409412652
Epoch Time (s)               143.9320419174619
Total Train Time (s)         867.836102027446
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------
2020-01-10 09:44:08.023393 UTC | [2020_01_10_09_29_40] Iteration #5 | Epoch Duration: 144.01361656188965
2020-01-10 09:44:08.023551 UTC | [2020_01_10_09_29_40] Iteration #5 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011651738
Z variance train             0.0027718204
KL Divergence                13.017469
KL Loss                      1.301747
QF Loss                      9893.666
VF Loss                      2395.6853
Policy Loss                  -1047.2919
Q Predictions Mean           1018.3372
Q Predictions Std            270.58862
Q Predictions Max            1273.4645
Q Predictions Min            -15.632416
V Predictions Mean           1068.6843
V Predictions Std            186.2477
V Predictions Max            1272.5568
V Predictions Min            97.12112
Log Pis Mean                 3.1897688
Log Pis Std                  3.5361874
Log Pis Max                  17.627296
Log Pis Min                  -3.3498607
Policy mu Mean               -0.11349082
Policy mu Std                1.4818853
Policy mu Max                4.9490075
Policy mu Min                -3.2434096
Policy log std Mean          -1.0262024
Policy log std Std           0.4207038
Policy log std Max           -0.27629972
Policy log std Min           -3.191818
Z mean eval                  0.01388981
Z variance eval              0.0011628935
total_rewards                [178.62096387 190.5044809  199.27037978 205.52749549 208.3297324
 191.33379674 207.54375911 196.78998305 198.15228045 209.74711982]
total_rewards_mean           198.58199916223174
total_rewards_std            9.318405445288752
total_rewards_max            209.74711982397378
total_rewards_min            178.62096386997194
Number of train steps total  28000
Number of env steps total    18532
Number of rollouts total     0
Train Time (s)               138.63349972572178
(Previous) Eval Time (s)     2.1001937640830874
Sample Time (s)              4.5594994723796844
Epoch Time (s)               145.29319296218455
Total Train Time (s)         1013.2069053081796
Epoch                        6
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:46:33.395150 UTC | [2020_01_10_09_29_40] Iteration #6 | Epoch Duration: 145.3714747428894
2020-01-10 09:46:33.395311 UTC | [2020_01_10_09_29_40] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01357301
Z variance train             0.0011602846
KL Divergence                15.405775
KL Loss                      1.5405775
QF Loss                      3134.289
VF Loss                      1664.7607
Policy Loss                  -1084.475
Q Predictions Mean           1048.9265
Q Predictions Std            268.78058
Q Predictions Max            1293.4819
Q Predictions Min            -51.495586
V Predictions Mean           1068.3782
V Predictions Std            213.83095
V Predictions Max            1275.1703
V Predictions Min            -45.144775
Log Pis Mean                 2.941784
Log Pis Std                  2.9631116
Log Pis Max                  15.266814
Log Pis Min                  -4.34504
Policy mu Mean               0.5643639
Policy mu Std                1.2906246
Policy mu Max                4.8532405
Policy mu Min                -3.2449825
Policy log std Mean          -1.0455308
Policy log std Std           0.411483
Policy log std Max           -0.11545685
Policy log std Min           -3.3326962
Z mean eval                  0.017068805
Z variance eval              0.0017769842
total_rewards                [232.72382261 215.86238533 240.60087788 243.53533278 234.00991347
 228.83331565 245.08111602 216.28488864 193.2990721  217.05426416]
total_rewards_mean           226.7284988628685
total_rewards_std            15.308112523878984
total_rewards_max            245.0811160180205
total_rewards_min            193.29907209537643
Number of train steps total  32000
Number of env steps total    21097
Number of rollouts total     0
Train Time (s)               138.39531684294343
(Previous) Eval Time (s)     2.133909550961107
Sample Time (s)              6.285187812987715
Epoch Time (s)               146.81441420689225
Total Train Time (s)         1160.103676895611
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:49:00.292867 UTC | [2020_01_10_09_29_40] Iteration #7 | Epoch Duration: 146.8974256515503
2020-01-10 09:49:00.293045 UTC | [2020_01_10_09_29_40] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01653664
Z variance train             0.001767795
KL Divergence                15.542281
KL Loss                      1.5542282
QF Loss                      2754.9639
VF Loss                      1146.0331
Policy Loss                  -1022.94006
Q Predictions Mean           981.75024
Q Predictions Std            297.62576
Q Predictions Max            1287.483
Q Predictions Min            -37.119984
V Predictions Mean           1035.5608
V Predictions Std            260.75034
V Predictions Max            1288.1816
V Predictions Min            70.97702
Log Pis Mean                 2.7251916
Log Pis Std                  3.01267
Log Pis Max                  17.339624
Log Pis Min                  -2.9574149
Policy mu Mean               0.5040365
Policy mu Std                1.2847245
Policy mu Max                4.3573723
Policy mu Min                -3.319846
Policy log std Mean          -1.052099
Policy log std Std           0.4118407
Policy log std Max           -0.23614258
Policy log std Min           -3.1515105
Z mean eval                  0.014815906
Z variance eval              0.0023150097
total_rewards                [231.60207561 227.71324341 282.63070131 234.34138658 233.80064878
 219.98114559 286.10280437 287.81774719 362.86142056 218.16911743]
total_rewards_mean           258.50202908434915
total_rewards_std            43.66960432705283
total_rewards_max            362.86142056331255
total_rewards_min            218.1691174337637
Number of train steps total  36000
Number of env steps total    23549
Number of rollouts total     0
Train Time (s)               137.46401291480288
(Previous) Eval Time (s)     2.186193672940135
Sample Time (s)              5.928377537522465
Epoch Time (s)               145.57858412526548
Total Train Time (s)         1305.7651989315636
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:51:25.956674 UTC | [2020_01_10_09_29_40] Iteration #8 | Epoch Duration: 145.66349411010742
2020-01-10 09:51:25.956852 UTC | [2020_01_10_09_29_40] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------
Z mean train                 0.01613737
Z variance train             0.002315383
KL Divergence                14.391844
KL Loss                      1.4391844
QF Loss                      5195.698
VF Loss                      3613.163
Policy Loss                  -945.46716
Q Predictions Mean           904.6167
Q Predictions Std            338.68655
Q Predictions Max            1240.037
Q Predictions Min            -43.215565
V Predictions Mean           963.06476
V Predictions Std            301.07394
V Predictions Max            1267.0164
V Predictions Min            61.956306
Log Pis Mean                 2.6516213
Log Pis Std                  3.2152193
Log Pis Max                  16.625313
Log Pis Min                  -4.4161916
Policy mu Mean               0.29702187
Policy mu Std                1.3960085
Policy mu Max                4.2495294
Policy mu Min                -3.143601
Policy log std Mean          -0.91923887
Policy log std Std           0.3790697
Policy log std Max           0.025056988
Policy log std Min           -3.527337
Z mean eval                  0.010755211
Z variance eval              0.0010994764
total_rewards                [7.01255028 6.30415382 7.96268602 7.57887294 6.64026412 7.06737886
 5.89580563 5.76978923 7.25748289 5.19974008]
total_rewards_mean           6.668872385854469
total_rewards_std            0.8260514188459318
total_rewards_max            7.962686015913281
total_rewards_min            5.199740075045296
Number of train steps total  40000
Number of env steps total    26085
Number of rollouts total     0
Train Time (s)               140.5602859039791
(Previous) Eval Time (s)     0.2396698622033
Sample Time (s)              6.373158543836325
Epoch Time (s)               147.17311431001872
Total Train Time (s)         1453.0228595770895
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------
2020-01-10 09:53:53.214572 UTC | [2020_01_10_09_29_40] Iteration #9 | Epoch Duration: 147.25758695602417
2020-01-10 09:53:53.216475 UTC | [2020_01_10_09_29_40] Iteration #9 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010531208
Z variance train             0.0010988887
KL Divergence                15.943693
KL Loss                      1.5943693
QF Loss                      4190.5205
VF Loss                      1835.5061
Policy Loss                  -923.7791
Q Predictions Mean           876.5225
Q Predictions Std            308.5249
Q Predictions Max            1183.1345
Q Predictions Min            -4.7134404
V Predictions Mean           946.54846
V Predictions Std            253.00494
V Predictions Max            1203.3894
V Predictions Min            122.78905
Log Pis Mean                 2.4850934
Log Pis Std                  3.2736053
Log Pis Max                  17.025568
Log Pis Min                  -7.4380856
Policy mu Mean               -0.12063718
Policy mu Std                1.4784211
Policy mu Max                4.101717
Policy mu Min                -3.101544
Policy log std Mean          -0.8056607
Policy log std Std           0.37447327
Policy log std Max           0.2860383
Policy log std Min           -2.8199127
Z mean eval                  0.014309986
Z variance eval              0.0006570063
total_rewards                [ 8.6082721   8.61320196  8.83928021  8.75757595  9.2440568   9.52920032
 16.36805914  9.27148242  9.83102834  9.31598923]
total_rewards_mean           9.837814648541912
total_rewards_std            2.2104389190019806
total_rewards_max            16.368059144672806
total_rewards_min            8.608272104508764
Number of train steps total  44000
Number of env steps total    28406
Number of rollouts total     0
Train Time (s)               139.19658433506265
(Previous) Eval Time (s)     0.6599461706355214
Sample Time (s)              4.573079661466181
Epoch Time (s)               144.42961016716436
Total Train Time (s)         1597.5309750745073
Epoch                        10
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:56:17.723292 UTC | [2020_01_10_09_29_40] Iteration #10 | Epoch Duration: 144.50669884681702
2020-01-10 09:56:17.723409 UTC | [2020_01_10_09_29_40] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0156184705
Z variance train             0.00065807777
KL Divergence                17.316147
KL Loss                      1.7316147
QF Loss                      4959.6865
VF Loss                      2882.0242
Policy Loss                  -866.31665
Q Predictions Mean           824.5779
Q Predictions Std            268.8707
Q Predictions Max            1156.7544
Q Predictions Min            -50.605778
V Predictions Mean           861.05884
V Predictions Std            220.3046
V Predictions Max            1049.8862
V Predictions Min            -9.1323805
Log Pis Mean                 2.6038294
Log Pis Std                  3.279444
Log Pis Max                  16.509146
Log Pis Min                  -3.3931086
Policy mu Mean               -0.0022646561
Policy mu Std                1.4826908
Policy mu Max                4.8638654
Policy mu Min                -3.6957016
Policy log std Mean          -0.74837476
Policy log std Std           0.38745582
Policy log std Max           0.47483176
Policy log std Min           -2.9611084
Z mean eval                  0.017479375
Z variance eval              0.0015481822
total_rewards                [194.49164772 185.05051325 325.70051879 197.00825515 504.14373982
 417.52242883 218.65691927 192.28217128 192.07460362 450.99957708]
total_rewards_mean           287.79303748124573
total_rewards_std            119.280296944535
total_rewards_max            504.14373981662857
total_rewards_min            185.05051324793897
Number of train steps total  48000
Number of env steps total    31030
Number of rollouts total     0
Train Time (s)               137.91229426581413
(Previous) Eval Time (s)     3.6487548663280904
Sample Time (s)              5.484969338867813
Epoch Time (s)               147.04601847101003
Total Train Time (s)         1744.6501934807748
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:58:44.843511 UTC | [2020_01_10_09_29_40] Iteration #11 | Epoch Duration: 147.1200132369995
2020-01-10 09:58:44.843649 UTC | [2020_01_10_09_29_40] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014700457
Z variance train             0.0015483685
KL Divergence                15.890634
KL Loss                      1.5890634
QF Loss                      2864.3447
VF Loss                      676.0203
Policy Loss                  -798.91644
Q Predictions Mean           778.1018
Q Predictions Std            246.55318
Q Predictions Max            1065.3123
Q Predictions Min            -78.684456
V Predictions Mean           817.1841
V Predictions Std            212.36272
V Predictions Max            1070.8917
V Predictions Min            -75.270226
Log Pis Mean                 2.6146185
Log Pis Std                  2.5655975
Log Pis Max                  11.254199
Log Pis Min                  -5.5407968
Policy mu Mean               0.18558641
Policy mu Std                1.4102913
Policy mu Max                3.5499263
Policy mu Min                -2.8541503
Policy log std Mean          -0.8495824
Policy log std Std           0.40792137
Policy log std Max           -0.07864076
Policy log std Min           -2.4682062
Z mean eval                  0.010131821
Z variance eval              0.0029927029
total_rewards                [378.59087059 372.48331156 367.92260419 373.54425972 368.20037843
 340.07099635 343.22133607 387.578983   355.18794353 328.89167909]
total_rewards_mean           361.56923625205593
total_rewards_std            17.945645482147054
total_rewards_max            387.5789829963114
total_rewards_min            328.89167908641474
Number of train steps total  52000
Number of env steps total    33691
Number of rollouts total     0
Train Time (s)               138.25001249508932
(Previous) Eval Time (s)     3.8270053383894265
Sample Time (s)              6.981520534493029
Epoch Time (s)               149.05853836797178
Total Train Time (s)         1893.793206892442
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:01:13.986956 UTC | [2020_01_10_09_29_40] Iteration #12 | Epoch Duration: 149.143217086792
2020-01-10 10:01:13.987080 UTC | [2020_01_10_09_29_40] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008879189
Z variance train             0.002996989
KL Divergence                15.30471
KL Loss                      1.5304711
QF Loss                      5251.6763
VF Loss                      1042.6321
Policy Loss                  -783.3579
Q Predictions Mean           759.2145
Q Predictions Std            234.99103
Q Predictions Max            996.70013
Q Predictions Min            -79.91589
V Predictions Mean           780.9718
V Predictions Std            197.49113
V Predictions Max            997.5983
V Predictions Min            -72.43831
Log Pis Mean                 2.329269
Log Pis Std                  2.927292
Log Pis Max                  15.939148
Log Pis Min                  -5.5600004
Policy mu Mean               0.21545659
Policy mu Std                1.3726258
Policy mu Max                4.3111253
Policy mu Min                -2.953465
Policy log std Mean          -0.74769425
Policy log std Std           0.36509052
Policy log std Max           0.09722003
Policy log std Min           -3.20148
Z mean eval                  0.023250993
Z variance eval              0.004767651
total_rewards                [202.63439135 714.49074607 185.98488904 178.71953105 276.97280583
 691.80415912 184.31357622 207.03122215 173.41238591 197.3420345 ]
total_rewards_mean           301.27057412367975
total_rewards_std            202.88057309926205
total_rewards_max            714.4907460664627
total_rewards_min            173.41238590976687
Number of train steps total  56000
Number of env steps total    36496
Number of rollouts total     0
Train Time (s)               139.058271298185
(Previous) Eval Time (s)     4.019497614353895
Sample Time (s)              7.730667087249458
Epoch Time (s)               150.80843599978834
Total Train Time (s)         2044.6855393513106
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:03:44.881326 UTC | [2020_01_10_09_29_40] Iteration #13 | Epoch Duration: 150.89414381980896
2020-01-10 10:03:44.881495 UTC | [2020_01_10_09_29_40] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024333641
Z variance train             0.004775781
KL Divergence                13.804222
KL Loss                      1.3804222
QF Loss                      7904.083
VF Loss                      735.3292
Policy Loss                  -745.24
Q Predictions Mean           751.29456
Q Predictions Std            199.83266
Q Predictions Max            1001.23267
Q Predictions Min            -25.09486
V Predictions Mean           751.9926
V Predictions Std            181.30673
V Predictions Max            970.34973
V Predictions Min            -28.361334
Log Pis Mean                 2.1576986
Log Pis Std                  2.8009477
Log Pis Max                  13.944956
Log Pis Min                  -3.9272811
Policy mu Mean               -0.05133233
Policy mu Std                1.3506027
Policy mu Max                3.7587929
Policy mu Min                -3.6434567
Policy log std Mean          -0.7343168
Policy log std Std           0.32448405
Policy log std Max           0.03221008
Policy log std Min           -3.0498934
Z mean eval                  0.016417917
Z variance eval              0.0020769387
total_rewards                [202.39767881 314.73206572 365.76495526 300.34660026 329.95612707
 331.73286349 335.48441771 343.37584797 309.65277359 373.65866153]
total_rewards_mean           320.71019914094586
total_rewards_std            45.1032144850222
total_rewards_max            373.6586615340107
total_rewards_min            202.39767880923216
Number of train steps total  60000
Number of env steps total    39101
Number of rollouts total     0
Train Time (s)               138.9033925589174
(Previous) Eval Time (s)     3.3747297446243465
Sample Time (s)              7.117485970724374
Epoch Time (s)               149.39560827426612
Total Train Time (s)         2194.165959919803
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:06:14.364274 UTC | [2020_01_10_09_29_40] Iteration #14 | Epoch Duration: 149.48264050483704
2020-01-10 10:06:14.364443 UTC | [2020_01_10_09_29_40] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017519064
Z variance train             0.0020704013
KL Divergence                15.056416
KL Loss                      1.5056416
QF Loss                      1927.9352
VF Loss                      213.57658
Policy Loss                  -732.59534
Q Predictions Mean           712.0033
Q Predictions Std            199.6604
Q Predictions Max            960.87476
Q Predictions Min            -49.801285
V Predictions Mean           730.23474
V Predictions Std            157.41264
V Predictions Max            969.2907
V Predictions Min            -46.770714
Log Pis Mean                 2.2303576
Log Pis Std                  2.392009
Log Pis Max                  13.005027
Log Pis Min                  -2.8810246
Policy mu Mean               0.3291298
Policy mu Std                1.3163655
Policy mu Max                3.4631114
Policy mu Min                -3.1416447
Policy log std Mean          -0.7059104
Policy log std Std           0.3402664
Policy log std Max           0.2095177
Policy log std Min           -2.4270887
Z mean eval                  0.03160608
Z variance eval              0.0023139713
total_rewards                [341.77509203 369.10362004 325.91233897 312.61783855 315.89100498
 411.36864547 357.93935958 251.59974284 593.51201022 326.89456854]
total_rewards_mean           360.66142212289833
total_rewards_std            87.0521211198135
total_rewards_max            593.5120102249641
total_rewards_min            251.5997428429281
Number of train steps total  64000
Number of env steps total    42054
Number of rollouts total     0
Train Time (s)               139.82023784471676
(Previous) Eval Time (s)     3.5183643992058933
Sample Time (s)              8.175613055936992
Epoch Time (s)               151.51421529985964
Total Train Time (s)         2345.765010040719
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:08:45.964126 UTC | [2020_01_10_09_29_40] Iteration #15 | Epoch Duration: 151.5995650291443
2020-01-10 10:08:45.964252 UTC | [2020_01_10_09_29_40] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03068698
Z variance train             0.0023205376
KL Divergence                14.082769
KL Loss                      1.4082769
QF Loss                      591.2118
VF Loss                      958.3554
Policy Loss                  -750.35065
Q Predictions Mean           729.2226
Q Predictions Std            198.08096
Q Predictions Max            925.1497
Q Predictions Min            -12.995546
V Predictions Mean           750.4747
V Predictions Std            172.40668
V Predictions Max            938.16504
V Predictions Min            -11.057471
Log Pis Mean                 1.9538574
Log Pis Std                  2.7079585
Log Pis Max                  15.759222
Log Pis Min                  -5.240062
Policy mu Mean               0.41007745
Policy mu Std                1.2336485
Policy mu Max                4.33011
Policy mu Min                -2.587881
Policy log std Mean          -0.7047078
Policy log std Std           0.29343864
Policy log std Max           0.10779703
Policy log std Min           -2.376414
Z mean eval                  0.019018404
Z variance eval              0.002009452
total_rewards                [357.26591524 582.16509035 412.06499398 279.13587251 470.07940496
 406.29460868 317.33731279 567.58377841 330.23634662 346.66899495]
total_rewards_mean           406.88323184761697
total_rewards_std            98.42234802326745
total_rewards_max            582.1650903483086
total_rewards_min            279.1358725106866
Number of train steps total  68000
Number of env steps total    44878
Number of rollouts total     0
Train Time (s)               140.36625898769125
(Previous) Eval Time (s)     4.194081262219697
Sample Time (s)              7.5438623507507145
Epoch Time (s)               152.10420260066167
Total Train Time (s)         2497.951672703959
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:11:18.151411 UTC | [2020_01_10_09_29_40] Iteration #16 | Epoch Duration: 152.1870710849762
2020-01-10 10:11:18.151537 UTC | [2020_01_10_09_29_40] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0185729
Z variance train             0.0020063147
KL Divergence                14.808044
KL Loss                      1.4808044
QF Loss                      4793.0312
VF Loss                      321.08078
Policy Loss                  -717.72144
Q Predictions Mean           706.55206
Q Predictions Std            200.48274
Q Predictions Max            917.593
Q Predictions Min            -29.731514
V Predictions Mean           728.2877
V Predictions Std            190.5811
V Predictions Max            889.2424
V Predictions Min            -16.449404
Log Pis Mean                 2.0523925
Log Pis Std                  2.6401489
Log Pis Max                  10.803072
Log Pis Min                  -3.94636
Policy mu Mean               0.25530902
Policy mu Std                1.3095421
Policy mu Max                3.8752093
Policy mu Min                -2.5852003
Policy log std Mean          -0.71441334
Policy log std Std           0.32146618
Policy log std Max           0.13306643
Policy log std Min           -2.5801733
Z mean eval                  0.027180275
Z variance eval              0.00095619075
total_rewards                [376.35515573 430.58825769 434.720974   374.66154403 392.55616663
 463.85123333 339.85984867 447.48368353 360.602863   433.23443162]
total_rewards_mean           405.3914158227715
total_rewards_std            39.6386432866528
total_rewards_max            463.8512333284972
total_rewards_min            339.8598486690805
Number of train steps total  72000
Number of env steps total    47577
Number of rollouts total     0
Train Time (s)               136.90994822327048
(Previous) Eval Time (s)     3.6203598328866065
Sample Time (s)              7.52613582322374
Epoch Time (s)               148.05644387938082
Total Train Time (s)         2646.087661667727
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:13:46.289123 UTC | [2020_01_10_09_29_40] Iteration #17 | Epoch Duration: 148.13747644424438
2020-01-10 10:13:46.289305 UTC | [2020_01_10_09_29_40] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026496882
Z variance train             0.00095661625
KL Divergence                15.105522
KL Loss                      1.5105523
QF Loss                      419.5053
VF Loss                      975.93726
Policy Loss                  -689.7598
Q Predictions Mean           683.40845
Q Predictions Std            187.25816
Q Predictions Max            822.20386
Q Predictions Min            -45.393234
V Predictions Mean           702.03625
V Predictions Std            174.86777
V Predictions Max            842.8535
V Predictions Min            -17.596964
Log Pis Mean                 0.89430463
Log Pis Std                  2.30029
Log Pis Max                  12.661449
Log Pis Min                  -3.9863832
Policy mu Mean               0.30977428
Policy mu Std                1.0450453
Policy mu Max                3.6244626
Policy mu Min                -2.9175782
Policy log std Mean          -0.6761551
Policy log std Std           0.30928126
Policy log std Max           0.24715447
Policy log std Min           -3.4726653
Z mean eval                  0.033967037
Z variance eval              0.0011714046
total_rewards                [309.25851585 331.91077954 393.99407382 233.09465378 296.62655185
 305.12433991 375.87168921 383.94894981 366.88961991 400.1819804 ]
total_rewards_mean           339.6901154082687
total_rewards_std            51.00431891342983
total_rewards_max            400.1819804013634
total_rewards_min            233.09465378235652
Number of train steps total  76000
Number of env steps total    50521
Number of rollouts total     0
Train Time (s)               138.30794649012387
(Previous) Eval Time (s)     3.33479881612584
Sample Time (s)              7.198976919054985
Epoch Time (s)               148.8417222253047
Total Train Time (s)         2795.012856794521
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:16:15.214849 UTC | [2020_01_10_09_29_40] Iteration #18 | Epoch Duration: 148.9254171848297
2020-01-10 10:16:15.215020 UTC | [2020_01_10_09_29_40] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035077862
Z variance train             0.0011687782
KL Divergence                14.656375
KL Loss                      1.4656376
QF Loss                      1348.6776
VF Loss                      478.30542
Policy Loss                  -658.1281
Q Predictions Mean           643.0736
Q Predictions Std            209.24715
Q Predictions Max            850.5375
Q Predictions Min            -25.75292
V Predictions Mean           653.891
V Predictions Std            177.53198
V Predictions Max            823.9752
V Predictions Min            -14.420188
Log Pis Mean                 1.2717968
Log Pis Std                  2.9004593
Log Pis Max                  14.192692
Log Pis Min                  -4.4857054
Policy mu Mean               0.52639556
Policy mu Std                1.0472019
Policy mu Max                4.3765945
Policy mu Min                -2.569255
Policy log std Mean          -0.73186094
Policy log std Std           0.34435833
Policy log std Max           0.1853467
Policy log std Min           -3.454142
Z mean eval                  0.020183664
Z variance eval              0.0015195882
total_rewards                [207.47528997 273.6351753  412.01733185 178.40703809 320.90761958
 323.54508864 191.21647942 360.68210658 401.38641039 214.04320958]
total_rewards_mean           288.3315749402137
total_rewards_std            83.30821191829956
total_rewards_max            412.0173318496101
total_rewards_min            178.40703809172317
Number of train steps total  80000
Number of env steps total    53173
Number of rollouts total     0
Train Time (s)               138.4679569490254
(Previous) Eval Time (s)     2.7946185232140124
Sample Time (s)              6.486759024206549
Epoch Time (s)               147.74933449644595
Total Train Time (s)         2942.849462735001
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:18:43.051988 UTC | [2020_01_10_09_29_40] Iteration #19 | Epoch Duration: 147.83684706687927
2020-01-10 10:18:43.052106 UTC | [2020_01_10_09_29_40] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021539684
Z variance train             0.0015187123
KL Divergence                14.760246
KL Loss                      1.4760246
QF Loss                      641.28
VF Loss                      662.1256
Policy Loss                  -623.7287
Q Predictions Mean           612.8349
Q Predictions Std            217.08014
Q Predictions Max            855.5336
Q Predictions Min            -19.34915
V Predictions Mean           619.7249
V Predictions Std            210.19243
V Predictions Max            852.1124
V Predictions Min            -12.733328
Log Pis Mean                 1.1837888
Log Pis Std                  2.826552
Log Pis Max                  14.254131
Log Pis Min                  -3.7506669
Policy mu Mean               0.51528287
Policy mu Std                1.0626951
Policy mu Max                4.2473083
Policy mu Min                -3.661943
Policy log std Mean          -0.72836274
Policy log std Std           0.319839
Policy log std Max           0.12771657
Policy log std Min           -3.4355512
Z mean eval                  0.007807867
Z variance eval              0.0009885455
total_rewards                [352.96158749 358.95710795 489.80976212 396.74914749 486.69420402
 480.65698258 312.17129817 397.26627367 439.47208116 469.82743122]
total_rewards_mean           418.45658758719554
total_rewards_std            60.61661465022146
total_rewards_max            489.80976212095595
total_rewards_min            312.17129816504973
Number of train steps total  84000
Number of env steps total    56673
Number of rollouts total     0
Train Time (s)               139.83062611194327
(Previous) Eval Time (s)     3.8306446499191225
Sample Time (s)              6.821635898202658
Epoch Time (s)               150.48290666006505
Total Train Time (s)         3093.4141356553882
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:21:13.617948 UTC | [2020_01_10_09_29_40] Iteration #20 | Epoch Duration: 150.56574058532715
2020-01-10 10:21:13.618116 UTC | [2020_01_10_09_29_40] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010075277
Z variance train             0.0009864668
KL Divergence                15.3447485
KL Loss                      1.5344748
QF Loss                      653.89417
VF Loss                      551.79297
Policy Loss                  -606.09064
Q Predictions Mean           592.27704
Q Predictions Std            207.98747
Q Predictions Max            834.3804
Q Predictions Min            -44.698143
V Predictions Mean           600.5836
V Predictions Std            202.74632
V Predictions Max            836.6125
V Predictions Min            6.6215224
Log Pis Mean                 0.96485656
Log Pis Std                  2.5304613
Log Pis Max                  10.165554
Log Pis Min                  -5.596657
Policy mu Mean               0.5236222
Policy mu Std                1.0466568
Policy mu Max                3.8827682
Policy mu Min                -2.8361127
Policy log std Mean          -0.6628565
Policy log std Std           0.34692022
Policy log std Max           0.26746565
Policy log std Min           -3.7580884
Z mean eval                  0.028674578
Z variance eval              0.00063479505
total_rewards                [479.86690508 629.06637138 367.06182774 469.36799724 406.06188729
 414.57202866 587.1959149  621.79983132 432.8425163  412.52507394]
total_rewards_mean           482.03603538422897
total_rewards_std            91.1975497574271
total_rewards_max            629.0663713752581
total_rewards_min            367.0618277399093
Number of train steps total  88000
Number of env steps total    60359
Number of rollouts total     0
Train Time (s)               139.70727448770776
(Previous) Eval Time (s)     3.9371966351754963
Sample Time (s)              6.940680579748005
Epoch Time (s)               150.58515170263126
Total Train Time (s)         3244.125037345104
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:23:44.328893 UTC | [2020_01_10_09_29_40] Iteration #21 | Epoch Duration: 150.71066093444824
2020-01-10 10:23:44.329001 UTC | [2020_01_10_09_29_40] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028718758
Z variance train             0.0006339276
KL Divergence                15.957419
KL Loss                      1.595742
QF Loss                      934.605
VF Loss                      479.95224
Policy Loss                  -605.68115
Q Predictions Mean           589.52484
Q Predictions Std            200.86919
Q Predictions Max            827.9503
Q Predictions Min            -29.753735
V Predictions Mean           608.33875
V Predictions Std            184.44157
V Predictions Max            840.2028
V Predictions Min            5.2259245
Log Pis Mean                 1.2193245
Log Pis Std                  2.5358841
Log Pis Max                  13.19084
Log Pis Min                  -7.277425
Policy mu Mean               0.42253718
Policy mu Std                1.107649
Policy mu Max                4.364913
Policy mu Min                -4.3877325
Policy log std Mean          -0.6672993
Policy log std Std           0.33047536
Policy log std Max           0.07517472
Policy log std Min           -3.201047
Z mean eval                  0.027199984
Z variance eval              0.0018925827
total_rewards                [474.56795326 422.18244232 337.73656373 358.7982727  514.08513329
 377.92149793 589.36164928 369.21725159 341.79334548 449.8123665 ]
total_rewards_mean           423.5476476080118
total_rewards_std            78.90463696654449
total_rewards_max            589.361649284349
total_rewards_min            337.736563730122
Number of train steps total  92000
Number of env steps total    63923
Number of rollouts total     0
Train Time (s)               140.1551880207844
(Previous) Eval Time (s)     3.511417062021792
Sample Time (s)              6.326045940164477
Epoch Time (s)               149.99265102297068
Total Train Time (s)         3394.193628893234
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:26:14.398228 UTC | [2020_01_10_09_29_40] Iteration #22 | Epoch Duration: 150.06914258003235
2020-01-10 10:26:14.398342 UTC | [2020_01_10_09_29_40] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029113416
Z variance train             0.0018849066
KL Divergence                14.368053
KL Loss                      1.4368054
QF Loss                      2327.6255
VF Loss                      283.30652
Policy Loss                  -607.8834
Q Predictions Mean           601.74854
Q Predictions Std            166.2657
Q Predictions Max            773.9331
Q Predictions Min            -9.964797
V Predictions Mean           605.87805
V Predictions Std            168.56203
V Predictions Max            777.44977
V Predictions Min            -2.3468711
Log Pis Mean                 1.3097312
Log Pis Std                  2.421155
Log Pis Max                  12.048892
Log Pis Min                  -4.7881546
Policy mu Mean               0.40096426
Policy mu Std                1.1123552
Policy mu Max                3.620767
Policy mu Min                -2.7074196
Policy log std Mean          -0.64913386
Policy log std Std           0.331227
Policy log std Max           0.19559735
Policy log std Min           -3.2258618
Z mean eval                  0.017740048
Z variance eval              0.0017602146
total_rewards                [420.46434728 193.0224043  202.37251653 211.75711825 207.96356582
 425.23685729 415.4843661  426.43074289 423.35724724 413.61421958]
total_rewards_mean           333.9703385271077
total_rewards_std            106.45915000558979
total_rewards_max            426.4307428915554
total_rewards_min            193.02240429644723
Number of train steps total  96000
Number of env steps total    67712
Number of rollouts total     0
Train Time (s)               138.5530191566795
(Previous) Eval Time (s)     2.5590641256421804
Sample Time (s)              7.987814515829086
Epoch Time (s)               149.09989779815078
Total Train Time (s)         3543.4709818698466
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:28:43.677691 UTC | [2020_01_10_09_29_40] Iteration #23 | Epoch Duration: 149.27923774719238
2020-01-10 10:28:43.677869 UTC | [2020_01_10_09_29_40] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018805338
Z variance train             0.0017622014
KL Divergence                13.938217
KL Loss                      1.3938217
QF Loss                      1696.9437
VF Loss                      608.89343
Policy Loss                  -622.4592
Q Predictions Mean           621.1476
Q Predictions Std            191.22598
Q Predictions Max            816.0613
Q Predictions Min            -93.47558
V Predictions Mean           621.2409
V Predictions Std            178.77069
V Predictions Max            815.7272
V Predictions Min            -24.86424
Log Pis Mean                 0.5607766
Log Pis Std                  2.598971
Log Pis Max                  16.379993
Log Pis Min                  -5.240588
Policy mu Mean               0.19982733
Policy mu Std                1.0270289
Policy mu Max                4.06695
Policy mu Min                -2.580579
Policy log std Mean          -0.6051956
Policy log std Std           0.27829087
Policy log std Max           0.18910289
Policy log std Min           -1.9732976
Z mean eval                  0.036013257
Z variance eval              0.0012505653
total_rewards                [358.559867   359.60788334 341.09099992 349.60536129 353.61750046
 362.10607897 347.24112938 349.8374893  346.97766749 349.5959423 ]
total_rewards_mean           351.82399194516677
total_rewards_std            6.232321332387609
total_rewards_max            362.1060789667309
total_rewards_min            341.09099992241835
Number of train steps total  100000
Number of env steps total    71266
Number of rollouts total     0
Train Time (s)               139.07988863391802
(Previous) Eval Time (s)     3.214621608145535
Sample Time (s)              6.910486721433699
Epoch Time (s)               149.20499696349725
Total Train Time (s)         3692.7730101919733
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:31:12.979529 UTC | [2020_01_10_09_29_40] Iteration #24 | Epoch Duration: 149.3015432357788
2020-01-10 10:31:12.979649 UTC | [2020_01_10_09_29_40] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042102642
Z variance train             0.0012501666
KL Divergence                14.629639
KL Loss                      1.4629639
QF Loss                      971.5802
VF Loss                      284.73383
Policy Loss                  -621.0446
Q Predictions Mean           619.4684
Q Predictions Std            190.77036
Q Predictions Max            837.13306
Q Predictions Min            27.83538
V Predictions Mean           624.85205
V Predictions Std            179.71114
V Predictions Max            829.9081
V Predictions Min            4.297224
Log Pis Mean                 0.86967564
Log Pis Std                  2.467392
Log Pis Max                  13.519754
Log Pis Min                  -6.618907
Policy mu Mean               0.27062365
Policy mu Std                1.0376115
Policy mu Max                3.8518205
Policy mu Min                -2.494408
Policy log std Mean          -0.6341029
Policy log std Std           0.31079763
Policy log std Max           0.36080515
Policy log std Min           -2.74758
Z mean eval                  0.02283161
Z variance eval              0.0014636687
total_rewards                [349.33659398 355.11532773 398.53273471 336.43685564 358.20405766
 597.51275295 353.64530873 328.3216764  379.98223527 343.83514392]
total_rewards_mean           380.0922686991295
total_rewards_std            75.00706157384504
total_rewards_max            597.512752946604
total_rewards_min            328.3216764010734
Number of train steps total  104000
Number of env steps total    74629
Number of rollouts total     0
Train Time (s)               139.50880212988704
(Previous) Eval Time (s)     3.278247321024537
Sample Time (s)              6.667029580567032
Epoch Time (s)               149.4540790314786
Total Train Time (s)         3842.3014348996803
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:33:42.508951 UTC | [2020_01_10_09_29_40] Iteration #25 | Epoch Duration: 149.5292148590088
2020-01-10 10:33:42.509072 UTC | [2020_01_10_09_29_40] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022736952
Z variance train             0.0014648272
KL Divergence                14.238286
KL Loss                      1.4238286
QF Loss                      546.8965
VF Loss                      195.57994
Policy Loss                  -627.4257
Q Predictions Mean           620.73456
Q Predictions Std            194.7115
Q Predictions Max            830.49304
Q Predictions Min            0.81763506
V Predictions Mean           625.3198
V Predictions Std            182.92085
V Predictions Max            829.979
V Predictions Min            -5.292517
Log Pis Mean                 0.60525656
Log Pis Std                  2.4045548
Log Pis Max                  12.983198
Log Pis Min                  -6.89908
Policy mu Mean               0.35884976
Policy mu Std                0.9932031
Policy mu Max                3.6650293
Policy mu Min                -2.439691
Policy log std Mean          -0.62709945
Policy log std Std           0.3012385
Policy log std Max           0.13076767
Policy log std Min           -2.7093518
Z mean eval                  0.017625062
Z variance eval              0.0017926439
total_rewards                [354.3290862  408.03975019 373.57490594 570.75807077 406.88266805
 605.44556874 389.50436659 341.08714112 338.14926865 409.097382  ]
total_rewards_mean           419.68682082563544
total_rewards_std            88.24725296699629
total_rewards_max            605.4455687392713
total_rewards_min            338.14926865429936
Number of train steps total  108000
Number of env steps total    78222
Number of rollouts total     0
Train Time (s)               139.1727416939102
(Previous) Eval Time (s)     3.1990127940662205
Sample Time (s)              6.325241049751639
Epoch Time (s)               148.69699553772807
Total Train Time (s)         3991.081240043044
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:36:11.289994 UTC | [2020_01_10_09_29_40] Iteration #26 | Epoch Duration: 148.78082275390625
2020-01-10 10:36:11.290151 UTC | [2020_01_10_09_29_40] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018034557
Z variance train             0.0017889686
KL Divergence                14.239018
KL Loss                      1.4239019
QF Loss                      925.6571
VF Loss                      233.00691
Policy Loss                  -632.6779
Q Predictions Mean           623.5331
Q Predictions Std            201.35333
Q Predictions Max            850.41095
Q Predictions Min            -15.776801
V Predictions Mean           634.86206
V Predictions Std            184.5504
V Predictions Max            849.0757
V Predictions Min            20.99143
Log Pis Mean                 1.0380862
Log Pis Std                  2.6639562
Log Pis Max                  12.833752
Log Pis Min                  -3.8147144
Policy mu Mean               0.4885081
Policy mu Std                1.0414478
Policy mu Max                4.1169815
Policy mu Min                -2.4021792
Policy log std Mean          -0.66424334
Policy log std Std           0.33451107
Policy log std Max           0.18148786
Policy log std Min           -3.5299792
Z mean eval                  0.023334518
Z variance eval              0.0020388376
total_rewards                [391.81876637 365.53272267 726.53456444 372.80565129 371.37486383
 422.41199884 376.94347519 313.4055873  397.84757809 379.94542061]
total_rewards_mean           411.8620628618731
total_rewards_std            108.15308855983092
total_rewards_max            726.5345644439735
total_rewards_min            313.4055873000295
Number of train steps total  112000
Number of env steps total    81844
Number of rollouts total     0
Train Time (s)               138.80457447236404
(Previous) Eval Time (s)     3.2636040402576327
Sample Time (s)              7.506093133240938
Epoch Time (s)               149.5742716458626
Total Train Time (s)         4140.745599632617
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:38:40.955827 UTC | [2020_01_10_09_29_40] Iteration #27 | Epoch Duration: 149.6655457019806
2020-01-10 10:38:40.956035 UTC | [2020_01_10_09_29_40] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022713486
Z variance train             0.0020420814
KL Divergence                14.131726
KL Loss                      1.4131726
QF Loss                      315.7303
VF Loss                      136.69559
Policy Loss                  -647.1203
Q Predictions Mean           640.3618
Q Predictions Std            188.92247
Q Predictions Max            878.6136
Q Predictions Min            0.0868192
V Predictions Mean           652.5637
V Predictions Std            179.24246
V Predictions Max            894.146
V Predictions Min            30.058979
Log Pis Mean                 0.6605961
Log Pis Std                  2.2111197
Log Pis Max                  10.202407
Log Pis Min                  -4.0998793
Policy mu Mean               0.36149916
Policy mu Std                0.95662063
Policy mu Max                3.4729028
Policy mu Min                -2.681452
Policy log std Mean          -0.62649673
Policy log std Std           0.28187194
Policy log std Max           0.17810878
Policy log std Min           -1.9562759
Z mean eval                  0.0158526
Z variance eval              0.0011168817
total_rewards                [ 766.10844812  494.77700359  585.89747963  365.63727467 1039.42186504
  650.67372036 1049.02356673  687.95112336  708.9609209   477.98196819]
total_rewards_mean           682.6433370603439
total_rewards_std            213.83809281309044
total_rewards_max            1049.023566734632
total_rewards_min            365.63727466567224
Number of train steps total  116000
Number of env steps total    85540
Number of rollouts total     0
Train Time (s)               138.47969883028418
(Previous) Eval Time (s)     5.599300455302
Sample Time (s)              7.66388847026974
Epoch Time (s)               151.74288775585592
Total Train Time (s)         4292.567053595092
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:41:12.780619 UTC | [2020_01_10_09_29_40] Iteration #28 | Epoch Duration: 151.82440090179443
2020-01-10 10:41:12.780906 UTC | [2020_01_10_09_29_40] Iteration #28 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016843453
Z variance train             0.0011130976
KL Divergence                14.819432
KL Loss                      1.4819432
QF Loss                      824.1273
VF Loss                      131.01558
Policy Loss                  -660.3443
Q Predictions Mean           652.92114
Q Predictions Std            201.417
Q Predictions Max            879.3241
Q Predictions Min            -39.068394
V Predictions Mean           661.1344
V Predictions Std            193.29813
V Predictions Max            874.7175
V Predictions Min            -48.46223
Log Pis Mean                 0.7010854
Log Pis Std                  2.5628414
Log Pis Max                  12.794892
Log Pis Min                  -5.0681043
Policy mu Mean               0.2983354
Policy mu Std                1.0353503
Policy mu Max                3.733721
Policy mu Min                -3.0527122
Policy log std Mean          -0.6451295
Policy log std Std           0.27893254
Policy log std Max           0.18355179
Policy log std Min           -2.1273193
Z mean eval                  0.013628933
Z variance eval              0.0015918978
total_rewards                [ 896.69430026  346.12141161  355.32077055 1093.73619172  422.471308
  477.77875543  719.46738785 1039.19555931  947.9652903  1011.80410968]
total_rewards_mean           731.0555084712863
total_rewards_std            287.8631390024232
total_rewards_max            1093.7361917162502
total_rewards_min            346.1214116114729
Number of train steps total  120000
Number of env steps total    89301
Number of rollouts total     0
Train Time (s)               135.8942387457937
(Previous) Eval Time (s)     4.666693328879774
Sample Time (s)              8.449110641609877
Epoch Time (s)               149.01004271628335
Total Train Time (s)         4441.65636381926
Epoch                        29
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:43:41.869982 UTC | [2020_01_10_09_29_40] Iteration #29 | Epoch Duration: 149.08887815475464
2020-01-10 10:43:41.870160 UTC | [2020_01_10_09_29_40] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013835925
Z variance train             0.0015907638
KL Divergence                13.985462
KL Loss                      1.3985462
QF Loss                      769.8712
VF Loss                      440.9159
Policy Loss                  -650.3419
Q Predictions Mean           639.2584
Q Predictions Std            230.68561
Q Predictions Max            950.6142
Q Predictions Min            -76.41951
V Predictions Mean           655.0171
V Predictions Std            216.71582
V Predictions Max            955.18353
V Predictions Min            -7.7642765
Log Pis Mean                 0.87711096
Log Pis Std                  2.4839215
Log Pis Max                  14.704203
Log Pis Min                  -5.131266
Policy mu Mean               0.4115379
Policy mu Std                1.0366668
Policy mu Max                3.6059632
Policy mu Min                -3.450773
Policy log std Mean          -0.61520284
Policy log std Std           0.30844826
Policy log std Max           0.17826375
Policy log std Min           -2.2743306
Z mean eval                  0.0337039
Z variance eval              0.0011620038
total_rewards                [1047.67176197  920.53280831  931.06500682  764.29251575 1207.57167465
  910.75726558  932.11692321  747.83581745 1047.58394424  953.95577207]
total_rewards_mean           946.3383490056063
total_rewards_std            127.95757519355405
total_rewards_max            1207.5716746460105
total_rewards_min            747.8358174533032
Number of train steps total  124000
Number of env steps total    92937
Number of rollouts total     0
Train Time (s)               139.59551289770752
(Previous) Eval Time (s)     5.964512767270207
Sample Time (s)              7.791397823952138
Epoch Time (s)               153.35142348892987
Total Train Time (s)         4595.08794224821
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:46:15.302139 UTC | [2020_01_10_09_29_40] Iteration #30 | Epoch Duration: 153.4318494796753
2020-01-10 10:46:15.302305 UTC | [2020_01_10_09_29_40] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03316582
Z variance train             0.0011617955
KL Divergence                14.945091
KL Loss                      1.4945091
QF Loss                      424.9799
VF Loss                      127.05997
Policy Loss                  -694.48425
Q Predictions Mean           686.1937
Q Predictions Std            190.20247
Q Predictions Max            892.60406
Q Predictions Min            -18.821749
V Predictions Mean           696.88635
V Predictions Std            178.10211
V Predictions Max            891.6629
V Predictions Min            0.04825577
Log Pis Mean                 0.8706082
Log Pis Std                  2.2164307
Log Pis Max                  7.2300744
Log Pis Min                  -5.4966655
Policy mu Mean               0.51104057
Policy mu Std                0.9992966
Policy mu Max                2.880111
Policy mu Min                -2.382555
Policy log std Mean          -0.61665773
Policy log std Std           0.28256482
Policy log std Max           0.18459216
Policy log std Min           -1.8683199
Z mean eval                  0.056098558
Z variance eval              0.0013459834
total_rewards                [ 827.26000392  889.396283    812.10174223  116.21725575 1367.06633258
  240.4074736   861.0649713   908.45555808  215.78880453 1042.2471181 ]
total_rewards_mean           728.000554310495
total_rewards_std            384.02953558508324
total_rewards_max            1367.0663325822209
total_rewards_min            116.217255752042
Number of train steps total  128000
Number of env steps total    96046
Number of rollouts total     0
Train Time (s)               139.29823963716626
(Previous) Eval Time (s)     4.899863895960152
Sample Time (s)              6.666505662724376
Epoch Time (s)               150.8646091958508
Total Train Time (s)         4746.043372742366
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:48:46.258750 UTC | [2020_01_10_09_29_40] Iteration #31 | Epoch Duration: 150.95631885528564
2020-01-10 10:48:46.258919 UTC | [2020_01_10_09_29_40] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056354187
Z variance train             0.0013433652
KL Divergence                14.685224
KL Loss                      1.4685224
QF Loss                      761.3429
VF Loss                      304.20474
Policy Loss                  -711.2256
Q Predictions Mean           701.2036
Q Predictions Std            203.07826
Q Predictions Max            1033.498
Q Predictions Min            7.6220837
V Predictions Mean           705.42786
V Predictions Std            187.69246
V Predictions Max            1027.07
V Predictions Min            11.302267
Log Pis Mean                 1.1571434
Log Pis Std                  2.5803413
Log Pis Max                  13.279872
Log Pis Min                  -4.8402996
Policy mu Mean               0.32448032
Policy mu Std                1.1135741
Policy mu Max                3.9523952
Policy mu Min                -2.5699263
Policy log std Mean          -0.60806274
Policy log std Std           0.29814696
Policy log std Max           0.0906741
Policy log std Min           -2.9973028
Z mean eval                  0.03496725
Z variance eval              0.0013101993
total_rewards                [ 941.10910551 1140.29541926  251.01917144  158.92629634 1281.83460366
 1084.56452716  862.7149739  1368.50313268  549.74065152  756.29751616]
total_rewards_mean           839.5005397643454
total_rewards_std            392.0810443094517
total_rewards_max            1368.503132677582
total_rewards_min            158.92629634106322
Number of train steps total  132000
Number of env steps total    99308
Number of rollouts total     0
Train Time (s)               140.4559439648874
(Previous) Eval Time (s)     7.2769942549057305
Sample Time (s)              6.823472167365253
Epoch Time (s)               154.5564103871584
Total Train Time (s)         4900.71081677964
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:51:20.926698 UTC | [2020_01_10_09_29_40] Iteration #32 | Epoch Duration: 154.66765451431274
2020-01-10 10:51:20.926833 UTC | [2020_01_10_09_29_40] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035983287
Z variance train             0.0013080025
KL Divergence                15.833426
KL Loss                      1.5833427
QF Loss                      5466.8535
VF Loss                      314.8845
Policy Loss                  -715.1928
Q Predictions Mean           709.2578
Q Predictions Std            217.07657
Q Predictions Max            1022.1867
Q Predictions Min            -18.889633
V Predictions Mean           713.0513
V Predictions Std            204.70894
V Predictions Max            1021.39636
V Predictions Min            -32.849724
Log Pis Mean                 1.123255
Log Pis Std                  2.5105832
Log Pis Max                  13.189458
Log Pis Min                  -4.5827765
Policy mu Mean               0.24929984
Policy mu Std                1.151903
Policy mu Max                3.6941528
Policy mu Min                -2.8933415
Policy log std Mean          -0.6217107
Policy log std Std           0.3256663
Policy log std Max           0.1896329
Policy log std Min           -2.9637773
Z mean eval                  0.04583668
Z variance eval              0.0010646221
total_rewards                [ 724.10082839  572.71933509  465.9610808  1053.11172813  888.75582909
  797.75772348 1269.78700351  746.84847761  673.3004026  1147.76117996]
total_rewards_mean           834.0103588654968
total_rewards_std            242.87771625119342
total_rewards_max            1269.7870035057392
total_rewards_min            465.96108079502926
Number of train steps total  136000
Number of env steps total    102428
Number of rollouts total     0
Train Time (s)               140.08283559884876
(Previous) Eval Time (s)     5.839121023658663
Sample Time (s)              6.406796231400222
Epoch Time (s)               152.32875285390764
Total Train Time (s)         5053.117771569639
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:53:53.337767 UTC | [2020_01_10_09_29_40] Iteration #33 | Epoch Duration: 152.41077160835266
2020-01-10 10:53:53.338064 UTC | [2020_01_10_09_29_40] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048291497
Z variance train             0.0010636825
KL Divergence                15.442741
KL Loss                      1.5442742
QF Loss                      568.6599
VF Loss                      123.83593
Policy Loss                  -769.78595
Q Predictions Mean           756.2449
Q Predictions Std            208.40424
Q Predictions Max            1062.5605
Q Predictions Min            -33.223305
V Predictions Mean           772.47986
V Predictions Std            187.8069
V Predictions Max            1048.8475
V Predictions Min            -56.353054
Log Pis Mean                 0.9096247
Log Pis Std                  2.2977786
Log Pis Max                  10.936027
Log Pis Min                  -4.898665
Policy mu Mean               0.3000326
Policy mu Std                1.1205815
Policy mu Max                3.8260837
Policy mu Min                -3.009045
Policy log std Mean          -0.612268
Policy log std Std           0.3067378
Policy log std Max           0.33757362
Policy log std Min           -3.1805866
Z mean eval                  0.034040265
Z variance eval              0.002345024
total_rewards                [672.64369904 660.61367359 667.04141047 833.23927709 470.91922957
 767.75782535 539.92895986 733.29435449 694.18020617 619.12459257]
total_rewards_mean           665.8743228196388
total_rewards_std            99.9340186327407
total_rewards_max            833.2392770877774
total_rewards_min            470.91922956610233
Number of train steps total  140000
Number of env steps total    105755
Number of rollouts total     0
Train Time (s)               138.36994240107015
(Previous) Eval Time (s)     4.358046184293926
Sample Time (s)              6.778028749860823
Epoch Time (s)               149.5060173352249
Total Train Time (s)         5202.709143980406
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:56:22.930669 UTC | [2020_01_10_09_29_40] Iteration #34 | Epoch Duration: 149.5923409461975
2020-01-10 10:56:22.930932 UTC | [2020_01_10_09_29_40] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032447927
Z variance train             0.002352166
KL Divergence                13.548632
KL Loss                      1.3548632
QF Loss                      2032.571
VF Loss                      205.41718
Policy Loss                  -774.8781
Q Predictions Mean           779.5047
Q Predictions Std            230.41977
Q Predictions Max            1073.2329
Q Predictions Min            -25.925419
V Predictions Mean           783.8245
V Predictions Std            228.53098
V Predictions Max            1084.9484
V Predictions Min            -45.04214
Log Pis Mean                 0.84799945
Log Pis Std                  2.5902417
Log Pis Max                  12.8405485
Log Pis Min                  -6.6547565
Policy mu Mean               0.27647972
Policy mu Std                1.0769887
Policy mu Max                3.8577523
Policy mu Min                -2.8726423
Policy log std Mean          -0.6319821
Policy log std Std           0.31178
Policy log std Max           0.23351386
Policy log std Min           -2.768075
Z mean eval                  0.05196734
Z variance eval              0.0028760883
total_rewards                [634.15780165 637.05453479 647.1357657  614.26938834 575.83864049
 623.45667243 670.7981979  610.01199136 633.21272314 657.61294095]
total_rewards_mean           630.354865675382
total_rewards_std            25.33763727710832
total_rewards_max            670.7981979006394
total_rewards_min            575.8386404874698
Number of train steps total  144000
Number of env steps total    109083
Number of rollouts total     0
Train Time (s)               139.62612588796765
(Previous) Eval Time (s)     4.496467679273337
Sample Time (s)              7.118986285757273
Epoch Time (s)               151.24157985299826
Total Train Time (s)         5354.055793872103
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:58:54.276474 UTC | [2020_01_10_09_29_40] Iteration #35 | Epoch Duration: 151.3454291820526
2020-01-10 10:58:54.276601 UTC | [2020_01_10_09_29_40] Iteration #35 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05086134
Z variance train             0.0028743378
KL Divergence                12.858744
KL Loss                      1.2858744
QF Loss                      899.59973
VF Loss                      386.76868
Policy Loss                  -830.983
Q Predictions Mean           821.0658
Q Predictions Std            210.66978
Q Predictions Max            1168.5471
Q Predictions Min            16.749548
V Predictions Mean           826.6135
V Predictions Std            207.61095
V Predictions Max            1163.1921
V Predictions Min            -48.61529
Log Pis Mean                 1.374108
Log Pis Std                  2.4295948
Log Pis Max                  11.951122
Log Pis Min                  -4.166765
Policy mu Mean               0.46522865
Policy mu Std                1.1308428
Policy mu Max                3.6663213
Policy mu Min                -2.640326
Policy log std Mean          -0.65242934
Policy log std Std           0.28328443
Policy log std Max           0.15013874
Policy log std Min           -1.925494
Z mean eval                  0.03184328
Z variance eval              0.0033775314
total_rewards                [657.00542532 719.90521566 656.90353728 714.05713388 684.9859351
 720.25539211 872.95551647 844.16034956 709.10732415 678.8564892 ]
total_rewards_mean           725.8192318720113
total_rewards_std            70.35257163113782
total_rewards_max            872.9555164725891
total_rewards_min            656.9035372761462
Number of train steps total  148000
Number of env steps total    112686
Number of rollouts total     0
Train Time (s)               139.67789918603376
(Previous) Eval Time (s)     5.358344011940062
Sample Time (s)              7.482357904780656
Epoch Time (s)               152.51860110275447
Total Train Time (s)         5506.651552236173
Epoch                        36
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:01:26.873071 UTC | [2020_01_10_09_29_40] Iteration #36 | Epoch Duration: 152.59638166427612
2020-01-10 11:01:26.873199 UTC | [2020_01_10_09_29_40] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034984995
Z variance train             0.0033807233
KL Divergence                12.135107
KL Loss                      1.2135108
QF Loss                      739.3843
VF Loss                      662.7654
Policy Loss                  -816.47266
Q Predictions Mean           804.10974
Q Predictions Std            274.7477
Q Predictions Max            1149.3254
Q Predictions Min            -157.08357
V Predictions Mean           821.4805
V Predictions Std            251.76715
V Predictions Max            1143.0598
V Predictions Min            -26.981262
Log Pis Mean                 1.281504
Log Pis Std                  2.7246354
Log Pis Max                  11.47748
Log Pis Min                  -4.2365403
Policy mu Mean               0.26941264
Policy mu Std                1.1460068
Policy mu Max                3.6869256
Policy mu Min                -3.012434
Policy log std Mean          -0.6265441
Policy log std Std           0.29481488
Policy log std Max           0.27764785
Policy log std Min           -2.120082
Z mean eval                  0.030261865
Z variance eval              0.0025585128
total_rewards                [606.77116324 646.63105158 676.85404521 592.77299249 685.327147
 685.28712502 670.9669054  694.43552267 678.45551596 595.80233952]
total_rewards_mean           653.3303808097922
total_rewards_std            37.973222148330336
total_rewards_max            694.4355226666294
total_rewards_min            592.7729924942091
Number of train steps total  152000
Number of env steps total    115822
Number of rollouts total     0
Train Time (s)               138.66863742098212
(Previous) Eval Time (s)     4.056883126031607
Sample Time (s)              6.501767192967236
Epoch Time (s)               149.22728773998097
Total Train Time (s)         5655.95483487891
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:03:56.177115 UTC | [2020_01_10_09_29_40] Iteration #37 | Epoch Duration: 149.30382800102234
2020-01-10 11:03:56.177229 UTC | [2020_01_10_09_29_40] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030450026
Z variance train             0.0025557415
KL Divergence                12.90583
KL Loss                      1.290583
QF Loss                      1840.501
VF Loss                      518.5137
Policy Loss                  -854.39044
Q Predictions Mean           835.2877
Q Predictions Std            262.78223
Q Predictions Max            1156.7424
Q Predictions Min            -109.89623
V Predictions Mean           847.98706
V Predictions Std            240.70198
V Predictions Max            1167.7498
V Predictions Min            -155.66197
Log Pis Mean                 1.1793625
Log Pis Std                  2.546174
Log Pis Max                  17.567448
Log Pis Min                  -4.6652336
Policy mu Mean               0.16616085
Policy mu Std                1.1962894
Policy mu Max                5.112097
Policy mu Min                -3.8455389
Policy log std Mean          -0.64380056
Policy log std Std           0.29154322
Policy log std Max           0.2664221
Policy log std Min           -1.7699637
Z mean eval                  0.043351114
Z variance eval              0.0032149106
total_rewards                [623.86009336 891.19326761 791.94444193 645.81766836 752.70413676
 685.13567143 672.66094368 639.18113457 659.80094413 682.16413314]
total_rewards_mean           704.4462434964223
total_rewards_std            79.32406982793698
total_rewards_max            891.1932676052745
total_rewards_min            623.8600933566562
Number of train steps total  156000
Number of env steps total    119358
Number of rollouts total     0
Train Time (s)               140.80566021893173
(Previous) Eval Time (s)     4.565220232121646
Sample Time (s)              6.5624375701881945
Epoch Time (s)               151.93331802124158
Total Train Time (s)         5807.967789594084
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:06:28.191294 UTC | [2020_01_10_09_29_40] Iteration #38 | Epoch Duration: 152.0139491558075
2020-01-10 11:06:28.191517 UTC | [2020_01_10_09_29_40] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04049138
Z variance train             0.003220915
KL Divergence                12.755089
KL Loss                      1.2755089
QF Loss                      2074.0874
VF Loss                      135.10446
Policy Loss                  -893.7582
Q Predictions Mean           880.7468
Q Predictions Std            252.96812
Q Predictions Max            1143.2686
Q Predictions Min            -14.680982
V Predictions Mean           891.96436
V Predictions Std            237.06201
V Predictions Max            1149.6495
V Predictions Min            11.611373
Log Pis Mean                 1.1251798
Log Pis Std                  2.1634436
Log Pis Max                  8.938961
Log Pis Min                  -3.8552628
Policy mu Mean               0.17523177
Policy mu Std                1.1442451
Policy mu Max                3.2294428
Policy mu Min                -2.654126
Policy log std Mean          -0.6392656
Policy log std Std           0.3033484
Policy log std Max           0.28441346
Policy log std Min           -2.2561429
Z mean eval                  0.024757927
Z variance eval              0.0027461608
total_rewards                [363.6718224  353.41237299 355.47789869 855.08940847 830.66149897
 357.30099892 856.72706724 355.47854274 629.75348347 362.35141045]
total_rewards_mean           531.9924504328285
total_rewards_std            221.4581328198552
total_rewards_max            856.7270672407761
total_rewards_min            353.4123729873533
Number of train steps total  160000
Number of env steps total    122522
Number of rollouts total     0
Train Time (s)               137.98338160896674
(Previous) Eval Time (s)     4.241069294977933
Sample Time (s)              6.407505227718502
Epoch Time (s)               148.63195613166317
Total Train Time (s)         5956.686701967847
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:08:56.911046 UTC | [2020_01_10_09_29_40] Iteration #39 | Epoch Duration: 148.71938228607178
2020-01-10 11:08:56.911169 UTC | [2020_01_10_09_29_40] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023244869
Z variance train             0.002748135
KL Divergence                12.695986
KL Loss                      1.2695986
QF Loss                      700.39307
VF Loss                      902.7031
Policy Loss                  -882.1762
Q Predictions Mean           868.5233
Q Predictions Std            293.4361
Q Predictions Max            1160.15
Q Predictions Min            -14.690856
V Predictions Mean           872.15686
V Predictions Std            282.4774
V Predictions Max            1161.9314
V Predictions Min            -13.536118
Log Pis Mean                 1.1449611
Log Pis Std                  2.589293
Log Pis Max                  12.13542
Log Pis Min                  -5.9912276
Policy mu Mean               0.038727302
Policy mu Std                1.1621426
Policy mu Max                3.5596354
Policy mu Min                -2.8063078
Policy log std Mean          -0.63698816
Policy log std Std           0.34062368
Policy log std Max           0.40139627
Policy log std Min           -2.7280152
Z mean eval                  0.04342369
Z variance eval              0.003562282
total_rewards                [662.73717419 824.61744307 445.4826808  361.83476332 843.47602794
 917.76900513 615.34567686 689.93885121 673.57097638 544.14653851]
total_rewards_mean           657.891913742091
total_rewards_std            166.90925533752056
total_rewards_max            917.7690051336184
total_rewards_min            361.83476332104897
Number of train steps total  164000
Number of env steps total    126225
Number of rollouts total     0
Train Time (s)               139.46294754976407
(Previous) Eval Time (s)     4.054842187091708
Sample Time (s)              7.207306861877441
Epoch Time (s)               150.72509659873322
Total Train Time (s)         6107.55579788005
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:11:27.781859 UTC | [2020_01_10_09_29_40] Iteration #40 | Epoch Duration: 150.8705849647522
2020-01-10 11:11:27.782042 UTC | [2020_01_10_09_29_40] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043142818
Z variance train             0.003568108
KL Divergence                13.298447
KL Loss                      1.3298447
QF Loss                      792.91895
VF Loss                      963.13983
Policy Loss                  -909.9162
Q Predictions Mean           904.33813
Q Predictions Std            267.84525
Q Predictions Max            1299.5619
Q Predictions Min            -7.5478415
V Predictions Mean           915.421
V Predictions Std            245.89049
V Predictions Max            1297.0153
V Predictions Min            34.4822
Log Pis Mean                 1.3123243
Log Pis Std                  2.7998605
Log Pis Max                  13.621138
Log Pis Min                  -7.558605
Policy mu Mean               0.27945086
Policy mu Std                1.1672921
Policy mu Max                4.003224
Policy mu Min                -3.0425496
Policy log std Mean          -0.63895535
Policy log std Std           0.30521506
Policy log std Max           0.3113783
Policy log std Min           -2.0556347
Z mean eval                  0.03826692
Z variance eval              0.003017558
total_rewards                [ 376.66804635  442.54484052 1190.67480515  681.47000127  377.91091296
  423.80950723  815.96633684  907.76490395  538.17497698  380.79951936]
total_rewards_mean           613.5783850591386
total_rewards_std            264.9449341208303
total_rewards_max            1190.6748051460659
total_rewards_min            376.6680463471835
Number of train steps total  168000
Number of env steps total    130039
Number of rollouts total     0
Train Time (s)               139.05574317183346
(Previous) Eval Time (s)     3.9012257107533514
Sample Time (s)              6.64861294394359
Epoch Time (s)               149.6055818265304
Total Train Time (s)         6257.239013245329
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:13:57.468347 UTC | [2020_01_10_09_29_40] Iteration #41 | Epoch Duration: 149.6861548423767
2020-01-10 11:13:57.468575 UTC | [2020_01_10_09_29_40] Iteration #41 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04032649
Z variance train             0.0030240584
KL Divergence                13.027102
KL Loss                      1.3027103
QF Loss                      829.05963
VF Loss                      208.29018
Policy Loss                  -916.7536
Q Predictions Mean           905.5034
Q Predictions Std            299.65442
Q Predictions Max            1302.6335
Q Predictions Min            -56.894913
V Predictions Mean           911.84985
V Predictions Std            269.92474
V Predictions Max            1296.6016
V Predictions Min            -1.7343922
Log Pis Mean                 1.0316557
Log Pis Std                  2.5992448
Log Pis Max                  11.921294
Log Pis Min                  -4.649432
Policy mu Mean               0.20163341
Policy mu Std                1.1243632
Policy mu Max                4.0726
Policy mu Min                -3.1813526
Policy log std Mean          -0.68670344
Policy log std Std           0.32087898
Policy log std Max           0.049241304
Policy log std Min           -3.4248133
Z mean eval                  0.03644258
Z variance eval              0.0024535046
total_rewards                [882.54512835 743.80858908 761.61775867 961.33619698 818.94724933
 973.76264498 542.82619903 908.96519412 779.21782288 987.36076758]
total_rewards_mean           836.0387551001492
total_rewards_std            129.8406745542356
total_rewards_max            987.3607675781104
total_rewards_min            542.8261990283295
Number of train steps total  172000
Number of env steps total    133566
Number of rollouts total     0
Train Time (s)               139.23859356576577
(Previous) Eval Time (s)     5.169295446015894
Sample Time (s)              7.025057247839868
Epoch Time (s)               151.43294625962153
Total Train Time (s)         6408.77000642661
Epoch                        42
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:16:28.998347 UTC | [2020_01_10_09_29_40] Iteration #42 | Epoch Duration: 151.52962517738342
2020-01-10 11:16:28.998475 UTC | [2020_01_10_09_29_40] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039731096
Z variance train             0.0024489753
KL Divergence                13.78622
KL Loss                      1.3786219
QF Loss                      652.8738
VF Loss                      1413.4591
Policy Loss                  -933.0801
Q Predictions Mean           926.6161
Q Predictions Std            252.3286
Q Predictions Max            1286.9037
Q Predictions Min            -86.44974
V Predictions Mean           929.30444
V Predictions Std            236.69215
V Predictions Max            1268.6134
V Predictions Min            32.19725
Log Pis Mean                 0.72309726
Log Pis Std                  2.467003
Log Pis Max                  10.263607
Log Pis Min                  -7.8086276
Policy mu Mean               0.042119816
Policy mu Std                1.0997925
Policy mu Max                3.311737
Policy mu Min                -2.6629248
Policy log std Mean          -0.5874869
Policy log std Std           0.2898962
Policy log std Max           0.18885976
Policy log std Min           -1.7918079
Z mean eval                  0.03956414
Z variance eval              0.0035593442
total_rewards                [ 726.4748119   807.00282594 1728.32902192  711.57042292 1214.30590318
  861.58697307 1491.64928439  730.58704567  664.81845877 1524.25795726]
total_rewards_mean           1046.0582705030943
total_rewards_std            383.5473499198204
total_rewards_max            1728.329021919073
total_rewards_min            664.8184587692
Number of train steps total  176000
Number of env steps total    137211
Number of rollouts total     0
Train Time (s)               141.237635016907
(Previous) Eval Time (s)     6.723369484767318
Sample Time (s)              7.5249558333307505
Epoch Time (s)               155.48596033500507
Total Train Time (s)         6564.465401235037
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:19:04.695457 UTC | [2020_01_10_09_29_40] Iteration #43 | Epoch Duration: 155.6968765258789
2020-01-10 11:19:04.695641 UTC | [2020_01_10_09_29_40] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042487755
Z variance train             0.003549007
KL Divergence                13.253416
KL Loss                      1.3253416
QF Loss                      1609.2559
VF Loss                      201.06107
Policy Loss                  -907.71295
Q Predictions Mean           905.2123
Q Predictions Std            244.35811
Q Predictions Max            1260.9196
Q Predictions Min            7.5978465
V Predictions Mean           901.46155
V Predictions Std            239.24316
V Predictions Max            1251.0466
V Predictions Min            24.61223
Log Pis Mean                 1.1498653
Log Pis Std                  2.416705
Log Pis Max                  10.167718
Log Pis Min                  -5.749485
Policy mu Mean               0.10669008
Policy mu Std                1.1323423
Policy mu Max                3.9641645
Policy mu Min                -2.8392367
Policy log std Mean          -0.66906404
Policy log std Std           0.30292067
Policy log std Max           0.027840734
Policy log std Min           -3.1027753
Z mean eval                  0.073372245
Z variance eval              0.0038559088
total_rewards                [ 981.60156189  477.25682762  942.2791267  1029.24232557 1231.03461007
  942.90364649  920.7937292  1007.51659916  702.49065935  549.13191169]
total_rewards_mean           878.4250997718825
total_rewards_std            220.1686022183702
total_rewards_max            1231.034610065126
total_rewards_min            477.25682761799374
Number of train steps total  180000
Number of env steps total    140575
Number of rollouts total     0
Train Time (s)               141.37916680425406
(Previous) Eval Time (s)     6.7004926460795105
Sample Time (s)              5.668296518269926
Epoch Time (s)               153.7479559686035
Total Train Time (s)         6718.295012266841
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:21:38.526043 UTC | [2020_01_10_09_29_40] Iteration #44 | Epoch Duration: 153.83023715019226
2020-01-10 11:21:38.526255 UTC | [2020_01_10_09_29_40] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.070542455
Z variance train             0.003858226
KL Divergence                12.780369
KL Loss                      1.278037
QF Loss                      1240.1537
VF Loss                      437.2218
Policy Loss                  -897.82416
Q Predictions Mean           880.50885
Q Predictions Std            265.52963
Q Predictions Max            1246.314
Q Predictions Min            11.241063
V Predictions Mean           896.5558
V Predictions Std            247.88635
V Predictions Max            1242.9337
V Predictions Min            17.505404
Log Pis Mean                 1.3924344
Log Pis Std                  2.5783026
Log Pis Max                  12.15638
Log Pis Min                  -5.7628126
Policy mu Mean               0.19602759
Policy mu Std                1.1763527
Policy mu Max                3.6326663
Policy mu Min                -3.3030005
Policy log std Mean          -0.65853393
Policy log std Std           0.31814328
Policy log std Max           0.07123411
Policy log std Min           -3.0085847
Z mean eval                  0.0363576
Z variance eval              0.0020153183
total_rewards                [ 899.46867713  996.24275087 1076.49785026  736.28693189 1006.03582398
  697.74276433 1000.90351065  670.17647502  595.69494458 1030.26274032]
total_rewards_mean           870.9312469037492
total_rewards_std            168.37113465992877
total_rewards_max            1076.4978502642193
total_rewards_min            595.6949445757534
Number of train steps total  184000
Number of env steps total    144101
Number of rollouts total     0
Train Time (s)               139.60962637327611
(Previous) Eval Time (s)     6.800241536926478
Sample Time (s)              6.084692585282028
Epoch Time (s)               152.49456049548462
Total Train Time (s)         6870.879656253848
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:24:11.111830 UTC | [2020_01_10_09_29_40] Iteration #45 | Epoch Duration: 152.58546209335327
2020-01-10 11:24:11.111966 UTC | [2020_01_10_09_29_40] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036599893
Z variance train             0.0020153583
KL Divergence                13.761579
KL Loss                      1.3761579
QF Loss                      3398.2773
VF Loss                      204.54347
Policy Loss                  -882.1236
Q Predictions Mean           875.7126
Q Predictions Std            266.39832
Q Predictions Max            1279.7241
Q Predictions Min            -7.8820615
V Predictions Mean           883.6481
V Predictions Std            258.5187
V Predictions Max            1284.2026
V Predictions Min            -26.755663
Log Pis Mean                 1.1341972
Log Pis Std                  2.6811252
Log Pis Max                  11.825546
Log Pis Min                  -5.9940357
Policy mu Mean               -0.079026945
Policy mu Std                1.1869143
Policy mu Max                3.6987858
Policy mu Min                -3.8326912
Policy log std Mean          -0.627777
Policy log std Std           0.31063792
Policy log std Max           0.15455961
Policy log std Min           -2.3686402
Z mean eval                  0.018124316
Z variance eval              0.004221603
total_rewards                [ 704.31397918  933.34001796 1823.15016351  714.18858865  745.67313207
 1276.95775768 1496.66772008  707.12032523  730.00342856 1161.97761359]
total_rewards_mean           1029.3392726500388
total_rewards_std            376.23266480991055
total_rewards_max            1823.1501635065868
total_rewards_min            704.3139791788386
Number of train steps total  188000
Number of env steps total    147765
Number of rollouts total     0
Train Time (s)               139.2952273930423
(Previous) Eval Time (s)     7.916346844751388
Sample Time (s)              7.26875447621569
Epoch Time (s)               154.48032871400937
Total Train Time (s)         7025.449835183565
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:26:45.683582 UTC | [2020_01_10_09_29_40] Iteration #46 | Epoch Duration: 154.57146978378296
2020-01-10 11:26:45.683782 UTC | [2020_01_10_09_29_40] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019814754
Z variance train             0.0042104307
KL Divergence                12.950669
KL Loss                      1.295067
QF Loss                      597.7114
VF Loss                      89.71373
Policy Loss                  -882.2038
Q Predictions Mean           878.8594
Q Predictions Std            288.35468
Q Predictions Max            1322.1128
Q Predictions Min            -69.657455
V Predictions Mean           880.77466
V Predictions Std            278.69806
V Predictions Max            1309.5077
V Predictions Min            13.2411
Log Pis Mean                 0.77338934
Log Pis Std                  2.0603378
Log Pis Max                  9.917536
Log Pis Min                  -5.445471
Policy mu Mean               0.064493485
Policy mu Std                1.0964158
Policy mu Max                3.2534966
Policy mu Min                -2.8367968
Policy log std Mean          -0.6001825
Policy log std Std           0.28191358
Policy log std Max           0.101747155
Policy log std Min           -3.0166416
Z mean eval                  0.033671085
Z variance eval              0.0029426639
total_rewards                [ 931.12313612  963.62894431 1146.19975651  911.82558711  791.20994885
  954.83050552  709.23745309 1926.04044155  759.20070107  756.85837445]
total_rewards_mean           985.0154848585
total_rewards_std            337.31292507392925
total_rewards_max            1926.0404415471135
total_rewards_min            709.237453090029
Number of train steps total  192000
Number of env steps total    151148
Number of rollouts total     0
Train Time (s)               140.1739123701118
(Previous) Eval Time (s)     6.1564038950018585
Sample Time (s)              6.448143277782947
Epoch Time (s)               152.7784595428966
Total Train Time (s)         7178.307473467197
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:29:18.545252 UTC | [2020_01_10_09_29_40] Iteration #47 | Epoch Duration: 152.8613166809082
2020-01-10 11:29:18.545523 UTC | [2020_01_10_09_29_40] Iteration #47 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034392867
Z variance train             0.0029532455
KL Divergence                12.375668
KL Loss                      1.2375668
QF Loss                      756.0719
VF Loss                      287.1943
Policy Loss                  -906.424
Q Predictions Mean           899.9169
Q Predictions Std            275.83386
Q Predictions Max            1269.5077
Q Predictions Min            53.882473
V Predictions Mean           899.058
V Predictions Std            271.71692
V Predictions Max            1270.7386
V Predictions Min            22.717093
Log Pis Mean                 0.7713306
Log Pis Std                  2.2932975
Log Pis Max                  9.407715
Log Pis Min                  -7.2526464
Policy mu Mean               0.213142
Policy mu Std                1.0633307
Policy mu Max                3.5326238
Policy mu Min                -2.8771262
Policy log std Mean          -0.5995985
Policy log std Std           0.28153825
Policy log std Max           0.12048745
Policy log std Min           -1.8401368
Z mean eval                  0.008987236
Z variance eval              0.0021190438
total_rewards                [677.96614605 699.65506997 752.28015707 679.36206266 694.3102646
 711.18868879 891.88396003 709.58360652 723.64665292 708.86482605]
total_rewards_mean           724.8741434659308
total_rewards_std            59.29934878101485
total_rewards_max            891.8839600311364
total_rewards_min            677.9661460478204
Number of train steps total  196000
Number of env steps total    154718
Number of rollouts total     0
Train Time (s)               139.40834825718775
(Previous) Eval Time (s)     5.025453311391175
Sample Time (s)              7.135933991521597
Epoch Time (s)               151.56973556010053
Total Train Time (s)         7329.957077939063
Epoch                        48
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:31:50.197548 UTC | [2020_01_10_09_29_40] Iteration #48 | Epoch Duration: 151.6517734527588
2020-01-10 11:31:50.197874 UTC | [2020_01_10_09_29_40] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009482166
Z variance train             0.0021204676
KL Divergence                13.08989
KL Loss                      1.3089889
QF Loss                      5158.1284
VF Loss                      280.60498
Policy Loss                  -883.0667
Q Predictions Mean           871.3904
Q Predictions Std            294.23007
Q Predictions Max            1234.5127
Q Predictions Min            -53.53398
V Predictions Mean           883.2461
V Predictions Std            280.05972
V Predictions Max            1216.1794
V Predictions Min            -26.7842
Log Pis Mean                 1.1514523
Log Pis Std                  2.3402834
Log Pis Max                  9.7230835
Log Pis Min                  -4.554948
Policy mu Mean               0.25146616
Policy mu Std                1.0977415
Policy mu Max                3.7579482
Policy mu Min                -2.5294871
Policy log std Mean          -0.6453459
Policy log std Std           0.30845344
Policy log std Max           0.10594696
Policy log std Min           -2.7581606
Z mean eval                  0.030276423
Z variance eval              0.003523526
total_rewards                [688.0663926  735.85718206 782.40083073 684.05376046 713.83724755
 729.30736042 694.69097544 699.22865388 690.58917611 689.17529496]
total_rewards_mean           710.7206874202822
total_rewards_std            29.339232981331207
total_rewards_max            782.400830727212
total_rewards_min            684.0537604619049
Number of train steps total  200000
Number of env steps total    158202
Number of rollouts total     0
Train Time (s)               140.69717314699665
(Previous) Eval Time (s)     4.932626110967249
Sample Time (s)              6.006677282974124
Epoch Time (s)               151.63647654093802
Total Train Time (s)         7481.67430957919
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:34:21.914247 UTC | [2020_01_10_09_29_40] Iteration #49 | Epoch Duration: 151.71615195274353
2020-01-10 11:34:21.914433 UTC | [2020_01_10_09_29_40] Iteration #49 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033299856
Z variance train             0.0035210936
KL Divergence                12.404747
KL Loss                      1.2404747
QF Loss                      1143.5415
VF Loss                      599.75574
Policy Loss                  -888.47235
Q Predictions Mean           870.47034
Q Predictions Std            300.94073
Q Predictions Max            1241.2721
Q Predictions Min            -22.771814
V Predictions Mean           879.2261
V Predictions Std            271.91608
V Predictions Max            1233.8351
V Predictions Min            57.450912
Log Pis Mean                 0.8181151
Log Pis Std                  2.4524148
Log Pis Max                  10.5244665
Log Pis Min                  -5.4393635
Policy mu Mean               0.28403473
Policy mu Std                1.1094072
Policy mu Max                3.243487
Policy mu Min                -2.5889833
Policy log std Mean          -0.62418073
Policy log std Std           0.28214997
Policy log std Max           0.18189186
Policy log std Min           -2.2801325
Z mean eval                  0.030032676
Z variance eval              0.0022880437
total_rewards                [719.98607582 949.08503653 782.02985288 810.64975127 689.90720414
 825.88075147 908.42914914 954.29034681 924.51614761 720.75886598]
total_rewards_mean           828.5533181661804
total_rewards_std            95.41910533196055
total_rewards_max            954.2903468125645
total_rewards_min            689.9072041424907
Number of train steps total  204000
Number of env steps total    161737
Number of rollouts total     0
Train Time (s)               138.7346256133169
(Previous) Eval Time (s)     4.835234312340617
Sample Time (s)              6.109054338186979
Epoch Time (s)               149.6789142638445
Total Train Time (s)         7631.434498058166
Epoch                        50
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:36:51.677017 UTC | [2020_01_10_09_29_40] Iteration #50 | Epoch Duration: 149.7624433040619
2020-01-10 11:36:51.677221 UTC | [2020_01_10_09_29_40] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03071021
Z variance train             0.0022903353
KL Divergence                12.901882
KL Loss                      1.2901882
QF Loss                      2033.3889
VF Loss                      310.4286
Policy Loss                  -927.02844
Q Predictions Mean           925.8641
Q Predictions Std            277.12933
Q Predictions Max            1269.0485
Q Predictions Min            -64.99431
V Predictions Mean           921.2961
V Predictions Std            268.10703
V Predictions Max            1263.6063
V Predictions Min            -53.184593
Log Pis Mean                 0.66912556
Log Pis Std                  2.5770442
Log Pis Max                  14.701871
Log Pis Min                  -5.6885414
Policy mu Mean               0.24947888
Policy mu Std                1.0559316
Policy mu Max                3.7816358
Policy mu Min                -3.2913074
Policy log std Mean          -0.592401
Policy log std Std           0.2935225
Policy log std Max           0.25842023
Policy log std Min           -2.567842
Z mean eval                  0.044745456
Z variance eval              0.0024693613
total_rewards                [ 735.83425353  808.66831127 1374.71559915  733.63203144  889.71801467
  988.59794389   98.02863232   90.7096753   989.82355794  793.41964513]
total_rewards_mean           750.3147664637099
total_rewards_std            372.79488221574445
total_rewards_max            1374.7155991485165
total_rewards_min            90.70967529520722
Number of train steps total  208000
Number of env steps total    165109
Number of rollouts total     0
Train Time (s)               139.80695126205683
(Previous) Eval Time (s)     4.9664138914085925
Sample Time (s)              6.096222434658557
Epoch Time (s)               150.86958758812398
Total Train Time (s)         7782.380327531137
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:39:22.623912 UTC | [2020_01_10_09_29_40] Iteration #51 | Epoch Duration: 150.94654250144958
2020-01-10 11:39:22.624090 UTC | [2020_01_10_09_29_40] Iteration #51 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04445533
Z variance train             0.0024640225
KL Divergence                12.893078
KL Loss                      1.2893078
QF Loss                      4988.8164
VF Loss                      646.37054
Policy Loss                  -910.23065
Q Predictions Mean           903.51385
Q Predictions Std            309.4912
Q Predictions Max            1274.3171
Q Predictions Min            -53.91571
V Predictions Mean           914.6278
V Predictions Std            297.17548
V Predictions Max            1332.6903
V Predictions Min            -3.5804744
Log Pis Mean                 0.69237375
Log Pis Std                  2.2823303
Log Pis Max                  10.110413
Log Pis Min                  -5.6342025
Policy mu Mean               0.20269199
Policy mu Std                1.0506145
Policy mu Max                3.2632246
Policy mu Min                -2.4469934
Policy log std Mean          -0.6195877
Policy log std Std           0.30048105
Policy log std Max           0.19442397
Policy log std Min           -2.3583677
Z mean eval                  0.019457258
Z variance eval              0.003920579
total_rewards                [3058.38281677 1494.48337664  352.08468993  186.43281961  147.4998667
 2181.13776308  732.32331948  131.3498526   118.73922831  816.70048781]
total_rewards_mean           921.9134220950755
total_rewards_std            962.311297610625
total_rewards_max            3058.382816773701
total_rewards_min            118.73922830843244
Number of train steps total  212000
Number of env steps total    168508
Number of rollouts total     0
Train Time (s)               140.4611156862229
(Previous) Eval Time (s)     6.129356657620519
Sample Time (s)              6.577186910435557
Epoch Time (s)               153.167659254279
Total Train Time (s)         7935.628228981979
Epoch                        52
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:41:55.873683 UTC | [2020_01_10_09_29_40] Iteration #52 | Epoch Duration: 153.24940156936646
2020-01-10 11:41:55.873944 UTC | [2020_01_10_09_29_40] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017736327
Z variance train             0.003936933
KL Divergence                12.171749
KL Loss                      1.2171749
QF Loss                      1223.4004
VF Loss                      181.22144
Policy Loss                  -956.65875
Q Predictions Mean           946.0856
Q Predictions Std            260.64914
Q Predictions Max            1269.853
Q Predictions Min            13.545888
V Predictions Mean           962.1962
V Predictions Std            238.94316
V Predictions Max            1275.3198
V Predictions Min            14.226171
Log Pis Mean                 0.9685199
Log Pis Std                  2.6214652
Log Pis Max                  10.259103
Log Pis Min                  -5.4604855
Policy mu Mean               0.23283923
Policy mu Std                1.0982914
Policy mu Max                3.5034733
Policy mu Min                -2.8898108
Policy log std Mean          -0.639677
Policy log std Std           0.29959092
Policy log std Max           0.032764852
Policy log std Min           -3.3817272
Z mean eval                  0.038310654
Z variance eval              0.0036024034
total_rewards                [ 735.29043236 3176.02738719  756.65817402 1453.98880481 1016.26587678
  969.43345462 1289.12205768 1265.85747427  865.37374479 1017.90066795]
total_rewards_mean           1254.5918074467972
total_rewards_std            677.9552238738036
total_rewards_max            3176.0273871873774
total_rewards_min            735.2904323578148
Number of train steps total  216000
Number of env steps total    172395
Number of rollouts total     0
Train Time (s)               139.88129767868668
(Previous) Eval Time (s)     8.62191091105342
Sample Time (s)              7.550616460386664
Epoch Time (s)               156.05382505012676
Total Train Time (s)         8091.768132032361
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:44:32.016997 UTC | [2020_01_10_09_29_40] Iteration #53 | Epoch Duration: 156.1428837776184
2020-01-10 11:44:32.017247 UTC | [2020_01_10_09_29_40] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03793789
Z variance train             0.0036082747
KL Divergence                11.927291
KL Loss                      1.1927291
QF Loss                      347.71344
VF Loss                      220.59909
Policy Loss                  -943.8136
Q Predictions Mean           938.21655
Q Predictions Std            286.93005
Q Predictions Max            1257.0155
Q Predictions Min            -3.6803687
V Predictions Mean           946.5582
V Predictions Std            275.53958
V Predictions Max            1261.3699
V Predictions Min            15.796447
Log Pis Mean                 1.0526093
Log Pis Std                  2.6647487
Log Pis Max                  10.822327
Log Pis Min                  -5.350587
Policy mu Mean               0.24295028
Policy mu Std                1.14614
Policy mu Max                3.4366004
Policy mu Min                -3.339121
Policy log std Mean          -0.6094056
Policy log std Std           0.3244315
Policy log std Max           0.17200324
Policy log std Min           -3.5741696
Z mean eval                  0.03572054
Z variance eval              0.003481491
total_rewards                [1192.52735007  853.5091567   842.04146896 2429.57745722 2421.00591297
  831.11992868 1489.05060975  736.11145665 1610.24261551  765.62045433]
total_rewards_mean           1317.0806410842217
total_rewards_std            624.9546694371519
total_rewards_max            2429.5774572192577
total_rewards_min            736.1114566491065
Number of train steps total  220000
Number of env steps total    175759
Number of rollouts total     0
Train Time (s)               139.13560341577977
(Previous) Eval Time (s)     7.586012088228017
Sample Time (s)              6.345489278901368
Epoch Time (s)               153.06710478290915
Total Train Time (s)         8244.92031683214
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:47:05.169832 UTC | [2020_01_10_09_29_40] Iteration #54 | Epoch Duration: 153.1523597240448
2020-01-10 11:47:05.170100 UTC | [2020_01_10_09_29_40] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034675457
Z variance train             0.003490898
KL Divergence                12.103256
KL Loss                      1.2103256
QF Loss                      692.2504
VF Loss                      207.99745
Policy Loss                  -924.4157
Q Predictions Mean           914.79095
Q Predictions Std            295.40735
Q Predictions Max            1307.5156
Q Predictions Min            -102.575714
V Predictions Mean           919.53516
V Predictions Std            288.58435
V Predictions Max            1279.4476
V Predictions Min            18.231707
Log Pis Mean                 0.8871144
Log Pis Std                  2.4630075
Log Pis Max                  12.225325
Log Pis Min                  -4.9938574
Policy mu Mean               0.025151297
Policy mu Std                1.103871
Policy mu Max                3.8267326
Policy mu Min                -3.1061935
Policy log std Mean          -0.62237835
Policy log std Std           0.29530835
Policy log std Max           -0.004916489
Policy log std Min           -2.2995129
Z mean eval                  0.030425007
Z variance eval              0.003297915
total_rewards                [ 730.86955697 1559.29420324  752.07246609 3200.51004482 1051.73752053
 1196.42358929  893.13315265  726.8941484  1200.78078167  803.3885993 ]
total_rewards_mean           1211.5104062969676
total_rewards_std            710.480294780846
total_rewards_max            3200.5100448209455
total_rewards_min            726.8941484039947
Number of train steps total  224000
Number of env steps total    179128
Number of rollouts total     0
Train Time (s)               142.57293783407658
(Previous) Eval Time (s)     7.191546720918268
Sample Time (s)              6.511186075862497
Epoch Time (s)               156.27567063085735
Total Train Time (s)         8401.272594749928
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:49:41.522469 UTC | [2020_01_10_09_29_40] Iteration #55 | Epoch Duration: 156.35223412513733
2020-01-10 11:49:41.522609 UTC | [2020_01_10_09_29_40] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032342583
Z variance train             0.0032880132
KL Divergence                12.395399
KL Loss                      1.23954
QF Loss                      740.9232
VF Loss                      152.16763
Policy Loss                  -956.88513
Q Predictions Mean           950.16705
Q Predictions Std            282.76562
Q Predictions Max            1287.952
Q Predictions Min            -55.02372
V Predictions Mean           957.00494
V Predictions Std            272.85934
V Predictions Max            1292.2286
V Predictions Min            -17.748701
Log Pis Mean                 0.86733305
Log Pis Std                  2.2788584
Log Pis Max                  9.78297
Log Pis Min                  -4.148579
Policy mu Mean               0.13784957
Policy mu Std                1.082113
Policy mu Max                2.8756313
Policy mu Min                -2.8579638
Policy log std Mean          -0.6172505
Policy log std Std           0.28320685
Policy log std Max           0.08091688
Policy log std Min           -2.2929182
Z mean eval                  0.048235774
Z variance eval              0.0029696946
total_rewards                [1698.24103071  691.99405743  802.66253724  697.8895908   801.59428528
  744.26618966  694.21079747  742.88733837 1603.09097529  801.99790818]
total_rewards_mean           927.8834710415673
total_rewards_std            364.4057015291233
total_rewards_max            1698.241030705556
total_rewards_min            691.9940574289446
Number of train steps total  228000
Number of env steps total    182472
Number of rollouts total     0
Train Time (s)               140.61414786195382
(Previous) Eval Time (s)     6.149346847087145
Sample Time (s)              5.434314588084817
Epoch Time (s)               152.1978092971258
Total Train Time (s)         8553.549018225633
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:52:13.799921 UTC | [2020_01_10_09_29_40] Iteration #56 | Epoch Duration: 152.27719616889954
2020-01-10 11:52:13.800044 UTC | [2020_01_10_09_29_40] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045100927
Z variance train             0.0029713782
KL Divergence                12.414095
KL Loss                      1.2414095
QF Loss                      722.6645
VF Loss                      487.33002
Policy Loss                  -967.2951
Q Predictions Mean           961.9077
Q Predictions Std            275.28467
Q Predictions Max            1308.4175
Q Predictions Min            5.773146
V Predictions Mean           960.8137
V Predictions Std            264.6154
V Predictions Max            1279.4635
V Predictions Min            -8.254458
Log Pis Mean                 0.7376259
Log Pis Std                  2.4924517
Log Pis Max                  15.129505
Log Pis Min                  -5.3115153
Policy mu Mean               0.24743491
Policy mu Std                1.0659149
Policy mu Max                3.933467
Policy mu Min                -3.425062
Policy log std Mean          -0.61608464
Policy log std Std           0.30808467
Policy log std Max           0.036188245
Policy log std Min           -2.418387
Z mean eval                  0.03823559
Z variance eval              0.0036131933
total_rewards                [1328.53412514  885.10499777  751.24998169  835.2833752   778.24455191
  803.70890387 1167.39746165 1044.00949993  804.84860568  823.22088576]
total_rewards_mean           922.1602388607095
total_rewards_std            183.45373483182007
total_rewards_max            1328.5341251430336
total_rewards_min            751.2499816877761
Number of train steps total  232000
Number of env steps total    185831
Number of rollouts total     0
Train Time (s)               140.80614924803376
(Previous) Eval Time (s)     5.955232280306518
Sample Time (s)              6.295726431068033
Epoch Time (s)               153.0571079594083
Total Train Time (s)         8706.686023375485
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:54:46.937912 UTC | [2020_01_10_09_29_40] Iteration #57 | Epoch Duration: 153.13778138160706
2020-01-10 11:54:46.938032 UTC | [2020_01_10_09_29_40] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038721398
Z variance train             0.0036130273
KL Divergence                11.968126
KL Loss                      1.1968126
QF Loss                      468.5196
VF Loss                      161.9676
Policy Loss                  -972.3468
Q Predictions Mean           959.7238
Q Predictions Std            294.2459
Q Predictions Max            1315.0369
Q Predictions Min            -63.894413
V Predictions Mean           965.1063
V Predictions Std            270.5758
V Predictions Max            1304.5244
V Predictions Min            49.54632
Log Pis Mean                 1.1076967
Log Pis Std                  2.682425
Log Pis Max                  14.037739
Log Pis Min                  -6.785584
Policy mu Mean               0.22512163
Policy mu Std                1.1211836
Policy mu Max                4.228212
Policy mu Min                -3.0095508
Policy log std Mean          -0.61458915
Policy log std Std           0.3139695
Policy log std Max           0.124147594
Policy log std Min           -2.8057163
Z mean eval                  0.046979494
Z variance eval              0.0042097443
total_rewards                [ 737.95037198  706.7134228   847.03513691  725.47158615  792.58127091
  743.25568702  794.51095779  715.93446685  737.40621229 1301.95033279]
total_rewards_mean           810.2809445479486
total_rewards_std            168.96939636559927
total_rewards_max            1301.9503327876457
total_rewards_min            706.713422803445
Number of train steps total  236000
Number of env steps total    189190
Number of rollouts total     0
Train Time (s)               141.2257324140519
(Previous) Eval Time (s)     4.322743847034872
Sample Time (s)              6.451764902565628
Epoch Time (s)               152.0002411636524
Total Train Time (s)         8858.766607725061
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:57:19.021201 UTC | [2020_01_10_09_29_40] Iteration #58 | Epoch Duration: 152.08306431770325
2020-01-10 11:57:19.021385 UTC | [2020_01_10_09_29_40] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047530036
Z variance train             0.0041950615
KL Divergence                11.548876
KL Loss                      1.1548876
QF Loss                      380.72617
VF Loss                      82.96401
Policy Loss                  -997.0155
Q Predictions Mean           988.4795
Q Predictions Std            266.82556
Q Predictions Max            1296.9204
Q Predictions Min            77.300995
V Predictions Mean           995.72833
V Predictions Std            259.51974
V Predictions Max            1304.8154
V Predictions Min            73.250244
Log Pis Mean                 0.5211951
Log Pis Std                  2.2513118
Log Pis Max                  11.569361
Log Pis Min                  -4.233428
Policy mu Mean               0.16594976
Policy mu Std                1.0343003
Policy mu Max                2.885094
Policy mu Min                -2.5886042
Policy log std Mean          -0.6059374
Policy log std Std           0.28000832
Policy log std Max           0.12466353
Policy log std Min           -1.602066
Z mean eval                  0.03044733
Z variance eval              0.0031229344
total_rewards                [2394.48496976 3121.35914012 3052.9133924  1297.80924277  993.64839526
  778.79198648  882.42609733  768.70575    1234.98618452  707.84392357]
total_rewards_mean           1523.2969082214051
total_rewards_std            909.1956771352923
total_rewards_max            3121.3591401237395
total_rewards_min            707.8439235707452
Number of train steps total  240000
Number of env steps total    192583
Number of rollouts total     0
Train Time (s)               141.06039256975055
(Previous) Eval Time (s)     10.250848604831845
Sample Time (s)              6.476837276946753
Epoch Time (s)               157.78807845152915
Total Train Time (s)         9016.633858393878
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:59:56.890236 UTC | [2020_01_10_09_29_40] Iteration #59 | Epoch Duration: 157.8687183856964
2020-01-10 11:59:56.890399 UTC | [2020_01_10_09_29_40] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031992096
Z variance train             0.003123441
KL Divergence                12.12776
KL Loss                      1.2127761
QF Loss                      1635.1199
VF Loss                      537.538
Policy Loss                  -995.1741
Q Predictions Mean           982.3944
Q Predictions Std            268.83652
Q Predictions Max            1295.5155
Q Predictions Min            11.132233
V Predictions Mean           987.9595
V Predictions Std            254.42848
V Predictions Max            1287.6036
V Predictions Min            39.323452
Log Pis Mean                 1.0317342
Log Pis Std                  2.5963988
Log Pis Max                  13.18578
Log Pis Min                  -5.2967544
Policy mu Mean               0.11914381
Policy mu Std                1.1389291
Policy mu Max                4.271777
Policy mu Min                -2.8269835
Policy log std Mean          -0.6471538
Policy log std Std           0.33293104
Policy log std Max           0.1343211
Policy log std Min           -4.0200543
Z mean eval                  0.054067045
Z variance eval              0.0050001875
total_rewards                [1753.6786615   737.56916258  784.56353882 1781.42077289  725.06067325
 1297.60540936  990.75754258  823.4933572   804.50781508 2998.16698778]
total_rewards_mean           1269.6823921050395
total_rewards_std            692.3103330658425
total_rewards_max            2998.1669877810455
total_rewards_min            725.0606732510744
Number of train steps total  244000
Number of env steps total    196023
Number of rollouts total     0
Train Time (s)               140.31492959614843
(Previous) Eval Time (s)     8.42445339821279
Sample Time (s)              6.364024888258427
Epoch Time (s)               155.10340788261965
Total Train Time (s)         9171.819598853122
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:02:32.076627 UTC | [2020_01_10_09_29_40] Iteration #60 | Epoch Duration: 155.18611431121826
2020-01-10 12:02:32.076752 UTC | [2020_01_10_09_29_40] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056865137
Z variance train             0.0049980143
KL Divergence                11.525682
KL Loss                      1.1525682
QF Loss                      1753.9236
VF Loss                      446.2492
Policy Loss                  -959.2538
Q Predictions Mean           947.3617
Q Predictions Std            323.68002
Q Predictions Max            1305.032
Q Predictions Min            3.8198464
V Predictions Mean           956.547
V Predictions Std            307.80447
V Predictions Max            1298.0769
V Predictions Min            16.157795
Log Pis Mean                 0.98333246
Log Pis Std                  2.5877504
Log Pis Max                  14.89551
Log Pis Min                  -4.4264812
Policy mu Mean               0.19679743
Policy mu Std                1.1070672
Policy mu Max                3.4360511
Policy mu Min                -4.044409
Policy log std Mean          -0.6161641
Policy log std Std           0.2922585
Policy log std Max           0.46925604
Policy log std Min           -3.0760002
Z mean eval                  0.020658616
Z variance eval              0.0022843122
total_rewards                [2921.96740244  732.38219821 2865.75765989 2842.52263879 2835.25940749
  721.56787122 2861.57703551 2855.00915986 2889.04829176  986.08230439]
total_rewards_mean           2251.117396956369
total_rewards_std            943.9014053583685
total_rewards_max            2921.967402438779
total_rewards_min            721.5678712182946
Number of train steps total  248000
Number of env steps total    199456
Number of rollouts total     0
Train Time (s)               140.70987679809332
(Previous) Eval Time (s)     17.056324526201934
Sample Time (s)              6.506303322501481
Epoch Time (s)               164.27250464679673
Total Train Time (s)         9336.170622162987
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:05:16.429005 UTC | [2020_01_10_09_29_40] Iteration #61 | Epoch Duration: 164.35216641426086
2020-01-10 12:05:16.429131 UTC | [2020_01_10_09_29_40] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02014133
Z variance train             0.0022825864
KL Divergence                12.919662
KL Loss                      1.2919663
QF Loss                      1016.4236
VF Loss                      416.77487
Policy Loss                  -989.6433
Q Predictions Mean           977.4513
Q Predictions Std            287.8974
Q Predictions Max            1327.3302
Q Predictions Min            -90.50997
V Predictions Mean           992.64307
V Predictions Std            261.8738
V Predictions Max            1320.215
V Predictions Min            -19.185045
Log Pis Mean                 1.1008031
Log Pis Std                  2.4638977
Log Pis Max                  12.65842
Log Pis Min                  -4.2173424
Policy mu Mean               0.17873584
Policy mu Std                1.1172662
Policy mu Max                3.797074
Policy mu Min                -3.9457417
Policy log std Mean          -0.6529059
Policy log std Std           0.29174107
Policy log std Max           0.25536263
Policy log std Min           -1.7674364
Z mean eval                  0.036339097
Z variance eval              0.0022240127
total_rewards                [1305.81856288  716.72860965 2623.73902528 2958.04799424 1042.38018366
  733.24496347  734.03358281  846.85111782  739.62720903  709.42592524]
total_rewards_mean           1240.9897174095834
total_rewards_std            798.9281527694156
total_rewards_max            2958.0479942447105
total_rewards_min            709.425925237416
Number of train steps total  252000
Number of env steps total    202890
Number of rollouts total     0
Train Time (s)               139.74266058020294
(Previous) Eval Time (s)     7.391553966328502
Sample Time (s)              6.6268941992893815
Epoch Time (s)               153.76110874582082
Total Train Time (s)         9490.009410398081
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:07:50.269528 UTC | [2020_01_10_09_29_40] Iteration #62 | Epoch Duration: 153.8402931690216
2020-01-10 12:07:50.269697 UTC | [2020_01_10_09_29_40] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036551464
Z variance train             0.002220557
KL Divergence                12.876152
KL Loss                      1.2876152
QF Loss                      564.8439
VF Loss                      1814.1802
Policy Loss                  -977.35266
Q Predictions Mean           968.51697
Q Predictions Std            321.04935
Q Predictions Max            1350.0365
Q Predictions Min            15.497912
V Predictions Mean           976.01404
V Predictions Std            307.6315
V Predictions Max            1343.8861
V Predictions Min            17.45301
Log Pis Mean                 0.5856868
Log Pis Std                  2.2076879
Log Pis Max                  9.993883
Log Pis Min                  -4.9458685
Policy mu Mean               0.05530542
Policy mu Std                1.0604362
Policy mu Max                3.7958212
Policy mu Min                -3.0034657
Policy log std Mean          -0.6164755
Policy log std Std           0.29155976
Policy log std Max           0.3631494
Policy log std Min           -2.4236364
Z mean eval                  0.048492037
Z variance eval              0.0026854475
total_rewards                [2821.16246244  738.49379584 2828.57743425  898.76284951  577.55390606
 1341.72393049 1811.19526392 1170.01808596 1529.6572782   556.51698334]
total_rewards_mean           1427.366199000622
total_rewards_std            798.244185304639
total_rewards_max            2828.5774342515274
total_rewards_min            556.5169833435224
Number of train steps total  256000
Number of env steps total    206325
Number of rollouts total     0
Train Time (s)               141.24360752105713
(Previous) Eval Time (s)     10.747891963925213
Sample Time (s)              6.493658184539527
Epoch Time (s)               158.48515766952187
Total Train Time (s)         9648.598871916998
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:10:28.860792 UTC | [2020_01_10_09_29_40] Iteration #63 | Epoch Duration: 158.5909023284912
2020-01-10 12:10:28.861049 UTC | [2020_01_10_09_29_40] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04920612
Z variance train             0.0026923306
KL Divergence                12.957027
KL Loss                      1.2957028
QF Loss                      838.38855
VF Loss                      112.2052
Policy Loss                  -1002.4951
Q Predictions Mean           987.813
Q Predictions Std            265.37372
Q Predictions Max            1359.9272
Q Predictions Min            2.2978954
V Predictions Mean           1006.34155
V Predictions Std            240.57948
V Predictions Max            1350.5852
V Predictions Min            41.184895
Log Pis Mean                 0.7403627
Log Pis Std                  2.441369
Log Pis Max                  12.220015
Log Pis Min                  -5.705208
Policy mu Mean               0.18598557
Policy mu Std                1.0643873
Policy mu Max                3.7625146
Policy mu Min                -2.8616178
Policy log std Mean          -0.65962166
Policy log std Std           0.29644457
Policy log std Max           0.3070907
Policy log std Min           -1.8955213
Z mean eval                  0.03865155
Z variance eval              0.0038789338
total_rewards                [1417.4468723  2854.1933445  2716.87043773 1209.69418288 2600.30648473
  840.74182425 2785.25920788 1395.24466514 1993.07202356 2173.66329488]
total_rewards_mean           1998.6492337849013
total_rewards_std            701.7334286509843
total_rewards_max            2854.1933444998494
total_rewards_min            840.7418242464369
Number of train steps total  260000
Number of env steps total    209741
Number of rollouts total     0
Train Time (s)               142.2593588042073
(Previous) Eval Time (s)     12.888798070140183
Sample Time (s)              6.404701857827604
Epoch Time (s)               161.55285873217508
Total Train Time (s)         9810.232230965514
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:13:10.495194 UTC | [2020_01_10_09_29_40] Iteration #64 | Epoch Duration: 161.6339976787567
2020-01-10 12:13:10.495363 UTC | [2020_01_10_09_29_40] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039906785
Z variance train             0.0038931295
KL Divergence                12.61203
KL Loss                      1.261203
QF Loss                      306.30438
VF Loss                      114.15734
Policy Loss                  -998.3254
Q Predictions Mean           995.60986
Q Predictions Std            288.711
Q Predictions Max            1457.3848
Q Predictions Min            44.43431
V Predictions Mean           999.1259
V Predictions Std            284.1217
V Predictions Max            1434.6633
V Predictions Min            17.606258
Log Pis Mean                 0.67652345
Log Pis Std                  2.4243948
Log Pis Max                  9.633579
Log Pis Min                  -4.8344517
Policy mu Mean               0.08323755
Policy mu Std                1.0317032
Policy mu Max                3.030696
Policy mu Min                -2.7502875
Policy log std Mean          -0.6587698
Policy log std Std           0.30928025
Policy log std Max           0.16595334
Policy log std Min           -2.125465
Z mean eval                  0.033647716
Z variance eval              0.0037934245
total_rewards                [2933.81724048 1706.71615246 1650.26957733 2961.73586131 1017.75413005
 2908.96961283 1258.09726631 1484.20930473 1081.58266455 2883.87738438]
total_rewards_mean           1988.7029194417348
total_rewards_std            789.6976063888283
total_rewards_max            2961.7358613082683
total_rewards_min            1017.7541300471396
Number of train steps total  264000
Number of env steps total    213148
Number of rollouts total     0
Train Time (s)               140.94945781072602
(Previous) Eval Time (s)     12.463468553964049
Sample Time (s)              6.705262866802514
Epoch Time (s)               160.11818923149258
Total Train Time (s)         9970.426147476304
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:15:50.690589 UTC | [2020_01_10_09_29_40] Iteration #65 | Epoch Duration: 160.19509410858154
2020-01-10 12:15:50.690772 UTC | [2020_01_10_09_29_40] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033708043
Z variance train             0.003786486
KL Divergence                11.562058
KL Loss                      1.1562059
QF Loss                      722.02057
VF Loss                      125.89595
Policy Loss                  -982.9252
Q Predictions Mean           975.02344
Q Predictions Std            290.75998
Q Predictions Max            1358.1523
Q Predictions Min            14.928484
V Predictions Mean           983.8386
V Predictions Std            290.69412
V Predictions Max            1377.2086
V Predictions Min            18.37236
Log Pis Mean                 0.6004087
Log Pis Std                  2.3136473
Log Pis Max                  8.006353
Log Pis Min                  -4.0079293
Policy mu Mean               0.101159595
Policy mu Std                1.0066664
Policy mu Max                3.0702727
Policy mu Min                -2.4529884
Policy log std Mean          -0.61911684
Policy log std Std           0.294859
Policy log std Max           0.13212126
Policy log std Min           -2.1898274
Z mean eval                  0.034794115
Z variance eval              0.0031612585
total_rewards                [2820.88485446 1518.18563171 1997.79824127  570.06082561 1811.69538262
 1851.69748826  295.14897573  767.70913552 2794.38395845 1717.68554867]
total_rewards_mean           1614.5250042290681
total_rewards_std            815.97031641698
total_rewards_max            2820.884854457198
total_rewards_min            295.1489757304376
Number of train steps total  268000
Number of env steps total    216585
Number of rollouts total     0
Train Time (s)               140.02694522822276
(Previous) Eval Time (s)     10.194630309939384
Sample Time (s)              6.677424823399633
Epoch Time (s)               156.89900036156178
Total Train Time (s)         10127.41132719256
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:18:27.677242 UTC | [2020_01_10_09_29_40] Iteration #66 | Epoch Duration: 156.98633480072021
2020-01-10 12:18:27.677408 UTC | [2020_01_10_09_29_40] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032977283
Z variance train             0.0031672579
KL Divergence                12.2304
KL Loss                      1.22304
QF Loss                      290.1138
VF Loss                      93.07397
Policy Loss                  -1018.22296
Q Predictions Mean           1009.92554
Q Predictions Std            267.74014
Q Predictions Max            1317.4625
Q Predictions Min            56.556187
V Predictions Mean           1016.6301
V Predictions Std            262.38464
V Predictions Max            1323.5961
V Predictions Min            73.37701
Log Pis Mean                 0.46302673
Log Pis Std                  2.206727
Log Pis Max                  11.875627
Log Pis Min                  -4.458125
Policy mu Mean               0.2286834
Policy mu Std                1.0146326
Policy mu Max                3.9144635
Policy mu Min                -2.4120264
Policy log std Mean          -0.6292182
Policy log std Std           0.277985
Policy log std Max           0.021254838
Policy log std Min           -2.1299305
Z mean eval                  0.03974372
Z variance eval              0.0025183496
total_rewards                [1404.12759774 2608.73739136 2112.68331528 1990.68576858 1010.36301301
 2577.47895467 2731.76378907 1168.86427202 1234.81974561 2255.33325921]
total_rewards_mean           1909.4857106547067
total_rewards_std            620.1858669387562
total_rewards_max            2731.7637890673905
total_rewards_min            1010.3630130085055
Number of train steps total  272000
Number of env steps total    220172
Number of rollouts total     0
Train Time (s)               140.3091020816937
(Previous) Eval Time (s)     11.490778816863894
Sample Time (s)              7.051593971904367
Epoch Time (s)               158.85147487046197
Total Train Time (s)         10286.340541287325
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:21:06.607393 UTC | [2020_01_10_09_29_40] Iteration #67 | Epoch Duration: 158.92985486984253
2020-01-10 12:21:06.607558 UTC | [2020_01_10_09_29_40] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03820744
Z variance train             0.0025233717
KL Divergence                12.952124
KL Loss                      1.2952124
QF Loss                      689.0992
VF Loss                      256.52597
Policy Loss                  -1024.8546
Q Predictions Mean           1021.577
Q Predictions Std            265.78308
Q Predictions Max            1369.0134
Q Predictions Min            48.80368
V Predictions Mean           1012.73914
V Predictions Std            263.10284
V Predictions Max            1349.1533
V Predictions Min            14.208569
Log Pis Mean                 0.43198687
Log Pis Std                  2.0621083
Log Pis Max                  6.691739
Log Pis Min                  -4.76762
Policy mu Mean               0.038265202
Policy mu Std                1.004959
Policy mu Max                2.4533298
Policy mu Min                -2.4109914
Policy log std Mean          -0.64438725
Policy log std Std           0.26289976
Policy log std Max           0.12326622
Policy log std Min           -1.9843752
Z mean eval                  0.01982956
Z variance eval              0.0031203644
total_rewards                [  65.43995938 1672.70636101 1335.78007073 2178.85586725 1305.05282332
  855.53693886   69.42669555 1138.19306063  634.09112392 2574.90308886]
total_rewards_mean           1182.9985989521622
total_rewards_std            781.4538182152024
total_rewards_max            2574.9030888588727
total_rewards_min            65.43995938388649
Number of train steps total  276000
Number of env steps total    223594
Number of rollouts total     0
Train Time (s)               141.23243360919878
(Previous) Eval Time (s)     9.217925981152803
Sample Time (s)              5.747793071903288
Epoch Time (s)               156.19815266225487
Total Train Time (s)         10442.615901210345
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:23:42.883924 UTC | [2020_01_10_09_29_40] Iteration #68 | Epoch Duration: 156.27624559402466
2020-01-10 12:23:42.884063 UTC | [2020_01_10_09_29_40] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019964354
Z variance train             0.0031188969
KL Divergence                12.673702
KL Loss                      1.2673702
QF Loss                      987.66516
VF Loss                      298.38522
Policy Loss                  -1018.03955
Q Predictions Mean           1010.1553
Q Predictions Std            287.54688
Q Predictions Max            1352.5443
Q Predictions Min            26.880398
V Predictions Mean           1010.0654
V Predictions Std            283.26013
V Predictions Max            1359.2253
V Predictions Min            27.131582
Log Pis Mean                 0.5441599
Log Pis Std                  2.1369913
Log Pis Max                  7.090023
Log Pis Min                  -4.569891
Policy mu Mean               0.038009368
Policy mu Std                1.0488014
Policy mu Max                2.777678
Policy mu Min                -2.8542004
Policy log std Mean          -0.60655236
Policy log std Std           0.27588537
Policy log std Max           0.123563886
Policy log std Min           -2.06057
Z mean eval                  0.040764496
Z variance eval              0.005116458
total_rewards                [1453.0237644  2521.68951463 2862.78266666 1113.17943288  959.82650987
 2945.60352688 2844.70992029 2866.54866071 2878.68687306 2871.27487172]
total_rewards_mean           2331.7325741116747
total_rewards_std            772.8843035221532
total_rewards_max            2945.6035268830237
total_rewards_min            959.8265098686288
Number of train steps total  280000
Number of env steps total    227046
Number of rollouts total     0
Train Time (s)               142.02627865970135
(Previous) Eval Time (s)     14.796291290782392
Sample Time (s)              6.505355837754905
Epoch Time (s)               163.32792578823864
Total Train Time (s)         10606.020057275891
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:26:26.290204 UTC | [2020_01_10_09_29_40] Iteration #69 | Epoch Duration: 163.4059772491455
2020-01-10 12:26:26.290448 UTC | [2020_01_10_09_29_40] Iteration #69 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039017025
Z variance train             0.0051205177
KL Divergence                11.397961
KL Loss                      1.1397961
QF Loss                      881.5199
VF Loss                      202.56522
Policy Loss                  -1028.9147
Q Predictions Mean           1017.0856
Q Predictions Std            301.53412
Q Predictions Max            1398.061
Q Predictions Min            -10.554009
V Predictions Mean           1034.4504
V Predictions Std            282.29358
V Predictions Max            1393.1622
V Predictions Min            12.475548
Log Pis Mean                 0.9393753
Log Pis Std                  2.592127
Log Pis Max                  12.949787
Log Pis Min                  -4.112114
Policy mu Mean               0.22775377
Policy mu Std                1.1085721
Policy mu Max                3.4803329
Policy mu Min                -2.890608
Policy log std Mean          -0.64682144
Policy log std Std           0.27433765
Policy log std Max           0.05472654
Policy log std Min           -2.8136487
Z mean eval                  0.05369879
Z variance eval              0.0050844783
total_rewards                [1986.33532723 1981.87416378 2848.42944113 1858.739841   2850.9913118
 2784.71354527  942.45992625 1726.07757769 2308.71881274 2937.16552699]
total_rewards_mean           2222.5505473869366
total_rewards_std            612.5346805790732
total_rewards_max            2937.165526990387
total_rewards_min            942.4599262529442
Number of train steps total  284000
Number of env steps total    230453
Number of rollouts total     0
Train Time (s)               142.21622692700475
(Previous) Eval Time (s)     16.236015252768993
Sample Time (s)              5.450902310200036
Epoch Time (s)               163.90314448997378
Total Train Time (s)         10770.002997158095
Epoch                        70
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:29:10.273817 UTC | [2020_01_10_09_29_40] Iteration #70 | Epoch Duration: 163.98322558403015
2020-01-10 12:29:10.273997 UTC | [2020_01_10_09_29_40] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05327158
Z variance train             0.0050921985
KL Divergence                11.09839
KL Loss                      1.109839
QF Loss                      470.28583
VF Loss                      257.63235
Policy Loss                  -1023.94604
Q Predictions Mean           1014.4144
Q Predictions Std            308.6561
Q Predictions Max            1372.8617
Q Predictions Min            10.912747
V Predictions Mean           1013.8447
V Predictions Std            290.35867
V Predictions Max            1354.0972
V Predictions Min            17.249218
Log Pis Mean                 0.5977209
Log Pis Std                  2.6868045
Log Pis Max                  13.739901
Log Pis Min                  -5.183438
Policy mu Mean               0.17650057
Policy mu Std                1.0597435
Policy mu Max                3.688333
Policy mu Min                -3.4223492
Policy log std Mean          -0.6018202
Policy log std Std           0.2536531
Policy log std Max           0.0786373
Policy log std Min           -2.3516011
Z mean eval                  0.033765376
Z variance eval              0.0035818112
total_rewards                [1860.00334242 2914.23823276 2976.73266628 1445.28736954 2968.53575733
 2245.70894597 1559.83365016 1294.08215419 1027.86142441 3045.11759573]
total_rewards_mean           2133.740113879477
total_rewards_std            752.7352956075648
total_rewards_max            3045.1175957319215
total_rewards_min            1027.861424412246
Number of train steps total  288000
Number of env steps total    233872
Number of rollouts total     0
Train Time (s)               143.30813622428104
(Previous) Eval Time (s)     13.191515637096018
Sample Time (s)              5.695379045326263
Epoch Time (s)               162.19503090670332
Total Train Time (s)         10932.275862665847
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:31:52.548762 UTC | [2020_01_10_09_29_40] Iteration #71 | Epoch Duration: 162.27457904815674
2020-01-10 12:31:52.549024 UTC | [2020_01_10_09_29_40] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03309972
Z variance train             0.003584389
KL Divergence                12.044911
KL Loss                      1.2044911
QF Loss                      960.2726
VF Loss                      86.833916
Policy Loss                  -973.06665
Q Predictions Mean           961.79224
Q Predictions Std            324.25943
Q Predictions Max            1364.8445
Q Predictions Min            0.4444642
V Predictions Mean           976.33765
V Predictions Std            318.0019
V Predictions Max            1376.1967
V Predictions Min            -31.311243
Log Pis Mean                 0.8107823
Log Pis Std                  2.7451322
Log Pis Max                  11.959997
Log Pis Min                  -5.464962
Policy mu Mean               0.115196206
Policy mu Std                1.123607
Policy mu Max                3.975171
Policy mu Min                -3.0176454
Policy log std Mean          -0.61119765
Policy log std Std           0.25462988
Policy log std Max           -0.037929118
Policy log std Min           -1.6204216
Z mean eval                  0.032371767
Z variance eval              0.004124413
total_rewards                [ 924.96542959 2244.23430142  926.55619921 2870.02597873 3054.24136394
 2885.33005032 2980.28768281 2398.43013491 1337.79547263 1088.03569443]
total_rewards_mean           2070.9902307981433
total_rewards_std            857.8647204307899
total_rewards_max            3054.2413639360566
total_rewards_min            924.9654295869612
Number of train steps total  292000
Number of env steps total    237288
Number of rollouts total     0
Train Time (s)               144.63940296089277
(Previous) Eval Time (s)     15.0420598462224
Sample Time (s)              5.603267017286271
Epoch Time (s)               165.28472982440144
Total Train Time (s)         11097.665406635497
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:34:37.938639 UTC | [2020_01_10_09_29_40] Iteration #72 | Epoch Duration: 165.38946795463562
2020-01-10 12:34:37.938783 UTC | [2020_01_10_09_29_40] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031776898
Z variance train             0.0041228235
KL Divergence                12.010267
KL Loss                      1.2010268
QF Loss                      382.66577
VF Loss                      483.3821
Policy Loss                  -1014.2248
Q Predictions Mean           1004.6625
Q Predictions Std            326.0545
Q Predictions Max            1405.5021
Q Predictions Min            11.62126
V Predictions Mean           1013.5603
V Predictions Std            311.98407
V Predictions Max            1392.9807
V Predictions Min            66.97903
Log Pis Mean                 0.43964666
Log Pis Std                  2.536143
Log Pis Max                  15.831654
Log Pis Min                  -5.212568
Policy mu Mean               0.14222056
Policy mu Std                1.0466678
Policy mu Max                4.6570773
Policy mu Min                -2.3812897
Policy log std Mean          -0.5946824
Policy log std Std           0.26301116
Policy log std Max           0.33294702
Policy log std Min           -2.2951968
Z mean eval                  0.012458274
Z variance eval              0.0036714394
total_rewards                [2700.02913725 2925.5505209   816.47073586 2927.34870034 2919.68759461
  994.86750518 1348.23076002 2541.36568914  675.74104216 1118.25972091]
total_rewards_mean           1896.755140638154
total_rewards_std            927.6815694807085
total_rewards_max            2927.348700339736
total_rewards_min            675.7410421579567
Number of train steps total  296000
Number of env steps total    240705
Number of rollouts total     0
Train Time (s)               143.54984928900376
(Previous) Eval Time (s)     13.709827792830765
Sample Time (s)              6.618901547044516
Epoch Time (s)               163.87857862887904
Total Train Time (s)         11261.634082463104
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:37:21.912130 UTC | [2020_01_10_09_29_40] Iteration #73 | Epoch Duration: 163.97319722175598
2020-01-10 12:37:21.912352 UTC | [2020_01_10_09_29_40] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009861603
Z variance train             0.0036755744
KL Divergence                11.721337
KL Loss                      1.1721338
QF Loss                      427.19482
VF Loss                      188.79964
Policy Loss                  -1010.8751
Q Predictions Mean           1002.3186
Q Predictions Std            299.1233
Q Predictions Max            1361.1516
Q Predictions Min            -21.964909
V Predictions Mean           1016.04224
V Predictions Std            289.80148
V Predictions Max            1362.753
V Predictions Min            -21.185167
Log Pis Mean                 0.58584744
Log Pis Std                  2.3909314
Log Pis Max                  11.7417345
Log Pis Min                  -4.937066
Policy mu Mean               0.055027634
Policy mu Std                1.0585449
Policy mu Max                3.8408408
Policy mu Min                -2.7285194
Policy log std Mean          -0.6238697
Policy log std Std           0.28160393
Policy log std Max           0.08482003
Policy log std Min           -2.587524
Z mean eval                  0.026552761
Z variance eval              0.0046672076
total_rewards                [3055.28252064 3058.48433884 1102.76937865 3074.05013587 3054.21850452
 1365.32076041 3082.72647457 1541.04820801 3050.25576469 3051.48078555]
total_rewards_mean           2543.5636871747843
total_rewards_std            796.4784195580289
total_rewards_max            3082.726474569479
total_rewards_min            1102.7693786543832
Number of train steps total  300000
Number of env steps total    244516
Number of rollouts total     0
Train Time (s)               143.19515846017748
(Previous) Eval Time (s)     15.23952904297039
Sample Time (s)              7.687130233738571
Epoch Time (s)               166.12181773688644
Total Train Time (s)         11427.841687029693
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:40:08.122722 UTC | [2020_01_10_09_29_40] Iteration #74 | Epoch Duration: 166.21017241477966
2020-01-10 12:40:08.123033 UTC | [2020_01_10_09_29_40] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028417086
Z variance train             0.0046566734
KL Divergence                11.160568
KL Loss                      1.1160568
QF Loss                      370.73584
VF Loss                      191.0322
Policy Loss                  -1027.2463
Q Predictions Mean           1028.7761
Q Predictions Std            319.09833
Q Predictions Max            1375.6428
Q Predictions Min            21.942215
V Predictions Mean           1028.5781
V Predictions Std            318.2946
V Predictions Max            1377.2745
V Predictions Min            24.468403
Log Pis Mean                 0.659659
Log Pis Std                  2.2016895
Log Pis Max                  8.302986
Log Pis Min                  -4.882044
Policy mu Mean               0.16894989
Policy mu Std                1.0244745
Policy mu Max                2.938058
Policy mu Min                -2.5437882
Policy log std Mean          -0.62919873
Policy log std Std           0.24338362
Policy log std Max           0.15746075
Policy log std Min           -1.7610662
Z mean eval                  0.05021177
Z variance eval              0.005438282
total_rewards                [2885.32164825 2837.61831896 2864.64219169 2459.88919089 1133.39515685
 2930.86304227 1519.12900941 2842.48192799 1185.24319467 2239.990986  ]
total_rewards_mean           2289.8574666975746
total_rewards_std            698.8759931550303
total_rewards_max            2930.8630422715405
total_rewards_min            1133.3951568451198
Number of train steps total  304000
Number of env steps total    247962
Number of rollouts total     0
Train Time (s)               143.51894056331366
(Previous) Eval Time (s)     15.49157403409481
Sample Time (s)              6.5440175156109035
Epoch Time (s)               165.55453211301938
Total Train Time (s)         11593.47919985652
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:42:53.761441 UTC | [2020_01_10_09_29_40] Iteration #75 | Epoch Duration: 165.63817834854126
2020-01-10 12:42:53.761688 UTC | [2020_01_10_09_29_40] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053722847
Z variance train             0.005444351
KL Divergence                10.770608
KL Loss                      1.0770608
QF Loss                      298.26672
VF Loss                      188.55069
Policy Loss                  -1048.8003
Q Predictions Mean           1047.4924
Q Predictions Std            299.9142
Q Predictions Max            1366.567
Q Predictions Min            -6.768299
V Predictions Mean           1040.5968
V Predictions Std            299.21494
V Predictions Max            1365.7089
V Predictions Min            9.474886
Log Pis Mean                 0.3860265
Log Pis Std                  2.3734207
Log Pis Max                  11.661496
Log Pis Min                  -5.4537597
Policy mu Mean               0.057085052
Policy mu Std                1.0189087
Policy mu Max                3.1554
Policy mu Min                -2.7681086
Policy log std Mean          -0.6410641
Policy log std Std           0.263586
Policy log std Max           0.11068237
Policy log std Min           -2.0305238
Z mean eval                  0.051161546
Z variance eval              0.0055210227
total_rewards                [3025.77274685 2905.09463852 2545.27150932 2950.18078874 2998.04821544
  639.19668744 2954.02180256 2987.53098455 2936.33638413 2983.31851771]
total_rewards_mean           2692.477227526709
total_rewards_std            696.6509562998448
total_rewards_max            3025.7727468527096
total_rewards_min            639.1966874433473
Number of train steps total  308000
Number of env steps total    251375
Number of rollouts total     0
Train Time (s)               142.75669164396822
(Previous) Eval Time (s)     16.7813983829692
Sample Time (s)              6.727069810964167
Epoch Time (s)               166.2651598379016
Total Train Time (s)         11759.82202147739
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:45:40.104549 UTC | [2020_01_10_09_29_40] Iteration #76 | Epoch Duration: 166.34270095825195
2020-01-10 12:45:40.104671 UTC | [2020_01_10_09_29_40] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048764147
Z variance train             0.00551943
KL Divergence                10.644653
KL Loss                      1.0644654
QF Loss                      942.1334
VF Loss                      449.17468
Policy Loss                  -1029.8545
Q Predictions Mean           1021.3198
Q Predictions Std            334.9697
Q Predictions Max            1389.7955
Q Predictions Min            27.353247
V Predictions Mean           1042.3951
V Predictions Std            321.98438
V Predictions Max            1390.4198
V Predictions Min            33.398632
Log Pis Mean                 0.2456459
Log Pis Std                  2.1236982
Log Pis Max                  9.968233
Log Pis Min                  -6.082279
Policy mu Mean               0.084709406
Policy mu Std                0.98340267
Policy mu Max                3.3179967
Policy mu Min                -2.8136356
Policy log std Mean          -0.61543244
Policy log std Std           0.25546193
Policy log std Max           0.047326624
Policy log std Min           -3.0158043
Z mean eval                  0.048570156
Z variance eval              0.003287085
total_rewards                [2967.79136996 2912.30103733 2957.82900797 2978.40988012 2937.25825617
 2908.31349848  717.65652523 2608.06465831 2940.22672883 2886.83271346]
total_rewards_mean           2681.4683675859455
total_rewards_std            662.402950613592
total_rewards_max            2978.409880123658
total_rewards_min            717.6565252321548
Number of train steps total  312000
Number of env steps total    254780
Number of rollouts total     0
Train Time (s)               143.35455127991736
(Previous) Eval Time (s)     16.57931132800877
Sample Time (s)              5.439113526139408
Epoch Time (s)               165.37297613406554
Total Train Time (s)         11925.269990813918
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:48:25.553011 UTC | [2020_01_10_09_29_40] Iteration #77 | Epoch Duration: 165.44825339317322
2020-01-10 12:48:25.553128 UTC | [2020_01_10_09_29_40] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046989907
Z variance train             0.003281456
KL Divergence                12.233207
KL Loss                      1.2233207
QF Loss                      1237.1609
VF Loss                      301.92136
Policy Loss                  -1067.066
Q Predictions Mean           1055.5789
Q Predictions Std            275.27808
Q Predictions Max            1345.8082
Q Predictions Min            -13.629042
V Predictions Mean           1076.134
V Predictions Std            262.97296
V Predictions Max            1359.4979
V Predictions Min            -6.07765
Log Pis Mean                 0.38626093
Log Pis Std                  2.2423644
Log Pis Max                  8.396702
Log Pis Min                  -5.2225275
Policy mu Mean               -0.028908813
Policy mu Std                1.049608
Policy mu Max                3.0681129
Policy mu Min                -3.5254016
Policy log std Mean          -0.62348247
Policy log std Std           0.2621231
Policy log std Max           0.089812696
Policy log std Min           -1.5884595
Z mean eval                  0.04281459
Z variance eval              0.0049746106
total_rewards                [2949.39060861 2305.48417531 1883.29805927 1214.09099856 1880.18965801
 2931.83099066 2945.26173178 2926.82478458 2146.40289792 2963.78681797]
total_rewards_mean           2414.6560722670297
total_rewards_std            590.9352843593537
total_rewards_max            2963.7868179741477
total_rewards_min            1214.0909985615858
Number of train steps total  316000
Number of env steps total    258206
Number of rollouts total     0
Train Time (s)               142.75743838306516
(Previous) Eval Time (s)     17.651422415859997
Sample Time (s)              5.527115845587105
Epoch Time (s)               165.93597664451227
Total Train Time (s)         12091.301457001828
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:51:11.585869 UTC | [2020_01_10_09_29_40] Iteration #78 | Epoch Duration: 166.03265070915222
2020-01-10 12:51:11.585999 UTC | [2020_01_10_09_29_40] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042749576
Z variance train             0.004979177
KL Divergence                11.2411175
KL Loss                      1.1241118
QF Loss                      442.9884
VF Loss                      144.67444
Policy Loss                  -1056.0753
Q Predictions Mean           1051.4436
Q Predictions Std            296.70493
Q Predictions Max            1377.9987
Q Predictions Min            40.86749
V Predictions Mean           1052.6791
V Predictions Std            290.8932
V Predictions Max            1374.0364
V Predictions Min            28.843958
Log Pis Mean                 0.54176766
Log Pis Std                  2.4883595
Log Pis Max                  12.416169
Log Pis Min                  -6.122379
Policy mu Mean               0.099443436
Policy mu Std                1.0392506
Policy mu Max                4.148671
Policy mu Min                -2.7524254
Policy log std Mean          -0.6188465
Policy log std Std           0.26496303
Policy log std Max           0.20157677
Policy log std Min           -1.7969503
Z mean eval                  0.037267946
Z variance eval              0.0029627536
total_rewards                [2912.24037913 2902.02291415 2103.57836634 2923.30732492 2918.95096167
 2934.73773836  730.33953572 2219.79971924 2634.2641135  1398.35421804]
total_rewards_mean           2367.7595271070877
total_rewards_std            727.9701763574093
total_rewards_max            2934.7377383632333
total_rewards_min            730.3395357204112
Number of train steps total  320000
Number of env steps total    261602
Number of rollouts total     0
Train Time (s)               143.1751834442839
(Previous) Eval Time (s)     17.880769681185484
Sample Time (s)              6.604737326968461
Epoch Time (s)               167.66069045243785
Total Train Time (s)         12259.045616002753
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:53:59.331144 UTC | [2020_01_10_09_29_40] Iteration #79 | Epoch Duration: 167.74505519866943
2020-01-10 12:53:59.331271 UTC | [2020_01_10_09_29_40] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036628217
Z variance train             0.0029634496
KL Divergence                12.513306
KL Loss                      1.2513306
QF Loss                      3611.7185
VF Loss                      1227.4117
Policy Loss                  -1050.8505
Q Predictions Mean           1047.8975
Q Predictions Std            292.0918
Q Predictions Max            1379.0187
Q Predictions Min            43.315388
V Predictions Mean           1054.3884
V Predictions Std            291.8362
V Predictions Max            1398.9437
V Predictions Min            38.41246
Log Pis Mean                 0.77468956
Log Pis Std                  2.5824225
Log Pis Max                  11.137266
Log Pis Min                  -5.108342
Policy mu Mean               0.21459533
Policy mu Std                1.0837355
Policy mu Max                4.8383183
Policy mu Min                -2.6236806
Policy log std Mean          -0.6455949
Policy log std Std           0.2822831
Policy log std Max           -0.00199306
Policy log std Min           -4.0188727
Z mean eval                  0.031839095
Z variance eval              0.001995836
total_rewards                [1023.06067213  726.01284601 1021.71933111  563.10392874 2341.73725241
  775.70205049  993.00765515  789.80398845  300.70833904 1378.60866955]
total_rewards_mean           991.3464733094115
total_rewards_std            528.5219824098805
total_rewards_max            2341.7372524145962
total_rewards_min            300.70833904317055
Number of train steps total  324000
Number of env steps total    265162
Number of rollouts total     0
Train Time (s)               144.2522272397764
(Previous) Eval Time (s)     7.159751852042973
Sample Time (s)              6.446865621488541
Epoch Time (s)               157.85884471330792
Total Train Time (s)         12416.991810149979
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:56:37.278352 UTC | [2020_01_10_09_29_40] Iteration #80 | Epoch Duration: 157.9469952583313
2020-01-10 12:56:37.278477 UTC | [2020_01_10_09_29_40] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03167504
Z variance train             0.0019948946
KL Divergence                13.244146
KL Loss                      1.3244146
QF Loss                      467.70325
VF Loss                      87.56302
Policy Loss                  -1057.8909
Q Predictions Mean           1054.2366
Q Predictions Std            308.39935
Q Predictions Max            1395.6444
Q Predictions Min            -24.092987
V Predictions Mean           1056.8296
V Predictions Std            306.0207
V Predictions Max            1384.3114
V Predictions Min            0.61437225
Log Pis Mean                 0.4153324
Log Pis Std                  2.0779886
Log Pis Max                  10.676906
Log Pis Min                  -6.5434184
Policy mu Mean               0.20620136
Policy mu Std                1.0072973
Policy mu Max                3.565182
Policy mu Min                -2.9115858
Policy log std Mean          -0.59214634
Policy log std Std           0.27191257
Policy log std Max           0.06910312
Policy log std Min           -2.91769
Z mean eval                  0.013123119
Z variance eval              0.0054348083
total_rewards                [2915.75588323  957.00232445 2987.81416202  766.88413867 2736.16545269
 2770.56595257 2992.10848398 2931.74002532 2995.52342166 2962.20553602]
total_rewards_mean           2501.576538059401
total_rewards_std            825.35149215889
total_rewards_max            2995.5234216578447
total_rewards_min            766.8841386679816
Number of train steps total  328000
Number of env steps total    269240
Number of rollouts total     0
Train Time (s)               143.86914658499882
(Previous) Eval Time (s)     17.6419490207918
Sample Time (s)              7.966913177166134
Epoch Time (s)               169.47800878295675
Total Train Time (s)         12586.564684602432
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:59:26.852191 UTC | [2020_01_10_09_29_40] Iteration #81 | Epoch Duration: 169.57362627983093
2020-01-10 12:59:26.852315 UTC | [2020_01_10_09_29_40] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012071313
Z variance train             0.005451963
KL Divergence                11.561797
KL Loss                      1.1561798
QF Loss                      3752.4297
VF Loss                      92.39601
Policy Loss                  -1068.965
Q Predictions Mean           1063.4475
Q Predictions Std            265.4079
Q Predictions Max            1385.7281
Q Predictions Min            -24.630497
V Predictions Mean           1069.238
V Predictions Std            260.7623
V Predictions Max            1386.7083
V Predictions Min            34.977413
Log Pis Mean                 0.51818526
Log Pis Std                  2.420649
Log Pis Max                  13.637057
Log Pis Min                  -5.345832
Policy mu Mean               0.12535472
Policy mu Std                1.0276484
Policy mu Max                2.9902375
Policy mu Min                -4.5118556
Policy log std Mean          -0.6396289
Policy log std Std           0.26454225
Policy log std Max           0.057818413
Policy log std Min           -2.3578448
Z mean eval                  0.017586717
Z variance eval              0.004363214
total_rewards                [2808.74002908 2877.75399985 2921.25746472 1293.46756656 2441.70333758
  942.17246787 2918.3487038  2738.55057946 2895.61656602 2852.29024053]
total_rewards_mean           2468.99009554686
total_rewards_std            693.134094621366
total_rewards_max            2921.2574647211177
total_rewards_min            942.1724678660655
Number of train steps total  332000
Number of env steps total    272813
Number of rollouts total     0
Train Time (s)               143.42149033676833
(Previous) Eval Time (s)     18.22275609895587
Sample Time (s)              5.551782545633614
Epoch Time (s)               167.1960289813578
Total Train Time (s)         12753.838588805404
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:02:14.127464 UTC | [2020_01_10_09_29_40] Iteration #82 | Epoch Duration: 167.27503538131714
2020-01-10 13:02:14.127689 UTC | [2020_01_10_09_29_40] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01836376
Z variance train             0.004337852
KL Divergence                11.340643
KL Loss                      1.1340643
QF Loss                      3120.2773
VF Loss                      375.332
Policy Loss                  -1055.4951
Q Predictions Mean           1044.5203
Q Predictions Std            332.66562
Q Predictions Max            1410.9783
Q Predictions Min            -46.997707
V Predictions Mean           1040.6921
V Predictions Std            323.63956
V Predictions Max            1408.0394
V Predictions Min            -28.17582
Log Pis Mean                 0.4921636
Log Pis Std                  2.4339182
Log Pis Max                  11.784378
Log Pis Min                  -5.789852
Policy mu Mean               0.043855917
Policy mu Std                0.9997074
Policy mu Max                3.728706
Policy mu Min                -3.5317576
Policy log std Mean          -0.61658406
Policy log std Std           0.26915422
Policy log std Max           -0.016497672
Policy log std Min           -3.5759943
Z mean eval                  0.052074187
Z variance eval              0.007899681
total_rewards                [ 783.3851053   552.44654914 1584.42217194 3014.33429197 2981.20015947
  530.82021214 2973.21053324 3039.59573702  673.25250185 2373.69624926]
total_rewards_mean           1850.6363511341356
total_rewards_std            1077.176663186121
total_rewards_max            3039.595737020705
total_rewards_min            530.8202121385681
Number of train steps total  336000
Number of env steps total    276370
Number of rollouts total     0
Train Time (s)               146.41668324591592
(Previous) Eval Time (s)     13.204906125087291
Sample Time (s)              6.657220839057118
Epoch Time (s)               166.27881021006033
Total Train Time (s)         12920.192890555598
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:05:00.482955 UTC | [2020_01_10_09_29_40] Iteration #83 | Epoch Duration: 166.35511660575867
2020-01-10 13:05:00.483081 UTC | [2020_01_10_09_29_40] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051863022
Z variance train             0.00787914
KL Divergence                10.1208515
KL Loss                      1.0120852
QF Loss                      463.75842
VF Loss                      122.44341
Policy Loss                  -1063.534
Q Predictions Mean           1053.9056
Q Predictions Std            311.7124
Q Predictions Max            1583.3064
Q Predictions Min            -76.784065
V Predictions Mean           1068.3812
V Predictions Std            308.01675
V Predictions Max            1542.0023
V Predictions Min            -2.2747955
Log Pis Mean                 0.5919697
Log Pis Std                  2.5286875
Log Pis Max                  12.274265
Log Pis Min                  -6.342429
Policy mu Mean               0.16346252
Policy mu Std                1.0305557
Policy mu Max                3.9415207
Policy mu Min                -3.4356413
Policy log std Mean          -0.59643775
Policy log std Std           0.28458247
Policy log std Max           0.23530692
Policy log std Min           -2.1336958
Z mean eval                  0.043877102
Z variance eval              0.0062755933
total_rewards                [2882.58346477 2893.69584473  667.48388267 2841.65203108 2934.64451648
 2882.52098858 2934.16571276 2932.53518711 2875.29869415 2898.56114985]
total_rewards_mean           2674.314147217179
total_rewards_std            669.5430198053574
total_rewards_max            2934.6445164750103
total_rewards_min            667.4838826735863
Number of train steps total  340000
Number of env steps total    280273
Number of rollouts total     0
Train Time (s)               143.76484638592228
(Previous) Eval Time (s)     19.973164313007146
Sample Time (s)              7.5757433930411935
Epoch Time (s)               171.31375409197062
Total Train Time (s)         13091.58654231485
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:07:51.878343 UTC | [2020_01_10_09_29_40] Iteration #84 | Epoch Duration: 171.39515686035156
2020-01-10 13:07:51.878529 UTC | [2020_01_10_09_29_40] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04084918
Z variance train             0.006274146
KL Divergence                10.587562
KL Loss                      1.0587562
QF Loss                      165.95882
VF Loss                      84.06273
Policy Loss                  -1076.7543
Q Predictions Mean           1067.1659
Q Predictions Std            323.25
Q Predictions Max            1383.3574
Q Predictions Min            31.189573
V Predictions Mean           1072.2125
V Predictions Std            310.87894
V Predictions Max            1375.0686
V Predictions Min            27.841356
Log Pis Mean                 0.33672494
Log Pis Std                  2.227265
Log Pis Max                  9.675209
Log Pis Min                  -3.953234
Policy mu Mean               0.12000426
Policy mu Std                0.9648972
Policy mu Max                3.6641161
Policy mu Min                -2.984485
Policy log std Mean          -0.60456437
Policy log std Std           0.2638412
Policy log std Max           0.07176143
Policy log std Min           -1.8447037
Z mean eval                  0.033184726
Z variance eval              0.0054899105
total_rewards                [2615.09949836 1829.88053654 2983.91493075  685.54864643 2999.08493282
  721.61436762 2969.55198946 2993.20952273  590.29195487 3003.93140182]
total_rewards_mean           2139.212778139896
total_rewards_std            1022.9100046947657
total_rewards_max            3003.931401816821
total_rewards_min            590.2919548692653
Number of train steps total  344000
Number of env steps total    283850
Number of rollouts total     0
Train Time (s)               143.7376745324582
(Previous) Eval Time (s)     15.510388204362243
Sample Time (s)              6.4575825980864465
Epoch Time (s)               165.70564533490688
Total Train Time (s)         13257.375949782785
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:10:37.668937 UTC | [2020_01_10_09_29_40] Iteration #85 | Epoch Duration: 165.79028296470642
2020-01-10 13:10:37.669075 UTC | [2020_01_10_09_29_40] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03168294
Z variance train             0.005495145
KL Divergence                11.08699
KL Loss                      1.1086991
QF Loss                      499.456
VF Loss                      92.8453
Policy Loss                  -1026.4656
Q Predictions Mean           1019.056
Q Predictions Std            354.61743
Q Predictions Max            1389.7834
Q Predictions Min            -13.47221
V Predictions Mean           1023.45465
V Predictions Std            349.03104
V Predictions Max            1375.5441
V Predictions Min            -1.6332538
Log Pis Mean                 0.37675
Log Pis Std                  2.2701225
Log Pis Max                  7.9811254
Log Pis Min                  -5.3136387
Policy mu Mean               0.17965288
Policy mu Std                0.96938795
Policy mu Max                2.849704
Policy mu Min                -2.5931978
Policy log std Mean          -0.59151334
Policy log std Std           0.2586283
Policy log std Max           0.10010511
Policy log std Min           -2.0554347
Z mean eval                  0.042097084
Z variance eval              0.0048767338
total_rewards                [2984.4882271  2946.64411939 2999.21141124  605.78921525 1923.27029512
 3006.47149715 1161.67468504  854.24754643 1781.00055127 2999.73977316]
total_rewards_mean           2126.2537321165937
total_rewards_std            934.347364707265
total_rewards_max            3006.4714971510602
total_rewards_min            605.7892152499173
Number of train steps total  348000
Number of env steps total    287407
Number of rollouts total     0
Train Time (s)               143.69395938888192
(Previous) Eval Time (s)     13.145348386839032
Sample Time (s)              5.795255301054567
Epoch Time (s)               162.63456307677552
Total Train Time (s)         13420.093014369253
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:13:20.389319 UTC | [2020_01_10_09_29_40] Iteration #86 | Epoch Duration: 162.72013592720032
2020-01-10 13:13:20.389495 UTC | [2020_01_10_09_29_40] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0446477
Z variance train             0.0048721847
KL Divergence                11.050919
KL Loss                      1.1050919
QF Loss                      352.913
VF Loss                      118.90091
Policy Loss                  -1062.7097
Q Predictions Mean           1055.7434
Q Predictions Std            327.9252
Q Predictions Max            1416.535
Q Predictions Min            -36.52182
V Predictions Mean           1056.025
V Predictions Std            317.88553
V Predictions Max            1403.8628
V Predictions Min            -0.095635295
Log Pis Mean                 0.40787643
Log Pis Std                  2.0827947
Log Pis Max                  6.4688597
Log Pis Min                  -5.9670877
Policy mu Mean               0.12106601
Policy mu Std                0.9873856
Policy mu Max                3.4104073
Policy mu Min                -2.420377
Policy log std Mean          -0.59600335
Policy log std Std           0.25979844
Policy log std Max           0.134314
Policy log std Min           -1.9467802
Z mean eval                  0.12068182
Z variance eval              0.004427043
total_rewards                [3024.42122251 2958.9957493  3007.69178497 3017.3227112  2998.01915996
 3010.91092363 1429.84145539 3026.11171259 2990.15977414 2996.64631048]
total_rewards_mean           2846.0120804166386
total_rewards_std            472.4219424210817
total_rewards_max            3026.111712589597
total_rewards_min            1429.8414553850942
Number of train steps total  352000
Number of env steps total    290959
Number of rollouts total     0
Train Time (s)               146.9179932801053
(Previous) Eval Time (s)     17.538603452965617
Sample Time (s)              6.548273068387061
Epoch Time (s)               171.00486980145797
Total Train Time (s)         13591.181732545141
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:16:11.479027 UTC | [2020_01_10_09_29_40] Iteration #87 | Epoch Duration: 171.0893886089325
2020-01-10 13:16:11.479235 UTC | [2020_01_10_09_29_40] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11894455
Z variance train             0.0044241063
KL Divergence                11.670164
KL Loss                      1.1670164
QF Loss                      200.62602
VF Loss                      201.71326
Policy Loss                  -1073.5308
Q Predictions Mean           1067.2173
Q Predictions Std            308.69647
Q Predictions Max            1392.3745
Q Predictions Min            26.726385
V Predictions Mean           1063.1812
V Predictions Std            302.09424
V Predictions Max            1373.6344
V Predictions Min            27.335217
Log Pis Mean                 0.13978985
Log Pis Std                  2.130511
Log Pis Max                  9.844552
Log Pis Min                  -4.8214827
Policy mu Mean               0.25508285
Policy mu Std                0.92322135
Policy mu Max                3.5151057
Policy mu Min                -2.4329643
Policy log std Mean          -0.5989675
Policy log std Std           0.23943317
Policy log std Max           0.15445155
Policy log std Min           -1.6589558
Z mean eval                  0.03382548
Z variance eval              0.00564657
total_rewards                [3017.17697776 1321.77096348 3014.38558231 1443.79911085 3047.68841146
 3012.65230467 3016.1844627  3032.82164127 3048.23374966 2988.10185535]
total_rewards_mean           2694.2815059518116
total_rewards_std            656.5302313482225
total_rewards_max            3048.2337496646137
total_rewards_min            1321.770963480711
Number of train steps total  356000
Number of env steps total    294520
Number of rollouts total     0
Train Time (s)               144.1684481059201
(Previous) Eval Time (s)     19.26307109091431
Sample Time (s)              6.6344173308461905
Epoch Time (s)               170.0659365276806
Total Train Time (s)         13761.33393352991
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:19:01.635177 UTC | [2020_01_10_09_29_40] Iteration #88 | Epoch Duration: 170.1557650566101
2020-01-10 13:19:01.635491 UTC | [2020_01_10_09_29_40] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034264408
Z variance train             0.0056437408
KL Divergence                11.006069
KL Loss                      1.1006069
QF Loss                      801.1315
VF Loss                      80.905876
Policy Loss                  -1048.669
Q Predictions Mean           1043.5962
Q Predictions Std            325.1301
Q Predictions Max            1388.9238
Q Predictions Min            -47.70493
V Predictions Mean           1047.946
V Predictions Std            325.6278
V Predictions Max            1385.7253
V Predictions Min            -177.3319
Log Pis Mean                 0.13797858
Log Pis Std                  2.1095557
Log Pis Max                  13.8263
Log Pis Min                  -7.8167257
Policy mu Mean               0.06248786
Policy mu Std                0.9400703
Policy mu Max                3.2621737
Policy mu Min                -3.1298468
Policy log std Mean          -0.5825219
Policy log std Std           0.22334677
Policy log std Max           0.117391825
Policy log std Min           -1.4089408
Z mean eval                  0.10138605
Z variance eval              0.0063650524
total_rewards                [3028.552665   3067.46519767 3026.07479817 3033.14285874  655.55217184
  631.35734049 2987.15736075 3092.03142658 3013.1201528   692.78203431]
total_rewards_mean           2322.7236006371672
total_rewards_std            1088.9939028432298
total_rewards_max            3092.0314265809616
total_rewards_min            631.357340487152
Number of train steps total  360000
Number of env steps total    298077
Number of rollouts total     0
Train Time (s)               142.65150833688676
(Previous) Eval Time (s)     14.040981906000525
Sample Time (s)              6.379708905238658
Epoch Time (s)               163.07219914812595
Total Train Time (s)         13924.488370344974
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:21:44.792764 UTC | [2020_01_10_09_29_40] Iteration #89 | Epoch Duration: 163.15702080726624
2020-01-10 13:21:44.793127 UTC | [2020_01_10_09_29_40] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10105245
Z variance train             0.0063692615
KL Divergence                10.310556
KL Loss                      1.0310557
QF Loss                      455.7214
VF Loss                      151.77965
Policy Loss                  -1089.6193
Q Predictions Mean           1078.98
Q Predictions Std            285.23172
Q Predictions Max            1399.755
Q Predictions Min            8.016233
V Predictions Mean           1094.7015
V Predictions Std            276.64548
V Predictions Max            1421.7448
V Predictions Min            28.16605
Log Pis Mean                 0.5561819
Log Pis Std                  2.4661577
Log Pis Max                  10.739164
Log Pis Min                  -7.424637
Policy mu Mean               0.21653634
Policy mu Std                1.0439302
Policy mu Max                4.1442204
Policy mu Min                -3.0134284
Policy log std Mean          -0.6168837
Policy log std Std           0.28273475
Policy log std Max           0.16406065
Policy log std Min           -3.3936355
Z mean eval                  0.01865226
Z variance eval              0.004828495
total_rewards                [2999.35687912 3025.09436535 3035.44015611 1757.92975715 3023.96621207
 1665.20431622  606.03214875 3046.49276131 3037.599269   2402.24037602]
total_rewards_mean           2459.935624110681
total_rewards_std            806.359544623989
total_rewards_max            3046.4927613132045
total_rewards_min            606.0321487514798
Number of train steps total  364000
Number of env steps total    301641
Number of rollouts total     0
Train Time (s)               143.79214818682522
(Previous) Eval Time (s)     15.105748319998384
Sample Time (s)              6.5756745440885425
Epoch Time (s)               165.47357105091214
Total Train Time (s)         14090.045035003684
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:24:30.352092 UTC | [2020_01_10_09_29_40] Iteration #90 | Epoch Duration: 165.55873322486877
2020-01-10 13:24:30.352356 UTC | [2020_01_10_09_29_40] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018684838
Z variance train             0.004837818
KL Divergence                11.339868
KL Loss                      1.1339868
QF Loss                      258.36298
VF Loss                      92.544846
Policy Loss                  -1074.6703
Q Predictions Mean           1069.4187
Q Predictions Std            326.83987
Q Predictions Max            1407.3663
Q Predictions Min            -40.46109
V Predictions Mean           1078.7119
V Predictions Std            325.08807
V Predictions Max            1406.9825
V Predictions Min            -27.367197
Log Pis Mean                 0.36591136
Log Pis Std                  2.283959
Log Pis Max                  12.24428
Log Pis Min                  -8.342561
Policy mu Mean               0.06574526
Policy mu Std                0.9764149
Policy mu Max                3.150639
Policy mu Min                -2.612895
Policy log std Mean          -0.6222175
Policy log std Std           0.2978117
Policy log std Max           -0.009239674
Policy log std Min           -3.3161712
Z mean eval                  0.023366142
Z variance eval              0.004218147
total_rewards                [3044.7223047  3044.31058864  641.64419795 3070.92572421 3011.74637734
 2986.957567   2985.1935289  3036.38699602 1180.71368382 3035.26252897]
total_rewards_mean           2603.7863497547046
total_rewards_std            855.2123109191793
total_rewards_max            3070.9257242087697
total_rewards_min            641.6441979534952
Number of train steps total  368000
Number of env steps total    305220
Number of rollouts total     0
Train Time (s)               144.0603327699937
(Previous) Eval Time (s)     18.267209656070918
Sample Time (s)              6.409385923296213
Epoch Time (s)               168.73692834936082
Total Train Time (s)         14258.866282631177
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:27:19.177298 UTC | [2020_01_10_09_29_40] Iteration #91 | Epoch Duration: 168.82471799850464
2020-01-10 13:27:19.177619 UTC | [2020_01_10_09_29_40] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02286354
Z variance train             0.0042126914
KL Divergence                11.667155
KL Loss                      1.1667155
QF Loss                      1328.6165
VF Loss                      85.31656
Policy Loss                  -1089.8748
Q Predictions Mean           1089.5457
Q Predictions Std            328.66382
Q Predictions Max            1473.7167
Q Predictions Min            35.98708
V Predictions Mean           1085.4729
V Predictions Std            324.02927
V Predictions Max            1426.8522
V Predictions Min            40.32618
Log Pis Mean                 0.41001862
Log Pis Std                  2.3931994
Log Pis Max                  7.9040914
Log Pis Min                  -5.2951055
Policy mu Mean               0.18299574
Policy mu Std                1.0005982
Policy mu Max                3.048511
Policy mu Min                -3.033007
Policy log std Mean          -0.61415654
Policy log std Std           0.2793287
Policy log std Max           0.117846966
Policy log std Min           -2.3846169
Z mean eval                  0.05249955
Z variance eval              0.006998468
total_rewards                [3015.85721651 3040.77045236 3039.37997431  912.89826779  722.37063087
  711.66965248  635.00317972 1545.72697624  642.79250215  650.93767938]
total_rewards_mean           1491.7406531793984
total_rewards_std            1040.0811418134238
total_rewards_max            3040.770452361157
total_rewards_min            635.0031797153629
Number of train steps total  372000
Number of env steps total    308839
Number of rollouts total     0
Train Time (s)               141.87737022014335
(Previous) Eval Time (s)     10.624876202084124
Sample Time (s)              6.655579027254134
Epoch Time (s)               159.1578254494816
Total Train Time (s)         14418.109565625899
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:29:58.420782 UTC | [2020_01_10_09_29_40] Iteration #92 | Epoch Duration: 159.2429256439209
2020-01-10 13:29:58.420965 UTC | [2020_01_10_09_29_40] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050821256
Z variance train             0.0070490465
KL Divergence                11.008022
KL Loss                      1.1008023
QF Loss                      282.7575
VF Loss                      273.83853
Policy Loss                  -1126.0184
Q Predictions Mean           1116.3799
Q Predictions Std            264.9092
Q Predictions Max            1397.7391
Q Predictions Min            26.225716
V Predictions Mean           1117.3279
V Predictions Std            256.76285
V Predictions Max            1386.4222
V Predictions Min            18.875404
Log Pis Mean                 0.43253806
Log Pis Std                  2.2304952
Log Pis Max                  9.621893
Log Pis Min                  -5.705729
Policy mu Mean               0.12423668
Policy mu Std                0.9869041
Policy mu Max                3.8397107
Policy mu Min                -2.752945
Policy log std Mean          -0.6029887
Policy log std Std           0.2747643
Policy log std Max           0.014649093
Policy log std Min           -3.395016
Z mean eval                  0.029345503
Z variance eval              0.0047637215
total_rewards                [2962.59279835 3025.10201653 3004.25163165 3030.88848371 2987.51080225
 3034.44109277 2991.68097439 2990.17611368 2982.17812025 3021.25801883]
total_rewards_mean           3003.00800524261
total_rewards_std            22.77830203248371
total_rewards_max            3034.4410927727045
total_rewards_min            2962.5927983521988
Number of train steps total  376000
Number of env steps total    312432
Number of rollouts total     0
Train Time (s)               143.72536849183962
(Previous) Eval Time (s)     21.707918148953468
Sample Time (s)              6.340064883697778
Epoch Time (s)               171.77335152449086
Total Train Time (s)         14589.975087522529
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:32:50.291023 UTC | [2020_01_10_09_29_40] Iteration #93 | Epoch Duration: 171.86991572380066
2020-01-10 13:32:50.291200 UTC | [2020_01_10_09_29_40] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030449888
Z variance train             0.004778375
KL Divergence                10.942423
KL Loss                      1.0942423
QF Loss                      217.99083
VF Loss                      88.55021
Policy Loss                  -1116.2324
Q Predictions Mean           1110.7683
Q Predictions Std            298.94736
Q Predictions Max            1427.2748
Q Predictions Min            -1.2436368
V Predictions Mean           1116.529
V Predictions Std            282.5954
V Predictions Max            1427.5652
V Predictions Min            30.143856
Log Pis Mean                 0.37093788
Log Pis Std                  2.422378
Log Pis Max                  17.679062
Log Pis Min                  -4.4599257
Policy mu Mean               0.08889157
Policy mu Std                1.0315751
Policy mu Max                5.5860815
Policy mu Min                -3.1815856
Policy log std Mean          -0.5796571
Policy log std Std           0.28439045
Policy log std Max           0.17007446
Policy log std Min           -2.989968
Z mean eval                  0.029339895
Z variance eval              0.0042998274
total_rewards                [3032.53922497 3053.14914547 3051.04664161 3048.91784089 3002.59802379
 2992.49397117 3019.02916329 2991.46737765 3014.25716984 3017.87053085]
total_rewards_mean           3022.3369089524417
total_rewards_std            22.166642162242788
total_rewards_max            3053.149145469771
total_rewards_min            2991.4673776457585
Number of train steps total  380000
Number of env steps total    315997
Number of rollouts total     0
Train Time (s)               143.8480536560528
(Previous) Eval Time (s)     21.799759461078793
Sample Time (s)              5.742824115790427
Epoch Time (s)               171.39063723292202
Total Train Time (s)         14761.448212957941
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:35:41.767556 UTC | [2020_01_10_09_29_40] Iteration #94 | Epoch Duration: 171.47618412971497
2020-01-10 13:35:41.767883 UTC | [2020_01_10_09_29_40] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02982983
Z variance train             0.004299202
KL Divergence                11.29712
KL Loss                      1.129712
QF Loss                      548.3588
VF Loss                      140.73819
Policy Loss                  -1135.7191
Q Predictions Mean           1126.1237
Q Predictions Std            288.2237
Q Predictions Max            1432.797
Q Predictions Min            15.198274
V Predictions Mean           1132.0747
V Predictions Std            279.99228
V Predictions Max            1428.8275
V Predictions Min            17.703253
Log Pis Mean                 0.25487044
Log Pis Std                  2.0997179
Log Pis Max                  13.091333
Log Pis Min                  -4.132394
Policy mu Mean               0.1478899
Policy mu Std                0.92586327
Policy mu Max                3.7539823
Policy mu Min                -2.9549937
Policy log std Mean          -0.60308367
Policy log std Std           0.26455012
Policy log std Max           0.059504986
Policy log std Min           -2.390905
Z mean eval                  0.045499116
Z variance eval              0.0032521132
total_rewards                [2810.0956262  3036.24911593 3060.34678921 2988.95722395 3021.27684236
 3008.67377994 3031.17088133 3000.78517231 3022.80541276 3035.84899838]
total_rewards_mean           3001.620984237243
total_rewards_std            66.64869684985611
total_rewards_max            3060.346789208734
total_rewards_min            2810.0956262034056
Number of train steps total  384000
Number of env steps total    319597
Number of rollouts total     0
Train Time (s)               142.82383833825588
(Previous) Eval Time (s)     18.24444421613589
Sample Time (s)              6.430680147372186
Epoch Time (s)               167.49896270176396
Total Train Time (s)         14929.029477889184
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:38:29.351024 UTC | [2020_01_10_09_29_40] Iteration #95 | Epoch Duration: 167.58289909362793
2020-01-10 13:38:29.351237 UTC | [2020_01_10_09_29_40] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045578796
Z variance train             0.0032501672
KL Divergence                12.18192
KL Loss                      1.218192
QF Loss                      249.81676
VF Loss                      100.29768
Policy Loss                  -1068.4551
Q Predictions Mean           1061.3057
Q Predictions Std            339.97098
Q Predictions Max            1418.2378
Q Predictions Min            32.75558
V Predictions Mean           1066.3986
V Predictions Std            335.0177
V Predictions Max            1432.5232
V Predictions Min            36.5785
Log Pis Mean                 0.18116707
Log Pis Std                  2.3151748
Log Pis Max                  11.690403
Log Pis Min                  -3.9823837
Policy mu Mean               -0.038291756
Policy mu Std                0.9688194
Policy mu Max                3.4851604
Policy mu Min                -3.9752276
Policy log std Mean          -0.5868729
Policy log std Std           0.2526162
Policy log std Max           0.07961124
Policy log std Min           -1.7200491
Z mean eval                  0.03810191
Z variance eval              0.0034198943
total_rewards                [3053.10721141 3061.89032378 3082.51367475 3047.07973629 3062.48942658
 3033.8523895  3004.02650561 3066.64569705 3061.84663401 2073.64060372]
total_rewards_mean           2954.7092202710983
total_rewards_std            294.3872892108192
total_rewards_max            3082.513674752383
total_rewards_min            2073.640603722868
Number of train steps total  388000
Number of env steps total    323164
Number of rollouts total     0
Train Time (s)               142.78429819690064
(Previous) Eval Time (s)     18.116459048818797
Sample Time (s)              6.710664211772382
Epoch Time (s)               167.61142145749182
Total Train Time (s)         15096.723239440471
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:41:17.049953 UTC | [2020_01_10_09_29_40] Iteration #96 | Epoch Duration: 167.6985445022583
2020-01-10 13:41:17.050275 UTC | [2020_01_10_09_29_40] Iteration #96 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04383336
Z variance train             0.0034175634
KL Divergence                12.214962
KL Loss                      1.2214962
QF Loss                      255.49707
VF Loss                      48.903473
Policy Loss                  -1117.4158
Q Predictions Mean           1113.8412
Q Predictions Std            306.4083
Q Predictions Max            1430.6868
Q Predictions Min            60.2285
V Predictions Mean           1119.0425
V Predictions Std            302.04132
V Predictions Max            1425.3157
V Predictions Min            64.37913
Log Pis Mean                 0.41328743
Log Pis Std                  2.4006517
Log Pis Max                  9.844532
Log Pis Min                  -5.542013
Policy mu Mean               0.05146122
Policy mu Std                1.020121
Policy mu Max                2.961844
Policy mu Min                -3.1750143
Policy log std Mean          -0.6165973
Policy log std Std           0.24017991
Policy log std Max           0.03296101
Policy log std Min           -1.4645793
Z mean eval                  0.04904379
Z variance eval              0.003341426
total_rewards                [2983.66814868 3003.46655243 3026.52111427 3016.4559849  2997.7075137
 2984.91386915 2995.99912946 3004.16279946 3034.00507244 2981.58505727]
total_rewards_mean           3002.8485241753037
total_rewards_std            17.1272069055681
total_rewards_max            3034.0050724397042
total_rewards_min            2981.585057273834
Number of train steps total  392000
Number of env steps total    326731
Number of rollouts total     0
Train Time (s)               144.54217849392444
(Previous) Eval Time (s)     18.379175999667495
Sample Time (s)              6.556672406382859
Epoch Time (s)               169.4780268999748
Total Train Time (s)         15266.453302221373
Epoch                        97
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:44:06.781256 UTC | [2020_01_10_09_29_40] Iteration #97 | Epoch Duration: 169.73073768615723
2020-01-10 13:44:06.781471 UTC | [2020_01_10_09_29_40] Iteration #97 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04899979
Z variance train             0.0033463058
KL Divergence                11.81976
KL Loss                      1.1819761
QF Loss                      489.6468
VF Loss                      98.320145
Policy Loss                  -1046.9608
Q Predictions Mean           1042.5913
Q Predictions Std            351.1519
Q Predictions Max            1408.7672
Q Predictions Min            -0.017012835
V Predictions Mean           1044.9971
V Predictions Std            349.06454
V Predictions Max            1408.2914
V Predictions Min            10.072028
Log Pis Mean                 0.38377562
Log Pis Std                  2.000831
Log Pis Max                  7.2381
Log Pis Min                  -4.353858
Policy mu Mean               0.077146105
Policy mu Std                0.9824205
Policy mu Max                2.7894971
Policy mu Min                -2.583015
Policy log std Mean          -0.60528994
Policy log std Std           0.2370314
Policy log std Max           0.050648868
Policy log std Min           -2.909391
Z mean eval                  0.0331906
Z variance eval              0.0034210435
total_rewards                [3064.41220451 1101.18571571 3077.81722682 2995.5853313  3054.0646825
  722.50315966 3073.20668737 3011.15050501 2733.12904248 3098.57977769]
total_rewards_mean           2593.163433304225
total_rewards_std            850.6994880345367
total_rewards_max            3098.5797776901236
total_rewards_min            722.5031596598197
Number of train steps total  396000
Number of env steps total    330286
Number of rollouts total     0
Train Time (s)               144.5909834271297
(Previous) Eval Time (s)     15.339223093353212
Sample Time (s)              6.579812330659479
Epoch Time (s)               166.51001885114238
Total Train Time (s)         15433.060734753031
Epoch                        98
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:46:53.391918 UTC | [2020_01_10_09_29_40] Iteration #98 | Epoch Duration: 166.61028265953064
2020-01-10 13:46:53.392167 UTC | [2020_01_10_09_29_40] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033136375
Z variance train             0.0034356222
KL Divergence                12.107371
KL Loss                      1.2107371
QF Loss                      289.47556
VF Loss                      245.69705
Policy Loss                  -1130.2134
Q Predictions Mean           1121.3337
Q Predictions Std            301.37064
Q Predictions Max            1452.4955
Q Predictions Min            81.44585
V Predictions Mean           1116.9567
V Predictions Std            295.88327
V Predictions Max            1444.2089
V Predictions Min            80.87009
Log Pis Mean                 0.32288677
Log Pis Std                  2.2237146
Log Pis Max                  9.640448
Log Pis Min                  -6.2735014
Policy mu Mean               0.14924787
Policy mu Std                0.9791634
Policy mu Max                2.8098862
Policy mu Min                -2.7094579
Policy log std Mean          -0.63178223
Policy log std Std           0.25873807
Policy log std Max           0.34986717
Policy log std Min           -2.436576
Z mean eval                  0.036447145
Z variance eval              0.0034695368
total_rewards                [3069.89403332 3069.38224931 3043.85240875 3028.92137671 3055.72663095
 3074.97488993 3095.68906716 3049.16313396 3045.85240617 3026.19102217]
total_rewards_mean           3055.964721843892
total_rewards_std            20.558615986098335
total_rewards_max            3095.689067159029
total_rewards_min            3026.1910221748085
Number of train steps total  400000
Number of env steps total    333862
Number of rollouts total     0
Train Time (s)               145.96969400113449
(Previous) Eval Time (s)     21.990768285933882
Sample Time (s)              6.625244870316237
Epoch Time (s)               174.5857071573846
Total Train Time (s)         15607.734618754592
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:49:48.065965 UTC | [2020_01_10_09_29_40] Iteration #99 | Epoch Duration: 174.67363595962524
2020-01-10 13:49:48.066092 UTC | [2020_01_10_09_29_40] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036442704
Z variance train             0.003472202
KL Divergence                12.545534
KL Loss                      1.2545534
QF Loss                      453.9306
VF Loss                      405.1867
Policy Loss                  -1111.6315
Q Predictions Mean           1110.4119
Q Predictions Std            305.46255
Q Predictions Max            1422.3452
Q Predictions Min            1.7133895
V Predictions Mean           1116.1873
V Predictions Std            298.86826
V Predictions Max            1433.1799
V Predictions Min            30.0909
Log Pis Mean                 0.2959838
Log Pis Std                  2.1067162
Log Pis Max                  9.265177
Log Pis Min                  -4.888751
Policy mu Mean               0.10359997
Policy mu Std                0.94906336
Policy mu Max                3.8813534
Policy mu Min                -2.5131621
Policy log std Mean          -0.64704734
Policy log std Std           0.28752303
Policy log std Max           0.13457656
Policy log std Min           -3.592922
Z mean eval                  0.024093295
Z variance eval              0.0057999054
total_rewards                [3056.71372464 3057.37536951 3062.47822507 3101.49775567 3000.79403864
 3045.13743472 3065.89940662 3077.89014111 3057.97061133 3108.17829814]
total_rewards_mean           3063.3935005426856
total_rewards_std            28.349786314884042
total_rewards_max            3108.178298136072
total_rewards_min            3000.7940386378077
Number of train steps total  404000
Number of env steps total    337957
Number of rollouts total     0
Train Time (s)               144.2191386851482
(Previous) Eval Time (s)     21.538712464738637
Sample Time (s)              6.700392011087388
Epoch Time (s)               172.45824316097423
Total Train Time (s)         15780.27487632772
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:52:40.607295 UTC | [2020_01_10_09_29_40] Iteration #100 | Epoch Duration: 172.54110193252563
2020-01-10 13:52:40.607467 UTC | [2020_01_10_09_29_40] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023301918
Z variance train             0.005791623
KL Divergence                10.8128805
KL Loss                      1.0812881
QF Loss                      201.4347
VF Loss                      107.36505
Policy Loss                  -1140.1317
Q Predictions Mean           1135.8019
Q Predictions Std            290.27365
Q Predictions Max            1437.4729
Q Predictions Min            23.020638
V Predictions Mean           1134.8287
V Predictions Std            287.10928
V Predictions Max            1429.1621
V Predictions Min            9.576209
Log Pis Mean                 0.31745636
Log Pis Std                  2.0589838
Log Pis Max                  6.37648
Log Pis Min                  -7.3486214
Policy mu Mean               0.10297518
Policy mu Std                0.9650595
Policy mu Max                3.2712402
Policy mu Min                -2.7859464
Policy log std Mean          -0.6200593
Policy log std Std           0.25131947
Policy log std Max           0.11381376
Policy log std Min           -2.644161
Z mean eval                  0.058465164
Z variance eval              0.0037880559
total_rewards                [3099.92226468 3153.43809971 3178.61002883 3137.43903886 3141.36133845
 3140.36528647 3127.14501109 3144.6736042  3132.42232315 3132.85506413]
total_rewards_mean           3138.8232059567995
total_rewards_std            18.888629082140522
total_rewards_max            3178.6100288327116
total_rewards_min            3099.9222646827016
Number of train steps total  408000
Number of env steps total    342067
Number of rollouts total     0
Train Time (s)               144.11710609542206
(Previous) Eval Time (s)     21.64043352380395
Sample Time (s)              6.669433146715164
Epoch Time (s)               172.42697276594117
Total Train Time (s)         15952.866148796864
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:55:33.201358 UTC | [2020_01_10_09_29_40] Iteration #101 | Epoch Duration: 172.5937466621399
2020-01-10 13:55:33.201595 UTC | [2020_01_10_09_29_40] Iteration #101 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058955323
Z variance train             0.0037817892
KL Divergence                11.567513
KL Loss                      1.1567514
QF Loss                      1610.4556
VF Loss                      639.7359
Policy Loss                  -1119.9901
Q Predictions Mean           1110.8872
Q Predictions Std            314.75424
Q Predictions Max            1451.594
Q Predictions Min            -1.4544129
V Predictions Mean           1113.7067
V Predictions Std            298.89725
V Predictions Max            1445.7599
V Predictions Min            36.58605
Log Pis Mean                 0.6047487
Log Pis Std                  2.7344568
Log Pis Max                  19.282951
Log Pis Min                  -8.517191
Policy mu Mean               0.19748773
Policy mu Std                1.0376425
Policy mu Max                4.306444
Policy mu Min                -4.7340198
Policy log std Mean          -0.5894578
Policy log std Std           0.24641973
Policy log std Max           0.23207515
Policy log std Min           -1.9592751
Z mean eval                  0.07609357
Z variance eval              0.0040045166
total_rewards                [3176.59077047 3196.41824195 3173.77083227 3154.12913811 3143.8083119
 3168.14917939 3164.10303293 3173.49914242 3151.92405023 3177.00387007]
total_rewards_mean           3167.9396569740375
total_rewards_std            14.412694053974848
total_rewards_max            3196.418241946689
total_rewards_min            3143.8083119009852
Number of train steps total  412000
Number of env steps total    346135
Number of rollouts total     0
Train Time (s)               142.67837180569768
(Previous) Eval Time (s)     21.642435832880437
Sample Time (s)              6.62261975184083
Epoch Time (s)               170.94342739041895
Total Train Time (s)         16123.886948035099
Epoch                        102
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:58:24.226269 UTC | [2020_01_10_09_29_40] Iteration #102 | Epoch Duration: 171.02446389198303
2020-01-10 13:58:24.226597 UTC | [2020_01_10_09_29_40] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07706334
Z variance train             0.0039944705
KL Divergence                11.97769
KL Loss                      1.197769
QF Loss                      391.95
VF Loss                      68.43476
Policy Loss                  -1110.5735
Q Predictions Mean           1105.9219
Q Predictions Std            305.14246
Q Predictions Max            1446.181
Q Predictions Min            13.995138
V Predictions Mean           1113.3638
V Predictions Std            299.50546
V Predictions Max            1434.99
V Predictions Min            18.072735
Log Pis Mean                 0.42708617
Log Pis Std                  2.3225284
Log Pis Max                  8.752462
Log Pis Min                  -4.4098897
Policy mu Mean               0.21591954
Policy mu Std                1.0021726
Policy mu Max                3.144478
Policy mu Min                -3.005263
Policy log std Mean          -0.59916085
Policy log std Std           0.24779299
Policy log std Max           0.10836065
Policy log std Min           -2.4214485
Z mean eval                  0.03453908
Z variance eval              0.00654022
total_rewards                [1275.00043692 3013.8735363  3034.61116254 2997.10193393 3029.91026019
  930.29182115 3008.13914768 2971.37793048 3047.52097423 1265.5527459 ]
total_rewards_mean           2457.3379949303353
total_rewards_std            856.0513617573132
total_rewards_max            3047.5209742275165
total_rewards_min            930.2918211466258
Number of train steps total  416000
Number of env steps total    350340
Number of rollouts total     0
Train Time (s)               145.2149861161597
(Previous) Eval Time (s)     14.96976027591154
Sample Time (s)              6.626190287992358
Epoch Time (s)               166.8109366800636
Total Train Time (s)         16290.78034904832
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:01:11.122921 UTC | [2020_01_10_09_29_40] Iteration #103 | Epoch Duration: 166.89604496955872
2020-01-10 14:01:11.123202 UTC | [2020_01_10_09_29_40] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032609466
Z variance train             0.0065676123
KL Divergence                10.734938
KL Loss                      1.0734938
QF Loss                      369.71075
VF Loss                      120.448135
Policy Loss                  -1143.1846
Q Predictions Mean           1131.4912
Q Predictions Std            309.3903
Q Predictions Max            1440.2078
Q Predictions Min            -2.0728207
V Predictions Mean           1140.0852
V Predictions Std            306.51236
V Predictions Max            1459.8096
V Predictions Min            -1.8645612
Log Pis Mean                 0.45478272
Log Pis Std                  2.3593807
Log Pis Max                  8.669338
Log Pis Min                  -6.092862
Policy mu Mean               0.057979356
Policy mu Std                1.0383953
Policy mu Max                3.0829883
Policy mu Min                -2.716258
Policy log std Mean          -0.5946266
Policy log std Std           0.23769408
Policy log std Max           0.14918977
Policy log std Min           -2.5696182
Z mean eval                  0.02227038
Z variance eval              0.0074693076
total_rewards                [3043.54707026 3014.36231907 3079.46892249 3066.41187126 3041.55280812
 3014.56726793 3061.88422668 3080.26656112 3012.92715622 3030.98552388]
total_rewards_mean           3044.597372703439
total_rewards_std            25.05523271598905
total_rewards_max            3080.2665611192037
total_rewards_min            3012.9271562194035
Number of train steps total  420000
Number of env steps total    354542
Number of rollouts total     0
Train Time (s)               142.7282929182984
(Previous) Eval Time (s)     18.350774527993053
Sample Time (s)              6.4029933591373265
Epoch Time (s)               167.48206080542877
Total Train Time (s)         16458.385313135106
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:03:58.728333 UTC | [2020_01_10_09_29_40] Iteration #104 | Epoch Duration: 167.60493659973145
2020-01-10 14:03:58.728588 UTC | [2020_01_10_09_29_40] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02372705
Z variance train             0.0074716522
KL Divergence                9.922583
KL Loss                      0.99225825
QF Loss                      835.64465
VF Loss                      269.03714
Policy Loss                  -1105.3966
Q Predictions Mean           1097.2723
Q Predictions Std            327.01303
Q Predictions Max            1439.8903
Q Predictions Min            -2.2282128
V Predictions Mean           1106.0554
V Predictions Std            312.949
V Predictions Max            1444.9407
V Predictions Min            2.8327494
Log Pis Mean                 0.53397
Log Pis Std                  2.3131804
Log Pis Max                  11.629261
Log Pis Min                  -4.0544286
Policy mu Mean               0.19234009
Policy mu Std                1.0096159
Policy mu Max                3.684895
Policy mu Min                -2.5403545
Policy log std Mean          -0.6116829
Policy log std Std           0.26375133
Policy log std Max           -0.027756393
Policy log std Min           -2.9495134
Z mean eval                  0.03797689
Z variance eval              0.004628859
total_rewards                [3028.6819296  3089.94685721 3024.40814989 3029.79450521 3013.95024634
 3059.53740721 3022.85355992 3047.95397867 3066.03014707 3056.69605033]
total_rewards_mean           3043.985283145053
total_rewards_std            22.770843511901536
total_rewards_max            3089.946857208224
total_rewards_min            3013.9502463372105
Number of train steps total  424000
Number of env steps total    358682
Number of rollouts total     0
Train Time (s)               144.1647534794174
(Previous) Eval Time (s)     18.194626533892006
Sample Time (s)              5.924783783964813
Epoch Time (s)               168.28416379727423
Total Train Time (s)         16626.872594454326
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:06:47.224221 UTC | [2020_01_10_09_29_40] Iteration #105 | Epoch Duration: 168.49544954299927
2020-01-10 14:06:47.224388 UTC | [2020_01_10_09_29_40] Iteration #105 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037772506
Z variance train             0.0046378495
KL Divergence                10.995287
KL Loss                      1.0995287
QF Loss                      583.5976
VF Loss                      224.92471
Policy Loss                  -1122.5027
Q Predictions Mean           1107.3461
Q Predictions Std            336.45386
Q Predictions Max            1469.6426
Q Predictions Min            5.399564
V Predictions Mean           1120.1533
V Predictions Std            315.22293
V Predictions Max            1452.2942
V Predictions Min            31.251768
Log Pis Mean                 0.33762214
Log Pis Std                  2.4302678
Log Pis Max                  9.278265
Log Pis Min                  -5.0391784
Policy mu Mean               0.10017695
Policy mu Std                1.0236068
Policy mu Max                3.3005
Policy mu Min                -3.0069566
Policy log std Mean          -0.5782942
Policy log std Std           0.2660822
Policy log std Max           0.12604803
Policy log std Min           -1.8927538
Z mean eval                  0.04143202
Z variance eval              0.0061447197
total_rewards                [2978.01538905 2991.60575813 2972.87574174 2958.81656896 3003.0271672
 1537.98516291 2968.12875665 2935.05899084 2995.00993224 2982.31141506]
total_rewards_mean           2832.283488277397
total_rewards_std            431.8292196004984
total_rewards_max            3003.0271671983924
total_rewards_min            1537.985162907008
Number of train steps total  428000
Number of env steps total    362768
Number of rollouts total     0
Train Time (s)               143.2281892276369
(Previous) Eval Time (s)     20.440243168268353
Sample Time (s)              6.867571588605642
Epoch Time (s)               170.5360039845109
Total Train Time (s)         16797.494523285422
Epoch                        106
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:09:37.845570 UTC | [2020_01_10_09_29_40] Iteration #106 | Epoch Duration: 170.6209306716919
2020-01-10 14:09:37.845995 UTC | [2020_01_10_09_29_40] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04222078
Z variance train             0.006144253
KL Divergence                10.395853
KL Loss                      1.0395854
QF Loss                      481.42123
VF Loss                      308.46793
Policy Loss                  -1115.6677
Q Predictions Mean           1106.5161
Q Predictions Std            327.5278
Q Predictions Max            1491.1527
Q Predictions Min            -58.1048
V Predictions Mean           1114.9789
V Predictions Std            313.67438
V Predictions Max            1471.8323
V Predictions Min            52.3495
Log Pis Mean                 0.2500023
Log Pis Std                  2.5299046
Log Pis Max                  13.429611
Log Pis Min                  -5.7404423
Policy mu Mean               0.13523303
Policy mu Std                0.99883544
Policy mu Max                4.9301443
Policy mu Min                -2.9081914
Policy log std Mean          -0.6068535
Policy log std Std           0.27085936
Policy log std Max           0.20843577
Policy log std Min           -4.3686256
Z mean eval                  0.037011836
Z variance eval              0.0056661186
total_rewards                [3133.14303371  951.863296    759.69211994  803.91070628 2936.11765423
 3101.04412296 3106.64002952  979.68360694 1207.99587592 3111.4088039 ]
total_rewards_mean           2009.1499249403703
total_rewards_std            1075.5264707043716
total_rewards_max            3133.1430337103666
total_rewards_min            759.692119935016
Number of train steps total  432000
Number of env steps total    366867
Number of rollouts total     0
Train Time (s)               144.3031963747926
(Previous) Eval Time (s)     14.139895199798048
Sample Time (s)              6.51330390246585
Epoch Time (s)               164.9563954770565
Total Train Time (s)         16962.532924295403
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:12:22.884169 UTC | [2020_01_10_09_29_40] Iteration #107 | Epoch Duration: 165.0379467010498
2020-01-10 14:12:22.884348 UTC | [2020_01_10_09_29_40] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034319628
Z variance train             0.005668454
KL Divergence                10.664821
KL Loss                      1.0664821
QF Loss                      388.25302
VF Loss                      103.44565
Policy Loss                  -1114.1118
Q Predictions Mean           1112.1396
Q Predictions Std            314.65918
Q Predictions Max            1441.0267
Q Predictions Min            35.07912
V Predictions Mean           1119.4585
V Predictions Std            309.23642
V Predictions Max            1441.3046
V Predictions Min            58.95156
Log Pis Mean                 0.5555325
Log Pis Std                  2.3346155
Log Pis Max                  12.626492
Log Pis Min                  -4.1175003
Policy mu Mean               0.20990849
Policy mu Std                1.0028265
Policy mu Max                3.9428434
Policy mu Min                -2.4783602
Policy log std Mean          -0.60205126
Policy log std Std           0.27022895
Policy log std Max           0.27439415
Policy log std Min           -3.1971545
Z mean eval                  0.054891508
Z variance eval              0.011301152
total_rewards                [3015.34284092  758.39152878 3051.19609792 3030.07847554 3039.17572571
 3025.29674259  734.25022489 3023.6984534   736.93277898  942.58287015]
total_rewards_mean           2135.694573887596
total_rewards_std            1097.685192389502
total_rewards_max            3051.1960979195837
total_rewards_min            734.2502248857082
Number of train steps total  436000
Number of env steps total    370959
Number of rollouts total     0
Train Time (s)               143.80710751190782
(Previous) Eval Time (s)     15.099762667901814
Sample Time (s)              6.619093989953399
Epoch Time (s)               165.52596416976303
Total Train Time (s)         17128.140562143642
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:15:08.492431 UTC | [2020_01_10_09_29_40] Iteration #108 | Epoch Duration: 165.60795831680298
2020-01-10 14:15:08.492573 UTC | [2020_01_10_09_29_40] Iteration #108 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056322254
Z variance train             0.011291231
KL Divergence                9.464065
KL Loss                      0.9464065
QF Loss                      602.80066
VF Loss                      172.81767
Policy Loss                  -1103.5002
Q Predictions Mean           1094.0294
Q Predictions Std            332.31488
Q Predictions Max            1420.4082
Q Predictions Min            -28.798124
V Predictions Mean           1112.2737
V Predictions Std            318.4758
V Predictions Max            1433.9801
V Predictions Min            28.146362
Log Pis Mean                 0.27716053
Log Pis Std                  2.659089
Log Pis Max                  13.335884
Log Pis Min                  -7.1445894
Policy mu Mean               0.111745566
Policy mu Std                1.017251
Policy mu Max                3.7924633
Policy mu Min                -2.7042532
Policy log std Mean          -0.5607788
Policy log std Std           0.25067952
Policy log std Max           0.28448927
Policy log std Min           -2.340448
Z mean eval                  0.032777164
Z variance eval              0.0034601302
total_rewards                [3036.87550456 3104.34701269 3043.15681406 3077.30989734 3106.0062242
  788.87019258 3047.55032179  917.8161249  3033.15732663 3105.49052073]
total_rewards_mean           2626.0579939485133
total_rewards_std            887.2469734940711
total_rewards_max            3106.0062241995875
total_rewards_min            788.8701925841985
Number of train steps total  440000
Number of env steps total    375054
Number of rollouts total     0
Train Time (s)               143.55441066995263
(Previous) Eval Time (s)     18.649123954586685
Sample Time (s)              6.60437482688576
Epoch Time (s)               168.80790945142508
Total Train Time (s)         17297.029292437714
Epoch                        109
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:17:57.384542 UTC | [2020_01_10_09_29_40] Iteration #109 | Epoch Duration: 168.89178848266602
2020-01-10 14:17:57.384853 UTC | [2020_01_10_09_29_40] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029374933
Z variance train             0.0034525215
KL Divergence                12.008917
KL Loss                      1.2008917
QF Loss                      508.01385
VF Loss                      142.11443
Policy Loss                  -1135.6482
Q Predictions Mean           1125.9092
Q Predictions Std            318.6545
Q Predictions Max            1477.394
Q Predictions Min            -15.016522
V Predictions Mean           1133.3389
V Predictions Std            314.4335
V Predictions Max            1473.3542
V Predictions Min            9.493334
Log Pis Mean                 0.471494
Log Pis Std                  2.2588222
Log Pis Max                  9.893053
Log Pis Min                  -7.7781057
Policy mu Mean               0.12667473
Policy mu Std                0.9980471
Policy mu Max                2.391281
Policy mu Min                -3.0880446
Policy log std Mean          -0.5937248
Policy log std Std           0.24462436
Policy log std Max           0.07655549
Policy log std Min           -2.0364108
Z mean eval                  0.042545266
Z variance eval              0.006140539
total_rewards                [3149.09339832 3182.15886249 3199.61676916 3235.14839338 3181.48360761
 1561.79387812 3159.78195654 3185.149819   3172.48014767 3124.82853695]
total_rewards_mean           3015.153536923631
total_rewards_std            485.2598747229351
total_rewards_max            3235.14839338413
total_rewards_min            1561.7938781211521
Number of train steps total  444000
Number of env steps total    379137
Number of rollouts total     0
Train Time (s)               144.41782766859978
(Previous) Eval Time (s)     20.47085422417149
Sample Time (s)              6.450837305746973
Epoch Time (s)               171.33951919851825
Total Train Time (s)         17468.451008529402
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:20:48.808701 UTC | [2020_01_10_09_29_40] Iteration #110 | Epoch Duration: 171.42366242408752
2020-01-10 14:20:48.808945 UTC | [2020_01_10_09_29_40] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043121338
Z variance train             0.006134471
KL Divergence                10.852088
KL Loss                      1.0852088
QF Loss                      147.58218
VF Loss                      111.450195
Policy Loss                  -1133.0785
Q Predictions Mean           1135.9475
Q Predictions Std            347.80643
Q Predictions Max            1493.3839
Q Predictions Min            -29.230558
V Predictions Mean           1141.081
V Predictions Std            344.5069
V Predictions Max            1494.1255
V Predictions Min            -9.289371
Log Pis Mean                 0.104404524
Log Pis Std                  2.1107924
Log Pis Max                  7.481063
Log Pis Min                  -5.6687784
Policy mu Mean               0.22090434
Policy mu Std                0.9383008
Policy mu Max                3.0435433
Policy mu Min                -3.214918
Policy log std Mean          -0.5628856
Policy log std Std           0.23573926
Policy log std Max           0.042735517
Policy log std Min           -2.8308048
Z mean eval                  0.066407435
Z variance eval              0.0069452925
total_rewards                [ 834.63105652 1866.22155933 3112.40064537 3099.5592468  1537.83548611
  984.5917389  3055.49424679 3047.46111192 3127.58722663 3102.04401376]
total_rewards_mean           2376.782633213991
total_rewards_std            913.4901463227923
total_rewards_max            3127.587226633927
total_rewards_min            834.6310565195839
Number of train steps total  448000
Number of env steps total    383239
Number of rollouts total     0
Train Time (s)               144.85967733804137
(Previous) Eval Time (s)     16.87582703633234
Sample Time (s)              6.495804042555392
Epoch Time (s)               168.2313084169291
Total Train Time (s)         17636.76283149235
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:23:37.122057 UTC | [2020_01_10_09_29_40] Iteration #111 | Epoch Duration: 168.31288480758667
2020-01-10 14:23:37.122324 UTC | [2020_01_10_09_29_40] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06632137
Z variance train             0.0069477023
KL Divergence                10.4572735
KL Loss                      1.0457274
QF Loss                      383.30762
VF Loss                      100.360535
Policy Loss                  -1180.555
Q Predictions Mean           1173.687
Q Predictions Std            302.60547
Q Predictions Max            1480.4109
Q Predictions Min            26.531918
V Predictions Mean           1175.1489
V Predictions Std            292.2773
V Predictions Max            1472.5908
V Predictions Min            60.88148
Log Pis Mean                 0.36574414
Log Pis Std                  2.059434
Log Pis Max                  6.8339915
Log Pis Min                  -4.4819045
Policy mu Mean               0.16934192
Policy mu Std                0.97412866
Policy mu Max                2.7065654
Policy mu Min                -3.021419
Policy log std Mean          -0.56880695
Policy log std Std           0.23573482
Policy log std Max           0.11632216
Policy log std Min           -2.1704845
Z mean eval                  0.060128234
Z variance eval              0.0058719846
total_rewards                [3210.58111747 2813.92830805 1718.13809162 3163.03025247 1522.80936123
 3167.90164337 3209.19081775  987.18570198 3174.01883612 3107.81471936]
total_rewards_mean           2607.4598849431377
total_rewards_std            809.6425376896357
total_rewards_max            3210.5811174741366
total_rewards_min            987.1857019790809
Number of train steps total  452000
Number of env steps total    387298
Number of rollouts total     0
Train Time (s)               145.43989622220397
(Previous) Eval Time (s)     18.11393330199644
Sample Time (s)              6.484198892023414
Epoch Time (s)               170.03802841622382
Total Train Time (s)         17806.895759380423
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:26:27.255439 UTC | [2020_01_10_09_29_40] Iteration #112 | Epoch Duration: 170.13297271728516
2020-01-10 14:26:27.255580 UTC | [2020_01_10_09_29_40] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05920306
Z variance train             0.0058570327
KL Divergence                10.790632
KL Loss                      1.0790633
QF Loss                      516.3362
VF Loss                      127.288345
Policy Loss                  -1163.7734
Q Predictions Mean           1160.763
Q Predictions Std            330.0321
Q Predictions Max            1501.9637
Q Predictions Min            27.578903
V Predictions Mean           1161.2913
V Predictions Std            320.3637
V Predictions Max            1491.6821
V Predictions Min            31.86701
Log Pis Mean                 0.58528316
Log Pis Std                  2.3921018
Log Pis Max                  14.766553
Log Pis Min                  -3.4165077
Policy mu Mean               0.30570352
Policy mu Std                1.0078865
Policy mu Max                3.9494457
Policy mu Min                -2.7381463
Policy log std Mean          -0.5813895
Policy log std Std           0.25680974
Policy log std Max           0.29109538
Policy log std Min           -2.755995
Z mean eval                  0.047511525
Z variance eval              0.0040857615
total_rewards                [3148.14964947 1212.02283566  746.11103537 3187.91566616 1803.80332855
 3148.02303498  765.71243296 3146.34261849 1023.00816766  738.03290804]
total_rewards_mean           1891.9121677325584
total_rewards_std            1074.5602915292804
total_rewards_max            3187.915666156391
total_rewards_min            738.0329080363234
Number of train steps total  456000
Number of env steps total    391304
Number of rollouts total     0
Train Time (s)               142.22082243207842
(Previous) Eval Time (s)     11.017652320675552
Sample Time (s)              6.458447350654751
Epoch Time (s)               159.69692210340872
Total Train Time (s)         17966.7249784139
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:29:07.087054 UTC | [2020_01_10_09_29_40] Iteration #113 | Epoch Duration: 159.83136200904846
2020-01-10 14:29:07.087220 UTC | [2020_01_10_09_29_40] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050231792
Z variance train             0.0040812604
KL Divergence                11.693214
KL Loss                      1.1693214
QF Loss                      192.22421
VF Loss                      75.73066
Policy Loss                  -1185.1086
Q Predictions Mean           1182.0532
Q Predictions Std            307.98505
Q Predictions Max            1480.9595
Q Predictions Min            39.673344
V Predictions Mean           1184.8792
V Predictions Std            305.98047
V Predictions Max            1485.8695
V Predictions Min            33.896854
Log Pis Mean                 0.23201682
Log Pis Std                  2.2621088
Log Pis Max                  9.385822
Log Pis Min                  -4.2295136
Policy mu Mean               0.11838644
Policy mu Std                0.99538594
Policy mu Max                2.377448
Policy mu Min                -3.1218991
Policy log std Mean          -0.5835201
Policy log std Std           0.24660966
Policy log std Max           0.2356214
Policy log std Min           -1.4748396
Z mean eval                  0.044665407
Z variance eval              0.005399946
total_rewards                [2390.33647327 3275.74491011 1635.98880856  763.31154635 3218.07337729
 3235.14613344 2859.63575713 3249.80093894  972.97073288  984.00052424]
total_rewards_mean           2258.5009202207502
total_rewards_std            1008.5073948629256
total_rewards_max            3275.744910106732
total_rewards_min            763.3115463516455
Number of train steps total  460000
Number of env steps total    395412
Number of rollouts total     0
Train Time (s)               144.5474281962961
(Previous) Eval Time (s)     12.621298878919333
Sample Time (s)              6.612995478324592
Epoch Time (s)               163.78172255354002
Total Train Time (s)         18130.658945365343
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:31:51.023009 UTC | [2020_01_10_09_29_40] Iteration #114 | Epoch Duration: 163.93562579154968
2020-01-10 14:31:51.023281 UTC | [2020_01_10_09_29_40] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048972476
Z variance train             0.0053902785
KL Divergence                11.348256
KL Loss                      1.1348256
QF Loss                      296.1997
VF Loss                      136.3941
Policy Loss                  -1187.4186
Q Predictions Mean           1184.1373
Q Predictions Std            318.64166
Q Predictions Max            1498.8516
Q Predictions Min            -41.24592
V Predictions Mean           1181.5098
V Predictions Std            316.74185
V Predictions Max            1504.9274
V Predictions Min            35.684723
Log Pis Mean                 0.40895554
Log Pis Std                  2.2863119
Log Pis Max                  13.950737
Log Pis Min                  -4.4721766
Policy mu Mean               0.19312157
Policy mu Std                0.9822975
Policy mu Max                3.8492708
Policy mu Min                -2.671316
Policy log std Mean          -0.58879256
Policy log std Std           0.25200123
Policy log std Max           0.097857
Policy log std Min           -2.8879294
Z mean eval                  0.030020693
Z variance eval              0.004500203
total_rewards                [1780.39820492  976.70079247 3169.98659859 3230.58807259 1532.19355818
  997.78915243  748.04916102  765.01063087 1317.81973151 3277.17900333]
total_rewards_mean           1779.5714905891905
total_rewards_std            995.243678932415
total_rewards_max            3277.1790033268485
total_rewards_min            748.0491610241686
Number of train steps total  464000
Number of env steps total    399644
Number of rollouts total     0
Train Time (s)               143.25627588108182
(Previous) Eval Time (s)     12.094846408814192
Sample Time (s)              7.093940173275769
Epoch Time (s)               162.44506246317178
Total Train Time (s)         18293.187206200324
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:34:33.553701 UTC | [2020_01_10_09_29_40] Iteration #115 | Epoch Duration: 162.5301821231842
2020-01-10 14:34:33.553922 UTC | [2020_01_10_09_29_40] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031232929
Z variance train             0.004493913
KL Divergence                11.145337
KL Loss                      1.1145338
QF Loss                      655.86316
VF Loss                      252.75299
Policy Loss                  -1180.2197
Q Predictions Mean           1177.8154
Q Predictions Std            330.54974
Q Predictions Max            1513.0131
Q Predictions Min            12.313981
V Predictions Mean           1191.239
V Predictions Std            332.10153
V Predictions Max            1523.2985
V Predictions Min            28.85014
Log Pis Mean                 0.27337292
Log Pis Std                  2.0865843
Log Pis Max                  10.166439
Log Pis Min                  -4.423793
Policy mu Mean               0.22951889
Policy mu Std                0.9549699
Policy mu Max                2.8389764
Policy mu Min                -2.590442
Policy log std Mean          -0.59397644
Policy log std Std           0.23305735
Policy log std Max           0.1411596
Policy log std Min           -1.7935257
Z mean eval                  0.031758644
Z variance eval              0.00430088
total_rewards                [3104.10971734 3241.40946774 3231.88270092 3246.44589052 1236.09480708
 2236.51672886  486.09945316 2856.87956109 3224.67096887  990.71337791]
total_rewards_mean           2385.482267348413
total_rewards_std            1026.1315470815534
total_rewards_max            3246.445890517212
total_rewards_min            486.0994531646072
Number of train steps total  468000
Number of env steps total    403750
Number of rollouts total     0
Train Time (s)               143.86343303183094
(Previous) Eval Time (s)     15.61905365390703
Sample Time (s)              6.621272929944098
Epoch Time (s)               166.10375961568207
Total Train Time (s)         18459.367296249606
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:37:19.734008 UTC | [2020_01_10_09_29_40] Iteration #116 | Epoch Duration: 166.17998385429382
2020-01-10 14:37:19.734129 UTC | [2020_01_10_09_29_40] Iteration #116 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031139934
Z variance train             0.0043042
KL Divergence                11.452105
KL Loss                      1.1452105
QF Loss                      244.59555
VF Loss                      60.521435
Policy Loss                  -1166.1724
Q Predictions Mean           1159.9474
Q Predictions Std            329.2299
Q Predictions Max            1485.1736
Q Predictions Min            25.482882
V Predictions Mean           1163.7144
V Predictions Std            323.08496
V Predictions Max            1486.6038
V Predictions Min            21.894073
Log Pis Mean                 0.35610914
Log Pis Std                  2.2931535
Log Pis Max                  6.532848
Log Pis Min                  -4.9641023
Policy mu Mean               0.18599515
Policy mu Std                0.9775376
Policy mu Max                2.8714995
Policy mu Min                -3.8635333
Policy log std Mean          -0.5975665
Policy log std Std           0.2506519
Policy log std Max           0.13115364
Policy log std Min           -2.1680596
Z mean eval                  0.0513659
Z variance eval              0.009313915
total_rewards                [2014.59050057 3234.88163982 3194.76726077 3178.92323909 3162.2019881
 1500.21331768 1075.65672933  763.82872565 1058.47444466  965.60591568]
total_rewards_mean           2014.914376134404
total_rewards_std            1013.8896170458175
total_rewards_max            3234.8816398194067
total_rewards_min            763.8287256468556
Number of train steps total  472000
Number of env steps total    407802
Number of rollouts total     0
Train Time (s)               142.7974273758009
(Previous) Eval Time (s)     11.61783787701279
Sample Time (s)              6.4502643696032465
Epoch Time (s)               160.86552962241694
Total Train Time (s)         18620.311243957374
Epoch                        117
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:40:00.680058 UTC | [2020_01_10_09_29_40] Iteration #117 | Epoch Duration: 160.94582509994507
2020-01-10 14:40:00.680235 UTC | [2020_01_10_09_29_40] Iteration #117 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04822498
Z variance train             0.009310132
KL Divergence                9.298618
KL Loss                      0.92986184
QF Loss                      886.78357
VF Loss                      94.08034
Policy Loss                  -1149.6445
Q Predictions Mean           1138.1781
Q Predictions Std            380.98154
Q Predictions Max            1501.2372
Q Predictions Min            -293.54834
V Predictions Mean           1146.9739
V Predictions Std            368.24634
V Predictions Max            1503.6666
V Predictions Min            6.487335
Log Pis Mean                 0.31914452
Log Pis Std                  2.1846254
Log Pis Max                  15.28454
Log Pis Min                  -4.833251
Policy mu Mean               0.07754623
Policy mu Std                0.9571589
Policy mu Max                3.7984598
Policy mu Min                -3.9166515
Policy log std Mean          -0.60860044
Policy log std Std           0.26490328
Policy log std Max           0.10326254
Policy log std Min           -3.2691534
Z mean eval                  0.034629352
Z variance eval              0.005196714
total_rewards                [ 850.53867014 1075.44262406 3282.71939597 3253.88927493 3298.1338622
 3282.48145141  961.39061538 3267.63094537 3073.71534097 3246.76496069]
total_rewards_mean           2559.2707141119563
total_rewards_std            1048.2668124918462
total_rewards_max            3298.133862196429
total_rewards_min            850.5386701440738
Number of train steps total  476000
Number of env steps total    411912
Number of rollouts total     0
Train Time (s)               144.22890935000032
(Previous) Eval Time (s)     14.10743990400806
Sample Time (s)              6.4372862707823515
Epoch Time (s)               164.77363552479073
Total Train Time (s)         18785.16765603423
Epoch                        118
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:42:45.540992 UTC | [2020_01_10_09_29_40] Iteration #118 | Epoch Duration: 164.86056566238403
2020-01-10 14:42:45.541269 UTC | [2020_01_10_09_29_40] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034056388
Z variance train             0.005196476
KL Divergence                10.999206
KL Loss                      1.0999206
QF Loss                      545.6378
VF Loss                      70.130066
Policy Loss                  -1216.037
Q Predictions Mean           1207.4299
Q Predictions Std            295.35358
Q Predictions Max            1536.6307
Q Predictions Min            11.266407
V Predictions Mean           1215.989
V Predictions Std            291.05124
V Predictions Max            1546.5804
V Predictions Min            12.181767
Log Pis Mean                 0.26803523
Log Pis Std                  2.2953532
Log Pis Max                  7.68252
Log Pis Min                  -5.556466
Policy mu Mean               0.22824037
Policy mu Std                0.95244586
Policy mu Max                3.4526513
Policy mu Min                -2.5356076
Policy log std Mean          -0.6035651
Policy log std Std           0.22189061
Policy log std Max           0.020165145
Policy log std Min           -1.8488686
Z mean eval                  0.047605358
Z variance eval              0.004903731
total_rewards                [1041.09659328 3216.81561214 3219.3670109  3196.29657956 2908.61728347
  923.74102347 1160.25506175 3170.00396302 3186.92503163  997.35257824]
total_rewards_mean           2302.047073746854
total_rewards_std            1042.9710213418393
total_rewards_max            3219.3670109040486
total_rewards_min            923.7410234669643
Number of train steps total  480000
Number of env steps total    416053
Number of rollouts total     0
Train Time (s)               143.29245148040354
(Previous) Eval Time (s)     13.060673273168504
Sample Time (s)              6.739545613061637
Epoch Time (s)               163.09267036663368
Total Train Time (s)         18948.478577787988
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:45:28.855026 UTC | [2020_01_10_09_29_40] Iteration #119 | Epoch Duration: 163.31357312202454
2020-01-10 14:45:28.855308 UTC | [2020_01_10_09_29_40] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045133255
Z variance train             0.004899312
KL Divergence                11.187492
KL Loss                      1.1187493
QF Loss                      772.41986
VF Loss                      467.43423
Policy Loss                  -1181.1633
Q Predictions Mean           1177.1984
Q Predictions Std            342.88992
Q Predictions Max            1512.2432
Q Predictions Min            9.947037
V Predictions Mean           1173.8497
V Predictions Std            337.77826
V Predictions Max            1502.7767
V Predictions Min            4.382086
Log Pis Mean                 0.4056714
Log Pis Std                  2.501933
Log Pis Max                  15.3177395
Log Pis Min                  -5.64425
Policy mu Mean               0.14190932
Policy mu Std                1.0008441
Policy mu Max                4.818543
Policy mu Min                -3.9056778
Policy log std Mean          -0.6317937
Policy log std Std           0.28703782
Policy log std Max           0.014492393
Policy log std Min           -3.9466305
Z mean eval                  0.05451051
Z variance eval              0.0073609157
total_rewards                [3177.54709137 2555.92839461 2229.07489693 3186.55798981 3180.30283167
  964.69742464 1239.42922319  786.78089748 3165.63814749 2221.29525069]
total_rewards_mean           2270.7252147873087
total_rewards_std            913.573525109259
total_rewards_max            3186.5579898060782
total_rewards_min            786.7808974770315
Number of train steps total  484000
Number of env steps total    420282
Number of rollouts total     0
Train Time (s)               142.8089087707922
(Previous) Eval Time (s)     13.297901106998324
Sample Time (s)              6.566835690755397
Epoch Time (s)               162.6736455685459
Total Train Time (s)         19111.23955574399
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:48:11.616316 UTC | [2020_01_10_09_29_40] Iteration #120 | Epoch Duration: 162.76081252098083
2020-01-10 14:48:11.616486 UTC | [2020_01_10_09_29_40] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056983918
Z variance train             0.00738416
KL Divergence                10.95854
KL Loss                      1.095854
QF Loss                      364.80933
VF Loss                      1600.7109
Policy Loss                  -1204.872
Q Predictions Mean           1200.3108
Q Predictions Std            334.18637
Q Predictions Max            1556.1204
Q Predictions Min            -26.99271
V Predictions Mean           1199.7307
V Predictions Std            318.10632
V Predictions Max            1528.757
V Predictions Min            14.107361
Log Pis Mean                 0.29377982
Log Pis Std                  2.571169
Log Pis Max                  15.924372
Log Pis Min                  -4.4211016
Policy mu Mean               0.22725427
Policy mu Std                0.96567506
Policy mu Max                4.1431565
Policy mu Min                -3.434509
Policy log std Mean          -0.6032534
Policy log std Std           0.24219961
Policy log std Max           -0.016641974
Policy log std Min           -3.5470471
Z mean eval                  0.036520172
Z variance eval              0.009026346
total_rewards                [3256.51441848 1006.28391879 1726.6579202  2819.60158376 2501.15721948
 3239.52014185 3267.33853784 3269.32164481 1042.29811698 3218.13255296]
total_rewards_mean           2534.6826055147367
total_rewards_std            886.5574351218946
total_rewards_max            3269.3216448092144
total_rewards_min            1006.2839187904835
Number of train steps total  488000
Number of env steps total    424591
Number of rollouts total     0
Train Time (s)               143.6326664062217
(Previous) Eval Time (s)     17.02475950261578
Sample Time (s)              6.649436409585178
Epoch Time (s)               167.30686231842265
Total Train Time (s)         19278.625885781366
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:50:59.005015 UTC | [2020_01_10_09_29_40] Iteration #121 | Epoch Duration: 167.38840627670288
2020-01-10 14:50:59.005159 UTC | [2020_01_10_09_29_40] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03603831
Z variance train             0.009046965
KL Divergence                10.489639
KL Loss                      1.0489639
QF Loss                      1179.898
VF Loss                      102.57087
Policy Loss                  -1165.464
Q Predictions Mean           1165.1855
Q Predictions Std            372.02423
Q Predictions Max            1543.6663
Q Predictions Min            9.459421
V Predictions Mean           1169.0999
V Predictions Std            363.76907
V Predictions Max            1532.3881
V Predictions Min            12.718278
Log Pis Mean                 0.52756643
Log Pis Std                  2.457979
Log Pis Max                  9.331966
Log Pis Min                  -4.6722546
Policy mu Mean               0.14557534
Policy mu Std                1.0437447
Policy mu Max                3.879947
Policy mu Min                -2.8157446
Policy log std Mean          -0.6053924
Policy log std Std           0.24921423
Policy log std Max           0.07511014
Policy log std Min           -2.4423554
Z mean eval                  0.038847215
Z variance eval              0.0072544543
total_rewards                [3276.80110169 1045.70364203 3293.07477069 3188.62049008 3213.63852865
 1195.58089944 3269.69306267 1554.54342636 2570.1243967   829.24290664]
total_rewards_mean           2343.702322493635
total_rewards_std            1003.5300373478915
total_rewards_max            3293.0747706853276
total_rewards_min            829.2429066362829
Number of train steps total  492000
Number of env steps total    428849
Number of rollouts total     0
Train Time (s)               142.40747413272038
(Previous) Eval Time (s)     13.441155492793769
Sample Time (s)              6.492982016410679
Epoch Time (s)               162.34161164192483
Total Train Time (s)         19441.05518173054
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:53:41.438492 UTC | [2020_01_10_09_29_40] Iteration #122 | Epoch Duration: 162.43321323394775
2020-01-10 14:53:41.439061 UTC | [2020_01_10_09_29_40] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040398754
Z variance train             0.0072407955
KL Divergence                10.552681
KL Loss                      1.0552682
QF Loss                      307.27228
VF Loss                      144.02591
Policy Loss                  -1178.067
Q Predictions Mean           1166.2473
Q Predictions Std            327.40918
Q Predictions Max            1515.6129
Q Predictions Min            6.424862
V Predictions Mean           1172.5211
V Predictions Std            319.8059
V Predictions Max            1522.6342
V Predictions Min            83.45471
Log Pis Mean                 0.4803718
Log Pis Std                  2.5113325
Log Pis Max                  13.111847
Log Pis Min                  -4.4887543
Policy mu Mean               0.098053694
Policy mu Std                1.0437642
Policy mu Max                4.273702
Policy mu Min                -3.3940263
Policy log std Mean          -0.6039509
Policy log std Std           0.24050649
Policy log std Max           0.050346732
Policy log std Min           -1.6656954
Z mean eval                  0.02688305
Z variance eval              0.009982903
total_rewards                [3190.99313474 3128.44021096 2692.77609672 3188.99230141 3151.10101698
  919.68036339 2343.02455433 2418.07204542 3186.95755921  922.77325476]
total_rewards_mean           2514.281053792014
total_rewards_std            854.0780528375396
total_rewards_max            3190.993134738474
total_rewards_min            919.6803633929984
Number of train steps total  496000
Number of env steps total    433177
Number of rollouts total     0
Train Time (s)               141.5723414910026
(Previous) Eval Time (s)     17.431817393749952
Sample Time (s)              6.554410171695054
Epoch Time (s)               165.5585690564476
Total Train Time (s)         19606.69019586686
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:56:27.074310 UTC | [2020_01_10_09_29_40] Iteration #123 | Epoch Duration: 165.63489055633545
2020-01-10 14:56:27.074449 UTC | [2020_01_10_09_29_40] Iteration #123 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026715543
Z variance train             0.010002908
KL Divergence                9.353632
KL Loss                      0.93536323
QF Loss                      359.7469
VF Loss                      81.4973
Policy Loss                  -1213.0737
Q Predictions Mean           1203.7678
Q Predictions Std            327.66638
Q Predictions Max            1538.9753
Q Predictions Min            17.400934
V Predictions Mean           1210.7229
V Predictions Std            319.91125
V Predictions Max            1539.7903
V Predictions Min            16.893076
Log Pis Mean                 0.27851388
Log Pis Std                  2.0320165
Log Pis Max                  6.314347
Log Pis Min                  -4.453988
Policy mu Mean               0.090088286
Policy mu Std                0.95918095
Policy mu Max                2.3565707
Policy mu Min                -2.696931
Policy log std Mean          -0.60870695
Policy log std Std           0.2460272
Policy log std Max           -0.069072306
Policy log std Min           -2.255581
Z mean eval                  0.051178742
Z variance eval              0.005999932
total_rewards                [ 982.5225522   873.8862482  3242.78690401 3219.09614721 3261.3640305
  831.74122586  983.3167657   910.46791127  930.42077621 3355.53120273]
total_rewards_mean           1859.113376389684
total_rewards_std            1152.981966303746
total_rewards_max            3355.5312027349573
total_rewards_min            831.7412258580408
Number of train steps total  500000
Number of env steps total    437447
Number of rollouts total     0
Train Time (s)               143.82445990201086
(Previous) Eval Time (s)     10.509081345051527
Sample Time (s)              6.582196189556271
Epoch Time (s)               160.91573743661866
Total Train Time (s)         19767.68989531137
Epoch                        124
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:59:08.077361 UTC | [2020_01_10_09_29_40] Iteration #124 | Epoch Duration: 161.00272965431213
2020-01-10 14:59:08.077651 UTC | [2020_01_10_09_29_40] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049050532
Z variance train             0.005988993
KL Divergence                10.608317
KL Loss                      1.0608318
QF Loss                      970.6041
VF Loss                      72.472824
Policy Loss                  -1201.103
Q Predictions Mean           1194.4457
Q Predictions Std            357.57233
Q Predictions Max            1552.4822
Q Predictions Min            6.6606054
V Predictions Mean           1200.9626
V Predictions Std            346.35693
V Predictions Max            1554.9031
V Predictions Min            12.576659
Log Pis Mean                 0.4257307
Log Pis Std                  2.0877821
Log Pis Max                  7.5368614
Log Pis Min                  -4.6661487
Policy mu Mean               0.17514728
Policy mu Std                0.9897672
Policy mu Max                3.1557708
Policy mu Min                -2.592802
Policy log std Mean          -0.5972464
Policy log std Std           0.24720122
Policy log std Max           0.104106605
Policy log std Min           -2.066904
Z mean eval                  0.08101216
Z variance eval              0.0030367742
total_rewards                [3219.36727358 3238.46529932 3232.08367316 3239.4029482  3203.06842284
 3271.89982527 3264.17532893 3237.5740689  3266.15955716 3290.35420133]
total_rewards_mean           3246.255059869348
total_rewards_std            25.083005410802087
total_rewards_max            3290.3542013326264
total_rewards_min            3203.0684228430673
Number of train steps total  504000
Number of env steps total    441795
Number of rollouts total     0
Train Time (s)               143.70708105899394
(Previous) Eval Time (s)     18.73491678899154
Sample Time (s)              6.7817484345287085
Epoch Time (s)               169.22374628251418
Total Train Time (s)         19936.996727901045
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:01:57.390748 UTC | [2020_01_10_09_29_40] Iteration #125 | Epoch Duration: 169.31292080879211
2020-01-10 15:01:57.391030 UTC | [2020_01_10_09_29_40] Iteration #125 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07802786
Z variance train             0.0030494733
KL Divergence                12.6111965
KL Loss                      1.2611197
QF Loss                      1327.961
VF Loss                      89.74156
Policy Loss                  -1163.4086
Q Predictions Mean           1152.5537
Q Predictions Std            356.05267
Q Predictions Max            1521.801
Q Predictions Min            31.253643
V Predictions Mean           1163.872
V Predictions Std            347.34412
V Predictions Max            1524.8182
V Predictions Min            28.2103
Log Pis Mean                 0.2571727
Log Pis Std                  2.3400953
Log Pis Max                  8.90233
Log Pis Min                  -5.481538
Policy mu Mean               0.12935093
Policy mu Std                1.0007457
Policy mu Max                3.1771505
Policy mu Min                -2.6292565
Policy log std Mean          -0.5824073
Policy log std Std           0.23745511
Policy log std Max           0.043887973
Policy log std Min           -2.6764164
Z mean eval                  0.033164572
Z variance eval              0.0076610846
total_rewards                [3141.60174872 3108.30165605 2852.88007617 3192.81512762  911.974104
 2130.13140615  982.45218069 3120.70236638  945.20922229 3120.85774643]
total_rewards_mean           2350.6925634514478
total_rewards_std            965.0370091453448
total_rewards_max            3192.8151276201315
total_rewards_min            911.9741040030506
Number of train steps total  508000
Number of env steps total    446098
Number of rollouts total     0
Train Time (s)               142.40356559772044
(Previous) Eval Time (s)     13.908354198094457
Sample Time (s)              6.759779588319361
Epoch Time (s)               163.07169938413426
Total Train Time (s)         20100.205772792455
Epoch                        126
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:04:40.605768 UTC | [2020_01_10_09_29_40] Iteration #126 | Epoch Duration: 163.21450877189636
2020-01-10 15:04:40.606083 UTC | [2020_01_10_09_29_40] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03302925
Z variance train             0.0076541677
KL Divergence                10.093542
KL Loss                      1.0093542
QF Loss                      1131.0845
VF Loss                      89.44313
Policy Loss                  -1127.564
Q Predictions Mean           1118.0405
Q Predictions Std            366.95303
Q Predictions Max            1521.7356
Q Predictions Min            9.040557
V Predictions Mean           1133.0034
V Predictions Std            360.9434
V Predictions Max            1535.9692
V Predictions Min            7.8743496
Log Pis Mean                 0.69259214
Log Pis Std                  2.386955
Log Pis Max                  8.76856
Log Pis Min                  -4.9556775
Policy mu Mean               0.16579545
Policy mu Std                1.0841424
Policy mu Max                3.4970608
Policy mu Min                -2.808127
Policy log std Mean          -0.590126
Policy log std Std           0.24170476
Policy log std Max           0.01680839
Policy log std Min           -2.5871818
Z mean eval                  0.03055754
Z variance eval              0.0060647177
total_rewards                [ 826.63429229 3301.48969103 3188.82682909 3270.79457235  969.67885213
 3279.03088638 1748.81715759 3300.94042924 3286.69366399 3319.86268284]
total_rewards_mean           2649.276905693165
total_rewards_std            986.606515040113
total_rewards_max            3319.86268283586
total_rewards_min            826.6342922921846
Number of train steps total  512000
Number of env steps total    450421
Number of rollouts total     0
Train Time (s)               143.4948936146684
(Previous) Eval Time (s)     14.855196432676166
Sample Time (s)              6.522602447774261
Epoch Time (s)               164.87269249511883
Total Train Time (s)         20265.177177025005
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:07:25.573899 UTC | [2020_01_10_09_29_40] Iteration #127 | Epoch Duration: 164.9675793647766
2020-01-10 15:07:25.574129 UTC | [2020_01_10_09_29_40] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030841906
Z variance train             0.006052656
KL Divergence                11.693526
KL Loss                      1.1693527
QF Loss                      2182.638
VF Loss                      96.35975
Policy Loss                  -1231.534
Q Predictions Mean           1223.485
Q Predictions Std            317.833
Q Predictions Max            1540.4163
Q Predictions Min            3.0246384
V Predictions Mean           1236.0774
V Predictions Std            303.69278
V Predictions Max            1549.3188
V Predictions Min            65.79399
Log Pis Mean                 0.1792377
Log Pis Std                  2.1602128
Log Pis Max                  7.5165205
Log Pis Min                  -4.974676
Policy mu Mean               0.12886365
Policy mu Std                0.94564605
Policy mu Max                2.666421
Policy mu Min                -2.7511163
Policy log std Mean          -0.59734815
Policy log std Std           0.22314021
Policy log std Max           0.15154415
Policy log std Min           -2.4566534
Z mean eval                  0.033910647
Z variance eval              0.008189848
total_rewards                [3127.55136646 3144.11975454 3149.67970289 3145.73743485 3133.06085913
 3124.83951872 3102.23094465 3099.75622973 3158.51946807 3070.39326699]
total_rewards_mean           3125.588854602604
total_rewards_std            25.949695525438774
total_rewards_max            3158.519468065718
total_rewards_min            3070.393266992425
Number of train steps total  516000
Number of env steps total    454997
Number of rollouts total     0
Train Time (s)               144.2705667023547
(Previous) Eval Time (s)     18.728772788774222
Sample Time (s)              7.14839241001755
Epoch Time (s)               170.14773190114647
Total Train Time (s)         20435.404362087604
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:10:15.802379 UTC | [2020_01_10_09_29_40] Iteration #128 | Epoch Duration: 170.22808361053467
2020-01-10 15:10:15.802548 UTC | [2020_01_10_09_29_40] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032792997
Z variance train             0.008258787
KL Divergence                11.105831
KL Loss                      1.1105832
QF Loss                      221.34457
VF Loss                      51.986404
Policy Loss                  -1183.9142
Q Predictions Mean           1177.7322
Q Predictions Std            314.9313
Q Predictions Max            1529.0875
Q Predictions Min            17.318495
V Predictions Mean           1183.9379
V Predictions Std            313.20126
V Predictions Max            1531.9161
V Predictions Min            16.829052
Log Pis Mean                 0.2744286
Log Pis Std                  2.1967041
Log Pis Max                  7.766323
Log Pis Min                  -6.205023
Policy mu Mean               0.14466406
Policy mu Std                0.95920306
Policy mu Max                2.6388009
Policy mu Min                -2.8107877
Policy log std Mean          -0.60528386
Policy log std Std           0.23743486
Policy log std Max           0.1260863
Policy log std Min           -2.098021
Z mean eval                  0.026363712
Z variance eval              0.0049778135
total_rewards                [3142.08729021 1514.97482497 3140.66552625  842.60916619 3153.12269097
 2755.5105938  3123.25339426 1007.01156691 3181.51967412 1549.14292988]
total_rewards_mean           2340.989765756437
total_rewards_std            936.2167073970516
total_rewards_max            3181.5196741241894
total_rewards_min            842.6091661854209
Number of train steps total  520000
Number of env steps total    459331
Number of rollouts total     0
Train Time (s)               146.01715748058632
(Previous) Eval Time (s)     16.182049052324146
Sample Time (s)              6.6626307484693825
Epoch Time (s)               168.86183728137985
Total Train Time (s)         20604.34361880133
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:13:04.745877 UTC | [2020_01_10_09_29_40] Iteration #129 | Epoch Duration: 168.94306468963623
2020-01-10 15:13:04.746228 UTC | [2020_01_10_09_29_40] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025638273
Z variance train             0.004972854
KL Divergence                11.210795
KL Loss                      1.1210796
QF Loss                      390.91174
VF Loss                      295.63388
Policy Loss                  -1180.5144
Q Predictions Mean           1175.5369
Q Predictions Std            338.66962
Q Predictions Max            1529.3795
Q Predictions Min            42.25046
V Predictions Mean           1170.9722
V Predictions Std            335.4886
V Predictions Max            1514.5746
V Predictions Min            38.656445
Log Pis Mean                 0.3408934
Log Pis Std                  2.4363487
Log Pis Max                  14.071959
Log Pis Min                  -4.7333007
Policy mu Mean               0.098129034
Policy mu Std                1.0021877
Policy mu Max                4.387428
Policy mu Min                -2.7964952
Policy log std Mean          -0.559076
Policy log std Std           0.24001019
Policy log std Max           0.27387637
Policy log std Min           -2.1773107
Z mean eval                  0.05916385
Z variance eval              0.004224556
total_rewards                [3122.37533453 3114.02876696 3167.38540801 3097.65221307 3168.43515918
 3123.33577034 3121.10678318 3148.0854848  1939.10851287 3123.51734978]
total_rewards_mean           3012.50307827159
total_rewards_std            358.4542375321786
total_rewards_max            3168.4351591802056
total_rewards_min            1939.1085128749494
Number of train steps total  524000
Number of env steps total    463856
Number of rollouts total     0
Train Time (s)               143.77905515907332
(Previous) Eval Time (s)     17.901831249706447
Sample Time (s)              7.0028753113001585
Epoch Time (s)               168.68376172007993
Total Train Time (s)         20773.11026503006
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:15:53.515284 UTC | [2020_01_10_09_29_40] Iteration #130 | Epoch Duration: 168.7688388824463
2020-01-10 15:15:53.515502 UTC | [2020_01_10_09_29_40] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05856969
Z variance train             0.0042226063
KL Divergence                11.60882
KL Loss                      1.160882
QF Loss                      372.5951
VF Loss                      146.78087
Policy Loss                  -1144.8131
Q Predictions Mean           1136.6864
Q Predictions Std            363.20056
Q Predictions Max            1514.9496
Q Predictions Min            25.408297
V Predictions Mean           1140.077
V Predictions Std            353.9341
V Predictions Max            1518.9678
V Predictions Min            31.523746
Log Pis Mean                 0.57770866
Log Pis Std                  2.4914198
Log Pis Max                  15.652595
Log Pis Min                  -5.5824065
Policy mu Mean               0.118209004
Policy mu Std                1.0627465
Policy mu Max                4.08126
Policy mu Min                -3.0268478
Policy log std Mean          -0.6252473
Policy log std Std           0.25078014
Policy log std Max           0.04404497
Policy log std Min           -2.8319497
Z mean eval                  0.086923614
Z variance eval              0.006421934
total_rewards                [3194.43196289 3171.51888508  874.66840383  951.39100211 3119.96621047
 3169.09729972 3159.89467892 3152.82119828  838.49300584  918.08586878]
total_rewards_mean           2255.036851592886
total_rewards_std            1110.3936312046394
total_rewards_max            3194.4319628945823
total_rewards_min            838.4930058406852
Number of train steps total  528000
Number of env steps total    468164
Number of rollouts total     0
Train Time (s)               142.80989417806268
(Previous) Eval Time (s)     15.268624137155712
Sample Time (s)              6.601414583623409
Epoch Time (s)               164.6799328988418
Total Train Time (s)         20937.870643382892
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:18:38.275681 UTC | [2020_01_10_09_29_40] Iteration #131 | Epoch Duration: 164.7599925994873
2020-01-10 15:18:38.275916 UTC | [2020_01_10_09_29_40] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08737482
Z variance train             0.0064353473
KL Divergence                11.023178
KL Loss                      1.1023178
QF Loss                      231.12436
VF Loss                      66.851776
Policy Loss                  -1203.1921
Q Predictions Mean           1199.8179
Q Predictions Std            339.7855
Q Predictions Max            1563.0192
Q Predictions Min            65.79018
V Predictions Mean           1200.1198
V Predictions Std            334.91315
V Predictions Max            1550.3732
V Predictions Min            59.792896
Log Pis Mean                 0.09391667
Log Pis Std                  1.9942755
Log Pis Max                  6.23843
Log Pis Min                  -4.7762694
Policy mu Mean               0.085976064
Policy mu Std                0.9173801
Policy mu Max                2.8805444
Policy mu Min                -2.5210638
Policy log std Mean          -0.56600213
Policy log std Std           0.22100185
Policy log std Max           0.2121523
Policy log std Min           -1.3951988
Z mean eval                  0.045914926
Z variance eval              0.0033192732
total_rewards                [3119.88857003  609.56584262  895.1013286  1662.62053048 3154.66310362
  890.3355473   897.59053999 3145.13968665  992.01721014  870.48535686]
total_rewards_mean           1623.740771629121
total_rewards_std            1024.1806334858586
total_rewards_max            3154.6631036198414
total_rewards_min            609.5658426243176
Number of train steps total  532000
Number of env steps total    472489
Number of rollouts total     0
Train Time (s)               142.92677427316085
(Previous) Eval Time (s)     11.215383403003216
Sample Time (s)              6.627748224884272
Epoch Time (s)               160.76990590104833
Total Train Time (s)         21098.719488098286
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:21:19.126263 UTC | [2020_01_10_09_29_40] Iteration #132 | Epoch Duration: 160.85024213790894
2020-01-10 15:21:19.126393 UTC | [2020_01_10_09_29_40] Iteration #132 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04584147
Z variance train             0.0033234456
KL Divergence                12.351166
KL Loss                      1.2351166
QF Loss                      378.57367
VF Loss                      53.658432
Policy Loss                  -1191.6345
Q Predictions Mean           1186.625
Q Predictions Std            315.82007
Q Predictions Max            1545.2526
Q Predictions Min            -30.869455
V Predictions Mean           1188.812
V Predictions Std            311.76785
V Predictions Max            1533.3239
V Predictions Min            -58.250748
Log Pis Mean                 0.31969026
Log Pis Std                  2.3294811
Log Pis Max                  8.740739
Log Pis Min                  -5.9103146
Policy mu Mean               0.0069755637
Policy mu Std                1.0210326
Policy mu Max                3.4387999
Policy mu Min                -2.5986109
Policy log std Mean          -0.595418
Policy log std Std           0.24845754
Policy log std Max           0.14201874
Policy log std Min           -2.0458188
Z mean eval                  0.03182797
Z variance eval              0.004709314
total_rewards                [ 948.28205648 3245.80373565 3232.45805876 3206.79918538 3164.381337
 1302.15582607  623.05434257 3220.80667276  792.67935115 3126.69227993]
total_rewards_mean           2286.3112845743835
total_rewards_std            1130.039402487983
total_rewards_max            3245.803735649656
total_rewards_min            623.0543425679474
Number of train steps total  536000
Number of env steps total    476722
Number of rollouts total     0
Train Time (s)               144.06970759527758
(Previous) Eval Time (s)     15.619385065045208
Sample Time (s)              6.395651761442423
Epoch Time (s)               166.0847444217652
Total Train Time (s)         21264.89137492096
Epoch                        133
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:24:05.300332 UTC | [2020_01_10_09_29_40] Iteration #133 | Epoch Duration: 166.17385149002075
2020-01-10 15:24:05.300457 UTC | [2020_01_10_09_29_40] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030163635
Z variance train             0.004702637
KL Divergence                12.058074
KL Loss                      1.2058074
QF Loss                      606.6133
VF Loss                      68.16193
Policy Loss                  -1205.3167
Q Predictions Mean           1204.9055
Q Predictions Std            328.30862
Q Predictions Max            1558.0911
Q Predictions Min            24.993303
V Predictions Mean           1203.7468
V Predictions Std            320.58557
V Predictions Max            1555.1108
V Predictions Min            27.298843
Log Pis Mean                 0.30739558
Log Pis Std                  2.329758
Log Pis Max                  12.921278
Log Pis Min                  -5.3649592
Policy mu Mean               0.13875498
Policy mu Std                0.96716356
Policy mu Max                3.5878582
Policy mu Min                -2.6164298
Policy log std Mean          -0.5749531
Policy log std Std           0.2456193
Policy log std Max           0.0876618
Policy log std Min           -2.5524604
Z mean eval                  0.037166428
Z variance eval              0.0044701844
total_rewards                [2685.28908733 3180.52053749  773.26349088 3112.48704519 3111.31615749
 3129.02063366 2753.34907294 3181.42999086 3131.85623677 2265.68973911]
total_rewards_mean           2732.422199171987
total_rewards_std            711.7618564575995
total_rewards_max            3181.4299908625285
total_rewards_min            773.2634908833064
Number of train steps total  540000
Number of env steps total    481089
Number of rollouts total     0
Train Time (s)               142.90430645411834
(Previous) Eval Time (s)     18.653818433173
Sample Time (s)              6.756146582774818
Epoch Time (s)               168.31427147006616
Total Train Time (s)         21433.298868983984
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:26:53.710541 UTC | [2020_01_10_09_29_40] Iteration #134 | Epoch Duration: 168.40997672080994
2020-01-10 15:26:53.710765 UTC | [2020_01_10_09_29_40] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038232498
Z variance train             0.004461704
KL Divergence                11.704987
KL Loss                      1.1704987
QF Loss                      201.18283
VF Loss                      69.03787
Policy Loss                  -1157.7843
Q Predictions Mean           1160.589
Q Predictions Std            383.43375
Q Predictions Max            1545.917
Q Predictions Min            39.13184
V Predictions Mean           1159.8972
V Predictions Std            381.521
V Predictions Max            1545.0953
V Predictions Min            43.56304
Log Pis Mean                 0.36047164
Log Pis Std                  2.2359092
Log Pis Max                  10.728295
Log Pis Min                  -5.8116326
Policy mu Mean               0.090149455
Policy mu Std                0.9964978
Policy mu Max                2.746733
Policy mu Min                -2.838068
Policy log std Mean          -0.57674605
Policy log std Std           0.21056359
Policy log std Max           0.017118871
Policy log std Min           -1.4644779
Z mean eval                  0.085910685
Z variance eval              0.004935096
total_rewards                [3190.16074633 3135.32181295 3155.1112708  3207.15175177 3149.04828799
 3083.60359258 3199.18122818 3151.44605721 3134.1375362  3175.41932712]
total_rewards_mean           3158.0581611128778
total_rewards_std            34.92774805815116
total_rewards_max            3207.1517517695224
total_rewards_min            3083.603592584201
Number of train steps total  544000
Number of env steps total    485376
Number of rollouts total     0
Train Time (s)               145.74321673298255
(Previous) Eval Time (s)     18.43424895592034
Sample Time (s)              6.445122337434441
Epoch Time (s)               170.62258802633733
Total Train Time (s)         21604.01336172782
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:29:44.429223 UTC | [2020_01_10_09_29_40] Iteration #135 | Epoch Duration: 170.71830463409424
2020-01-10 15:29:44.429500 UTC | [2020_01_10_09_29_40] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08395983
Z variance train             0.004932654
KL Divergence                11.425694
KL Loss                      1.1425694
QF Loss                      147.66507
VF Loss                      83.18318
Policy Loss                  -1203.0823
Q Predictions Mean           1204.2166
Q Predictions Std            343.38812
Q Predictions Max            1558.7003
Q Predictions Min            58.560043
V Predictions Mean           1205.7026
V Predictions Std            343.44336
V Predictions Max            1565.8856
V Predictions Min            57.028084
Log Pis Mean                 0.09421196
Log Pis Std                  2.150206
Log Pis Max                  13.238049
Log Pis Min                  -6.6303806
Policy mu Mean               0.036646757
Policy mu Std                0.9348397
Policy mu Max                3.7794323
Policy mu Min                -2.6735253
Policy log std Mean          -0.5658528
Policy log std Std           0.22367054
Policy log std Max           0.058561027
Policy log std Min           -1.3317688
Z mean eval                  0.056271404
Z variance eval              0.005893638
total_rewards                [1693.4578873  3175.26389765 3183.03744696 3154.43130672 3179.98759771
 3146.54553474 3161.68949771 2483.78539323 3143.12319873  546.47987881]
total_rewards_mean           2686.7801639553113
total_rewards_std            848.5748159558026
total_rewards_max            3183.0374469581666
total_rewards_min            546.4798788084719
Number of train steps total  548000
Number of env steps total    489738
Number of rollouts total     0
Train Time (s)               142.9937682938762
(Previous) Eval Time (s)     18.392644279636443
Sample Time (s)              6.40765592828393
Epoch Time (s)               167.79406850179657
Total Train Time (s)         21771.886614151765
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:32:32.302960 UTC | [2020_01_10_09_29_40] Iteration #136 | Epoch Duration: 167.8732750415802
2020-01-10 15:32:32.303126 UTC | [2020_01_10_09_29_40] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05685998
Z variance train             0.005925403
KL Divergence                11.134573
KL Loss                      1.1134573
QF Loss                      244.17157
VF Loss                      52.53162
Policy Loss                  -1234.7908
Q Predictions Mean           1223.7017
Q Predictions Std            314.77505
Q Predictions Max            1546.6012
Q Predictions Min            8.147632
V Predictions Mean           1231.5142
V Predictions Std            308.74805
V Predictions Max            1556.236
V Predictions Min            3.4623892
Log Pis Mean                 0.40111175
Log Pis Std                  2.314305
Log Pis Max                  11.792107
Log Pis Min                  -5.0236344
Policy mu Mean               0.16330118
Policy mu Std                1.0134594
Policy mu Max                3.5880477
Policy mu Min                -2.4856067
Policy log std Mean          -0.56934667
Policy log std Std           0.23459901
Policy log std Max           0.111058176
Policy log std Min           -2.50423
Z mean eval                  0.062246323
Z variance eval              0.007825659
total_rewards                [3142.89737378 3117.97756448 3090.45035328 2111.4151557  3094.89791288
 3128.85215989 3081.33533417 3083.74422153 3066.77548347 2532.30111944]
total_rewards_mean           2945.0646678616044
total_rewards_std            326.24561026801575
total_rewards_max            3142.8973737776837
total_rewards_min            2111.4151556972365
Number of train steps total  552000
Number of env steps total    494050
Number of rollouts total     0
Train Time (s)               142.35396031104028
(Previous) Eval Time (s)     17.55751568218693
Sample Time (s)              6.509043687954545
Epoch Time (s)               166.42051968118176
Total Train Time (s)         21938.38951488072
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:35:18.810444 UTC | [2020_01_10_09_29_40] Iteration #137 | Epoch Duration: 166.50717449188232
2020-01-10 15:35:18.810689 UTC | [2020_01_10_09_29_40] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.063458465
Z variance train             0.007837488
KL Divergence                11.222202
KL Loss                      1.1222203
QF Loss                      259.26288
VF Loss                      403.13412
Policy Loss                  -1206.5916
Q Predictions Mean           1200.337
Q Predictions Std            354.8866
Q Predictions Max            1575.2766
Q Predictions Min            -28.094553
V Predictions Mean           1209.667
V Predictions Std            344.44717
V Predictions Max            1559.3268
V Predictions Min            9.623153
Log Pis Mean                 0.27256224
Log Pis Std                  2.5727274
Log Pis Max                  14.399218
Log Pis Min                  -6.2197328
Policy mu Mean               0.15526715
Policy mu Std                0.9918826
Policy mu Max                3.424592
Policy mu Min                -4.022094
Policy log std Mean          -0.57901525
Policy log std Std           0.24800888
Policy log std Max           0.08446157
Policy log std Min           -2.7947235
Z mean eval                  0.056970973
Z variance eval              0.002892528
total_rewards                [3234.53187551 3034.68532245  948.1679619  3104.67964895 3162.14697889
 3250.14932442  849.61299315  822.01204994  995.82303717 3187.00916265]
total_rewards_mean           2258.8818355012945
total_rewards_std            1108.7370886997198
total_rewards_max            3250.1493244204144
total_rewards_min            822.0120499358961
Number of train steps total  556000
Number of env steps total    498372
Number of rollouts total     0
Train Time (s)               142.21251061698422
(Previous) Eval Time (s)     13.599822830874473
Sample Time (s)              6.639452150091529
Epoch Time (s)               162.45178559795022
Total Train Time (s)         22100.918709666934
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:38:01.344926 UTC | [2020_01_10_09_29_40] Iteration #138 | Epoch Duration: 162.53402590751648
2020-01-10 15:38:01.345249 UTC | [2020_01_10_09_29_40] Iteration #138 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054356486
Z variance train             0.0028931033
KL Divergence                12.745666
KL Loss                      1.2745665
QF Loss                      642.03674
VF Loss                      107.41855
Policy Loss                  -1196.0712
Q Predictions Mean           1197.4417
Q Predictions Std            339.57132
Q Predictions Max            1558.97
Q Predictions Min            -12.340483
V Predictions Mean           1203.5707
V Predictions Std            337.03494
V Predictions Max            1561.1246
V Predictions Min            -16.589748
Log Pis Mean                 0.31671813
Log Pis Std                  2.2643833
Log Pis Max                  10.441931
Log Pis Min                  -5.1052847
Policy mu Mean               0.16224296
Policy mu Std                0.96596164
Policy mu Max                2.9513423
Policy mu Min                -2.5674973
Policy log std Mean          -0.5593586
Policy log std Std           0.2008165
Policy log std Max           0.043522656
Policy log std Min           -1.387663
Z mean eval                  0.024576675
Z variance eval              0.0055493684
total_rewards                [3092.80360491 3090.79577212 1469.01067287 3120.39697094 1724.541175
 3142.46962608 3065.93247722 3127.98010268 3120.29283157 3100.94223264]
total_rewards_mean           2805.5165466028966
total_rewards_std            607.4142327751583
total_rewards_max            3142.4696260780115
total_rewards_min            1469.0106728692092
Number of train steps total  560000
Number of env steps total    502629
Number of rollouts total     0
Train Time (s)               142.11020352412015
(Previous) Eval Time (s)     19.79235187219456
Sample Time (s)              6.4261835580691695
Epoch Time (s)               168.32873895438388
Total Train Time (s)         22269.331837504636
Epoch                        139
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:40:49.757507 UTC | [2020_01_10_09_29_40] Iteration #139 | Epoch Duration: 168.41204524040222
2020-01-10 15:40:49.757627 UTC | [2020_01_10_09_29_40] Iteration #139 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02579948
Z variance train             0.005546296
KL Divergence                11.04373
KL Loss                      1.104373
QF Loss                      353.15588
VF Loss                      65.91106
Policy Loss                  -1195.7854
Q Predictions Mean           1192.754
Q Predictions Std            354.30957
Q Predictions Max            1561.0918
Q Predictions Min            -12.4680195
V Predictions Mean           1193.8423
V Predictions Std            350.47244
V Predictions Max            1561.0801
V Predictions Min            20.823069
Log Pis Mean                 0.296487
Log Pis Std                  2.293648
Log Pis Max                  13.515318
Log Pis Min                  -4.930137
Policy mu Mean               0.1852289
Policy mu Std                0.9735347
Policy mu Max                4.2286363
Policy mu Min                -2.5873559
Policy log std Mean          -0.6065795
Policy log std Std           0.24314152
Policy log std Max           0.081498384
Policy log std Min           -2.9090345
Z mean eval                  0.09387372
Z variance eval              0.0050599873
total_rewards                [ 921.66273436 2919.50223034 3116.49078359 1544.49114793 3208.6957934
 1832.22151488 2468.03663455 1589.41902468 1308.594691   2446.98850609]
total_rewards_mean           2135.610306082316
total_rewards_std            763.7410712160786
total_rewards_max            3208.695793404605
total_rewards_min            921.662734355625
Number of train steps total  564000
Number of env steps total    506995
Number of rollouts total     0
Train Time (s)               145.03323469590396
(Previous) Eval Time (s)     14.795058412943035
Sample Time (s)              6.719223286956549
Epoch Time (s)               166.54751639580354
Total Train Time (s)         22435.961269880645
Epoch                        140
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:43:36.389445 UTC | [2020_01_10_09_29_40] Iteration #140 | Epoch Duration: 166.6317286491394
2020-01-10 15:43:36.389576 UTC | [2020_01_10_09_29_40] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0943783
Z variance train             0.0050465777
KL Divergence                10.874578
KL Loss                      1.0874579
QF Loss                      170.47406
VF Loss                      48.530968
Policy Loss                  -1198.4175
Q Predictions Mean           1194.2538
Q Predictions Std            349.81833
Q Predictions Max            1565.9889
Q Predictions Min            20.809872
V Predictions Mean           1198.9194
V Predictions Std            343.30533
V Predictions Max            1562.7883
V Predictions Min            19.89517
Log Pis Mean                 0.50367093
Log Pis Std                  2.2627106
Log Pis Max                  9.398102
Log Pis Min                  -4.7305036
Policy mu Mean               0.22960185
Policy mu Std                0.99095124
Policy mu Max                2.9019742
Policy mu Min                -2.6591892
Policy log std Mean          -0.58216846
Policy log std Std           0.21934935
Policy log std Max           0.21168524
Policy log std Min           -2.2764714
Z mean eval                  0.024865596
Z variance eval              0.007535906
total_rewards                [3088.79027007 3139.880645   2400.7295196  2486.14054142 2997.22821047
 3095.52659828 3094.37753163 3083.22181381 3083.42943967 3056.72325102]
total_rewards_mean           2952.60478209912
total_rewards_std            257.54764474404584
total_rewards_max            3139.8806449975905
total_rewards_min            2400.7295196006976
Number of train steps total  568000
Number of env steps total    511369
Number of rollouts total     0
Train Time (s)               142.58364438312128
(Previous) Eval Time (s)     20.158279782161117
Sample Time (s)              6.503863289952278
Epoch Time (s)               169.24578745523468
Total Train Time (s)         22605.304145518225
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:46:25.733523 UTC | [2020_01_10_09_29_40] Iteration #141 | Epoch Duration: 169.34385704994202
2020-01-10 15:46:25.733648 UTC | [2020_01_10_09_29_40] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023628075
Z variance train             0.007554274
KL Divergence                10.17776
KL Loss                      1.017776
QF Loss                      167.30016
VF Loss                      75.390015
Policy Loss                  -1211.7997
Q Predictions Mean           1208.0576
Q Predictions Std            343.9629
Q Predictions Max            1567.8551
Q Predictions Min            -30.548378
V Predictions Mean           1214.7666
V Predictions Std            335.14218
V Predictions Max            1575.0781
V Predictions Min            -35.207542
Log Pis Mean                 -0.19124153
Log Pis Std                  2.146316
Log Pis Max                  8.565661
Log Pis Min                  -6.5
Policy mu Mean               0.0744318
Policy mu Std                0.9145283
Policy mu Max                2.429916
Policy mu Min                -2.5714118
Policy log std Mean          -0.5652227
Policy log std Std           0.206837
Policy log std Max           -0.020677865
Policy log std Min           -1.3128018
Z mean eval                  0.05242417
Z variance eval              0.0053229635
total_rewards                [ 916.72864841  359.04803916 3189.45281145 2099.62319616  852.81710571
 3163.20151551  772.28744433 2592.00215372  946.79217617 3115.12673971]
total_rewards_mean           1800.7079830315647
total_rewards_std            1085.0490884916194
total_rewards_max            3189.452811449866
total_rewards_min            359.0480391591028
Number of train steps total  572000
Number of env steps total    515807
Number of rollouts total     0
Train Time (s)               143.93017413280904
(Previous) Eval Time (s)     10.538710691966116
Sample Time (s)              5.530583616811782
Epoch Time (s)               159.99946844158694
Total Train Time (s)         22765.384924022015
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:49:05.819482 UTC | [2020_01_10_09_29_40] Iteration #142 | Epoch Duration: 160.0857355594635
2020-01-10 15:49:05.819630 UTC | [2020_01_10_09_29_40] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052672993
Z variance train             0.0053220442
KL Divergence                10.867363
KL Loss                      1.0867363
QF Loss                      171.47467
VF Loss                      109.75314
Policy Loss                  -1158.0975
Q Predictions Mean           1156.283
Q Predictions Std            378.5862
Q Predictions Max            1560.0549
Q Predictions Min            26.652922
V Predictions Mean           1155.5436
V Predictions Std            376.63635
V Predictions Max            1560.5485
V Predictions Min            24.454
Log Pis Mean                 0.32362407
Log Pis Std                  2.306601
Log Pis Max                  10.082529
Log Pis Min                  -6.639562
Policy mu Mean               0.17670767
Policy mu Std                0.9779563
Policy mu Max                3.2365308
Policy mu Min                -3.40743
Policy log std Mean          -0.56986326
Policy log std Std           0.2189159
Policy log std Max           0.28320742
Policy log std Min           -2.4058924
Z mean eval                  0.034820236
Z variance eval              0.009426449
total_rewards                [ 864.24767699  962.60386808  894.62873553 3096.6749705  3111.44900753
 2745.79816342 3120.41357514 3115.0489265  2628.10470158 3131.8146252 ]
total_rewards_mean           2367.078425047867
total_rewards_std            969.9955846465393
total_rewards_max            3131.814625195635
total_rewards_min            864.2476769919124
Number of train steps total  576000
Number of env steps total    520171
Number of rollouts total     0
Train Time (s)               142.70415776222944
(Previous) Eval Time (s)     16.829929046798497
Sample Time (s)              6.571272534318268
Epoch Time (s)               166.1053593433462
Total Train Time (s)         22931.573664468713
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:51:52.009026 UTC | [2020_01_10_09_29_40] Iteration #143 | Epoch Duration: 166.18928694725037
2020-01-10 15:51:52.009149 UTC | [2020_01_10_09_29_40] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034494087
Z variance train             0.009428995
KL Divergence                9.656296
KL Loss                      0.9656296
QF Loss                      3577.251
VF Loss                      368.52054
Policy Loss                  -1188.9852
Q Predictions Mean           1191.0725
Q Predictions Std            347.91556
Q Predictions Max            1554.4921
Q Predictions Min            0.25810492
V Predictions Mean           1191.3862
V Predictions Std            353.9535
V Predictions Max            1564.7288
V Predictions Min            -34.302803
Log Pis Mean                 0.22392945
Log Pis Std                  2.4056022
Log Pis Max                  11.742508
Log Pis Min                  -6.382759
Policy mu Mean               0.11958436
Policy mu Std                0.99924845
Policy mu Max                4.33608
Policy mu Min                -2.67212
Policy log std Mean          -0.5874071
Policy log std Std           0.20459759
Policy log std Max           -0.01987958
Policy log std Min           -1.5918442
Z mean eval                  0.030846903
Z variance eval              0.0041580885
total_rewards                [3112.02444765 2752.1397288  3149.95467191 1835.7794579  2508.31663531
 3117.96210696 1569.10062251 3083.84554122 2630.40267906 2742.36024834]
total_rewards_mean           2650.1886139657336
total_rewards_std            523.5791364785233
total_rewards_max            3149.9546719064783
total_rewards_min            1569.1006225081494
Number of train steps total  580000
Number of env steps total    524602
Number of rollouts total     0
Train Time (s)               143.2954056239687
(Previous) Eval Time (s)     18.70534901274368
Sample Time (s)              6.625085950829089
Epoch Time (s)               168.62584058754146
Total Train Time (s)         23100.288239288144
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:54:40.727650 UTC | [2020_01_10_09_29_40] Iteration #144 | Epoch Duration: 168.7184009552002
2020-01-10 15:54:40.727826 UTC | [2020_01_10_09_29_40] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03097235
Z variance train             0.004171717
KL Divergence                11.720013
KL Loss                      1.1720012
QF Loss                      273.8355
VF Loss                      53.37654
Policy Loss                  -1209.5455
Q Predictions Mean           1206.3573
Q Predictions Std            365.48654
Q Predictions Max            1573.9703
Q Predictions Min            62.455395
V Predictions Mean           1207.8372
V Predictions Std            361.47516
V Predictions Max            1569.1849
V Predictions Min            74.85449
Log Pis Mean                 0.05449353
Log Pis Std                  2.1739972
Log Pis Max                  6.312512
Log Pis Min                  -7.0410147
Policy mu Mean               0.17204659
Policy mu Std                0.9455482
Policy mu Max                2.9427214
Policy mu Min                -2.7901776
Policy log std Mean          -0.59071296
Policy log std Std           0.21076697
Policy log std Max           0.06788355
Policy log std Min           -1.4467833
Z mean eval                  0.065275215
Z variance eval              0.006113969
total_rewards                [2752.28365189 1204.52749885 1676.9703472   865.42706811  916.10019997
 3156.52857598 3161.17941909 2401.28389276 1242.54395324  964.48842287]
total_rewards_mean           1834.1333029967166
total_rewards_std            893.4752875264123
total_rewards_max            3161.1794190886585
total_rewards_min            865.4270681116379
Number of train steps total  584000
Number of env steps total    528993
Number of rollouts total     0
Train Time (s)               142.59478144999593
(Previous) Eval Time (s)     10.792175207752734
Sample Time (s)              6.691710232757032
Epoch Time (s)               160.0786668905057
Total Train Time (s)         23260.44376506703
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:57:20.883140 UTC | [2020_01_10_09_29_40] Iteration #145 | Epoch Duration: 160.15519738197327
2020-01-10 15:57:20.883250 UTC | [2020_01_10_09_29_40] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06501408
Z variance train             0.0061275577
KL Divergence                11.042376
KL Loss                      1.1042376
QF Loss                      281.7664
VF Loss                      45.972023
Policy Loss                  -1221.1647
Q Predictions Mean           1218.9167
Q Predictions Std            362.92096
Q Predictions Max            1616.1637
Q Predictions Min            40.034077
V Predictions Mean           1219.7051
V Predictions Std            361.86255
V Predictions Max            1590.008
V Predictions Min            29.73947
Log Pis Mean                 0.15716423
Log Pis Std                  2.1238637
Log Pis Max                  8.670515
Log Pis Min                  -4.971611
Policy mu Mean               0.049009103
Policy mu Std                0.9388226
Policy mu Max                2.8951335
Policy mu Min                -2.9291651
Policy log std Mean          -0.57700616
Policy log std Std           0.20922557
Policy log std Max           -0.0017905235
Policy log std Min           -1.3150961
Z mean eval                  0.015878186
Z variance eval              0.0050876094
total_rewards                [ 975.17870242  257.40733255  250.4987923  1802.18578698  488.56313836
 1496.06214265  247.16782405 2021.20204859  709.32792711  485.42999738]
total_rewards_mean           873.3023692398929
total_rewards_std            637.4416781874132
total_rewards_max            2021.2020485944722
total_rewards_min            247.16782404851958
Number of train steps total  588000
Number of env steps total    533528
Number of rollouts total     0
Train Time (s)               142.3462163321674
(Previous) Eval Time (s)     5.515393274370581
Sample Time (s)              5.496763376053423
Epoch Time (s)               153.3583729825914
Total Train Time (s)         23413.883705215063
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:59:54.326409 UTC | [2020_01_10_09_29_40] Iteration #146 | Epoch Duration: 153.44305968284607
2020-01-10 15:59:54.326586 UTC | [2020_01_10_09_29_40] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01520546
Z variance train             0.005087357
KL Divergence                11.164179
KL Loss                      1.1164179
QF Loss                      284.8289
VF Loss                      200.18202
Policy Loss                  -1230.115
Q Predictions Mean           1224.8024
Q Predictions Std            336.4755
Q Predictions Max            1585.718
Q Predictions Min            67.890785
V Predictions Mean           1227.1232
V Predictions Std            330.59616
V Predictions Max            1581.9589
V Predictions Min            64.68864
Log Pis Mean                 0.12968343
Log Pis Std                  2.0876327
Log Pis Max                  11.528842
Log Pis Min                  -5.5886097
Policy mu Mean               0.23127478
Policy mu Std                0.9041737
Policy mu Max                3.533517
Policy mu Min                -3.7472172
Policy log std Mean          -0.5998726
Policy log std Std           0.21785067
Policy log std Max           0.18873411
Policy log std Min           -3.5942852
Z mean eval                  0.07144508
Z variance eval              0.00555723
total_rewards                [2636.90854346 3138.5163823  2364.92717435 1020.07436503 3147.40030332
 1171.01041164  693.04495879  868.61452821  835.44397988  808.20949201]
total_rewards_mean           1668.4150139006924
total_rewards_std            972.8454762292005
total_rewards_max            3147.400303320641
total_rewards_min            693.0449587933507
Number of train steps total  592000
Number of env steps total    537883
Number of rollouts total     0
Train Time (s)               145.01718786917627
(Previous) Eval Time (s)     9.71390878688544
Sample Time (s)              6.282389492262155
Epoch Time (s)               161.01348614832386
Total Train Time (s)         23574.974552408792
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:02:35.419387 UTC | [2020_01_10_09_29_40] Iteration #147 | Epoch Duration: 161.09265732765198
2020-01-10 16:02:35.419550 UTC | [2020_01_10_09_29_40] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06971631
Z variance train             0.0055425093
KL Divergence                11.164414
KL Loss                      1.1164415
QF Loss                      272.26273
VF Loss                      64.52449
Policy Loss                  -1226.6687
Q Predictions Mean           1222.2802
Q Predictions Std            378.86124
Q Predictions Max            1590.4843
Q Predictions Min            28.028893
V Predictions Mean           1228.5195
V Predictions Std            376.31702
V Predictions Max            1584.8031
V Predictions Min            30.889235
Log Pis Mean                 0.41416338
Log Pis Std                  2.3804836
Log Pis Max                  8.329468
Log Pis Min                  -4.7992473
Policy mu Mean               0.11022606
Policy mu Std                0.9828341
Policy mu Max                3.1521268
Policy mu Min                -2.8991294
Policy log std Mean          -0.600959
Policy log std Std           0.22453488
Policy log std Max           0.040060043
Policy log std Min           -1.9966867
Z mean eval                  0.07254492
Z variance eval              0.015457086
total_rewards                [2400.56787774  646.65021847 2399.93232204 3128.87357449 1685.44556612
 2358.742542   3099.11893266 1805.42840258 3064.3826445  3140.98652747]
total_rewards_mean           2373.012860806805
total_rewards_std            770.9246156207339
total_rewards_max            3140.9865274658646
total_rewards_min            646.6502184720588
Number of train steps total  596000
Number of env steps total    542261
Number of rollouts total     0
Train Time (s)               144.86521926010028
(Previous) Eval Time (s)     16.85498925112188
Sample Time (s)              6.560892675071955
Epoch Time (s)               168.2811011862941
Total Train Time (s)         23743.33725313563
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:05:23.784123 UTC | [2020_01_10_09_29_40] Iteration #148 | Epoch Duration: 168.364431142807
2020-01-10 16:05:23.784330 UTC | [2020_01_10_09_29_40] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07273775
Z variance train             0.015461492
KL Divergence                9.00844
KL Loss                      0.90084404
QF Loss                      2474.8389
VF Loss                      124.137566
Policy Loss                  -1191.0194
Q Predictions Mean           1186.6628
Q Predictions Std            360.26593
Q Predictions Max            1586.4496
Q Predictions Min            40.31277
V Predictions Mean           1196.0852
V Predictions Std            350.435
V Predictions Max            1592.9005
V Predictions Min            74.01439
Log Pis Mean                 0.569356
Log Pis Std                  2.6968744
Log Pis Max                  12.208969
Log Pis Min                  -4.9067407
Policy mu Mean               0.09090509
Policy mu Std                1.0780863
Policy mu Max                3.9038663
Policy mu Min                -4.0967383
Policy log std Mean          -0.5743938
Policy log std Std           0.24320196
Policy log std Max           0.14318335
Policy log std Min           -2.1134567
Z mean eval                  0.055707015
Z variance eval              0.0049402113
total_rewards                [1534.07316302 3104.24209645 1885.6716885  3149.67276074 2109.32257371
 3091.52949031 1735.28162208 3118.1324878  1713.14728238 3129.00231746]
total_rewards_mean           2457.007548244347
total_rewards_std            675.5229604324553
total_rewards_max            3149.672760739696
total_rewards_min            1534.0731630204912
Number of train steps total  600000
Number of env steps total    546676
Number of rollouts total     0
Train Time (s)               143.9310645852238
(Previous) Eval Time (s)     14.463949606753886
Sample Time (s)              6.521894891746342
Epoch Time (s)               164.91690908372402
Total Train Time (s)         23908.339814271312
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:08:08.788690 UTC | [2020_01_10_09_29_40] Iteration #149 | Epoch Duration: 165.00420689582825
2020-01-10 16:08:08.788872 UTC | [2020_01_10_09_29_40] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05771482
Z variance train             0.0049424423
KL Divergence                10.908702
KL Loss                      1.0908703
QF Loss                      9082.916
VF Loss                      485.4979
Policy Loss                  -1198.7522
Q Predictions Mean           1194.0491
Q Predictions Std            359.56116
Q Predictions Max            1565.9127
Q Predictions Min            -0.90462375
V Predictions Mean           1196.1108
V Predictions Std            355.71823
V Predictions Max            1554.6306
V Predictions Min            1.2608527
Log Pis Mean                 0.3570699
Log Pis Std                  2.336119
Log Pis Max                  11.694501
Log Pis Min                  -5.943588
Policy mu Mean               0.14804272
Policy mu Std                0.9906493
Policy mu Max                4.494999
Policy mu Min                -3.270587
Policy log std Mean          -0.5782938
Policy log std Std           0.258003
Policy log std Max           0.015275598
Policy log std Min           -3.0393927
Z mean eval                  0.04181321
Z variance eval              0.005433245
total_rewards                [1563.81288758 2466.54045959 2038.21025288 3127.49579129 1181.73435672
 3166.00345418  996.25426486 1184.65631865  957.20894906  910.62979604]
total_rewards_mean           1759.2546530874893
total_rewards_std            841.2251134218614
total_rewards_max            3166.003454178511
total_rewards_min            910.6297960429425
Number of train steps total  604000
Number of env steps total    551219
Number of rollouts total     0
Train Time (s)               143.8015513336286
(Previous) Eval Time (s)     12.292662573046982
Sample Time (s)              6.6120789628475904
Epoch Time (s)               162.70629286952317
Total Train Time (s)         24071.125337462872
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:10:51.580274 UTC | [2020_01_10_09_29_40] Iteration #150 | Epoch Duration: 162.7912209033966
2020-01-10 16:10:51.580597 UTC | [2020_01_10_09_29_40] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04170226
Z variance train             0.0054544257
KL Divergence                10.825607
KL Loss                      1.0825608
QF Loss                      584.928
VF Loss                      263.75494
Policy Loss                  -1209.2308
Q Predictions Mean           1200.2188
Q Predictions Std            350.249
Q Predictions Max            1586.2738
Q Predictions Min            1.2844014
V Predictions Mean           1208.731
V Predictions Std            336.1892
V Predictions Max            1575.7034
V Predictions Min            -1.5227956
Log Pis Mean                 0.44326228
Log Pis Std                  2.3747606
Log Pis Max                  11.978239
Log Pis Min                  -6.332097
Policy mu Mean               0.098854214
Policy mu Std                0.99876964
Policy mu Max                3.6273518
Policy mu Min                -2.6573484
Policy log std Mean          -0.5933135
Policy log std Std           0.21438289
Policy log std Max           0.05691415
Policy log std Min           -2.744666
Z mean eval                  0.061823286
Z variance eval              0.00601161
total_rewards                [3159.32304955  908.87774411  831.24726432 3187.43420614 3144.41086913
 2643.19421183 3103.58521721 3187.33375983 1643.65175325 3139.26543221]
total_rewards_mean           2494.8323507589666
total_rewards_std            929.4039340569805
total_rewards_max            3187.4342061420402
total_rewards_min            831.2472643226702
Number of train steps total  608000
Number of env steps total    555686
Number of rollouts total     0
Train Time (s)               142.82132045179605
(Previous) Eval Time (s)     17.195522909983993
Sample Time (s)              5.646770417224616
Epoch Time (s)               165.66361377900466
Total Train Time (s)         24236.8666907046
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:13:37.321315 UTC | [2020_01_10_09_29_40] Iteration #151 | Epoch Duration: 165.74051666259766
2020-01-10 16:13:37.321438 UTC | [2020_01_10_09_29_40] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059239514
Z variance train             0.0060158432
KL Divergence                10.542354
KL Loss                      1.0542353
QF Loss                      323.222
VF Loss                      166.55656
Policy Loss                  -1240.1149
Q Predictions Mean           1235.8021
Q Predictions Std            307.02136
Q Predictions Max            1584.2523
Q Predictions Min            44.592495
V Predictions Mean           1237.7565
V Predictions Std            307.29312
V Predictions Max            1589.285
V Predictions Min            31.968548
Log Pis Mean                 0.5599984
Log Pis Std                  2.0856988
Log Pis Max                  8.062819
Log Pis Min                  -7.8265676
Policy mu Mean               0.08280136
Policy mu Std                1.0320746
Policy mu Max                3.2964163
Policy mu Min                -2.6745827
Policy log std Mean          -0.5956411
Policy log std Std           0.21065162
Policy log std Max           0.087141335
Policy log std Min           -1.2615412
Z mean eval                  0.044965412
Z variance eval              0.0048818975
total_rewards                [1472.29781112 1429.33520114  888.4872773   870.96235458 1658.89756747
 2722.57908364 1712.43646181 2465.5802424  2422.79160763 2871.26075986]
total_rewards_mean           1851.462836697024
total_rewards_std            690.6126822475644
total_rewards_max            2871.260759857093
total_rewards_min            870.9623545817369
Number of train steps total  612000
Number of env steps total    560183
Number of rollouts total     0
Train Time (s)               141.36812322307378
(Previous) Eval Time (s)     10.790945296175778
Sample Time (s)              6.589803732000291
Epoch Time (s)               158.74887225124985
Total Train Time (s)         24395.692559622694
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:16:16.149124 UTC | [2020_01_10_09_29_40] Iteration #152 | Epoch Duration: 158.82758378982544
2020-01-10 16:16:16.149293 UTC | [2020_01_10_09_29_40] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04599654
Z variance train             0.0048695235
KL Divergence                11.000028
KL Loss                      1.1000028
QF Loss                      323.6253
VF Loss                      45.5514
Policy Loss                  -1213.8768
Q Predictions Mean           1210.781
Q Predictions Std            385.08972
Q Predictions Max            1583.5251
Q Predictions Min            -9.642666
V Predictions Mean           1211.6312
V Predictions Std            382.98883
V Predictions Max            1589.5364
V Predictions Min            2.3212814
Log Pis Mean                 0.38699585
Log Pis Std                  2.1003249
Log Pis Max                  9.12609
Log Pis Min                  -4.8755035
Policy mu Mean               0.043102924
Policy mu Std                0.9981879
Policy mu Max                3.7767732
Policy mu Min                -2.996815
Policy log std Mean          -0.61494976
Policy log std Std           0.24543937
Policy log std Max           0.06646085
Policy log std Min           -2.755156
Z mean eval                  0.0616386
Z variance eval              0.003352252
total_rewards                [3182.55775858 2142.93716014 3174.18316054 3178.60346176 3189.70840238
 1001.78585909  863.23558897  807.21817653 3117.25150631 3181.45399669]
total_rewards_mean           2383.893507100421
total_rewards_std            1023.9056442754822
total_rewards_max            3189.708402382983
total_rewards_min            807.218176534258
Number of train steps total  616000
Number of env steps total    564674
Number of rollouts total     0
Train Time (s)               144.32269140006974
(Previous) Eval Time (s)     13.672431943006814
Sample Time (s)              5.532050225883722
Epoch Time (s)               163.52717356896028
Total Train Time (s)         24559.296101603657
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:18:59.754007 UTC | [2020_01_10_09_29_40] Iteration #153 | Epoch Duration: 163.60459542274475
2020-01-10 16:18:59.754141 UTC | [2020_01_10_09_29_40] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0608191
Z variance train             0.0033621371
KL Divergence                12.87582
KL Loss                      1.287582
QF Loss                      216.17387
VF Loss                      112.90185
Policy Loss                  -1208.5815
Q Predictions Mean           1205.4429
Q Predictions Std            346.90836
Q Predictions Max            1572.3024
Q Predictions Min            -29.323414
V Predictions Mean           1203.9409
V Predictions Std            342.02283
V Predictions Max            1571.441
V Predictions Min            -35.593075
Log Pis Mean                 0.34913385
Log Pis Std                  2.446881
Log Pis Max                  17.114407
Log Pis Min                  -7.0125427
Policy mu Mean               0.12271732
Policy mu Std                1.0177772
Policy mu Max                3.9530456
Policy mu Min                -2.7308266
Policy log std Mean          -0.59258884
Policy log std Std           0.20831273
Policy log std Max           0.07924944
Policy log std Min           -1.3201066
Z mean eval                  0.121108636
Z variance eval              0.003658155
total_rewards                [3122.76941395 3154.52957414 1416.42870022 3186.60656448 3137.73514447
 3130.94657052 1491.20498865 3148.66559991  303.12501047  145.30819993]
total_rewards_mean           2223.731976673585
total_rewards_std            1196.3541763653232
total_rewards_max            3186.6065644752334
total_rewards_min            145.30819992778166
Number of train steps total  620000
Number of env steps total    569048
Number of rollouts total     0
Train Time (s)               143.12027641106397
(Previous) Eval Time (s)     12.971764331683517
Sample Time (s)              5.554132597986609
Epoch Time (s)               161.6461733407341
Total Train Time (s)         24721.02282878384
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:21:41.486822 UTC | [2020_01_10_09_29_40] Iteration #154 | Epoch Duration: 161.73252964019775
2020-01-10 16:21:41.487152 UTC | [2020_01_10_09_29_40] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12180742
Z variance train             0.0036655557
KL Divergence                12.42394
KL Loss                      1.242394
QF Loss                      374.01337
VF Loss                      231.03491
Policy Loss                  -1211.9882
Q Predictions Mean           1209.6094
Q Predictions Std            373.8061
Q Predictions Max            1590.9221
Q Predictions Min            13.493124
V Predictions Mean           1217.3914
V Predictions Std            368.4298
V Predictions Max            1578.3462
V Predictions Min            -9.753593
Log Pis Mean                 0.44932818
Log Pis Std                  2.2633235
Log Pis Max                  10.713495
Log Pis Min                  -4.3620133
Policy mu Mean               0.17907506
Policy mu Std                0.99332255
Policy mu Max                3.0260005
Policy mu Min                -2.7459407
Policy log std Mean          -0.6124503
Policy log std Std           0.21397428
Policy log std Max           0.017109096
Policy log std Min           -2.236409
Z mean eval                  0.050471097
Z variance eval              0.0028340663
total_rewards                [ 805.62678765  860.05058189  972.38181351  823.59065217 3110.06402775
 3168.02054144 1128.71446811 3097.17012803  814.69617313  850.84134755]
total_rewards_mean           1563.1156521225778
total_rewards_std            1026.7529630940887
total_rewards_max            3168.0205414383304
total_rewards_min            805.6267876507055
Number of train steps total  624000
Number of env steps total    573890
Number of rollouts total     0
Train Time (s)               143.18407374620438
(Previous) Eval Time (s)     10.834889808669686
Sample Time (s)              7.297032180707902
Epoch Time (s)               161.31599573558196
Total Train Time (s)         24882.418167416472
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:24:22.881572 UTC | [2020_01_10_09_29_40] Iteration #155 | Epoch Duration: 161.394207239151
2020-01-10 16:24:22.881698 UTC | [2020_01_10_09_29_40] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051718343
Z variance train             0.0028303394
KL Divergence                12.261123
KL Loss                      1.2261122
QF Loss                      397.3027
VF Loss                      59.015694
Policy Loss                  -1240.1753
Q Predictions Mean           1236.3499
Q Predictions Std            348.52225
Q Predictions Max            1609.0396
Q Predictions Min            45.24773
V Predictions Mean           1236.2385
V Predictions Std            344.80856
V Predictions Max            1613.524
V Predictions Min            49.896427
Log Pis Mean                 0.23428181
Log Pis Std                  1.8546948
Log Pis Max                  6.619987
Log Pis Min                  -4.03751
Policy mu Mean               0.1488065
Policy mu Std                0.9434034
Policy mu Max                2.5604162
Policy mu Min                -2.8024158
Policy log std Mean          -0.5947045
Policy log std Std           0.20916237
Policy log std Max           0.06646782
Policy log std Min           -1.4861593
Z mean eval                  0.08847751
Z variance eval              0.0038371198
total_rewards                [2964.28979992 3211.94910195 3151.56607656 3213.36461044 3119.37633035
 3169.78345888 1788.03091426 3095.44102728 3160.05263091 1173.92041203]
total_rewards_mean           2804.7774362576374
total_rewards_std            679.3242650415492
total_rewards_max            3213.364610439205
total_rewards_min            1173.920412025451
Number of train steps total  628000
Number of env steps total    578419
Number of rollouts total     0
Train Time (s)               143.20209902664647
(Previous) Eval Time (s)     16.274506172165275
Sample Time (s)              6.53942983597517
Epoch Time (s)               166.0160350347869
Total Train Time (s)         25048.516931997612
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:27:08.981650 UTC | [2020_01_10_09_29_40] Iteration #156 | Epoch Duration: 166.099862575531
2020-01-10 16:27:08.981779 UTC | [2020_01_10_09_29_40] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.090422444
Z variance train             0.00385074
KL Divergence                11.72918
KL Loss                      1.1729181
QF Loss                      632.8225
VF Loss                      97.89184
Policy Loss                  -1229.1196
Q Predictions Mean           1224.4185
Q Predictions Std            326.87567
Q Predictions Max            1575.5033
Q Predictions Min            -9.977678
V Predictions Mean           1234.6838
V Predictions Std            328.59473
V Predictions Max            1585.3771
V Predictions Min            -10.659868
Log Pis Mean                 0.13517797
Log Pis Std                  2.1561038
Log Pis Max                  9.218174
Log Pis Min                  -3.8169966
Policy mu Mean               0.2071809
Policy mu Std                0.9094457
Policy mu Max                3.3694534
Policy mu Min                -2.4732332
Policy log std Mean          -0.5875431
Policy log std Std           0.21456653
Policy log std Max           0.10087311
Policy log std Min           -2.3035007
Z mean eval                  0.082182944
Z variance eval              0.007788879
total_rewards                [1377.09835238 1880.05679482 3083.89170407 2619.48777005  831.29473096
  810.4169665   921.50772351  837.79226963  634.7563671  1325.0426033 ]
total_rewards_mean           1432.1345282304706
total_rewards_std            796.9050809972919
total_rewards_max            3083.8917040696874
total_rewards_min            634.7563670966747
Number of train steps total  632000
Number of env steps total    582956
Number of rollouts total     0
Train Time (s)               144.0140588390641
(Previous) Eval Time (s)     9.699528307188302
Sample Time (s)              5.674501564819366
Epoch Time (s)               159.38808871107176
Total Train Time (s)         25207.992450735066
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:29:48.458710 UTC | [2020_01_10_09_29_40] Iteration #157 | Epoch Duration: 159.47684264183044
2020-01-10 16:29:48.458840 UTC | [2020_01_10_09_29_40] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.083296865
Z variance train             0.0078014424
KL Divergence                10.559118
KL Loss                      1.0559119
QF Loss                      1528.3204
VF Loss                      68.53776
Policy Loss                  -1209.3303
Q Predictions Mean           1206.8757
Q Predictions Std            370.51297
Q Predictions Max            1585.1339
Q Predictions Min            16.034126
V Predictions Mean           1205.0244
V Predictions Std            367.10025
V Predictions Max            1579.9241
V Predictions Min            4.391451
Log Pis Mean                 0.18266982
Log Pis Std                  2.2412229
Log Pis Max                  10.411915
Log Pis Min                  -5.0837126
Policy mu Mean               0.038261667
Policy mu Std                0.9448748
Policy mu Max                2.3629808
Policy mu Min                -3.2581646
Policy log std Mean          -0.59408844
Policy log std Std           0.21039413
Policy log std Max           -0.04971361
Policy log std Min           -2.4251506
Z mean eval                  0.035284683
Z variance eval              0.0071438164
total_rewards                [ 609.91906912  865.03367203  559.85467828  826.86381845  885.19769886
  932.31459349  864.71492037  820.70269638 1347.76722622  581.41026917]
total_rewards_mean           829.3778642365147
total_rewards_std            216.17905001249622
total_rewards_max            1347.7672262207486
total_rewards_min            559.8546782754211
Number of train steps total  636000
Number of env steps total    587487
Number of rollouts total     0
Train Time (s)               143.15179625479504
(Previous) Eval Time (s)     5.595224529039115
Sample Time (s)              6.622128817718476
Epoch Time (s)               155.36914960155264
Total Train Time (s)         25363.444731589872
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:32:23.912661 UTC | [2020_01_10_09_29_40] Iteration #158 | Epoch Duration: 155.45373106002808
2020-01-10 16:32:23.912804 UTC | [2020_01_10_09_29_40] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035065632
Z variance train             0.0071459375
KL Divergence                10.687064
KL Loss                      1.0687064
QF Loss                      239.10754
VF Loss                      49.961563
Policy Loss                  -1234.3479
Q Predictions Mean           1230.1005
Q Predictions Std            350.98822
Q Predictions Max            1614.1427
Q Predictions Min            18.15343
V Predictions Mean           1233.645
V Predictions Std            347.32385
V Predictions Max            1612.0562
V Predictions Min            12.178988
Log Pis Mean                 0.25395587
Log Pis Std                  1.939148
Log Pis Max                  5.912256
Log Pis Min                  -3.8940482
Policy mu Mean               0.20859636
Policy mu Std                0.9452621
Policy mu Max                3.901692
Policy mu Min                -2.629862
Policy log std Mean          -0.5807152
Policy log std Std           0.20179941
Policy log std Max           0.022091985
Policy log std Min           -1.2912121
Z mean eval                  0.029445339
Z variance eval              0.005516881
total_rewards                [3155.96848112  892.42330294  915.5077179   957.17632321 3097.12241792
 1472.48176153 2208.85800994  948.14250059 2022.71223976 2701.21442637]
total_rewards_mean           1837.160718127391
total_rewards_std            876.6769165212335
total_rewards_max            3155.968481116634
total_rewards_min            892.4233029443674
Number of train steps total  640000
Number of env steps total    592464
Number of rollouts total     0
Train Time (s)               143.53494111215696
(Previous) Eval Time (s)     12.71063303668052
Sample Time (s)              8.238756366074085
Epoch Time (s)               164.48433051491156
Total Train Time (s)         25528.018160898704
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:35:08.488732 UTC | [2020_01_10_09_29_40] Iteration #159 | Epoch Duration: 164.57581400871277
2020-01-10 16:35:08.488907 UTC | [2020_01_10_09_29_40] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030580437
Z variance train             0.005522079
KL Divergence                10.845747
KL Loss                      1.0845747
QF Loss                      148.41582
VF Loss                      56.48005
Policy Loss                  -1270.5453
Q Predictions Mean           1265.8878
Q Predictions Std            326.53516
Q Predictions Max            1599.4316
Q Predictions Min            34.63028
V Predictions Mean           1273.8251
V Predictions Std            323.56427
V Predictions Max            1600.9987
V Predictions Min            31.571012
Log Pis Mean                 -0.08924548
Log Pis Std                  1.9104931
Log Pis Max                  10.68525
Log Pis Min                  -3.937357
Policy mu Mean               0.16811693
Policy mu Std                0.8897559
Policy mu Max                3.5464714
Policy mu Min                -2.6369097
Policy log std Mean          -0.59388
Policy log std Std           0.21457282
Policy log std Max           0.15469688
Policy log std Min           -2.6452007
Z mean eval                  0.05612409
Z variance eval              0.009698741
total_rewards                [3255.35533564  953.46881065  909.09955849  940.76838826 3180.20286471
 3200.77267749  955.74680936  907.32730017 3212.9236206  3247.74818006]
total_rewards_mean           2076.341354543969
total_rewards_std            1143.3324676449254
total_rewards_max            3255.3553356401007
total_rewards_min            907.3273001680578
Number of train steps total  644000
Number of env steps total    597011
Number of rollouts total     0
Train Time (s)               143.06273500388488
(Previous) Eval Time (s)     13.852553443983197
Sample Time (s)              6.542359332088381
Epoch Time (s)               163.45764777995646
Total Train Time (s)         25691.556366899516
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:37:52.032373 UTC | [2020_01_10_09_29_40] Iteration #160 | Epoch Duration: 163.54329991340637
2020-01-10 16:37:52.032683 UTC | [2020_01_10_09_29_40] Iteration #160 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056815784
Z variance train             0.009700854
KL Divergence                9.835583
KL Loss                      0.9835583
QF Loss                      227.91739
VF Loss                      90.480995
Policy Loss                  -1260.683
Q Predictions Mean           1249.9058
Q Predictions Std            358.7953
Q Predictions Max            1604.6599
Q Predictions Min            6.7083206
V Predictions Mean           1255.4526
V Predictions Std            344.70374
V Predictions Max            1596.6488
V Predictions Min            -1.510697
Log Pis Mean                 0.42362264
Log Pis Std                  2.5015688
Log Pis Max                  15.064404
Log Pis Min                  -4.171683
Policy mu Mean               0.04657927
Policy mu Std                1.022676
Policy mu Max                4.2296147
Policy mu Min                -4.8150725
Policy log std Mean          -0.574111
Policy log std Std           0.2339684
Policy log std Max           0.01790297
Policy log std Min           -3.1288967
Z mean eval                  0.109111205
Z variance eval              0.0069249384
total_rewards                [ 854.11392311 3145.62714488  816.77952295  922.13404694 3188.5541455
  834.06931785  939.56364689 3131.59677653  942.07356291  907.3436859 ]
total_rewards_mean           1568.1855773438838
total_rewards_std            1039.8501436897357
total_rewards_max            3188.5541454987047
total_rewards_min            816.779522946949
Number of train steps total  648000
Number of env steps total    601504
Number of rollouts total     0
Train Time (s)               139.96195697691292
(Previous) Eval Time (s)     10.813682110980153
Sample Time (s)              6.702123048715293
Epoch Time (s)               157.47776213660836
Total Train Time (s)         25849.109965893906
Epoch                        161
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:40:29.585665 UTC | [2020_01_10_09_29_40] Iteration #161 | Epoch Duration: 157.55278205871582
2020-01-10 16:40:29.585792 UTC | [2020_01_10_09_29_40] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10891537
Z variance train             0.0069413604
KL Divergence                10.490794
KL Loss                      1.0490794
QF Loss                      486.17407
VF Loss                      76.81821
Policy Loss                  -1241.4498
Q Predictions Mean           1244.3745
Q Predictions Std            336.21982
Q Predictions Max            1621.0417
Q Predictions Min            21.819687
V Predictions Mean           1244.0504
V Predictions Std            335.49316
V Predictions Max            1622.8019
V Predictions Min            4.2275887
Log Pis Mean                 0.12193948
Log Pis Std                  2.088824
Log Pis Max                  9.98908
Log Pis Min                  -5.047819
Policy mu Mean               0.09679536
Policy mu Std                0.92437774
Policy mu Max                3.4230146
Policy mu Min                -2.4708242
Policy log std Mean          -0.58206105
Policy log std Std           0.22165154
Policy log std Max           0.15004349
Policy log std Min           -2.3005533
Z mean eval                  0.035778172
Z variance eval              0.009712146
total_rewards                [3216.19932539 3188.43491767  945.48387449 3172.04657699 3213.62569739
 3174.18457119 3171.2310304  3202.55784278 3182.28259355  943.2558752 ]
total_rewards_mean           2740.9302305050924
total_rewards_std            898.4132809638845
total_rewards_max            3216.1993253898686
total_rewards_min            943.2558752029535
Number of train steps total  652000
Number of env steps total    605987
Number of rollouts total     0
Train Time (s)               146.85475444886833
(Previous) Eval Time (s)     15.497899489011616
Sample Time (s)              6.453795365989208
Epoch Time (s)               168.80644930386916
Total Train Time (s)         26017.99611612456
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:43:18.473196 UTC | [2020_01_10_09_29_40] Iteration #162 | Epoch Duration: 168.88730478286743
2020-01-10 16:43:18.473336 UTC | [2020_01_10_09_29_40] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03453356
Z variance train             0.00967318
KL Divergence                9.80262
KL Loss                      0.980262
QF Loss                      120.012024
VF Loss                      45.044384
Policy Loss                  -1262.5089
Q Predictions Mean           1261.8455
Q Predictions Std            328.8428
Q Predictions Max            1596.931
Q Predictions Min            20.188055
V Predictions Mean           1263.2146
V Predictions Std            327.57498
V Predictions Max            1602.0886
V Predictions Min            17.606073
Log Pis Mean                 0.24699931
Log Pis Std                  2.1628735
Log Pis Max                  14.834895
Log Pis Min                  -4.3103843
Policy mu Mean               0.062104587
Policy mu Std                0.96940446
Policy mu Max                4.078988
Policy mu Min                -4.2701645
Policy log std Mean          -0.5981348
Policy log std Std           0.21860974
Policy log std Max           0.09823692
Policy log std Min           -2.0769503
Z mean eval                  0.073062204
Z variance eval              0.01454963
total_rewards                [3241.61334253 3217.56697929 1758.20369535  961.73664416  859.38200425
 3213.1183871   917.73877209  953.4095962   989.02147691  984.70968314]
total_rewards_mean           1709.6500581031632
total_rewards_std            1020.2792204379834
total_rewards_max            3241.613342531306
total_rewards_min            859.3820042528198
Number of train steps total  656000
Number of env steps total    610448
Number of rollouts total     0
Train Time (s)               144.57931344769895
(Previous) Eval Time (s)     11.621368201915175
Sample Time (s)              6.64529690798372
Epoch Time (s)               162.84597855759785
Total Train Time (s)         26180.923298812937
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:46:01.402283 UTC | [2020_01_10_09_29_40] Iteration #163 | Epoch Duration: 162.9288454055786
2020-01-10 16:46:01.402426 UTC | [2020_01_10_09_29_40] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.073093146
Z variance train             0.014555596
KL Divergence                8.534344
KL Loss                      0.8534344
QF Loss                      278.99506
VF Loss                      78.65273
Policy Loss                  -1242.274
Q Predictions Mean           1243.9834
Q Predictions Std            338.2486
Q Predictions Max            1601.6528
Q Predictions Min            7.6458073
V Predictions Mean           1242.1531
V Predictions Std            336.9932
V Predictions Max            1597.9753
V Predictions Min            14.053256
Log Pis Mean                 0.13278054
Log Pis Std                  2.0904899
Log Pis Max                  7.379102
Log Pis Min                  -5.8337526
Policy mu Mean               0.121294044
Policy mu Std                0.89447117
Policy mu Max                2.4118974
Policy mu Min                -2.8544123
Policy log std Mean          -0.5819048
Policy log std Std           0.19587468
Policy log std Max           0.1734637
Policy log std Min           -1.315211
Z mean eval                  0.06791707
Z variance eval              0.010976302
total_rewards                [ 907.93978135 3126.2560949  1020.16363203  894.50254322 3137.01515315
 3178.44146567 3190.72084653 3117.23480026 3158.99894688 3133.23503253]
total_rewards_mean           2486.4508296522145
total_rewards_std            1012.5199172519561
total_rewards_max            3190.720846529795
total_rewards_min            894.5025432211291
Number of train steps total  660000
Number of env steps total    614915
Number of rollouts total     0
Train Time (s)               145.30417521717027
(Previous) Eval Time (s)     17.166393536143005
Sample Time (s)              6.5568110519088805
Epoch Time (s)               169.02737980522215
Total Train Time (s)         26350.072065339424
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:48:50.552564 UTC | [2020_01_10_09_29_40] Iteration #164 | Epoch Duration: 169.1500427722931
2020-01-10 16:48:50.552696 UTC | [2020_01_10_09_29_40] Iteration #164 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0676812
Z variance train             0.010983737
KL Divergence                8.984974
KL Loss                      0.8984974
QF Loss                      3129.4265
VF Loss                      84.163376
Policy Loss                  -1245.9696
Q Predictions Mean           1239.6272
Q Predictions Std            324.2859
Q Predictions Max            1593.091
Q Predictions Min            19.243725
V Predictions Mean           1248.0398
V Predictions Std            315.36478
V Predictions Max            1598.6937
V Predictions Min            11.13528
Log Pis Mean                 0.1380346
Log Pis Std                  2.1446388
Log Pis Max                  7.597383
Log Pis Min                  -6.521143
Policy mu Mean               0.039716538
Policy mu Std                0.98434204
Policy mu Max                2.9186003
Policy mu Min                -2.7555726
Policy log std Mean          -0.57075304
Policy log std Std           0.2380179
Policy log std Max           0.36897904
Policy log std Min           -2.6121664
Z mean eval                  0.10303243
Z variance eval              0.007004899
total_rewards                [3155.0562098  2425.84085611 3187.78233285 3142.52041973 3148.2274208
 3159.82102742 1478.14921299 3107.73911819 3147.52179201 2050.69127671]
total_rewards_mean           2800.3349666598156
total_rewards_std            575.2143570636409
total_rewards_max            3187.7823328464806
total_rewards_min            1478.1492129851308
Number of train steps total  664000
Number of env steps total    619521
Number of rollouts total     0
Train Time (s)               145.98920981679112
(Previous) Eval Time (s)     19.5739854760468
Sample Time (s)              6.628745142836124
Epoch Time (s)               172.19194043567404
Total Train Time (s)         26522.340238562785
Epoch                        165
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:51:42.821834 UTC | [2020_01_10_09_29_40] Iteration #165 | Epoch Duration: 172.2690508365631
2020-01-10 16:51:42.821960 UTC | [2020_01_10_09_29_40] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.102036074
Z variance train             0.0070124418
KL Divergence                11.067073
KL Loss                      1.1067073
QF Loss                      153.05908
VF Loss                      513.1888
Policy Loss                  -1262.5758
Q Predictions Mean           1258.6033
Q Predictions Std            333.07043
Q Predictions Max            1585.5795
Q Predictions Min            45.403484
V Predictions Mean           1261.9375
V Predictions Std            323.89453
V Predictions Max            1591.2114
V Predictions Min            34.961273
Log Pis Mean                 0.28379267
Log Pis Std                  2.0806553
Log Pis Max                  10.627344
Log Pis Min                  -3.8974674
Policy mu Mean               0.08087838
Policy mu Std                0.9490433
Policy mu Max                3.23417
Policy mu Min                -2.4958048
Policy log std Mean          -0.5845974
Policy log std Std           0.2230593
Policy log std Max           0.1972304
Policy log std Min           -2.2398725
Z mean eval                  0.04717475
Z variance eval              0.0050836266
total_rewards                [3154.96003821 3128.61488056 3116.19516008  864.85530156 3147.68849462
  875.78693807 3141.65789204  953.44812136  898.90612053 3126.31664046]
total_rewards_mean           2240.84295874811
total_rewards_std            1096.4848573914614
total_rewards_max            3154.9600382050926
total_rewards_min            864.8553015621836
Number of train steps total  668000
Number of env steps total    623988
Number of rollouts total     0
Train Time (s)               145.16060385899618
(Previous) Eval Time (s)     13.172788900788873
Sample Time (s)              6.676446405239403
Epoch Time (s)               165.00983916502446
Total Train Time (s)         26687.42550164601
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:54:27.910099 UTC | [2020_01_10_09_29_40] Iteration #166 | Epoch Duration: 165.08803057670593
2020-01-10 16:54:27.910286 UTC | [2020_01_10_09_29_40] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04963969
Z variance train             0.005101501
KL Divergence                10.940677
KL Loss                      1.0940677
QF Loss                      309.08392
VF Loss                      193.8919
Policy Loss                  -1255.6035
Q Predictions Mean           1255.6074
Q Predictions Std            328.06384
Q Predictions Max            1587.6307
Q Predictions Min            -7.4621315
V Predictions Mean           1264.2354
V Predictions Std            325.95142
V Predictions Max            1588.6599
V Predictions Min            21.322588
Log Pis Mean                 0.059565365
Log Pis Std                  2.0319328
Log Pis Max                  5.8694625
Log Pis Min                  -4.4889245
Policy mu Mean               -0.02634568
Policy mu Std                0.9240868
Policy mu Max                3.6381383
Policy mu Min                -3.110581
Policy log std Mean          -0.5870855
Policy log std Std           0.20094629
Policy log std Max           0.005050719
Policy log std Min           -2.3360991
Z mean eval                  0.061845053
Z variance eval              0.006441717
total_rewards                [3084.57489597 3052.80574969  835.91806018 1465.0873408  3083.74964791
 3129.45292258 3116.24936386 3069.24966034 2338.1251757   818.12468827]
total_rewards_mean           2399.3337505300865
total_rewards_std            931.7665530095057
total_rewards_max            3129.4529225791184
total_rewards_min            818.1246882678489
Number of train steps total  672000
Number of env steps total    628334
Number of rollouts total     0
Train Time (s)               145.79665350494906
(Previous) Eval Time (s)     17.18504017125815
Sample Time (s)              6.659879921935499
Epoch Time (s)               169.6415735981427
Total Train Time (s)         26857.150412099436
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:57:17.636274 UTC | [2020_01_10_09_29_40] Iteration #167 | Epoch Duration: 169.72585606575012
2020-01-10 16:57:17.636419 UTC | [2020_01_10_09_29_40] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06062454
Z variance train             0.006435594
KL Divergence                10.242714
KL Loss                      1.0242714
QF Loss                      196.899
VF Loss                      54.38031
Policy Loss                  -1262.803
Q Predictions Mean           1260.3002
Q Predictions Std            330.017
Q Predictions Max            1594.8735
Q Predictions Min            80.82126
V Predictions Mean           1260.5614
V Predictions Std            324.072
V Predictions Max            1595.6414
V Predictions Min            77.60584
Log Pis Mean                 0.028755073
Log Pis Std                  2.2450533
Log Pis Max                  9.012765
Log Pis Min                  -7.873144
Policy mu Mean               0.08460307
Policy mu Std                0.92587215
Policy mu Max                2.7162216
Policy mu Min                -3.000808
Policy log std Mean          -0.58687836
Policy log std Std           0.21932685
Policy log std Max           0.14705032
Policy log std Min           -1.9016837
Z mean eval                  0.098705076
Z variance eval              0.006197418
total_rewards                [3179.67912601 1520.8658824   762.09198387 3125.82174588 3160.84334217
 3251.72809127 3209.22873128 3213.96341664 3157.5218048   748.28635459]
total_rewards_mean           2533.0030478907947
total_rewards_std            1016.7175749450356
total_rewards_max            3251.72809127293
total_rewards_min            748.2863545867298
Number of train steps total  676000
Number of env steps total    632786
Number of rollouts total     0
Train Time (s)               144.08243550918996
(Previous) Eval Time (s)     17.5604743831791
Sample Time (s)              6.4551416505128145
Epoch Time (s)               168.09805154288188
Total Train Time (s)         27025.329395341687
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:00:05.817494 UTC | [2020_01_10_09_29_40] Iteration #168 | Epoch Duration: 168.1809802055359
2020-01-10 17:00:05.817623 UTC | [2020_01_10_09_29_40] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.097063445
Z variance train             0.006213379
KL Divergence                10.613058
KL Loss                      1.0613059
QF Loss                      202.0643
VF Loss                      119.282265
Policy Loss                  -1210.5323
Q Predictions Mean           1214.0625
Q Predictions Std            386.65714
Q Predictions Max            1592.5293
Q Predictions Min            59.00125
V Predictions Mean           1213.6006
V Predictions Std            385.2743
V Predictions Max            1593.8899
V Predictions Min            58.831173
Log Pis Mean                 0.25839534
Log Pis Std                  2.1915166
Log Pis Max                  6.1516805
Log Pis Min                  -7.1581106
Policy mu Mean               0.07688
Policy mu Std                0.9514423
Policy mu Max                2.815865
Policy mu Min                -2.472647
Policy log std Mean          -0.60831964
Policy log std Std           0.198857
Policy log std Max           0.0848397
Policy log std Min           -1.310775
Z mean eval                  0.09146877
Z variance eval              0.004463042
total_rewards                [ 813.49655887  675.08048222  870.0524688  3205.81714903  957.68582751
 1137.16263498 3204.93996787  963.17794066  999.62241435  842.14511197]
total_rewards_mean           1366.9180556268939
total_rewards_std            926.564719748541
total_rewards_max            3205.8171490326827
total_rewards_min            675.0804822167148
Number of train steps total  680000
Number of env steps total    637332
Number of rollouts total     0
Train Time (s)               143.53067876119167
(Previous) Eval Time (s)     9.376092021353543
Sample Time (s)              6.681025407742709
Epoch Time (s)               159.58779619028792
Total Train Time (s)         27185.010681745596
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:02:45.499986 UTC | [2020_01_10_09_29_40] Iteration #169 | Epoch Duration: 159.6822748184204
2020-01-10 17:02:45.500111 UTC | [2020_01_10_09_29_40] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09102235
Z variance train             0.004470888
KL Divergence                12.299294
KL Loss                      1.2299294
QF Loss                      147.11102
VF Loss                      38.37572
Policy Loss                  -1275.2473
Q Predictions Mean           1274.9579
Q Predictions Std            284.67413
Q Predictions Max            1590.6715
Q Predictions Min            20.021698
V Predictions Mean           1278.5358
V Predictions Std            283.58917
V Predictions Max            1590.7234
V Predictions Min            18.578484
Log Pis Mean                 0.14307508
Log Pis Std                  2.0366743
Log Pis Max                  6.0905023
Log Pis Min                  -8.935037
Policy mu Mean               0.16946018
Policy mu Std                0.9054515
Policy mu Max                2.285207
Policy mu Min                -2.5152214
Policy log std Mean          -0.60915524
Policy log std Std           0.18688099
Policy log std Max           0.032355726
Policy log std Min           -1.3477261
Z mean eval                  0.04553462
Z variance eval              0.0034964003
total_rewards                [1061.05537502 3089.16143612 3039.52545506  867.42379012 3049.25857434
 3012.56830568 3072.27110889  853.30383593 3044.28418916 2986.96905471]
total_rewards_mean           2407.582112502652
total_rewards_std            970.8528640894917
total_rewards_max            3089.161436117956
total_rewards_min            853.303835934372
Number of train steps total  684000
Number of env steps total    641752
Number of rollouts total     0
Train Time (s)               142.38824068382382
(Previous) Eval Time (s)     14.265096003189683
Sample Time (s)              6.493824110832065
Epoch Time (s)               163.14716079784557
Total Train Time (s)         27348.2372890627
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:05:28.728652 UTC | [2020_01_10_09_29_40] Iteration #170 | Epoch Duration: 163.22844624519348
2020-01-10 17:05:28.728778 UTC | [2020_01_10_09_29_40] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044252027
Z variance train             0.003493328
KL Divergence                12.058952
KL Loss                      1.2058953
QF Loss                      247.61932
VF Loss                      130.26976
Policy Loss                  -1274.4092
Q Predictions Mean           1271.7219
Q Predictions Std            330.31076
Q Predictions Max            1589.2261
Q Predictions Min            11.790161
V Predictions Mean           1275.5575
V Predictions Std            323.91046
V Predictions Max            1582.389
V Predictions Min            -16.447706
Log Pis Mean                 -0.015670754
Log Pis Std                  2.1627884
Log Pis Max                  13.820702
Log Pis Min                  -5.78416
Policy mu Mean               -0.042638972
Policy mu Std                0.9065358
Policy mu Max                4.0267754
Policy mu Min                -2.6224217
Policy log std Mean          -0.5557456
Policy log std Std           0.25267658
Policy log std Max           0.1305219
Policy log std Min           -4.2284083
Z mean eval                  0.11349018
Z variance eval              0.0038836554
total_rewards                [3101.72638012 3095.04242382 1390.40962117 1908.66878832 3097.72733618
 3061.46815777 3049.19000301 3161.19682162 3110.50531442 3058.97154518]
total_rewards_mean           2803.4906391610466
total_rewards_std            589.2732080268611
total_rewards_max            3161.1968216233613
total_rewards_min            1390.4096211731203
Number of train steps total  688000
Number of env steps total    646172
Number of rollouts total     0
Train Time (s)               143.94471591012552
(Previous) Eval Time (s)     16.671667827758938
Sample Time (s)              6.661253008060157
Epoch Time (s)               167.27763674594462
Total Train Time (s)         27515.59876702167
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:08:16.093319 UTC | [2020_01_10_09_29_40] Iteration #171 | Epoch Duration: 167.36444330215454
2020-01-10 17:08:16.093485 UTC | [2020_01_10_09_29_40] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11228049
Z variance train             0.0038623295
KL Divergence                11.5919075
KL Loss                      1.1591908
QF Loss                      153.5256
VF Loss                      92.377464
Policy Loss                  -1244.0258
Q Predictions Mean           1243.3984
Q Predictions Std            341.46097
Q Predictions Max            1595.6254
Q Predictions Min            4.578176
V Predictions Mean           1239.2891
V Predictions Std            338.70944
V Predictions Max            1591.2068
V Predictions Min            -5.251565
Log Pis Mean                 0.22272348
Log Pis Std                  1.9903765
Log Pis Max                  6.78407
Log Pis Min                  -4.722655
Policy mu Mean               -0.00014716636
Policy mu Std                0.949377
Policy mu Max                2.1659324
Policy mu Min                -2.5512292
Policy log std Mean          -0.5765826
Policy log std Std           0.20300014
Policy log std Max           0.09910232
Policy log std Min           -1.2541564
Z mean eval                  0.029913923
Z variance eval              0.003956604
total_rewards                [ 903.6387405   853.96048102  884.35722991 1735.07575503 1589.52150238
 3169.80681329 1103.13784912 3191.42111742 2016.95198348  863.99616924]
total_rewards_mean           1631.186764138857
total_rewards_std            867.2718636247727
total_rewards_max            3191.4211174243674
total_rewards_min            853.9604810168594
Number of train steps total  692000
Number of env steps total    650830
Number of rollouts total     0
Train Time (s)               147.03569449204952
(Previous) Eval Time (s)     9.790033295750618
Sample Time (s)              6.689323971513659
Epoch Time (s)               163.5150517593138
Total Train Time (s)         27679.19067582069
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:10:59.686813 UTC | [2020_01_10_09_29_40] Iteration #172 | Epoch Duration: 163.5932011604309
2020-01-10 17:10:59.686985 UTC | [2020_01_10_09_29_40] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02992397
Z variance train             0.0039663687
KL Divergence                11.577377
KL Loss                      1.1577377
QF Loss                      257.4973
VF Loss                      76.622986
Policy Loss                  -1257.4065
Q Predictions Mean           1254.4
Q Predictions Std            358.5848
Q Predictions Max            1611.7458
Q Predictions Min            8.709941
V Predictions Mean           1258.5239
V Predictions Std            352.21234
V Predictions Max            1616.6119
V Predictions Min            7.883145
Log Pis Mean                 0.078417495
Log Pis Std                  2.1171238
Log Pis Max                  10.917342
Log Pis Min                  -7.649063
Policy mu Mean               0.086591594
Policy mu Std                0.9095783
Policy mu Max                3.521704
Policy mu Min                -2.6171567
Policy log std Mean          -0.5984145
Policy log std Std           0.20998043
Policy log std Max           0.028824627
Policy log std Min           -1.4328876
Z mean eval                  0.06367552
Z variance eval              0.0024941885
total_rewards                [ 743.24964902 1268.07988964  968.21450181  781.54709019 1120.69949754
 3190.6887376  3220.87455804  960.59809635 1704.86137184  877.19794975]
total_rewards_mean           1483.6011341786839
total_rewards_std            900.4027274092656
total_rewards_max            3220.8745580433456
total_rewards_min            743.2496490155413
Number of train steps total  696000
Number of env steps total    655294
Number of rollouts total     0
Train Time (s)               146.1007967297919
(Previous) Eval Time (s)     8.967437560670078
Sample Time (s)              5.519057317636907
Epoch Time (s)               160.5872916080989
Total Train Time (s)         27839.857687802985
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:13:40.358331 UTC | [2020_01_10_09_29_40] Iteration #173 | Epoch Duration: 160.67120456695557
2020-01-10 17:13:40.358553 UTC | [2020_01_10_09_29_40] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06346309
Z variance train             0.0024918043
KL Divergence                13.076573
KL Loss                      1.3076574
QF Loss                      168.68863
VF Loss                      87.76492
Policy Loss                  -1231.7133
Q Predictions Mean           1228.2307
Q Predictions Std            349.85968
Q Predictions Max            1595.892
Q Predictions Min            17.413681
V Predictions Mean           1237.7058
V Predictions Std            348.92484
V Predictions Max            1604.0167
V Predictions Min            19.481888
Log Pis Mean                 0.117211856
Log Pis Std                  2.2033656
Log Pis Max                  8.282514
Log Pis Min                  -6.5414476
Policy mu Mean               0.1322005
Policy mu Std                0.94926566
Policy mu Max                3.0747097
Policy mu Min                -2.6224518
Policy log std Mean          -0.56734616
Policy log std Std           0.22143532
Policy log std Max           0.04297018
Policy log std Min           -2.4685302
Z mean eval                  0.044373903
Z variance eval              0.0037661865
total_rewards                [1570.18749997 3091.0871357  3182.11876498 1752.27259684 3108.83005906
  927.49222766 2543.00141506 3139.82712355 3123.65081617 3162.63933316]
total_rewards_mean           2560.1106972159596
total_rewards_std            792.7735135555587
total_rewards_max            3182.118764984046
total_rewards_min            927.4922276606794
Number of train steps total  700000
Number of env steps total    659848
Number of rollouts total     0
Train Time (s)               144.90379436127841
(Previous) Eval Time (s)     17.675099186133593
Sample Time (s)              6.48935034358874
Epoch Time (s)               169.06824389100075
Total Train Time (s)         28009.010626500007
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:16:29.512797 UTC | [2020_01_10_09_29_40] Iteration #174 | Epoch Duration: 169.154070854187
2020-01-10 17:16:29.512931 UTC | [2020_01_10_09_29_40] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04395136
Z variance train             0.0037558272
KL Divergence                12.751817
KL Loss                      1.2751817
QF Loss                      447.15735
VF Loss                      314.6359
Policy Loss                  -1274.0199
Q Predictions Mean           1258.6506
Q Predictions Std            345.41766
Q Predictions Max            1605.1141
Q Predictions Min            10.885731
V Predictions Mean           1274.89
V Predictions Std            327.00198
V Predictions Max            1609.9791
V Predictions Min            -43.876827
Log Pis Mean                 0.021479499
Log Pis Std                  2.4652083
Log Pis Max                  16.179855
Log Pis Min                  -5.264451
Policy mu Mean               0.05544508
Policy mu Std                0.9434496
Policy mu Max                3.5931587
Policy mu Min                -2.8473365
Policy log std Mean          -0.59669685
Policy log std Std           0.22054325
Policy log std Max           0.16561705
Policy log std Min           -2.3156781
Z mean eval                  0.022221504
Z variance eval              0.006859026
total_rewards                [3155.10294957 3129.74745103 1770.71837508 3122.15747374  951.10616243
 3151.78966853 3111.24616003 1119.31736602 3194.19673925  875.10684294]
total_rewards_mean           2358.04891886253
total_rewards_std            988.3909865767911
total_rewards_max            3194.196739252055
total_rewards_min            875.1068429407428
Number of train steps total  704000
Number of env steps total    664452
Number of rollouts total     0
Train Time (s)               144.3848520340398
(Previous) Eval Time (s)     13.746754650957882
Sample Time (s)              6.408052791375667
Epoch Time (s)               164.53965947637334
Total Train Time (s)         28173.634522552136
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:19:14.138722 UTC | [2020_01_10_09_29_40] Iteration #175 | Epoch Duration: 164.62568950653076
2020-01-10 17:19:14.138884 UTC | [2020_01_10_09_29_40] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021193333
Z variance train             0.006876125
KL Divergence                11.84734
KL Loss                      1.184734
QF Loss                      182.66388
VF Loss                      71.69857
Policy Loss                  -1287.0804
Q Predictions Mean           1285.3046
Q Predictions Std            286.09015
Q Predictions Max            1585.0438
Q Predictions Min            129.6353
V Predictions Mean           1284.5012
V Predictions Std            280.25357
V Predictions Max            1582.0093
V Predictions Min            153.4774
Log Pis Mean                 0.28447205
Log Pis Std                  2.1059086
Log Pis Max                  9.648769
Log Pis Min                  -3.9372861
Policy mu Mean               -0.04322198
Policy mu Std                0.9928618
Policy mu Max                2.0523756
Policy mu Min                -2.862264
Policy log std Mean          -0.57800865
Policy log std Std           0.20070261
Policy log std Max           0.33397692
Policy log std Min           -1.2736204
Z mean eval                  0.059562445
Z variance eval              0.0085864635
total_rewards                [ 893.87368835  952.41631728 1068.62008007 3225.86095542 3259.60934914
 3224.06270339 3215.36597972 1172.95757416 1570.94922925 3218.08464912]
total_rewards_mean           2180.1800525900617
total_rewards_std            1062.0911327553522
total_rewards_max            3259.6093491405686
total_rewards_min            893.8736883457032
Number of train steps total  708000
Number of env steps total    668879
Number of rollouts total     0
Train Time (s)               142.36749459104612
(Previous) Eval Time (s)     14.608571792021394
Sample Time (s)              6.655071299523115
Epoch Time (s)               163.63113768259063
Total Train Time (s)         28337.346741414163
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:21:57.857228 UTC | [2020_01_10_09_29_40] Iteration #176 | Epoch Duration: 163.71817684173584
2020-01-10 17:21:57.857544 UTC | [2020_01_10_09_29_40] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06089116
Z variance train             0.008631447
KL Divergence                10.647153
KL Loss                      1.0647153
QF Loss                      152.81923
VF Loss                      96.792595
Policy Loss                  -1287.1454
Q Predictions Mean           1287.6525
Q Predictions Std            335.30685
Q Predictions Max            1602.8109
Q Predictions Min            32.600845
V Predictions Mean           1292.4619
V Predictions Std            333.32883
V Predictions Max            1601.93
V Predictions Min            37.744675
Log Pis Mean                 -0.049242433
Log Pis Std                  2.074936
Log Pis Max                  8.946439
Log Pis Min                  -3.9799676
Policy mu Mean               0.107630886
Policy mu Std                0.8898932
Policy mu Max                2.721415
Policy mu Min                -3.001665
Policy log std Mean          -0.56421274
Policy log std Std           0.18438715
Policy log std Max           0.07725054
Policy log std Min           -1.2232602
Z mean eval                  0.09907478
Z variance eval              0.0038092528
total_rewards                [3166.08908945 3276.73167931 3122.15494704 3148.67330132 3201.11161948
  373.41817917  605.60647536 3180.42459987 1982.13723236 3201.739326  ]
total_rewards_mean           2525.808644936439
total_rewards_std            1080.4819239063806
total_rewards_max            3276.731679310996
total_rewards_min            373.41817917431916
Number of train steps total  712000
Number of env steps total    673281
Number of rollouts total     0
Train Time (s)               143.82777545927092
(Previous) Eval Time (s)     14.61166361020878
Sample Time (s)              6.53303485782817
Epoch Time (s)               164.97247392730787
Total Train Time (s)         28502.400967724156
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:24:42.912140 UTC | [2020_01_10_09_29_40] Iteration #177 | Epoch Duration: 165.0543713569641
2020-01-10 17:24:42.912304 UTC | [2020_01_10_09_29_40] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09772144
Z variance train             0.003816376
KL Divergence                12.520204
KL Loss                      1.2520204
QF Loss                      169.3532
VF Loss                      53.277576
Policy Loss                  -1284.1748
Q Predictions Mean           1281.674
Q Predictions Std            319.4828
Q Predictions Max            1601.165
Q Predictions Min            42.981537
V Predictions Mean           1282.5433
V Predictions Std            319.06326
V Predictions Max            1611.133
V Predictions Min            45.96824
Log Pis Mean                 0.006156996
Log Pis Std                  2.1038184
Log Pis Max                  9.516181
Log Pis Min                  -6.9820538
Policy mu Mean               0.032935172
Policy mu Std                0.91374964
Policy mu Max                3.1387012
Policy mu Min                -2.6805398
Policy log std Mean          -0.5813094
Policy log std Std           0.21432884
Policy log std Max           0.02427566
Policy log std Min           -3.025529
Z mean eval                  0.038182985
Z variance eval              0.004728474
total_rewards                [ 969.93672894 3018.70832598 1802.69905827  991.52686695  846.78571474
 1000.52277142 1677.78461207  856.3969464   954.76577582  851.470391  ]
total_rewards_mean           1297.0597191586742
total_rewards_std            660.7295814451819
total_rewards_max            3018.7083259821725
total_rewards_min            846.7857147403207
Number of train steps total  716000
Number of env steps total    677913
Number of rollouts total     0
Train Time (s)               145.27605503890663
(Previous) Eval Time (s)     8.559239314869046
Sample Time (s)              6.703155332710594
Epoch Time (s)               160.53844968648627
Total Train Time (s)         28663.01877433108
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:27:23.532007 UTC | [2020_01_10_09_29_40] Iteration #178 | Epoch Duration: 160.61958479881287
2020-01-10 17:27:23.532148 UTC | [2020_01_10_09_29_40] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036378086
Z variance train             0.004716305
KL Divergence                12.649914
KL Loss                      1.2649914
QF Loss                      232.62375
VF Loss                      120.572845
Policy Loss                  -1277.3462
Q Predictions Mean           1275.7622
Q Predictions Std            319.81067
Q Predictions Max            1613.4829
Q Predictions Min            110.00347
V Predictions Mean           1276.7585
V Predictions Std            313.32654
V Predictions Max            1603.9094
V Predictions Min            123.55853
Log Pis Mean                 0.30513036
Log Pis Std                  2.213452
Log Pis Max                  8.124941
Log Pis Min                  -6.74895
Policy mu Mean               0.0864073
Policy mu Std                0.9832499
Policy mu Max                2.9044068
Policy mu Min                -2.7492216
Policy log std Mean          -0.5904886
Policy log std Std           0.20281251
Policy log std Max           0.13388908
Policy log std Min           -2.4627023
Z mean eval                  0.024970658
Z variance eval              0.006166036
total_rewards                [ 736.12699649  370.85585903  850.94510897  356.45976509 3189.20954092
  603.26594219  601.88843374 3177.46736985 3198.4560458  3214.8182526 ]
total_rewards_mean           1629.9493314678577
total_rewards_std            1285.3782818454442
total_rewards_max            3214.8182526047076
total_rewards_min            356.4597650937868
Number of train steps total  720000
Number of env steps total    682256
Number of rollouts total     0
Train Time (s)               145.14250813564286
(Previous) Eval Time (s)     12.012478093151003
Sample Time (s)              6.408906261436641
Epoch Time (s)               163.5638924902305
Total Train Time (s)         28826.66225832142
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:30:07.177621 UTC | [2020_01_10_09_29_40] Iteration #179 | Epoch Duration: 163.64538145065308
2020-01-10 17:30:07.177747 UTC | [2020_01_10_09_29_40] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024723819
Z variance train             0.006170024
KL Divergence                10.352055
KL Loss                      1.0352055
QF Loss                      151.40166
VF Loss                      57.108486
Policy Loss                  -1277.7013
Q Predictions Mean           1274.6958
Q Predictions Std            331.0396
Q Predictions Max            1628.0035
Q Predictions Min            -18.152748
V Predictions Mean           1280.8588
V Predictions Std            327.83984
V Predictions Max            1629.7775
V Predictions Min            -36.25122
Log Pis Mean                 0.12636808
Log Pis Std                  2.1328483
Log Pis Max                  6.559251
Log Pis Min                  -5.119302
Policy mu Mean               0.14919938
Policy mu Std                0.9784504
Policy mu Max                2.5120425
Policy mu Min                -2.5424914
Policy log std Mean          -0.5808698
Policy log std Std           0.20422289
Policy log std Max           0.09709412
Policy log std Min           -1.5337427
Z mean eval                  0.020416727
Z variance eval              0.004818017
total_rewards                [2972.63037383 3284.38633895 1101.07246721 1715.23554079  758.22174063
  947.22662236 3171.55239973 2177.78294322 2779.604251    899.56917382]
total_rewards_mean           1980.728185154152
total_rewards_std            967.1775023982444
total_rewards_max            3284.3863389493013
total_rewards_min            758.221740629552
Number of train steps total  724000
Number of env steps total    687140
Number of rollouts total     0
Train Time (s)               145.62137892097235
(Previous) Eval Time (s)     14.030562151223421
Sample Time (s)              7.534186585340649
Epoch Time (s)               167.18612765753642
Total Train Time (s)         28993.970473417547
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:32:54.487476 UTC | [2020_01_10_09_29_40] Iteration #180 | Epoch Duration: 167.30963802337646
2020-01-10 17:32:54.487611 UTC | [2020_01_10_09_29_40] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020036831
Z variance train             0.0048177093
KL Divergence                11.044792
KL Loss                      1.1044792
QF Loss                      150.634
VF Loss                      50.9509
Policy Loss                  -1280.2723
Q Predictions Mean           1278.5369
Q Predictions Std            336.84705
Q Predictions Max            1657.4622
Q Predictions Min            74.78623
V Predictions Mean           1281.3794
V Predictions Std            332.18863
V Predictions Max            1650.7603
V Predictions Min            84.89113
Log Pis Mean                 0.38988364
Log Pis Std                  2.3746417
Log Pis Max                  14.790676
Log Pis Min                  -6.7545376
Policy mu Mean               0.06485217
Policy mu Std                1.0174735
Policy mu Max                3.9247937
Policy mu Min                -2.486628
Policy log std Mean          -0.5815488
Policy log std Std           0.20080543
Policy log std Max           0.14807397
Policy log std Min           -1.536454
Z mean eval                  0.07715993
Z variance eval              0.0046932865
total_rewards                [ 772.55207858  389.34757193  369.8223162  2189.87032915 1654.40156037
  368.64696783  889.52081858  374.64834584 3270.260499    364.64105534]
total_rewards_mean           1064.3711542821693
total_rewards_std            947.8391171193673
total_rewards_max            3270.260499003664
total_rewards_min            364.64105534149076
Number of train steps total  728000
Number of env steps total    691683
Number of rollouts total     0
Train Time (s)               145.20045571634546
(Previous) Eval Time (s)     7.405331791844219
Sample Time (s)              6.453882787376642
Epoch Time (s)               159.05967029556632
Total Train Time (s)         29153.11179715488
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:35:33.630550 UTC | [2020_01_10_09_29_40] Iteration #181 | Epoch Duration: 159.14284777641296
2020-01-10 17:35:33.630687 UTC | [2020_01_10_09_29_40] Iteration #181 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07751651
Z variance train             0.004684051
KL Divergence                11.536064
KL Loss                      1.1536064
QF Loss                      89.21135
VF Loss                      40.45974
Policy Loss                  -1272.8202
Q Predictions Mean           1267.6923
Q Predictions Std            325.85632
Q Predictions Max            1595.8033
Q Predictions Min            32.732624
V Predictions Mean           1270.3357
V Predictions Std            324.55966
V Predictions Max            1588.1849
V Predictions Min            34.46481
Log Pis Mean                 -0.098882616
Log Pis Std                  1.9554186
Log Pis Max                  7.0395207
Log Pis Min                  -4.783948
Policy mu Mean               0.09186476
Policy mu Std                0.87277544
Policy mu Max                2.2283154
Policy mu Min                -2.5248003
Policy log std Mean          -0.5415259
Policy log std Std           0.19929793
Policy log std Max           0.08349526
Policy log std Min           -1.284357
Z mean eval                  0.08951014
Z variance eval              0.004956956
total_rewards                [ 831.61716296 1101.09021687  744.81083623  887.69594614  775.3982501
 2480.94407293  954.56197608  748.54824472 2499.37401556 3281.50488198]
total_rewards_mean           1430.5545603568482
total_rewards_std            895.8155102828274
total_rewards_max            3281.504881982517
total_rewards_min            744.8108362286522
Number of train steps total  732000
Number of env steps total    696451
Number of rollouts total     0
Train Time (s)               145.48398293927312
(Previous) Eval Time (s)     8.217823390848935
Sample Time (s)              6.777320879511535
Epoch Time (s)               160.4791272096336
Total Train Time (s)         29313.672186239623
Epoch                        182
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:38:14.193489 UTC | [2020_01_10_09_29_40] Iteration #182 | Epoch Duration: 160.56269454956055
2020-01-10 17:38:14.193653 UTC | [2020_01_10_09_29_40] Iteration #182 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.089454316
Z variance train             0.004952249
KL Divergence                11.37763
KL Loss                      1.137763
QF Loss                      1000.4007
VF Loss                      41.1954
Policy Loss                  -1305.8857
Q Predictions Mean           1302.4973
Q Predictions Std            318.86163
Q Predictions Max            1627.4955
Q Predictions Min            9.327727
V Predictions Mean           1306.2622
V Predictions Std            308.517
V Predictions Max            1629.4253
V Predictions Min            2.2223773
Log Pis Mean                 0.34793052
Log Pis Std                  2.0921257
Log Pis Max                  11.183915
Log Pis Min                  -5.3138456
Policy mu Mean               0.13253851
Policy mu Std                0.9976349
Policy mu Max                3.594319
Policy mu Min                -2.7764442
Policy log std Mean          -0.57620084
Policy log std Std           0.18421507
Policy log std Max           -0.013283312
Policy log std Min           -1.400765
Z mean eval                  0.10244645
Z variance eval              0.007451144
total_rewards                [ 705.480666    635.29800328  689.98544409  765.9342409   663.8345208
  702.71302601 1091.12491619  622.03441073  629.27728726  626.44447556]
total_rewards_mean           713.2126990824106
total_rewards_std            133.30528879477345
total_rewards_max            1091.1249161924604
total_rewards_min            622.0344107263543
Number of train steps total  736000
Number of env steps total    701088
Number of rollouts total     0
Train Time (s)               141.7693248433061
(Previous) Eval Time (s)     4.794777508359402
Sample Time (s)              6.989180805627257
Epoch Time (s)               153.55328315729275
Total Train Time (s)         29467.31644552294
Epoch                        183
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:40:47.839243 UTC | [2020_01_10_09_29_40] Iteration #183 | Epoch Duration: 153.6454679965973
2020-01-10 17:40:47.839382 UTC | [2020_01_10_09_29_40] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10138629
Z variance train             0.007457927
KL Divergence                10.562723
KL Loss                      1.0562724
QF Loss                      116.77956
VF Loss                      106.52831
Policy Loss                  -1281.2332
Q Predictions Mean           1275.3628
Q Predictions Std            352.84302
Q Predictions Max            1596.1115
Q Predictions Min            -4.9205003
V Predictions Mean           1282.0947
V Predictions Std            342.6935
V Predictions Max            1601.4653
V Predictions Min            20.004469
Log Pis Mean                 0.06102769
Log Pis Std                  2.2392826
Log Pis Max                  14.6798725
Log Pis Min                  -4.960403
Policy mu Mean               0.10883024
Policy mu Std                0.9129922
Policy mu Max                4.1429553
Policy mu Min                -2.529568
Policy log std Mean          -0.5793769
Policy log std Std           0.20605999
Policy log std Max           0.12222093
Policy log std Min           -1.9239807
Z mean eval                  0.02698782
Z variance eval              0.00397385
total_rewards                [3166.75333306  951.085906   3232.01070589 3254.21443855  874.34284464
 3262.43816782 3190.91970726 3212.55772376 3265.24014366 3252.59308952]
total_rewards_mean           2766.2156060150664
total_rewards_std            927.4069773114065
total_rewards_max            3265.240143656621
total_rewards_min            874.3428446437736
Number of train steps total  740000
Number of env steps total    705672
Number of rollouts total     0
Train Time (s)               145.2975239250809
(Previous) Eval Time (s)     18.669935828074813
Sample Time (s)              6.427890939172357
Epoch Time (s)               170.39535069232807
Total Train Time (s)         29637.792573641054
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:43:38.321968 UTC | [2020_01_10_09_29_40] Iteration #184 | Epoch Duration: 170.4824402332306
2020-01-10 17:43:38.322309 UTC | [2020_01_10_09_29_40] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026782528
Z variance train             0.003951844
KL Divergence                12.056651
KL Loss                      1.2056651
QF Loss                      528.0326
VF Loss                      239.74248
Policy Loss                  -1294.5145
Q Predictions Mean           1299.1971
Q Predictions Std            311.42023
Q Predictions Max            1619.7617
Q Predictions Min            17.841234
V Predictions Mean           1295.075
V Predictions Std            311.81857
V Predictions Max            1623.618
V Predictions Min            11.636156
Log Pis Mean                 0.10373132
Log Pis Std                  2.2767527
Log Pis Max                  13.247211
Log Pis Min                  -5.3688474
Policy mu Mean               -0.014295415
Policy mu Std                0.964255
Policy mu Max                3.1638787
Policy mu Min                -4.0408316
Policy log std Mean          -0.56602836
Policy log std Std           0.1922348
Policy log std Max           0.15478349
Policy log std Min           -1.1862472
Z mean eval                  0.09137223
Z variance eval              0.0035107355
total_rewards                [ 821.7433576   978.17598631 3177.64511808 1161.3886625  3127.62635412
  906.17123793 2033.40370885 2165.56694008 2425.26988247 3172.52819028]
total_rewards_mean           1996.9519438213115
total_rewards_std            925.9937757872384
total_rewards_max            3177.6451180840018
total_rewards_min            821.743357603257
Number of train steps total  744000
Number of env steps total    710207
Number of rollouts total     0
Train Time (s)               143.1591117652133
(Previous) Eval Time (s)     11.662670127116144
Sample Time (s)              6.696525224018842
Epoch Time (s)               161.5183071163483
Total Train Time (s)         29799.38590420643
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:46:19.915089 UTC | [2020_01_10_09_29_40] Iteration #185 | Epoch Duration: 161.5925726890564
2020-01-10 17:46:19.915223 UTC | [2020_01_10_09_29_40] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0905285
Z variance train             0.0035110482
KL Divergence                11.8235445
KL Loss                      1.1823545
QF Loss                      1058.5447
VF Loss                      318.93542
Policy Loss                  -1289.1027
Q Predictions Mean           1287.9517
Q Predictions Std            299.76804
Q Predictions Max            1636.6476
Q Predictions Min            76.364105
V Predictions Mean           1285.4921
V Predictions Std            297.1721
V Predictions Max            1635.2819
V Predictions Min            76.62645
Log Pis Mean                 0.043019623
Log Pis Std                  2.1004016
Log Pis Max                  9.891422
Log Pis Min                  -4.9489126
Policy mu Mean               0.20910911
Policy mu Std                0.9259704
Policy mu Max                3.8242488
Policy mu Min                -2.6141353
Policy log std Mean          -0.57762295
Policy log std Std           0.20044701
Policy log std Max           0.03756267
Policy log std Min           -1.6330446
Z mean eval                  0.07709013
Z variance eval              0.005636538
total_rewards                [3300.41010651 3343.77907227 3299.01757512 1066.08655129 3274.26761444
 1012.77317479 1073.87382424 1000.03736372 1006.69654989  900.66655958]
total_rewards_mean           1927.760839184609
total_rewards_std            1124.964894963227
total_rewards_max            3343.7790722678797
total_rewards_min            900.6665595842603
Number of train steps total  748000
Number of env steps total    714744
Number of rollouts total     0
Train Time (s)               143.75701502896845
(Previous) Eval Time (s)     10.901911618653685
Sample Time (s)              5.562880062032491
Epoch Time (s)               160.22180670965463
Total Train Time (s)         29959.68378167553
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:49:00.215274 UTC | [2020_01_10_09_29_40] Iteration #186 | Epoch Duration: 160.29995918273926
2020-01-10 17:49:00.215394 UTC | [2020_01_10_09_29_40] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07777238
Z variance train             0.0056274445
KL Divergence                10.816551
KL Loss                      1.0816551
QF Loss                      298.5968
VF Loss                      72.893105
Policy Loss                  -1282.5771
Q Predictions Mean           1276.147
Q Predictions Std            328.4175
Q Predictions Max            1612.5171
Q Predictions Min            3.8133106
V Predictions Mean           1287.9845
V Predictions Std            319.07587
V Predictions Max            1621.1586
V Predictions Min            12.417504
Log Pis Mean                 0.11246522
Log Pis Std                  2.024911
Log Pis Max                  8.57929
Log Pis Min                  -5.6654515
Policy mu Mean               0.15730567
Policy mu Std                0.907882
Policy mu Max                2.660326
Policy mu Min                -2.6377556
Policy log std Mean          -0.5868905
Policy log std Std           0.19648737
Policy log std Max           0.09581339
Policy log std Min           -1.4298567
Z mean eval                  0.043825537
Z variance eval              0.0056002024
total_rewards                [ 843.48967077  944.93955372 3247.31224764  762.21470306 1637.91889375
  740.94410024 2855.75139933 1698.51319724 1756.50516562 1404.67864471]
total_rewards_mean           1589.2267576081108
total_rewards_std            824.8908346584001
total_rewards_max            3247.3122476386898
total_rewards_min            740.9441002407199
Number of train steps total  752000
Number of env steps total    719284
Number of rollouts total     0
Train Time (s)               144.23796594934538
(Previous) Eval Time (s)     10.71881366102025
Sample Time (s)              5.537955156061798
Epoch Time (s)               160.49473476642743
Total Train Time (s)         30120.263174747117
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:51:40.800142 UTC | [2020_01_10_09_29_40] Iteration #187 | Epoch Duration: 160.58461332321167
2020-01-10 17:51:40.800340 UTC | [2020_01_10_09_29_40] Iteration #187 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042699642
Z variance train             0.0056141973
KL Divergence                10.830875
KL Loss                      1.0830876
QF Loss                      443.5335
VF Loss                      386.27502
Policy Loss                  -1247.7672
Q Predictions Mean           1244.5994
Q Predictions Std            380.74792
Q Predictions Max            1617.6884
Q Predictions Min            19.868961
V Predictions Mean           1253.5027
V Predictions Std            372.94376
V Predictions Max            1624.5808
V Predictions Min            29.43179
Log Pis Mean                 0.20590793
Log Pis Std                  2.056408
Log Pis Max                  7.3531194
Log Pis Min                  -5.0346346
Policy mu Mean               0.19931097
Policy mu Std                0.9597417
Policy mu Max                3.4153583
Policy mu Min                -2.697424
Policy log std Mean          -0.6027687
Policy log std Std           0.22792803
Policy log std Max           0.05183196
Policy log std Min           -3.3309026
Z mean eval                  0.0633855
Z variance eval              0.0060483045
total_rewards                [ 771.18448377  888.00219703 2385.05829906  813.96361581 1149.0183036
 1294.84847803 1221.2557554  1023.8710207  1319.36947231 1046.67561532]
total_rewards_mean           1191.3247241034999
total_rewards_std            437.5712585935641
total_rewards_max            2385.0582990552125
total_rewards_min            771.1844837673243
Number of train steps total  756000
Number of env steps total    723794
Number of rollouts total     0
Train Time (s)               144.5579221881926
(Previous) Eval Time (s)     6.645839177072048
Sample Time (s)              6.521762639284134
Epoch Time (s)               157.7255240045488
Total Train Time (s)         30278.074912648648
Epoch                        188
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:54:18.614543 UTC | [2020_01_10_09_29_40] Iteration #188 | Epoch Duration: 157.81405329704285
2020-01-10 17:54:18.614752 UTC | [2020_01_10_09_29_40] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06311596
Z variance train             0.006051179
KL Divergence                10.517588
KL Loss                      1.0517588
QF Loss                      151.48798
VF Loss                      50.016693
Policy Loss                  -1288.2466
Q Predictions Mean           1286.1445
Q Predictions Std            344.24185
Q Predictions Max            1660.4016
Q Predictions Min            52.228985
V Predictions Mean           1288.1426
V Predictions Std            339.98404
V Predictions Max            1653.4142
V Predictions Min            64.38376
Log Pis Mean                 0.08322735
Log Pis Std                  1.9327751
Log Pis Max                  7.5859747
Log Pis Min                  -4.6211395
Policy mu Mean               0.07129575
Policy mu Std                0.9247988
Policy mu Max                2.4385073
Policy mu Min                -3.636505
Policy log std Mean          -0.5700729
Policy log std Std           0.19984739
Policy log std Max           0.11455226
Policy log std Min           -1.3229856
Z mean eval                  0.06657539
Z variance eval              0.002869314
total_rewards                [3096.43745639 2428.3671243   755.21964485 3157.33402488  773.27782071
  728.67885813  883.47552705 3149.36534698 3220.36150477 1067.94528968]
total_rewards_mean           1926.0462597755627
total_rewards_std            1107.5496668551734
total_rewards_max            3220.36150477037
total_rewards_min            728.6788581320886
Number of train steps total  760000
Number of env steps total    728353
Number of rollouts total     0
Train Time (s)               142.8653847319074
(Previous) Eval Time (s)     10.993584804236889
Sample Time (s)              6.298497023060918
Epoch Time (s)               160.1574665592052
Total Train Time (s)         30438.32015350461
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:56:58.862306 UTC | [2020_01_10_09_29_40] Iteration #189 | Epoch Duration: 160.24738693237305
2020-01-10 17:56:58.862535 UTC | [2020_01_10_09_29_40] Iteration #189 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06586822
Z variance train             0.0028713837
KL Divergence                12.582037
KL Loss                      1.2582037
QF Loss                      1870.2665
VF Loss                      40.310867
Policy Loss                  -1274.9609
Q Predictions Mean           1270.0934
Q Predictions Std            366.0647
Q Predictions Max            1611.857
Q Predictions Min            -6.27571
V Predictions Mean           1275.4326
V Predictions Std            358.82068
V Predictions Max            1609.7347
V Predictions Min            8.13104
Log Pis Mean                 0.10059659
Log Pis Std                  2.0997605
Log Pis Max                  9.189744
Log Pis Min                  -4.215614
Policy mu Mean               0.082591586
Policy mu Std                0.9314465
Policy mu Max                3.0991871
Policy mu Min                -3.6446493
Policy log std Mean          -0.58197266
Policy log std Std           0.24749559
Policy log std Max           0.20342267
Policy log std Min           -3.4316168
Z mean eval                  0.04844721
Z variance eval              0.005980869
total_rewards                [1037.23666212 3217.95835781 3245.61511502 3220.11137634  762.8330715
 3201.32175461 3232.14330449  937.28669701  944.7103197   929.50451791]
total_rewards_mean           2072.8721176510394
total_rewards_std            1152.3172600027112
total_rewards_max            3245.6151150244414
total_rewards_min            762.8330714990373
Number of train steps total  764000
Number of env steps total    732961
Number of rollouts total     0
Train Time (s)               145.3693723534234
(Previous) Eval Time (s)     11.918511467985809
Sample Time (s)              5.666234638076276
Epoch Time (s)               162.95411845948547
Total Train Time (s)         30601.362999395467
Epoch                        190
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:59:41.905697 UTC | [2020_01_10_09_29_40] Iteration #190 | Epoch Duration: 163.04300379753113
2020-01-10 17:59:41.905816 UTC | [2020_01_10_09_29_40] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048077714
Z variance train             0.005988501
KL Divergence                10.369534
KL Loss                      1.0369533
QF Loss                      146.9851
VF Loss                      81.607025
Policy Loss                  -1264.7057
Q Predictions Mean           1265.6394
Q Predictions Std            370.48895
Q Predictions Max            1644.865
Q Predictions Min            -28.577353
V Predictions Mean           1261.5715
V Predictions Std            372.15692
V Predictions Max            1641.6458
V Predictions Min            -38.89797
Log Pis Mean                 0.14876097
Log Pis Std                  2.2533376
Log Pis Max                  13.2001915
Log Pis Min                  -3.9669962
Policy mu Mean               0.050195407
Policy mu Std                0.96303296
Policy mu Max                2.4593916
Policy mu Min                -4.2734346
Policy log std Mean          -0.5837149
Policy log std Std           0.212298
Policy log std Max           0.020584822
Policy log std Min           -2.2685072
Z mean eval                  0.08541342
Z variance eval              0.008221755
total_rewards                [1179.39603701  861.91799772 1701.6146347  3241.99323812 1077.63908551
  767.96037495 3292.19360533 1920.76632035 3230.46442386 3242.77339785]
total_rewards_mean           2051.671911539942
total_rewards_std            1033.2833432345715
total_rewards_max            3292.1936053291615
total_rewards_min            767.9603749466
Number of train steps total  768000
Number of env steps total    737540
Number of rollouts total     0
Train Time (s)               143.7864194153808
(Previous) Eval Time (s)     11.682195168919861
Sample Time (s)              5.557502947747707
Epoch Time (s)               161.02611753204837
Total Train Time (s)         30762.465786602814
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:02:23.010823 UTC | [2020_01_10_09_29_40] Iteration #191 | Epoch Duration: 161.10490322113037
2020-01-10 18:02:23.010984 UTC | [2020_01_10_09_29_40] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.085586704
Z variance train             0.008215332
KL Divergence                10.122871
KL Loss                      1.0122871
QF Loss                      138.14775
VF Loss                      44.66252
Policy Loss                  -1275.1328
Q Predictions Mean           1271.2036
Q Predictions Std            347.5798
Q Predictions Max            1595.7124
Q Predictions Min            -11.717033
V Predictions Mean           1276.4692
V Predictions Std            335.28784
V Predictions Max            1595.6708
V Predictions Min            42.234463
Log Pis Mean                 0.21517727
Log Pis Std                  2.2887154
Log Pis Max                  10.391634
Log Pis Min                  -6.083946
Policy mu Mean               0.11723425
Policy mu Std                0.9471629
Policy mu Max                2.9109242
Policy mu Min                -2.6386924
Policy log std Mean          -0.5783366
Policy log std Std           0.2139125
Policy log std Max           0.112555206
Policy log std Min           -2.926939
Z mean eval                  0.029569248
Z variance eval              0.008670557
total_rewards                [1153.58059869 3168.87859473 3241.43100519  760.67617848  762.56468353
 3214.57952833  817.247725   1074.51171684 1175.83202225 2948.71460862]
total_rewards_mean           1831.8016661655383
total_rewards_std            1082.5000700150617
total_rewards_max            3241.431005186439
total_rewards_min            760.6761784822677
Number of train steps total  772000
Number of env steps total    742080
Number of rollouts total     0
Train Time (s)               144.56483936822042
(Previous) Eval Time (s)     12.39764330489561
Sample Time (s)              6.68800903018564
Epoch Time (s)               163.65049170330167
Total Train Time (s)         30926.195928645786
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:05:06.743054 UTC | [2020_01_10_09_29_40] Iteration #192 | Epoch Duration: 163.73195362091064
2020-01-10 18:05:06.743189 UTC | [2020_01_10_09_29_40] Iteration #192 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030446673
Z variance train             0.00866995
KL Divergence                9.969775
KL Loss                      0.9969775
QF Loss                      196.4582
VF Loss                      245.68657
Policy Loss                  -1287.9784
Q Predictions Mean           1284.2078
Q Predictions Std            365.2002
Q Predictions Max            1639.6974
Q Predictions Min            22.52153
V Predictions Mean           1288.4053
V Predictions Std            365.8327
V Predictions Max            1648.3204
V Predictions Min            12.342684
Log Pis Mean                 -0.09266025
Log Pis Std                  1.9195207
Log Pis Max                  6.0518303
Log Pis Min                  -5.309001
Policy mu Mean               0.13523877
Policy mu Std                0.85526913
Policy mu Max                2.4978552
Policy mu Min                -2.3801253
Policy log std Mean          -0.55637866
Policy log std Std           0.20245986
Policy log std Max           0.20766258
Policy log std Min           -1.7753546
Z mean eval                  0.09323044
Z variance eval              0.007756304
total_rewards                [3179.42170199 3139.61894239 3166.60967751 3216.55204621 3216.6628174
 1151.67357921 3182.33455052 3195.04621441 3163.90045576 3193.96150284]
total_rewards_mean           2980.5781488238654
total_rewards_std            610.0486668157421
total_rewards_max            3216.662817403454
total_rewards_min            1151.6735792086392
Number of train steps total  776000
Number of env steps total    746757
Number of rollouts total     0
Train Time (s)               143.86705113900825
(Previous) Eval Time (s)     17.326241848059
Sample Time (s)              6.55270167067647
Epoch Time (s)               167.74599465774372
Total Train Time (s)         31094.03495377768
Epoch                        193
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:07:54.583418 UTC | [2020_01_10_09_29_40] Iteration #193 | Epoch Duration: 167.8401336669922
2020-01-10 18:07:54.583542 UTC | [2020_01_10_09_29_40] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.092905395
Z variance train             0.007762919
KL Divergence                10.399681
KL Loss                      1.0399681
QF Loss                      251.68886
VF Loss                      35.516796
Policy Loss                  -1306.8589
Q Predictions Mean           1302.3488
Q Predictions Std            325.7094
Q Predictions Max            1629.4615
Q Predictions Min            -55.435486
V Predictions Mean           1308.6001
V Predictions Std            321.14304
V Predictions Max            1633.0173
V Predictions Min            -20.202335
Log Pis Mean                 0.087127164
Log Pis Std                  2.2116032
Log Pis Max                  10.847641
Log Pis Min                  -5.3564672
Policy mu Mean               0.12858744
Policy mu Std                0.9241904
Policy mu Max                3.2384245
Policy mu Min                -2.6301522
Policy log std Mean          -0.55916363
Policy log std Std           0.20182844
Policy log std Max           0.21825808
Policy log std Min           -1.7543116
Z mean eval                  0.07609315
Z variance eval              0.008152107
total_rewards                [1156.6326481  3188.05670753 1112.50811491 3133.17987769 3164.99409619
 3036.61325517 3217.56934435 1847.44576685 3177.99576521 1111.752286  ]
total_rewards_mean           2414.6747861993986
total_rewards_std            926.7749532829854
total_rewards_max            3217.5693443461473
total_rewards_min            1111.752285996763
Number of train steps total  780000
Number of env steps total    751298
Number of rollouts total     0
Train Time (s)               145.4311740458943
(Previous) Eval Time (s)     16.630092098843306
Sample Time (s)              5.806697795633227
Epoch Time (s)               167.86796394037083
Total Train Time (s)         31261.985349350143
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:10:42.537094 UTC | [2020_01_10_09_29_40] Iteration #194 | Epoch Duration: 167.95346069335938
2020-01-10 18:10:42.537228 UTC | [2020_01_10_09_29_40] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07291565
Z variance train             0.008146848
KL Divergence                11.15363
KL Loss                      1.115363
QF Loss                      189.42596
VF Loss                      78.37667
Policy Loss                  -1248.8817
Q Predictions Mean           1246.5758
Q Predictions Std            329.79852
Q Predictions Max            1593.3127
Q Predictions Min            22.125889
V Predictions Mean           1248.3752
V Predictions Std            329.39996
V Predictions Max            1595.6781
V Predictions Min            17.70741
Log Pis Mean                 0.07315857
Log Pis Std                  2.1264768
Log Pis Max                  8.46609
Log Pis Min                  -7.14727
Policy mu Mean               0.15105203
Policy mu Std                0.9710278
Policy mu Max                3.4550433
Policy mu Min                -2.7695122
Policy log std Mean          -0.5878535
Policy log std Std           0.20049596
Policy log std Max           0.030000865
Policy log std Min           -2.0315166
Z mean eval                  0.03605693
Z variance eval              0.0068910373
total_rewards                [3212.25294149 3231.61063908 1023.00162465 3213.31501634 3205.31295395
 3256.01148307 3225.03292944 3255.62968391 3223.06751699 3238.74557341]
total_rewards_mean           3008.398036233758
total_rewards_std            662.0011790483171
total_rewards_max            3256.0114830744774
total_rewards_min            1023.001624653065
Number of train steps total  784000
Number of env steps total    755904
Number of rollouts total     0
Train Time (s)               144.18897329922765
(Previous) Eval Time (s)     17.512206577695906
Sample Time (s)              6.659406214486808
Epoch Time (s)               168.36058609141037
Total Train Time (s)         31430.425436523277
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:13:30.984313 UTC | [2020_01_10_09_29_40] Iteration #195 | Epoch Duration: 168.44693422317505
2020-01-10 18:13:30.984646 UTC | [2020_01_10_09_29_40] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03635315
Z variance train             0.006884503
KL Divergence                10.638661
KL Loss                      1.0638661
QF Loss                      412.7215
VF Loss                      70.383835
Policy Loss                  -1285.4697
Q Predictions Mean           1278.8043
Q Predictions Std            362.5216
Q Predictions Max            1625.1831
Q Predictions Min            6.0934496
V Predictions Mean           1289.8677
V Predictions Std            353.26486
V Predictions Max            1626.3096
V Predictions Min            -5.79679
Log Pis Mean                 0.3714472
Log Pis Std                  2.3254974
Log Pis Max                  11.628235
Log Pis Min                  -3.72192
Policy mu Mean               -0.015830686
Policy mu Std                0.9756726
Policy mu Max                3.0998979
Policy mu Min                -2.6345198
Policy log std Mean          -0.56326634
Policy log std Std           0.21813528
Policy log std Max           0.07266337
Policy log std Min           -1.23475
Z mean eval                  0.03504938
Z variance eval              0.008736415
total_rewards                [ 958.99810296 3254.53312593 3268.0516868  1067.14957666 1162.88811253
 1009.08621006  956.082648   3274.71484582 3279.72014332 3242.86641773]
total_rewards_mean           2147.4090869801894
total_rewards_std            1117.950684149835
total_rewards_max            3279.7201433210766
total_rewards_min            956.0826479966146
Number of train steps total  788000
Number of env steps total    760324
Number of rollouts total     0
Train Time (s)               145.04459999781102
(Previous) Eval Time (s)     14.137301169801503
Sample Time (s)              6.47249562619254
Epoch Time (s)               165.65439679380506
Total Train Time (s)         31596.18257315457
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:16:16.740870 UTC | [2020_01_10_09_29_40] Iteration #196 | Epoch Duration: 165.75600814819336
2020-01-10 18:16:16.740996 UTC | [2020_01_10_09_29_40] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03530637
Z variance train             0.008716835
KL Divergence                10.004215
KL Loss                      1.0004215
QF Loss                      119.67888
VF Loss                      40.092518
Policy Loss                  -1312.2921
Q Predictions Mean           1309.189
Q Predictions Std            301.86255
Q Predictions Max            1616.6569
Q Predictions Min            32.92859
V Predictions Mean           1312.599
V Predictions Std            301.51935
V Predictions Max            1617.5635
V Predictions Min            31.456352
Log Pis Mean                 0.10184157
Log Pis Std                  2.096215
Log Pis Max                  6.6755543
Log Pis Min                  -5.1007843
Policy mu Mean               0.10093322
Policy mu Std                0.9147481
Policy mu Max                2.5519915
Policy mu Min                -2.5705693
Policy log std Mean          -0.5236053
Policy log std Std           0.22375435
Policy log std Max           0.035763025
Policy log std Min           -1.3681912
Z mean eval                  0.050088488
Z variance eval              0.00944672
total_rewards                [3201.22961246 3188.94627287 3186.64179643 3214.09680125 3217.50267135
 3204.79356309 3242.89830571 3185.64183029 3181.17845519 3206.94414421]
total_rewards_mean           3202.987345284789
total_rewards_std            17.860098066844426
total_rewards_max            3242.898305712873
total_rewards_min            3181.1784551856526
Number of train steps total  792000
Number of env steps total    764946
Number of rollouts total     0
Train Time (s)               144.9337085406296
(Previous) Eval Time (s)     18.52738198498264
Sample Time (s)              6.640123913995922
Epoch Time (s)               170.10121443960816
Total Train Time (s)         31766.36260372866
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:19:06.923845 UTC | [2020_01_10_09_29_40] Iteration #197 | Epoch Duration: 170.18274116516113
2020-01-10 18:19:06.924008 UTC | [2020_01_10_09_29_40] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04337714
Z variance train             0.009448677
KL Divergence                9.5915785
KL Loss                      0.9591579
QF Loss                      291.062
VF Loss                      183.73157
Policy Loss                  -1290.2977
Q Predictions Mean           1292.5859
Q Predictions Std            309.0229
Q Predictions Max            1631.8203
Q Predictions Min            36.811867
V Predictions Mean           1299.9534
V Predictions Std            304.12216
V Predictions Max            1639.8275
V Predictions Min            37.517555
Log Pis Mean                 0.15910232
Log Pis Std                  2.3255074
Log Pis Max                  8.912846
Log Pis Min                  -5.574088
Policy mu Mean               0.06575764
Policy mu Std                1.0056802
Policy mu Max                3.0849442
Policy mu Min                -3.4502134
Policy log std Mean          -0.5688723
Policy log std Std           0.23095354
Policy log std Max           0.29648715
Policy log std Min           -3.0991342
Z mean eval                  0.06919132
Z variance eval              0.0052668736
total_rewards                [3192.94960669 3229.01425038 3216.61113176 3185.54573168 3222.58682631
 3212.41474923 3222.93342657 3226.25268665 3187.09804419 1047.28509872]
total_rewards_mean           2994.2691552188976
total_rewards_std            649.180400844599
total_rewards_max            3229.0142503823336
total_rewards_min            1047.285098715223
Number of train steps total  796000
Number of env steps total    769469
Number of rollouts total     0
Train Time (s)               144.94217798206955
(Previous) Eval Time (s)     17.10568705620244
Sample Time (s)              6.597796460613608
Epoch Time (s)               168.6456614988856
Total Train Time (s)         31935.085761163384
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:21:55.654033 UTC | [2020_01_10_09_29_40] Iteration #198 | Epoch Duration: 168.72990703582764
2020-01-10 18:21:55.654161 UTC | [2020_01_10_09_29_40] Iteration #198 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0693336
Z variance train             0.0052703237
KL Divergence                10.876337
KL Loss                      1.0876337
QF Loss                      93.834
VF Loss                      43.860863
Policy Loss                  -1294.2484
Q Predictions Mean           1289.1909
Q Predictions Std            342.123
Q Predictions Max            1603.3988
Q Predictions Min            -9.807473
V Predictions Mean           1291.0201
V Predictions Std            332.44635
V Predictions Max            1601.9564
V Predictions Min            -1.998694
Log Pis Mean                 0.048998658
Log Pis Std                  1.9950311
Log Pis Max                  5.3981905
Log Pis Min                  -6.4131393
Policy mu Mean               -0.013198509
Policy mu Std                0.9013458
Policy mu Max                3.0388634
Policy mu Min                -2.546885
Policy log std Mean          -0.58371514
Policy log std Std           0.21119192
Policy log std Max           0.09031206
Policy log std Min           -1.3371181
Z mean eval                  0.046935193
Z variance eval              0.0075800642
total_rewards                [ 888.32994997  951.8680926  3199.32619546 3234.06237654  883.9724169
  918.14411379  873.10082212  848.36335446  845.17570424  746.7696783 ]
total_rewards_mean           1338.9112704372155
total_rewards_std            940.2980816079053
total_rewards_max            3234.0623765418054
total_rewards_min            746.7696782975476
Number of train steps total  800000
Number of env steps total    773889
Number of rollouts total     0
Train Time (s)               144.02855360973626
(Previous) Eval Time (s)     8.687566373962909
Sample Time (s)              5.530052907764912
Epoch Time (s)               158.24617289146408
Total Train Time (s)         32093.416186179034
Epoch                        199
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:24:33.981916 UTC | [2020_01_10_09_29_40] Iteration #199 | Epoch Duration: 158.32764673233032
2020-01-10 18:24:33.982099 UTC | [2020_01_10_09_29_40] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047764823
Z variance train             0.0075840307
KL Divergence                10.121093
KL Loss                      1.0121093
QF Loss                      190.59799
VF Loss                      51.562504
Policy Loss                  -1259.9796
Q Predictions Mean           1256.5426
Q Predictions Std            337.4432
Q Predictions Max            1607.7675
Q Predictions Min            18.798418
V Predictions Mean           1261.7455
V Predictions Std            335.41583
V Predictions Max            1614.5995
V Predictions Min            23.35263
Log Pis Mean                 0.25125653
Log Pis Std                  2.19568
Log Pis Max                  11.298108
Log Pis Min                  -4.7730613
Policy mu Mean               0.16767214
Policy mu Std                0.9698919
Policy mu Max                3.5163007
Policy mu Min                -2.4265354
Policy log std Mean          -0.55644566
Policy log std Std           0.1948381
Policy log std Max           0.05394852
Policy log std Min           -1.5000615
Z mean eval                  0.040819168
Z variance eval              0.007777537
total_rewards                [ 849.29870316 3138.00588624  934.29711674  754.8686922  3124.32539535
 2018.13251075 1277.22579118 2084.41434889 3113.64874607 2621.58669699]
total_rewards_mean           1991.5803887567442
total_rewards_std            934.0816268134321
total_rewards_max            3138.0058862380565
total_rewards_min            754.8686921972205
Number of train steps total  804000
Number of env steps total    778524
Number of rollouts total     0
Train Time (s)               144.77450377400964
(Previous) Eval Time (s)     11.71903023775667
Sample Time (s)              6.5176696120761335
Epoch Time (s)               163.01120362384245
Total Train Time (s)         32256.691577513702
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:27:17.260983 UTC | [2020_01_10_09_29_40] Iteration #200 | Epoch Duration: 163.2787308692932
2020-01-10 18:27:17.261249 UTC | [2020_01_10_09_29_40] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040685646
Z variance train             0.007789637
KL Divergence                10.211606
KL Loss                      1.0211606
QF Loss                      270.71805
VF Loss                      139.20395
Policy Loss                  -1256.1515
Q Predictions Mean           1256.5984
Q Predictions Std            364.38974
Q Predictions Max            1642.585
Q Predictions Min            47.05724
V Predictions Mean           1263.832
V Predictions Std            362.23642
V Predictions Max            1642.0864
V Predictions Min            53.064728
Log Pis Mean                 0.2661686
Log Pis Std                  2.073592
Log Pis Max                  8.596508
Log Pis Min                  -3.9361057
Policy mu Mean               0.041661736
Policy mu Std                1.0104793
Policy mu Max                3.09276
Policy mu Min                -2.759821
Policy log std Mean          -0.57831407
Policy log std Std           0.20668277
Policy log std Max           0.22407603
Policy log std Min           -1.2437347
Z mean eval                  0.093108974
Z variance eval              0.0036006023
total_rewards                [1105.29114969 3208.48710571  572.82788531 3237.17966994  595.84991137
 1146.35728772  925.45203964 3233.05965568 3216.80213915 3217.46331519]
total_rewards_mean           2045.877015939856
total_rewards_std            1189.352300250106
total_rewards_max            3237.1796699442507
total_rewards_min            572.8278853143571
Number of train steps total  808000
Number of env steps total    783190
Number of rollouts total     0
Train Time (s)               144.49295624624938
(Previous) Eval Time (s)     13.562054796144366
Sample Time (s)              6.359733772929758
Epoch Time (s)               164.4147448153235
Total Train Time (s)         32421.18904886581
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:30:01.758919 UTC | [2020_01_10_09_29_40] Iteration #201 | Epoch Duration: 164.49750351905823
2020-01-10 18:30:01.759039 UTC | [2020_01_10_09_29_40] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.092600726
Z variance train             0.003606775
KL Divergence                12.562573
KL Loss                      1.2562574
QF Loss                      139.7193
VF Loss                      59.34503
Policy Loss                  -1265.7832
Q Predictions Mean           1267.2161
Q Predictions Std            326.34946
Q Predictions Max            1592.596
Q Predictions Min            11.232802
V Predictions Mean           1270.2981
V Predictions Std            323.70435
V Predictions Max            1593.1615
V Predictions Min            19.2526
Log Pis Mean                 0.070225306
Log Pis Std                  2.0071664
Log Pis Max                  6.7979918
Log Pis Min                  -4.899474
Policy mu Mean               0.036624487
Policy mu Std                0.9175503
Policy mu Max                2.5083249
Policy mu Min                -2.6653621
Policy log std Mean          -0.5841178
Policy log std Std           0.20417361
Policy log std Max           0.031612575
Policy log std Min           -1.8737233
Z mean eval                  0.051006615
Z variance eval              0.0065083145
total_rewards                [3224.55943894 3195.16463691 3215.17847481  865.88602859 3173.26545307
 3237.54100663  751.59582094 3192.44856833 3199.88623437 1048.76568289]
total_rewards_mean           2510.429134549908
total_rewards_std            1063.8861964974778
total_rewards_max            3237.5410066316203
total_rewards_min            751.5958209422913
Number of train steps total  812000
Number of env steps total    788352
Number of rollouts total     0
Train Time (s)               146.06364622805268
(Previous) Eval Time (s)     14.279380204156041
Sample Time (s)              7.728417227976024
Epoch Time (s)               168.07144366018474
Total Train Time (s)         32589.338233005255
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:32:49.910042 UTC | [2020_01_10_09_29_40] Iteration #202 | Epoch Duration: 168.15089678764343
2020-01-10 18:32:49.910156 UTC | [2020_01_10_09_29_40] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04701964
Z variance train             0.006519945
KL Divergence                10.305414
KL Loss                      1.0305414
QF Loss                      281.6695
VF Loss                      118.272316
Policy Loss                  -1266.5626
Q Predictions Mean           1259.6569
Q Predictions Std            356.69543
Q Predictions Max            1618.1582
Q Predictions Min            3.3592217
V Predictions Mean           1264.9922
V Predictions Std            338.52554
V Predictions Max            1616.6471
V Predictions Min            -11.716595
Log Pis Mean                 0.09444134
Log Pis Std                  2.1566489
Log Pis Max                  13.118451
Log Pis Min                  -7.301426
Policy mu Mean               0.1335708
Policy mu Std                0.94760007
Policy mu Max                4.02748
Policy mu Min                -2.5890343
Policy log std Mean          -0.57081014
Policy log std Std           0.20956641
Policy log std Max           0.14685845
Policy log std Min           -1.9008691
Z mean eval                  0.05768631
Z variance eval              0.007947306
total_rewards                [2258.56786766 2769.48980803 3262.91431807 3231.40538909 3236.58330154
 3267.95472998 3247.68141331 3119.7075908   779.35209979 3274.87195457]
total_rewards_mean           2844.8528472843946
total_rewards_std            754.6589714602227
total_rewards_max            3274.8719545698696
total_rewards_min            779.3520997928314
Number of train steps total  816000
Number of env steps total    793103
Number of rollouts total     0
Train Time (s)               145.3865594379604
(Previous) Eval Time (s)     16.278995711822063
Sample Time (s)              5.40642376197502
Epoch Time (s)               167.07197891175747
Total Train Time (s)         32756.487260107882
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:35:37.065117 UTC | [2020_01_10_09_29_40] Iteration #203 | Epoch Duration: 167.1548249721527
2020-01-10 18:35:37.065408 UTC | [2020_01_10_09_29_40] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05823765
Z variance train             0.00793759
KL Divergence                10.01231
KL Loss                      1.0012311
QF Loss                      168.29187
VF Loss                      195.03627
Policy Loss                  -1278.6631
Q Predictions Mean           1279.7986
Q Predictions Std            344.0136
Q Predictions Max            1616.8152
Q Predictions Min            18.40777
V Predictions Mean           1284.3074
V Predictions Std            341.81696
V Predictions Max            1620.3344
V Predictions Min            17.729448
Log Pis Mean                 0.03366589
Log Pis Std                  2.1716588
Log Pis Max                  12.02526
Log Pis Min                  -5.6155505
Policy mu Mean               0.08909278
Policy mu Std                0.93254685
Policy mu Max                2.76664
Policy mu Min                -3.6314147
Policy log std Mean          -0.5582166
Policy log std Std           0.21773387
Policy log std Max           0.1479789
Policy log std Min           -3.4728842
Z mean eval                  0.07603002
Z variance eval              0.006159477
total_rewards                [3226.9223854  1182.32893507 3229.76147638 3218.58539763 3174.06938854
 1339.68246745 3233.40524117  978.02319098 3238.79359832 3229.10754671]
total_rewards_mean           2605.067962764632
total_rewards_std            945.2837656132888
total_rewards_max            3238.7935983189936
total_rewards_min            978.0231909777096
Number of train steps total  820000
Number of env steps total    797765
Number of rollouts total     0
Train Time (s)               145.3536048689857
(Previous) Eval Time (s)     14.800116741098464
Sample Time (s)              6.560112115927041
Epoch Time (s)               166.71383372601122
Total Train Time (s)         32923.279583163094
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:38:23.858990 UTC | [2020_01_10_09_29_40] Iteration #204 | Epoch Duration: 166.79336595535278
2020-01-10 18:38:23.859158 UTC | [2020_01_10_09_29_40] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.076405145
Z variance train             0.0061787385
KL Divergence                10.607445
KL Loss                      1.0607445
QF Loss                      356.29803
VF Loss                      103.679344
Policy Loss                  -1296.9849
Q Predictions Mean           1292.118
Q Predictions Std            323.21478
Q Predictions Max            1616.6467
Q Predictions Min            -6.868907
V Predictions Mean           1293.4382
V Predictions Std            318.35983
V Predictions Max            1620.2655
V Predictions Min            7.0701714
Log Pis Mean                 0.0941629
Log Pis Std                  2.3455055
Log Pis Max                  12.590005
Log Pis Min                  -6.2977605
Policy mu Mean               -0.035304446
Policy mu Std                0.94987494
Policy mu Max                4.191261
Policy mu Min                -3.151451
Policy log std Mean          -0.55816394
Policy log std Std           0.2173009
Policy log std Max           0.22030234
Policy log std Min           -1.2550771
Z mean eval                  0.059649
Z variance eval              0.006753498
total_rewards                [3110.12988001 3016.69073754 2098.06968547 3137.72243639 3163.45908174
 3193.15936334 3148.3729353  2098.72683361 2941.03244579 1277.30624303]
total_rewards_mean           2718.466964221171
total_rewards_std            626.2373865226398
total_rewards_max            3193.159363339683
total_rewards_min            1277.306243028319
Number of train steps total  824000
Number of env steps total    802369
Number of rollouts total     0
Train Time (s)               144.41473403479904
(Previous) Eval Time (s)     18.434034297708422
Sample Time (s)              6.596784585621208
Epoch Time (s)               169.44555291812867
Total Train Time (s)         33092.81341421697
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:41:13.399504 UTC | [2020_01_10_09_29_40] Iteration #205 | Epoch Duration: 169.54008436203003
2020-01-10 18:41:13.399929 UTC | [2020_01_10_09_29_40] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06096189
Z variance train             0.006768176
KL Divergence                10.1858425
KL Loss                      1.0185843
QF Loss                      134.23027
VF Loss                      27.37729
Policy Loss                  -1259.0317
Q Predictions Mean           1261.6608
Q Predictions Std            343.79248
Q Predictions Max            1620.5621
Q Predictions Min            21.67264
V Predictions Mean           1258.3148
V Predictions Std            341.28815
V Predictions Max            1619.2775
V Predictions Min            17.77325
Log Pis Mean                 0.101540826
Log Pis Std                  2.0456903
Log Pis Max                  8.071678
Log Pis Min                  -6.0797114
Policy mu Mean               0.06902925
Policy mu Std                0.9120303
Policy mu Max                3.346045
Policy mu Min                -2.9858735
Policy log std Mean          -0.58451825
Policy log std Std           0.2094289
Policy log std Max           0.07832724
Policy log std Min           -1.6875837
Z mean eval                  0.09857349
Z variance eval              0.008865988
total_rewards                [1626.06391659 1141.84169202 1029.18484898 1174.48263943 3232.70531816
  789.10127463 1056.69153979 1053.97650904 3030.74466459 3192.39882075]
total_rewards_mean           1732.7191223992045
total_rewards_std            950.8266457738949
total_rewards_max            3232.705318158202
total_rewards_min            789.1012746326369
Number of train steps total  828000
Number of env steps total    807132
Number of rollouts total     0
Train Time (s)               146.0123774628155
(Previous) Eval Time (s)     11.456265782006085
Sample Time (s)              6.50597554538399
Epoch Time (s)               163.97461879020557
Total Train Time (s)         33256.866181245074
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:43:57.451376 UTC | [2020_01_10_09_29_40] Iteration #206 | Epoch Duration: 164.0512399673462
2020-01-10 18:43:57.451512 UTC | [2020_01_10_09_29_40] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09810855
Z variance train             0.008849842
KL Divergence                10.697161
KL Loss                      1.0697161
QF Loss                      2843.8318
VF Loss                      105.29672
Policy Loss                  -1264.9
Q Predictions Mean           1257.2015
Q Predictions Std            375.56708
Q Predictions Max            1607.9209
Q Predictions Min            21.030565
V Predictions Mean           1259.7402
V Predictions Std            370.3844
V Predictions Max            1603.5197
V Predictions Min            13.87159
Log Pis Mean                 0.04171148
Log Pis Std                  2.045523
Log Pis Max                  7.317519
Log Pis Min                  -5.901372
Policy mu Mean               0.08928528
Policy mu Std                0.9210248
Policy mu Max                3.0479999
Policy mu Min                -2.716971
Policy log std Mean          -0.5632846
Policy log std Std           0.22244082
Policy log std Max           0.09609944
Policy log std Min           -3.00391
Z mean eval                  0.025772754
Z variance eval              0.009584869
total_rewards                [3190.50549331 3149.67013186  991.12775327 3161.40870823 3166.29094466
 1692.91966187 3204.10783145 3167.67199078 3168.90227196 3164.48626288]
total_rewards_mean           2805.709105027383
total_rewards_std            748.6183104581892
total_rewards_max            3204.1078314526903
total_rewards_min            991.1277532698879
Number of train steps total  832000
Number of env steps total    811851
Number of rollouts total     0
Train Time (s)               145.41713017085567
(Previous) Eval Time (s)     18.78267464088276
Sample Time (s)              5.663227446377277
Epoch Time (s)               169.8630322581157
Total Train Time (s)         33426.81161556672
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:46:47.400277 UTC | [2020_01_10_09_29_40] Iteration #207 | Epoch Duration: 169.9486198425293
2020-01-10 18:46:47.400498 UTC | [2020_01_10_09_29_40] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024695776
Z variance train             0.009559302
KL Divergence                10.860973
KL Loss                      1.0860974
QF Loss                      252.90335
VF Loss                      43.282135
Policy Loss                  -1281.3865
Q Predictions Mean           1281.8411
Q Predictions Std            312.68216
Q Predictions Max            1613.5669
Q Predictions Min            49.989502
V Predictions Mean           1280.734
V Predictions Std            310.74005
V Predictions Max            1609.511
V Predictions Min            50.79111
Log Pis Mean                 0.15912786
Log Pis Std                  2.1117036
Log Pis Max                  7.453684
Log Pis Min                  -5.037682
Policy mu Mean               0.022994956
Policy mu Std                0.9447134
Policy mu Max                2.4118958
Policy mu Min                -2.7557812
Policy log std Mean          -0.5234501
Policy log std Std           0.21181306
Policy log std Max           0.34636772
Policy log std Min           -1.1996927
Z mean eval                  0.022415433
Z variance eval              0.0047204816
total_rewards                [ 906.03026825 3190.29765146 3125.09266542 3146.50478185 1166.97238461
 3147.66774007 2221.01815914 1151.67790434 3157.19023386 1865.17871539]
total_rewards_mean           2307.763050438075
total_rewards_std            915.6170439591564
total_rewards_max            3190.297651464643
total_rewards_min            906.0302682501766
Number of train steps total  836000
Number of env steps total    816523
Number of rollouts total     0
Train Time (s)               144.7176692900248
(Previous) Eval Time (s)     14.675189319998026
Sample Time (s)              6.630989017430693
Epoch Time (s)               166.0238476274535
Total Train Time (s)         33592.92658118904
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:49:33.518333 UTC | [2020_01_10_09_29_40] Iteration #208 | Epoch Duration: 166.11770224571228
2020-01-10 18:49:33.518542 UTC | [2020_01_10_09_29_40] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021829467
Z variance train             0.004712155
KL Divergence                11.469463
KL Loss                      1.1469463
QF Loss                      189.9076
VF Loss                      46.854973
Policy Loss                  -1248.36
Q Predictions Mean           1244.9525
Q Predictions Std            373.90918
Q Predictions Max            1606.3022
Q Predictions Min            82.23974
V Predictions Mean           1244.3015
V Predictions Std            373.2
V Predictions Max            1608.1284
V Predictions Min            67.73336
Log Pis Mean                 0.17249286
Log Pis Std                  2.1886861
Log Pis Max                  13.880968
Log Pis Min                  -3.6387582
Policy mu Mean               0.08879337
Policy mu Std                0.9678823
Policy mu Max                4.026123
Policy mu Min                -2.832169
Policy log std Mean          -0.55172485
Policy log std Std           0.1957097
Policy log std Max           0.2656669
Policy log std Min           -1.5318747
Z mean eval                  0.051608074
Z variance eval              0.008690761
total_rewards                [1127.12333353 3224.93007541 3163.24234143 3181.28773598 3177.75241012
 3197.27315749 3191.30668457 1155.91942489 3221.70680291 1068.51576903]
total_rewards_mean           2570.9057735349406
total_rewards_std            952.054860500673
total_rewards_max            3224.9300754108863
total_rewards_min            1068.5157690250696
Number of train steps total  840000
Number of env steps total    821217
Number of rollouts total     0
Train Time (s)               146.82331468490884
(Previous) Eval Time (s)     17.605322377756238
Sample Time (s)              6.589449024759233
Epoch Time (s)               171.0180860874243
Total Train Time (s)         33764.027589447796
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:52:24.621571 UTC | [2020_01_10_09_29_40] Iteration #209 | Epoch Duration: 171.1028847694397
2020-01-10 18:52:24.621703 UTC | [2020_01_10_09_29_40] Iteration #209 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051713325
Z variance train             0.008683309
KL Divergence                9.48178
KL Loss                      0.948178
QF Loss                      2340.5122
VF Loss                      142.61067
Policy Loss                  -1291.7168
Q Predictions Mean           1290.2211
Q Predictions Std            348.9725
Q Predictions Max            1629.0537
Q Predictions Min            43.6486
V Predictions Mean           1293.4963
V Predictions Std            344.7491
V Predictions Max            1638.6443
V Predictions Min            48.463943
Log Pis Mean                 -0.09110305
Log Pis Std                  2.2834349
Log Pis Max                  13.4331875
Log Pis Min                  -5.5768366
Policy mu Mean               0.08198171
Policy mu Std                0.92541367
Policy mu Max                4.1073074
Policy mu Min                -2.6445613
Policy log std Mean          -0.55393475
Policy log std Std           0.22300673
Policy log std Max           0.083661556
Policy log std Min           -2.6373086
Z mean eval                  0.056351017
Z variance eval              0.008607291
total_rewards                [3218.00922687 3195.19654559 3179.69313484 3191.51966067 3156.8621333
 3196.53642805 3143.95390872 3170.13748803  786.57116367 3190.05508494]
total_rewards_mean           2942.8534774664545
total_rewards_std            719.0432396643438
total_rewards_max            3218.0092268692756
total_rewards_min            786.5711636662701
Number of train steps total  844000
Number of env steps total    825792
Number of rollouts total     0
Train Time (s)               143.7481965511106
(Previous) Eval Time (s)     19.94481557700783
Sample Time (s)              6.452040405012667
Epoch Time (s)               170.1450525331311
Total Train Time (s)         33934.252226701006
Epoch                        210
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:55:14.849031 UTC | [2020_01_10_09_29_40] Iteration #210 | Epoch Duration: 170.22723817825317
2020-01-10 18:55:14.849158 UTC | [2020_01_10_09_29_40] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05760793
Z variance train             0.00858814
KL Divergence                10.489897
KL Loss                      1.0489897
QF Loss                      128.26093
VF Loss                      57.266434
Policy Loss                  -1221.3997
Q Predictions Mean           1219.7871
Q Predictions Std            406.98288
Q Predictions Max            1640.8713
Q Predictions Min            44.136326
V Predictions Mean           1216.2727
V Predictions Std            404.84924
V Predictions Max            1637.3759
V Predictions Min            40.972687
Log Pis Mean                 0.053550348
Log Pis Std                  2.140082
Log Pis Max                  6.656805
Log Pis Min                  -5.8466845
Policy mu Mean               0.081310466
Policy mu Std                0.934555
Policy mu Max                2.120694
Policy mu Min                -2.9773114
Policy log std Mean          -0.57423645
Policy log std Std           0.19579057
Policy log std Max           0.13747525
Policy log std Min           -1.6064079
Z mean eval                  0.030546948
Z variance eval              0.0059663793
total_rewards                [1065.51572166 3086.89944736 2086.34439027 3080.69701749 3097.37891122
 2464.39793382 3105.55098416 3142.30844419 1644.3522504  2054.65522145]
total_rewards_mean           2482.810032202747
total_rewards_std            705.3656776130409
total_rewards_max            3142.3084441949327
total_rewards_min            1065.5157216578573
Number of train steps total  848000
Number of env steps total    830436
Number of rollouts total     0
Train Time (s)               147.741816427093
(Previous) Eval Time (s)     14.412010626401752
Sample Time (s)              6.521247955504805
Epoch Time (s)               168.67507500899956
Total Train Time (s)         34103.00890874863
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:58:03.611133 UTC | [2020_01_10_09_29_40] Iteration #211 | Epoch Duration: 168.76184153556824
2020-01-10 18:58:03.611409 UTC | [2020_01_10_09_29_40] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030784497
Z variance train             0.005962241
KL Divergence                11.596665
KL Loss                      1.1596665
QF Loss                      216.8761
VF Loss                      105.11801
Policy Loss                  -1283.6688
Q Predictions Mean           1282.3177
Q Predictions Std            342.35574
Q Predictions Max            1636.856
Q Predictions Min            -20.203396
V Predictions Mean           1279.7521
V Predictions Std            342.51434
V Predictions Max            1637.5685
V Predictions Min            -15.1215925
Log Pis Mean                 0.0042205155
Log Pis Std                  1.9540625
Log Pis Max                  7.9201703
Log Pis Min                  -5.4294686
Policy mu Mean               0.06324988
Policy mu Std                0.919593
Policy mu Max                2.5808542
Policy mu Min                -2.5425537
Policy log std Mean          -0.57438743
Policy log std Std           0.20002687
Policy log std Max           0.1304962
Policy log std Min           -1.2820415
Z mean eval                  0.08742799
Z variance eval              0.005173699
total_rewards                [1038.03390328 3184.61879513  988.69107666  872.75254079 3243.80107999
  950.28060685 3203.87569388 3238.30771105  756.909696    819.62164867]
total_rewards_mean           1829.6892752296928
total_rewards_std            1135.8836544599437
total_rewards_max            3243.8010799881404
total_rewards_min            756.9096960049968
Number of train steps total  852000
Number of env steps total    835103
Number of rollouts total     0
Train Time (s)               144.74589138105512
(Previous) Eval Time (s)     10.230150368995965
Sample Time (s)              6.632001825608313
Epoch Time (s)               161.6080435756594
Total Train Time (s)         34264.700748757925
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:00:45.307756 UTC | [2020_01_10_09_29_40] Iteration #212 | Epoch Duration: 161.6961407661438
2020-01-10 19:00:45.307958 UTC | [2020_01_10_09_29_40] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08661674
Z variance train             0.00518159
KL Divergence                11.642544
KL Loss                      1.1642544
QF Loss                      154.33423
VF Loss                      54.925686
Policy Loss                  -1291.0093
Q Predictions Mean           1290.697
Q Predictions Std            349.86746
Q Predictions Max            1647.3662
Q Predictions Min            59.67813
V Predictions Mean           1290.2146
V Predictions Std            347.28928
V Predictions Max            1649.4431
V Predictions Min            71.30419
Log Pis Mean                 -0.008264035
Log Pis Std                  1.9551107
Log Pis Max                  5.803268
Log Pis Min                  -5.259419
Policy mu Mean               0.07419755
Policy mu Std                0.9088327
Policy mu Max                2.871208
Policy mu Min                -2.6906192
Policy log std Mean          -0.56149507
Policy log std Std           0.20567602
Policy log std Max           -0.0026005507
Policy log std Min           -2.1619508
Z mean eval                  0.035389554
Z variance eval              0.0058432347
total_rewards                [3196.50944973 3192.75083688 3231.02444033 3166.8573712  3202.97637538
 3186.77781525 3150.12423635 3193.40621283  988.34747814 1051.94946633]
total_rewards_mean           2756.0723682420435
total_rewards_std            868.3116369798788
total_rewards_max            3231.0244403250376
total_rewards_min            988.3474781390672
Number of train steps total  856000
Number of env steps total    839822
Number of rollouts total     0
Train Time (s)               144.83228080999106
(Previous) Eval Time (s)     18.370978519320488
Sample Time (s)              6.476466916035861
Epoch Time (s)               169.6797262453474
Total Train Time (s)         34434.466605934314
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:03:35.075064 UTC | [2020_01_10_09_29_40] Iteration #213 | Epoch Duration: 169.76696467399597
2020-01-10 19:03:35.075248 UTC | [2020_01_10_09_29_40] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032717057
Z variance train             0.005856669
KL Divergence                11.079435
KL Loss                      1.1079435
QF Loss                      130.3982
VF Loss                      56.667385
Policy Loss                  -1275.3538
Q Predictions Mean           1270.3495
Q Predictions Std            364.3648
Q Predictions Max            1653.9498
Q Predictions Min            -18.503809
V Predictions Mean           1272.9521
V Predictions Std            361.32858
V Predictions Max            1654.3951
V Predictions Min            26.639963
Log Pis Mean                 0.18635532
Log Pis Std                  2.170526
Log Pis Max                  7.976889
Log Pis Min                  -4.54611
Policy mu Mean               0.06598275
Policy mu Std                0.94273186
Policy mu Max                3.9176958
Policy mu Min                -2.6647196
Policy log std Mean          -0.57202643
Policy log std Std           0.22218624
Policy log std Max           0.13797104
Policy log std Min           -2.8003664
Z mean eval                  0.073268294
Z variance eval              0.00534551
total_rewards                [2220.61913656 3263.4124812  1227.61830764 2132.24838104 2367.22917678
 3185.54612515 2449.24158622 3241.23001742 3172.31141069  946.69524216]
total_rewards_mean           2420.6151864850226
total_rewards_std            790.9732904226933
total_rewards_max            3263.4124811973493
total_rewards_min            946.6952421641012
Number of train steps total  860000
Number of env steps total    844513
Number of rollouts total     0
Train Time (s)               144.69754714192823
(Previous) Eval Time (s)     16.257001233287156
Sample Time (s)              6.593375434167683
Epoch Time (s)               167.54792380938306
Total Train Time (s)         34602.09493012028
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:06:22.705581 UTC | [2020_01_10_09_29_40] Iteration #214 | Epoch Duration: 167.63021111488342
2020-01-10 19:06:22.705716 UTC | [2020_01_10_09_29_40] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07361576
Z variance train             0.0053317486
KL Divergence                11.18434
KL Loss                      1.118434
QF Loss                      272.5108
VF Loss                      122.00911
Policy Loss                  -1234.9895
Q Predictions Mean           1227.803
Q Predictions Std            391.41623
Q Predictions Max            1610.9374
Q Predictions Min            51.109306
V Predictions Mean           1242.2339
V Predictions Std            385.12445
V Predictions Max            1622.9714
V Predictions Min            55.81513
Log Pis Mean                 -0.02901756
Log Pis Std                  2.1150134
Log Pis Max                  12.371565
Log Pis Min                  -4.2393055
Policy mu Mean               0.18677783
Policy mu Std                0.89833623
Policy mu Max                3.4274306
Policy mu Min                -2.9409823
Policy log std Mean          -0.5675655
Policy log std Std           0.2152716
Policy log std Max           0.10813528
Policy log std Min           -2.819096
Z mean eval                  0.07742031
Z variance eval              0.011988448
total_rewards                [3147.69668432 3149.74077977 3171.06159106 3142.49990545 3180.83651694
 3161.12730126 3140.54585502 3146.61619272 3186.41618093 1591.43025004]
total_rewards_mean           3001.797125751924
total_rewards_std            470.37279231165763
total_rewards_max            3186.416180934876
total_rewards_min            1591.430250044363
Number of train steps total  864000
Number of env steps total    849260
Number of rollouts total     0
Train Time (s)               144.82803047122434
(Previous) Eval Time (s)     17.724988612812012
Sample Time (s)              6.481276565231383
Epoch Time (s)               169.03429564926773
Total Train Time (s)         34771.21450397046
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:09:11.828119 UTC | [2020_01_10_09_29_40] Iteration #215 | Epoch Duration: 169.12229371070862
2020-01-10 19:09:11.828284 UTC | [2020_01_10_09_29_40] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07827097
Z variance train             0.011980709
KL Divergence                9.720385
KL Loss                      0.97203845
QF Loss                      212.43065
VF Loss                      131.23663
Policy Loss                  -1273.702
Q Predictions Mean           1269.7214
Q Predictions Std            331.39706
Q Predictions Max            1606.5443
Q Predictions Min            28.735462
V Predictions Mean           1278.2454
V Predictions Std            321.00107
V Predictions Max            1607.8824
V Predictions Min            49.886955
Log Pis Mean                 0.08629616
Log Pis Std                  2.030844
Log Pis Max                  8.177008
Log Pis Min                  -4.636325
Policy mu Mean               0.059926555
Policy mu Std                0.93409306
Policy mu Max                2.7496436
Policy mu Min                -2.5900917
Policy log std Mean          -0.6059838
Policy log std Std           0.22317663
Policy log std Max           0.048252344
Policy log std Min           -1.7899199
Z mean eval                  0.046104077
Z variance eval              0.008035876
total_rewards                [3146.7322225  3158.1813182  3133.16893738 3182.29396751 3224.23958186
 3176.40910927 3165.71484026 3119.52467058 3148.67351861 3167.26372153]
total_rewards_mean           3162.2201887690017
total_rewards_std            27.558884806123665
total_rewards_max            3224.239581858804
total_rewards_min            3119.524670575295
Number of train steps total  868000
Number of env steps total    853968
Number of rollouts total     0
Train Time (s)               145.04657527478412
(Previous) Eval Time (s)     18.479066600091755
Sample Time (s)              6.75954929785803
Epoch Time (s)               170.2851911727339
Total Train Time (s)         34941.588405791204
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:12:02.207675 UTC | [2020_01_10_09_29_40] Iteration #216 | Epoch Duration: 170.37924671173096
2020-01-10 19:12:02.207894 UTC | [2020_01_10_09_29_40] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043799955
Z variance train             0.008003769
KL Divergence                10.925506
KL Loss                      1.0925506
QF Loss                      175.20346
VF Loss                      126.00599
Policy Loss                  -1236.2574
Q Predictions Mean           1235.8344
Q Predictions Std            363.61325
Q Predictions Max            1602.4994
Q Predictions Min            22.777542
V Predictions Mean           1235.6855
V Predictions Std            364.67896
V Predictions Max            1611.5032
V Predictions Min            23.45157
Log Pis Mean                 0.19133888
Log Pis Std                  1.9883138
Log Pis Max                  6.6132436
Log Pis Min                  -5.380005
Policy mu Mean               -0.05289638
Policy mu Std                0.9366567
Policy mu Max                2.7230835
Policy mu Min                -2.5528684
Policy log std Mean          -0.5874222
Policy log std Std           0.22423622
Policy log std Max           0.3217678
Policy log std Min           -2.0616627
Z mean eval                  0.07842287
Z variance eval              0.005412061
total_rewards                [3225.65053102 3218.61703351 3232.43749924 2056.11383045 3231.63222162
 3233.11533366 3203.64836657 3208.730389    948.14593127  971.223702  ]
total_rewards_mean           2652.931483833487
total_rewards_std            914.2302760548898
total_rewards_max            3233.115333663351
total_rewards_min            948.1459312698794
Number of train steps total  872000
Number of env steps total    858605
Number of rollouts total     0
Train Time (s)               145.14647105382755
(Previous) Eval Time (s)     17.717027978040278
Sample Time (s)              6.660532537382096
Epoch Time (s)               169.52403156924993
Total Train Time (s)         35111.45076081436
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:14:52.068764 UTC | [2020_01_10_09_29_40] Iteration #217 | Epoch Duration: 169.86072421073914
2020-01-10 19:14:52.068900 UTC | [2020_01_10_09_29_40] Iteration #217 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07808544
Z variance train             0.0054105124
KL Divergence                10.939404
KL Loss                      1.0939404
QF Loss                      135.60013
VF Loss                      161.11946
Policy Loss                  -1277.7273
Q Predictions Mean           1275.9719
Q Predictions Std            350.0714
Q Predictions Max            1625.9454
Q Predictions Min            37.77764
V Predictions Mean           1271.9736
V Predictions Std            342.09378
V Predictions Max            1622.8414
V Predictions Min            67.79648
Log Pis Mean                 -0.022959415
Log Pis Std                  2.0199578
Log Pis Max                  7.0802665
Log Pis Min                  -5.262417
Policy mu Mean               0.061776202
Policy mu Std                0.9155974
Policy mu Max                3.5386221
Policy mu Min                -2.4849863
Policy log std Mean          -0.5777855
Policy log std Std           0.24386582
Policy log std Max           0.07761389
Policy log std Min           -3.105737
Z mean eval                  0.07882629
Z variance eval              0.005435528
total_rewards                [1054.01629249 3166.20328068  943.74900665 1258.31936574 3102.2700295
 3153.82754581 1149.61397299  932.15794938  875.91448051 3163.25765668]
total_rewards_mean           1879.9329580417884
total_rewards_std            1039.3751747886922
total_rewards_max            3166.2032806825705
total_rewards_min            875.9144805061226
Number of train steps total  876000
Number of env steps total    863267
Number of rollouts total     0
Train Time (s)               145.35590857313946
(Previous) Eval Time (s)     12.794587454292923
Sample Time (s)              6.449573426973075
Epoch Time (s)               164.60006945440546
Total Train Time (s)         35276.13639010955
Epoch                        218
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:17:36.759156 UTC | [2020_01_10_09_29_40] Iteration #218 | Epoch Duration: 164.69015669822693
2020-01-10 19:17:36.759319 UTC | [2020_01_10_09_29_40] Iteration #218 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.078968346
Z variance train             0.0054293857
KL Divergence                10.759918
KL Loss                      1.0759919
QF Loss                      340.79092
VF Loss                      97.666885
Policy Loss                  -1274.7297
Q Predictions Mean           1274.6266
Q Predictions Std            368.46835
Q Predictions Max            1617.2877
Q Predictions Min            39.826557
V Predictions Mean           1279.5728
V Predictions Std            368.03708
V Predictions Max            1624.088
V Predictions Min            46.422054
Log Pis Mean                 -0.007307263
Log Pis Std                  2.1007571
Log Pis Max                  8.710758
Log Pis Min                  -4.2446375
Policy mu Mean               0.016430808
Policy mu Std                0.92938054
Policy mu Max                2.2673478
Policy mu Min                -2.9102306
Policy log std Mean          -0.56029123
Policy log std Std           0.20430042
Policy log std Max           0.14707339
Policy log std Min           -1.7425693
Z mean eval                  0.038417272
Z variance eval              0.0076683974
total_rewards                [3153.05445654  865.621466   3176.67034581 1144.48314781 3183.4470251
 1003.2734992  3110.74179552 3163.51743333 3177.77810138 3185.1278284 ]
total_rewards_mean           2516.3715099095493
total_rewards_std            991.9493949354071
total_rewards_max            3185.1278284048713
total_rewards_min            865.6214660007552
Number of train steps total  880000
Number of env steps total    867955
Number of rollouts total     0
Train Time (s)               145.01150311203673
(Previous) Eval Time (s)     17.23316792026162
Sample Time (s)              5.592302791774273
Epoch Time (s)               167.83697382407263
Total Train Time (s)         35444.05593661079
Epoch                        219
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:20:24.677643 UTC | [2020_01_10_09_29_40] Iteration #219 | Epoch Duration: 167.9182140827179
2020-01-10 19:20:24.677770 UTC | [2020_01_10_09_29_40] Iteration #219 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03736987
Z variance train             0.007663563
KL Divergence                10.20977
KL Loss                      1.020977
QF Loss                      170.39282
VF Loss                      28.266272
Policy Loss                  -1263.3687
Q Predictions Mean           1261.5482
Q Predictions Std            367.55508
Q Predictions Max            1620.8074
Q Predictions Min            47.719864
V Predictions Mean           1264.3547
V Predictions Std            366.4492
V Predictions Max            1612.4313
V Predictions Min            49.77739
Log Pis Mean                 0.062114716
Log Pis Std                  1.9780548
Log Pis Max                  8.002236
Log Pis Min                  -4.320087
Policy mu Mean               0.107856125
Policy mu Std                0.9141646
Policy mu Max                2.1564965
Policy mu Min                -2.800608
Policy log std Mean          -0.5548835
Policy log std Std           0.21197273
Policy log std Max           0.3241778
Policy log std Min           -1.1761471
Z mean eval                  0.074817635
Z variance eval              0.0055003623
total_rewards                [3137.49614597 3193.43073275 2377.53585246 1264.86446534 2563.0567559
 3206.66222975 3166.62588816 3183.70823713 2141.60538764 1139.40548903]
total_rewards_mean           2537.4391184134092
total_rewards_std            762.1447834206821
total_rewards_max            3206.6622297451327
total_rewards_min            1139.4054890261737
Number of train steps total  884000
Number of env steps total    872616
Number of rollouts total     0
Train Time (s)               146.6682289778255
(Previous) Eval Time (s)     14.958411713130772
Sample Time (s)              6.540842523332685
Epoch Time (s)               168.16748321428895
Total Train Time (s)         35612.30359057337
Epoch                        220
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:23:12.932425 UTC | [2020_01_10_09_29_40] Iteration #220 | Epoch Duration: 168.25451612472534
2020-01-10 19:23:12.932719 UTC | [2020_01_10_09_29_40] Iteration #220 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07496316
Z variance train             0.0054975008
KL Divergence                10.787211
KL Loss                      1.0787212
QF Loss                      128.24252
VF Loss                      97.656364
Policy Loss                  -1276.8848
Q Predictions Mean           1277.3379
Q Predictions Std            337.48798
Q Predictions Max            1612.193
Q Predictions Min            60.91991
V Predictions Mean           1278.6853
V Predictions Std            336.50323
V Predictions Max            1612.3075
V Predictions Min            52.289707
Log Pis Mean                 -0.016483191
Log Pis Std                  2.0535798
Log Pis Max                  6.183522
Log Pis Min                  -6.1137924
Policy mu Mean               0.1657287
Policy mu Std                0.9061249
Policy mu Max                2.921085
Policy mu Min                -2.7982037
Policy log std Mean          -0.57315403
Policy log std Std           0.2026131
Policy log std Max           0.027276456
Policy log std Min           -1.3729932
Z mean eval                  0.08279323
Z variance eval              0.00500201
total_rewards                [ 231.87616876  682.27699706 1694.8023713  1741.88605474 3108.8838578
  237.80649311  145.41967189 3139.29022332 3089.88222325 3132.97847347]
total_rewards_mean           1720.5102534689638
total_rewards_std            1256.3901570091207
total_rewards_max            3139.290223319968
total_rewards_min            145.41967189094132
Number of train steps total  888000
Number of env steps total    877351
Number of rollouts total     0
Train Time (s)               144.7171703740023
(Previous) Eval Time (s)     12.062318861018866
Sample Time (s)              6.529116812162101
Epoch Time (s)               163.30860604718328
Total Train Time (s)         35775.69486974832
Epoch                        221
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:25:56.323621 UTC | [2020_01_10_09_29_40] Iteration #221 | Epoch Duration: 163.39070343971252
2020-01-10 19:25:56.323748 UTC | [2020_01_10_09_29_40] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08454414
Z variance train             0.0050021745
KL Divergence                11.450686
KL Loss                      1.1450686
QF Loss                      106.683
VF Loss                      129.09846
Policy Loss                  -1295.802
Q Predictions Mean           1296.6501
Q Predictions Std            372.83536
Q Predictions Max            1654.9614
Q Predictions Min            -44.846916
V Predictions Mean           1299.4346
V Predictions Std            367.49722
V Predictions Max            1645.31
V Predictions Min            35.280384
Log Pis Mean                 -0.23853311
Log Pis Std                  1.7526547
Log Pis Max                  8.376614
Log Pis Min                  -4.4994583
Policy mu Mean               0.1777376
Policy mu Std                0.8812547
Policy mu Max                2.4949446
Policy mu Min                -2.581332
Policy log std Mean          -0.5526554
Policy log std Std           0.22053593
Policy log std Max           0.01622814
Policy log std Min           -3.2191994
Z mean eval                  0.16426687
Z variance eval              0.007303278
total_rewards                [ 475.12109851  472.52961831 3203.63939117 3213.99981727 3147.57043399
 3148.26326483 3172.66704183 3139.38432441 3173.3389147  3179.4930134 ]
total_rewards_mean           2632.6006918424737
total_rewards_std            1079.621574983732
total_rewards_max            3213.999817272075
total_rewards_min            472.52961830700485
Number of train steps total  892000
Number of env steps total    882346
Number of rollouts total     0
Train Time (s)               144.54935627197847
(Previous) Eval Time (s)     18.23010131297633
Sample Time (s)              7.196127876639366
Epoch Time (s)               169.97558546159416
Total Train Time (s)         35945.758294036146
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:28:46.394653 UTC | [2020_01_10_09_29_40] Iteration #222 | Epoch Duration: 170.0707426071167
2020-01-10 19:28:46.394973 UTC | [2020_01_10_09_29_40] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16331491
Z variance train             0.0073160306
KL Divergence                10.414377
KL Loss                      1.0414377
QF Loss                      9456.137
VF Loss                      109.026535
Policy Loss                  -1263.921
Q Predictions Mean           1255.8331
Q Predictions Std            392.06723
Q Predictions Max            1637.7948
Q Predictions Min            7.1820536
V Predictions Mean           1258.0354
V Predictions Std            383.81714
V Predictions Max            1632.6853
V Predictions Min            7.496088
Log Pis Mean                 0.012838148
Log Pis Std                  2.2239103
Log Pis Max                  8.8501
Log Pis Min                  -4.864101
Policy mu Mean               0.064464085
Policy mu Std                0.95420593
Policy mu Max                3.497852
Policy mu Min                -2.5241764
Policy log std Mean          -0.5719693
Policy log std Std           0.20820118
Policy log std Max           0.25383765
Policy log std Min           -2.7956362
Z mean eval                  0.027219022
Z variance eval              0.003570341
total_rewards                [1909.14277697 2905.33436843 3146.12397753 2855.63352255 1206.48378991
 3147.02788109 2675.91367684 3165.63584696 3199.51859081 1199.8720663 ]
total_rewards_mean           2541.0686497384395
total_rewards_std            760.6574876410997
total_rewards_max            3199.518590805354
total_rewards_min            1199.8720662975722
Number of train steps total  896000
Number of env steps total    887277
Number of rollouts total     0
Train Time (s)               143.5740628382191
(Previous) Eval Time (s)     14.84043979505077
Sample Time (s)              7.017076274380088
Epoch Time (s)               165.43157890764996
Total Train Time (s)         36111.27534098178
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:31:31.915801 UTC | [2020_01_10_09_29_40] Iteration #223 | Epoch Duration: 165.52060437202454
2020-01-10 19:31:31.915987 UTC | [2020_01_10_09_29_40] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02732324
Z variance train             0.0035748289
KL Divergence                12.071337
KL Loss                      1.2071337
QF Loss                      145.13245
VF Loss                      53.946484
Policy Loss                  -1265.144
Q Predictions Mean           1263.1958
Q Predictions Std            356.56973
Q Predictions Max            1636.8878
Q Predictions Min            56.363194
V Predictions Mean           1261.4192
V Predictions Std            354.39557
V Predictions Max            1630.3815
V Predictions Min            31.878544
Log Pis Mean                 0.14592417
Log Pis Std                  2.1155138
Log Pis Max                  6.3309402
Log Pis Min                  -6.917928
Policy mu Mean               0.12462161
Policy mu Std                0.9637695
Policy mu Max                2.9793646
Policy mu Min                -2.6369188
Policy log std Mean          -0.56698847
Policy log std Std           0.20574129
Policy log std Max           0.093199015
Policy log std Min           -1.4082084
Z mean eval                  0.08234523
Z variance eval              0.005791427
total_rewards                [3222.17804225  800.00553028 3201.69718484 3012.46345315 1271.85827947
 2405.35853859 2711.41636538 3047.58294388 3156.44377889 3166.08889166]
total_rewards_mean           2599.5093008379617
total_rewards_std            824.8590752736901
total_rewards_max            3222.17804225186
total_rewards_min            800.0055302812495
Number of train steps total  900000
Number of env steps total    891984
Number of rollouts total     0
Train Time (s)               146.86774310702458
(Previous) Eval Time (s)     14.712661823723465
Sample Time (s)              6.536075736396015
Epoch Time (s)               168.11648066714406
Total Train Time (s)         36279.47325670486
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:34:20.115004 UTC | [2020_01_10_09_29_40] Iteration #224 | Epoch Duration: 168.19887924194336
2020-01-10 19:34:20.115159 UTC | [2020_01_10_09_29_40] Iteration #224 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08176915
Z variance train             0.0057744407
KL Divergence                11.092286
KL Loss                      1.1092286
QF Loss                      551.0056
VF Loss                      909.7947
Policy Loss                  -1278.6499
Q Predictions Mean           1273.554
Q Predictions Std            358.61618
Q Predictions Max            1637.599
Q Predictions Min            33.260506
V Predictions Mean           1276.3253
V Predictions Std            352.19125
V Predictions Max            1636.2056
V Predictions Min            26.59908
Log Pis Mean                 0.14520165
Log Pis Std                  2.2202785
Log Pis Max                  8.492138
Log Pis Min                  -5.3477254
Policy mu Mean               0.08371758
Policy mu Std                0.9094246
Policy mu Max                2.9420915
Policy mu Min                -2.5698192
Policy log std Mean          -0.6052212
Policy log std Std           0.24077405
Policy log std Max           0.10638976
Policy log std Min           -3.50245
Z mean eval                  0.076581836
Z variance eval              0.006365251
total_rewards                [3169.96278947 3203.68355483 3242.25333434 1976.79015042 1221.4794846
 3241.46060293 3213.76378996 3221.07766944 3235.58410878 3215.26852083]
total_rewards_mean           2894.1324005606994
total_rewards_std            669.4616551483315
total_rewards_max            3242.2533343359187
total_rewards_min            1221.4794846002544
Number of train steps total  904000
Number of env steps total    896682
Number of rollouts total     0
Train Time (s)               145.24503630399704
(Previous) Eval Time (s)     19.598835243377835
Sample Time (s)              6.42586951283738
Epoch Time (s)               171.26974106021225
Total Train Time (s)         36450.822232539766
Epoch                        225
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:37:11.465430 UTC | [2020_01_10_09_29_40] Iteration #225 | Epoch Duration: 171.35015392303467
2020-01-10 19:37:11.465560 UTC | [2020_01_10_09_29_40] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.077782586
Z variance train             0.0063748695
KL Divergence                11.725538
KL Loss                      1.1725539
QF Loss                      230.58907
VF Loss                      79.46487
Policy Loss                  -1287.3875
Q Predictions Mean           1285.166
Q Predictions Std            340.4318
Q Predictions Max            1636.7765
Q Predictions Min            -58.556942
V Predictions Mean           1284.3136
V Predictions Std            338.91086
V Predictions Max            1638.6632
V Predictions Min            17.07879
Log Pis Mean                 0.053134955
Log Pis Std                  2.1358488
Log Pis Max                  15.368758
Log Pis Min                  -5.039847
Policy mu Mean               0.02708655
Policy mu Std                0.96559656
Policy mu Max                3.8728228
Policy mu Min                -3.996147
Policy log std Mean          -0.5518814
Policy log std Std           0.20855479
Policy log std Max           0.057558
Policy log std Min           -2.2595384
Z mean eval                  0.046142936
Z variance eval              0.0058308626
total_rewards                [1658.65182841  477.00988004 1392.62699171 2788.75756301 3258.24256416
 3239.41811691 2720.70431964 1326.74622923 1774.17303983 1640.94075046]
total_rewards_mean           2027.727128338823
total_rewards_std            877.0010457963516
total_rewards_max            3258.242564155351
total_rewards_min            477.009880040624
Number of train steps total  908000
Number of env steps total    901320
Number of rollouts total     0
Train Time (s)               144.39888562913984
(Previous) Eval Time (s)     13.627796544227749
Sample Time (s)              6.147742296569049
Epoch Time (s)               164.17442446993664
Total Train Time (s)         36615.077208446804
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:39:55.723746 UTC | [2020_01_10_09_29_40] Iteration #226 | Epoch Duration: 164.25808215141296
2020-01-10 19:39:55.723923 UTC | [2020_01_10_09_29_40] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04714655
Z variance train             0.0058408882
KL Divergence                12.303825
KL Loss                      1.2303826
QF Loss                      465.69385
VF Loss                      452.5938
Policy Loss                  -1272.5798
Q Predictions Mean           1267.1475
Q Predictions Std            386.82104
Q Predictions Max            1660.2148
Q Predictions Min            18.894148
V Predictions Mean           1278.687
V Predictions Std            384.20337
V Predictions Max            1666.3492
V Predictions Min            9.831277
Log Pis Mean                 0.069174565
Log Pis Std                  2.027076
Log Pis Max                  8.617156
Log Pis Min                  -4.283857
Policy mu Mean               0.11241341
Policy mu Std                0.9055743
Policy mu Max                3.6872656
Policy mu Min                -2.5225675
Policy log std Mean          -0.54104966
Policy log std Std           0.22763465
Policy log std Max           0.02050805
Policy log std Min           -2.5965517
Z mean eval                  0.025430435
Z variance eval              0.0055038063
total_rewards                [ 935.0900795  3259.54642508  998.50088164 3247.98571897  980.29669891
 3313.40798389 3244.7418148  3248.8184128   977.9394964  1168.61641141]
total_rewards_mean           2137.494392340593
total_rewards_std            1127.0085806110726
total_rewards_max            3313.407983889403
total_rewards_min            935.0900795049704
Number of train steps total  912000
Number of env steps total    905936
Number of rollouts total     0
Train Time (s)               143.91989280516282
(Previous) Eval Time (s)     14.269616153091192
Sample Time (s)              6.442904655821621
Epoch Time (s)               164.63241361407563
Total Train Time (s)         36779.800698087085
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:42:40.451848 UTC | [2020_01_10_09_29_40] Iteration #227 | Epoch Duration: 164.72779273986816
2020-01-10 19:42:40.452019 UTC | [2020_01_10_09_29_40] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025820594
Z variance train             0.0055055404
KL Divergence                11.39517
KL Loss                      1.1395171
QF Loss                      129.41165
VF Loss                      66.88755
Policy Loss                  -1327.2197
Q Predictions Mean           1328.1389
Q Predictions Std            343.12338
Q Predictions Max            1661.8135
Q Predictions Min            70.27669
V Predictions Mean           1327.039
V Predictions Std            340.1916
V Predictions Max            1655.8766
V Predictions Min            73.13517
Log Pis Mean                 -0.31962273
Log Pis Std                  1.8725835
Log Pis Max                  5.254306
Log Pis Min                  -4.414568
Policy mu Mean               0.08875459
Policy mu Std                0.8372873
Policy mu Max                2.6462667
Policy mu Min                -2.516572
Policy log std Mean          -0.52724844
Policy log std Std           0.19425268
Policy log std Max           0.050129175
Policy log std Min           -1.2139264
Z mean eval                  0.05891826
Z variance eval              0.0056337826
total_rewards                [3184.98262728 3184.4928548  3207.6524231  1139.21093799  750.23257699
 1087.40530503 3206.61144404 3217.48361037 3217.58821516 3179.69596074]
total_rewards_mean           2537.5355955498335
total_rewards_std            1016.0842975983536
total_rewards_max            3217.588215156406
total_rewards_min            750.2325769918589
Number of train steps total  916000
Number of env steps total    910540
Number of rollouts total     0
Train Time (s)               146.75676812883466
(Previous) Eval Time (s)     17.41578208375722
Sample Time (s)              5.72142469836399
Epoch Time (s)               169.89397491095588
Total Train Time (s)         36949.8109885375
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:45:30.463808 UTC | [2020_01_10_09_29_40] Iteration #228 | Epoch Duration: 170.0116753578186
2020-01-10 19:45:30.463941 UTC | [2020_01_10_09_29_40] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0585186
Z variance train             0.0056405463
KL Divergence                11.294635
KL Loss                      1.1294636
QF Loss                      182.66357
VF Loss                      37.37134
Policy Loss                  -1330.7305
Q Predictions Mean           1327.2113
Q Predictions Std            326.36255
Q Predictions Max            1658.6387
Q Predictions Min            87.4455
V Predictions Mean           1330.0308
V Predictions Std            324.49518
V Predictions Max            1662.869
V Predictions Min            89.915794
Log Pis Mean                 -0.24910411
Log Pis Std                  2.152253
Log Pis Max                  9.452689
Log Pis Min                  -7.9973836
Policy mu Mean               0.1366265
Policy mu Std                0.88174903
Policy mu Max                3.6989896
Policy mu Min                -2.815737
Policy log std Mean          -0.55986136
Policy log std Std           0.20511913
Policy log std Max           0.038353562
Policy log std Min           -1.3198133
Z mean eval                  0.11997185
Z variance eval              0.012903462
total_rewards                [1137.95715392 3269.20602327 1203.14133273 1160.13509276 1274.78288931
 3233.96581873  952.22818437 2674.37492565  916.58390071 3206.16809496]
total_rewards_mean           1902.854341640225
total_rewards_std            991.4553213094085
total_rewards_max            3269.2060232734634
total_rewards_min            916.5839007142491
Number of train steps total  920000
Number of env steps total    915193
Number of rollouts total     0
Train Time (s)               144.20370095409453
(Previous) Eval Time (s)     12.526325717102736
Sample Time (s)              6.6107212523929775
Epoch Time (s)               163.34074792359024
Total Train Time (s)         37113.22820084449
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:48:13.883468 UTC | [2020_01_10_09_29_40] Iteration #229 | Epoch Duration: 163.41943669319153
2020-01-10 19:48:13.883595 UTC | [2020_01_10_09_29_40] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.121604085
Z variance train             0.012914175
KL Divergence                9.736449
KL Loss                      0.9736449
QF Loss                      189.51999
VF Loss                      335.69504
Policy Loss                  -1306.204
Q Predictions Mean           1304.3123
Q Predictions Std            324.51102
Q Predictions Max            1625.3208
Q Predictions Min            67.569916
V Predictions Mean           1312.7053
V Predictions Std            318.61496
V Predictions Max            1617.4263
V Predictions Min            108.402916
Log Pis Mean                 -0.069254845
Log Pis Std                  1.8858349
Log Pis Max                  7.3297825
Log Pis Min                  -4.291379
Policy mu Mean               0.15434287
Policy mu Std                0.8582049
Policy mu Max                3.0242815
Policy mu Min                -2.565436
Policy log std Mean          -0.58407694
Policy log std Std           0.18874581
Policy log std Max           0.024821818
Policy log std Min           -1.3558698
Z mean eval                  0.0651734
Z variance eval              0.0055771666
total_rewards                [3278.68908029 3272.10868044 3265.78590442  795.6039995   986.96164147
 3238.07624445 1832.07791617 1474.60326875 1668.03822111 1628.52179679]
total_rewards_mean           2144.046675339271
total_rewards_std            959.6931398358753
total_rewards_max            3278.689080289112
total_rewards_min            795.6039994993891
Number of train steps total  924000
Number of env steps total    920108
Number of rollouts total     0
Train Time (s)               145.13637389615178
(Previous) Eval Time (s)     11.923937579151243
Sample Time (s)              7.061719699762762
Epoch Time (s)               164.12203117506579
Total Train Time (s)         37277.433468470816
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:50:58.091367 UTC | [2020_01_10_09_29_40] Iteration #230 | Epoch Duration: 164.20767378807068
2020-01-10 19:50:58.091531 UTC | [2020_01_10_09_29_40] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06509276
Z variance train             0.0055947816
KL Divergence                11.46594
KL Loss                      1.146594
QF Loss                      128.6133
VF Loss                      366.3379
Policy Loss                  -1339.6511
Q Predictions Mean           1335.2118
Q Predictions Std            306.94415
Q Predictions Max            1685.6675
Q Predictions Min            54.062553
V Predictions Mean           1334.4076
V Predictions Std            295.06134
V Predictions Max            1677.0952
V Predictions Min            58.327686
Log Pis Mean                 -0.0008714795
Log Pis Std                  2.3858871
Log Pis Max                  15.809335
Log Pis Min                  -5.1812525
Policy mu Mean               0.16315289
Policy mu Std                0.9294835
Policy mu Max                4.1471434
Policy mu Min                -2.6658483
Policy log std Mean          -0.5560213
Policy log std Std           0.19720604
Policy log std Max           0.08260411
Policy log std Min           -1.359403
Z mean eval                  0.06155644
Z variance eval              0.0044923495
total_rewards                [3185.3397828  3213.18720735 3147.4026892  3163.77628458 3187.21925929
 3134.15290954 3225.62359558 3175.72690676 1043.09841562 3167.53666203]
total_rewards_mean           2964.3063712742955
total_rewards_std            640.9349299447707
total_rewards_max            3225.623595579595
total_rewards_min            1043.0984156179138
Number of train steps total  928000
Number of env steps total    924888
Number of rollouts total     0
Train Time (s)               145.9450153033249
(Previous) Eval Time (s)     17.016405316069722
Sample Time (s)              6.485886641778052
Epoch Time (s)               169.44730726117268
Total Train Time (s)         37446.96361383563
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:53:47.623215 UTC | [2020_01_10_09_29_40] Iteration #231 | Epoch Duration: 169.53157258033752
2020-01-10 19:53:47.623333 UTC | [2020_01_10_09_29_40] Iteration #231 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06216536
Z variance train             0.0045027887
KL Divergence                11.966652
KL Loss                      1.1966652
QF Loss                      81.05173
VF Loss                      32.09564
Policy Loss                  -1299.981
Q Predictions Mean           1298.5867
Q Predictions Std            337.11905
Q Predictions Max            1629.6383
Q Predictions Min            42.91481
V Predictions Mean           1298.5774
V Predictions Std            336.03885
V Predictions Max            1631.3496
V Predictions Min            41.223995
Log Pis Mean                 0.11988558
Log Pis Std                  1.9575306
Log Pis Max                  5.617283
Log Pis Min                  -4.4547224
Policy mu Mean               0.11166694
Policy mu Std                0.91989404
Policy mu Max                2.325617
Policy mu Min                -2.6980176
Policy log std Mean          -0.5760267
Policy log std Std           0.17978396
Policy log std Max           0.015813231
Policy log std Min           -1.3366859
Z mean eval                  0.09736066
Z variance eval              0.0040234127
total_rewards                [3179.18479282 3198.22967025 3191.58353144 1187.95475865 3169.0895008
 3200.01785881 3215.133096   3238.8442063  3153.43069807 3194.1590086 ]
total_rewards_mean           2992.7627121738124
total_rewards_std            602.0179832639858
total_rewards_max            3238.8442063023413
total_rewards_min            1187.9547586528784
Number of train steps total  932000
Number of env steps total    929552
Number of rollouts total     0
Train Time (s)               144.48172131180763
(Previous) Eval Time (s)     17.61227794503793
Sample Time (s)              5.577578000258654
Epoch Time (s)               167.67157725710422
Total Train Time (s)         37614.7115011164
Epoch                        232
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:56:35.373666 UTC | [2020_01_10_09_29_40] Iteration #232 | Epoch Duration: 167.75022959709167
2020-01-10 19:56:35.373830 UTC | [2020_01_10_09_29_40] Iteration #232 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09662775
Z variance train             0.004025143
KL Divergence                12.082227
KL Loss                      1.2082227
QF Loss                      141.43787
VF Loss                      214.65881
Policy Loss                  -1321.7256
Q Predictions Mean           1321.6816
Q Predictions Std            317.66296
Q Predictions Max            1627.1743
Q Predictions Min            51.04364
V Predictions Mean           1322.1124
V Predictions Std            317.9674
V Predictions Max            1637.3062
V Predictions Min            40.474194
Log Pis Mean                 -0.016231466
Log Pis Std                  2.174593
Log Pis Max                  11.001675
Log Pis Min                  -4.994875
Policy mu Mean               0.031169862
Policy mu Std                0.9214387
Policy mu Max                3.695394
Policy mu Min                -2.6771634
Policy log std Mean          -0.5475138
Policy log std Std           0.2044458
Policy log std Max           0.10982859
Policy log std Min           -1.6182747
Z mean eval                  0.10341138
Z variance eval              0.011409847
total_rewards                [ 813.22458889 1506.65423857 3264.01944936  788.68772644 3294.4919843
 3240.9031431  3301.99391235 3248.12472528 1967.81494347 3230.42518314]
total_rewards_mean           2465.633989491758
total_rewards_std            1026.266728599219
total_rewards_max            3301.9939123532763
total_rewards_min            788.6877264383911
Number of train steps total  936000
Number of env steps total    934262
Number of rollouts total     0
Train Time (s)               145.58611107291654
(Previous) Eval Time (s)     13.603243991266936
Sample Time (s)              5.674675667192787
Epoch Time (s)               164.86403073137626
Total Train Time (s)         37779.65737418458
Epoch                        233
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:59:20.325115 UTC | [2020_01_10_09_29_40] Iteration #233 | Epoch Duration: 164.95105266571045
2020-01-10 19:59:20.325507 UTC | [2020_01_10_09_29_40] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10247566
Z variance train             0.011417762
KL Divergence                10.801289
KL Loss                      1.0801289
QF Loss                      215.70099
VF Loss                      36.233456
Policy Loss                  -1289.0217
Q Predictions Mean           1284.4948
Q Predictions Std            355.42517
Q Predictions Max            1646.1577
Q Predictions Min            23.123137
V Predictions Mean           1288.6917
V Predictions Std            348.9726
V Predictions Max            1650.6018
V Predictions Min            25.20596
Log Pis Mean                 0.1347327
Log Pis Std                  2.2255998
Log Pis Max                  8.937769
Log Pis Min                  -4.79039
Policy mu Mean               0.0820778
Policy mu Std                0.9278482
Policy mu Max                2.9335303
Policy mu Min                -2.433492
Policy log std Mean          -0.55270225
Policy log std Std           0.20250374
Policy log std Max           0.16727054
Policy log std Min           -1.8396683
Z mean eval                  0.049203224
Z variance eval              0.0071942955
total_rewards                [1789.64662126  647.10413967 3310.6955712  1061.42165232 1685.99421014
 3258.24818747 3269.83233291 2290.21880753 3285.4610811  3243.4659473 ]
total_rewards_mean           2384.208855089643
total_rewards_std            978.4871233203892
total_rewards_max            3310.6955711959904
total_rewards_min            647.1041396702439
Number of train steps total  940000
Number of env steps total    938987
Number of rollouts total     0
Train Time (s)               144.98069204529747
(Previous) Eval Time (s)     15.813316754065454
Sample Time (s)              6.624526659492403
Epoch Time (s)               167.41853545885533
Total Train Time (s)         37947.15837647021
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:02:07.828108 UTC | [2020_01_10_09_29_40] Iteration #234 | Epoch Duration: 167.5022852420807
2020-01-10 20:02:07.828288 UTC | [2020_01_10_09_29_40] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04966681
Z variance train             0.007184869
KL Divergence                10.534313
KL Loss                      1.0534314
QF Loss                      15011.184
VF Loss                      123.34374
Policy Loss                  -1290.1079
Q Predictions Mean           1285.8265
Q Predictions Std            383.49103
Q Predictions Max            1661.4688
Q Predictions Min            -139.13612
V Predictions Mean           1298.1854
V Predictions Std            370.504
V Predictions Max            1662.7058
V Predictions Min            11.846028
Log Pis Mean                 0.09879471
Log Pis Std                  2.0855947
Log Pis Max                  11.377642
Log Pis Min                  -5.1174564
Policy mu Mean               0.07896486
Policy mu Std                0.9617079
Policy mu Max                3.2468925
Policy mu Min                -3.7022603
Policy log std Mean          -0.55813646
Policy log std Std           0.19385272
Policy log std Max           0.032554746
Policy log std Min           -1.2617943
Z mean eval                  0.048794575
Z variance eval              0.005834264
total_rewards                [3165.19599514 3160.83293984 3235.06893305 3230.57820842 3234.36528517
 3170.61098668 3212.14928536 3224.16981819 3171.76653573 3233.37733623]
total_rewards_mean           3203.8115323810807
total_rewards_std            30.745086947560527
total_rewards_max            3235.068933051926
total_rewards_min            3160.8329398447945
Number of train steps total  944000
Number of env steps total    943970
Number of rollouts total     0
Train Time (s)               145.40636150399223
(Previous) Eval Time (s)     20.35681449295953
Sample Time (s)              6.989696150645614
Epoch Time (s)               172.75287214759737
Total Train Time (s)         38119.99823689042
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:05:00.673266 UTC | [2020_01_10_09_29_40] Iteration #235 | Epoch Duration: 172.8448450565338
2020-01-10 20:05:00.673450 UTC | [2020_01_10_09_29_40] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049234606
Z variance train             0.0058554523
KL Divergence                10.672134
KL Loss                      1.0672134
QF Loss                      134.12207
VF Loss                      92.44012
Policy Loss                  -1314.9888
Q Predictions Mean           1313.0085
Q Predictions Std            336.66605
Q Predictions Max            1646.5742
Q Predictions Min            4.204233
V Predictions Mean           1310.2745
V Predictions Std            327.8805
V Predictions Max            1648.7166
V Predictions Min            42.096584
Log Pis Mean                 0.14723144
Log Pis Std                  2.283017
Log Pis Max                  10.717201
Log Pis Min                  -7.60114
Policy mu Mean               0.0729479
Policy mu Std                0.95514244
Policy mu Max                3.7995553
Policy mu Min                -2.565446
Policy log std Mean          -0.5604666
Policy log std Std           0.20788805
Policy log std Max           0.10845947
Policy log std Min           -2.5406206
Z mean eval                  0.071241125
Z variance eval              0.0071558654
total_rewards                [3115.28487825 3150.45564284 3166.72560697 3125.4154728  3150.86128862
 3167.67172954 3221.82223416 3145.14549501 3183.79668076 3133.67840911]
total_rewards_mean           3156.085743806067
total_rewards_std            29.364554754179323
total_rewards_max            3221.8222341580304
total_rewards_min            3115.28487824558
Number of train steps total  948000
Number of env steps total    948750
Number of rollouts total     0
Train Time (s)               144.43928799498826
(Previous) Eval Time (s)     19.28978128125891
Sample Time (s)              6.487314538564533
Epoch Time (s)               170.2163838148117
Total Train Time (s)         38290.46201596316
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:07:51.145446 UTC | [2020_01_10_09_29_40] Iteration #236 | Epoch Duration: 170.47186040878296
2020-01-10 20:07:51.145638 UTC | [2020_01_10_09_29_40] Iteration #236 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07160096
Z variance train             0.0071381084
KL Divergence                10.037959
KL Loss                      1.003796
QF Loss                      245.81473
VF Loss                      268.49603
Policy Loss                  -1307.3667
Q Predictions Mean           1302.4575
Q Predictions Std            336.59433
Q Predictions Max            1629.9746
Q Predictions Min            40.312122
V Predictions Mean           1297.4719
V Predictions Std            332.30295
V Predictions Max            1608.5963
V Predictions Min            40.449234
Log Pis Mean                 -0.04713563
Log Pis Std                  1.930176
Log Pis Max                  5.3955135
Log Pis Min                  -3.721245
Policy mu Mean               0.01605999
Policy mu Std                0.89827174
Policy mu Max                2.3873568
Policy mu Min                -2.5129163
Policy log std Mean          -0.575923
Policy log std Std           0.19371712
Policy log std Max           -0.051863313
Policy log std Min           -1.1417949
Z mean eval                  0.057679795
Z variance eval              0.0060919835
total_rewards                [1138.92457044 3232.73138996 3238.2532034  2993.53817309  912.3329777
 3232.21118548 3218.80459866 3197.77364628 3207.58193872 3194.64694603]
total_rewards_mean           2756.679862976198
total_rewards_std            869.6417826207243
total_rewards_max            3238.253203404926
total_rewards_min            912.3329777004034
Number of train steps total  952000
Number of env steps total    953382
Number of rollouts total     0
Train Time (s)               146.73829846875742
(Previous) Eval Time (s)     18.549643251113594
Sample Time (s)              6.565228819847107
Epoch Time (s)               171.85317053971812
Total Train Time (s)         38462.40214847261
Epoch                        237
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:10:43.084517 UTC | [2020_01_10_09_29_40] Iteration #237 | Epoch Duration: 171.93873620033264
2020-01-10 20:10:43.084717 UTC | [2020_01_10_09_29_40] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056018047
Z variance train             0.0061194478
KL Divergence                10.439103
KL Loss                      1.0439104
QF Loss                      225.81834
VF Loss                      151.54788
Policy Loss                  -1265.2134
Q Predictions Mean           1259.872
Q Predictions Std            349.13965
Q Predictions Max            1635.4576
Q Predictions Min            67.40434
V Predictions Mean           1268.0754
V Predictions Std            349.28586
V Predictions Max            1650.3912
V Predictions Min            56.432724
Log Pis Mean                 0.08181206
Log Pis Std                  2.0459661
Log Pis Max                  7.9634123
Log Pis Min                  -5.223403
Policy mu Mean               0.028357266
Policy mu Std                0.93117565
Policy mu Max                2.2692683
Policy mu Min                -2.6432915
Policy log std Mean          -0.55985755
Policy log std Std           0.20781665
Policy log std Max           0.35324335
Policy log std Min           -1.2736619
Z mean eval                  0.088639095
Z variance eval              0.01341935
total_rewards                [3154.84668545 3187.48623973 1030.8000926  3173.77574461 3143.88313609
  867.87987904 3154.47582804  882.84893585 3157.0918013  2985.13037695]
total_rewards_mean           2473.821871965141
total_rewards_std            1014.7004268891288
total_rewards_max            3187.486239729402
total_rewards_min            867.8798790359037
Number of train steps total  956000
Number of env steps total    957940
Number of rollouts total     0
Train Time (s)               146.12141325697303
(Previous) Eval Time (s)     14.259055406786501
Sample Time (s)              6.412344399373978
Epoch Time (s)               166.7928130631335
Total Train Time (s)         38629.27950299019
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:13:29.968382 UTC | [2020_01_10_09_29_40] Iteration #238 | Epoch Duration: 166.88341522216797
2020-01-10 20:13:29.968750 UTC | [2020_01_10_09_29_40] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08928329
Z variance train             0.013439137
KL Divergence                9.527576
KL Loss                      0.95275766
QF Loss                      120.74653
VF Loss                      37.235085
Policy Loss                  -1245.5869
Q Predictions Mean           1245.3545
Q Predictions Std            363.00894
Q Predictions Max            1633.0608
Q Predictions Min            12.968132
V Predictions Mean           1248.7799
V Predictions Std            363.51727
V Predictions Max            1647.7454
V Predictions Min            20.644024
Log Pis Mean                 0.056092706
Log Pis Std                  2.057453
Log Pis Max                  6.1466045
Log Pis Min                  -5.154933
Policy mu Mean               0.0011893859
Policy mu Std                0.9315353
Policy mu Max                2.2088194
Policy mu Min                -2.7702017
Policy log std Mean          -0.55322564
Policy log std Std           0.20350482
Policy log std Max           0.20603216
Policy log std Min           -1.6012506
Z mean eval                  0.06785102
Z variance eval              0.0075648865
total_rewards                [3205.47703224 3188.3917814  3169.97266182 3163.83567107 3174.09895871
 3190.9184929  3190.70729963 3171.55834988 2086.15058778 3195.57931845]
total_rewards_mean           3073.669015389745
total_rewards_std            329.4097367399074
total_rewards_max            3205.477032241205
total_rewards_min            2086.150587784713
Number of train steps total  960000
Number of env steps total    962670
Number of rollouts total     0
Train Time (s)               146.48846512194723
(Previous) Eval Time (s)     20.931519312784076
Sample Time (s)              6.66870654374361
Epoch Time (s)               174.08869097847492
Total Train Time (s)         38803.45228195842
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:16:24.141261 UTC | [2020_01_10_09_29_40] Iteration #239 | Epoch Duration: 174.1723358631134
2020-01-10 20:16:24.141384 UTC | [2020_01_10_09_29_40] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.067415744
Z variance train             0.0075915223
KL Divergence                10.846565
KL Loss                      1.0846566
QF Loss                      5565.58
VF Loss                      395.7228
Policy Loss                  -1343.0134
Q Predictions Mean           1344.4711
Q Predictions Std            280.66086
Q Predictions Max            1675.2367
Q Predictions Min            72.19725
V Predictions Mean           1348.483
V Predictions Std            279.53372
V Predictions Max            1680.3345
V Predictions Min            67.64287
Log Pis Mean                 -0.17456947
Log Pis Std                  1.9552352
Log Pis Max                  5.674201
Log Pis Min                  -4.479603
Policy mu Mean               0.08584813
Policy mu Std                0.8839886
Policy mu Max                3.2440312
Policy mu Min                -2.6654718
Policy log std Mean          -0.55688745
Policy log std Std           0.2176382
Policy log std Max           0.19100112
Policy log std Min           -2.2814965
Z mean eval                  0.051195987
Z variance eval              0.0051161265
total_rewards                [2429.25925621 1144.8200183  2855.16024423 2951.72725147 3174.20570867
 3231.26949306 1644.63817802 3264.41578376 3152.95466858 2093.28124317]
total_rewards_mean           2594.1731845460436
total_rewards_std            705.6969002332894
total_rewards_max            3264.415783759296
total_rewards_min            1144.8200183023755
Number of train steps total  964000
Number of env steps total    967500
Number of rollouts total     0
Train Time (s)               147.6992121040821
(Previous) Eval Time (s)     14.513355141039938
Sample Time (s)              6.698913752101362
Epoch Time (s)               168.9114809972234
Total Train Time (s)         38972.44501193799
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:19:13.137374 UTC | [2020_01_10_09_29_40] Iteration #240 | Epoch Duration: 168.99587082862854
2020-01-10 20:19:13.137543 UTC | [2020_01_10_09_29_40] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05063785
Z variance train             0.005118621
KL Divergence                11.442223
KL Loss                      1.1442223
QF Loss                      63.533913
VF Loss                      52.642647
Policy Loss                  -1296.2855
Q Predictions Mean           1293.7745
Q Predictions Std            374.86227
Q Predictions Max            1657.7107
Q Predictions Min            32.30746
V Predictions Mean           1291.6752
V Predictions Std            375.50726
V Predictions Max            1644.1309
V Predictions Min            22.109287
Log Pis Mean                 -0.051572297
Log Pis Std                  1.9834808
Log Pis Max                  6.6720805
Log Pis Min                  -5.327504
Policy mu Mean               0.073675305
Policy mu Std                0.89526045
Policy mu Max                2.1292233
Policy mu Min                -2.4846172
Policy log std Mean          -0.5556306
Policy log std Std           0.19632463
Policy log std Max           0.13975888
Policy log std Min           -1.5018798
Z mean eval                  0.06658487
Z variance eval              0.006687531
total_rewards                [3159.97366734 3196.54646868 3188.86310079 2731.01352069 3153.43223942
 2221.8153721  1523.66908715 1163.8366748  3205.43962755 3113.98335346]
total_rewards_mean           2665.8573111966507
total_rewards_std            727.3988489377614
total_rewards_max            3205.4396275542645
total_rewards_min            1163.8366747972916
Number of train steps total  968000
Number of env steps total    972412
Number of rollouts total     0
Train Time (s)               144.86317006219178
(Previous) Eval Time (s)     18.05096070887521
Sample Time (s)              7.1457837033085525
Epoch Time (s)               170.05991447437555
Total Train Time (s)         39142.588645583484
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:22:03.282647 UTC | [2020_01_10_09_29_40] Iteration #241 | Epoch Duration: 170.14497327804565
2020-01-10 20:22:03.282791 UTC | [2020_01_10_09_29_40] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.066759184
Z variance train             0.006685277
KL Divergence                10.904228
KL Loss                      1.0904229
QF Loss                      162.62582
VF Loss                      62.109795
Policy Loss                  -1310.0206
Q Predictions Mean           1310.3716
Q Predictions Std            322.27786
Q Predictions Max            1655.3241
Q Predictions Min            81.92691
V Predictions Mean           1306.4946
V Predictions Std            319.88165
V Predictions Max            1650.2733
V Predictions Min            74.44698
Log Pis Mean                 0.05353523
Log Pis Std                  1.8922455
Log Pis Max                  8.192598
Log Pis Min                  -4.5308046
Policy mu Mean               0.08949598
Policy mu Std                0.9144202
Policy mu Max                2.6193886
Policy mu Min                -2.533258
Policy log std Mean          -0.5440715
Policy log std Std           0.19624673
Policy log std Max           0.10871047
Policy log std Min           -1.3919652
Z mean eval                  0.10416745
Z variance eval              0.005400548
total_rewards                [1103.7515457  3244.24405656 3249.58879568 3237.42454719 3258.14943842
 3243.81453285 3217.77923934 3231.72775709 3247.55952721 3277.06379351]
total_rewards_mean           3031.110323354237
total_rewards_std            642.6244700137333
total_rewards_max            3277.0637935071195
total_rewards_min            1103.7515457005886
Number of train steps total  972000
Number of env steps total    977380
Number of rollouts total     0
Train Time (s)               145.40129442699254
(Previous) Eval Time (s)     20.40553623205051
Sample Time (s)              6.482647660188377
Epoch Time (s)               172.28947831923142
Total Train Time (s)         39314.9669786212
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:24:55.662575 UTC | [2020_01_10_09_29_40] Iteration #242 | Epoch Duration: 172.37969207763672
2020-01-10 20:24:55.662711 UTC | [2020_01_10_09_29_40] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10321693
Z variance train             0.0053920075
KL Divergence                10.954416
KL Loss                      1.0954417
QF Loss                      190.05696
VF Loss                      42.837597
Policy Loss                  -1303.7395
Q Predictions Mean           1299.0925
Q Predictions Std            327.47754
Q Predictions Max            1631.8544
Q Predictions Min            46.479828
V Predictions Mean           1305.3517
V Predictions Std            326.24832
V Predictions Max            1635.2694
V Predictions Min            53.61577
Log Pis Mean                 -0.09990311
Log Pis Std                  1.9965086
Log Pis Max                  5.6319814
Log Pis Min                  -6.056772
Policy mu Mean               0.14546366
Policy mu Std                0.8754633
Policy mu Max                2.4912703
Policy mu Min                -2.5007656
Policy log std Mean          -0.55385303
Policy log std Std           0.19015396
Policy log std Max           -0.00035315752
Policy log std Min           -1.6419377
Z mean eval                  0.05924163
Z variance eval              0.0064363056
total_rewards                [ 119.38961618 3278.03812162 3265.98937022 3266.79070504 1070.94604989
 3268.94903887   99.39258835 3267.16656877 3257.04094069   80.42564108]
total_rewards_mean           2097.4128640714316
total_rewards_std            1457.3600162207726
total_rewards_max            3278.038121624696
total_rewards_min            80.42564107744381
Number of train steps total  976000
Number of env steps total    982322
Number of rollouts total     0
Train Time (s)               145.98776075989008
(Previous) Eval Time (s)     14.026358963921666
Sample Time (s)              6.951759946066886
Epoch Time (s)               166.96587966987863
Total Train Time (s)         39482.27217396302
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:27:42.969104 UTC | [2020_01_10_09_29_40] Iteration #243 | Epoch Duration: 167.30630016326904
2020-01-10 20:27:42.969238 UTC | [2020_01_10_09_29_40] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059902914
Z variance train             0.0064321226
KL Divergence                10.430395
KL Loss                      1.0430396
QF Loss                      95.29825
VF Loss                      32.24302
Policy Loss                  -1336.4694
Q Predictions Mean           1338.617
Q Predictions Std            319.4421
Q Predictions Max            1659.741
Q Predictions Min            58.92453
V Predictions Mean           1337.6831
V Predictions Std            317.70273
V Predictions Max            1656.699
V Predictions Min            47.67479
Log Pis Mean                 -0.10037038
Log Pis Std                  1.8779933
Log Pis Max                  6.1653447
Log Pis Min                  -6.058538
Policy mu Mean               0.074344076
Policy mu Std                0.8699933
Policy mu Max                2.3164382
Policy mu Min                -2.7727823
Policy log std Mean          -0.55651194
Policy log std Std           0.19983521
Policy log std Max           0.1804604
Policy log std Min           -1.1984806
Z mean eval                  0.060554452
Z variance eval              0.006890551
total_rewards                [3242.48197023 3198.55794028 3173.25508982 3216.17813607 1590.52338301
 3221.5968474  3193.7258823  3139.66350491 3190.98531109 3194.83997075]
total_rewards_mean           3036.1808035851514
total_rewards_std            482.60601743780296
total_rewards_max            3242.481970233206
total_rewards_min            1590.5233830077532
Number of train steps total  980000
Number of env steps total    987518
Number of rollouts total     0
Train Time (s)               144.9989154068753
(Previous) Eval Time (s)     17.869053110014647
Sample Time (s)              7.03780811605975
Epoch Time (s)               169.9057766329497
Total Train Time (s)         39652.2528442014
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:30:32.952520 UTC | [2020_01_10_09_29_40] Iteration #244 | Epoch Duration: 169.9831941127777
2020-01-10 20:30:32.952641 UTC | [2020_01_10_09_29_40] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061974514
Z variance train             0.0068967356
KL Divergence                10.928467
KL Loss                      1.0928468
QF Loss                      332.2621
VF Loss                      64.51529
Policy Loss                  -1296.0717
Q Predictions Mean           1292.6858
Q Predictions Std            367.06137
Q Predictions Max            1654.1469
Q Predictions Min            34.828915
V Predictions Mean           1293.5862
V Predictions Std            361.44397
V Predictions Max            1647.8292
V Predictions Min            38.588737
Log Pis Mean                 -0.08547972
Log Pis Std                  1.759966
Log Pis Max                  5.132791
Log Pis Min                  -4.6763973
Policy mu Mean               0.09827859
Policy mu Std                0.8957765
Policy mu Max                3.1289496
Policy mu Min                -2.5305965
Policy log std Mean          -0.5610481
Policy log std Std           0.19078243
Policy log std Max           0.17761755
Policy log std Min           -1.6661191
Z mean eval                  0.046259984
Z variance eval              0.006207711
total_rewards                [ 939.81704848 1881.75815158  959.11715075 1135.87596728 1822.95105616
 3249.22059651 2778.58484337 2635.50621611 1904.65920068 2477.41999283]
total_rewards_mean           1978.4910223757738
total_rewards_std            761.7395071725294
total_rewards_max            3249.2205965125236
total_rewards_min            939.8170484805974
Number of train steps total  984000
Number of env steps total    992387
Number of rollouts total     0
Train Time (s)               142.42142319492996
(Previous) Eval Time (s)     13.430396963842213
Sample Time (s)              5.952852681279182
Epoch Time (s)               161.80467284005135
Total Train Time (s)         39814.144329792354
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:33:14.846923 UTC | [2020_01_10_09_29_40] Iteration #245 | Epoch Duration: 161.8941831588745
2020-01-10 20:33:14.847086 UTC | [2020_01_10_09_29_40] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0462569
Z variance train             0.0062092673
KL Divergence                11.731373
KL Loss                      1.1731373
QF Loss                      117.45046
VF Loss                      75.77471
Policy Loss                  -1311.5521
Q Predictions Mean           1310.3698
Q Predictions Std            335.3324
Q Predictions Max            1631.6985
Q Predictions Min            11.927322
V Predictions Mean           1305.6532
V Predictions Std            330.7557
V Predictions Max            1625.834
V Predictions Min            25.523666
Log Pis Mean                 -0.18915255
Log Pis Std                  2.0035427
Log Pis Max                  6.5660543
Log Pis Min                  -8.0823
Policy mu Mean               0.19486623
Policy mu Std                0.8830979
Policy mu Max                2.5385163
Policy mu Min                -2.5569503
Policy log std Mean          -0.52744544
Policy log std Std           0.1800986
Policy log std Max           0.036475718
Policy log std Min           -1.1275373
Z mean eval                  0.080373615
Z variance eval              0.010793969
total_rewards                [1714.02455249 1581.81166039 1852.76513588 2285.94125002 1563.35951646
 2327.49679381 2154.66236608 1711.5864011  1370.46469652 2597.15375364]
total_rewards_mean           1915.9266126391035
total_rewards_std            380.4391962149136
total_rewards_max            2597.153753637372
total_rewards_min            1370.464696517789
Number of train steps total  988000
Number of env steps total    997235
Number of rollouts total     0
Train Time (s)               146.77310866303742
(Previous) Eval Time (s)     10.962924876715988
Sample Time (s)              6.5402266113087535
Epoch Time (s)               164.27626015106216
Total Train Time (s)         39978.50038562482
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:35:59.205860 UTC | [2020_01_10_09_29_40] Iteration #246 | Epoch Duration: 164.3586459159851
2020-01-10 20:35:59.206027 UTC | [2020_01_10_09_29_40] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07968204
Z variance train             0.010776053
KL Divergence                9.705473
KL Loss                      0.9705473
QF Loss                      143.51825
VF Loss                      63.28758
Policy Loss                  -1303.5023
Q Predictions Mean           1304.6132
Q Predictions Std            339.87756
Q Predictions Max            1651.5013
Q Predictions Min            -12.586295
V Predictions Mean           1302.2751
V Predictions Std            337.4465
V Predictions Max            1651.1105
V Predictions Min            -20.539059
Log Pis Mean                 0.07746289
Log Pis Std                  2.1493077
Log Pis Max                  6.1896596
Log Pis Min                  -4.861538
Policy mu Mean               0.08271225
Policy mu Std                0.8998842
Policy mu Max                2.4478667
Policy mu Min                -2.6886816
Policy log std Mean          -0.57217395
Policy log std Std           0.20119895
Policy log std Max           0.10747707
Policy log std Min           -1.3804433
Z mean eval                  0.026369298
Z variance eval              0.0042760754
total_rewards                [1441.84347753  530.63245066 1922.92603142  806.93299233 1638.20552941
 3213.82787212  988.60609394 1841.07562099 1705.88651471 1000.02435221]
total_rewards_mean           1508.9960935329277
total_rewards_std            723.0478953937402
total_rewards_max            3213.827872118769
total_rewards_min            530.632450655654
Number of train steps total  992000
Number of env steps total    1002053
Number of rollouts total     0
Train Time (s)               144.73041157703847
(Previous) Eval Time (s)     10.120493368711323
Sample Time (s)              6.582149412017316
Epoch Time (s)               161.4330543577671
Total Train Time (s)         40140.020057824906
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:38:40.727998 UTC | [2020_01_10_09_29_40] Iteration #247 | Epoch Duration: 161.52184128761292
2020-01-10 20:38:40.728165 UTC | [2020_01_10_09_29_40] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026174355
Z variance train             0.0042824564
KL Divergence                11.980463
KL Loss                      1.1980463
QF Loss                      148.36319
VF Loss                      95.34366
Policy Loss                  -1277.4508
Q Predictions Mean           1276.6104
Q Predictions Std            351.8466
Q Predictions Max            1644.6353
Q Predictions Min            55.947098
V Predictions Mean           1274.4631
V Predictions Std            352.197
V Predictions Max            1634.188
V Predictions Min            45.693172
Log Pis Mean                 -0.1288454
Log Pis Std                  1.9369202
Log Pis Max                  4.8126593
Log Pis Min                  -4.413276
Policy mu Mean               -0.0019956157
Policy mu Std                0.9297588
Policy mu Max                2.0511935
Policy mu Min                -2.7072964
Policy log std Mean          -0.5605872
Policy log std Std           0.19124126
Policy log std Max           0.14696598
Policy log std Min           -1.1182259
Z mean eval                  0.052477874
Z variance eval              0.011025125
total_rewards                [3278.43657171 3254.77109593 2741.45495973 1922.95164637 2531.01401989
 3220.55764375 3178.179806   2499.861426    814.27512471 3251.74185325]
total_rewards_mean           2669.3244147333085
total_rewards_std            752.801292117439
total_rewards_max            3278.4365717080727
total_rewards_min            814.2751247129557
Number of train steps total  996000
Number of env steps total    1006750
Number of rollouts total     0
Train Time (s)               145.94963231030852
(Previous) Eval Time (s)     15.305644453968853
Sample Time (s)              5.428575455211103
Epoch Time (s)               166.68385221948847
Total Train Time (s)         40306.78269315045
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:41:27.493413 UTC | [2020_01_10_09_29_40] Iteration #248 | Epoch Duration: 166.76512050628662
2020-01-10 20:41:27.493596 UTC | [2020_01_10_09_29_40] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05121951
Z variance train             0.011041684
KL Divergence                9.237389
KL Loss                      0.9237389
QF Loss                      84.55032
VF Loss                      25.260956
Policy Loss                  -1299.5247
Q Predictions Mean           1297.6462
Q Predictions Std            348.45883
Q Predictions Max            1644.4247
Q Predictions Min            22.766047
V Predictions Mean           1298.4017
V Predictions Std            348.43985
V Predictions Max            1638.7373
V Predictions Min            13.191998
Log Pis Mean                 0.008332014
Log Pis Std                  1.9842494
Log Pis Max                  6.669015
Log Pis Min                  -4.971892
Policy mu Mean               0.08359661
Policy mu Std                0.91402805
Policy mu Max                3.2004817
Policy mu Min                -2.5786915
Policy log std Mean          -0.5496252
Policy log std Std           0.19153172
Policy log std Max           0.094869316
Policy log std Min           -1.1136132
Z mean eval                  0.07533321
Z variance eval              0.0064702383
total_rewards                [3200.04897155 1917.36956573 3250.21351937 3198.60824838 3274.61832081
 3175.03426768 2215.65256526 3249.26170744 3237.58708955 1848.67539976]
total_rewards_mean           2856.7069655536516
total_rewards_std            572.2072899759238
total_rewards_max            3274.618320814042
total_rewards_min            1848.6753997649876
Number of train steps total  1000000
Number of env steps total    1011579
Number of rollouts total     0
Train Time (s)               145.49076796835288
(Previous) Eval Time (s)     16.48547147307545
Sample Time (s)              6.659035811666399
Epoch Time (s)               168.63527525309473
Total Train Time (s)         40475.50396858528
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:44:16.219143 UTC | [2020_01_10_09_29_40] Iteration #249 | Epoch Duration: 168.72540187835693
2020-01-10 20:44:16.219333 UTC | [2020_01_10_09_29_40] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07665755
Z variance train             0.006500312
KL Divergence                10.972008
KL Loss                      1.0972008
QF Loss                      154.4475
VF Loss                      113.89018
Policy Loss                  -1314.4128
Q Predictions Mean           1306.4689
Q Predictions Std            344.96146
Q Predictions Max            1661.3918
Q Predictions Min            19.086807
V Predictions Mean           1305.8063
V Predictions Std            344.44302
V Predictions Max            1653.7291
V Predictions Min            21.634838
Log Pis Mean                 -0.009461809
Log Pis Std                  2.0349567
Log Pis Max                  7.339894
Log Pis Min                  -4.394263
Policy mu Mean               0.0056192577
Policy mu Std                0.9368796
Policy mu Max                2.9449916
Policy mu Min                -2.5863771
Policy log std Mean          -0.5625083
Policy log std Std           0.20206127
Policy log std Max           0.17208856
Policy log std Min           -1.2043632
Z mean eval                  0.1095858
Z variance eval              0.010854102
total_rewards                [2992.58318284 3214.13029875 3246.29426806  952.9842046  3282.56494689
 3222.16585959 3296.41125483 3249.95468888 3223.76697874 1438.29764572]
total_rewards_mean           2811.915332889688
total_rewards_std            819.243944627407
total_rewards_max            3296.411254830503
total_rewards_min            952.984204602949
Number of train steps total  1004000
Number of env steps total    1016300
Number of rollouts total     0
Train Time (s)               143.41608621412888
(Previous) Eval Time (s)     18.882340982090682
Sample Time (s)              6.714723460841924
Epoch Time (s)               169.0131506570615
Total Train Time (s)         40644.61162112141
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:47:05.328541 UTC | [2020_01_10_09_29_40] Iteration #250 | Epoch Duration: 169.10908770561218
2020-01-10 20:47:05.328670 UTC | [2020_01_10_09_29_40] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11211052
Z variance train             0.010903606
KL Divergence                9.825413
KL Loss                      0.98254126
QF Loss                      129.97351
VF Loss                      157.16379
Policy Loss                  -1273.6326
Q Predictions Mean           1274.0818
Q Predictions Std            365.80457
Q Predictions Max            1635.3484
Q Predictions Min            28.954895
V Predictions Mean           1283.6147
V Predictions Std            361.81903
V Predictions Max            1644.5491
V Predictions Min            40.066887
Log Pis Mean                 -0.08131063
Log Pis Std                  1.9371549
Log Pis Max                  6.90359
Log Pis Min                  -5.6151094
Policy mu Mean               0.06865432
Policy mu Std                0.9187215
Policy mu Max                2.5542126
Policy mu Min                -2.5705156
Policy log std Mean          -0.55570483
Policy log std Std           0.20023343
Policy log std Max           0.028871775
Policy log std Min           -2.5742905
Z mean eval                  0.038193993
Z variance eval              0.008515102
total_rewards                [3284.50850919 3267.78698867 3240.23688169 3236.9595573  3230.84817188
 3257.94912868 2143.48293731 2457.56866818 3273.64306663 1908.10356506]
total_rewards_mean           2930.1087474579435
total_rewards_std            513.0761049623148
total_rewards_max            3284.508509193185
total_rewards_min            1908.1035650573826
Number of train steps total  1008000
Number of env steps total    1021134
Number of rollouts total     0
Train Time (s)               145.37394086970016
(Previous) Eval Time (s)     16.789822390768677
Sample Time (s)              6.704747870564461
Epoch Time (s)               168.8685111310333
Total Train Time (s)         40813.55998497736
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:49:54.282533 UTC | [2020_01_10_09_29_40] Iteration #251 | Epoch Duration: 168.95376205444336
2020-01-10 20:49:54.282728 UTC | [2020_01_10_09_29_40] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040436123
Z variance train             0.008489342
KL Divergence                10.509478
KL Loss                      1.0509478
QF Loss                      169.09691
VF Loss                      93.95876
Policy Loss                  -1311.4259
Q Predictions Mean           1311.671
Q Predictions Std            345.39948
Q Predictions Max            1657.0753
Q Predictions Min            51.991604
V Predictions Mean           1317.7742
V Predictions Std            344.2999
V Predictions Max            1657.9224
V Predictions Min            62.365025
Log Pis Mean                 0.13952744
Log Pis Std                  1.9630319
Log Pis Max                  6.512572
Log Pis Min                  -4.634295
Policy mu Mean               0.026609777
Policy mu Std                0.9419574
Policy mu Max                2.5298095
Policy mu Min                -2.5597157
Policy log std Mean          -0.57233113
Policy log std Std           0.2021665
Policy log std Max           -0.01517874
Policy log std Min           -1.4801594
Z mean eval                  0.076191664
Z variance eval              0.0053393925
total_rewards                [3211.81009269 3241.99328026 3211.40898323 3285.80581051 3238.19350968
 3252.89225346 3225.96981455 3244.06771492 3265.49122339 3219.64374059]
total_rewards_mean           3239.7276423290227
total_rewards_std            22.716880401622465
total_rewards_max            3285.8058105128707
total_rewards_min            3211.4089832348723
Number of train steps total  1012000
Number of env steps total    1026060
Number of rollouts total     0
Train Time (s)               147.3758864137344
(Previous) Eval Time (s)     21.770517596043646
Sample Time (s)              6.712472146376967
Epoch Time (s)               175.85887615615502
Total Train Time (s)         40989.499383418355
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:52:50.225371 UTC | [2020_01_10_09_29_40] Iteration #252 | Epoch Duration: 175.94252133369446
2020-01-10 20:52:50.225498 UTC | [2020_01_10_09_29_40] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07639581
Z variance train             0.0053372383
KL Divergence                11.36584
KL Loss                      1.136584
QF Loss                      71.27022
VF Loss                      23.011528
Policy Loss                  -1273.8789
Q Predictions Mean           1273.2793
Q Predictions Std            368.09946
Q Predictions Max            1655.8024
Q Predictions Min            13.460779
V Predictions Mean           1275.5938
V Predictions Std            366.59155
V Predictions Max            1658.6282
V Predictions Min            23.47624
Log Pis Mean                 -0.1470856
Log Pis Std                  1.9853071
Log Pis Max                  5.708585
Log Pis Min                  -6.886676
Policy mu Mean               -0.05483986
Policy mu Std                0.9150031
Policy mu Max                2.416924
Policy mu Min                -2.5958457
Policy log std Mean          -0.54997045
Policy log std Std           0.1843489
Policy log std Max           0.081725
Policy log std Min           -1.0863476
Z mean eval                  0.059210926
Z variance eval              0.007844249
total_rewards                [3232.3666459  3247.92190564 3251.8781084  3230.43132043 2040.36856303
 3231.39788294 3271.597424   3212.29609612 3213.66226459 3238.29822424]
total_rewards_mean           3117.0218435275456
total_rewards_std            359.27280176786985
total_rewards_max            3271.5974239956613
total_rewards_min            2040.3685630308685
Number of train steps total  1016000
Number of env steps total    1030789
Number of rollouts total     0
Train Time (s)               146.5026957509108
(Previous) Eval Time (s)     17.410964160691947
Sample Time (s)              6.673672367818654
Epoch Time (s)               170.5873322794214
Total Train Time (s)         41160.170364423655
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:55:40.899580 UTC | [2020_01_10_09_29_40] Iteration #253 | Epoch Duration: 170.67398405075073
2020-01-10 20:55:40.899747 UTC | [2020_01_10_09_29_40] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06016637
Z variance train             0.007830158
KL Divergence                10.087848
KL Loss                      1.0087848
QF Loss                      101.40823
VF Loss                      40.899464
Policy Loss                  -1314.2485
Q Predictions Mean           1314.3868
Q Predictions Std            356.36945
Q Predictions Max            1641.0854
Q Predictions Min            48.91371
V Predictions Mean           1315.8018
V Predictions Std            355.07016
V Predictions Max            1638.371
V Predictions Min            57.92091
Log Pis Mean                 0.10615035
Log Pis Std                  2.1576095
Log Pis Max                  7.800659
Log Pis Min                  -4.6509037
Policy mu Mean               0.04558171
Policy mu Std                0.93342084
Policy mu Max                2.4129517
Policy mu Min                -2.769648
Policy log std Mean          -0.55209845
Policy log std Std           0.18210495
Policy log std Max           0.0433771
Policy log std Min           -1.3730334
Z mean eval                  0.072784856
Z variance eval              0.008813512
total_rewards                [2305.81494578 3298.66239751 3266.39213672 3260.9551478  1579.70794205
 3264.91324321 2392.86223212 2219.73408191 3239.42925802 3244.11147826]
total_rewards_mean           2807.2582863381604
total_rewards_std            593.3310464528272
total_rewards_max            3298.6623975119733
total_rewards_min            1579.7079420467899
Number of train steps total  1020000
Number of env steps total    1035545
Number of rollouts total     0
Train Time (s)               146.3375492100604
(Previous) Eval Time (s)     15.774301246274263
Sample Time (s)              6.724715183489025
Epoch Time (s)               168.83656563982368
Total Train Time (s)         41329.095719947014
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:58:29.826653 UTC | [2020_01_10_09_29_40] Iteration #254 | Epoch Duration: 168.92678213119507
2020-01-10 20:58:29.826790 UTC | [2020_01_10_09_29_40] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.072434925
Z variance train             0.00880125
KL Divergence                10.047277
KL Loss                      1.0047277
QF Loss                      157.8294
VF Loss                      24.206215
Policy Loss                  -1305.8109
Q Predictions Mean           1304.9136
Q Predictions Std            341.4956
Q Predictions Max            1632.1143
Q Predictions Min            56.7538
V Predictions Mean           1304.844
V Predictions Std            341.46268
V Predictions Max            1633.7347
V Predictions Min            65.313965
Log Pis Mean                 0.086924076
Log Pis Std                  1.9900208
Log Pis Max                  8.209562
Log Pis Min                  -4.6847663
Policy mu Mean               0.062232938
Policy mu Std                0.92154795
Policy mu Max                2.7818792
Policy mu Min                -3.047345
Policy log std Mean          -0.5618699
Policy log std Std           0.19807926
Policy log std Max           0.2307787
Policy log std Min           -1.515353
Z mean eval                  0.0488797
Z variance eval              0.01262789
total_rewards                [3274.61098155 3286.6457803  3342.2114885  3224.51744007 3278.34856442
 3276.32525505 3300.55250892 3302.90776678 3266.66098182 1172.38091636]
total_rewards_mean           3072.5161683762044
total_rewards_std            634.0130851458291
total_rewards_max            3342.2114884952734
total_rewards_min            1172.380916355135
Number of train steps total  1024000
Number of env steps total    1040356
Number of rollouts total     0
Train Time (s)               147.0017728288658
(Previous) Eval Time (s)     20.40300140483305
Sample Time (s)              6.573367516044527
Epoch Time (s)               173.97814174974337
Total Train Time (s)         41503.15354047017
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:01:23.886384 UTC | [2020_01_10_09_29_40] Iteration #255 | Epoch Duration: 174.0594940185547
2020-01-10 21:01:23.886517 UTC | [2020_01_10_09_29_40] Iteration #255 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04942974
Z variance train             0.012599006
KL Divergence                9.065099
KL Loss                      0.9065099
QF Loss                      89.53288
VF Loss                      20.689487
Policy Loss                  -1351.5094
Q Predictions Mean           1347.944
Q Predictions Std            325.69028
Q Predictions Max            1636.8333
Q Predictions Min            19.461143
V Predictions Mean           1353.7163
V Predictions Std            326.2303
V Predictions Max            1642.4902
V Predictions Min            11.333882
Log Pis Mean                 -0.17841583
Log Pis Std                  1.7986994
Log Pis Max                  4.8667727
Log Pis Min                  -4.3317866
Policy mu Mean               0.08741806
Policy mu Std                0.8740134
Policy mu Max                2.2893577
Policy mu Min                -2.668862
Policy log std Mean          -0.5502791
Policy log std Std           0.17703402
Policy log std Max           0.26186365
Policy log std Min           -1.0737277
Z mean eval                  0.10960647
Z variance eval              0.013717298
total_rewards                [1038.72689246 3220.56052708 3224.85597022 3190.2220599  1023.6004755
 1411.60934398 3279.62563044 3185.50192741 3200.56467017 3219.35777415]
total_rewards_mean           2599.4625271318946
total_rewards_std            949.0925429577792
total_rewards_max            3279.6256304442118
total_rewards_min            1023.6004755046686
Number of train steps total  1028000
Number of env steps total    1045040
Number of rollouts total     0
Train Time (s)               146.99532445473596
(Previous) Eval Time (s)     17.680713267996907
Sample Time (s)              5.713918935973197
Epoch Time (s)               170.38995665870607
Total Train Time (s)         41673.63154352363
Epoch                        256
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:04:14.366177 UTC | [2020_01_10_09_29_40] Iteration #256 | Epoch Duration: 170.47956156730652
2020-01-10 21:04:14.366316 UTC | [2020_01_10_09_29_40] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10787133
Z variance train             0.013729392
KL Divergence                9.506571
KL Loss                      0.95065707
QF Loss                      131.72104
VF Loss                      75.98601
Policy Loss                  -1337.3538
Q Predictions Mean           1339.0339
Q Predictions Std            311.6285
Q Predictions Max            1666.2233
Q Predictions Min            69.66871
V Predictions Mean           1340.3083
V Predictions Std            311.53815
V Predictions Max            1660.8165
V Predictions Min            59.276295
Log Pis Mean                 -0.041573554
Log Pis Std                  2.005029
Log Pis Max                  9.840002
Log Pis Min                  -5.0018883
Policy mu Mean               0.06610695
Policy mu Std                0.9269949
Policy mu Max                3.3507843
Policy mu Min                -2.8097186
Policy log std Mean          -0.5310116
Policy log std Std           0.19073953
Policy log std Max           0.12680757
Policy log std Min           -1.2676837
Z mean eval                  0.12776208
Z variance eval              0.0137247
total_rewards                [2809.52501572 3282.98508363 3280.35738408 3274.53699555 3282.02869398
 2471.6537663  3277.11894701 3264.41222845 3315.08599758 2787.06409023]
total_rewards_mean           3104.476820253112
total_rewards_std            284.81530752357867
total_rewards_max            3315.085997581034
total_rewards_min            2471.653766302295
Number of train steps total  1032000
Number of env steps total    1049876
Number of rollouts total     0
Train Time (s)               145.64005059190094
(Previous) Eval Time (s)     20.40977912582457
Sample Time (s)              6.548028311692178
Epoch Time (s)               172.5978580294177
Total Train Time (s)         41846.31936924346
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:07:07.056192 UTC | [2020_01_10_09_29_40] Iteration #257 | Epoch Duration: 172.68978714942932
2020-01-10 21:07:07.056313 UTC | [2020_01_10_09_29_40] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12652571
Z variance train             0.013686702
KL Divergence                10.340406
KL Loss                      1.0340407
QF Loss                      184.7815
VF Loss                      24.950594
Policy Loss                  -1341.7695
Q Predictions Mean           1341.4343
Q Predictions Std            326.4883
Q Predictions Max            1655.5138
Q Predictions Min            115.22581
V Predictions Mean           1341.6667
V Predictions Std            326.7338
V Predictions Max            1653.7107
V Predictions Min            102.10441
Log Pis Mean                 0.023175195
Log Pis Std                  1.9501446
Log Pis Max                  6.0634227
Log Pis Min                  -5.9400287
Policy mu Mean               0.00087207434
Policy mu Std                0.90045285
Policy mu Max                1.7590847
Policy mu Min                -2.61051
Policy log std Mean          -0.56348324
Policy log std Std           0.19156252
Policy log std Max           0.08278006
Policy log std Min           -1.3362908
Z mean eval                  0.09086414
Z variance eval              0.0071852775
total_rewards                [3305.72950118 3327.01289809 3284.40540848 3325.62459764 3333.27914627
 3357.20781917 3045.58407838 3324.77178706 1975.53876006 3324.08864981]
total_rewards_mean           3160.3242646141966
total_rewards_std            403.8648787019335
total_rewards_max            3357.2078191687497
total_rewards_min            1975.5387600602917
Number of train steps total  1036000
Number of env steps total    1054645
Number of rollouts total     0
Train Time (s)               146.02310721529648
(Previous) Eval Time (s)     20.698125054128468
Sample Time (s)              6.419100626837462
Epoch Time (s)               173.1403328962624
Total Train Time (s)         42019.53748504305
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:10:00.277753 UTC | [2020_01_10_09_29_40] Iteration #258 | Epoch Duration: 173.2213499546051
2020-01-10 21:10:00.277881 UTC | [2020_01_10_09_29_40] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.090979464
Z variance train             0.007187332
KL Divergence                10.525228
KL Loss                      1.0525228
QF Loss                      95.46636
VF Loss                      33.060062
Policy Loss                  -1328.9025
Q Predictions Mean           1329.4493
Q Predictions Std            333.25763
Q Predictions Max            1658.386
Q Predictions Min            87.5879
V Predictions Mean           1325.858
V Predictions Std            331.67905
V Predictions Max            1654.1135
V Predictions Min            82.31169
Log Pis Mean                 -0.2699245
Log Pis Std                  1.9244105
Log Pis Max                  5.5635405
Log Pis Min                  -5.041562
Policy mu Mean               0.024073184
Policy mu Std                0.8760091
Policy mu Max                2.4566245
Policy mu Min                -2.6790504
Policy log std Mean          -0.55381954
Policy log std Std           0.18628095
Policy log std Max           0.047905147
Policy log std Min           -1.2163401
Z mean eval                  0.040360343
Z variance eval              0.006687918
total_rewards                [3244.60762536 3232.53350008 2223.97576011 3225.51192871 3214.27210989
 3237.01778892 3235.88301471 3249.25208811 3226.8230634  2508.48195581]
total_rewards_mean           3059.8358835097533
total_rewards_std            352.71329711841935
total_rewards_max            3249.2520881123332
total_rewards_min            2223.9757601059587
Number of train steps total  1040000
Number of env steps total    1059405
Number of rollouts total     0
Train Time (s)               145.76043757703155
(Previous) Eval Time (s)     20.947491948027164
Sample Time (s)              6.4656537543050945
Epoch Time (s)               173.1735832793638
Total Train Time (s)         42192.791220272426
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:12:53.534081 UTC | [2020_01_10_09_29_40] Iteration #259 | Epoch Duration: 173.256108045578
2020-01-10 21:12:53.534218 UTC | [2020_01_10_09_29_40] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040549688
Z variance train             0.006675533
KL Divergence                10.548161
KL Loss                      1.0548161
QF Loss                      97.75244
VF Loss                      42.856163
Policy Loss                  -1328.1244
Q Predictions Mean           1326.8123
Q Predictions Std            348.48566
Q Predictions Max            1651.2185
Q Predictions Min            46.723263
V Predictions Mean           1330.8468
V Predictions Std            348.98557
V Predictions Max            1650.4404
V Predictions Min            51.98342
Log Pis Mean                 0.3629653
Log Pis Std                  2.1973934
Log Pis Max                  8.433202
Log Pis Min                  -3.9628444
Policy mu Mean               -0.13665861
Policy mu Std                0.95987064
Policy mu Max                3.4321716
Policy mu Min                -2.9210832
Policy log std Mean          -0.5572416
Policy log std Std           0.18877934
Policy log std Max           0.11536604
Policy log std Min           -1.3786808
Z mean eval                  0.0713379
Z variance eval              0.0045223217
total_rewards                [3000.7328217  3256.74435504 3279.43531127 3251.87562223 3226.03752894
 1013.22360769 3237.66657356 3240.4030927  3219.59919815 3224.88637195]
total_rewards_mean           2995.060448322426
total_rewards_std            664.7292504659581
total_rewards_max            3279.4353112706426
total_rewards_min            1013.2236076859402
Number of train steps total  1044000
Number of env steps total    1064592
Number of rollouts total     0
Train Time (s)               145.73198511404917
(Previous) Eval Time (s)     17.15019849780947
Sample Time (s)              6.731592633295804
Epoch Time (s)               169.61377624515444
Total Train Time (s)         42362.51179106394
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:15:43.259688 UTC | [2020_01_10_09_29_40] Iteration #260 | Epoch Duration: 169.725346326828
2020-01-10 21:15:43.259941 UTC | [2020_01_10_09_29_40] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07070905
Z variance train             0.004522928
KL Divergence                11.5144415
KL Loss                      1.1514442
QF Loss                      76.31075
VF Loss                      20.914677
Policy Loss                  -1373.4569
Q Predictions Mean           1373.6018
Q Predictions Std            304.9773
Q Predictions Max            1685.0868
Q Predictions Min            16.09866
V Predictions Mean           1374.1367
V Predictions Std            302.4204
V Predictions Max            1685.7279
V Predictions Min            18.530285
Log Pis Mean                 -0.055086117
Log Pis Std                  1.9633709
Log Pis Max                  6.9622564
Log Pis Min                  -3.7741559
Policy mu Mean               0.027452031
Policy mu Std                0.88216263
Policy mu Max                2.1494727
Policy mu Min                -3.1947389
Policy log std Mean          -0.5691921
Policy log std Std           0.1813987
Policy log std Max           0.11183131
Policy log std Min           -1.2183787
Z mean eval                  0.037549503
Z variance eval              0.006403947
total_rewards                [3314.07889294 2854.45294322 3258.35222549 3307.04475546 3115.89645428
 2245.28543127 2250.88927137 3311.64969285 3196.16743839 3214.15720317]
total_rewards_mean           3006.797430843096
total_rewards_std            400.755942571596
total_rewards_max            3314.078892941549
total_rewards_min            2245.2854312665327
Number of train steps total  1048000
Number of env steps total    1069709
Number of rollouts total     0
Train Time (s)               145.9610556201078
(Previous) Eval Time (s)     19.714416924864054
Sample Time (s)              6.528638034593314
Epoch Time (s)               172.20411057956517
Total Train Time (s)         42534.80135531584
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:18:35.548702 UTC | [2020_01_10_09_29_40] Iteration #261 | Epoch Duration: 172.28859448432922
2020-01-10 21:18:35.548835 UTC | [2020_01_10_09_29_40] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03680312
Z variance train             0.0064216247
KL Divergence                10.686115
KL Loss                      1.0686115
QF Loss                      119.88929
VF Loss                      43.761658
Policy Loss                  -1323.0791
Q Predictions Mean           1322.3
Q Predictions Std            346.34427
Q Predictions Max            1661.0505
Q Predictions Min            32.971058
V Predictions Mean           1325.3462
V Predictions Std            347.86743
V Predictions Max            1653.4225
V Predictions Min            31.6427
Log Pis Mean                 -0.13134965
Log Pis Std                  2.0557528
Log Pis Max                  8.245989
Log Pis Min                  -7.3622
Policy mu Mean               -0.072351515
Policy mu Std                0.93310577
Policy mu Max                2.2197678
Policy mu Min                -2.998882
Policy log std Mean          -0.5504074
Policy log std Std           0.19626148
Policy log std Max           0.14901507
Policy log std Min           -1.3220134
Z mean eval                  0.054895908
Z variance eval              0.0076029287
total_rewards                [2364.60506127 3246.25399625 3274.9568408  3276.84954779 3313.06267793
 1355.39387758 3022.86946008 1416.51575972 3298.2768473  3249.30515883]
total_rewards_mean           2781.808922755008
total_rewards_std            748.4882272173519
total_rewards_max            3313.0626779274367
total_rewards_min            1355.3938775840386
Number of train steps total  1052000
Number of env steps total    1074694
Number of rollouts total     0
Train Time (s)               144.5569778168574
(Previous) Eval Time (s)     15.533818481024355
Sample Time (s)              6.609171808231622
Epoch Time (s)               166.69996810611337
Total Train Time (s)         42701.58162201289
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:21:22.336264 UTC | [2020_01_10_09_29_40] Iteration #262 | Epoch Duration: 166.78729009628296
2020-01-10 21:21:22.336552 UTC | [2020_01_10_09_29_40] Iteration #262 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055127196
Z variance train             0.0075978884
KL Divergence                10.356884
KL Loss                      1.0356884
QF Loss                      52.062916
VF Loss                      14.081993
Policy Loss                  -1356.1279
Q Predictions Mean           1356.8058
Q Predictions Std            318.74194
Q Predictions Max            1669.3943
Q Predictions Min            44.442184
V Predictions Mean           1357.5732
V Predictions Std            318.70355
V Predictions Max            1662.615
V Predictions Min            57.13508
Log Pis Mean                 -0.15850057
Log Pis Std                  1.9238324
Log Pis Max                  5.989903
Log Pis Min                  -4.3466244
Policy mu Mean               -0.07766757
Policy mu Std                0.88737404
Policy mu Max                2.279351
Policy mu Min                -2.635359
Policy log std Mean          -0.5384092
Policy log std Std           0.17997473
Policy log std Max           0.06455994
Policy log std Min           -1.1791621
Z mean eval                  0.08434327
Z variance eval              0.009629432
total_rewards                [3251.72559166 3256.97921678 3206.46400967 3110.14242397 3262.8763347
 1417.89467502 1798.0646369  3259.09043274 3270.5478489  2005.46995647]
total_rewards_mean           2783.9255126813136
total_rewards_std            697.3883303872374
total_rewards_max            3270.5478488969015
total_rewards_min            1417.8946750219395
Number of train steps total  1056000
Number of env steps total    1079615
Number of rollouts total     0
Train Time (s)               146.3626493080519
(Previous) Eval Time (s)     18.277172528207302
Sample Time (s)              6.687321670353413
Epoch Time (s)               171.32714350661263
Total Train Time (s)         42872.993225062266
Epoch                        263
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:24:13.752203 UTC | [2020_01_10_09_29_40] Iteration #263 | Epoch Duration: 171.4154543876648
2020-01-10 21:24:13.752329 UTC | [2020_01_10_09_29_40] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08459825
Z variance train             0.009639903
KL Divergence                10.243152
KL Loss                      1.0243152
QF Loss                      66.32045
VF Loss                      23.607101
Policy Loss                  -1303.7365
Q Predictions Mean           1302.96
Q Predictions Std            395.61462
Q Predictions Max            1652.5131
Q Predictions Min            21.294174
V Predictions Mean           1303.4011
V Predictions Std            392.9095
V Predictions Max            1650.0405
V Predictions Min            22.944473
Log Pis Mean                 -0.12483683
Log Pis Std                  1.9226606
Log Pis Max                  6.8271184
Log Pis Min                  -4.671927
Policy mu Mean               -0.020065451
Policy mu Std                0.8812056
Policy mu Max                1.8763641
Policy mu Min                -2.5767095
Policy log std Mean          -0.53034735
Policy log std Std           0.19201873
Policy log std Max           0.12709355
Policy log std Min           -1.1265202
Z mean eval                  0.07325568
Z variance eval              0.013784436
total_rewards                [3288.29983429 3237.15951941 3281.32566775 3181.49547224 1046.28736529
 3287.76890907 3283.53776533 1227.0336984  3238.19844308 3287.09192716]
total_rewards_mean           2835.8198602008347
total_rewards_std            851.1558279666906
total_rewards_max            3288.2998342853
total_rewards_min            1046.287365285606
Number of train steps total  1060000
Number of env steps total    1084508
Number of rollouts total     0
Train Time (s)               145.75700219208375
(Previous) Eval Time (s)     18.56624122383073
Sample Time (s)              6.3970593507401645
Epoch Time (s)               170.72030276665464
Total Train Time (s)         43043.79126317287
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:27:04.553501 UTC | [2020_01_10_09_29_40] Iteration #264 | Epoch Duration: 170.8010675907135
2020-01-10 21:27:04.553682 UTC | [2020_01_10_09_29_40] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07351704
Z variance train             0.013809711
KL Divergence                9.094154
KL Loss                      0.9094154
QF Loss                      99.648865
VF Loss                      59.831272
Policy Loss                  -1326.1991
Q Predictions Mean           1328.7122
Q Predictions Std            307.32245
Q Predictions Max            1638.5266
Q Predictions Min            49.693073
V Predictions Mean           1331.8682
V Predictions Std            307.28165
V Predictions Max            1642.4437
V Predictions Min            54.664284
Log Pis Mean                 0.110026225
Log Pis Std                  1.8214982
Log Pis Max                  5.9668345
Log Pis Min                  -4.19483
Policy mu Mean               0.060024787
Policy mu Std                0.93083745
Policy mu Max                2.5613477
Policy mu Min                -2.8628364
Policy log std Mean          -0.5583489
Policy log std Std           0.18824634
Policy log std Max           0.0017014146
Policy log std Min           -1.4375172
Z mean eval                  0.05888052
Z variance eval              0.0124596
total_rewards                [3311.97871196 2294.66033948 3270.82308164 3330.22594672 3295.62495371
 3285.05374672 3092.02411278 2077.26796422 1840.41596066 3379.39313158]
total_rewards_mean           2917.7467949468078
total_rewards_std            568.0404972338611
total_rewards_max            3379.3931315812724
total_rewards_min            1840.415960658128
Number of train steps total  1064000
Number of env steps total    1089604
Number of rollouts total     0
Train Time (s)               145.06743214000016
(Previous) Eval Time (s)     18.590545499231666
Sample Time (s)              6.443865248467773
Epoch Time (s)               170.1018428876996
Total Train Time (s)         43213.97608151706
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:29:54.742129 UTC | [2020_01_10_09_29_40] Iteration #265 | Epoch Duration: 170.18831253051758
2020-01-10 21:29:54.742335 UTC | [2020_01_10_09_29_40] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06505147
Z variance train             0.012443798
KL Divergence                10.184924
KL Loss                      1.0184925
QF Loss                      141.08383
VF Loss                      93.76894
Policy Loss                  -1316.7924
Q Predictions Mean           1315.7754
Q Predictions Std            361.21704
Q Predictions Max            1671.8595
Q Predictions Min            -5.2814245
V Predictions Mean           1309.6179
V Predictions Std            359.14496
V Predictions Max            1666.5654
V Predictions Min            5.0857377
Log Pis Mean                 0.011427283
Log Pis Std                  1.910704
Log Pis Max                  6.074136
Log Pis Min                  -4.1896954
Policy mu Mean               0.0002063606
Policy mu Std                0.8653471
Policy mu Max                2.1746979
Policy mu Min                -2.431737
Policy log std Mean          -0.54935676
Policy log std Std           0.18260421
Policy log std Max           0.052002013
Policy log std Min           -1.3718269
Z mean eval                  0.11710944
Z variance eval              0.014031364
total_rewards                [3264.90655164 3265.55476396 3264.0806588  3261.63537095 3304.38118347
 3305.79553773 3279.54556489 3312.50613246 3296.93397936 3256.53274723]
total_rewards_mean           3281.187249048523
total_rewards_std            20.41383132074692
total_rewards_max            3312.5061324619664
total_rewards_min            3256.532747226583
Number of train steps total  1068000
Number of env steps total    1094572
Number of rollouts total     0
Train Time (s)               148.04424513923004
(Previous) Eval Time (s)     18.604806773830205
Sample Time (s)              6.511710066813976
Epoch Time (s)               173.16076197987422
Total Train Time (s)         43387.21808380168
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:32:47.988235 UTC | [2020_01_10_09_29_40] Iteration #266 | Epoch Duration: 173.24576115608215
2020-01-10 21:32:47.988393 UTC | [2020_01_10_09_29_40] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.117406234
Z variance train             0.014033882
KL Divergence                8.940515
KL Loss                      0.8940515
QF Loss                      186.01172
VF Loss                      19.898031
Policy Loss                  -1323.2067
Q Predictions Mean           1322.018
Q Predictions Std            380.3011
Q Predictions Max            1704.6173
Q Predictions Min            87.880936
V Predictions Mean           1321.5607
V Predictions Std            380.9115
V Predictions Max            1705.2767
V Predictions Min            89.87561
Log Pis Mean                 -0.24280895
Log Pis Std                  1.8945011
Log Pis Max                  5.4553823
Log Pis Min                  -4.6248817
Policy mu Mean               -0.10845692
Policy mu Std                0.888096
Policy mu Max                2.0558636
Policy mu Min                -2.6368065
Policy log std Mean          -0.54077846
Policy log std Std           0.18750754
Policy log std Max           0.10389006
Policy log std Min           -1.1854911
Z mean eval                  0.051703732
Z variance eval              0.01381771
total_rewards                [3281.74524837 3263.84502674 3236.75730384 3249.26581121 3279.80724857
 3258.04162006 3237.67237765 1997.58701999 3213.899821   3242.1101186 ]
total_rewards_mean           3126.073159601855
total_rewards_std            376.67035874015664
total_rewards_max            3281.7452483669445
total_rewards_min            1997.587019986894
Number of train steps total  1072000
Number of env steps total    1099464
Number of rollouts total     0
Train Time (s)               145.18514317274094
(Previous) Eval Time (s)     17.80998237291351
Sample Time (s)              6.633028455078602
Epoch Time (s)               169.62815400073305
Total Train Time (s)         43556.923325714655
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:35:37.697190 UTC | [2020_01_10_09_29_40] Iteration #267 | Epoch Duration: 169.7086718082428
2020-01-10 21:35:37.697371 UTC | [2020_01_10_09_29_40] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050669808
Z variance train             0.0138413105
KL Divergence                9.7141695
KL Loss                      0.97141695
QF Loss                      181.4459
VF Loss                      104.76063
Policy Loss                  -1316.5646
Q Predictions Mean           1314.333
Q Predictions Std            351.90903
Q Predictions Max            1674.2985
Q Predictions Min            23.673016
V Predictions Mean           1316.7146
V Predictions Std            348.3906
V Predictions Max            1686.0251
V Predictions Min            41.53008
Log Pis Mean                 -0.30451035
Log Pis Std                  2.0488951
Log Pis Max                  6.810998
Log Pis Min                  -6.389635
Policy mu Mean               0.057490963
Policy mu Std                0.8594996
Policy mu Max                2.3423352
Policy mu Min                -2.687389
Policy log std Mean          -0.5139198
Policy log std Std           0.17736495
Policy log std Max           0.02131188
Policy log std Min           -1.3120202
Z mean eval                  0.11697068
Z variance eval              0.012629894
total_rewards                [3268.12399011 3295.48179745 3280.39439551 3309.20702193 3268.76311136
 3282.14674474 3266.46572016 3307.5404355  3280.47782399 3276.75028427]
total_rewards_mean           3283.5351325019046
total_rewards_std            14.806340495788337
total_rewards_max            3309.207021929841
total_rewards_min            3266.465720158063
Number of train steps total  1076000
Number of env steps total    1104616
Number of rollouts total     0
Train Time (s)               144.92782127205282
(Previous) Eval Time (s)     21.951666799839586
Sample Time (s)              6.777062485925853
Epoch Time (s)               173.65655055781826
Total Train Time (s)         43730.66236760467
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:38:31.437805 UTC | [2020_01_10_09_29_40] Iteration #268 | Epoch Duration: 173.74031257629395
2020-01-10 21:38:31.437945 UTC | [2020_01_10_09_29_40] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11558548
Z variance train             0.012630482
KL Divergence                8.896521
KL Loss                      0.8896521
QF Loss                      57.814323
VF Loss                      23.908691
Policy Loss                  -1306.84
Q Predictions Mean           1305.5885
Q Predictions Std            370.7414
Q Predictions Max            1677.8491
Q Predictions Min            71.35292
V Predictions Mean           1304.8135
V Predictions Std            370.8133
V Predictions Max            1680.2434
V Predictions Min            71.58719
Log Pis Mean                 -0.26512754
Log Pis Std                  2.0597808
Log Pis Max                  5.7699122
Log Pis Min                  -9.414009
Policy mu Mean               0.03818522
Policy mu Std                0.92313856
Policy mu Max                2.3881264
Policy mu Min                -2.7867935
Policy log std Mean          -0.52365154
Policy log std Std           0.17127341
Policy log std Max           0.04610282
Policy log std Min           -1.0634283
Z mean eval                  0.02818427
Z variance eval              0.009642854
total_rewards                [2261.74179525 3280.91385514 3256.84937606 3295.5407301  3245.55897259
 3248.25707245 3250.39244356 1988.07234469 3287.50121275 3265.54204889]
total_rewards_mean           3038.0369851491273
total_rewards_std            460.93164776301023
total_rewards_max            3295.540730097645
total_rewards_min            1988.072344692497
Number of train steps total  1080000
Number of env steps total    1109669
Number of rollouts total     0
Train Time (s)               144.2484599109739
(Previous) Eval Time (s)     20.343364670407027
Sample Time (s)              6.767699681222439
Epoch Time (s)               171.35952426260337
Total Train Time (s)         43902.11565898964
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:41:22.893047 UTC | [2020_01_10_09_29_40] Iteration #269 | Epoch Duration: 171.45500922203064
2020-01-10 21:41:22.893176 UTC | [2020_01_10_09_29_40] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027916204
Z variance train             0.009644714
KL Divergence                9.383908
KL Loss                      0.93839085
QF Loss                      92.28869
VF Loss                      33.0118
Policy Loss                  -1316.7007
Q Predictions Mean           1317.8953
Q Predictions Std            395.76166
Q Predictions Max            1667.3114
Q Predictions Min            41.32195
V Predictions Mean           1319.7465
V Predictions Std            396.08755
V Predictions Max            1659.5321
V Predictions Min            33.92838
Log Pis Mean                 -0.17508908
Log Pis Std                  1.7962562
Log Pis Max                  5.627092
Log Pis Min                  -5.008176
Policy mu Mean               -0.09767447
Policy mu Std                0.8567794
Policy mu Max                2.4284136
Policy mu Min                -2.5931458
Policy log std Mean          -0.52441144
Policy log std Std           0.18558264
Policy log std Max           -0.019512057
Policy log std Min           -1.1242902
Z mean eval                  0.07796111
Z variance eval              0.01038216
total_rewards                [1383.98442944 3317.2561893  3333.46076623  882.99040582 3283.19017177
 3320.10798734 3308.30547299 3316.96688123 3277.57334864 3346.15325359]
total_rewards_mean           2876.998890634471
total_rewards_std            879.1385495829118
total_rewards_max            3346.153253587758
total_rewards_min            882.9904058181088
Number of train steps total  1084000
Number of env steps total    1114592
Number of rollouts total     0
Train Time (s)               146.3485283688642
(Previous) Eval Time (s)     18.65588471572846
Sample Time (s)              6.6449660724028945
Epoch Time (s)               171.64937915699556
Total Train Time (s)         44073.848252420314
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:44:14.628398 UTC | [2020_01_10_09_29_40] Iteration #270 | Epoch Duration: 171.73512601852417
2020-01-10 21:44:14.628536 UTC | [2020_01_10_09_29_40] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07768105
Z variance train             0.010400057
KL Divergence                9.473209
KL Loss                      0.94732094
QF Loss                      76.00362
VF Loss                      24.193064
Policy Loss                  -1312.5743
Q Predictions Mean           1310.568
Q Predictions Std            363.237
Q Predictions Max            1680.213
Q Predictions Min            47.57578
V Predictions Mean           1311.0525
V Predictions Std            364.77756
V Predictions Max            1679.0122
V Predictions Min            46.97683
Log Pis Mean                 0.004917633
Log Pis Std                  2.0585697
Log Pis Max                  6.503751
Log Pis Min                  -4.9394917
Policy mu Mean               -0.02144821
Policy mu Std                0.9358529
Policy mu Max                2.6555781
Policy mu Min                -2.6546168
Policy log std Mean          -0.5300794
Policy log std Std           0.19256987
Policy log std Max           0.05426365
Policy log std Min           -1.1336223
Z mean eval                  0.08404223
Z variance eval              0.013137785
total_rewards                [3323.78456133 3308.45560753 3306.13182379 3317.19478729 3326.90650389
 3320.9971571  3216.41605361 3277.34842823 3304.26646534 3299.556214  ]
total_rewards_mean           3300.1057602114315
total_rewards_std            31.069214352241
total_rewards_max            3326.906503885265
total_rewards_min            3216.416053611791
Number of train steps total  1088000
Number of env steps total    1119678
Number of rollouts total     0
Train Time (s)               145.41740274662152
(Previous) Eval Time (s)     21.559464083984494
Sample Time (s)              6.4488152069970965
Epoch Time (s)               173.4256820376031
Total Train Time (s)         44247.35354598146
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:47:08.136263 UTC | [2020_01_10_09_29_40] Iteration #271 | Epoch Duration: 173.50763750076294
2020-01-10 21:47:08.136389 UTC | [2020_01_10_09_29_40] Iteration #271 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.082903124
Z variance train             0.013141595
KL Divergence                8.826567
KL Loss                      0.8826567
QF Loss                      115.8031
VF Loss                      90.124565
Policy Loss                  -1373.5623
Q Predictions Mean           1371.4017
Q Predictions Std            296.45297
Q Predictions Max            1682.3204
Q Predictions Min            153.87932
V Predictions Mean           1374.4755
V Predictions Std            295.30618
V Predictions Max            1688.843
V Predictions Min            170.30049
Log Pis Mean                 0.041203666
Log Pis Std                  2.1183932
Log Pis Max                  6.7249823
Log Pis Min                  -5.9252896
Policy mu Mean               -0.0056603947
Policy mu Std                0.93545145
Policy mu Max                1.9632121
Policy mu Min                -2.851307
Policy log std Mean          -0.5368472
Policy log std Std           0.1807777
Policy log std Max           0.08478755
Policy log std Min           -1.3057327
Z mean eval                  0.05198543
Z variance eval              0.010814766
total_rewards                [3332.32211741 3272.6720937  3312.48612517 3321.43514284 3245.7060017
 3313.41412616 3300.5656747  3311.31552052 3320.32454569 3315.7079517 ]
total_rewards_mean           3304.5949299592817
total_rewards_std            24.721920480499247
total_rewards_max            3332.3221174052437
total_rewards_min            3245.70600169581
Number of train steps total  1092000
Number of env steps total    1124772
Number of rollouts total     0
Train Time (s)               145.6992896818556
(Previous) Eval Time (s)     18.400769882835448
Sample Time (s)              6.625570455566049
Epoch Time (s)               170.72563002025709
Total Train Time (s)         44418.15552233858
Epoch                        272
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:49:58.944476 UTC | [2020_01_10_09_29_40] Iteration #272 | Epoch Duration: 170.8079903125763
2020-01-10 21:49:58.944633 UTC | [2020_01_10_09_29_40] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051556855
Z variance train             0.010811528
KL Divergence                9.4196205
KL Loss                      0.94196206
QF Loss                      64.73553
VF Loss                      21.114576
Policy Loss                  -1319.1708
Q Predictions Mean           1317.1813
Q Predictions Std            366.57626
Q Predictions Max            1670.9647
Q Predictions Min            37.946785
V Predictions Mean           1317.528
V Predictions Std            365.89633
V Predictions Max            1676.6742
V Predictions Min            40.211334
Log Pis Mean                 -0.141501
Log Pis Std                  1.8491375
Log Pis Max                  5.8315973
Log Pis Min                  -5.6927214
Policy mu Mean               0.027637484
Policy mu Std                0.9118579
Policy mu Max                2.1636598
Policy mu Min                -2.5757754
Policy log std Mean          -0.52099997
Policy log std Std           0.16991296
Policy log std Max           0.08649516
Policy log std Min           -1.1033366
Z mean eval                  0.05612368
Z variance eval              0.009239411
total_rewards                [3271.31460057 3246.09132621 3307.32456342 3279.6069429  3289.89022069
 3292.07208504 3305.71688619 3318.07519688 3306.23588453 3289.90776021]
total_rewards_mean           3290.623546664795
total_rewards_std            19.96131020036125
total_rewards_max            3318.0751968823497
total_rewards_min            3246.0913262064364
Number of train steps total  1096000
Number of env steps total    1129815
Number of rollouts total     0
Train Time (s)               145.48933298932388
(Previous) Eval Time (s)     21.679159166757017
Sample Time (s)              5.536710950545967
Epoch Time (s)               172.70520310662687
Total Train Time (s)         44590.94288106216
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:52:51.733911 UTC | [2020_01_10_09_29_40] Iteration #273 | Epoch Duration: 172.7891697883606
2020-01-10 21:52:51.734036 UTC | [2020_01_10_09_29_40] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05579398
Z variance train             0.009245539
KL Divergence                10.249001
KL Loss                      1.0249001
QF Loss                      56.875893
VF Loss                      20.170769
Policy Loss                  -1351.5991
Q Predictions Mean           1351.6057
Q Predictions Std            345.6838
Q Predictions Max            1686.1448
Q Predictions Min            187.5339
V Predictions Mean           1354.4155
V Predictions Std            345.53717
V Predictions Max            1687.0168
V Predictions Min            190.55746
Log Pis Mean                 0.05283741
Log Pis Std                  1.9840362
Log Pis Max                  6.054175
Log Pis Min                  -5.311124
Policy mu Mean               -0.06723761
Policy mu Std                0.9438282
Policy mu Max                2.0576682
Policy mu Min                -2.8322356
Policy log std Mean          -0.5295764
Policy log std Std           0.16552407
Policy log std Max           0.047615707
Policy log std Min           -1.0582924
Z mean eval                  0.079890445
Z variance eval              0.007742175
total_rewards                [3326.65898177 3287.0094135  3326.7743287  1084.79658734 3262.21624444
 1155.49883391   78.24184779 3272.95895645 3264.93824854 3311.56249497]
total_rewards_mean           2537.0655937424112
total_rewards_std            1186.177309210794
total_rewards_max            3326.7743287016765
total_rewards_min            78.24184778998202
Number of train steps total  1100000
Number of env steps total    1134868
Number of rollouts total     0
Train Time (s)               145.22382943099365
(Previous) Eval Time (s)     14.20501323370263
Sample Time (s)              6.484412474557757
Epoch Time (s)               165.91325513925403
Total Train Time (s)         44756.94708560221
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:55:37.742127 UTC | [2020_01_10_09_29_40] Iteration #274 | Epoch Duration: 166.00799250602722
2020-01-10 21:55:37.742292 UTC | [2020_01_10_09_29_40] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07700069
Z variance train             0.0077559473
KL Divergence                10.391483
KL Loss                      1.0391483
QF Loss                      80.81796
VF Loss                      95.45936
Policy Loss                  -1325.3986
Q Predictions Mean           1324.4761
Q Predictions Std            380.6289
Q Predictions Max            1688.0162
Q Predictions Min            22.265293
V Predictions Mean           1326.2996
V Predictions Std            377.40665
V Predictions Max            1696.5837
V Predictions Min            26.98543
Log Pis Mean                 -0.29153967
Log Pis Std                  1.7445133
Log Pis Max                  6.1236515
Log Pis Min                  -4.638823
Policy mu Mean               0.058724787
Policy mu Std                0.8256279
Policy mu Max                1.9810733
Policy mu Min                -2.753378
Policy log std Mean          -0.5052955
Policy log std Std           0.16208518
Policy log std Max           0.03263682
Policy log std Min           -0.94476736
Z mean eval                  0.11836388
Z variance eval              0.005971825
total_rewards                [3336.31851461 3296.27667046 3299.23732071 3341.52332598 3191.24319879
 3346.06077505 1918.90275103 1711.91448491 3330.1803891  2741.49112395]
total_rewards_mean           2951.3148554603126
total_rewards_std            595.2715546187302
total_rewards_max            3346.0607750471227
total_rewards_min            1711.9144849141696
Number of train steps total  1104000
Number of env steps total    1140017
Number of rollouts total     0
Train Time (s)               147.8326997840777
(Previous) Eval Time (s)     16.42310171201825
Sample Time (s)              6.580154286697507
Epoch Time (s)               170.83595578279346
Total Train Time (s)         44927.85533275409
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:58:28.652358 UTC | [2020_01_10_09_29_40] Iteration #275 | Epoch Duration: 170.9099564552307
2020-01-10 21:58:28.652481 UTC | [2020_01_10_09_29_40] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11838539
Z variance train             0.0059716934
KL Divergence                10.682071
KL Loss                      1.0682071
QF Loss                      59.29387
VF Loss                      18.11324
Policy Loss                  -1301.5352
Q Predictions Mean           1300.9558
Q Predictions Std            402.30902
Q Predictions Max            1662.6196
Q Predictions Min            21.28495
V Predictions Mean           1300.7731
V Predictions Std            401.376
V Predictions Max            1661.2167
V Predictions Min            15.667551
Log Pis Mean                 -0.1371145
Log Pis Std                  1.9507303
Log Pis Max                  6.310603
Log Pis Min                  -4.6131177
Policy mu Mean               -0.056604635
Policy mu Std                0.8889539
Policy mu Max                2.0399702
Policy mu Min                -2.6138575
Policy log std Mean          -0.49740767
Policy log std Std           0.1773146
Policy log std Max           0.22496969
Policy log std Min           -1.0123711
Z mean eval                  0.19641204
Z variance eval              0.0072893957
total_rewards                [3204.5620713  3281.38692287 3255.12971237 3285.34842849 3255.05728222
 3250.90640084 3298.66501931 2374.80282238 3305.78801834 3230.66343182]
total_rewards_mean           3174.2310109928035
total_rewards_std            268.0983327106182
total_rewards_max            3305.788018339302
total_rewards_min            2374.802822383971
Number of train steps total  1108000
Number of env steps total    1145082
Number of rollouts total     0
Train Time (s)               144.98620701301843
(Previous) Eval Time (s)     21.05193952191621
Sample Time (s)              5.671075578778982
Epoch Time (s)               171.70922211371362
Total Train Time (s)         45099.759917513
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:01:20.562851 UTC | [2020_01_10_09_29_40] Iteration #276 | Epoch Duration: 171.9102487564087
2020-01-10 22:01:20.563084 UTC | [2020_01_10_09_29_40] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19735038
Z variance train             0.00729741
KL Divergence                10.072971
KL Loss                      1.0072972
QF Loss                      61.64677
VF Loss                      30.67656
Policy Loss                  -1357.4624
Q Predictions Mean           1359.2542
Q Predictions Std            316.30722
Q Predictions Max            1677.0857
Q Predictions Min            22.445137
V Predictions Mean           1360.3713
V Predictions Std            314.51355
V Predictions Max            1666.1259
V Predictions Min            27.085907
Log Pis Mean                 -0.37710434
Log Pis Std                  1.9837018
Log Pis Max                  5.71673
Log Pis Min                  -6.8537493
Policy mu Mean               0.03602469
Policy mu Std                0.8579127
Policy mu Max                1.8340368
Policy mu Min                -2.554149
Policy log std Mean          -0.5045174
Policy log std Std           0.16030063
Policy log std Max           0.15672529
Policy log std Min           -1.0178907
Z mean eval                  0.10674896
Z variance eval              0.009324485
total_rewards                [3336.79402955 3287.55196701 3302.90225368 3342.70127909 1213.08562205
 3305.30693365 3281.24634849 3252.09619587 3268.61236173 3283.40615142]
total_rewards_mean           3087.370314256135
total_rewards_std            625.3297963325882
total_rewards_max            3342.7012790926715
total_rewards_min            1213.085622054916
Number of train steps total  1112000
Number of env steps total    1150121
Number of rollouts total     0
Train Time (s)               144.66236899700016
(Previous) Eval Time (s)     17.008021775633097
Sample Time (s)              6.548200198449194
Epoch Time (s)               168.21859097108245
Total Train Time (s)         45268.06505991239
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:04:08.871696 UTC | [2020_01_10_09_29_40] Iteration #277 | Epoch Duration: 168.3084466457367
2020-01-10 22:04:08.871900 UTC | [2020_01_10_09_29_40] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.105865
Z variance train             0.009292414
KL Divergence                9.496149
KL Loss                      0.94961494
QF Loss                      281.32892
VF Loss                      164.19342
Policy Loss                  -1349.6584
Q Predictions Mean           1343.1921
Q Predictions Std            379.97903
Q Predictions Max            1681.973
Q Predictions Min            46.994038
V Predictions Mean           1350.5188
V Predictions Std            389.09247
V Predictions Max            1682.4503
V Predictions Min            18.375942
Log Pis Mean                 -0.02112418
Log Pis Std                  1.8564267
Log Pis Max                  5.73903
Log Pis Min                  -3.9305866
Policy mu Mean               -0.063390665
Policy mu Std                0.8914594
Policy mu Max                2.2830985
Policy mu Min                -2.7766907
Policy log std Mean          -0.5391624
Policy log std Std           0.17255823
Policy log std Max           0.22805852
Policy log std Min           -1.0855907
Z mean eval                  0.0855435
Z variance eval              0.006981025
total_rewards                [3362.78834344 3320.09408411 3332.58866329 3325.67533202 3313.43762464
 3310.16329077 3311.57704917 3339.73234597 3310.72611204 3317.73792795]
total_rewards_mean           3324.4520773388053
total_rewards_std            15.857440718018584
total_rewards_max            3362.788343437158
total_rewards_min            3310.1632907722483
Number of train steps total  1116000
Number of env steps total    1155185
Number of rollouts total     0
Train Time (s)               145.11831737915054
(Previous) Eval Time (s)     21.00976261496544
Sample Time (s)              6.57251477940008
Epoch Time (s)               172.70059477351606
Total Train Time (s)         45440.84738696739
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:07:01.657056 UTC | [2020_01_10_09_29_40] Iteration #278 | Epoch Duration: 172.7850091457367
2020-01-10 22:07:01.657240 UTC | [2020_01_10_09_29_40] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.085238226
Z variance train             0.006981696
KL Divergence                10.284195
KL Loss                      1.0284195
QF Loss                      53.77223
VF Loss                      16.816591
Policy Loss                  -1393.8335
Q Predictions Mean           1394.3842
Q Predictions Std            325.7699
Q Predictions Max            1689.3328
Q Predictions Min            122.81843
V Predictions Mean           1394.6742
V Predictions Std            326.02997
V Predictions Max            1696.9958
V Predictions Min            101.61005
Log Pis Mean                 -0.033065934
Log Pis Std                  1.8677477
Log Pis Max                  5.9404097
Log Pis Min                  -5.1899595
Policy mu Mean               0.0017712141
Policy mu Std                0.8893397
Policy mu Max                1.8015609
Policy mu Min                -2.5000703
Policy log std Mean          -0.53839606
Policy log std Std           0.17300166
Policy log std Max           0.061531544
Policy log std Min           -1.0831598
Z mean eval                  0.11255954
Z variance eval              0.0055803577
total_rewards                [3389.44216272 3354.14295035 3351.94973012 3378.22853879 3396.71402828
  274.50400883 3397.75767849 3361.77166761 3340.98446307 3381.09791819]
total_rewards_mean           3062.6593146461573
total_rewards_std            929.5726074952839
total_rewards_max            3397.7576784936573
total_rewards_min            274.50400883183903
Number of train steps total  1120000
Number of env steps total    1160119
Number of rollouts total     0
Train Time (s)               143.2906942809932
(Previous) Eval Time (s)     17.763303013984114
Sample Time (s)              6.762037120759487
Epoch Time (s)               167.8160344157368
Total Train Time (s)         45608.74440831179
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:09:49.556930 UTC | [2020_01_10_09_29_40] Iteration #279 | Epoch Duration: 167.89949870109558
2020-01-10 22:09:49.557185 UTC | [2020_01_10_09_29_40] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10391796
Z variance train             0.0055805137
KL Divergence                10.813967
KL Loss                      1.0813967
QF Loss                      118.82155
VF Loss                      42.52241
Policy Loss                  -1382.3909
Q Predictions Mean           1384.4325
Q Predictions Std            362.999
Q Predictions Max            1712.7163
Q Predictions Min            64.26929
V Predictions Mean           1386.0183
V Predictions Std            362.638
V Predictions Max            1707.5387
V Predictions Min            55.890877
Log Pis Mean                 0.12898773
Log Pis Std                  2.0669727
Log Pis Max                  7.6402407
Log Pis Min                  -4.361372
Policy mu Mean               0.12543269
Policy mu Std                0.94431466
Policy mu Max                2.3169851
Policy mu Min                -2.5701952
Policy log std Mean          -0.50678205
Policy log std Std           0.19071369
Policy log std Max           0.10135704
Policy log std Min           -1.0618688
Z mean eval                  0.05241842
Z variance eval              0.009692203
total_rewards                [3362.97573581 3355.33504314 3383.49184945  925.21051178 3324.50120347
 3386.47252569 3343.17571322 3335.2013043  3314.20930342 3358.54719167]
total_rewards_mean           3108.9120381944103
total_rewards_std            728.2368144882656
total_rewards_max            3386.4725256868014
total_rewards_min            925.210511783521
Number of train steps total  1124000
Number of env steps total    1165971
Number of rollouts total     0
Train Time (s)               146.35333629185334
(Previous) Eval Time (s)     18.739922549109906
Sample Time (s)              7.675674469675869
Epoch Time (s)               172.7689333106391
Total Train Time (s)         45781.59927303344
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:12:42.418414 UTC | [2020_01_10_09_29_40] Iteration #280 | Epoch Duration: 172.86104321479797
2020-01-10 22:12:42.418767 UTC | [2020_01_10_09_29_40] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05238427
Z variance train             0.009684439
KL Divergence                9.304028
KL Loss                      0.93040276
QF Loss                      73.46348
VF Loss                      28.56308
Policy Loss                  -1362.6007
Q Predictions Mean           1362.7178
Q Predictions Std            321.1584
Q Predictions Max            1681.1107
Q Predictions Min            54.971443
V Predictions Mean           1365.2273
V Predictions Std            321.7799
V Predictions Max            1680.9065
V Predictions Min            60.869347
Log Pis Mean                 -0.23003456
Log Pis Std                  1.892707
Log Pis Max                  7.0417175
Log Pis Min                  -6.181931
Policy mu Mean               0.008838895
Policy mu Std                0.8587015
Policy mu Max                2.3635263
Policy mu Min                -2.4132965
Policy log std Mean          -0.52522373
Policy log std Std           0.18995126
Policy log std Max           0.06730729
Policy log std Min           -1.1335045
Z mean eval                  0.07565077
Z variance eval              0.018376
total_rewards                [3266.11186675 3312.32438612 3276.76288613 3276.18330378 3324.73600001
 3350.07833477 3304.79132122 3329.90213028 3321.24782385 3335.24637104]
total_rewards_mean           3309.738442395335
total_rewards_std            26.813619859717594
total_rewards_max            3350.078334769925
total_rewards_min            3266.111866751249
Number of train steps total  1128000
Number of env steps total    1171226
Number of rollouts total     0
Train Time (s)               144.25698833120987
(Previous) Eval Time (s)     21.452027049846947
Sample Time (s)              6.734987233765423
Epoch Time (s)               172.44400261482224
Total Train Time (s)         45954.143922994845
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:15:34.969440 UTC | [2020_01_10_09_29_40] Iteration #281 | Epoch Duration: 172.55038571357727
2020-01-10 22:15:34.969736 UTC | [2020_01_10_09_29_40] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07242254
Z variance train             0.018425249
KL Divergence                7.954337
KL Loss                      0.7954337
QF Loss                      119.00234
VF Loss                      125.41235
Policy Loss                  -1345.5557
Q Predictions Mean           1343.893
Q Predictions Std            357.8609
Q Predictions Max            1686.3431
Q Predictions Min            23.65605
V Predictions Mean           1346.9841
V Predictions Std            355.92572
V Predictions Max            1690.7806
V Predictions Min            57.887035
Log Pis Mean                 0.0033908635
Log Pis Std                  1.9074723
Log Pis Max                  7.0624866
Log Pis Min                  -5.1956887
Policy mu Mean               -0.05015039
Policy mu Std                0.953672
Policy mu Max                2.358354
Policy mu Min                -2.6894696
Policy log std Mean          -0.52977747
Policy log std Std           0.18594614
Policy log std Max           -0.016557395
Policy log std Min           -1.0978655
Z mean eval                  0.061444312
Z variance eval              0.011687221
total_rewards                [3344.26415059 3335.84861282 3370.70995289 3345.34183242 3295.12785205
 3377.20701898 3346.60836279 3359.58936953 3286.28192742 3375.32949939]
total_rewards_mean           3343.6308578874655
total_rewards_std            29.722571751622095
total_rewards_max            3377.207018978938
total_rewards_min            3286.281927416716
Number of train steps total  1132000
Number of env steps total    1176506
Number of rollouts total     0
Train Time (s)               146.0141533613205
(Previous) Eval Time (s)     21.826333648059517
Sample Time (s)              6.630605896003544
Epoch Time (s)               174.47109290538356
Total Train Time (s)         46128.69316040166
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:18:29.521318 UTC | [2020_01_10_09_29_40] Iteration #282 | Epoch Duration: 174.55141830444336
2020-01-10 22:18:29.521497 UTC | [2020_01_10_09_29_40] Iteration #282 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060955513
Z variance train             0.01165877
KL Divergence                9.210377
KL Loss                      0.9210377
QF Loss                      69.05072
VF Loss                      25.915384
Policy Loss                  -1337.2163
Q Predictions Mean           1335.3881
Q Predictions Std            399.18988
Q Predictions Max            1682.6115
Q Predictions Min            66.042656
V Predictions Mean           1335.3313
V Predictions Std            400.49332
V Predictions Max            1683.5402
V Predictions Min            61.21101
Log Pis Mean                 -0.06965301
Log Pis Std                  2.1115856
Log Pis Max                  6.217176
Log Pis Min                  -5.0268707
Policy mu Mean               -0.113343336
Policy mu Std                0.9355604
Policy mu Max                2.086697
Policy mu Min                -2.658726
Policy log std Mean          -0.52644354
Policy log std Std           0.1922604
Policy log std Max           0.012077093
Policy log std Min           -1.2196329
Z mean eval                  0.066690594
Z variance eval              0.0059261704
total_rewards                [3342.53495431 3317.29075138 3321.94934923 3327.27207098 3288.3424985
 3325.30739923 1062.11648059 3323.67135673 3256.93360676 3309.84076864]
total_rewards_mean           3087.5259236361385
total_rewards_std            675.521450234153
total_rewards_max            3342.534954308816
total_rewards_min            1062.1164805910269
Number of train steps total  1136000
Number of env steps total    1181869
Number of rollouts total     0
Train Time (s)               146.55468334816396
(Previous) Eval Time (s)     16.991674962919205
Sample Time (s)              5.813466972671449
Epoch Time (s)               169.35982528375462
Total Train Time (s)         46298.13479803782
Epoch                        283
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:21:18.966538 UTC | [2020_01_10_09_29_40] Iteration #283 | Epoch Duration: 169.44484162330627
2020-01-10 22:21:18.966845 UTC | [2020_01_10_09_29_40] Iteration #283 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.065711394
Z variance train             0.0059366887
KL Divergence                10.718416
KL Loss                      1.0718416
QF Loss                      199.373
VF Loss                      104.5083
Policy Loss                  -1333.1614
Q Predictions Mean           1337.0808
Q Predictions Std            362.44876
Q Predictions Max            1685.9192
Q Predictions Min            40.65577
V Predictions Mean           1338.592
V Predictions Std            365.15604
V Predictions Max            1693.9257
V Predictions Min            58.426582
Log Pis Mean                 0.109058395
Log Pis Std                  2.184902
Log Pis Max                  5.9190702
Log Pis Min                  -4.6454935
Policy mu Mean               0.076617755
Policy mu Std                0.95622635
Policy mu Max                2.4810176
Policy mu Min                -2.6864102
Policy log std Mean          -0.51797837
Policy log std Std           0.18757452
Policy log std Max           0.0111352205
Policy log std Min           -1.1892918
Z mean eval                  0.13579625
Z variance eval              0.0057169534
total_rewards                [ 959.86726593 3305.83193547 3300.60354622 1982.17911304 3363.4145911
 3323.46144754 3315.81121544 3332.58957966 3334.92255623 3304.66867712]
total_rewards_mean           2952.33499277586
total_rewards_std            775.3272349803766
total_rewards_max            3363.4145910992156
total_rewards_min            959.8672659329369
Number of train steps total  1140000
Number of env steps total    1187453
Number of rollouts total     0
Train Time (s)               147.85132876271382
(Previous) Eval Time (s)     19.277908167801797
Sample Time (s)              6.714867887552828
Epoch Time (s)               173.84410481806844
Total Train Time (s)         46472.069649111014
Epoch                        284
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:24:12.905526 UTC | [2020_01_10_09_29_40] Iteration #284 | Epoch Duration: 173.9384741783142
2020-01-10 22:24:12.905777 UTC | [2020_01_10_09_29_40] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13555518
Z variance train             0.0057139643
KL Divergence                10.877816
KL Loss                      1.0877817
QF Loss                      65.934906
VF Loss                      14.345784
Policy Loss                  -1385.3523
Q Predictions Mean           1383.9996
Q Predictions Std            325.93396
Q Predictions Max            1695.5698
Q Predictions Min            109.62013
V Predictions Mean           1386.6537
V Predictions Std            327.33334
V Predictions Max            1690.8975
V Predictions Min            100.224075
Log Pis Mean                 -0.15039116
Log Pis Std                  1.8905911
Log Pis Max                  5.419426
Log Pis Min                  -5.1933823
Policy mu Mean               -0.011539216
Policy mu Std                0.8810603
Policy mu Max                3.2082822
Policy mu Min                -2.5337195
Policy log std Mean          -0.514646
Policy log std Std           0.1899962
Policy log std Max           0.037949383
Policy log std Min           -1.0395457
Z mean eval                  0.20851609
Z variance eval              0.0076827244
total_rewards                [3328.76417798 3348.95768089 3299.74377338 3335.18894594 2270.71817408
 1033.81074901 3344.92378435 3319.42643826 3332.56079246 3288.13490815]
total_rewards_mean           2990.2229424497737
total_rewards_std            724.1184725706166
total_rewards_max            3348.9576808944994
total_rewards_min            1033.8107490067914
Number of train steps total  1144000
Number of env steps total    1192805
Number of rollouts total     0
Train Time (s)               145.45518825529143
(Previous) Eval Time (s)     16.77910709613934
Sample Time (s)              7.107691251207143
Epoch Time (s)               169.34198660263792
Total Train Time (s)         46641.50642471714
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:27:02.348381 UTC | [2020_01_10_09_29_40] Iteration #285 | Epoch Duration: 169.44238686561584
2020-01-10 22:27:02.348690 UTC | [2020_01_10_09_29_40] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21371421
Z variance train             0.0077181472
KL Divergence                9.989292
KL Loss                      0.9989292
QF Loss                      114.315155
VF Loss                      118.60822
Policy Loss                  -1374.0337
Q Predictions Mean           1374.7598
Q Predictions Std            348.59076
Q Predictions Max            1688.4443
Q Predictions Min            83.47971
V Predictions Mean           1371.3698
V Predictions Std            349.3235
V Predictions Max            1703.2404
V Predictions Min            92.06703
Log Pis Mean                 -0.11264991
Log Pis Std                  1.8918095
Log Pis Max                  6.343527
Log Pis Min                  -4.0682545
Policy mu Mean               -0.06924579
Policy mu Std                0.92657554
Policy mu Max                2.0188706
Policy mu Min                -2.5538511
Policy log std Mean          -0.53912044
Policy log std Std           0.17500421
Policy log std Max           0.047394812
Policy log std Min           -1.0974909
Z mean eval                  0.06919932
Z variance eval              0.005423677
total_rewards                [3350.12048458 3353.60012842 3322.73370479 3327.97762291 3331.36066253
 3362.26820201 3352.75777493 3333.47436149 3353.29242698 3356.44210843]
total_rewards_mean           3344.40274770632
total_rewards_std            13.263090232786029
total_rewards_max            3362.268202008675
total_rewards_min            3322.73370478509
Number of train steps total  1148000
Number of env steps total    1198114
Number of rollouts total     0
Train Time (s)               145.55055184522644
(Previous) Eval Time (s)     21.57790869101882
Sample Time (s)              6.570620351936668
Epoch Time (s)               173.69908088818192
Total Train Time (s)         46815.28629502701
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:29:56.132751 UTC | [2020_01_10_09_29_40] Iteration #286 | Epoch Duration: 173.7838294506073
2020-01-10 22:29:56.133013 UTC | [2020_01_10_09_29_40] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06972292
Z variance train             0.005414231
KL Divergence                11.099173
KL Loss                      1.1099173
QF Loss                      209.22049
VF Loss                      85.657814
Policy Loss                  -1386.0477
Q Predictions Mean           1387.462
Q Predictions Std            339.35886
Q Predictions Max            1712.4576
Q Predictions Min            57.14424
V Predictions Mean           1380.439
V Predictions Std            339.63348
V Predictions Max            1710.3286
V Predictions Min            57.95674
Log Pis Mean                 -0.11744036
Log Pis Std                  1.860269
Log Pis Max                  5.921729
Log Pis Min                  -5.400132
Policy mu Mean               0.08144515
Policy mu Std                0.8893862
Policy mu Max                2.1517816
Policy mu Min                -2.6100812
Policy log std Mean          -0.5067614
Policy log std Std           0.18363899
Policy log std Max           0.06262761
Policy log std Min           -1.1925881
Z mean eval                  0.13657716
Z variance eval              0.008836558
total_rewards                [1740.57695818 3372.23919919 1051.80815335 1281.13761554 3371.06809114
 3437.05724232 3386.1743411  3378.6746226  3389.94922342 3363.24243785]
total_rewards_mean           2777.192788468571
total_rewards_std            942.52100088031
total_rewards_max            3437.0572423176072
total_rewards_min            1051.808153346732
Number of train steps total  1152000
Number of env steps total    1203861
Number of rollouts total     0
Train Time (s)               147.2326516811736
(Previous) Eval Time (s)     17.683684214018285
Sample Time (s)              6.652165648527443
Epoch Time (s)               171.56850154371932
Total Train Time (s)         46987.16124059167
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:32:48.017358 UTC | [2020_01_10_09_29_40] Iteration #287 | Epoch Duration: 171.88417840003967
2020-01-10 22:32:48.017535 UTC | [2020_01_10_09_29_40] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1365983
Z variance train             0.008825816
KL Divergence                9.66349
KL Loss                      0.96634907
QF Loss                      69.090065
VF Loss                      67.800964
Policy Loss                  -1374.7437
Q Predictions Mean           1373.2161
Q Predictions Std            350.7805
Q Predictions Max            1717.7806
Q Predictions Min            24.071995
V Predictions Mean           1368.9402
V Predictions Std            351.37625
V Predictions Max            1713.5374
V Predictions Min            28.398207
Log Pis Mean                 -0.100044824
Log Pis Std                  2.1214457
Log Pis Max                  5.504431
Log Pis Min                  -6.4437456
Policy mu Mean               -0.09383138
Policy mu Std                0.9177296
Policy mu Max                2.0649934
Policy mu Min                -2.4372225
Policy log std Mean          -0.5155923
Policy log std Std           0.18607277
Policy log std Max           0.07170737
Policy log std Min           -1.0237238
Z mean eval                  0.049527477
Z variance eval              0.008870373
total_rewards                [  78.12767789 3315.55005729 3357.46439292 3403.73507394 3377.97294156
 1337.70119328 1218.00377582 1772.77479736 3341.52483261   65.73890652]
total_rewards_mean           2126.8593649173913
total_rewards_std            1327.3344456309526
total_rewards_max            3403.7350739376707
total_rewards_min            65.73890651503301
Number of train steps total  1156000
Number of env steps total    1209343
Number of rollouts total     0
Train Time (s)               147.79269313486293
(Previous) Eval Time (s)     11.592867511324584
Sample Time (s)              6.513856212608516
Epoch Time (s)               165.89941685879603
Total Train Time (s)         47153.15634921938
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:35:34.006510 UTC | [2020_01_10_09_29_40] Iteration #288 | Epoch Duration: 165.98883199691772
2020-01-10 22:35:34.006717 UTC | [2020_01_10_09_29_40] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04982827
Z variance train             0.008891069
KL Divergence                9.638531
KL Loss                      0.96385306
QF Loss                      53.71797
VF Loss                      21.236961
Policy Loss                  -1388.0887
Q Predictions Mean           1386.3789
Q Predictions Std            332.5721
Q Predictions Max            1714.6229
Q Predictions Min            66.826294
V Predictions Mean           1389.6938
V Predictions Std            333.74454
V Predictions Max            1722.9138
V Predictions Min            71.77761
Log Pis Mean                 -0.13827309
Log Pis Std                  1.9492856
Log Pis Max                  5.1972313
Log Pis Min                  -8.626142
Policy mu Mean               -0.01706463
Policy mu Std                0.88113904
Policy mu Max                2.2400355
Policy mu Min                -2.5918198
Policy log std Mean          -0.5196097
Policy log std Std           0.18561047
Policy log std Max           0.15928811
Policy log std Min           -0.9940832
Z mean eval                  0.08222871
Z variance eval              0.011444539
total_rewards                [3012.74474078 3342.31961898 3419.55827271 3339.49221785 3362.11572768
 3381.62046714 2148.58630983 3335.34868101 3329.03184883 1845.3135868 ]
total_rewards_mean           3051.6131471605136
total_rewards_std            542.0035748705839
total_rewards_max            3419.558272705712
total_rewards_min            1845.3135868045092
Number of train steps total  1160000
Number of env steps total    1214827
Number of rollouts total     0
Train Time (s)               146.73170725116506
(Previous) Eval Time (s)     16.841275518294424
Sample Time (s)              5.5433546379208565
Epoch Time (s)               169.11633740738034
Total Train Time (s)         47322.35473344801
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:38:23.209769 UTC | [2020_01_10_09_29_40] Iteration #289 | Epoch Duration: 169.20294451713562
2020-01-10 22:38:23.209928 UTC | [2020_01_10_09_29_40] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08206732
Z variance train             0.011448093
KL Divergence                9.0240555
KL Loss                      0.90240556
QF Loss                      58.92488
VF Loss                      25.135635
Policy Loss                  -1366.3988
Q Predictions Mean           1365.1958
Q Predictions Std            347.99112
Q Predictions Max            1705.752
Q Predictions Min            101.155655
V Predictions Mean           1365.2191
V Predictions Std            349.3926
V Predictions Max            1707.8184
V Predictions Min            121.62826
Log Pis Mean                 -0.07842321
Log Pis Std                  1.9406881
Log Pis Max                  6.183389
Log Pis Min                  -3.8829682
Policy mu Mean               0.010334569
Policy mu Std                0.89649665
Policy mu Max                2.209869
Policy mu Min                -2.4675581
Policy log std Mean          -0.51475173
Policy log std Std           0.19094224
Policy log std Max           0.14689618
Policy log std Min           -1.1442198
Z mean eval                  0.17628154
Z variance eval              0.011216608
total_rewards                [2060.79963345 2305.9276303   809.43905769 1077.86768425  461.42918138
 1625.00789816  747.80730016   45.58740123  978.58637381  235.74645792]
total_rewards_mean           1034.819861834361
total_rewards_std            714.1943324518919
total_rewards_max            2305.927630300803
total_rewards_min            45.58740122571205
Number of train steps total  1164000
Number of env steps total    1220029
Number of rollouts total     0
Train Time (s)               147.97883072961122
(Previous) Eval Time (s)     7.069108983036131
Sample Time (s)              6.681521651800722
Epoch Time (s)               161.72946136444807
Total Train Time (s)         47484.171031166334
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:41:05.029900 UTC | [2020_01_10_09_29_40] Iteration #290 | Epoch Duration: 161.81984758377075
2020-01-10 22:41:05.030088 UTC | [2020_01_10_09_29_40] Iteration #290 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17574082
Z variance train             0.011163542
KL Divergence                9.911497
KL Loss                      0.9911497
QF Loss                      69.58153
VF Loss                      31.279434
Policy Loss                  -1406.6715
Q Predictions Mean           1406.2445
Q Predictions Std            314.4032
Q Predictions Max            1731.1914
Q Predictions Min            141.16891
V Predictions Mean           1407.7183
V Predictions Std            312.46634
V Predictions Max            1734.9713
V Predictions Min            131.42734
Log Pis Mean                 -0.0055057816
Log Pis Std                  2.0001771
Log Pis Max                  6.888167
Log Pis Min                  -4.956389
Policy mu Mean               -0.065074414
Policy mu Std                0.92705
Policy mu Max                1.9138334
Policy mu Min                -2.6028752
Policy log std Mean          -0.52039355
Policy log std Std           0.19212627
Policy log std Max           0.037959635
Policy log std Min           -1.2298442
Z mean eval                  0.0745683
Z variance eval              0.008191681
total_rewards                [3337.52965133  993.73455501 3345.72407441 3383.61178909 3353.6198516
 3403.86470994 1815.97697856   46.51104881 2209.17414882 3335.92777319]
total_rewards_mean           2522.567458074579
total_rewards_std            1152.2893004773
total_rewards_max            3403.864709935522
total_rewards_min            46.51104880662167
Number of train steps total  1168000
Number of env steps total    1225585
Number of rollouts total     0
Train Time (s)               146.16110576782376
(Previous) Eval Time (s)     15.995774216018617
Sample Time (s)              6.458640916272998
Epoch Time (s)               168.61552090011537
Total Train Time (s)         47652.86500291526
Epoch                        291
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:43:53.732852 UTC | [2020_01_10_09_29_40] Iteration #291 | Epoch Duration: 168.70261478424072
2020-01-10 22:43:53.733076 UTC | [2020_01_10_09_29_40] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.074562296
Z variance train             0.008186611
KL Divergence                10.388091
KL Loss                      1.0388092
QF Loss                      63.86367
VF Loss                      15.272741
Policy Loss                  -1428.0098
Q Predictions Mean           1426.7035
Q Predictions Std            293.37482
Q Predictions Max            1728.9131
Q Predictions Min            70.16931
V Predictions Mean           1428.7385
V Predictions Std            293.3404
V Predictions Max            1727.6398
V Predictions Min            83.52763
Log Pis Mean                 -0.14059937
Log Pis Std                  1.9357877
Log Pis Max                  7.8899965
Log Pis Min                  -4.37622
Policy mu Mean               -0.043151785
Policy mu Std                0.88494927
Policy mu Max                2.184655
Policy mu Min                -2.437708
Policy log std Mean          -0.5143122
Policy log std Std           0.1971302
Policy log std Max           0.052991986
Policy log std Min           -1.0605581
Z mean eval                  0.06658221
Z variance eval              0.009096275
total_rewards                [3364.89352737 2532.59961819 3077.22724052 3376.71317901 3375.71405692
 3390.72018039 3368.55035567 3362.33116021 3347.49929603 3333.19335322]
total_rewards_mean           3252.944196751379
total_rewards_std            255.41920837514624
total_rewards_max            3390.7201803857656
total_rewards_min            2532.599618186015
Number of train steps total  1172000
Number of env steps total    1231114
Number of rollouts total     0
Train Time (s)               144.95705260895193
(Previous) Eval Time (s)     21.069498285185546
Sample Time (s)              6.938031272962689
Epoch Time (s)               172.96458216710016
Total Train Time (s)         47826.07360953884
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:46:46.950631 UTC | [2020_01_10_09_29_40] Iteration #292 | Epoch Duration: 173.2173683643341
2020-01-10 22:46:46.950869 UTC | [2020_01_10_09_29_40] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0662671
Z variance train             0.009091278
KL Divergence                9.795082
KL Loss                      0.9795082
QF Loss                      77.205246
VF Loss                      23.73958
Policy Loss                  -1376.0166
Q Predictions Mean           1375.8594
Q Predictions Std            339.6002
Q Predictions Max            1717.6685
Q Predictions Min            27.884851
V Predictions Mean           1378.082
V Predictions Std            340.81995
V Predictions Max            1721.8851
V Predictions Min            27.757706
Log Pis Mean                 0.03954207
Log Pis Std                  1.9945582
Log Pis Max                  7.465085
Log Pis Min                  -3.7504878
Policy mu Mean               -0.04273809
Policy mu Std                0.9159623
Policy mu Max                2.3314111
Policy mu Min                -2.7446597
Policy log std Mean          -0.55542797
Policy log std Std           0.18373272
Policy log std Max           -0.06543434
Policy log std Min           -1.22195
Z mean eval                  0.0579619
Z variance eval              0.0077948906
total_rewards                [1049.67166841 3367.07441297 3363.33991723 3373.79361416 3339.61358305
 3337.74114741 2581.83169834 3364.29051572 3342.35989304 1301.56099716]
total_rewards_mean           2842.1277447471975
total_rewards_std            866.0201739476247
total_rewards_max            3373.7936141589153
total_rewards_min            1049.671668405345
Number of train steps total  1176000
Number of env steps total    1236641
Number of rollouts total     0
Train Time (s)               145.97401046473533
(Previous) Eval Time (s)     18.254095963668078
Sample Time (s)              6.71344454633072
Epoch Time (s)               170.94155097473413
Total Train Time (s)         47997.10871318821
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:49:37.986068 UTC | [2020_01_10_09_29_40] Iteration #293 | Epoch Duration: 171.03502440452576
2020-01-10 22:49:37.986270 UTC | [2020_01_10_09_29_40] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05748886
Z variance train             0.0077941767
KL Divergence                9.874449
KL Loss                      0.9874449
QF Loss                      51.553673
VF Loss                      21.20122
Policy Loss                  -1385.559
Q Predictions Mean           1382.1484
Q Predictions Std            338.72852
Q Predictions Max            1710.486
Q Predictions Min            162.70015
V Predictions Mean           1385.7246
V Predictions Std            339.10263
V Predictions Max            1712.3969
V Predictions Min            159.06598
Log Pis Mean                 -0.06410544
Log Pis Std                  1.9912167
Log Pis Max                  6.6013494
Log Pis Min                  -4.9186645
Policy mu Mean               -0.055738315
Policy mu Std                0.8881815
Policy mu Max                3.094175
Policy mu Min                -2.4861798
Policy log std Mean          -0.53063065
Policy log std Std           0.1896912
Policy log std Max           0.042293668
Policy log std Min           -1.0971043
Z mean eval                  0.09146597
Z variance eval              0.0075408355
total_rewards                [3401.20443323 2337.17200088 3333.28184542 3300.49230608 2917.00876606
 1303.90838064 2089.03380611  967.44074264 3213.70956197 2677.55630532]
total_rewards_mean           2554.0808148343194
total_rewards_std            825.0849502669133
total_rewards_max            3401.204433225597
total_rewards_min            967.4407426389935
Number of train steps total  1180000
Number of env steps total    1241954
Number of rollouts total     0
Train Time (s)               146.47097959788516
(Previous) Eval Time (s)     16.77811009204015
Sample Time (s)              6.62557278573513
Epoch Time (s)               169.87466247566044
Total Train Time (s)         48167.215715253726
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:52:28.097157 UTC | [2020_01_10_09_29_40] Iteration #294 | Epoch Duration: 170.11070585250854
2020-01-10 22:52:28.097449 UTC | [2020_01_10_09_29_40] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09117511
Z variance train             0.007551008
KL Divergence                10.224162
KL Loss                      1.0224162
QF Loss                      134.87646
VF Loss                      27.558064
Policy Loss                  -1395.6632
Q Predictions Mean           1395.5623
Q Predictions Std            317.90384
Q Predictions Max            1722.5225
Q Predictions Min            74.36817
V Predictions Mean           1394.3352
V Predictions Std            316.97778
V Predictions Max            1720.9471
V Predictions Min            75.72859
Log Pis Mean                 -0.03999587
Log Pis Std                  2.008112
Log Pis Max                  6.755986
Log Pis Min                  -4.654207
Policy mu Mean               -0.1253345
Policy mu Std                0.86548877
Policy mu Max                1.9452274
Policy mu Min                -2.6336796
Policy log std Mean          -0.51327664
Policy log std Std           0.19100288
Policy log std Max           0.061237276
Policy log std Min           -1.3312068
Z mean eval                  0.13274284
Z variance eval              0.01841575
total_rewards                [2138.30644391 3364.1590789  3392.2719428  3374.45960062 2320.00140267
 1290.32206492 3388.63142772  758.6683646  3348.58881084 3411.5902819 ]
total_rewards_mean           2678.699941887825
total_rewards_std            948.0404503646855
total_rewards_max            3411.5902819037997
total_rewards_min            758.6683645956812
Number of train steps total  1184000
Number of env steps total    1247216
Number of rollouts total     0
Train Time (s)               146.00082779675722
(Previous) Eval Time (s)     16.19385155895725
Sample Time (s)              6.321148383431137
Epoch Time (s)               168.5158277391456
Total Train Time (s)         48336.032660062425
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:55:16.919629 UTC | [2020_01_10_09_29_40] Iteration #295 | Epoch Duration: 168.82198095321655
2020-01-10 22:55:16.919798 UTC | [2020_01_10_09_29_40] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1332945
Z variance train             0.0183846
KL Divergence                7.904843
KL Loss                      0.7904843
QF Loss                      100.30814
VF Loss                      26.69464
Policy Loss                  -1399.6384
Q Predictions Mean           1399.8325
Q Predictions Std            316.9602
Q Predictions Max            1715.6146
Q Predictions Min            115.928085
V Predictions Mean           1401.2283
V Predictions Std            316.80203
V Predictions Max            1719.3063
V Predictions Min            94.98492
Log Pis Mean                 -0.00861961
Log Pis Std                  2.113581
Log Pis Max                  7.834548
Log Pis Min                  -6.9235716
Policy mu Mean               -0.09864986
Policy mu Std                0.91150075
Policy mu Max                2.1514075
Policy mu Min                -2.676819
Policy log std Mean          -0.5277675
Policy log std Std           0.1826106
Policy log std Max           0.01574105
Policy log std Min           -1.1173797
Z mean eval                  0.13055834
Z variance eval              0.0150216045
total_rewards                [3356.1281666  3380.72578505 3369.77626917 3357.59860917 3326.23139509
 1317.43349    3333.0168166  3323.00531852 3387.98025316 2814.74796096]
total_rewards_mean           3096.6644064304683
total_rewards_std            614.8566653046295
total_rewards_max            3387.980253156586
total_rewards_min            1317.433490004536
Number of train steps total  1188000
Number of env steps total    1252648
Number of rollouts total     0
Train Time (s)               147.19615631410852
(Previous) Eval Time (s)     20.069399011787027
Sample Time (s)              6.455652209464461
Epoch Time (s)               173.72120753536
Total Train Time (s)         48509.83290744061
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:58:10.721812 UTC | [2020_01_10_09_29_40] Iteration #296 | Epoch Duration: 173.80190086364746
2020-01-10 22:58:10.721939 UTC | [2020_01_10_09_29_40] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13324922
Z variance train             0.015010471
KL Divergence                8.838444
KL Loss                      0.8838444
QF Loss                      165.10611
VF Loss                      50.35196
Policy Loss                  -1390.0951
Q Predictions Mean           1390.4697
Q Predictions Std            347.21933
Q Predictions Max            1718.6241
Q Predictions Min            73.98768
V Predictions Mean           1389.5873
V Predictions Std            346.43362
V Predictions Max            1718.6676
V Predictions Min            80.87818
Log Pis Mean                 -0.03371948
Log Pis Std                  2.0530977
Log Pis Max                  7.3418922
Log Pis Min                  -5.605485
Policy mu Mean               -0.060105756
Policy mu Std                0.91412646
Policy mu Max                2.0699701
Policy mu Min                -2.753105
Policy log std Mean          -0.51184225
Policy log std Std           0.19012631
Policy log std Max           0.102869034
Policy log std Min           -1.0173796
Z mean eval                  0.0130358245
Z variance eval              0.014673315
total_rewards                [1171.40662375 3353.64261442 3294.90089548 2682.53121529 1071.44112657
 1908.05255335 3341.21476654 1392.6075004  1306.55278811 2424.30747136]
total_rewards_mean           2194.665755526112
total_rewards_std            893.4175627781991
total_rewards_max            3353.6426144212915
total_rewards_min            1071.4411265657052
Number of train steps total  1192000
Number of env steps total    1258163
Number of rollouts total     0
Train Time (s)               144.95111126126722
(Previous) Eval Time (s)     13.96701055765152
Sample Time (s)              6.692671034485102
Epoch Time (s)               165.61079285340384
Total Train Time (s)         48675.52232979704
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:00:56.413827 UTC | [2020_01_10_09_29_40] Iteration #297 | Epoch Duration: 165.6917998790741
2020-01-10 23:00:56.413962 UTC | [2020_01_10_09_29_40] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013069078
Z variance train             0.014664486
KL Divergence                8.2525425
KL Loss                      0.82525426
QF Loss                      45.783375
VF Loss                      16.912691
Policy Loss                  -1414.7449
Q Predictions Mean           1414.2004
Q Predictions Std            310.33844
Q Predictions Max            1733.91
Q Predictions Min            32.840347
V Predictions Mean           1413.7089
V Predictions Std            310.34003
V Predictions Max            1733.35
V Predictions Min            35.94793
Log Pis Mean                 -0.011305787
Log Pis Std                  2.0051725
Log Pis Max                  5.5458794
Log Pis Min                  -5.033393
Policy mu Mean               -0.11658429
Policy mu Std                0.9054038
Policy mu Max                2.0457952
Policy mu Min                -2.7430613
Policy log std Mean          -0.54879
Policy log std Std           0.1655697
Policy log std Max           0.002650261
Policy log std Min           -0.99744594
Z mean eval                  0.028914925
Z variance eval              0.012794244
total_rewards                [2160.99774452 3325.30613974 3302.84854499  968.15654059  742.38992235
 3345.53588048 3345.30271684 3295.10650936  742.39427673 3319.12717291]
total_rewards_mean           2454.716544851858
total_rewards_std            1125.9511254577471
total_rewards_max            3345.5358804834964
total_rewards_min            742.3899223488457
Number of train steps total  1196000
Number of env steps total    1263501
Number of rollouts total     0
Train Time (s)               145.88666803762317
(Previous) Eval Time (s)     13.57952069491148
Sample Time (s)              6.512355382088572
Epoch Time (s)               165.97854411462322
Total Train Time (s)         48841.58466246491
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:03:42.484303 UTC | [2020_01_10_09_29_40] Iteration #298 | Epoch Duration: 166.07019710540771
2020-01-10 23:03:42.484623 UTC | [2020_01_10_09_29_40] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028779283
Z variance train             0.01280646
KL Divergence                8.661813
KL Loss                      0.8661813
QF Loss                      60.10569
VF Loss                      14.913288
Policy Loss                  -1395.2855
Q Predictions Mean           1395.0547
Q Predictions Std            324.34094
Q Predictions Max            1711.4778
Q Predictions Min            67.621
V Predictions Mean           1395.6367
V Predictions Std            323.54373
V Predictions Max            1711.2119
V Predictions Min            61.645844
Log Pis Mean                 -0.095030315
Log Pis Std                  1.8488532
Log Pis Max                  6.008923
Log Pis Min                  -5.4660406
Policy mu Mean               -0.023126481
Policy mu Std                0.8914308
Policy mu Max                2.5615647
Policy mu Min                -2.5257294
Policy log std Mean          -0.5228906
Policy log std Std           0.17397752
Policy log std Max           0.011675298
Policy log std Min           -1.0605274
Z mean eval                  0.088150725
Z variance eval              0.010931829
total_rewards                [2497.59985033 1010.21084238 3307.32806054 3344.11016849 1039.00202093
 3295.91546198 3294.26167241 3368.87877776 3285.00228819 3318.83115684]
total_rewards_mean           2776.114029986037
total_rewards_std            908.949943684544
total_rewards_max            3368.8787777568746
total_rewards_min            1010.2108423828165
Number of train steps total  1200000
Number of env steps total    1268942
Number of rollouts total     0
Train Time (s)               144.79615856288
(Previous) Eval Time (s)     15.560140101704746
Sample Time (s)              6.560537890531123
Epoch Time (s)               166.91683655511588
Total Train Time (s)         49008.58184083551
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:06:29.484457 UTC | [2020_01_10_09_29_40] Iteration #299 | Epoch Duration: 166.99956727027893
2020-01-10 23:06:29.484779 UTC | [2020_01_10_09_29_40] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08840613
Z variance train             0.010933231
KL Divergence                8.947714
KL Loss                      0.8947714
QF Loss                      63.32379
VF Loss                      26.330006
Policy Loss                  -1408.2493
Q Predictions Mean           1407.2424
Q Predictions Std            315.9683
Q Predictions Max            1728.4818
Q Predictions Min            74.20375
V Predictions Mean           1409.3506
V Predictions Std            316.21088
V Predictions Max            1724.0343
V Predictions Min            69.5933
Log Pis Mean                 -0.22143787
Log Pis Std                  2.0208967
Log Pis Max                  5.8125167
Log Pis Min                  -6.4152145
Policy mu Mean               -0.14143269
Policy mu Std                0.879875
Policy mu Max                1.9932393
Policy mu Min                -2.608943
Policy log std Mean          -0.5423499
Policy log std Std           0.18437912
Policy log std Max           0.06631696
Policy log std Min           -1.087089
Z mean eval                  0.092720516
Z variance eval              0.008196501
total_rewards                [3352.83673978 3348.16295504 3332.48819251 3344.92424434 3315.32916989
 3341.00281912 3317.75562263 3327.19052794 3335.96801003 3330.60381668]
total_rewards_mean           3334.626209795223
total_rewards_std            11.816981652240388
total_rewards_max            3352.83673978235
total_rewards_min            3315.3291698915077
Number of train steps total  1204000
Number of env steps total    1274774
Number of rollouts total     0
Train Time (s)               146.55430165491998
(Previous) Eval Time (s)     21.878146533854306
Sample Time (s)              5.686549021396786
Epoch Time (s)               174.11899721017107
Total Train Time (s)         49182.78132898081
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:09:23.684662 UTC | [2020_01_10_09_29_40] Iteration #300 | Epoch Duration: 174.19967222213745
2020-01-10 23:09:23.684793 UTC | [2020_01_10_09_29_40] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0921011
Z variance train             0.008215316
KL Divergence                9.85652
KL Loss                      0.98565197
QF Loss                      125.890976
VF Loss                      25.956873
Policy Loss                  -1380.2036
Q Predictions Mean           1379.4038
Q Predictions Std            357.83066
Q Predictions Max            1721.6458
Q Predictions Min            35.943493
V Predictions Mean           1382.2593
V Predictions Std            357.18015
V Predictions Max            1719.7744
V Predictions Min            52.635414
Log Pis Mean                 0.014860328
Log Pis Std                  2.0007186
Log Pis Max                  5.7646337
Log Pis Min                  -5.156044
Policy mu Mean               -0.08530801
Policy mu Std                0.89843386
Policy mu Max                2.2732534
Policy mu Min                -2.516316
Policy log std Mean          -0.54833305
Policy log std Std           0.18401304
Policy log std Max           -0.041267514
Policy log std Min           -1.147224
Z mean eval                  0.12519173
Z variance eval              0.012273388
total_rewards                [2189.97668309 2897.17638459 3377.0402151   793.22862136 2649.65798569
  962.07953621 2025.67031483  719.21430025 1014.3544876   454.33327597]
total_rewards_mean           1708.2731804709226
total_rewards_std            992.1439515666589
total_rewards_max            3377.0402150998934
total_rewards_min            454.3332759743354
Number of train steps total  1208000
Number of env steps total    1280590
Number of rollouts total     0
Train Time (s)               146.41568486066535
(Previous) Eval Time (s)     11.220582764130086
Sample Time (s)              6.497661264613271
Epoch Time (s)               164.1339288894087
Total Train Time (s)         49346.99640801968
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:12:07.901464 UTC | [2020_01_10_09_29_40] Iteration #301 | Epoch Duration: 164.21658182144165
2020-01-10 23:12:07.901589 UTC | [2020_01_10_09_29_40] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1256608
Z variance train             0.0122783575
KL Divergence                8.792906
KL Loss                      0.8792906
QF Loss                      48.810455
VF Loss                      18.182878
Policy Loss                  -1377.9669
Q Predictions Mean           1375.3872
Q Predictions Std            347.0039
Q Predictions Max            1707.4069
Q Predictions Min            75.058395
V Predictions Mean           1378.8696
V Predictions Std            346.50928
V Predictions Max            1719.1322
V Predictions Min            74.94548
Log Pis Mean                 0.0329977
Log Pis Std                  2.041094
Log Pis Max                  7.9184527
Log Pis Min                  -4.7571716
Policy mu Mean               -0.046528745
Policy mu Std                0.9231167
Policy mu Max                2.3969848
Policy mu Min                -2.579314
Policy log std Mean          -0.5374883
Policy log std Std           0.18037842
Policy log std Max           0.07271749
Policy log std Min           -1.1573915
Z mean eval                  0.09210262
Z variance eval              0.012253361
total_rewards                [ 766.37431812 3390.70341821 3326.36779202 3355.6238298  3402.24378426
 3360.72045496 1111.18771259 3357.88336908 2227.88064988 3355.42198112]
total_rewards_mean           2765.4407310053775
total_rewards_std            976.4548802723001
total_rewards_max            3402.2437842569484
total_rewards_min            766.3743181176363
Number of train steps total  1212000
Number of env steps total    1286327
Number of rollouts total     0
Train Time (s)               145.3469094322063
(Previous) Eval Time (s)     15.194673203863204
Sample Time (s)              6.536416901741177
Epoch Time (s)               167.07799953781068
Total Train Time (s)         49514.15087845549
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:14:55.058439 UTC | [2020_01_10_09_29_40] Iteration #302 | Epoch Duration: 167.1567621231079
2020-01-10 23:14:55.058560 UTC | [2020_01_10_09_29_40] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09173328
Z variance train             0.012261888
KL Divergence                8.721598
KL Loss                      0.8721598
QF Loss                      78.134605
VF Loss                      17.76575
Policy Loss                  -1405.3146
Q Predictions Mean           1404.9651
Q Predictions Std            323.90454
Q Predictions Max            1737.9504
Q Predictions Min            21.72539
V Predictions Mean           1404.1914
V Predictions Std            321.81766
V Predictions Max            1734.082
V Predictions Min            27.186716
Log Pis Mean                 -0.084193945
Log Pis Std                  1.9673545
Log Pis Max                  6.5027375
Log Pis Min                  -7.601303
Policy mu Mean               -0.09724764
Policy mu Std                0.8976268
Policy mu Max                2.9402568
Policy mu Min                -2.7098503
Policy log std Mean          -0.51725286
Policy log std Std           0.19880182
Policy log std Max           0.17341208
Policy log std Min           -1.1022723
Z mean eval                  0.12123878
Z variance eval              0.010896465
total_rewards                [ 979.821744   1998.1970702  3324.85888629  736.37728533 3329.67731921
 3369.66235573 3367.58895004 1297.35775949 3362.04423584 1304.44948626]
total_rewards_mean           2307.003509236837
total_rewards_std            1086.1503682848086
total_rewards_max            3369.662355725897
total_rewards_min            736.3772853254228
Number of train steps total  1216000
Number of env steps total    1292156
Number of rollouts total     0
Train Time (s)               145.37568595120683
(Previous) Eval Time (s)     12.932922757230699
Sample Time (s)              5.653947415295988
Epoch Time (s)               163.96255612373352
Total Train Time (s)         49678.19179844577
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:17:39.102372 UTC | [2020_01_10_09_29_40] Iteration #303 | Epoch Duration: 164.043710231781
2020-01-10 23:17:39.102545 UTC | [2020_01_10_09_29_40] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.120770335
Z variance train             0.010899691
KL Divergence                8.93984
KL Loss                      0.893984
QF Loss                      139.97792
VF Loss                      83.28058
Policy Loss                  -1399.7388
Q Predictions Mean           1401.0952
Q Predictions Std            350.65567
Q Predictions Max            1741.7574
Q Predictions Min            8.951276
V Predictions Mean           1396.9335
V Predictions Std            349.28677
V Predictions Max            1730.1558
V Predictions Min            22.374601
Log Pis Mean                 -0.1811999
Log Pis Std                  1.9531708
Log Pis Max                  8.015561
Log Pis Min                  -7.87639
Policy mu Mean               -0.20235191
Policy mu Std                0.8577155
Policy mu Max                2.0540473
Policy mu Min                -2.6919832
Policy log std Mean          -0.5377858
Policy log std Std           0.18745366
Policy log std Max           0.23671955
Policy log std Min           -1.2221644
Z mean eval                  0.12256183
Z variance eval              0.010918394
total_rewards                [2677.43719707 3332.20079712 3351.90449387 3339.09595087 3338.58122984
 3309.43686807 3291.50409279 1261.71404823 3332.89120354 3333.10578078]
total_rewards_mean           3056.7871662166194
total_rewards_std            629.2659430628731
total_rewards_max            3351.90449386598
total_rewards_min            1261.7140482349448
Number of train steps total  1220000
Number of env steps total    1297916
Number of rollouts total     0
Train Time (s)               145.7665577000007
(Previous) Eval Time (s)     17.182804683223367
Sample Time (s)              5.768343492876738
Epoch Time (s)               168.7177058761008
Total Train Time (s)         49846.98844058998
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:20:27.902661 UTC | [2020_01_10_09_29_40] Iteration #304 | Epoch Duration: 168.79991269111633
2020-01-10 23:20:27.902916 UTC | [2020_01_10_09_29_40] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.120799325
Z variance train             0.010891899
KL Divergence                8.998859
KL Loss                      0.89988595
QF Loss                      195.60411
VF Loss                      164.25467
Policy Loss                  -1433.597
Q Predictions Mean           1433.5815
Q Predictions Std            277.22116
Q Predictions Max            1721.8987
Q Predictions Min            174.39735
V Predictions Mean           1428.3083
V Predictions Std            276.83557
V Predictions Max            1744.3176
V Predictions Min            185.26254
Log Pis Mean                 -0.06505881
Log Pis Std                  1.9763234
Log Pis Max                  6.7392273
Log Pis Min                  -5.4999237
Policy mu Mean               -0.054279637
Policy mu Std                0.90629506
Policy mu Max                2.3650432
Policy mu Min                -2.674378
Policy log std Mean          -0.5150551
Policy log std Std           0.17930067
Policy log std Max           0.0007469058
Policy log std Min           -1.0551441
Z mean eval                  0.1038483
Z variance eval              0.009096201
total_rewards                [3328.91663648 3015.15255426 2322.26512398 1019.78734559 1050.93525914
 1293.52357057 2362.34781888  983.92827695 1785.80317699 3359.71529326]
total_rewards_mean           2052.2375056102637
total_rewards_std            910.6137873348154
total_rewards_max            3359.7152932606336
total_rewards_min            983.9282769535785
Number of train steps total  1224000
Number of env steps total    1303808
Number of rollouts total     0
Train Time (s)               145.64081037510186
(Previous) Eval Time (s)     13.796740578953177
Sample Time (s)              6.690398439299315
Epoch Time (s)               166.12794939335436
Total Train Time (s)         50013.1957728737
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:23:14.114085 UTC | [2020_01_10_09_29_40] Iteration #305 | Epoch Duration: 166.21102380752563
2020-01-10 23:23:14.114268 UTC | [2020_01_10_09_29_40] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.103760675
Z variance train             0.009091837
KL Divergence                9.487656
KL Loss                      0.9487656
QF Loss                      55.491486
VF Loss                      36.11521
Policy Loss                  -1411.8319
Q Predictions Mean           1409.7322
Q Predictions Std            363.67352
Q Predictions Max            1729.529
Q Predictions Min            16.21656
V Predictions Mean           1409.927
V Predictions Std            363.3746
V Predictions Max            1726.616
V Predictions Min            11.081975
Log Pis Mean                 -0.0936202
Log Pis Std                  2.070903
Log Pis Max                  6.4407306
Log Pis Min                  -5.482833
Policy mu Mean               -0.14157091
Policy mu Std                0.919501
Policy mu Max                1.9856893
Policy mu Min                -2.6220675
Policy log std Mean          -0.49567017
Policy log std Std           0.18411444
Policy log std Max           0.019601703
Policy log std Min           -1.0010358
Z mean eval                  0.10253117
Z variance eval              0.007887417
total_rewards                [ 725.8380562  3331.40186729  996.64497326  810.45318814 3322.75988268
 2925.71260283  853.05665151 3312.3375433  1137.11183676 3297.18773256]
total_rewards_mean           2071.2504334546293
total_rewards_std            1176.3806643295495
total_rewards_max            3331.4018672891393
total_rewards_min            725.8380562045584
Number of train steps total  1228000
Number of env steps total    1309333
Number of rollouts total     0
Train Time (s)               146.04393598996103
(Previous) Eval Time (s)     12.053503262810409
Sample Time (s)              6.44792482117191
Epoch Time (s)               164.54536407394335
Total Train Time (s)         50177.82315844856
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:25:58.748056 UTC | [2020_01_10_09_29_40] Iteration #306 | Epoch Duration: 164.6336133480072
2020-01-10 23:25:58.748378 UTC | [2020_01_10_09_29_40] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.101732396
Z variance train             0.007891328
KL Divergence                9.836443
KL Loss                      0.9836443
QF Loss                      90.40291
VF Loss                      153.02673
Policy Loss                  -1395.9012
Q Predictions Mean           1399.3706
Q Predictions Std            338.39496
Q Predictions Max            1717.6016
Q Predictions Min            51.27015
V Predictions Mean           1405.5599
V Predictions Std            336.68677
V Predictions Max            1721.6653
V Predictions Min            63.36943
Log Pis Mean                 -0.10356513
Log Pis Std                  2.1354809
Log Pis Max                  9.224474
Log Pis Min                  -7.4173493
Policy mu Mean               -0.015299673
Policy mu Std                0.9204403
Policy mu Max                1.8735964
Policy mu Min                -2.473682
Policy log std Mean          -0.50577396
Policy log std Std           0.19518046
Policy log std Max           0.12498164
Policy log std Min           -1.2591453
Z mean eval                  0.07917231
Z variance eval              0.012724437
total_rewards                [3355.10585536  917.82568965 3339.92149516 3353.52146961 3335.75047428
 3411.33903434 3355.38087009 3333.26327022 3338.76702382 3338.34120219]
total_rewards_mean           3107.9216384726246
total_rewards_std            730.3512372031254
total_rewards_max            3411.339034338183
total_rewards_min            917.8256896454295
Number of train steps total  1232000
Number of env steps total    1315354
Number of rollouts total     0
Train Time (s)               144.93038859730586
(Previous) Eval Time (s)     17.023700505960733
Sample Time (s)              6.435798845719546
Epoch Time (s)               168.38988794898614
Total Train Time (s)         50346.38597697392
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:28:47.312909 UTC | [2020_01_10_09_29_40] Iteration #307 | Epoch Duration: 168.56425428390503
2020-01-10 23:28:47.313169 UTC | [2020_01_10_09_29_40] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07913211
Z variance train             0.012738089
KL Divergence                9.048781
KL Loss                      0.90487814
QF Loss                      52.206467
VF Loss                      18.856777
Policy Loss                  -1392.3378
Q Predictions Mean           1391.4343
Q Predictions Std            365.87683
Q Predictions Max            1748.0221
Q Predictions Min            5.3919315
V Predictions Mean           1394.249
V Predictions Std            365.73907
V Predictions Max            1752.8221
V Predictions Min            -1.8894571
Log Pis Mean                 0.023484822
Log Pis Std                  2.010166
Log Pis Max                  5.950808
Log Pis Min                  -5.197998
Policy mu Mean               -0.0800439
Policy mu Std                0.9261307
Policy mu Max                2.2991958
Policy mu Min                -2.6719618
Policy log std Mean          -0.5312572
Policy log std Std           0.16489007
Policy log std Max           0.010471582
Policy log std Min           -1.1729529
Z mean eval                  0.083477505
Z variance eval              0.011379267
total_rewards                [3396.10642656 1004.68423806  937.04867673 2934.39754646 3370.71572018
 1171.46355999  449.80605243 3384.21335715 3344.37981856  997.63804966]
total_rewards_mean           2099.0453445775383
total_rewards_std            1205.868972778447
total_rewards_max            3396.10642656429
total_rewards_min            449.80605243327193
Number of train steps total  1236000
Number of env steps total    1321327
Number of rollouts total     0
Train Time (s)               146.74812557408586
(Previous) Eval Time (s)     11.447247189003974
Sample Time (s)              6.538805657532066
Epoch Time (s)               164.7341784206219
Total Train Time (s)         50511.19611342484
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:31:32.125351 UTC | [2020_01_10_09_29_40] Iteration #308 | Epoch Duration: 164.81205677986145
2020-01-10 23:31:32.125471 UTC | [2020_01_10_09_29_40] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.082261786
Z variance train             0.011399873
KL Divergence                9.064053
KL Loss                      0.90640527
QF Loss                      282.05402
VF Loss                      159.12378
Policy Loss                  -1407.6062
Q Predictions Mean           1408.7427
Q Predictions Std            340.7452
Q Predictions Max            1757.3706
Q Predictions Min            36.808834
V Predictions Mean           1398.3895
V Predictions Std            339.54855
V Predictions Max            1741.7032
V Predictions Min            28.979109
Log Pis Mean                 0.0822877
Log Pis Std                  1.9771184
Log Pis Max                  7.5316973
Log Pis Min                  -5.2809496
Policy mu Mean               -0.14733155
Policy mu Std                0.90009433
Policy mu Max                1.9603618
Policy mu Min                -2.510686
Policy log std Mean          -0.527376
Policy log std Std           0.19038223
Policy log std Max           0.017823935
Policy log std Min           -1.2562551
Z mean eval                  0.09322043
Z variance eval              0.011788594
total_rewards                [3332.65333998 3359.10430176 3349.55611985 3360.36207213 3346.89989384
 3331.06115145 3345.37854824 3334.51191564 3375.18778522 3357.25778578]
total_rewards_mean           3349.197291389418
total_rewards_std            13.422184161574837
total_rewards_max            3375.1877852243447
total_rewards_min            3331.0611514508223
Number of train steps total  1240000
Number of env steps total    1327169
Number of rollouts total     0
Train Time (s)               144.44475133903325
(Previous) Eval Time (s)     21.529504070989788
Sample Time (s)              6.010853921063244
Epoch Time (s)               171.98510933108628
Total Train Time (s)         50683.26101742545
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:34:24.194291 UTC | [2020_01_10_09_29_40] Iteration #309 | Epoch Duration: 172.0687153339386
2020-01-10 23:34:24.194470 UTC | [2020_01_10_09_29_40] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.093082674
Z variance train             0.011785065
KL Divergence                9.013721
KL Loss                      0.90137213
QF Loss                      46.203526
VF Loss                      22.658218
Policy Loss                  -1374.986
Q Predictions Mean           1375.774
Q Predictions Std            394.37192
Q Predictions Max            1720.0961
Q Predictions Min            28.890808
V Predictions Mean           1376.4546
V Predictions Std            392.71466
V Predictions Max            1719.8821
V Predictions Min            30.57465
Log Pis Mean                 -0.16412334
Log Pis Std                  1.854932
Log Pis Max                  5.7045145
Log Pis Min                  -4.1628056
Policy mu Mean               -0.039923728
Policy mu Std                0.8866047
Policy mu Max                2.381375
Policy mu Min                -2.5740702
Policy log std Mean          -0.5243375
Policy log std Std           0.18306565
Policy log std Max           0.29177475
Policy log std Min           -1.0594928
Z mean eval                  0.062521726
Z variance eval              0.015070183
total_rewards                [3379.9763753  1084.12688677 3365.26793799 3369.83767285 3332.00259113
 3368.49824612  523.66829481 3363.95664834  794.49664361 3323.38554024]
total_rewards_mean           2590.5216837143334
total_rewards_std            1178.471492403429
total_rewards_max            3379.9763752982067
total_rewards_min            523.6682948066601
Number of train steps total  1244000
Number of env steps total    1332933
Number of rollouts total     0
Train Time (s)               145.32562171900645
(Previous) Eval Time (s)     16.7010998101905
Sample Time (s)              6.670638980809599
Epoch Time (s)               168.69736051000655
Total Train Time (s)         50852.03540604841
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:37:12.971169 UTC | [2020_01_10_09_29_40] Iteration #310 | Epoch Duration: 168.77657341957092
2020-01-10 23:37:12.971302 UTC | [2020_01_10_09_29_40] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0624711
Z variance train             0.015052959
KL Divergence                8.179056
KL Loss                      0.8179056
QF Loss                      72.630196
VF Loss                      35.129055
Policy Loss                  -1397.851
Q Predictions Mean           1396.9819
Q Predictions Std            376.562
Q Predictions Max            1740.5067
Q Predictions Min            32.574207
V Predictions Mean           1396.703
V Predictions Std            375.811
V Predictions Max            1735.7098
V Predictions Min            27.349596
Log Pis Mean                 0.34793067
Log Pis Std                  2.028338
Log Pis Max                  7.6588707
Log Pis Min                  -4.1239023
Policy mu Mean               -0.14308833
Policy mu Std                0.9509178
Policy mu Max                2.319191
Policy mu Min                -2.5946743
Policy log std Mean          -0.540273
Policy log std Std           0.18249099
Policy log std Max           0.14075238
Policy log std Min           -1.2881573
Z mean eval                  0.07316149
Z variance eval              0.014354585
total_rewards                [3265.2711532  3293.09313621 3306.11023113  928.01869592 3316.34597085
 3335.96304841 3297.43676119 3293.30185393 3337.26164907 3322.56830412]
total_rewards_mean           3069.537080403282
total_rewards_std            714.1403638020395
total_rewards_max            3337.261649074943
total_rewards_min            928.0186959209125
Number of train steps total  1248000
Number of env steps total    1338650
Number of rollouts total     0
Train Time (s)               144.4780099503696
(Previous) Eval Time (s)     17.290756984148175
Sample Time (s)              7.154046145733446
Epoch Time (s)               168.92281308025122
Total Train Time (s)         51021.034921525046
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:40:01.973979 UTC | [2020_01_10_09_29_40] Iteration #311 | Epoch Duration: 169.0025691986084
2020-01-10 23:40:01.974152 UTC | [2020_01_10_09_29_40] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0731289
Z variance train             0.014360202
KL Divergence                8.225258
KL Loss                      0.8225258
QF Loss                      60.62178
VF Loss                      18.541721
Policy Loss                  -1398.1583
Q Predictions Mean           1399.2089
Q Predictions Std            346.70157
Q Predictions Max            1732.3466
Q Predictions Min            74.54564
V Predictions Mean           1398.3147
V Predictions Std            348.37155
V Predictions Max            1734.4327
V Predictions Min            75.72659
Log Pis Mean                 -0.12375204
Log Pis Std                  1.9429793
Log Pis Max                  6.0006394
Log Pis Min                  -5.7354193
Policy mu Mean               -0.14007407
Policy mu Std                0.9064969
Policy mu Max                2.0754015
Policy mu Min                -2.5927272
Policy log std Mean          -0.5134853
Policy log std Std           0.1763916
Policy log std Max           0.16018307
Policy log std Min           -0.9656236
Z mean eval                  0.07044534
Z variance eval              0.012420665
total_rewards                [3336.03611118 3324.11959364 2623.64442115 3300.25442874 3319.87107679
 3316.33557479 3349.90983356 3309.78285432 3317.89904248  914.16765153]
total_rewards_mean           3011.2020588183364
total_rewards_std            729.4559314122052
total_rewards_max            3349.9098335581343
total_rewards_min            914.1676515285683
Number of train steps total  1252000
Number of env steps total    1344318
Number of rollouts total     0
Train Time (s)               144.15506246779114
(Previous) Eval Time (s)     19.647912899032235
Sample Time (s)              6.595248070079833
Epoch Time (s)               170.3982234369032
Total Train Time (s)         51191.516979341395
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:42:52.463787 UTC | [2020_01_10_09_29_40] Iteration #312 | Epoch Duration: 170.48943829536438
2020-01-10 23:42:52.464067 UTC | [2020_01_10_09_29_40] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07040077
Z variance train             0.012420794
KL Divergence                8.760544
KL Loss                      0.8760544
QF Loss                      59.380577
VF Loss                      12.010708
Policy Loss                  -1430.4642
Q Predictions Mean           1430.6093
Q Predictions Std            340.0678
Q Predictions Max            1743.6812
Q Predictions Min            37.73201
V Predictions Mean           1429.3623
V Predictions Std            341.24835
V Predictions Max            1743.5336
V Predictions Min            34.175766
Log Pis Mean                 0.0055705793
Log Pis Std                  2.100462
Log Pis Max                  7.973237
Log Pis Min                  -4.935442
Policy mu Mean               -0.062549956
Policy mu Std                0.92930645
Policy mu Max                1.805683
Policy mu Min                -2.4838574
Policy log std Mean          -0.5209318
Policy log std Std           0.17951286
Policy log std Max           0.081030905
Policy log std Min           -1.0597674
Z mean eval                  0.07219126
Z variance eval              0.012494863
total_rewards                [3326.67931208 3312.24932826 3335.95223336 3326.5073944  3337.00196363
 3378.8640332  3333.62755758 3348.20715334 3321.05379078 3339.11160746]
total_rewards_mean           3335.925437408457
total_rewards_std            17.225183594646047
total_rewards_max            3378.8640332032332
total_rewards_min            3312.249328262258
Number of train steps total  1256000
Number of env steps total    1350032
Number of rollouts total     0
Train Time (s)               144.8813273771666
(Previous) Eval Time (s)     18.612031432334334
Sample Time (s)              5.708540499676019
Epoch Time (s)               169.20189930917695
Total Train Time (s)         51360.799332221504
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:45:41.748322 UTC | [2020_01_10_09_29_40] Iteration #313 | Epoch Duration: 169.2841076850891
2020-01-10 23:45:41.748504 UTC | [2020_01_10_09_29_40] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.071955465
Z variance train             0.012461072
KL Divergence                8.706624
KL Loss                      0.8706624
QF Loss                      73.17572
VF Loss                      23.746689
Policy Loss                  -1382.4825
Q Predictions Mean           1381.8387
Q Predictions Std            362.26187
Q Predictions Max            1703.6156
Q Predictions Min            102.02928
V Predictions Mean           1381.709
V Predictions Std            360.58112
V Predictions Max            1706.1566
V Predictions Min            126.44839
Log Pis Mean                 0.092696376
Log Pis Std                  1.9681053
Log Pis Max                  6.0961113
Log Pis Min                  -4.28501
Policy mu Mean               -0.14131744
Policy mu Std                0.91126627
Policy mu Max                1.9022319
Policy mu Min                -2.698406
Policy log std Mean          -0.5400722
Policy log std Std           0.18755655
Policy log std Max           0.17341918
Policy log std Min           -1.1000807
Z mean eval                  0.08993034
Z variance eval              0.014869404
total_rewards                [3382.01547721 3288.8293859  3309.99059247 3309.23417778 3346.41288349
 3284.3297117  3311.46311562 3288.40113888 3320.58219351 3283.51873323]
total_rewards_mean           3312.4777409796516
total_rewards_std            29.732763127451797
total_rewards_max            3382.0154772125497
total_rewards_min            3283.518733228258
Number of train steps total  1260000
Number of env steps total    1355643
Number of rollouts total     0
Train Time (s)               145.69143626792356
(Previous) Eval Time (s)     21.548997496254742
Sample Time (s)              6.738449372816831
Epoch Time (s)               173.97888313699514
Total Train Time (s)         51534.878851222806
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:48:35.831726 UTC | [2020_01_10_09_29_40] Iteration #314 | Epoch Duration: 174.08304500579834
2020-01-10 23:48:35.831979 UTC | [2020_01_10_09_29_40] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08950785
Z variance train             0.014851267
KL Divergence                8.209479
KL Loss                      0.82094795
QF Loss                      56.686455
VF Loss                      21.56934
Policy Loss                  -1398.1044
Q Predictions Mean           1398.4803
Q Predictions Std            344.42612
Q Predictions Max            1736.3212
Q Predictions Min            96.464485
V Predictions Mean           1397.49
V Predictions Std            344.26675
V Predictions Max            1733.0004
V Predictions Min            133.47838
Log Pis Mean                 0.043336295
Log Pis Std                  2.1384158
Log Pis Max                  6.285384
Log Pis Min                  -5.7415156
Policy mu Mean               -0.07026016
Policy mu Std                0.90356374
Policy mu Max                2.0473459
Policy mu Min                -2.513723
Policy log std Mean          -0.5284764
Policy log std Std           0.17745446
Policy log std Max           0.15242082
Policy log std Min           -1.0485072
Z mean eval                  0.07507773
Z variance eval              0.014876312
total_rewards                [3305.05694714 3324.81335375 3317.96985716 3301.12604875 2237.65889552
 3323.60914933 3311.48054947 3312.52617828 3345.85356623 3316.41532197]
total_rewards_mean           3209.650986761616
total_rewards_std            324.210232988168
total_rewards_max            3345.8535662329405
total_rewards_min            2237.6588955234383
Number of train steps total  1264000
Number of env steps total    1361659
Number of rollouts total     0
Train Time (s)               147.82232154579833
(Previous) Eval Time (s)     17.966113513801247
Sample Time (s)              5.615457359235734
Epoch Time (s)               171.4038924188353
Total Train Time (s)         51706.36110452935
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:51:27.315568 UTC | [2020_01_10_09_29_40] Iteration #315 | Epoch Duration: 171.48346209526062
2020-01-10 23:51:27.315683 UTC | [2020_01_10_09_29_40] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07368841
Z variance train             0.014866248
KL Divergence                8.345654
KL Loss                      0.83456534
QF Loss                      81.2166
VF Loss                      24.09205
Policy Loss                  -1432.1025
Q Predictions Mean           1433.4368
Q Predictions Std            332.5451
Q Predictions Max            1727.8646
Q Predictions Min            18.146908
V Predictions Mean           1434.1145
V Predictions Std            332.8472
V Predictions Max            1729.0485
V Predictions Min            37.744503
Log Pis Mean                 0.16812992
Log Pis Std                  2.0756662
Log Pis Max                  8.707288
Log Pis Min                  -4.408465
Policy mu Mean               -0.09375665
Policy mu Std                0.932309
Policy mu Max                1.984285
Policy mu Min                -2.58816
Policy log std Mean          -0.568638
Policy log std Std           0.1748273
Policy log std Max           -0.026183248
Policy log std Min           -1.1687334
Z mean eval                  0.047558907
Z variance eval              0.014263648
total_rewards                [3327.24111189 3343.66927247 3257.00498891 3287.99011152  630.65631461
 3344.27943116 1001.29930468 2621.99958659  895.65999261 3290.56172617]
total_rewards_mean           2500.036184061347
total_rewards_std            1107.1235975238967
total_rewards_max            3344.2794311617813
total_rewards_min            630.6563146127596
Number of train steps total  1268000
Number of env steps total    1367523
Number of rollouts total     0
Train Time (s)               146.6628900510259
(Previous) Eval Time (s)     14.065818340983242
Sample Time (s)              5.71356779942289
Epoch Time (s)               166.44227619143203
Total Train Time (s)         51872.88883850258
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:54:13.848273 UTC | [2020_01_10_09_29_40] Iteration #316 | Epoch Duration: 166.53249192237854
2020-01-10 23:54:13.848436 UTC | [2020_01_10_09_29_40] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045840967
Z variance train             0.01429109
KL Divergence                8.340605
KL Loss                      0.8340605
QF Loss                      79.52991
VF Loss                      107.38228
Policy Loss                  -1434.0413
Q Predictions Mean           1431.2122
Q Predictions Std            318.03848
Q Predictions Max            1754.8705
Q Predictions Min            86.625046
V Predictions Mean           1425.1538
V Predictions Std            316.9992
V Predictions Max            1747.5994
V Predictions Min            83.45507
Log Pis Mean                 -0.113271326
Log Pis Std                  1.9578729
Log Pis Max                  6.8512373
Log Pis Min                  -5.067901
Policy mu Mean               -0.1644516
Policy mu Std                0.87978834
Policy mu Max                1.6974277
Policy mu Min                -2.5515401
Policy log std Mean          -0.5164502
Policy log std Std           0.18777494
Policy log std Max           0.12798756
Policy log std Min           -0.9435483
Z mean eval                  0.11526097
Z variance eval              0.017191028
total_rewards                [3377.42605789 3356.31107217 3387.4813916  3394.42618047  939.39876564
 1485.89885717  996.90665425 1074.36726392  944.63329865 3399.08317404]
total_rewards_mean           2235.5932715825033
total_rewards_std            1156.4933698943275
total_rewards_max            3399.0831740448784
total_rewards_min            939.3987656437365
Number of train steps total  1272000
Number of env steps total    1373284
Number of rollouts total     0
Train Time (s)               145.9496031170711
(Previous) Eval Time (s)     14.433054240886122
Sample Time (s)              6.635310265235603
Epoch Time (s)               167.01796762319282
Total Train Time (s)         52039.9875496123
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:57:00.949062 UTC | [2020_01_10_09_29_40] Iteration #317 | Epoch Duration: 167.10051894187927
2020-01-10 23:57:00.949189 UTC | [2020_01_10_09_29_40] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11634133
Z variance train             0.017174812
KL Divergence                8.294701
KL Loss                      0.8294701
QF Loss                      174.5539
VF Loss                      47.56195
Policy Loss                  -1444.9174
Q Predictions Mean           1439.609
Q Predictions Std            306.6187
Q Predictions Max            1726.4993
Q Predictions Min            48.67229
V Predictions Mean           1449.3335
V Predictions Std            309.25256
V Predictions Max            1738.2776
V Predictions Min            51.54813
Log Pis Mean                 -0.10976295
Log Pis Std                  1.8458381
Log Pis Max                  6.692446
Log Pis Min                  -4.749726
Policy mu Mean               0.03894402
Policy mu Std                0.8791113
Policy mu Max                2.6645932
Policy mu Min                -2.4596484
Policy log std Mean          -0.5245045
Policy log std Std           0.188667
Policy log std Max           0.14191866
Policy log std Min           -1.242419
Z mean eval                  0.06525023
Z variance eval              0.016655542
total_rewards                [3298.46096312  986.40625594 3307.1157463  3322.81547448 3285.63165305
 3318.19148221 3296.90435402 3290.12494783  928.9128738  3318.46895107]
total_rewards_mean           2835.303270180908
total_rewards_std            938.9834287756795
total_rewards_max            3322.8154744798553
total_rewards_min            928.9128737988784
Number of train steps total  1276000
Number of env steps total    1379158
Number of rollouts total     0
Train Time (s)               143.79060847265646
(Previous) Eval Time (s)     18.289631437975913
Sample Time (s)              6.886409394908696
Epoch Time (s)               168.96664930554107
Total Train Time (s)         52209.04481383553
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:59:50.014720 UTC | [2020_01_10_09_29_40] Iteration #318 | Epoch Duration: 169.06535935401917
2020-01-10 23:59:50.015020 UTC | [2020_01_10_09_29_40] Iteration #318 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.065592594
Z variance train             0.016634548
KL Divergence                8.512493
KL Loss                      0.85124934
QF Loss                      67.31099
VF Loss                      26.227232
Policy Loss                  -1409.2719
Q Predictions Mean           1411.1028
Q Predictions Std            340.92398
Q Predictions Max            1764.692
Q Predictions Min            53.505653
V Predictions Mean           1408.219
V Predictions Std            339.19894
V Predictions Max            1762.786
V Predictions Min            54.708622
Log Pis Mean                 -0.14202179
Log Pis Std                  2.0941737
Log Pis Max                  6.976576
Log Pis Min                  -6.0768223
Policy mu Mean               -0.12052416
Policy mu Std                0.896556
Policy mu Max                2.1802304
Policy mu Min                -2.5717986
Policy log std Mean          -0.5394664
Policy log std Std           0.18182938
Policy log std Max           -0.037147522
Policy log std Min           -1.0759616
Z mean eval                  0.104112014
Z variance eval              0.013765642
total_rewards                [108.67019782 576.71161806  13.43571606 124.02932872  74.01272398
 121.7408982   82.01164553 103.17931348  72.03728524  17.52688094]
total_rewards_mean           129.33556080256045
total_rewards_std            153.57721010051986
total_rewards_max            576.7116180568493
total_rewards_min            13.435716060696734
Number of train steps total  1280000
Number of env steps total    1385126
Number of rollouts total     0
Train Time (s)               144.54572262894362
(Previous) Eval Time (s)     1.21160840196535
Sample Time (s)              6.7807059939950705
Epoch Time (s)               152.53803702490404
Total Train Time (s)         52361.66834333958
Epoch                        319
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:02:22.640087 UTC | [2020_01_10_09_29_40] Iteration #319 | Epoch Duration: 152.62486624717712
2020-01-11 00:02:22.640206 UTC | [2020_01_10_09_29_40] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10402032
Z variance train             0.013774509
KL Divergence                9.016981
KL Loss                      0.9016981
QF Loss                      2648.8977
VF Loss                      73.875336
Policy Loss                  -1373.077
Q Predictions Mean           1374.3809
Q Predictions Std            403.43518
Q Predictions Max            1720.5906
Q Predictions Min            51.254215
V Predictions Mean           1376.104
V Predictions Std            402.6488
V Predictions Max            1721.1698
V Predictions Min            60.99914
Log Pis Mean                 -0.16675964
Log Pis Std                  2.0234487
Log Pis Max                  9.496823
Log Pis Min                  -5.285892
Policy mu Mean               -0.21400273
Policy mu Std                0.88899684
Policy mu Max                1.560214
Policy mu Min                -3.4688556
Policy log std Mean          -0.51706547
Policy log std Std           0.18197097
Policy log std Max           0.0934183
Policy log std Min           -1.1006558
Z mean eval                  0.1587373
Z variance eval              0.016736034
total_rewards                [3214.76711171 3231.03657834 3238.76192157 3263.33914751 3227.94227187
 3245.86343068 3223.49485257 3233.55028786 3226.22228425 3247.49478428]
total_rewards_mean           3235.247267063514
total_rewards_std            13.331129241666503
total_rewards_max            3263.3391475091616
total_rewards_min            3214.767111711891
Number of train steps total  1284000
Number of env steps total    1391500
Number of rollouts total     0
Train Time (s)               145.8011804833077
(Previous) Eval Time (s)     21.795216143596917
Sample Time (s)              5.588514096103609
Epoch Time (s)               173.18491072300822
Total Train Time (s)         52534.935782999266
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:05:15.909638 UTC | [2020_01_10_09_29_40] Iteration #320 | Epoch Duration: 173.26934266090393
2020-01-11 00:05:15.909764 UTC | [2020_01_10_09_29_40] Iteration #320 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15820359
Z variance train             0.016689848
KL Divergence                8.534673
KL Loss                      0.8534673
QF Loss                      78.07927
VF Loss                      18.69801
Policy Loss                  -1377.95
Q Predictions Mean           1379.3447
Q Predictions Std            333.606
Q Predictions Max            1715.7646
Q Predictions Min            28.720568
V Predictions Mean           1377.6665
V Predictions Std            334.1642
V Predictions Max            1716.8856
V Predictions Min            14.367198
Log Pis Mean                 -0.09916704
Log Pis Std                  2.1170988
Log Pis Max                  6.293865
Log Pis Min                  -6.5558224
Policy mu Mean               -0.1019269
Policy mu Std                0.924892
Policy mu Max                2.1362557
Policy mu Min                -2.9230313
Policy log std Mean          -0.547044
Policy log std Std           0.17774168
Policy log std Max           0.008292258
Policy log std Min           -1.3214979
Z mean eval                  0.08803223
Z variance eval              0.017668333
total_rewards                [3332.3456206  3293.7282432  3320.42772381 3308.69736181 3323.92453711
 3276.4683382  3324.6246706  3278.18637324 3309.23241774 3310.49164909]
total_rewards_mean           3307.8126935384307
total_rewards_std            18.36238502979883
total_rewards_max            3332.345620595697
total_rewards_min            3276.4683382009794
Number of train steps total  1288000
Number of env steps total    1397625
Number of rollouts total     0
Train Time (s)               146.85114328097552
(Previous) Eval Time (s)     18.995120130013674
Sample Time (s)              6.862648520153016
Epoch Time (s)               172.7089119311422
Total Train Time (s)         52707.72691507405
Epoch                        321
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:08:08.704207 UTC | [2020_01_10_09_29_40] Iteration #321 | Epoch Duration: 172.79432368278503
2020-01-11 00:08:08.704370 UTC | [2020_01_10_09_29_40] Iteration #321 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.090795614
Z variance train             0.017764024
KL Divergence                7.968047
KL Loss                      0.7968047
QF Loss                      135.18384
VF Loss                      56.62513
Policy Loss                  -1405.771
Q Predictions Mean           1407.9698
Q Predictions Std            335.96933
Q Predictions Max            1729.3442
Q Predictions Min            9.354698
V Predictions Mean           1405.7059
V Predictions Std            336.89993
V Predictions Max            1723.5398
V Predictions Min            -12.733383
Log Pis Mean                 0.08490293
Log Pis Std                  1.9508277
Log Pis Max                  5.883897
Log Pis Min                  -4.4534388
Policy mu Mean               -0.1576173
Policy mu Std                0.9006997
Policy mu Max                1.9175992
Policy mu Min                -2.6142366
Policy log std Mean          -0.55896354
Policy log std Std           0.17216659
Policy log std Max           -0.0771088
Policy log std Min           -1.376919
Z mean eval                  0.07370128
Z variance eval              0.012716983
total_rewards                [3289.34873377 3288.74872531 3326.81737038 3285.12341525 3290.2098894
 3316.63052191 3280.11048177 3302.14134539 3341.58966874 3286.66842891]
total_rewards_mean           3300.7388580833003
total_rewards_std            19.634397935686078
total_rewards_max            3341.5896687391623
total_rewards_min            3280.110481773784
Number of train steps total  1292000
Number of env steps total    1404126
Number of rollouts total     0
Train Time (s)               146.77891800459474
(Previous) Eval Time (s)     18.29605270875618
Sample Time (s)              6.6653481824323535
Epoch Time (s)               171.74031889578328
Total Train Time (s)         52879.54570109071
Epoch                        322
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:11:00.529761 UTC | [2020_01_10_09_29_40] Iteration #322 | Epoch Duration: 171.82520508766174
2020-01-11 00:11:00.530025 UTC | [2020_01_10_09_29_40] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07338478
Z variance train             0.0127505455
KL Divergence                8.607935
KL Loss                      0.86079353
QF Loss                      62.0092
VF Loss                      27.675392
Policy Loss                  -1376.3339
Q Predictions Mean           1373.5735
Q Predictions Std            375.93124
Q Predictions Max            1740.8265
Q Predictions Min            37.117645
V Predictions Mean           1373.5099
V Predictions Std            376.60077
V Predictions Max            1736.6702
V Predictions Min            37.508556
Log Pis Mean                 -0.084162936
Log Pis Std                  1.899525
Log Pis Max                  7.216712
Log Pis Min                  -3.8179843
Policy mu Mean               -0.11576714
Policy mu Std                0.8904468
Policy mu Max                2.2016222
Policy mu Min                -2.803706
Policy log std Mean          -0.52734536
Policy log std Std           0.1739555
Policy log std Max           0.120970726
Policy log std Min           -1.1752617
Z mean eval                  0.22468662
Z variance eval              0.013117415
total_rewards                [3282.05758828 3253.87086919 3245.73750458 3248.59147046 3283.61627892
 3289.30830336 3289.24456949 3280.92762714 3297.8309108  3277.44306025]
total_rewards_mean           3274.8628182458046
total_rewards_std            17.58976112912266
total_rewards_max            3297.8309107973637
total_rewards_min            3245.737504581985
Number of train steps total  1296000
Number of env steps total    1410113
Number of rollouts total     0
Train Time (s)               145.6255743978545
(Previous) Eval Time (s)     21.913789059966803
Sample Time (s)              6.604962136596441
Epoch Time (s)               174.14432559441775
Total Train Time (s)         53053.765774881
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:13:54.753858 UTC | [2020_01_10_09_29_40] Iteration #323 | Epoch Duration: 174.2236864566803
2020-01-11 00:13:54.754032 UTC | [2020_01_10_09_29_40] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22498913
Z variance train             0.013117073
KL Divergence                8.749554
KL Loss                      0.87495536
QF Loss                      53.155666
VF Loss                      32.531464
Policy Loss                  -1381.385
Q Predictions Mean           1382.0094
Q Predictions Std            361.6484
Q Predictions Max            1739.3701
Q Predictions Min            33.67831
V Predictions Mean           1385.1177
V Predictions Std            360.54187
V Predictions Max            1741.8992
V Predictions Min            21.079788
Log Pis Mean                 0.07019071
Log Pis Std                  2.0387385
Log Pis Max                  7.338505
Log Pis Min                  -6.2879214
Policy mu Mean               -0.1509242
Policy mu Std                0.917873
Policy mu Max                1.8406819
Policy mu Min                -2.6186628
Policy log std Mean          -0.5485749
Policy log std Std           0.17285697
Policy log std Max           0.0187577
Policy log std Min           -1.0428743
Z mean eval                  0.15436006
Z variance eval              0.012914698
total_rewards                [3325.79917294 3320.12542701 3265.08756278  880.31590787 3287.14504577
 3289.20881271 1330.78073594 3302.96898395 1019.97914597 3261.01704242]
total_rewards_mean           2628.2427837367027
total_rewards_std            1020.9168834089159
total_rewards_max            3325.7991729391993
total_rewards_min            880.3159078688562
Number of train steps total  1300000
Number of env steps total    1416220
Number of rollouts total     0
Train Time (s)               145.443900431972
(Previous) Eval Time (s)     17.49105082033202
Sample Time (s)              6.6181850573048
Epoch Time (s)               169.55313630960882
Total Train Time (s)         53223.40031356178
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:16:44.390384 UTC | [2020_01_10_09_29_40] Iteration #324 | Epoch Duration: 169.63623213768005
2020-01-11 00:16:44.390528 UTC | [2020_01_10_09_29_40] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15444362
Z variance train             0.012910242
KL Divergence                8.612548
KL Loss                      0.8612548
QF Loss                      80.152176
VF Loss                      26.690342
Policy Loss                  -1437.8547
Q Predictions Mean           1436.8878
Q Predictions Std            315.531
Q Predictions Max            1737.0939
Q Predictions Min            69.13502
V Predictions Mean           1440.2268
V Predictions Std            316.7545
V Predictions Max            1746.8914
V Predictions Min            89.34963
Log Pis Mean                 0.099463984
Log Pis Std                  2.1328218
Log Pis Max                  7.760418
Log Pis Min                  -4.873349
Policy mu Mean               -0.14569038
Policy mu Std                0.91184807
Policy mu Max                2.2351935
Policy mu Min                -2.8175883
Policy log std Mean          -0.52771395
Policy log std Std           0.18559167
Policy log std Max           0.10795146
Policy log std Min           -1.1835208
Z mean eval                  0.16011369
Z variance eval              0.011734356
total_rewards                [3278.30613342 3320.3732184  3349.53192698 3323.54488875 3327.84727659
 3336.60905856 3324.17398999 3273.0058652  3328.13753339 3305.7413419 ]
total_rewards_mean           3316.7271233189117
total_rewards_std            23.12777937061323
total_rewards_max            3349.531926980625
total_rewards_min            3273.005865204026
Number of train steps total  1304000
Number of env steps total    1422567
Number of rollouts total     0
Train Time (s)               146.35161948110908
(Previous) Eval Time (s)     18.715963810216635
Sample Time (s)              6.5702281962148845
Epoch Time (s)               171.6378114875406
Total Train Time (s)         53395.11368108215
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:19:36.107502 UTC | [2020_01_10_09_29_40] Iteration #325 | Epoch Duration: 171.71686244010925
2020-01-11 00:19:36.107667 UTC | [2020_01_10_09_29_40] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1591993
Z variance train             0.011700043
KL Divergence                9.209353
KL Loss                      0.92093533
QF Loss                      97.54056
VF Loss                      21.444353
Policy Loss                  -1446.6556
Q Predictions Mean           1448.185
Q Predictions Std            308.3699
Q Predictions Max            1759.5363
Q Predictions Min            60.347893
V Predictions Mean           1446.1533
V Predictions Std            306.95285
V Predictions Max            1757.0607
V Predictions Min            67.79412
Log Pis Mean                 0.14177386
Log Pis Std                  1.9637016
Log Pis Max                  6.456004
Log Pis Min                  -4.523358
Policy mu Mean               -0.20093095
Policy mu Std                0.9214813
Policy mu Max                1.8732585
Policy mu Min                -2.7227025
Policy log std Mean          -0.5440377
Policy log std Std           0.18528292
Policy log std Max           0.12634683
Policy log std Min           -1.1795762
Z mean eval                  0.09078546
Z variance eval              0.010069659
total_rewards                [3315.02441506 3288.05794889 3311.59382074 3272.69088396 3294.72660978
 3297.18994616 3334.17530406 3301.02906517 3313.06589908 3307.12522674]
total_rewards_mean           3303.4679119634993
total_rewards_std            15.98276572384857
total_rewards_max            3334.1753040631775
total_rewards_min            3272.690883958077
Number of train steps total  1308000
Number of env steps total    1428420
Number of rollouts total     0
Train Time (s)               145.8579001291655
(Previous) Eval Time (s)     21.65715626999736
Sample Time (s)              6.5967559814453125
Epoch Time (s)               174.11181238060817
Total Train Time (s)         53569.303238159046
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:22:30.298722 UTC | [2020_01_10_09_29_40] Iteration #326 | Epoch Duration: 174.19093227386475
2020-01-11 00:22:30.298867 UTC | [2020_01_10_09_29_40] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09124218
Z variance train             0.010071518
KL Divergence                9.590807
KL Loss                      0.9590807
QF Loss                      93.535286
VF Loss                      50.204144
Policy Loss                  -1451.5231
Q Predictions Mean           1449.2711
Q Predictions Std            323.77896
Q Predictions Max            1729.3577
Q Predictions Min            163.32602
V Predictions Mean           1451.1438
V Predictions Std            321.9425
V Predictions Max            1730.3926
V Predictions Min            199.75641
Log Pis Mean                 3.837049e-05
Log Pis Std                  1.9585758
Log Pis Max                  5.6862044
Log Pis Min                  -4.5557585
Policy mu Mean               -0.15582186
Policy mu Std                0.903056
Policy mu Max                2.4907758
Policy mu Min                -2.5880377
Policy log std Mean          -0.5553418
Policy log std Std           0.18158238
Policy log std Max           0.21548575
Policy log std Min           -1.2744144
Z mean eval                  0.17501484
Z variance eval              0.0062033827
total_rewards                [3320.28391092 3311.40274691 3331.7622638  3324.60580794 3336.03529745
 1715.84549002 3332.44104881 3328.80175128 3345.30867711 3303.02665487]
total_rewards_mean           3164.951364911704
total_rewards_std            483.17310169483284
total_rewards_max            3345.308677110285
total_rewards_min            1715.845490019233
Number of train steps total  1312000
Number of env steps total    1434797
Number of rollouts total     0
Train Time (s)               145.52702079713345
(Previous) Eval Time (s)     20.629142047371715
Sample Time (s)              6.49696279456839
Epoch Time (s)               172.65312563907355
Total Train Time (s)         53742.03829869861
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:25:23.037200 UTC | [2020_01_10_09_29_40] Iteration #327 | Epoch Duration: 172.73822116851807
2020-01-11 00:25:23.037385 UTC | [2020_01_10_09_29_40] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17205277
Z variance train             0.00620301
KL Divergence                10.384701
KL Loss                      1.0384701
QF Loss                      148.96277
VF Loss                      201.34398
Policy Loss                  -1425.6599
Q Predictions Mean           1429.9675
Q Predictions Std            335.71127
Q Predictions Max            1743.9298
Q Predictions Min            101.63215
V Predictions Mean           1413.8896
V Predictions Std            336.75693
V Predictions Max            1730.4167
V Predictions Min            79.341415
Log Pis Mean                 0.011395402
Log Pis Std                  2.103438
Log Pis Max                  7.2605643
Log Pis Min                  -6.85089
Policy mu Mean               -0.22092251
Policy mu Std                0.9265374
Policy mu Max                2.6741824
Policy mu Min                -2.5789752
Policy log std Mean          -0.52180034
Policy log std Std           0.18915941
Policy log std Max           0.09638327
Policy log std Min           -1.2021058
Z mean eval                  0.094203725
Z variance eval              0.0120294
total_rewards                [3331.73309538 3343.07537856 3349.02591829 3320.5170401  3351.39527122
 3326.96858904 3347.93164484 3357.23007415 3358.24311937 1152.93900499]
total_rewards_mean           3123.9059135934626
total_rewards_std            657.0997165132666
total_rewards_max            3358.2431193701073
total_rewards_min            1152.939004989276
Number of train steps total  1316000
Number of env steps total    1440988
Number of rollouts total     0
Train Time (s)               145.99306807899848
(Previous) Eval Time (s)     20.26791108539328
Sample Time (s)              5.696662957314402
Epoch Time (s)               171.95764212170616
Total Train Time (s)         53914.09468325088
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:28:15.098970 UTC | [2020_01_10_09_29_40] Iteration #328 | Epoch Duration: 172.06144905090332
2020-01-11 00:28:15.099162 UTC | [2020_01_10_09_29_40] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.094752
Z variance train             0.012028607
KL Divergence                8.788373
KL Loss                      0.8788373
QF Loss                      59.863907
VF Loss                      15.484478
Policy Loss                  -1453.8351
Q Predictions Mean           1452.7976
Q Predictions Std            289.81454
Q Predictions Max            1772.869
Q Predictions Min            27.669537
V Predictions Mean           1453.7834
V Predictions Std            290.0085
V Predictions Max            1777.6705
V Predictions Min            40.032627
Log Pis Mean                 -0.09925219
Log Pis Std                  2.1617148
Log Pis Max                  6.005313
Log Pis Min                  -7.5419946
Policy mu Mean               -0.11719676
Policy mu Std                0.89439946
Policy mu Max                1.7795627
Policy mu Min                -2.6003654
Policy log std Mean          -0.5239365
Policy log std Std           0.19034089
Policy log std Max           0.13072598
Policy log std Min           -1.1695404
Z mean eval                  0.07157538
Z variance eval              0.016979214
total_rewards                [3263.93068444 1410.9369017  3323.77641353 3312.51409384  770.61479427
 3305.6384443  3289.69937436 3341.82543485 3273.66736489  831.36756331]
total_rewards_mean           2612.3971069474546
total_rewards_std            1064.7591847934852
total_rewards_max            3341.825434848759
total_rewards_min            770.614794265705
Number of train steps total  1320000
Number of env steps total    1446882
Number of rollouts total     0
Train Time (s)               147.37637482304126
(Previous) Eval Time (s)     14.559152842964977
Sample Time (s)              6.6054231454618275
Epoch Time (s)               168.54095081146806
Total Train Time (s)         54082.7239660318
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:31:03.732119 UTC | [2020_01_10_09_29_40] Iteration #329 | Epoch Duration: 168.63281631469727
2020-01-11 00:31:03.732288 UTC | [2020_01_10_09_29_40] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07146569
Z variance train             0.01695112
KL Divergence                7.879266
KL Loss                      0.7879266
QF Loss                      68.11507
VF Loss                      15.0543785
Policy Loss                  -1453.1997
Q Predictions Mean           1452.8607
Q Predictions Std            311.09784
Q Predictions Max            1751.4135
Q Predictions Min            47.961815
V Predictions Mean           1452.2534
V Predictions Std            311.16812
V Predictions Max            1746.7505
V Predictions Min            60.399197
Log Pis Mean                 -0.18920392
Log Pis Std                  1.8827549
Log Pis Max                  6.9471955
Log Pis Min                  -4.2990093
Policy mu Mean               -0.047559682
Policy mu Std                0.8781041
Policy mu Max                2.0240119
Policy mu Min                -2.6010234
Policy log std Mean          -0.52737164
Policy log std Std           0.17124373
Policy log std Max           -0.061104715
Policy log std Min           -1.0563495
Z mean eval                  0.11401343
Z variance eval              0.01928705
total_rewards                [3363.61435251 3302.93477991 3338.03590929 3363.02277733 3315.10374281
 3339.50740297 3331.11953606 3313.93757389  990.57500423 3322.63740624]
total_rewards_mean           3098.0488485251235
total_rewards_std            702.7474102743992
total_rewards_max            3363.6143525110983
total_rewards_min            990.5750042338742
Number of train steps total  1324000
Number of env steps total    1453248
Number of rollouts total     0
Train Time (s)               145.49004730395973
(Previous) Eval Time (s)     17.36780240619555
Sample Time (s)              6.419986030086875
Epoch Time (s)               169.27783574024215
Total Train Time (s)         54252.08191991085
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:33:53.093126 UTC | [2020_01_10_09_29_40] Iteration #330 | Epoch Duration: 169.36070370674133
2020-01-11 00:33:53.093301 UTC | [2020_01_10_09_29_40] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.113708675
Z variance train             0.019271335
KL Divergence                7.68373
KL Loss                      0.768373
QF Loss                      40.211746
VF Loss                      19.098265
Policy Loss                  -1426.598
Q Predictions Mean           1428.5242
Q Predictions Std            349.17072
Q Predictions Max            1786.4043
Q Predictions Min            40.164143
V Predictions Mean           1429.1968
V Predictions Std            348.53036
V Predictions Max            1783.9445
V Predictions Min            51.34189
Log Pis Mean                 -0.16106045
Log Pis Std                  1.8966923
Log Pis Max                  6.829557
Log Pis Min                  -5.7771955
Policy mu Mean               -0.039498206
Policy mu Std                0.8630941
Policy mu Max                1.9916517
Policy mu Min                -2.552381
Policy log std Mean          -0.52187055
Policy log std Std           0.1742026
Policy log std Max           0.06846559
Policy log std Min           -1.1215489
Z mean eval                  0.032137882
Z variance eval              0.018816292
total_rewards                [1132.01906995  243.97540847 3302.48481755 1026.83506838 1027.99756189
 3294.91426529 3286.20433033  728.06892577 3323.7916984  3309.20872815]
total_rewards_mean           2067.549987417583
total_rewards_std            1256.7845409151994
total_rewards_max            3323.791698399935
total_rewards_min            243.97540846554057
Number of train steps total  1328000
Number of env steps total    1459531
Number of rollouts total     0
Train Time (s)               144.96250098291785
(Previous) Eval Time (s)     13.399713951628655
Sample Time (s)              6.682586794253439
Epoch Time (s)               165.04480172879994
Total Train Time (s)         54417.207235601265
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:36:38.222797 UTC | [2020_01_10_09_29_40] Iteration #331 | Epoch Duration: 165.12936687469482
2020-01-11 00:36:38.222973 UTC | [2020_01_10_09_29_40] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03267262
Z variance train             0.018861443
KL Divergence                7.5575027
KL Loss                      0.7557503
QF Loss                      111.705154
VF Loss                      28.570038
Policy Loss                  -1425.4838
Q Predictions Mean           1426.5076
Q Predictions Std            335.1957
Q Predictions Max            1764.0538
Q Predictions Min            247.06032
V Predictions Mean           1422.3369
V Predictions Std            332.93643
V Predictions Max            1756.6619
V Predictions Min            246.00832
Log Pis Mean                 -0.23067498
Log Pis Std                  1.93532
Log Pis Max                  5.303594
Log Pis Min                  -5.5952067
Policy mu Mean               -0.02822552
Policy mu Std                0.876981
Policy mu Max                1.9048674
Policy mu Min                -2.7514706
Policy log std Mean          -0.5191124
Policy log std Std           0.17670538
Policy log std Max           0.13524002
Policy log std Min           -1.1043494
Z mean eval                  0.103068724
Z variance eval              0.012666581
total_rewards                [1259.67431332 3320.28598883 3310.04492001 3317.1410801  3320.61628192
 3271.34409942  990.73895562 3318.79805131 3302.56849869 3310.76807134]
total_rewards_mean           2872.1980260566365
total_rewards_std            875.6710875143345
total_rewards_max            3320.6162819225224
total_rewards_min            990.7389556197163
Number of train steps total  1332000
Number of env steps total    1465710
Number of rollouts total     0
Train Time (s)               146.86519433371723
(Previous) Eval Time (s)     19.010990709997714
Sample Time (s)              6.351440936792642
Epoch Time (s)               172.22762598050758
Total Train Time (s)         54589.52853584243
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:39:30.548046 UTC | [2020_01_10_09_29_40] Iteration #332 | Epoch Duration: 172.32488870620728
2020-01-11 00:39:30.548302 UTC | [2020_01_10_09_29_40] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10306732
Z variance train             0.012691448
KL Divergence                8.60162
KL Loss                      0.86016196
QF Loss                      98.24324
VF Loss                      38.83602
Policy Loss                  -1423.9248
Q Predictions Mean           1423.3708
Q Predictions Std            345.70615
Q Predictions Max            1748.4873
Q Predictions Min            120.42118
V Predictions Mean           1425.1821
V Predictions Std            344.55917
V Predictions Max            1745.9866
V Predictions Min            128.71646
Log Pis Mean                 -0.20519982
Log Pis Std                  2.0178494
Log Pis Max                  5.228128
Log Pis Min                  -7.036742
Policy mu Mean               -0.14642976
Policy mu Std                0.8921044
Policy mu Max                2.2758873
Policy mu Min                -2.7748594
Policy log std Mean          -0.51582307
Policy log std Std           0.17873135
Policy log std Max           0.1680826
Policy log std Min           -1.1964608
Z mean eval                  0.075893745
Z variance eval              0.010829441
total_rewards                [3252.46600816 3303.65620783 2593.94937634 3275.17230567 3264.00970379
  955.5751565  1906.45485516 2380.94245164 3294.77914312 3312.33448664]
total_rewards_mean           2753.933969484601
total_rewards_std            761.8367963058353
total_rewards_max            3312.3344866428515
total_rewards_min            955.5751564964916
Number of train steps total  1336000
Number of env steps total    1471665
Number of rollouts total     0
Train Time (s)               144.19045722391456
(Previous) Eval Time (s)     15.334638412110507
Sample Time (s)              6.4431238463148475
Epoch Time (s)               165.96821948233992
Total Train Time (s)         54755.891722116154
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:42:16.924455 UTC | [2020_01_10_09_29_40] Iteration #333 | Epoch Duration: 166.37599992752075
2020-01-11 00:42:16.924645 UTC | [2020_01_10_09_29_40] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07563683
Z variance train             0.010826477
KL Divergence                9.1416025
KL Loss                      0.91416025
QF Loss                      81.97604
VF Loss                      29.587526
Policy Loss                  -1431.016
Q Predictions Mean           1429.9281
Q Predictions Std            336.9417
Q Predictions Max            1742.0388
Q Predictions Min            104.94873
V Predictions Mean           1429.582
V Predictions Std            334.81708
V Predictions Max            1738.8154
V Predictions Min            112.62808
Log Pis Mean                 -0.07537209
Log Pis Std                  1.8291303
Log Pis Max                  7.1137705
Log Pis Min                  -4.401309
Policy mu Mean               -0.07036973
Policy mu Std                0.8866526
Policy mu Max                2.5943835
Policy mu Min                -2.8926115
Policy log std Mean          -0.51996064
Policy log std Std           0.17877784
Policy log std Max           0.045066357
Policy log std Min           -1.3457205
Z mean eval                  0.08234243
Z variance eval              0.014265661
total_rewards                [3323.13249456 3320.07840523 3299.00173772 3313.81750321 3312.01693984
 3331.86901825 3301.58815331 3310.65042514 3290.51573826 3315.52661407]
total_rewards_mean           3311.8197029584226
total_rewards_std            11.576453353435653
total_rewards_max            3331.869018245146
total_rewards_min            3290.5157382562475
Number of train steps total  1340000
Number of env steps total    1477670
Number of rollouts total     0
Train Time (s)               145.48662846162915
(Previous) Eval Time (s)     19.67503407690674
Sample Time (s)              6.6611447064206
Epoch Time (s)               171.8228072449565
Total Train Time (s)         54927.8042600248
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:45:08.832014 UTC | [2020_01_10_09_29_40] Iteration #334 | Epoch Duration: 171.90723323822021
2020-01-11 00:45:08.832151 UTC | [2020_01_10_09_29_40] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.082354605
Z variance train             0.014265792
KL Divergence                8.740692
KL Loss                      0.8740692
QF Loss                      43.65123
VF Loss                      23.358896
Policy Loss                  -1398.6084
Q Predictions Mean           1398.0847
Q Predictions Std            366.77808
Q Predictions Max            1718.6265
Q Predictions Min            19.788544
V Predictions Mean           1398.9629
V Predictions Std            366.64124
V Predictions Max            1720.7944
V Predictions Min            42.17778
Log Pis Mean                 0.07617175
Log Pis Std                  2.1367118
Log Pis Max                  7.115908
Log Pis Min                  -6.67183
Policy mu Mean               -0.1308263
Policy mu Std                0.93671036
Policy mu Max                1.9067918
Policy mu Min                -2.7841337
Policy log std Mean          -0.5278516
Policy log std Std           0.18396175
Policy log std Max           0.13409597
Policy log std Min           -1.0854083
Z mean eval                  0.05281155
Z variance eval              0.012912462
total_rewards                [3265.12331149  955.41790262  972.61713841 3269.88930438  797.71317099
 3290.96506064 3301.55116387 3247.51285976 3311.82993116 3284.34655531]
total_rewards_mean           2569.6966398622385
total_rewards_std            1088.445338235189
total_rewards_max            3311.829931160941
total_rewards_min            797.7131709945952
Number of train steps total  1344000
Number of env steps total    1484000
Number of rollouts total     0
Train Time (s)               144.88843211485073
(Previous) Eval Time (s)     16.811888901982456
Sample Time (s)              6.8566112094558775
Epoch Time (s)               168.55693222628906
Total Train Time (s)         55096.43832322955
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:47:57.469424 UTC | [2020_01_10_09_29_40] Iteration #335 | Epoch Duration: 168.63717889785767
2020-01-11 00:47:57.469551 UTC | [2020_01_10_09_29_40] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05285554
Z variance train             0.012929501
KL Divergence                8.596191
KL Loss                      0.85961914
QF Loss                      45.316463
VF Loss                      22.835552
Policy Loss                  -1440.8213
Q Predictions Mean           1441.9393
Q Predictions Std            280.71448
Q Predictions Max            1773.9056
Q Predictions Min            92.56454
V Predictions Mean           1441.0986
V Predictions Std            279.5737
V Predictions Max            1777.3513
V Predictions Min            109.27926
Log Pis Mean                 -0.055096902
Log Pis Std                  2.2155252
Log Pis Max                  6.6366177
Log Pis Min                  -5.552959
Policy mu Mean               -0.11505041
Policy mu Std                0.9246784
Policy mu Max                2.1941917
Policy mu Min                -2.8783207
Policy log std Mean          -0.53431416
Policy log std Std           0.18584865
Policy log std Max           0.06385362
Policy log std Min           -1.1103942
Z mean eval                  0.05238535
Z variance eval              0.016084436
total_rewards                [ 722.26409076 3319.36577072 3286.6976833  3327.4767208   921.46379985
 3329.86306934 3294.74078128  987.33964008 3323.46417151 3298.57127351]
total_rewards_mean           2581.1247001140373
total_rewards_std            1117.386095828598
total_rewards_max            3329.8630693441173
total_rewards_min            722.2640907556672
Number of train steps total  1348000
Number of env steps total    1490226
Number of rollouts total     0
Train Time (s)               144.9111868198961
(Previous) Eval Time (s)     17.034717443864793
Sample Time (s)              6.485614357050508
Epoch Time (s)               168.4315186208114
Total Train Time (s)         55264.950384306256
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:50:45.985098 UTC | [2020_01_10_09_29_40] Iteration #336 | Epoch Duration: 168.51544094085693
2020-01-11 00:50:45.985286 UTC | [2020_01_10_09_29_40] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051599734
Z variance train             0.016100442
KL Divergence                8.063015
KL Loss                      0.80630153
QF Loss                      17787.906
VF Loss                      25.201199
Policy Loss                  -1468.7291
Q Predictions Mean           1472.3004
Q Predictions Std            324.2442
Q Predictions Max            1759.5686
Q Predictions Min            101.511635
V Predictions Mean           1470.7493
V Predictions Std            322.20572
V Predictions Max            1758.3615
V Predictions Min            110.34652
Log Pis Mean                 -0.18046
Log Pis Std                  2.0412054
Log Pis Max                  6.241147
Log Pis Min                  -5.773899
Policy mu Mean               -0.104003094
Policy mu Std                0.8829083
Policy mu Max                2.2584357
Policy mu Min                -2.5592895
Policy log std Mean          -0.54192466
Policy log std Std           0.19297887
Policy log std Max           0.012820542
Policy log std Min           -1.3190945
Z mean eval                  0.08788353
Z variance eval              0.015795723
total_rewards                [ 902.56396568 3330.53752985 3309.13302354 3316.83600346 3326.38395849
  954.48986766 3311.82567519 3317.52967979 3305.9568372  3333.62863438]
total_rewards_mean           2840.8885175233618
total_rewards_std            956.2893290475719
total_rewards_max            3333.628634378226
total_rewards_min            902.5639656806244
Number of train steps total  1352000
Number of env steps total    1496298
Number of rollouts total     0
Train Time (s)               146.49015087075531
(Previous) Eval Time (s)     15.433364517986774
Sample Time (s)              6.646184661891311
Epoch Time (s)               168.5697000506334
Total Train Time (s)         55433.87618638389
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:53:34.917389 UTC | [2020_01_10_09_29_40] Iteration #337 | Epoch Duration: 168.93193769454956
2020-01-11 00:53:34.917663 UTC | [2020_01_10_09_29_40] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09029246
Z variance train             0.015809003
KL Divergence                7.975884
KL Loss                      0.7975884
QF Loss                      196.11588
VF Loss                      72.24772
Policy Loss                  -1433.2687
Q Predictions Mean           1429.9897
Q Predictions Std            300.14893
Q Predictions Max            1720.1609
Q Predictions Min            79.262505
V Predictions Mean           1430.0554
V Predictions Std            299.11505
V Predictions Max            1715.9542
V Predictions Min            76.2174
Log Pis Mean                 -0.09215696
Log Pis Std                  2.1438968
Log Pis Max                  10.835321
Log Pis Min                  -7.8940587
Policy mu Mean               -0.13831168
Policy mu Std                0.90080863
Policy mu Max                2.417529
Policy mu Min                -3.4308045
Policy log std Mean          -0.50046307
Policy log std Std           0.1909392
Policy log std Max           0.44450015
Policy log std Min           -1.0493033
Z mean eval                  0.09349549
Z variance eval              0.016110433
total_rewards                [3312.25726179 3324.54524279 3361.24963245 3324.17052203 3339.29659201
 3326.87069159 3346.83023782 3346.33236895  199.52299214 3327.03947521]
total_rewards_mean           3020.8115016779266
total_rewards_std            940.5275695237303
total_rewards_max            3361.2496324507324
total_rewards_min            199.5229921416473
Number of train steps total  1356000
Number of env steps total    1502391
Number of rollouts total     0
Train Time (s)               146.02078061876819
(Previous) Eval Time (s)     19.751877781935036
Sample Time (s)              6.615896455477923
Epoch Time (s)               172.38855485618114
Total Train Time (s)         55606.347560148686
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:56:27.390277 UTC | [2020_01_10_09_29_40] Iteration #338 | Epoch Duration: 172.4724462032318
2020-01-11 00:56:27.390407 UTC | [2020_01_10_09_29_40] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.094288416
Z variance train             0.01611216
KL Divergence                7.977869
KL Loss                      0.7977869
QF Loss                      62.43502
VF Loss                      43.270073
Policy Loss                  -1491.7526
Q Predictions Mean           1493.1182
Q Predictions Std            290.11984
Q Predictions Max            1759.1981
Q Predictions Min            83.42888
V Predictions Mean           1487.065
V Predictions Std            288.2524
V Predictions Max            1759.1582
V Predictions Min            88.81859
Log Pis Mean                 -0.2947424
Log Pis Std                  1.8105136
Log Pis Max                  6.9491262
Log Pis Min                  -5.027625
Policy mu Mean               -0.014784299
Policy mu Std                0.8421964
Policy mu Max                1.9808716
Policy mu Min                -2.5357664
Policy log std Mean          -0.50172764
Policy log std Std           0.17075527
Policy log std Max           -0.06782043
Policy log std Min           -1.1319335
Z mean eval                  0.12203644
Z variance eval              0.014097181
total_rewards                [ 947.32204528 3321.31465836 3291.4533431  3340.43524001 2021.97580875
 3321.34129422 3306.01394952  752.68669037 3324.02820196 3335.20116863]
total_rewards_mean           2696.1772400193804
total_rewards_std            1000.7844772284764
total_rewards_max            3340.435240012871
total_rewards_min            752.686690368005
Number of train steps total  1360000
Number of env steps total    1508550
Number of rollouts total     0
Train Time (s)               145.5215795938857
(Previous) Eval Time (s)     15.174565606750548
Sample Time (s)              6.5041170171462
Epoch Time (s)               167.20026221778244
Total Train Time (s)         55773.63853625255
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:59:14.688645 UTC | [2020_01_10_09_29_40] Iteration #339 | Epoch Duration: 167.2981333732605
2020-01-11 00:59:14.688827 UTC | [2020_01_10_09_29_40] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12091933
Z variance train             0.014091859
KL Divergence                8.450136
KL Loss                      0.8450136
QF Loss                      45.54201
VF Loss                      21.296654
Policy Loss                  -1418.7207
Q Predictions Mean           1417.6064
Q Predictions Std            345.8635
Q Predictions Max            1741.0155
Q Predictions Min            38.94957
V Predictions Mean           1417.4824
V Predictions Std            344.54425
V Predictions Max            1739.2385
V Predictions Min            44.949253
Log Pis Mean                 -0.148061
Log Pis Std                  2.0027683
Log Pis Max                  6.4742894
Log Pis Min                  -6.702954
Policy mu Mean               -0.08800078
Policy mu Std                0.87840706
Policy mu Max                1.9808966
Policy mu Min                -2.6753373
Policy log std Mean          -0.5149782
Policy log std Std           0.18282054
Policy log std Max           0.06971857
Policy log std Min           -1.0588086
Z mean eval                  0.06497615
Z variance eval              0.010213003
total_rewards                [3336.97309093 3318.10867417 3013.216246   3318.13833964 3344.26521079
 1639.33622537 3348.70162084  881.1745474  3307.25642295 3316.876826  ]
total_rewards_mean           2882.4047204075855
total_rewards_std            833.8824953952735
total_rewards_max            3348.7016208365344
total_rewards_min            881.1745474005791
Number of train steps total  1364000
Number of env steps total    1515769
Number of rollouts total     0
Train Time (s)               146.16167526505888
(Previous) Eval Time (s)     16.1577392029576
Sample Time (s)              6.919668432325125
Epoch Time (s)               169.2390829003416
Total Train Time (s)         55942.956012547016
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:02:04.008202 UTC | [2020_01_10_09_29_40] Iteration #340 | Epoch Duration: 169.3192584514618
2020-01-11 01:02:04.008322 UTC | [2020_01_10_09_29_40] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.067203596
Z variance train             0.010181947
KL Divergence                9.350685
KL Loss                      0.93506855
QF Loss                      53.10773
VF Loss                      37.55768
Policy Loss                  -1512.8547
Q Predictions Mean           1509.6813
Q Predictions Std            273.3977
Q Predictions Max            1755.5549
Q Predictions Min            17.644407
V Predictions Mean           1509.1248
V Predictions Std            273.67868
V Predictions Max            1758.1659
V Predictions Min            25.338072
Log Pis Mean                 -0.22151336
Log Pis Std                  1.9195449
Log Pis Max                  6.133922
Log Pis Min                  -6.249691
Policy mu Mean               -0.022923874
Policy mu Std                0.85389876
Policy mu Max                2.1866035
Policy mu Min                -2.6716716
Policy log std Mean          -0.50398856
Policy log std Std           0.19738524
Policy log std Max           0.15704519
Policy log std Min           -1.1352334
Z mean eval                  0.07335326
Z variance eval              0.011763898
total_rewards                [3314.52889802 3338.11360627 3313.12771117 3309.85827127 3323.9038821
 3331.75311557 3308.7338348  3295.49871664 3317.8439845  3281.42562458]
total_rewards_mean           3313.478764491689
total_rewards_std            15.67194884714006
total_rewards_max            3338.113606268102
total_rewards_min            3281.4256245756665
Number of train steps total  1368000
Number of env steps total    1522399
Number of rollouts total     0
Train Time (s)               145.86488979589194
(Previous) Eval Time (s)     22.067414339631796
Sample Time (s)              5.537159204483032
Epoch Time (s)               173.46946334000677
Total Train Time (s)         56116.502533991355
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:04:57.558068 UTC | [2020_01_10_09_29_40] Iteration #341 | Epoch Duration: 173.54964590072632
2020-01-11 01:04:57.558238 UTC | [2020_01_10_09_29_40] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07325275
Z variance train             0.011751851
KL Divergence                8.686209
KL Loss                      0.8686209
QF Loss                      91.14537
VF Loss                      32.834763
Policy Loss                  -1441.7239
Q Predictions Mean           1441.898
Q Predictions Std            336.568
Q Predictions Max            1736.768
Q Predictions Min            34.236794
V Predictions Mean           1444.7405
V Predictions Std            338.04767
V Predictions Max            1747.0251
V Predictions Min            37.02091
Log Pis Mean                 0.22176588
Log Pis Std                  2.1043255
Log Pis Max                  9.619047
Log Pis Min                  -5.8626328
Policy mu Mean               -0.14002371
Policy mu Std                0.9524295
Policy mu Max                2.3937552
Policy mu Min                -2.744182
Policy log std Mean          -0.50217855
Policy log std Std           0.20057228
Policy log std Max           0.21125251
Policy log std Min           -1.1307452
Z mean eval                  0.2086957
Z variance eval              0.01262587
total_rewards                [ 927.29656192 3328.82472714 3326.06708959 3331.33055019 1042.20648165
 3340.45820767 3341.57168793 3324.74213996 3331.25461622 1099.52887427]
total_rewards_mean           2639.3280936534707
total_rewards_std            1058.8672594424083
total_rewards_max            3341.5716879344395
total_rewards_min            927.2965619163014
Number of train steps total  1372000
Number of env steps total    1529372
Number of rollouts total     0
Train Time (s)               145.08736546197906
(Previous) Eval Time (s)     14.28559786779806
Sample Time (s)              6.717488592490554
Epoch Time (s)               166.09045192226768
Total Train Time (s)         56282.671226139646
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:07:43.730918 UTC | [2020_01_10_09_29_40] Iteration #342 | Epoch Duration: 166.17248392105103
2020-01-11 01:07:43.731176 UTC | [2020_01_10_09_29_40] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20882332
Z variance train             0.01262555
KL Divergence                8.687204
KL Loss                      0.8687205
QF Loss                      58.73239
VF Loss                      15.108584
Policy Loss                  -1411.8488
Q Predictions Mean           1410.914
Q Predictions Std            357.5263
Q Predictions Max            1742.9757
Q Predictions Min            67.631096
V Predictions Mean           1412.7393
V Predictions Std            357.29764
V Predictions Max            1744.1251
V Predictions Min            69.981895
Log Pis Mean                 -0.10662116
Log Pis Std                  2.0895555
Log Pis Max                  7.0362926
Log Pis Min                  -4.7601027
Policy mu Mean               -0.13288468
Policy mu Std                0.89134216
Policy mu Max                1.8605357
Policy mu Min                -2.7893798
Policy log std Mean          -0.5016611
Policy log std Std           0.19299617
Policy log std Max           0.110960245
Policy log std Min           -1.0708383
Z mean eval                  0.08362421
Z variance eval              0.01535373
total_rewards                [3335.8314098  3291.14026241 3286.10120623 3318.19505525 3300.47173614
  974.71332212  995.09313842 3313.5475669  3275.17463524 1096.63342454]
total_rewards_mean           2618.6901757043947
total_rewards_std            1045.7166897954926
total_rewards_max            3335.8314098005553
total_rewards_min            974.713322121177
Number of train steps total  1376000
Number of env steps total    1536691
Number of rollouts total     0
Train Time (s)               145.51804583892226
(Previous) Eval Time (s)     17.19929928565398
Sample Time (s)              6.752937053795904
Epoch Time (s)               169.47028217837214
Total Train Time (s)         56452.22871543141
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:10:33.291951 UTC | [2020_01_10_09_29_40] Iteration #343 | Epoch Duration: 169.5606186389923
2020-01-11 01:10:33.292134 UTC | [2020_01_10_09_29_40] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.083727345
Z variance train             0.015316034
KL Divergence                8.284884
KL Loss                      0.82848847
QF Loss                      42.086044
VF Loss                      24.002592
Policy Loss                  -1458.6041
Q Predictions Mean           1457.9248
Q Predictions Std            312.86386
Q Predictions Max            1773.0663
Q Predictions Min            67.9244
V Predictions Mean           1455.9036
V Predictions Std            312.66495
V Predictions Max            1762.1937
V Predictions Min            71.26874
Log Pis Mean                 -0.21249263
Log Pis Std                  1.9567643
Log Pis Max                  6.8219914
Log Pis Min                  -5.574089
Policy mu Mean               -0.13063447
Policy mu Std                0.8660971
Policy mu Max                2.246388
Policy mu Min                -2.853537
Policy log std Mean          -0.51307195
Policy log std Std           0.19758265
Policy log std Max           0.09959656
Policy log std Min           -1.2418568
Z mean eval                  0.11744048
Z variance eval              0.008834252
total_rewards                [3284.20119054 1539.03361377 2763.35751535 3268.66252747 3295.06398061
 3298.96339523 3271.57019066 3300.00443753  864.57498725  950.77399819]
total_rewards_mean           2583.6205836600516
total_rewards_std            985.3535518285993
total_rewards_max            3300.004437528069
total_rewards_min            864.5749872488899
Number of train steps total  1380000
Number of env steps total    1543427
Number of rollouts total     0
Train Time (s)               143.95554924709722
(Previous) Eval Time (s)     15.81139581091702
Sample Time (s)              6.371557085774839
Epoch Time (s)               166.13850214378908
Total Train Time (s)         56618.44828046998
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:13:19.515901 UTC | [2020_01_10_09_29_40] Iteration #344 | Epoch Duration: 166.22362899780273
2020-01-11 01:13:19.516102 UTC | [2020_01_10_09_29_40] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11809546
Z variance train             0.008838354
KL Divergence                9.412283
KL Loss                      0.94122833
QF Loss                      55.504913
VF Loss                      26.266012
Policy Loss                  -1398.0027
Q Predictions Mean           1397.7349
Q Predictions Std            356.92603
Q Predictions Max            1766.1068
Q Predictions Min            42.09073
V Predictions Mean           1397.7808
V Predictions Std            356.49194
V Predictions Max            1770.9795
V Predictions Min            44.644836
Log Pis Mean                 -0.052190818
Log Pis Std                  1.9856687
Log Pis Max                  6.908232
Log Pis Min                  -5.921711
Policy mu Mean               -0.118088745
Policy mu Std                0.9134138
Policy mu Max                2.1010954
Policy mu Min                -2.70207
Policy log std Mean          -0.532897
Policy log std Std           0.18264171
Policy log std Max           -0.029280245
Policy log std Min           -1.1734625
Z mean eval                  0.09145305
Z variance eval              0.01291055
total_rewards                [ 885.02806851  937.01744468 3293.50739556  912.39581877 3284.61201665
 3267.59120931 3303.88429925 1411.06207336  677.45270347 3280.29568872]
total_rewards_mean           2125.284671826865
total_rewards_std            1173.2195926169338
total_rewards_max            3303.8842992483997
total_rewards_min            677.4527034662018
Number of train steps total  1384000
Number of env steps total    1549957
Number of rollouts total     0
Train Time (s)               145.61338013689965
(Previous) Eval Time (s)     13.0987609596923
Sample Time (s)              6.380668202415109
Epoch Time (s)               165.09280929900706
Total Train Time (s)         56783.615974464454
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:16:04.685874 UTC | [2020_01_10_09_29_40] Iteration #345 | Epoch Duration: 165.1696012020111
2020-01-11 01:16:04.686086 UTC | [2020_01_10_09_29_40] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09162168
Z variance train             0.012898454
KL Divergence                8.656713
KL Loss                      0.8656713
QF Loss                      62.775654
VF Loss                      26.332949
Policy Loss                  -1421.8082
Q Predictions Mean           1420.5148
Q Predictions Std            339.68988
Q Predictions Max            1735.7081
Q Predictions Min            43.234314
V Predictions Mean           1421.3198
V Predictions Std            338.43924
V Predictions Max            1735.6294
V Predictions Min            47.551773
Log Pis Mean                 0.047985233
Log Pis Std                  1.9910505
Log Pis Max                  7.7587876
Log Pis Min                  -3.6922324
Policy mu Mean               -0.17301814
Policy mu Std                0.90921766
Policy mu Max                2.4709017
Policy mu Min                -2.717155
Policy log std Mean          -0.5067723
Policy log std Std           0.20107888
Policy log std Max           0.16370475
Policy log std Min           -1.1298351
Z mean eval                  0.066656664
Z variance eval              0.018122548
total_rewards                [3313.90030072 3294.18408482 3317.3234006  3319.66088688 3315.46633113
 3303.76772654 3281.17949846 3334.20736809 3331.39459195 3293.91629131]
total_rewards_mean           3310.5000480523386
total_rewards_std            16.160365735414732
total_rewards_max            3334.2073680897593
total_rewards_min            3281.179498460532
Number of train steps total  1388000
Number of env steps total    1557076
Number of rollouts total     0
Train Time (s)               149.4063082560897
(Previous) Eval Time (s)     18.285134410019964
Sample Time (s)              6.797199377790093
Epoch Time (s)               174.48864204389974
Total Train Time (s)         56958.17943885317
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:18:59.251300 UTC | [2020_01_10_09_29_40] Iteration #346 | Epoch Duration: 174.56511282920837
2020-01-11 01:18:59.251417 UTC | [2020_01_10_09_29_40] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06669656
Z variance train             0.01810034
KL Divergence                7.728573
KL Loss                      0.7728573
QF Loss                      12377.313
VF Loss                      42.71618
Policy Loss                  -1461.1986
Q Predictions Mean           1464.7499
Q Predictions Std            299.56174
Q Predictions Max            1752.8778
Q Predictions Min            150.3872
V Predictions Mean           1463.4927
V Predictions Std            299.65097
V Predictions Max            1751.9196
V Predictions Min            165.47697
Log Pis Mean                 0.16838078
Log Pis Std                  2.0611634
Log Pis Max                  6.8756056
Log Pis Min                  -4.8514953
Policy mu Mean               -0.19791985
Policy mu Std                0.9212845
Policy mu Max                2.5383897
Policy mu Min                -2.674036
Policy log std Mean          -0.51105255
Policy log std Std           0.20776737
Policy log std Max           0.22100449
Policy log std Min           -1.1672852
Z mean eval                  0.0479885
Z variance eval              0.012593554
total_rewards                [3307.03640466 3288.99621349 3300.38487101 3371.75051878 3313.49754727
 3272.79020428  902.04691786 3307.80008044 3316.57550438  867.67702449]
total_rewards_mean           2824.8555286657656
total_rewards_std            970.3261503062746
total_rewards_max            3371.750518781635
total_rewards_min            867.6770244902439
Number of train steps total  1392000
Number of env steps total    1564142
Number of rollouts total     0
Train Time (s)               145.93903939938173
(Previous) Eval Time (s)     18.374576091300696
Sample Time (s)              5.704201841261238
Epoch Time (s)               170.01781733194366
Total Train Time (s)         57128.30994800432
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:21:49.384174 UTC | [2020_01_10_09_29_40] Iteration #347 | Epoch Duration: 170.132670879364
2020-01-11 01:21:49.384299 UTC | [2020_01_10_09_29_40] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04344831
Z variance train             0.012556357
KL Divergence                9.311132
KL Loss                      0.93111324
QF Loss                      180.05962
VF Loss                      160.51788
Policy Loss                  -1443.8525
Q Predictions Mean           1448.5393
Q Predictions Std            309.38614
Q Predictions Max            1743.6891
Q Predictions Min            84.14512
V Predictions Mean           1449.442
V Predictions Std            309.12445
V Predictions Max            1750.3782
V Predictions Min            86.1954
Log Pis Mean                 -0.04377922
Log Pis Std                  1.9240216
Log Pis Max                  6.091743
Log Pis Min                  -3.4595628
Policy mu Mean               -0.123290636
Policy mu Std                0.8956127
Policy mu Max                2.0635889
Policy mu Min                -2.7430615
Policy log std Mean          -0.48861066
Policy log std Std           0.19204897
Policy log std Max           0.16032183
Policy log std Min           -1.1218307
Z mean eval                  0.11363743
Z variance eval              0.011796998
total_rewards                [ 851.67965732 3304.08810044  775.58449632 3297.06042477 3299.50308979
 3247.01304365 3303.41126796 3256.52671802 3270.04692334 3288.19835279]
total_rewards_mean           2789.3112074405335
total_rewards_std            988.1643058680596
total_rewards_max            3304.0881004403223
total_rewards_min            775.5844963220736
Number of train steps total  1396000
Number of env steps total    1571110
Number of rollouts total     0
Train Time (s)               147.11118287406862
(Previous) Eval Time (s)     18.339031036011875
Sample Time (s)              6.586697746068239
Epoch Time (s)               172.03691165614873
Total Train Time (s)         57300.428257672116
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:24:41.504822 UTC | [2020_01_10_09_29_40] Iteration #348 | Epoch Duration: 172.1204149723053
2020-01-11 01:24:41.504954 UTC | [2020_01_10_09_29_40] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11351396
Z variance train             0.011800691
KL Divergence                8.918011
KL Loss                      0.89180106
QF Loss                      158.03836
VF Loss                      50.858734
Policy Loss                  -1454.3685
Q Predictions Mean           1456.3546
Q Predictions Std            298.89203
Q Predictions Max            1754.9567
Q Predictions Min            16.852936
V Predictions Mean           1451.7932
V Predictions Std            297.10077
V Predictions Max            1743.4836
V Predictions Min            11.943898
Log Pis Mean                 0.16279005
Log Pis Std                  2.1759338
Log Pis Max                  10.0353985
Log Pis Min                  -5.7733965
Policy mu Mean               -0.33823642
Policy mu Std                0.9251444
Policy mu Max                2.0948477
Policy mu Min                -2.958686
Policy log std Mean          -0.53728795
Policy log std Std           0.2040825
Policy log std Max           0.12698719
Policy log std Min           -1.2502977
Z mean eval                  0.108060956
Z variance eval              0.015653426
total_rewards                [3317.15675634 3296.4313996  3305.12559238 3294.50528004 3289.14847297
 3300.98049302 3306.07408892 3296.34150594 3299.70033651 3278.70853357]
total_rewards_mean           3298.417245928723
total_rewards_std            9.80262321416725
total_rewards_max            3317.156756342918
total_rewards_min            3278.708533568683
Number of train steps total  1400000
Number of env steps total    1578027
Number of rollouts total     0
Train Time (s)               144.85307546611875
(Previous) Eval Time (s)     21.641079091001302
Sample Time (s)              6.44051383016631
Epoch Time (s)               172.93466838728637
Total Train Time (s)         57473.43582134275
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:27:34.514577 UTC | [2020_01_10_09_29_40] Iteration #349 | Epoch Duration: 173.00953364372253
2020-01-11 01:27:34.514712 UTC | [2020_01_10_09_29_40] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10779784
Z variance train             0.015645668
KL Divergence                8.182722
KL Loss                      0.81827223
QF Loss                      52.847694
VF Loss                      19.301014
Policy Loss                  -1437.9923
Q Predictions Mean           1436.6244
Q Predictions Std            327.3358
Q Predictions Max            1731.9354
Q Predictions Min            39.356865
V Predictions Mean           1436.4844
V Predictions Std            328.5391
V Predictions Max            1731.1561
V Predictions Min            32.401855
Log Pis Mean                 -0.09339904
Log Pis Std                  1.8641529
Log Pis Max                  7.2753334
Log Pis Min                  -4.623662
Policy mu Mean               -0.1670564
Policy mu Std                0.87374926
Policy mu Max                2.010803
Policy mu Min                -2.6898696
Policy log std Mean          -0.5220907
Policy log std Std           0.1905395
Policy log std Max           0.17238343
Policy log std Min           -1.1556883
Z mean eval                  0.03805109
Z variance eval              0.016829755
total_rewards                [3301.14959066 3320.09117615 3345.79510522 3317.26549473 3336.74877275
 3317.20655478 3305.50931183 3317.78670394 3324.24514572 3317.38489218]
total_rewards_mean           3320.3182747962455
total_rewards_std            12.471013305029329
total_rewards_max            3345.7951052219014
total_rewards_min            3301.1495906556815
Number of train steps total  1404000
Number of env steps total    1584583
Number of rollouts total     0
Train Time (s)               148.19007320515811
(Previous) Eval Time (s)     21.705738285090774
Sample Time (s)              6.481505982577801
Epoch Time (s)               176.3773174728267
Total Train Time (s)         57649.89079772821
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:30:30.974192 UTC | [2020_01_10_09_29_40] Iteration #350 | Epoch Duration: 176.4593894481659
2020-01-11 01:30:30.974319 UTC | [2020_01_10_09_29_40] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03808991
Z variance train             0.01681691
KL Divergence                7.975491
KL Loss                      0.7975491
QF Loss                      93.43039
VF Loss                      22.29343
Policy Loss                  -1442.5071
Q Predictions Mean           1443.6588
Q Predictions Std            309.11655
Q Predictions Max            1788.8496
Q Predictions Min            32.40327
V Predictions Mean           1440.9431
V Predictions Std            310.4861
V Predictions Max            1787.4528
V Predictions Min            23.5248
Log Pis Mean                 -0.21891269
Log Pis Std                  1.9095033
Log Pis Max                  6.1812387
Log Pis Min                  -3.778544
Policy mu Mean               -0.15293264
Policy mu Std                0.8969222
Policy mu Max                2.3618257
Policy mu Min                -2.5411034
Policy log std Mean          -0.4812146
Policy log std Std           0.18489428
Policy log std Max           0.32773823
Policy log std Min           -1.1115308
Z mean eval                  0.04652872
Z variance eval              0.010625193
total_rewards                [3320.11815721 3325.06199068 3290.1811176  3293.68334991 3315.12937585
 3302.59720351  775.94337972 3308.22132338 3305.71748279 3287.17263545]
total_rewards_mean           3052.3826016089565
total_rewards_std            758.9062973262833
total_rewards_max            3325.0619906822485
total_rewards_min            775.9433797160477
Number of train steps total  1408000
Number of env steps total    1591891
Number of rollouts total     0
Train Time (s)               145.96872145170346
(Previous) Eval Time (s)     17.186911463737488
Sample Time (s)              6.542047513648868
Epoch Time (s)               169.69768042908981
Total Train Time (s)         57819.68870405061
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:33:20.779837 UTC | [2020_01_10_09_29_40] Iteration #351 | Epoch Duration: 169.80537843704224
2020-01-11 01:33:20.780117 UTC | [2020_01_10_09_29_40] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04647943
Z variance train             0.010622099
KL Divergence                9.078758
KL Loss                      0.90787584
QF Loss                      42.432762
VF Loss                      16.558178
Policy Loss                  -1472.3286
Q Predictions Mean           1474.2809
Q Predictions Std            327.09003
Q Predictions Max            1755.543
Q Predictions Min            43.79152
V Predictions Mean           1470.5261
V Predictions Std            324.63547
V Predictions Max            1752.3903
V Predictions Min            56.886818
Log Pis Mean                 -0.30041516
Log Pis Std                  1.8894038
Log Pis Max                  7.4648643
Log Pis Min                  -4.8231936
Policy mu Mean               -0.12757541
Policy mu Std                0.84435946
Policy mu Max                1.9307816
Policy mu Min                -2.749228
Policy log std Mean          -0.50261503
Policy log std Std           0.2000938
Policy log std Max           0.54085916
Policy log std Min           -1.2962961
Z mean eval                  0.058759533
Z variance eval              0.020114603
total_rewards                [3283.05575227 3286.27202506  883.45081081 1232.23932619 3305.01961321
 3292.12044099 3294.63098927 3289.47107349 3289.20057636 3302.2888586 ]
total_rewards_mean           2845.7749466239597
total_rewards_std            897.3831175475947
total_rewards_max            3305.019613211453
total_rewards_min            883.450810809463
Number of train steps total  1412000
Number of env steps total    1598926
Number of rollouts total     0
Train Time (s)               144.82264738995582
(Previous) Eval Time (s)     18.738307242747396
Sample Time (s)              5.52387905633077
Epoch Time (s)               169.08483368903399
Total Train Time (s)         57988.85270979768
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:36:09.946936 UTC | [2020_01_10_09_29_40] Iteration #352 | Epoch Duration: 169.1666078567505
2020-01-11 01:36:09.947116 UTC | [2020_01_10_09_29_40] Iteration #352 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05913043
Z variance train             0.020139823
KL Divergence                8.080018
KL Loss                      0.8080018
QF Loss                      54.647198
VF Loss                      26.432531
Policy Loss                  -1467.3846
Q Predictions Mean           1465.0536
Q Predictions Std            296.25696
Q Predictions Max            1744.2422
Q Predictions Min            26.027298
V Predictions Mean           1465.8938
V Predictions Std            297.74542
V Predictions Max            1741.3088
V Predictions Min            14.81786
Log Pis Mean                 -0.11326045
Log Pis Std                  1.9820443
Log Pis Max                  8.539153
Log Pis Min                  -3.7702768
Policy mu Mean               -0.20991834
Policy mu Std                0.8857394
Policy mu Max                2.0470557
Policy mu Min                -2.6293118
Policy log std Mean          -0.5071508
Policy log std Std           0.20889276
Policy log std Max           0.17357504
Policy log std Min           -1.3577602
Z mean eval                  0.10859163
Z variance eval              0.013685134
total_rewards                [3349.85079532 3356.84936078 3325.60844456 3361.69807433 1069.3247985
 1973.1593019  3367.10475766 3307.93598273 3350.25962783 3384.15187357]
total_rewards_mean           2984.5943017176896
total_rewards_std            759.3394195204432
total_rewards_max            3384.1518735740183
total_rewards_min            1069.3247985010305
Number of train steps total  1416000
Number of env steps total    1605780
Number of rollouts total     0
Train Time (s)               147.12951953569427
(Previous) Eval Time (s)     15.833800952881575
Sample Time (s)              6.664161896333098
Epoch Time (s)               169.62748238490894
Total Train Time (s)         58158.56481412193
Epoch                        353
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:38:59.666119 UTC | [2020_01_10_09_29_40] Iteration #353 | Epoch Duration: 169.7187740802765
2020-01-11 01:38:59.666407 UTC | [2020_01_10_09_29_40] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.108363606
Z variance train             0.013724314
KL Divergence                8.5661335
KL Loss                      0.85661334
QF Loss                      112.532135
VF Loss                      42.84683
Policy Loss                  -1491.9205
Q Predictions Mean           1495.6062
Q Predictions Std            280.26804
Q Predictions Max            1799.5582
Q Predictions Min            48.6129
V Predictions Mean           1492.5183
V Predictions Std            278.7897
V Predictions Max            1804.1804
V Predictions Min            83.64924
Log Pis Mean                 -0.3275475
Log Pis Std                  1.9399167
Log Pis Max                  7.0173798
Log Pis Min                  -4.7085676
Policy mu Mean               -0.10781863
Policy mu Std                0.8577084
Policy mu Max                1.8527713
Policy mu Min                -2.5389082
Policy log std Mean          -0.47890106
Policy log std Std           0.19733529
Policy log std Max           0.3498357
Policy log std Min           -1.0446527
Z mean eval                  0.10631716
Z variance eval              0.011988852
total_rewards                [3330.51848123 3340.59844619  871.26372136 3334.72450222 3298.41520554
  931.42972906 3313.32016645  992.2980221  3325.23617945 3320.57496847]
total_rewards_mean           2605.8379422071
total_rewards_std            1096.3936048978844
total_rewards_max            3340.5984461865182
total_rewards_min            871.2637213619487
Number of train steps total  1420000
Number of env steps total    1613603
Number of rollouts total     0
Train Time (s)               147.66985030006617
(Previous) Eval Time (s)     17.131794396787882
Sample Time (s)              6.76458000484854
Epoch Time (s)               171.5662247017026
Total Train Time (s)         58330.211061937734
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:41:51.315773 UTC | [2020_01_10_09_29_40] Iteration #354 | Epoch Duration: 171.64920830726624
2020-01-11 01:41:51.315935 UTC | [2020_01_10_09_29_40] Iteration #354 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10606311
Z variance train             0.011998606
KL Divergence                9.378992
KL Loss                      0.93789923
QF Loss                      52.62911
VF Loss                      33.854538
Policy Loss                  -1480.6337
Q Predictions Mean           1481.5435
Q Predictions Std            266.77924
Q Predictions Max            1763.9286
Q Predictions Min            425.66705
V Predictions Mean           1482.7173
V Predictions Std            266.88153
V Predictions Max            1760.1879
V Predictions Min            412.84586
Log Pis Mean                 -0.3530329
Log Pis Std                  1.9941915
Log Pis Max                  6.688306
Log Pis Min                  -7.113013
Policy mu Mean               -0.1340543
Policy mu Std                0.87317216
Policy mu Max                1.7215021
Policy mu Min                -2.6854954
Policy log std Mean          -0.5042844
Policy log std Std           0.19975671
Policy log std Max           0.2179133
Policy log std Min           -1.1187148
Z mean eval                  0.082268886
Z variance eval              0.01024009
total_rewards                [3274.07836095 3273.55385205 3287.92438107 3328.71491282  965.2339995
  967.24103897 3331.3757947  3286.43600224 3277.13060401 2113.41121892]
total_rewards_mean           2710.5100165248127
total_rewards_std            939.6775141112918
total_rewards_max            3331.3757947027225
total_rewards_min            965.2339994984591
Number of train steps total  1424000
Number of env steps total    1620558
Number of rollouts total     0
Train Time (s)               146.19587905006483
(Previous) Eval Time (s)     17.6844384027645
Sample Time (s)              6.600500307045877
Epoch Time (s)               170.4808177598752
Total Train Time (s)         58500.77696979651
Epoch                        355
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:44:41.888647 UTC | [2020_01_10_09_29_40] Iteration #355 | Epoch Duration: 170.57256770133972
2020-01-11 01:44:41.888854 UTC | [2020_01_10_09_29_40] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0827618
Z variance train             0.010243697
KL Divergence                9.047769
KL Loss                      0.9047769
QF Loss                      48.35988
VF Loss                      21.266922
Policy Loss                  -1434.765
Q Predictions Mean           1436.8671
Q Predictions Std            332.7301
Q Predictions Max            1770.0046
Q Predictions Min            65.17106
V Predictions Mean           1435.0175
V Predictions Std            332.0195
V Predictions Max            1766.8431
V Predictions Min            96.817314
Log Pis Mean                 -0.13024257
Log Pis Std                  1.9092717
Log Pis Max                  5.714795
Log Pis Min                  -3.864932
Policy mu Mean               -0.15978535
Policy mu Std                0.87303483
Policy mu Max                2.2849314
Policy mu Min                -2.6756496
Policy log std Mean          -0.48073888
Policy log std Std           0.18415728
Policy log std Max           0.49965453
Policy log std Min           -1.0981177
Z mean eval                  0.15423283
Z variance eval              0.009669122
total_rewards                [3308.17542881 3301.39507907 3300.47806366 3314.62567218 1373.59613091
 3310.43526104 3313.33355571 3271.52593217  987.00496774 3291.84736181]
total_rewards_mean           2877.2417453090316
total_rewards_std            852.9466165100124
total_rewards_max            3314.6256721782743
total_rewards_min            987.004967739498
Number of train steps total  1428000
Number of env steps total    1627596
Number of rollouts total     0
Train Time (s)               145.16768157994375
(Previous) Eval Time (s)     16.187605956103653
Sample Time (s)              6.675023692194372
Epoch Time (s)               168.03031122824177
Total Train Time (s)         58668.89152665483
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:47:30.002190 UTC | [2020_01_10_09_29_40] Iteration #356 | Epoch Duration: 168.11321568489075
2020-01-11 01:47:30.002362 UTC | [2020_01_10_09_29_40] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15384574
Z variance train             0.009662383
KL Divergence                9.474196
KL Loss                      0.94741964
QF Loss                      37.366447
VF Loss                      20.159365
Policy Loss                  -1456.5314
Q Predictions Mean           1455.9287
Q Predictions Std            303.44257
Q Predictions Max            1744.832
Q Predictions Min            102.51607
V Predictions Mean           1454.6248
V Predictions Std            303.10632
V Predictions Max            1742.1882
V Predictions Min            105.03031
Log Pis Mean                 -0.32388818
Log Pis Std                  1.9108438
Log Pis Max                  5.2660446
Log Pis Min                  -6.1617513
Policy mu Mean               -0.1673554
Policy mu Std                0.8307215
Policy mu Max                1.990734
Policy mu Min                -2.4266546
Policy log std Mean          -0.4828508
Policy log std Std           0.18744728
Policy log std Max           0.5063398
Policy log std Min           -1.1856892
Z mean eval                  0.10019489
Z variance eval              0.011507297
total_rewards                [3334.23768006 3336.89190978 3348.61568452 3319.91999366 3315.19977789
 3360.70353506 3331.31650971 3376.4963041  3308.59493827 3367.86475663]
total_rewards_mean           3339.9841089682573
total_rewards_std            21.757968347463187
total_rewards_max            3376.4963040950033
total_rewards_min            3308.594938272066
Number of train steps total  1432000
Number of env steps total    1634469
Number of rollouts total     0
Train Time (s)               146.36260103806853
(Previous) Eval Time (s)     21.642043724656105
Sample Time (s)              6.5483056721277535
Epoch Time (s)               174.5529504348524
Total Train Time (s)         58843.81008783216
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:50:24.940910 UTC | [2020_01_10_09_29_40] Iteration #357 | Epoch Duration: 174.93838238716125
2020-01-11 01:50:24.941193 UTC | [2020_01_10_09_29_40] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1006788
Z variance train             0.011479122
KL Divergence                9.317543
KL Loss                      0.9317543
QF Loss                      116.58953
VF Loss                      75.126366
Policy Loss                  -1449.3438
Q Predictions Mean           1450.5059
Q Predictions Std            345.5593
Q Predictions Max            1769.9791
Q Predictions Min            91.433914
V Predictions Mean           1445.3057
V Predictions Std            341.69846
V Predictions Max            1763.2601
V Predictions Min            112.155624
Log Pis Mean                 -0.16495213
Log Pis Std                  1.9034599
Log Pis Max                  5.5206785
Log Pis Min                  -5.7772326
Policy mu Mean               -0.22105296
Policy mu Std                0.83030534
Policy mu Max                2.2914655
Policy mu Min                -2.5706718
Policy log std Mean          -0.5045372
Policy log std Std           0.18106365
Policy log std Max           0.20029247
Policy log std Min           -1.2598813
Z mean eval                  0.07727869
Z variance eval              0.015610717
total_rewards                [ 848.93425329  866.52653531  799.41887539  927.91102337 3344.31746355
 3335.88123997 3296.42569181 3316.38407527  802.52410645 3327.40537468]
total_rewards_mean           2086.572863909915
total_rewards_std            1238.0163138585276
total_rewards_max            3344.317463551634
total_rewards_min            799.4188753926542
Number of train steps total  1436000
Number of env steps total    1641720
Number of rollouts total     0
Train Time (s)               145.92518947226927
(Previous) Eval Time (s)     13.99793429672718
Sample Time (s)              6.579488914925605
Epoch Time (s)               166.50261268392205
Total Train Time (s)         59010.414563523605
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:53:11.532229 UTC | [2020_01_10_09_29_40] Iteration #358 | Epoch Duration: 166.59085750579834
2020-01-11 01:53:11.532354 UTC | [2020_01_10_09_29_40] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0772876
Z variance train             0.015602568
KL Divergence                8.244633
KL Loss                      0.8244633
QF Loss                      127.343475
VF Loss                      20.45742
Policy Loss                  -1463.8214
Q Predictions Mean           1464.6025
Q Predictions Std            285.5298
Q Predictions Max            1749.0872
Q Predictions Min            91.42509
V Predictions Mean           1464.3755
V Predictions Std            285.655
V Predictions Max            1750.519
V Predictions Min            117.74698
Log Pis Mean                 -0.21706298
Log Pis Std                  1.9733142
Log Pis Max                  6.0649405
Log Pis Min                  -4.5463324
Policy mu Mean               -0.12111517
Policy mu Std                0.89981997
Policy mu Max                2.3927948
Policy mu Min                -2.8179479
Policy log std Mean          -0.5079985
Policy log std Std           0.19929102
Policy log std Max           0.014769375
Policy log std Min           -1.3279254
Z mean eval                  0.105441526
Z variance eval              0.0100349365
total_rewards                [1037.67916646 3325.94089983 3307.48832439 3315.48664644 3328.86213887
 3323.06514397 3301.09011517 3339.87277233 3315.86127503 3326.62367861]
total_rewards_mean           3092.19701611103
total_rewards_std            684.9204366052303
total_rewards_max            3339.872772332004
total_rewards_min            1037.6791664614025
Number of train steps total  1440000
Number of env steps total    1648747
Number of rollouts total     0
Train Time (s)               146.08931276202202
(Previous) Eval Time (s)     20.57638922613114
Sample Time (s)              6.431765362620354
Epoch Time (s)               173.0974673507735
Total Train Time (s)         59183.5945951147
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:56:04.714552 UTC | [2020_01_10_09_29_40] Iteration #359 | Epoch Duration: 173.18211102485657
2020-01-11 01:56:04.714696 UTC | [2020_01_10_09_29_40] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10802106
Z variance train             0.009997695
KL Divergence                9.482613
KL Loss                      0.94826126
QF Loss                      48.496887
VF Loss                      37.21263
Policy Loss                  -1453.8176
Q Predictions Mean           1453.3694
Q Predictions Std            293.00623
Q Predictions Max            1751.7922
Q Predictions Min            35.93687
V Predictions Mean           1457.8611
V Predictions Std            289.84952
V Predictions Max            1753.0304
V Predictions Min            50.174126
Log Pis Mean                 -0.26711684
Log Pis Std                  1.9362378
Log Pis Max                  6.904659
Log Pis Min                  -5.560041
Policy mu Mean               -0.13694732
Policy mu Std                0.8722888
Policy mu Max                1.7409006
Policy mu Min                -2.5217605
Policy log std Mean          -0.46906936
Policy log std Std           0.17692143
Policy log std Max           0.1658032
Policy log std Min           -1.1376647
Z mean eval                  0.07644127
Z variance eval              0.00855342
total_rewards                [1047.64194999  839.15247699 3351.22656916 3356.57867935 3338.34064537
 3344.32757642 1034.88387653 3326.77306543 3362.97654998  813.70378757]
total_rewards_mean           2381.560517680418
total_rewards_std            1184.0582540220514
total_rewards_max            3362.976549983528
total_rewards_min            813.7037875719911
Number of train steps total  1444000
Number of env steps total    1656216
Number of rollouts total     0
Train Time (s)               146.15539341187105
(Previous) Eval Time (s)     13.185021338053048
Sample Time (s)              6.599468324333429
Epoch Time (s)               165.93988307425752
Total Train Time (s)         59349.61680931458
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:58:50.739409 UTC | [2020_01_10_09_29_40] Iteration #360 | Epoch Duration: 166.0246229171753
2020-01-11 01:58:50.739525 UTC | [2020_01_10_09_29_40] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07671923
Z variance train             0.008582622
KL Divergence                9.523792
KL Loss                      0.9523792
QF Loss                      117.00525
VF Loss                      32.605648
Policy Loss                  -1493.5044
Q Predictions Mean           1495.7966
Q Predictions Std            271.93573
Q Predictions Max            1737.955
Q Predictions Min            72.27995
V Predictions Mean           1490.7546
V Predictions Std            271.5635
V Predictions Max            1726.1783
V Predictions Min            70.15745
Log Pis Mean                 -0.2553401
Log Pis Std                  1.87044
Log Pis Max                  5.6547
Log Pis Min                  -5.212246
Policy mu Mean               -0.17894106
Policy mu Std                0.8344152
Policy mu Max                2.0421193
Policy mu Min                -2.420759
Policy log std Mean          -0.46314144
Policy log std Std           0.20557581
Policy log std Max           0.3715616
Policy log std Min           -1.2028831
Z mean eval                  0.07534093
Z variance eval              0.008303722
total_rewards                [3300.22726659 3307.11639376 3294.79017254 3284.30604122 3303.73192905
 3282.58128332 1032.92570387 3300.50839053 3310.46958658 3293.63212025]
total_rewards_mean           3071.028888771126
total_rewards_std            679.4218176752793
total_rewards_max            3310.4695865841245
total_rewards_min            1032.9257038709484
Number of train steps total  1448000
Number of env steps total    1663703
Number of rollouts total     0
Train Time (s)               145.52128256019205
(Previous) Eval Time (s)     20.107091154903173
Sample Time (s)              5.501406121067703
Epoch Time (s)               171.12977983616292
Total Train Time (s)         59520.82633432001
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:01:41.952202 UTC | [2020_01_10_09_29_40] Iteration #361 | Epoch Duration: 171.21258735656738
2020-01-11 02:01:41.952327 UTC | [2020_01_10_09_29_40] Iteration #361 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07504984
Z variance train             0.008315864
KL Divergence                9.911318
KL Loss                      0.9911318
QF Loss                      53.973465
VF Loss                      12.667187
Policy Loss                  -1505.9216
Q Predictions Mean           1505.2883
Q Predictions Std            246.932
Q Predictions Max            1785.3551
Q Predictions Min            59.435814
V Predictions Mean           1505.3882
V Predictions Std            246.0248
V Predictions Max            1779.4575
V Predictions Min            76.37396
Log Pis Mean                 -0.39118284
Log Pis Std                  1.8502706
Log Pis Max                  7.4891267
Log Pis Min                  -6.319683
Policy mu Mean               -0.12953608
Policy mu Std                0.8171792
Policy mu Max                1.5659047
Policy mu Min                -2.7576644
Policy log std Mean          -0.49318066
Policy log std Std           0.18858446
Policy log std Max           0.0997805
Policy log std Min           -1.2550616
Z mean eval                  0.0621713
Z variance eval              0.010311841
total_rewards                [1226.01926823 3341.80676812 3347.90814245 3383.53044437 1002.8895819
 3345.85085887 3327.11221674 3338.77861446 3355.23115183 3343.24177448]
total_rewards_mean           2901.236882144683
total_rewards_std            894.8895978759348
total_rewards_max            3383.5304443659775
total_rewards_min            1002.889581900528
Number of train steps total  1452000
Number of env steps total    1671402
Number of rollouts total     0
Train Time (s)               145.57828615373
(Previous) Eval Time (s)     18.774520019069314
Sample Time (s)              6.575610673986375
Epoch Time (s)               170.9284168467857
Total Train Time (s)         59691.83500351198
Epoch                        362
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:04:32.964407 UTC | [2020_01_10_09_29_40] Iteration #362 | Epoch Duration: 171.01199007034302
2020-01-11 02:04:32.964535 UTC | [2020_01_10_09_29_40] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061469756
Z variance train             0.01030173
KL Divergence                9.211916
KL Loss                      0.92119163
QF Loss                      105.44369
VF Loss                      20.194725
Policy Loss                  -1456.5302
Q Predictions Mean           1459.7183
Q Predictions Std            308.08893
Q Predictions Max            1771.2874
Q Predictions Min            27.103931
V Predictions Mean           1456.7042
V Predictions Std            305.7088
V Predictions Max            1757.3438
V Predictions Min            30.137186
Log Pis Mean                 -0.013503475
Log Pis Std                  2.0170774
Log Pis Max                  7.8025227
Log Pis Min                  -4.6214805
Policy mu Mean               -0.18824863
Policy mu Std                0.9217983
Policy mu Max                1.713484
Policy mu Min                -3.0342429
Policy log std Mean          -0.46094337
Policy log std Std           0.20964691
Policy log std Max           0.39782375
Policy log std Min           -1.3300965
Z mean eval                  0.049524166
Z variance eval              0.012345998
total_rewards                [ 849.52059999 3278.60934678 3314.17880632 3320.41696921 3296.21641501
 3308.8776517  3301.64774292 3308.99497692 3323.80117267 3299.64142858]
total_rewards_mean           3060.190511011403
total_rewards_std            736.9926870921701
total_rewards_max            3323.8011726676255
total_rewards_min            849.5205999922708
Number of train steps total  1456000
Number of env steps total    1679010
Number of rollouts total     0
Train Time (s)               145.66107968706638
(Previous) Eval Time (s)     19.634795846883208
Sample Time (s)              6.833987262565643
Epoch Time (s)               172.12986279651523
Total Train Time (s)         59864.04958082456
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:07:25.184174 UTC | [2020_01_10_09_29_40] Iteration #363 | Epoch Duration: 172.21952724456787
2020-01-11 02:07:25.184387 UTC | [2020_01_10_09_29_40] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049591053
Z variance train             0.012364836
KL Divergence                8.578713
KL Loss                      0.85787135
QF Loss                      75.431114
VF Loss                      42.385666
Policy Loss                  -1467.9583
Q Predictions Mean           1467.1063
Q Predictions Std            295.64987
Q Predictions Max            1744.2611
Q Predictions Min            41.709538
V Predictions Mean           1471.0591
V Predictions Std            298.14014
V Predictions Max            1749.46
V Predictions Min            38.94368
Log Pis Mean                 -0.33668756
Log Pis Std                  1.8517071
Log Pis Max                  6.8806653
Log Pis Min                  -5.1227922
Policy mu Mean               -0.07432449
Policy mu Std                0.8496975
Policy mu Max                1.8426313
Policy mu Min                -2.507238
Policy log std Mean          -0.47115374
Policy log std Std           0.18503655
Policy log std Max           0.1157977
Policy log std Min           -1.0811677
Z mean eval                  0.2069581
Z variance eval              0.012169136
total_rewards                [ 950.46596394 1122.0861888   751.38225177 3333.94692462  739.81532338
 1142.52045633 1087.11730735 3318.392663   3354.36532576 1102.54318568]
total_rewards_mean           1690.2635590649782
total_rewards_std            1085.6303783425674
total_rewards_max            3354.3653257647597
total_rewards_min            739.8153233795998
Number of train steps total  1460000
Number of env steps total    1686615
Number of rollouts total     0
Train Time (s)               145.9903965438716
(Previous) Eval Time (s)     9.546423458028585
Sample Time (s)              6.498624944593757
Epoch Time (s)               162.03544494649395
Total Train Time (s)         60026.15862858435
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:10:07.295565 UTC | [2020_01_10_09_29_40] Iteration #364 | Epoch Duration: 162.11104202270508
2020-01-11 02:10:07.295679 UTC | [2020_01_10_09_29_40] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20789461
Z variance train             0.012173052
KL Divergence                9.292864
KL Loss                      0.9292864
QF Loss                      40.46876
VF Loss                      34.005444
Policy Loss                  -1473.2827
Q Predictions Mean           1474.8007
Q Predictions Std            324.9092
Q Predictions Max            1744.69
Q Predictions Min            66.667534
V Predictions Mean           1477.6437
V Predictions Std            325.9434
V Predictions Max            1750.4135
V Predictions Min            59.87476
Log Pis Mean                 -0.28172904
Log Pis Std                  1.9372538
Log Pis Max                  5.9247127
Log Pis Min                  -4.662609
Policy mu Mean               -0.12738465
Policy mu Std                0.85431695
Policy mu Max                1.8700502
Policy mu Min                -2.8826387
Policy log std Mean          -0.4882631
Policy log std Std           0.18054496
Policy log std Max           -0.03185481
Policy log std Min           -1.1067897
Z mean eval                  0.15956822
Z variance eval              0.016306793
total_rewards                [3315.0808184  3269.04935769 3285.11373218 3275.04554326 3325.38276798
  827.45658656 3292.16179742 3071.22483505 3259.89090541 1250.63633897]
total_rewards_mean           2817.1042682917296
total_rewards_std            896.5579572231239
total_rewards_max            3325.3827679824535
total_rewards_min            827.4565865599252
Number of train steps total  1464000
Number of env steps total    1694270
Number of rollouts total     0
Train Time (s)               145.78082813881338
(Previous) Eval Time (s)     18.853852939791977
Sample Time (s)              5.5694947792217135
Epoch Time (s)               170.20417585782707
Total Train Time (s)         60196.44132854417
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:12:57.581178 UTC | [2020_01_10_09_29_40] Iteration #365 | Epoch Duration: 170.28541088104248
2020-01-11 02:12:57.581307 UTC | [2020_01_10_09_29_40] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1587303
Z variance train             0.016298532
KL Divergence                8.335166
KL Loss                      0.8335166
QF Loss                      74.0854
VF Loss                      25.828125
Policy Loss                  -1449.378
Q Predictions Mean           1449.23
Q Predictions Std            317.7454
Q Predictions Max            1756.5211
Q Predictions Min            119.45922
V Predictions Mean           1448.2623
V Predictions Std            315.061
V Predictions Max            1753.3611
V Predictions Min            118.74445
Log Pis Mean                 -0.11071029
Log Pis Std                  2.0787573
Log Pis Max                  6.790147
Log Pis Min                  -4.2026806
Policy mu Mean               -0.23057754
Policy mu Std                0.87344956
Policy mu Max                2.2273943
Policy mu Min                -2.5374908
Policy log std Mean          -0.47677532
Policy log std Std           0.20632249
Policy log std Max           0.18392822
Policy log std Min           -1.3545161
Z mean eval                  0.08304064
Z variance eval              0.011852958
total_rewards                [3363.78270051  986.70223066 2743.46163568 1289.98838723 2706.23565079
 3354.01735273 3335.46588955 3359.89220648 2796.32892516 3326.41198121]
total_rewards_mean           2726.2286959988587
total_rewards_std            838.3234680546735
total_rewards_max            3363.782700507242
total_rewards_min            986.7022306581458
Number of train steps total  1468000
Number of env steps total    1701683
Number of rollouts total     0
Train Time (s)               144.85322414617985
(Previous) Eval Time (s)     15.221823854837567
Sample Time (s)              5.9034362635575235
Epoch Time (s)               165.97848426457494
Total Train Time (s)         60362.50270618405
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:15:43.647577 UTC | [2020_01_10_09_29_40] Iteration #366 | Epoch Duration: 166.0661540031433
2020-01-11 02:15:43.647806 UTC | [2020_01_10_09_29_40] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.084119655
Z variance train             0.011905769
KL Divergence                8.828577
KL Loss                      0.88285774
QF Loss                      83.22345
VF Loss                      91.90736
Policy Loss                  -1413.7689
Q Predictions Mean           1415.3132
Q Predictions Std            378.03555
Q Predictions Max            1734.1528
Q Predictions Min            43.95021
V Predictions Mean           1421.2699
V Predictions Std            375.65353
V Predictions Max            1739.2124
V Predictions Min            49.070698
Log Pis Mean                 -0.085544236
Log Pis Std                  2.1389978
Log Pis Max                  7.282611
Log Pis Min                  -7.78391
Policy mu Mean               -0.15836327
Policy mu Std                0.897269
Policy mu Max                2.0229506
Policy mu Min                -2.5526948
Policy log std Mean          -0.48113874
Policy log std Std           0.18657725
Policy log std Max           0.067814946
Policy log std Min           -1.110827
Z mean eval                  0.12809959
Z variance eval              0.012124044
total_rewards                [3245.09266213 3264.5894348  3207.47759691 3246.90981174 3244.26007344
 3208.80985749 1261.45782981 3222.66862344 3225.97557574 3246.8612522 ]
total_rewards_mean           3037.410271769951
total_rewards_std            592.239333222819
total_rewards_max            3264.589434797142
total_rewards_min            1261.4578298134477
Number of train steps total  1472000
Number of env steps total    1709003
Number of rollouts total     0
Train Time (s)               145.86057676700875
(Previous) Eval Time (s)     20.27540512988344
Sample Time (s)              6.722752312198281
Epoch Time (s)               172.85873420909047
Total Train Time (s)         60535.46186514851
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:18:36.612738 UTC | [2020_01_10_09_29_40] Iteration #367 | Epoch Duration: 172.96476650238037
2020-01-11 02:18:36.612921 UTC | [2020_01_10_09_29_40] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1274319
Z variance train             0.012112066
KL Divergence                9.100899
KL Loss                      0.9100899
QF Loss                      64.52195
VF Loss                      41.13685
Policy Loss                  -1453.8284
Q Predictions Mean           1452.9556
Q Predictions Std            343.12402
Q Predictions Max            1746.3472
Q Predictions Min            42.577297
V Predictions Mean           1456.9572
V Predictions Std            339.86417
V Predictions Max            1756.6897
V Predictions Min            41.177643
Log Pis Mean                 -0.0026033781
Log Pis Std                  2.184766
Log Pis Max                  7.2204256
Log Pis Min                  -6.1687
Policy mu Mean               -0.21086733
Policy mu Std                0.92254764
Policy mu Max                2.0053263
Policy mu Min                -2.675192
Policy log std Mean          -0.49438825
Policy log std Std           0.17916001
Policy log std Max           0.07379508
Policy log std Min           -1.1244305
Z mean eval                  0.08569151
Z variance eval              0.016266366
total_rewards                [3332.28383139 3310.21668699  929.22593039 3349.01519732 3319.04259968
  960.1513022   942.58671987 3314.50635422 3324.93277015 1040.74199435]
total_rewards_mean           2382.2703386562744
total_rewards_std            1154.9706588496392
total_rewards_max            3349.0151973201437
total_rewards_min            929.2259303904927
Number of train steps total  1476000
Number of env steps total    1716139
Number of rollouts total     0
Train Time (s)               146.1851759813726
(Previous) Eval Time (s)     13.023341654334217
Sample Time (s)              6.495199913624674
Epoch Time (s)               165.7037175493315
Total Train Time (s)         60701.2418899131
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:21:22.397816 UTC | [2020_01_10_09_29_40] Iteration #368 | Epoch Duration: 165.78470516204834
2020-01-11 02:21:22.398074 UTC | [2020_01_10_09_29_40] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.085819125
Z variance train             0.016234245
KL Divergence                8.989393
KL Loss                      0.8989393
QF Loss                      41.79162
VF Loss                      20.464561
Policy Loss                  -1493.5575
Q Predictions Mean           1492.2698
Q Predictions Std            272.19608
Q Predictions Max            1773.923
Q Predictions Min            86.1018
V Predictions Mean           1495.0457
V Predictions Std            267.92572
V Predictions Max            1776.7892
V Predictions Min            116.23453
Log Pis Mean                 -0.22058272
Log Pis Std                  1.9525073
Log Pis Max                  6.02191
Log Pis Min                  -5.0034432
Policy mu Mean               -0.17476404
Policy mu Std                0.8799897
Policy mu Max                2.1168945
Policy mu Min                -2.5713942
Policy log std Mean          -0.50447124
Policy log std Std           0.1799489
Policy log std Max           0.055333465
Policy log std Min           -1.351224
Z mean eval                  0.12644692
Z variance eval              0.015378636
total_rewards                [3309.40387767 3274.14893801 3290.13666013 3307.91324857 3321.52846248
 3300.21774096 3286.97519373 3283.60884829 3283.51843997 3291.4552925 ]
total_rewards_mean           3294.890670232623
total_rewards_std            13.791498027121461
total_rewards_max            3321.5284624809506
total_rewards_min            3274.148938012753
Number of train steps total  1480000
Number of env steps total    1723587
Number of rollouts total     0
Train Time (s)               147.1290031876415
(Previous) Eval Time (s)     18.187514580786228
Sample Time (s)              6.603433475364
Epoch Time (s)               171.91995124379173
Total Train Time (s)         60873.24032523204
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:24:14.398036 UTC | [2020_01_10_09_29_40] Iteration #369 | Epoch Duration: 171.99982500076294
2020-01-11 02:24:14.398161 UTC | [2020_01_10_09_29_40] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12655008
Z variance train             0.015422109
KL Divergence                8.712291
KL Loss                      0.8712291
QF Loss                      214.74135
VF Loss                      59.397327
Policy Loss                  -1464.3263
Q Predictions Mean           1460.9524
Q Predictions Std            290.30447
Q Predictions Max            1787.7045
Q Predictions Min            64.94283
V Predictions Mean           1459.8838
V Predictions Std            287.82758
V Predictions Max            1784.7521
V Predictions Min            87.19106
Log Pis Mean                 -0.054378856
Log Pis Std                  1.9656073
Log Pis Max                  7.498102
Log Pis Min                  -5.2592278
Policy mu Mean               -0.13829885
Policy mu Std                0.8830018
Policy mu Max                2.0440397
Policy mu Min                -2.7193909
Policy log std Mean          -0.5171566
Policy log std Std           0.19267206
Policy log std Max           0.3222965
Policy log std Min           -1.3400898
Z mean eval                  0.08154157
Z variance eval              0.015978755
total_rewards                [3276.59542084 3296.67114613 3290.87977021 3297.06670867 3298.55341868
 3288.94333059 3280.13215996 3308.28180617 3292.84617393 3305.09609982]
total_rewards_mean           3293.506603501109
total_rewards_std            9.454130210001829
total_rewards_max            3308.2818061737644
total_rewards_min            3276.595420840385
Number of train steps total  1484000
Number of env steps total    1731425
Number of rollouts total     0
Train Time (s)               145.03085314901546
(Previous) Eval Time (s)     18.557750390842557
Sample Time (s)              5.5881144888699055
Epoch Time (s)               169.17671802872792
Total Train Time (s)         61042.50000307197
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:27:03.664029 UTC | [2020_01_10_09_29_40] Iteration #370 | Epoch Duration: 169.26569318771362
2020-01-11 02:27:03.664321 UTC | [2020_01_10_09_29_40] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08141377
Z variance train             0.015999813
KL Divergence                8.859112
KL Loss                      0.88591117
QF Loss                      69.15864
VF Loss                      15.802923
Policy Loss                  -1516.0979
Q Predictions Mean           1515.5316
Q Predictions Std            276.0131
Q Predictions Max            1791.0924
Q Predictions Min            152.82544
V Predictions Mean           1514.6902
V Predictions Std            270.86777
V Predictions Max            1787.2145
V Predictions Min            150.00899
Log Pis Mean                 -0.39126793
Log Pis Std                  2.099314
Log Pis Max                  6.2514687
Log Pis Min                  -5.26893
Policy mu Mean               -0.11355112
Policy mu Std                0.8578448
Policy mu Max                1.987129
Policy mu Min                -2.491054
Policy log std Mean          -0.48821414
Policy log std Std           0.2020133
Policy log std Max           0.1360546
Policy log std Min           -1.2015815
Z mean eval                  0.047441036
Z variance eval              0.020217016
total_rewards                [3304.13157632 2468.71787661 2217.57921783  820.45021727 3294.15931367
 1923.867799   3340.60406664 1143.84662956 3309.33419202 3298.00359377]
total_rewards_mean           2512.0694482690665
total_rewards_std            913.6199690188337
total_rewards_max            3340.6040666428416
total_rewards_min            820.4502172685176
Number of train steps total  1488000
Number of env steps total    1739325
Number of rollouts total     0
Train Time (s)               146.23106859065592
(Previous) Eval Time (s)     17.052866318728775
Sample Time (s)              6.497812924906611
Epoch Time (s)               169.7817478342913
Total Train Time (s)         61212.37448785268
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:29:53.540704 UTC | [2020_01_10_09_29_40] Iteration #371 | Epoch Duration: 169.87623405456543
2020-01-11 02:29:53.540843 UTC | [2020_01_10_09_29_40] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046764947
Z variance train             0.020237215
KL Divergence                8.565573
KL Loss                      0.8565573
QF Loss                      50.928505
VF Loss                      15.204504
Policy Loss                  -1514.8236
Q Predictions Mean           1513.5299
Q Predictions Std            245.38477
Q Predictions Max            1773.9991
Q Predictions Min            -8.106855
V Predictions Mean           1516.4392
V Predictions Std            242.21451
V Predictions Max            1775.5599
V Predictions Min            -8.534366
Log Pis Mean                 -0.15027082
Log Pis Std                  2.0161958
Log Pis Max                  5.7446294
Log Pis Min                  -6.874408
Policy mu Mean               -0.15104145
Policy mu Std                0.90146834
Policy mu Max                1.9096622
Policy mu Min                -2.5302253
Policy log std Mean          -0.48347545
Policy log std Std           0.189946
Policy log std Max           0.13525116
Policy log std Min           -1.0780642
Z mean eval                  0.06263612
Z variance eval              0.012622258
total_rewards                [3297.81195786 3276.6539083  3323.48025478 3319.76247968 3302.30728679
 3316.6088106  3287.07346362 3321.63988481 3304.89670208 3296.0199165 ]
total_rewards_mean           3304.6254665014903
total_rewards_std            14.947009617259958
total_rewards_max            3323.4802547758554
total_rewards_min            3276.65390830178
Number of train steps total  1492000
Number of env steps total    1746601
Number of rollouts total     0
Train Time (s)               145.63732517976314
(Previous) Eval Time (s)     18.632632012013346
Sample Time (s)              6.832079361192882
Epoch Time (s)               171.10203655296937
Total Train Time (s)         61383.551110014785
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:32:44.719502 UTC | [2020_01_10_09_29_40] Iteration #372 | Epoch Duration: 171.1785705089569
2020-01-11 02:32:44.719629 UTC | [2020_01_10_09_29_40] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06263068
Z variance train             0.012653669
KL Divergence                9.321262
KL Loss                      0.9321262
QF Loss                      41.35191
VF Loss                      19.507013
Policy Loss                  -1496.5032
Q Predictions Mean           1496.8511
Q Predictions Std            287.0406
Q Predictions Max            1762.0353
Q Predictions Min            29.136036
V Predictions Mean           1495.8817
V Predictions Std            287.53668
V Predictions Max            1758.473
V Predictions Min            31.963003
Log Pis Mean                 -0.20914596
Log Pis Std                  2.0603852
Log Pis Max                  6.860824
Log Pis Min                  -6.995952
Policy mu Mean               -0.11022981
Policy mu Std                0.84992605
Policy mu Max                2.110999
Policy mu Min                -2.687693
Policy log std Mean          -0.49193668
Policy log std Std           0.18061581
Policy log std Max           0.04025632
Policy log std Min           -1.4096355
Z mean eval                  0.12687626
Z variance eval              0.013442037
total_rewards                [3256.539714   3288.36866813 3261.46646671 3248.68673375 3271.70862927
 3255.33181554 3283.41950628 3254.20335074 3257.91897098 3234.29514508]
total_rewards_mean           3261.1939000481175
total_rewards_std            15.292710899587146
total_rewards_max            3288.368668131513
total_rewards_min            3234.2951450761625
Number of train steps total  1496000
Number of env steps total    1753727
Number of rollouts total     0
Train Time (s)               144.03417666628957
(Previous) Eval Time (s)     21.565009049139917
Sample Time (s)              5.796522472985089
Epoch Time (s)               171.39570818841457
Total Train Time (s)         61555.025176190306
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:35:36.197775 UTC | [2020_01_10_09_29_40] Iteration #373 | Epoch Duration: 171.4780592918396
2020-01-11 02:35:36.197920 UTC | [2020_01_10_09_29_40] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12677749
Z variance train             0.013455058
KL Divergence                8.643467
KL Loss                      0.8643467
QF Loss                      45.310295
VF Loss                      26.334087
Policy Loss                  -1481.8408
Q Predictions Mean           1482.3971
Q Predictions Std            323.93393
Q Predictions Max            1765.9329
Q Predictions Min            17.371363
V Predictions Mean           1480.8594
V Predictions Std            324.80505
V Predictions Max            1767.775
V Predictions Min            9.959753
Log Pis Mean                 -0.18766534
Log Pis Std                  2.1835623
Log Pis Max                  7.1153197
Log Pis Min                  -5.42782
Policy mu Mean               -0.18568045
Policy mu Std                0.87155986
Policy mu Max                2.391333
Policy mu Min                -2.6636748
Policy log std Mean          -0.45050588
Policy log std Std           0.19268627
Policy log std Max           0.050618052
Policy log std Min           -1.1179609
Z mean eval                  0.16474763
Z variance eval              0.014138001
total_rewards                [3265.36004658 3274.23755608 3267.47891157 3241.33871452 3266.68557156
 3293.85843952 3263.35530103 3300.29707268 3267.77598518 3273.34328909]
total_rewards_mean           3271.3730887799384
total_rewards_std            15.514046946227353
total_rewards_max            3300.2970726751473
total_rewards_min            3241.338714522852
Number of train steps total  1500000
Number of env steps total    1761279
Number of rollouts total     0
Train Time (s)               146.5298641580157
(Previous) Eval Time (s)     21.923982446081936
Sample Time (s)              6.434571101330221
Epoch Time (s)               174.88841770542786
Total Train Time (s)         61729.98912970396
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:38:31.164808 UTC | [2020_01_10_09_29_40] Iteration #374 | Epoch Duration: 174.9667992591858
2020-01-11 02:38:31.164933 UTC | [2020_01_10_09_29_40] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16446257
Z variance train             0.014111501
KL Divergence                8.52946
KL Loss                      0.852946
QF Loss                      53.588722
VF Loss                      31.955448
Policy Loss                  -1474.4156
Q Predictions Mean           1476.7073
Q Predictions Std            303.38794
Q Predictions Max            1756.4541
Q Predictions Min            35.288757
V Predictions Mean           1478.2612
V Predictions Std            300.83023
V Predictions Max            1763.1729
V Predictions Min            40.29636
Log Pis Mean                 -0.029814199
Log Pis Std                  2.112963
Log Pis Max                  6.61831
Log Pis Min                  -8.486982
Policy mu Mean               -0.1765907
Policy mu Std                0.9088177
Policy mu Max                2.2344494
Policy mu Min                -2.7011366
Policy log std Mean          -0.47139785
Policy log std Std           0.19194387
Policy log std Max           0.3962235
Policy log std Min           -1.2167656
Z mean eval                  0.14222953
Z variance eval              0.013541254
total_rewards                [3264.04871914  955.91716604 1250.12112118 1494.62965683 3246.62767298
 3301.26776026  931.72664225 3295.4412879  3301.16968878 1345.76912827]
total_rewards_mean           2238.671884364713
total_rewards_std            1054.695121352503
total_rewards_max            3301.2677602627937
total_rewards_min            931.7266422519431
Number of train steps total  1504000
Number of env steps total    1769141
Number of rollouts total     0
Train Time (s)               147.26545348297805
(Previous) Eval Time (s)     14.32620388502255
Sample Time (s)              6.508171476889402
Epoch Time (s)               168.09982884489
Total Train Time (s)         61898.169836890884
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:41:19.348315 UTC | [2020_01_10_09_29_40] Iteration #375 | Epoch Duration: 168.183274269104
2020-01-11 02:41:19.348439 UTC | [2020_01_10_09_29_40] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14521259
Z variance train             0.013409624
KL Divergence                8.856486
KL Loss                      0.88564867
QF Loss                      124.14269
VF Loss                      43.9949
Policy Loss                  -1462.7135
Q Predictions Mean           1465.3428
Q Predictions Std            357.3423
Q Predictions Max            1773.8004
Q Predictions Min            -52.10483
V Predictions Mean           1464.7103
V Predictions Std            354.04156
V Predictions Max            1770.011
V Predictions Min            5.626698
Log Pis Mean                 -0.21848004
Log Pis Std                  1.8991435
Log Pis Max                  6.6741123
Log Pis Min                  -5.048816
Policy mu Mean               -0.12499747
Policy mu Std                0.83527154
Policy mu Max                3.1191025
Policy mu Min                -2.3135147
Policy log std Mean          -0.4716997
Policy log std Std           0.17290242
Policy log std Max           0.15036774
Policy log std Min           -1.0408752
Z mean eval                  0.15091275
Z variance eval              0.0091529535
total_rewards                [ 894.02037666 1065.35443636  998.73970447 1022.33312395 3351.77128896
  995.74875347  988.70445383 3359.50418991 3367.16302028  976.34417596]
total_rewards_mean           1701.9683523851527
total_rewards_std            1085.848138785282
total_rewards_max            3367.1630202806437
total_rewards_min            894.0203766584995
Number of train steps total  1508000
Number of env steps total    1776528
Number of rollouts total     0
Train Time (s)               144.6391813470982
(Previous) Eval Time (s)     10.874655046965927
Sample Time (s)              6.578826060518622
Epoch Time (s)               162.09266245458275
Total Train Time (s)         62060.34127590433
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:44:01.522570 UTC | [2020_01_10_09_29_40] Iteration #376 | Epoch Duration: 162.17404341697693
2020-01-11 02:44:01.522729 UTC | [2020_01_10_09_29_40] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15054339
Z variance train             0.009139889
KL Divergence                10.179663
KL Loss                      1.0179663
QF Loss                      48.99694
VF Loss                      27.381172
Policy Loss                  -1460.853
Q Predictions Mean           1461.1162
Q Predictions Std            349.52277
Q Predictions Max            1793.0299
Q Predictions Min            7.8209996
V Predictions Mean           1459.227
V Predictions Std            349.0455
V Predictions Max            1795.9583
V Predictions Min            -45.238197
Log Pis Mean                 -0.002278246
Log Pis Std                  2.1145852
Log Pis Max                  8.087011
Log Pis Min                  -7.1245513
Policy mu Mean               -0.2159205
Policy mu Std                0.9148366
Policy mu Max                2.5265827
Policy mu Min                -2.485705
Policy log std Mean          -0.45018816
Policy log std Std           0.1809543
Policy log std Max           0.20924097
Policy log std Min           -1.5544715
Z mean eval                  0.11126222
Z variance eval              0.011604701
total_rewards                [3288.65015169 1015.28260645 3284.38237152  943.50161013 3308.71401845
 3273.47834428 3278.17770333  963.83326978  952.57665502 1036.54997212]
total_rewards_mean           2134.5146702773154
total_rewards_std            1152.4913599183594
total_rewards_max            3308.7140184474133
total_rewards_min            943.5016101334487
Number of train steps total  1512000
Number of env steps total    1783538
Number of rollouts total     0
Train Time (s)               146.77491438016295
(Previous) Eval Time (s)     14.261556894052774
Sample Time (s)              6.3925695908255875
Epoch Time (s)               167.42904086504132
Total Train Time (s)         62227.84652914666
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:46:49.031379 UTC | [2020_01_10_09_29_40] Iteration #377 | Epoch Duration: 167.5085175037384
2020-01-11 02:46:49.031537 UTC | [2020_01_10_09_29_40] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11155691
Z variance train             0.01160121
KL Divergence                8.954144
KL Loss                      0.89541435
QF Loss                      52.57869
VF Loss                      17.510166
Policy Loss                  -1474.4452
Q Predictions Mean           1471.354
Q Predictions Std            364.1182
Q Predictions Max            1788.3226
Q Predictions Min            35.569942
V Predictions Mean           1474.9426
V Predictions Std            360.96338
V Predictions Max            1790.511
V Predictions Min            39.67702
Log Pis Mean                 -0.42923254
Log Pis Std                  1.9628216
Log Pis Max                  6.6863923
Log Pis Min                  -5.963368
Policy mu Mean               -0.25545773
Policy mu Std                0.8663659
Policy mu Max                1.9011467
Policy mu Min                -2.4355934
Policy log std Mean          -0.47772074
Policy log std Std           0.1912203
Policy log std Max           0.2578928
Policy log std Min           -1.152905
Z mean eval                  0.03240516
Z variance eval              0.008059602
total_rewards                [3263.09358209 3283.29613625 3280.38214496 1353.94945943 3299.07742938
 3266.40891334 3276.96885716 3277.56107984 3289.62106135 1237.93903171]
total_rewards_mean           2882.8297695524766
total_rewards_std            793.9266318722123
total_rewards_max            3299.077429378654
total_rewards_min            1237.9390317078883
Number of train steps total  1516000
Number of env steps total    1790953
Number of rollouts total     0
Train Time (s)               145.44868853501976
(Previous) Eval Time (s)     18.801432956010103
Sample Time (s)              6.550093618687242
Epoch Time (s)               170.8002151097171
Total Train Time (s)         62398.96440625517
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:49:40.151887 UTC | [2020_01_10_09_29_40] Iteration #378 | Epoch Duration: 171.1202311515808
2020-01-11 02:49:40.152023 UTC | [2020_01_10_09_29_40] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032204963
Z variance train             0.008056314
KL Divergence                10.243785
KL Loss                      1.0243785
QF Loss                      43.041336
VF Loss                      18.447828
Policy Loss                  -1454.3273
Q Predictions Mean           1454.129
Q Predictions Std            322.45233
Q Predictions Max            1776.612
Q Predictions Min            63.256893
V Predictions Mean           1455.4775
V Predictions Std            322.07266
V Predictions Max            1774.3679
V Predictions Min            73.612946
Log Pis Mean                 -0.26995218
Log Pis Std                  2.074027
Log Pis Max                  6.6742344
Log Pis Min                  -5.59859
Policy mu Mean               -0.18673043
Policy mu Std                0.9089039
Policy mu Max                1.6606512
Policy mu Min                -2.6335766
Policy log std Mean          -0.47097325
Policy log std Std           0.18022802
Policy log std Max           0.13621092
Policy log std Min           -1.2289543
Z mean eval                  0.14462574
Z variance eval              0.01290777
total_rewards                [3303.9038404  3289.96177239 3299.20692028 3289.29894381 3289.21741529
 3287.8398762  3263.65489402 3273.70859936 3280.89147077 3275.75386044]
total_rewards_mean           3285.3437592950236
total_rewards_std            11.45618627441266
total_rewards_max            3303.9038404000776
total_rewards_min            3263.6548940249163
Number of train steps total  1520000
Number of env steps total    1798420
Number of rollouts total     0
Train Time (s)               145.74080256791785
(Previous) Eval Time (s)     18.493825164157897
Sample Time (s)              6.3136748932302
Epoch Time (s)               170.54830262530595
Total Train Time (s)         62569.591924978886
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:52:30.783109 UTC | [2020_01_10_09_29_40] Iteration #379 | Epoch Duration: 170.63099455833435
2020-01-11 02:52:30.783233 UTC | [2020_01_10_09_29_40] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14423403
Z variance train             0.012894829
KL Divergence                8.697533
KL Loss                      0.8697533
QF Loss                      59.6657
VF Loss                      58.369057
Policy Loss                  -1447.3347
Q Predictions Mean           1448.6667
Q Predictions Std            298.89612
Q Predictions Max            1796.0961
Q Predictions Min            52.80183
V Predictions Mean           1443.5273
V Predictions Std            298.71207
V Predictions Max            1789.2014
V Predictions Min            31.158842
Log Pis Mean                 0.019427795
Log Pis Std                  2.0686097
Log Pis Max                  5.536607
Log Pis Min                  -5.2957344
Policy mu Mean               -0.20248203
Policy mu Std                0.9152963
Policy mu Max                1.9809065
Policy mu Min                -2.6394742
Policy log std Mean          -0.48800817
Policy log std Std           0.1822225
Policy log std Max           0.0047441125
Policy log std Min           -1.2271484
Z mean eval                  0.07313423
Z variance eval              0.01437434
total_rewards                [ 749.37356898 3357.54453324 1311.5916496  3330.68613997 3339.00182523
 2328.60793917  947.96242743 3346.55868851 3319.2546184  1071.23915876]
total_rewards_mean           2310.182054928475
total_rewards_std            1100.6106526574022
total_rewards_max            3357.5445332351587
total_rewards_min            749.373568980417
Number of train steps total  1524000
Number of env steps total    1805468
Number of rollouts total     0
Train Time (s)               146.8404599511996
(Previous) Eval Time (s)     12.94805716816336
Sample Time (s)              5.537888599094003
Epoch Time (s)               165.32640571845695
Total Train Time (s)         62735.00317749288
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:55:16.200156 UTC | [2020_01_10_09_29_40] Iteration #380 | Epoch Duration: 165.41682696342468
2020-01-11 02:55:16.200323 UTC | [2020_01_10_09_29_40] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07496469
Z variance train             0.014232969
KL Divergence                8.779247
KL Loss                      0.87792474
QF Loss                      212.28032
VF Loss                      62.223824
Policy Loss                  -1489.5378
Q Predictions Mean           1484.6733
Q Predictions Std            278.39804
Q Predictions Max            1771.3616
Q Predictions Min            249.89836
V Predictions Mean           1493.0706
V Predictions Std            270.93454
V Predictions Max            1779.0015
V Predictions Min            238.44122
Log Pis Mean                 -0.17323887
Log Pis Std                  1.9985343
Log Pis Max                  5.976335
Log Pis Min                  -6.4614778
Policy mu Mean               -0.17531563
Policy mu Std                0.91230506
Policy mu Max                1.7046769
Policy mu Min                -2.529309
Policy log std Mean          -0.46362457
Policy log std Std           0.2083001
Policy log std Max           0.5966009
Policy log std Min           -1.1337849
Z mean eval                  0.14408694
Z variance eval              0.009191004
total_rewards                [3312.32175537 3311.60849586  351.72186873 3291.27615524 3317.08510923
 3334.6655799  3335.86041143 3341.15664525 3302.21542608 2409.47685004]
total_rewards_mean           2930.7388297130615
total_rewards_std            901.4809115821689
total_rewards_max            3341.15664524556
total_rewards_min            351.72186873219295
Number of train steps total  1528000
Number of env steps total    1812627
Number of rollouts total     0
Train Time (s)               144.06111472379416
(Previous) Eval Time (s)     16.499373964965343
Sample Time (s)              6.4089227369986475
Epoch Time (s)               166.96941142575815
Total Train Time (s)         62902.04440615699
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:58:03.244620 UTC | [2020_01_10_09_29_40] Iteration #381 | Epoch Duration: 167.0441882610321
2020-01-11 02:58:03.244731 UTC | [2020_01_10_09_29_40] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14436729
Z variance train             0.00919053
KL Divergence                9.981445
KL Loss                      0.99814457
QF Loss                      34.204765
VF Loss                      11.963682
Policy Loss                  -1541.27
Q Predictions Mean           1541.4214
Q Predictions Std            205.40955
Q Predictions Max            1789.9481
Q Predictions Min            413.45178
V Predictions Mean           1539.4126
V Predictions Std            203.7655
V Predictions Max            1778.4758
V Predictions Min            390.59103
Log Pis Mean                 -0.22485378
Log Pis Std                  1.7694972
Log Pis Max                  6.022499
Log Pis Min                  -4.475194
Policy mu Mean               -0.08006272
Policy mu Std                0.85185206
Policy mu Max                1.8123775
Policy mu Min                -2.583254
Policy log std Mean          -0.47842237
Policy log std Std           0.17005709
Policy log std Max           0.055122197
Policy log std Min           -0.97647375
Z mean eval                  0.08712369
Z variance eval              0.013137439
total_rewards                [3322.37900092 3310.84936422  721.8523588  3302.47901397 3319.40561371
  970.96805287  746.40554087 3300.15112919  972.32773157  980.72208933]
total_rewards_mean           2094.753989544821
total_rewards_std            1219.1804528381579
total_rewards_max            3322.3790009191557
total_rewards_min            721.852358798225
Number of train steps total  1532000
Number of env steps total    1820482
Number of rollouts total     0
Train Time (s)               145.13004061486572
(Previous) Eval Time (s)     11.85607956815511
Sample Time (s)              6.071142586879432
Epoch Time (s)               163.05726276990026
Total Train Time (s)         63065.185798987746
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:00:46.392610 UTC | [2020_01_10_09_29_40] Iteration #382 | Epoch Duration: 163.1477916240692
2020-01-11 03:00:46.392731 UTC | [2020_01_10_09_29_40] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.084936365
Z variance train             0.013075118
KL Divergence                8.628958
KL Loss                      0.8628958
QF Loss                      34.08894
VF Loss                      19.791311
Policy Loss                  -1543.249
Q Predictions Mean           1544.1367
Q Predictions Std            196.83168
Q Predictions Max            1788.9758
Q Predictions Min            531.7333
V Predictions Mean           1544.8262
V Predictions Std            194.58226
V Predictions Max            1787.4149
V Predictions Min            591.82666
Log Pis Mean                 -0.32127407
Log Pis Std                  1.9780053
Log Pis Max                  5.350151
Log Pis Min                  -11.177628
Policy mu Mean               -0.25169227
Policy mu Std                0.8128814
Policy mu Max                2.2239883
Policy mu Min                -2.6076875
Policy log std Mean          -0.47480416
Policy log std Std           0.1871766
Policy log std Max           0.13295549
Policy log std Min           -1.114913
Z mean eval                  0.117496
Z variance eval              0.023054346
total_rewards                [1058.73807929 3293.66749169 3296.74577965 3313.73105946 3313.20320289
 3281.39120063 3302.58827544 3268.30388122 3297.83649808 3309.63646768]
total_rewards_mean           3073.5841936021916
total_rewards_std            671.7501435297712
total_rewards_max            3313.731059464085
total_rewards_min            1058.7380792868523
Number of train steps total  1536000
Number of env steps total    1828177
Number of rollouts total     0
Train Time (s)               145.46199851064011
(Previous) Eval Time (s)     17.021040350198746
Sample Time (s)              5.718402571976185
Epoch Time (s)               168.20144143281505
Total Train Time (s)         63233.46882771049
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:03:34.682958 UTC | [2020_01_10_09_29_40] Iteration #383 | Epoch Duration: 168.29012870788574
2020-01-11 03:03:34.683123 UTC | [2020_01_10_09_29_40] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1171698
Z variance train             0.023004627
KL Divergence                7.459389
KL Loss                      0.74593896
QF Loss                      96.28292
VF Loss                      49.159344
Policy Loss                  -1512.4254
Q Predictions Mean           1509.7764
Q Predictions Std            262.31604
Q Predictions Max            1759.8414
Q Predictions Min            35.41361
V Predictions Mean           1512.6958
V Predictions Std            248.58417
V Predictions Max            1760.155
V Predictions Min            63.11476
Log Pis Mean                 -0.21126421
Log Pis Std                  2.0681534
Log Pis Max                  6.944881
Log Pis Min                  -5.5362744
Policy mu Mean               -0.15515615
Policy mu Std                0.86771107
Policy mu Max                1.7313185
Policy mu Min                -2.5392885
Policy log std Mean          -0.47298566
Policy log std Std           0.2011512
Policy log std Max           0.16293609
Policy log std Min           -1.481991
Z mean eval                  0.16719982
Z variance eval              0.014811355
total_rewards                [ 895.15106339 3305.67008965  975.41662601  738.75781643  912.14707852
 1223.80708929 1181.51728237 3286.44980801 1228.54306713 1328.69752883]
total_rewards_mean           1507.615744963946
total_rewards_std            910.9393631624098
total_rewards_max            3305.6700896535567
total_rewards_min            738.757816427834
Number of train steps total  1540000
Number of env steps total    1835433
Number of rollouts total     0
Train Time (s)               145.64600608684123
(Previous) Eval Time (s)     9.798422830179334
Sample Time (s)              6.576967309694737
Epoch Time (s)               162.0213962267153
Total Train Time (s)         63395.57158849249
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:06:16.787871 UTC | [2020_01_10_09_29_40] Iteration #384 | Epoch Duration: 162.10463500022888
2020-01-11 03:06:16.787997 UTC | [2020_01_10_09_29_40] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16710927
Z variance train             0.01480707
KL Divergence                8.536987
KL Loss                      0.85369873
QF Loss                      42.952908
VF Loss                      21.28205
Policy Loss                  -1534.5447
Q Predictions Mean           1534.3962
Q Predictions Std            231.27324
Q Predictions Max            1772.1517
Q Predictions Min            79.3429
V Predictions Mean           1534.6211
V Predictions Std            229.39757
V Predictions Max            1769.4248
V Predictions Min            98.6425
Log Pis Mean                 -0.3447163
Log Pis Std                  1.6847602
Log Pis Max                  6.5228477
Log Pis Min                  -4.189353
Policy mu Mean               -0.14231241
Policy mu Std                0.82319653
Policy mu Max                1.6163229
Policy mu Min                -2.4145694
Policy log std Mean          -0.47944084
Policy log std Std           0.177375
Policy log std Max           -0.078308046
Policy log std Min           -1.59106
Z mean eval                  0.05748806
Z variance eval              0.010266116
total_rewards                [3264.82176156  746.6518837  3286.59166759 3062.19139961  741.77612536
 3288.46408251 1737.77477343 1073.89137976 1054.67114408  797.99050252]
total_rewards_mean           1905.4824720117444
total_rewards_std            1112.3429498647315
total_rewards_max            3288.464082514523
total_rewards_min            741.776125362199
Number of train steps total  1544000
Number of env steps total    1843132
Number of rollouts total     0
Train Time (s)               145.07934250915423
(Previous) Eval Time (s)     10.921693270094693
Sample Time (s)              6.559164809063077
Epoch Time (s)               162.560200588312
Total Train Time (s)         63558.21529111592
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:08:59.434085 UTC | [2020_01_10_09_29_40] Iteration #385 | Epoch Duration: 162.64599132537842
2020-01-11 03:08:59.434229 UTC | [2020_01_10_09_29_40] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057672244
Z variance train             0.010263691
KL Divergence                9.198803
KL Loss                      0.91988033
QF Loss                      39.65309
VF Loss                      14.1563015
Policy Loss                  -1560.0176
Q Predictions Mean           1558.6958
Q Predictions Std            213.41388
Q Predictions Max            1790.3557
Q Predictions Min            160.23851
V Predictions Mean           1561.4523
V Predictions Std            210.35713
V Predictions Max            1793.559
V Predictions Min            215.9261
Log Pis Mean                 -0.3114708
Log Pis Std                  1.9953177
Log Pis Max                  5.9223957
Log Pis Min                  -6.088395
Policy mu Mean               -0.1446508
Policy mu Std                0.8372731
Policy mu Max                1.6415812
Policy mu Min                -2.5391197
Policy log std Mean          -0.46548676
Policy log std Std           0.1870306
Policy log std Max           0.24481323
Policy log std Min           -1.1807296
Z mean eval                  0.062047966
Z variance eval              0.01523371
total_rewards                [ 811.97254712 3315.73711099 3286.88162696 1361.3927912   778.02133128
  831.35133923  879.06795671  688.82054599  697.09136757  829.62306995]
total_rewards_mean           1347.9959686980765
total_rewards_std            992.8428437035003
total_rewards_max            3315.7371109887185
total_rewards_min            688.8205459891795
Number of train steps total  1548000
Number of env steps total    1851331
Number of rollouts total     0
Train Time (s)               144.64506231388077
(Previous) Eval Time (s)     7.455468310974538
Sample Time (s)              7.3469931138679385
Epoch Time (s)               159.44752373872325
Total Train Time (s)         63717.73704830138
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:11:38.959734 UTC | [2020_01_10_09_29_40] Iteration #386 | Epoch Duration: 159.5253963470459
2020-01-11 03:11:38.959892 UTC | [2020_01_10_09_29_40] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060464837
Z variance train             0.015181387
KL Divergence                8.853862
KL Loss                      0.88538617
QF Loss                      110.96732
VF Loss                      95.235855
Policy Loss                  -1565.7146
Q Predictions Mean           1560.2524
Q Predictions Std            216.15648
Q Predictions Max            1778.8519
Q Predictions Min            460.93298
V Predictions Mean           1558.4932
V Predictions Std            216.78317
V Predictions Max            1778.1044
V Predictions Min            450.23785
Log Pis Mean                 -0.32984775
Log Pis Std                  1.8238677
Log Pis Max                  5.4299984
Log Pis Min                  -4.6248817
Policy mu Mean               -0.20132585
Policy mu Std                0.82298875
Policy mu Max                2.1662636
Policy mu Min                -2.393971
Policy log std Mean          -0.48747388
Policy log std Std           0.1893354
Policy log std Max           0.3025203
Policy log std Min           -1.5137517
Z mean eval                  0.14829974
Z variance eval              0.010755804
total_rewards                [1001.376439   3355.84361591 1032.78697454 3320.58754385 3306.66373085
 3345.25411431  663.35682132 1239.69183911 3326.17903024 1298.16617637]
total_rewards_mean           2188.9906285492298
total_rewards_std            1152.8626374642904
total_rewards_max            3355.843615908092
total_rewards_min            663.3568213221703
Number of train steps total  1552000
Number of env steps total    1858645
Number of rollouts total     0
Train Time (s)               144.56036995723844
(Previous) Eval Time (s)     13.79658563900739
Sample Time (s)              6.392317253164947
Epoch Time (s)               164.74927284941077
Total Train Time (s)         63882.56016252143
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:14:23.785712 UTC | [2020_01_10_09_29_40] Iteration #387 | Epoch Duration: 164.82570934295654
2020-01-11 03:14:23.785832 UTC | [2020_01_10_09_29_40] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14690162
Z variance train             0.010746567
KL Divergence                9.538498
KL Loss                      0.9538498
QF Loss                      35.77771
VF Loss                      16.763546
Policy Loss                  -1539.0638
Q Predictions Mean           1536.8044
Q Predictions Std            247.1471
Q Predictions Max            1787.8107
Q Predictions Min            10.814188
V Predictions Mean           1538.1038
V Predictions Std            240.07494
V Predictions Max            1781.188
V Predictions Min            21.802322
Log Pis Mean                 -0.5235286
Log Pis Std                  1.7691714
Log Pis Max                  7.646038
Log Pis Min                  -5.3217454
Policy mu Mean               -0.13913666
Policy mu Std                0.8023137
Policy mu Max                1.9625387
Policy mu Min                -2.5077577
Policy log std Mean          -0.4606043
Policy log std Std           0.18513376
Policy log std Max           0.16432321
Policy log std Min           -1.1581405
Z mean eval                  0.14013657
Z variance eval              0.0076862127
total_rewards                [3348.09778909 3348.28591601  981.00031974  811.20003094 3337.48755653
 3358.64806125 3359.33543863 3351.26205669 1264.65734486  981.41586121]
total_rewards_mean           2414.1390374952693
total_rewards_std            1151.4546807553268
total_rewards_max            3359.3354386328215
total_rewards_min            811.2000309406192
Number of train steps total  1556000
Number of env steps total    1866454
Number of rollouts total     0
Train Time (s)               146.554894908797
(Previous) Eval Time (s)     15.58884710026905
Sample Time (s)              5.642644111067057
Epoch Time (s)               167.7863861201331
Total Train Time (s)         64050.556069321465
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:17:11.785377 UTC | [2020_01_10_09_29_40] Iteration #388 | Epoch Duration: 167.99944376945496
2020-01-11 03:17:11.785558 UTC | [2020_01_10_09_29_40] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14012294
Z variance train             0.007688823
KL Divergence                10.73103
KL Loss                      1.0731031
QF Loss                      47.993504
VF Loss                      11.108082
Policy Loss                  -1536.7715
Q Predictions Mean           1536.41
Q Predictions Std            243.14214
Q Predictions Max            1785.9675
Q Predictions Min            147.77692
V Predictions Mean           1536.9126
V Predictions Std            239.71736
V Predictions Max            1786.6038
V Predictions Min            195.18588
Log Pis Mean                 -0.35671195
Log Pis Std                  1.8546525
Log Pis Max                  7.705946
Log Pis Min                  -5.369571
Policy mu Mean               -0.18872087
Policy mu Std                0.8377862
Policy mu Max                2.0526965
Policy mu Min                -2.7026236
Policy log std Mean          -0.46021846
Policy log std Std           0.19628328
Policy log std Max           0.45770627
Policy log std Min           -1.1984938
Z mean eval                  0.11384058
Z variance eval              0.008391435
total_rewards                [1024.16119722  845.99819882 1191.98001743  983.12069425  716.60430903
  961.32801862  904.63596109 3371.45068334  840.90024912  957.16964142]
total_rewards_mean           1179.7348970345054
total_rewards_std            740.2853286238872
total_rewards_max            3371.4506833442515
total_rewards_min            716.6043090250462
Number of train steps total  1560000
Number of env steps total    1873852
Number of rollouts total     0
Train Time (s)               146.0860088779591
(Previous) Eval Time (s)     6.315032144077122
Sample Time (s)              6.5575001034885645
Epoch Time (s)               158.9585411255248
Total Train Time (s)         64209.59988702275
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:19:50.832243 UTC | [2020_01_10_09_29_40] Iteration #389 | Epoch Duration: 159.04655861854553
2020-01-11 03:19:50.832412 UTC | [2020_01_10_09_29_40] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11346587
Z variance train             0.008394483
KL Divergence                10.300198
KL Loss                      1.0300198
QF Loss                      10071.197
VF Loss                      30.353832
Policy Loss                  -1526.4646
Q Predictions Mean           1528.448
Q Predictions Std            304.02863
Q Predictions Max            1807.5292
Q Predictions Min            70.52847
V Predictions Mean           1528.0714
V Predictions Std            300.22836
V Predictions Max            1806.5868
V Predictions Min            67.49475
Log Pis Mean                 -0.2322789
Log Pis Std                  1.8587022
Log Pis Max                  5.498278
Log Pis Min                  -5.2940593
Policy mu Mean               -0.2653232
Policy mu Std                0.82445997
Policy mu Max                2.007715
Policy mu Min                -2.5486019
Policy log std Mean          -0.4443883
Policy log std Std           0.19931339
Policy log std Max           0.56214714
Policy log std Min           -1.1099744
Z mean eval                  0.10635264
Z variance eval              0.008427597
total_rewards                [3360.27441665 1193.42423831 1652.27033139 3359.66570983 3320.94996015
 3067.00175157 1652.91953291 3260.84848592  857.64974228 3323.39597052]
total_rewards_mean           2504.8400139523155
total_rewards_std            978.3572768805104
total_rewards_max            3360.2744166520088
total_rewards_min            857.6497422779022
Number of train steps total  1564000
Number of env steps total    1881536
Number of rollouts total     0
Train Time (s)               144.8103273580782
(Previous) Eval Time (s)     13.914335593115538
Sample Time (s)              6.4474317682906985
Epoch Time (s)               165.17209471948445
Total Train Time (s)         64374.847944921814
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:22:36.083975 UTC | [2020_01_10_09_29_40] Iteration #390 | Epoch Duration: 165.25143551826477
2020-01-11 03:22:36.084142 UTC | [2020_01_10_09_29_40] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10634927
Z variance train             0.008434213
KL Divergence                9.918329
KL Loss                      0.9918329
QF Loss                      46.705555
VF Loss                      14.402161
Policy Loss                  -1515.0131
Q Predictions Mean           1514.929
Q Predictions Std            331.69043
Q Predictions Max            1810.9081
Q Predictions Min            40.539425
V Predictions Mean           1514.3204
V Predictions Std            331.14267
V Predictions Max            1810.7797
V Predictions Min            29.037271
Log Pis Mean                 -0.13807315
Log Pis Std                  1.8241053
Log Pis Max                  7.0278206
Log Pis Min                  -5.6182704
Policy mu Mean               -0.15897949
Policy mu Std                0.8731057
Policy mu Max                2.9353437
Policy mu Min                -2.4176414
Policy log std Mean          -0.48221436
Policy log std Std           0.18625838
Policy log std Max           0.14096254
Policy log std Min           -1.1116651
Z mean eval                  0.17141536
Z variance eval              0.007661416
total_rewards                [3294.8603908  1082.91197193 1126.20895946  835.57957919  889.10815925
  968.57582549 1394.47662094 1094.24561766 3280.6412335  1169.09997202]
total_rewards_mean           1513.5708330241437
total_rewards_std            899.2424109062966
total_rewards_max            3294.8603907956813
total_rewards_min            835.5795791931386
Number of train steps total  1568000
Number of env steps total    1889247
Number of rollouts total     0
Train Time (s)               146.89620089903474
(Previous) Eval Time (s)     8.380917106289417
Sample Time (s)              6.546474447939545
Epoch Time (s)               161.8235924532637
Total Train Time (s)         64536.75142947957
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:25:17.991524 UTC | [2020_01_10_09_29_40] Iteration #391 | Epoch Duration: 161.90724444389343
2020-01-11 03:25:17.991702 UTC | [2020_01_10_09_29_40] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17154983
Z variance train             0.007658801
KL Divergence                10.453486
KL Loss                      1.0453486
QF Loss                      54.95857
VF Loss                      21.80069
Policy Loss                  -1469.9015
Q Predictions Mean           1471.1597
Q Predictions Std            341.4841
Q Predictions Max            1802.1877
Q Predictions Min            28.084044
V Predictions Mean           1471.7168
V Predictions Std            342.33597
V Predictions Max            1806.032
V Predictions Min            25.466393
Log Pis Mean                 -0.3708021
Log Pis Std                  1.8873314
Log Pis Max                  6.4993787
Log Pis Min                  -5.7678127
Policy mu Mean               -0.10659414
Policy mu Std                0.8558988
Policy mu Max                1.6891477
Policy mu Min                -2.5382588
Policy log std Mean          -0.48369896
Policy log std Std           0.17679586
Policy log std Max           0.10282689
Policy log std Min           -1.012329
Z mean eval                  0.15641214
Z variance eval              0.0105313985
total_rewards                [1110.50420287 1218.89615711 1472.14677058 1395.91810679 1146.54436025
  809.81154625  786.78333257 1108.7033255   782.84217369 1101.45465398]
total_rewards_mean           1093.360462958264
total_rewards_std            229.13181627911553
total_rewards_max            1472.146770581054
total_rewards_min            782.8421736852432
Number of train steps total  1572000
Number of env steps total    1896595
Number of rollouts total     0
Train Time (s)               146.45485008414835
(Previous) Eval Time (s)     6.941642849706113
Sample Time (s)              6.415966019965708
Epoch Time (s)               159.81245895382017
Total Train Time (s)         64696.65195644833
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:27:57.894607 UTC | [2020_01_10_09_29_40] Iteration #392 | Epoch Duration: 159.90279173851013
2020-01-11 03:27:57.894737 UTC | [2020_01_10_09_29_40] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15553086
Z variance train             0.01052799
KL Divergence                10.087366
KL Loss                      1.0087366
QF Loss                      40.36544
VF Loss                      16.297298
Policy Loss                  -1495.272
Q Predictions Mean           1495.8259
Q Predictions Std            344.2518
Q Predictions Max            1795.756
Q Predictions Min            62.79797
V Predictions Mean           1496.1588
V Predictions Std            344.9673
V Predictions Max            1798.9457
V Predictions Min            71.106415
Log Pis Mean                 -0.24962105
Log Pis Std                  1.8913059
Log Pis Max                  7.32628
Log Pis Min                  -4.7430525
Policy mu Mean               -0.11246226
Policy mu Std                0.8948486
Policy mu Max                2.0656133
Policy mu Min                -2.6129837
Policy log std Mean          -0.49321875
Policy log std Std           0.17726812
Policy log std Max           0.21189669
Policy log std Min           -1.0695949
Z mean eval                  0.09715859
Z variance eval              0.012515431
total_rewards                [3280.86094839 3309.50137448 3307.77472295 3304.96917621  750.55071568
 1174.68266991 1240.72071626  765.56282032 3309.22854348 3307.65611071]
total_rewards_mean           2375.1507798387515
total_rewards_std            1145.770181721972
total_rewards_max            3309.5013744831413
total_rewards_min            750.5507156819598
Number of train steps total  1576000
Number of env steps total    1904450
Number of rollouts total     0
Train Time (s)               145.50076536508277
(Previous) Eval Time (s)     13.405038959346712
Sample Time (s)              6.44585106568411
Epoch Time (s)               165.3516553901136
Total Train Time (s)         64862.08314107312
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:30:43.329274 UTC | [2020_01_10_09_29_40] Iteration #393 | Epoch Duration: 165.4344310760498
2020-01-11 03:30:43.329440 UTC | [2020_01_10_09_29_40] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.096482955
Z variance train             0.012523323
KL Divergence                8.59839
KL Loss                      0.85983896
QF Loss                      237.79773
VF Loss                      22.578812
Policy Loss                  -1485.5234
Q Predictions Mean           1485.5999
Q Predictions Std            342.9069
Q Predictions Max            1790.0128
Q Predictions Min            34.09904
V Predictions Mean           1484.1282
V Predictions Std            343.7843
V Predictions Max            1787.3765
V Predictions Min            37.121876
Log Pis Mean                 -0.385065
Log Pis Std                  1.9588811
Log Pis Max                  6.3605285
Log Pis Min                  -8.474643
Policy mu Mean               -0.07476259
Policy mu Std                0.854367
Policy mu Max                1.7785698
Policy mu Min                -2.3885648
Policy log std Mean          -0.4798347
Policy log std Std           0.17987213
Policy log std Max           0.20361674
Policy log std Min           -1.082558
Z mean eval                  0.08196052
Z variance eval              0.0096455375
total_rewards                [3264.03086269 3244.62709619 3291.00739138 3269.80873174 3266.33483817
 3310.34559058 3259.30575183 3303.52128793 3295.17798633 3323.38344039]
total_rewards_mean           3282.754297723688
total_rewards_std            24.201254722546455
total_rewards_max            3323.3834403890323
total_rewards_min            3244.6270961948508
Number of train steps total  1580000
Number of env steps total    1913436
Number of rollouts total     0
Train Time (s)               145.63041837513447
(Previous) Eval Time (s)     21.99506806069985
Sample Time (s)              5.925227834377438
Epoch Time (s)               173.55071427021176
Total Train Time (s)         65035.714055040386
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:33:36.964813 UTC | [2020_01_10_09_29_40] Iteration #394 | Epoch Duration: 173.6351900100708
2020-01-11 03:33:36.965082 UTC | [2020_01_10_09_29_40] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.081082754
Z variance train             0.009647196
KL Divergence                9.712612
KL Loss                      0.9712612
QF Loss                      41.91009
VF Loss                      32.666405
Policy Loss                  -1482.037
Q Predictions Mean           1482.0287
Q Predictions Std            330.8944
Q Predictions Max            1788.5308
Q Predictions Min            75.33355
V Predictions Mean           1480.9739
V Predictions Std            330.37305
V Predictions Max            1790.2203
V Predictions Min            84.2079
Log Pis Mean                 0.10603027
Log Pis Std                  1.9741805
Log Pis Max                  5.163555
Log Pis Min                  -5.12895
Policy mu Mean               -0.1619486
Policy mu Std                0.931889
Policy mu Max                1.9314389
Policy mu Min                -2.6911082
Policy log std Mean          -0.48281136
Policy log std Std           0.21030512
Policy log std Max           0.28754538
Policy log std Min           -1.2250726
Z mean eval                  0.1682586
Z variance eval              0.0063440213
total_rewards                [3235.64452513 3294.41257956 3221.68001831  607.06077579 3226.15417472
 1251.76547596 3236.26364374  980.0944557  3231.2855298  3253.68251811]
total_rewards_mean           2553.8043696809277
total_rewards_std            1062.4386222596006
total_rewards_max            3294.4125795568825
total_rewards_min            607.0607757854481
Number of train steps total  1584000
Number of env steps total    1921108
Number of rollouts total     0
Train Time (s)               147.11258751293644
(Previous) Eval Time (s)     17.316791997291148
Sample Time (s)              6.119239539839327
Epoch Time (s)               170.54861905006692
Total Train Time (s)         65206.517560415436
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:36:27.771667 UTC | [2020_01_10_09_29_40] Iteration #395 | Epoch Duration: 170.80642914772034
2020-01-11 03:36:27.771863 UTC | [2020_01_10_09_29_40] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16787127
Z variance train             0.0063442215
KL Divergence                10.416021
KL Loss                      1.0416021
QF Loss                      30.315182
VF Loss                      17.790733
Policy Loss                  -1515.5247
Q Predictions Mean           1516.3702
Q Predictions Std            307.487
Q Predictions Max            1802.2004
Q Predictions Min            27.310514
V Predictions Mean           1516.2506
V Predictions Std            306.62436
V Predictions Max            1803.5327
V Predictions Min            28.700151
Log Pis Mean                 -0.3317518
Log Pis Std                  1.7837383
Log Pis Max                  5.9056864
Log Pis Min                  -4.316343
Policy mu Mean               0.019298373
Policy mu Std                0.838527
Policy mu Max                2.2703238
Policy mu Min                -2.5232453
Policy log std Mean          -0.47441244
Policy log std Std           0.18277664
Policy log std Max           0.34278387
Policy log std Min           -0.9993251
Z mean eval                  0.29457912
Z variance eval              0.0054226415
total_rewards                [3249.29013992 3256.92495376 3268.93171244 3299.3270644  3285.56227463
 3288.64819511 3302.02816804  943.18156689 3274.88633898 3268.79982323]
total_rewards_mean           3043.7580237383145
total_rewards_std            700.3807418363057
total_rewards_max            3302.028168041664
total_rewards_min            943.1815668937556
Number of train steps total  1588000
Number of env steps total    1928805
Number of rollouts total     0
Train Time (s)               145.607186045032
(Previous) Eval Time (s)     17.26962073519826
Sample Time (s)              6.734675601590425
Epoch Time (s)               169.61148238182068
Total Train Time (s)         65376.205847238656
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:39:17.463009 UTC | [2020_01_10_09_29_40] Iteration #396 | Epoch Duration: 169.69097423553467
2020-01-11 03:39:17.463200 UTC | [2020_01_10_09_29_40] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.29468203
Z variance train             0.0054123825
KL Divergence                11.235022
KL Loss                      1.1235021
QF Loss                      37.19827
VF Loss                      23.158693
Policy Loss                  -1497.552
Q Predictions Mean           1501.1594
Q Predictions Std            317.14337
Q Predictions Max            1822.4525
Q Predictions Min            116.78512
V Predictions Mean           1500.0874
V Predictions Std            316.6265
V Predictions Max            1822.1171
V Predictions Min            118.993
Log Pis Mean                 -0.348068
Log Pis Std                  1.757409
Log Pis Max                  5.526893
Log Pis Min                  -5.65386
Policy mu Mean               -0.08044158
Policy mu Std                0.82933146
Policy mu Max                2.0626736
Policy mu Min                -2.463237
Policy log std Mean          -0.48623514
Policy log std Std           0.1646531
Policy log std Max           -0.021278143
Policy log std Min           -0.9680778
Z mean eval                  0.13152602
Z variance eval              0.00588687
total_rewards                [3270.44998704 3281.10435576  847.86332638 3280.3828736  3282.89947937
 3267.65687593 3290.72597643 3265.14061562 3294.39033696 3287.80542628]
total_rewards_mean           3036.8419253376633
total_rewards_std            729.7182668263251
total_rewards_max            3294.390336963216
total_rewards_min            847.8633263836814
Number of train steps total  1592000
Number of env steps total    1936720
Number of rollouts total     0
Train Time (s)               146.33411758672446
(Previous) Eval Time (s)     17.462870799936354
Sample Time (s)              5.655669190920889
Epoch Time (s)               169.4526575775817
Total Train Time (s)         65545.73816706473
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:42:07.002519 UTC | [2020_01_10_09_29_40] Iteration #397 | Epoch Duration: 169.5391755104065
2020-01-11 03:42:07.002789 UTC | [2020_01_10_09_29_40] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13100794
Z variance train             0.0058826134
KL Divergence                11.19967
KL Loss                      1.119967
QF Loss                      66.50046
VF Loss                      28.317272
Policy Loss                  -1476.5582
Q Predictions Mean           1478.7502
Q Predictions Std            343.44788
Q Predictions Max            1806.6855
Q Predictions Min            22.051542
V Predictions Mean           1475.2292
V Predictions Std            343.098
V Predictions Max            1804.6583
V Predictions Min            18.705132
Log Pis Mean                 -0.09027018
Log Pis Std                  1.9748305
Log Pis Max                  6.4053497
Log Pis Min                  -5.5067487
Policy mu Mean               -0.061518848
Policy mu Std                0.8970144
Policy mu Max                1.9501313
Policy mu Min                -2.7058825
Policy log std Mean          -0.49565634
Policy log std Std           0.17982155
Policy log std Max           0.111784756
Policy log std Min           -1.2533234
Z mean eval                  0.1769314
Z variance eval              0.011698654
total_rewards                [ 883.1630768  3271.119224   1247.80258318 1231.79825998 3264.95073904
 3280.9427904  3306.23126682 3251.93549479 1007.79817567 1021.92127704]
total_rewards_mean           2176.7662887735446
total_rewards_std            1102.820942489212
total_rewards_max            3306.231266821943
total_rewards_min            883.1630768038202
Number of train steps total  1596000
Number of env steps total    1944905
Number of rollouts total     0
Train Time (s)               146.95134628983214
(Previous) Eval Time (s)     14.379285758826882
Sample Time (s)              6.554717291146517
Epoch Time (s)               167.88534933980554
Total Train Time (s)         65713.70592076005
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:44:54.972773 UTC | [2020_01_10_09_29_40] Iteration #398 | Epoch Duration: 167.96982049942017
2020-01-11 03:44:54.972897 UTC | [2020_01_10_09_29_40] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17796561
Z variance train             0.011735469
KL Divergence                9.663328
KL Loss                      0.96633285
QF Loss                      70.22488
VF Loss                      36.880573
Policy Loss                  -1442.0605
Q Predictions Mean           1442.8513
Q Predictions Std            384.58167
Q Predictions Max            1777.9377
Q Predictions Min            99.809875
V Predictions Mean           1446.0762
V Predictions Std            385.18378
V Predictions Max            1781.4752
V Predictions Min            106.42057
Log Pis Mean                 -0.07335425
Log Pis Std                  1.9687552
Log Pis Max                  5.7917056
Log Pis Min                  -7.20235
Policy mu Mean               -0.076242484
Policy mu Std                0.8909986
Policy mu Max                1.971134
Policy mu Min                -2.6658158
Policy log std Mean          -0.49686113
Policy log std Std           0.18087493
Policy log std Max           0.07832253
Policy log std Min           -1.240358
Z mean eval                  0.11547989
Z variance eval              0.008674744
total_rewards                [3198.01436598 3249.65489962 3271.36006761 1058.36761357 3275.25398006
 3256.32378962 2858.41285841 3161.03975377 3295.28319998 3248.08550803]
total_rewards_mean           2987.179603664041
total_rewards_std            654.1905066450774
total_rewards_max            3295.2831999844384
total_rewards_min            1058.367613569988
Number of train steps total  1600000
Number of env steps total    1952733
Number of rollouts total     0
Train Time (s)               146.4356561298482
(Previous) Eval Time (s)     17.06440500775352
Sample Time (s)              6.36578074702993
Epoch Time (s)               169.86584188463166
Total Train Time (s)         65883.65010196669
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:47:44.921244 UTC | [2020_01_10_09_29_40] Iteration #399 | Epoch Duration: 169.9482421875
2020-01-11 03:47:44.921416 UTC | [2020_01_10_09_29_40] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11680591
Z variance train             0.008680875
KL Divergence                10.027582
KL Loss                      1.0027583
QF Loss                      61.223244
VF Loss                      29.007439
Policy Loss                  -1465.5426
Q Predictions Mean           1467.1025
Q Predictions Std            352.40344
Q Predictions Max            1787.792
Q Predictions Min            95.11716
V Predictions Mean           1462.5897
V Predictions Std            351.6488
V Predictions Max            1787.1969
V Predictions Min            83.00973
Log Pis Mean                 -0.034271814
Log Pis Std                  2.1153367
Log Pis Max                  6.2374105
Log Pis Min                  -4.795291
Policy mu Mean               -0.13103576
Policy mu Std                0.885948
Policy mu Max                1.8972414
Policy mu Min                -2.540649
Policy log std Mean          -0.4808186
Policy log std Std           0.1957604
Policy log std Max           0.31391066
Policy log std Min           -1.2348125
Z mean eval                  0.20417902
Z variance eval              0.008304802
total_rewards                [3258.12910224 3273.51231361  931.26052373 3274.69832048 1016.81797714
 3274.0427975  3277.27921041 3284.13936497 3279.12081883 3290.92671299]
total_rewards_mean           2815.992714191055
total_rewards_std            921.209591164088
total_rewards_max            3290.926712992548
total_rewards_min            931.2605237253813
Number of train steps total  1604000
Number of env steps total    1960675
Number of rollouts total     0
Train Time (s)               145.37546980567276
(Previous) Eval Time (s)     18.420976154971868
Sample Time (s)              6.754406769759953
Epoch Time (s)               170.55085273040459
Total Train Time (s)         66054.28059254307
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:50:35.555606 UTC | [2020_01_10_09_29_40] Iteration #400 | Epoch Duration: 170.63406538963318
2020-01-11 03:50:35.555751 UTC | [2020_01_10_09_29_40] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20407215
Z variance train             0.00830093
KL Divergence                9.868427
KL Loss                      0.98684275
QF Loss                      32.67296
VF Loss                      13.619875
Policy Loss                  -1491.1665
Q Predictions Mean           1490.1316
Q Predictions Std            341.5985
Q Predictions Max            1807.4683
Q Predictions Min            41.974716
V Predictions Mean           1491.3042
V Predictions Std            339.96182
V Predictions Max            1808.19
V Predictions Min            55.080517
Log Pis Mean                 -0.4013104
Log Pis Std                  1.8422558
Log Pis Max                  5.018776
Log Pis Min                  -5.3169127
Policy mu Mean               -0.07078532
Policy mu Std                0.8144329
Policy mu Max                1.9196762
Policy mu Min                -2.6434493
Policy log std Mean          -0.47597018
Policy log std Std           0.17668426
Policy log std Max           0.12458637
Policy log std Min           -0.9621505
Z mean eval                  0.06603608
Z variance eval              0.012073865
total_rewards                [3295.80873582 1041.01169552 3339.27522507 3327.97679012 1555.97018202
 3327.43771052 3281.805808   3315.46318144 3303.30230241 3336.03128103]
total_rewards_mean           2912.4082911944697
total_rewards_std            815.3140360737368
total_rewards_max            3339.2752250716376
total_rewards_min            1041.0116955223873
Number of train steps total  1608000
Number of env steps total    1970638
Number of rollouts total     0
Train Time (s)               146.08647965174168
(Previous) Eval Time (s)     18.90445993002504
Sample Time (s)              6.667233822867274
Epoch Time (s)               171.658173404634
Total Train Time (s)         66226.03117753332
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:53:27.308578 UTC | [2020_01_10_09_29_40] Iteration #401 | Epoch Duration: 171.75273323059082
2020-01-11 03:53:27.308705 UTC | [2020_01_10_09_29_40] Iteration #401 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06605799
Z variance train             0.012070656
KL Divergence                8.80982
KL Loss                      0.88098204
QF Loss                      49.22409
VF Loss                      12.702672
Policy Loss                  -1472.6425
Q Predictions Mean           1471.675
Q Predictions Std            377.09683
Q Predictions Max            1821.6674
Q Predictions Min            74.25052
V Predictions Mean           1473.3625
V Predictions Std            375.9235
V Predictions Max            1824.3723
V Predictions Min            91.607155
Log Pis Mean                 -0.34997237
Log Pis Std                  1.7307454
Log Pis Max                  5.5332136
Log Pis Min                  -3.713347
Policy mu Mean               -0.09938729
Policy mu Std                0.84561604
Policy mu Max                1.6899095
Policy mu Min                -2.6290412
Policy log std Mean          -0.480031
Policy log std Std           0.1721451
Policy log std Max           0.048968583
Policy log std Min           -1.2234571
Z mean eval                  0.065637395
Z variance eval              0.010123923
total_rewards                [3313.4357592  3290.92327436 3313.71760659 3307.00269482 3314.4783722
  991.76650975 3326.59464348  916.56373659 1167.31201955 3334.47015638]
total_rewards_mean           2627.6264772933755
total_rewards_std            1050.657506319844
total_rewards_max            3334.4701563797985
total_rewards_min            916.5637365893664
Number of train steps total  1612000
Number of env steps total    1979760
Number of rollouts total     0
Train Time (s)               145.09941385220736
(Previous) Eval Time (s)     16.09459853777662
Sample Time (s)              6.602204983122647
Epoch Time (s)               167.79621737310663
Total Train Time (s)         66393.91399269085
Epoch                        402
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:56:15.199380 UTC | [2020_01_10_09_29_40] Iteration #402 | Epoch Duration: 167.890540599823
2020-01-11 03:56:15.199669 UTC | [2020_01_10_09_29_40] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06569526
Z variance train             0.010133436
KL Divergence                9.159616
KL Loss                      0.9159617
QF Loss                      50.724747
VF Loss                      17.814486
Policy Loss                  -1454.5695
Q Predictions Mean           1455.3977
Q Predictions Std            364.14694
Q Predictions Max            1789.6533
Q Predictions Min            9.14874
V Predictions Mean           1454.2083
V Predictions Std            364.63107
V Predictions Max            1796.9556
V Predictions Min            6.8890996
Log Pis Mean                 -0.1462243
Log Pis Std                  1.8017716
Log Pis Max                  7.1516685
Log Pis Min                  -3.626874
Policy mu Mean               -0.17604661
Policy mu Std                0.88676435
Policy mu Max                2.2155635
Policy mu Min                -2.8440135
Policy log std Mean          -0.47381595
Policy log std Std           0.20036666
Policy log std Max           0.13652793
Policy log std Min           -1.2284611
Z mean eval                  0.17481682
Z variance eval              0.010647675
total_rewards                [3286.54517848 3287.81101655 3300.37892285 3297.68714967 3304.02754669
 3293.64951657 3329.55088365 3308.38062565 3289.72574267 3290.03890937]
total_rewards_mean           3298.779549215536
total_rewards_std            12.349188114244036
total_rewards_max            3329.550883651719
total_rewards_min            3286.5451784798797
Number of train steps total  1616000
Number of env steps total    1989576
Number of rollouts total     0
Train Time (s)               147.037168181967
(Previous) Eval Time (s)     18.428126368671656
Sample Time (s)              6.3937544580549
Epoch Time (s)               171.85904900869355
Total Train Time (s)         66565.85675036814
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:59:07.152320 UTC | [2020_01_10_09_29_40] Iteration #403 | Epoch Duration: 171.95241808891296
2020-01-11 03:59:07.152640 UTC | [2020_01_10_09_29_40] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17582974
Z variance train             0.010620078
KL Divergence                9.335456
KL Loss                      0.9335456
QF Loss                      70.31905
VF Loss                      33.421402
Policy Loss                  -1505.7197
Q Predictions Mean           1502.8839
Q Predictions Std            354.06287
Q Predictions Max            1819.6062
Q Predictions Min            47.062557
V Predictions Mean           1501.9604
V Predictions Std            352.5345
V Predictions Max            1817.7467
V Predictions Min            59.268517
Log Pis Mean                 0.10037799
Log Pis Std                  2.1682487
Log Pis Max                  8.876438
Log Pis Min                  -5.089423
Policy mu Mean               -0.12955396
Policy mu Std                0.92878807
Policy mu Max                2.7522702
Policy mu Min                -2.7339427
Policy log std Mean          -0.49206483
Policy log std Std           0.2020414
Policy log std Max           0.2816429
Policy log std Min           -1.5047758
Z mean eval                  0.09984101
Z variance eval              0.013108453
total_rewards                [ 990.29113657 3302.62262704  433.3339327  3328.27382347 3344.84754329
 3344.70696552 3312.04120413 3312.93652694 3316.18067903  207.15675936]
total_rewards_mean           2489.239119804614
total_rewards_std            1286.4784140710728
total_rewards_max            3344.8475432923565
total_rewards_min            207.15675936293974
Number of train steps total  1620000
Number of env steps total    1998124
Number of rollouts total     0
Train Time (s)               145.96011507418007
(Previous) Eval Time (s)     16.53306601429358
Sample Time (s)              6.803909805603325
Epoch Time (s)               169.29709089407697
Total Train Time (s)         66735.26457325974
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:01:56.562455 UTC | [2020_01_10_09_29_40] Iteration #404 | Epoch Duration: 169.40964651107788
2020-01-11 04:01:56.562603 UTC | [2020_01_10_09_29_40] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.099997744
Z variance train             0.013096318
KL Divergence                8.562231
KL Loss                      0.8562231
QF Loss                      51.142914
VF Loss                      27.260721
Policy Loss                  -1515.8434
Q Predictions Mean           1514.6655
Q Predictions Std            298.42172
Q Predictions Max            1807.7856
Q Predictions Min            18.48747
V Predictions Mean           1515.6794
V Predictions Std            300.03238
V Predictions Max            1809.5447
V Predictions Min            25.569036
Log Pis Mean                 -0.51486677
Log Pis Std                  1.8644146
Log Pis Max                  7.0469847
Log Pis Min                  -4.6050897
Policy mu Mean               -0.06496789
Policy mu Std                0.8359011
Policy mu Max                1.5455588
Policy mu Min                -2.6674883
Policy log std Mean          -0.4804089
Policy log std Std           0.17337885
Policy log std Max           0.29572853
Policy log std Min           -1.1523513
Z mean eval                  0.060248006
Z variance eval              0.010105652
total_rewards                [3347.31644317 3350.37280527 3350.29033956 3373.13848651 3336.95130704
 3331.70736947 3315.82674377 3313.77385985 3364.82438321 1043.79059428]
total_rewards_mean           3112.7992332114286
total_rewards_std            689.9063266419305
total_rewards_max            3373.138486506809
total_rewards_min            1043.7905942843902
Number of train steps total  1624000
Number of env steps total    2009038
Number of rollouts total     0
Train Time (s)               144.79118340741843
(Previous) Eval Time (s)     20.37104096543044
Sample Time (s)              7.368801369331777
Epoch Time (s)               172.53102574218065
Total Train Time (s)         66907.89523137081
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:04:49.200267 UTC | [2020_01_10_09_29_40] Iteration #405 | Epoch Duration: 172.63756394386292
2020-01-11 04:04:49.200396 UTC | [2020_01_10_09_29_40] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060806554
Z variance train             0.010090588
KL Divergence                9.158011
KL Loss                      0.91580117
QF Loss                      84.47814
VF Loss                      132.46567
Policy Loss                  -1530.1289
Q Predictions Mean           1527.6094
Q Predictions Std            296.4176
Q Predictions Max            1799.2533
Q Predictions Min            24.633362
V Predictions Mean           1519.7213
V Predictions Std            295.15146
V Predictions Max            1788.5757
V Predictions Min            32.546936
Log Pis Mean                 -0.32362726
Log Pis Std                  1.8807923
Log Pis Max                  5.401924
Log Pis Min                  -6.4972463
Policy mu Mean               -0.042476997
Policy mu Std                0.8539453
Policy mu Max                2.0812607
Policy mu Min                -2.6378875
Policy log std Mean          -0.46968472
Policy log std Std           0.18972819
Policy log std Max           0.24783158
Policy log std Min           -1.38516
Z mean eval                  0.14666948
Z variance eval              0.01431567
total_rewards                [3227.16664998 3231.71846256 3230.78271725  974.35997429 3294.53393641
 3247.74341765  820.504193   3172.50596193 3191.54372166 3200.54943021]
total_rewards_mean           2759.1408464936276
total_rewards_std            932.0215331437613
total_rewards_max            3294.533936413289
total_rewards_min            820.5041929957317
Number of train steps total  1628000
Number of env steps total    2018112
Number of rollouts total     0
Train Time (s)               146.2401622198522
(Previous) Eval Time (s)     18.653291708324105
Sample Time (s)              6.653130957391113
Epoch Time (s)               171.54658488556743
Total Train Time (s)         67079.51813946012
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:07:40.831245 UTC | [2020_01_10_09_29_40] Iteration #406 | Epoch Duration: 171.63075709342957
2020-01-11 04:07:40.831374 UTC | [2020_01_10_09_29_40] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14607866
Z variance train             0.01425647
KL Divergence                9.047075
KL Loss                      0.90470755
QF Loss                      223.16739
VF Loss                      457.55664
Policy Loss                  -1525.9237
Q Predictions Mean           1528.3767
Q Predictions Std            287.82062
Q Predictions Max            1795.8138
Q Predictions Min            146.08896
V Predictions Mean           1544.4263
V Predictions Std            288.41104
V Predictions Max            1820.6942
V Predictions Min            143.6916
Log Pis Mean                 -0.2939835
Log Pis Std                  1.7844052
Log Pis Max                  5.514018
Log Pis Min                  -5.0615444
Policy mu Mean               -0.1535775
Policy mu Std                0.8525538
Policy mu Max                2.061509
Policy mu Min                -2.6608489
Policy log std Mean          -0.47600505
Policy log std Std           0.17446451
Policy log std Max           0.18328282
Policy log std Min           -1.0350184
Z mean eval                  0.09830321
Z variance eval              0.014310738
total_rewards                [3267.70579922 1010.74440807  958.15694234 3241.66277419 1717.01246237
 3294.91435315 1001.67581248 1010.65187214  972.17374755  661.19828089]
total_rewards_mean           1713.589645239475
total_rewards_std            1047.5553439448222
total_rewards_max            3294.914353153552
total_rewards_min            661.1982808868495
Number of train steps total  1632000
Number of env steps total    2027148
Number of rollouts total     0
Train Time (s)               146.9753414900042
(Previous) Eval Time (s)     11.226448455359787
Sample Time (s)              6.586684414185584
Epoch Time (s)               164.78847435954958
Total Train Time (s)         67244.4066351899
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:10:25.722174 UTC | [2020_01_10_09_29_40] Iteration #407 | Epoch Duration: 164.8907127380371
2020-01-11 04:10:25.722300 UTC | [2020_01_10_09_29_40] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.097796805
Z variance train             0.014287107
KL Divergence                8.558654
KL Loss                      0.8558654
QF Loss                      78.85765
VF Loss                      52.046124
Policy Loss                  -1531.9448
Q Predictions Mean           1529.467
Q Predictions Std            312.5446
Q Predictions Max            1812.3811
Q Predictions Min            126.26084
V Predictions Mean           1534.2893
V Predictions Std            310.8247
V Predictions Max            1813.2421
V Predictions Min            146.06775
Log Pis Mean                 -0.20715304
Log Pis Std                  1.899138
Log Pis Max                  5.8387194
Log Pis Min                  -5.5601096
Policy mu Mean               -0.12842847
Policy mu Std                0.8753959
Policy mu Max                1.8555859
Policy mu Min                -2.6131794
Policy log std Mean          -0.47789177
Policy log std Std           0.18616092
Policy log std Max           0.41298538
Policy log std Min           -1.2726862
Z mean eval                  0.12141931
Z variance eval              0.016847823
total_rewards                [ 889.0410565   365.47221367 3290.18174535  398.69255065 3297.38731433
  392.87201276 3320.59338721 3299.09485955 3295.97134464 1443.50076261]
total_rewards_mean           1999.28072472773
total_rewards_std            1334.9749755997623
total_rewards_max            3320.5933872142336
total_rewards_min            365.47221366941227
Number of train steps total  1636000
Number of env steps total    2037580
Number of rollouts total     0
Train Time (s)               145.84345423290506
(Previous) Eval Time (s)     11.404338460415602
Sample Time (s)              6.932355644647032
Epoch Time (s)               164.1801483379677
Total Train Time (s)         67408.6687598289
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:13:09.986581 UTC | [2020_01_10_09_29_40] Iteration #408 | Epoch Duration: 164.26419496536255
2020-01-11 04:13:09.986698 UTC | [2020_01_10_09_29_40] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12070908
Z variance train             0.016754944
KL Divergence                8.650127
KL Loss                      0.86501276
QF Loss                      116.60904
VF Loss                      59.685577
Policy Loss                  -1512.3528
Q Predictions Mean           1509.346
Q Predictions Std            308.9241
Q Predictions Max            1788.0177
Q Predictions Min            61.324898
V Predictions Mean           1506.9784
V Predictions Std            308.06985
V Predictions Max            1784.1261
V Predictions Min            64.96732
Log Pis Mean                 -0.042488635
Log Pis Std                  1.9315785
Log Pis Max                  5.8808584
Log Pis Min                  -6.396622
Policy mu Mean               -0.073518455
Policy mu Std                0.8916786
Policy mu Max                1.8930922
Policy mu Min                -2.6659966
Policy log std Mean          -0.4637008
Policy log std Std           0.19323222
Policy log std Max           0.37494966
Policy log std Min           -1.2461542
Z mean eval                  0.072384864
Z variance eval              0.020156864
total_rewards                [ 908.47158152  911.06906604 3272.56392065  902.68606005 2188.25476512
 1404.92024893  965.54678435 1211.1083076  3251.69170526 3259.52049002]
total_rewards_mean           1827.5832929547028
total_rewards_std            1006.9048509066602
total_rewards_max            3272.563920650737
total_rewards_min            902.6860600546053
Number of train steps total  1640000
Number of env steps total    2048520
Number of rollouts total     0
Train Time (s)               145.40398440416902
(Previous) Eval Time (s)     10.36289122980088
Sample Time (s)              5.980616746004671
Epoch Time (s)               161.74749237997457
Total Train Time (s)         67570.50453592092
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:15:51.826145 UTC | [2020_01_10_09_29_40] Iteration #409 | Epoch Duration: 161.8393518924713
2020-01-11 04:15:51.826304 UTC | [2020_01_10_09_29_40] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07405935
Z variance train             0.020246854
KL Divergence                7.681529
KL Loss                      0.7681529
QF Loss                      161.17459
VF Loss                      162.00969
Policy Loss                  -1533.8043
Q Predictions Mean           1537.8877
Q Predictions Std            303.2075
Q Predictions Max            1807.0352
Q Predictions Min            35.06893
V Predictions Mean           1541.579
V Predictions Std            307.0876
V Predictions Max            1816.8655
V Predictions Min            32.219357
Log Pis Mean                 -0.13047592
Log Pis Std                  1.8373573
Log Pis Max                  5.916568
Log Pis Min                  -4.22951
Policy mu Mean               -0.02850622
Policy mu Std                0.9085944
Policy mu Max                1.9873906
Policy mu Min                -2.7446566
Policy log std Mean          -0.5051853
Policy log std Std           0.1677356
Policy log std Max           0.009868145
Policy log std Min           -1.0533838
Z mean eval                  0.096302524
Z variance eval              0.026139688
total_rewards                [1686.93691827 1186.01182302  852.09703472 2422.38082438  919.68717077
 1026.07803937 1026.42633241 1086.38683876 1030.71432034 1373.92658421]
total_rewards_mean           1261.064588624588
total_rewards_std            450.1148455486354
total_rewards_max            2422.380824378384
total_rewards_min            852.097034715906
Number of train steps total  1644000
Number of env steps total    2057371
Number of rollouts total     0
Train Time (s)               144.8847322179936
(Previous) Eval Time (s)     6.853901208844036
Sample Time (s)              6.559127249754965
Epoch Time (s)               158.2977606765926
Total Train Time (s)         67728.90976308752
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:18:30.235439 UTC | [2020_01_10_09_29_40] Iteration #410 | Epoch Duration: 158.40901947021484
2020-01-11 04:18:30.235597 UTC | [2020_01_10_09_29_40] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09533014
Z variance train             0.026139382
KL Divergence                7.7978697
KL Loss                      0.779787
QF Loss                      88.66724
VF Loss                      37.224472
Policy Loss                  -1524.9153
Q Predictions Mean           1521.8037
Q Predictions Std            299.6571
Q Predictions Max            1811.3881
Q Predictions Min            62.860462
V Predictions Mean           1526.4283
V Predictions Std            301.55115
V Predictions Max            1821.6346
V Predictions Min            57.34914
Log Pis Mean                 -0.63503087
Log Pis Std                  1.7198714
Log Pis Max                  5.274201
Log Pis Min                  -5.8282776
Policy mu Mean               -0.16139692
Policy mu Std                0.7725417
Policy mu Max                1.7627723
Policy mu Min                -2.6566331
Policy log std Mean          -0.459443
Policy log std Std           0.1697577
Policy log std Max           0.45016897
Policy log std Min           -1.2161995
Z mean eval                  0.08108726
Z variance eval              0.02638643
total_rewards                [2010.74582353 3256.97318486 3271.28297548 3302.62323221 2616.04882175
 3313.17869929 3294.6283742   792.89773304 3277.04408883 3114.16168669]
total_rewards_mean           2824.9584619887573
total_rewards_std            787.1995258564248
total_rewards_max            3313.178699291418
total_rewards_min            792.8977330440488
Number of train steps total  1648000
Number of env steps total    2066941
Number of rollouts total     0
Train Time (s)               145.39750969875604
(Previous) Eval Time (s)     15.903260750696063
Sample Time (s)              6.053301393054426
Epoch Time (s)               167.35407184250653
Total Train Time (s)         67896.34441390587
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:21:17.675920 UTC | [2020_01_10_09_29_40] Iteration #411 | Epoch Duration: 167.4402060508728
2020-01-11 04:21:17.676089 UTC | [2020_01_10_09_29_40] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08090517
Z variance train             0.026391516
KL Divergence                7.1936264
KL Loss                      0.7193627
QF Loss                      59.172264
VF Loss                      23.838486
Policy Loss                  -1521.2335
Q Predictions Mean           1518.9744
Q Predictions Std            326.6065
Q Predictions Max            1802.5007
Q Predictions Min            56.71811
V Predictions Mean           1518.2253
V Predictions Std            327.35748
V Predictions Max            1804.0928
V Predictions Min            48.35944
Log Pis Mean                 -0.23734093
Log Pis Std                  1.9555839
Log Pis Max                  6.356467
Log Pis Min                  -5.112665
Policy mu Mean               -0.039216146
Policy mu Std                0.8958753
Policy mu Max                2.1845758
Policy mu Min                -2.582654
Policy log std Mean          -0.48673868
Policy log std Std           0.18338309
Policy log std Max           0.43094254
Policy log std Min           -1.1088803
Z mean eval                  0.038900822
Z variance eval              0.023856584
total_rewards                [3287.95540518 3298.39772392 3323.32302262 2588.03316829 3308.00083698
  913.69099255 3295.62711779 3254.30716076 3277.24188699 3250.88952823]
total_rewards_mean           2979.7466843292477
total_rewards_std            719.8290026565215
total_rewards_max            3323.3230226154883
total_rewards_min            913.6909925475562
Number of train steps total  1652000
Number of env steps total    2075116
Number of rollouts total     0
Train Time (s)               145.13713203696534
(Previous) Eval Time (s)     16.86733880499378
Sample Time (s)              6.523960695602
Epoch Time (s)               168.52843153756112
Total Train Time (s)         68064.95229527447
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:24:06.287843 UTC | [2020_01_10_09_29_40] Iteration #412 | Epoch Duration: 168.61163187026978
2020-01-11 04:24:06.287998 UTC | [2020_01_10_09_29_40] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03708864
Z variance train             0.023847802
KL Divergence                7.9270144
KL Loss                      0.7927014
QF Loss                      98.734085
VF Loss                      39.155907
Policy Loss                  -1550.9622
Q Predictions Mean           1550.747
Q Predictions Std            272.2374
Q Predictions Max            1810.6542
Q Predictions Min            100.61166
V Predictions Mean           1552.4507
V Predictions Std            272.41385
V Predictions Max            1815.6931
V Predictions Min            107.59383
Log Pis Mean                 -0.28294605
Log Pis Std                  1.5833651
Log Pis Max                  5.4290376
Log Pis Min                  -4.5942183
Policy mu Mean               0.015857043
Policy mu Std                0.8336992
Policy mu Max                2.1044526
Policy mu Min                -2.7239313
Policy log std Mean          -0.46857467
Policy log std Std           0.16593829
Policy log std Max           0.24956617
Policy log std Min           -1.1561971
Z mean eval                  0.08322509
Z variance eval              0.022000639
total_rewards                [3393.95968264 3341.00954466 3300.83838812 3314.93077486 3335.44282882
 3334.90863723 3042.97158833 2313.87429951 3342.83089743 2476.44404212]
total_rewards_mean           3119.7210683721087
total_rewards_std            375.0720082786013
total_rewards_max            3393.9596826406982
total_rewards_min            2313.8742995066964
Number of train steps total  1656000
Number of env steps total    2083639
Number of rollouts total     0
Train Time (s)               147.00070823682472
(Previous) Eval Time (s)     20.467956473119557
Sample Time (s)              6.485295868944377
Epoch Time (s)               173.95396057888865
Total Train Time (s)         68238.99578746548
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:27:00.335566 UTC | [2020_01_10_09_29_40] Iteration #413 | Epoch Duration: 174.04744172096252
2020-01-11 04:27:00.335747 UTC | [2020_01_10_09_29_40] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08323153
Z variance train             0.0219866
KL Divergence                7.4132276
KL Loss                      0.74132276
QF Loss                      37.621475
VF Loss                      18.034258
Policy Loss                  -1535.49
Q Predictions Mean           1536.6128
Q Predictions Std            308.1772
Q Predictions Max            1821.5256
Q Predictions Min            62.86918
V Predictions Mean           1537.0051
V Predictions Std            307.65936
V Predictions Max            1823.9675
V Predictions Min            60.922108
Log Pis Mean                 -0.32611227
Log Pis Std                  1.8530715
Log Pis Max                  6.9011564
Log Pis Min                  -5.911868
Policy mu Mean               -0.11717189
Policy mu Std                0.8406652
Policy mu Max                2.1432981
Policy mu Min                -2.4427104
Policy log std Mean          -0.49264917
Policy log std Std           0.17893137
Policy log std Max           0.05913484
Policy log std Min           -1.3593106
Z mean eval                  0.09038234
Z variance eval              0.01613493
total_rewards                [3349.67171664 3333.98832953 1537.14968647  977.36316524 3308.0371646
 3328.2771781  3327.27696243 3299.26046879 3323.52084549 3314.74096354]
total_rewards_mean           2909.9286480841683
total_rewards_std            835.8665135519799
total_rewards_max            3349.6717166391413
total_rewards_min            977.3631652429226
Number of train steps total  1660000
Number of env steps total    2092255
Number of rollouts total     0
Train Time (s)               145.82077202992514
(Previous) Eval Time (s)     19.337354534305632
Sample Time (s)              6.688506596721709
Epoch Time (s)               171.84663316095248
Total Train Time (s)         68410.91748812143
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:29:52.260268 UTC | [2020_01_10_09_29_40] Iteration #414 | Epoch Duration: 171.92440247535706
2020-01-11 04:29:52.260406 UTC | [2020_01_10_09_29_40] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09042255
Z variance train             0.016165195
KL Divergence                8.365398
KL Loss                      0.83653986
QF Loss                      39.410057
VF Loss                      31.051296
Policy Loss                  -1510.2533
Q Predictions Mean           1510.397
Q Predictions Std            299.34375
Q Predictions Max            1814.8191
Q Predictions Min            24.387596
V Predictions Mean           1509.2013
V Predictions Std            300.02716
V Predictions Max            1809.9578
V Predictions Min            17.73604
Log Pis Mean                 -0.2741406
Log Pis Std                  1.880305
Log Pis Max                  6.122123
Log Pis Min                  -4.885728
Policy mu Mean               -0.18459189
Policy mu Std                0.8812014
Policy mu Max                1.9556097
Policy mu Min                -2.668916
Policy log std Mean          -0.46905884
Policy log std Std           0.17478973
Policy log std Max           0.09536588
Policy log std Min           -1.2610507
Z mean eval                  0.08228452
Z variance eval              0.01639836
total_rewards                [ 377.51207681  948.00790967  385.90984978  153.52890859  390.56246413
  390.74684707  383.44766113  391.10659104 3277.76403073 1410.06571947]
total_rewards_mean           810.865205842508
total_rewards_std            893.0816910016005
total_rewards_max            3277.764030726272
total_rewards_min            153.52890859250775
Number of train steps total  1664000
Number of env steps total    2100950
Number of rollouts total     0
Train Time (s)               144.43195083318278
(Previous) Eval Time (s)     5.773693060968071
Sample Time (s)              5.75103299273178
Epoch Time (s)               155.95667688688263
Total Train Time (s)         68567.0539119551
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:32:28.401886 UTC | [2020_01_10_09_29_40] Iteration #415 | Epoch Duration: 156.1413779258728
2020-01-11 04:32:28.402057 UTC | [2020_01_10_09_29_40] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.081994735
Z variance train             0.016398855
KL Divergence                8.505392
KL Loss                      0.8505392
QF Loss                      53.85135
VF Loss                      20.258635
Policy Loss                  -1520.4592
Q Predictions Mean           1520.145
Q Predictions Std            328.54422
Q Predictions Max            1797.8684
Q Predictions Min            59.388027
V Predictions Mean           1520.6249
V Predictions Std            329.80627
V Predictions Max            1795.2593
V Predictions Min            52.37693
Log Pis Mean                 -0.2638197
Log Pis Std                  1.8210686
Log Pis Max                  6.229063
Log Pis Min                  -5.813698
Policy mu Mean               0.030088082
Policy mu Std                0.8902055
Policy mu Max                2.2086601
Policy mu Min                -2.511979
Policy log std Mean          -0.48498163
Policy log std Std           0.16772516
Policy log std Max           0.010842085
Policy log std Min           -0.9976398
Z mean eval                  0.08793899
Z variance eval              0.023126267
total_rewards                [3260.67248465 1591.76231285 3285.03477871 3281.91508081  912.43293283
 3294.47900578  823.46597762  965.0191114   850.35875723 3334.30919189]
total_rewards_mean           2159.944963375604
total_rewards_std            1149.378164085926
total_rewards_max            3334.3091918852474
total_rewards_min            823.4659776156087
Number of train steps total  1668000
Number of env steps total    2109655
Number of rollouts total     0
Train Time (s)               145.2447273088619
(Previous) Eval Time (s)     12.377528383862227
Sample Time (s)              8.543244142085314
Epoch Time (s)               166.16549983480945
Total Train Time (s)         68733.4347177213
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:35:14.787523 UTC | [2020_01_10_09_29_40] Iteration #416 | Epoch Duration: 166.38533520698547
2020-01-11 04:35:14.787687 UTC | [2020_01_10_09_29_40] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08784358
Z variance train             0.023137871
KL Divergence                7.567229
KL Loss                      0.75672287
QF Loss                      31.31094
VF Loss                      12.959048
Policy Loss                  -1528.7755
Q Predictions Mean           1529.8259
Q Predictions Std            326.60422
Q Predictions Max            1814.1946
Q Predictions Min            20.3264
V Predictions Mean           1528.7084
V Predictions Std            325.1157
V Predictions Max            1814.9984
V Predictions Min            21.429777
Log Pis Mean                 -0.3216511
Log Pis Std                  1.8787354
Log Pis Max                  7.1470723
Log Pis Min                  -4.9927635
Policy mu Mean               -0.066523425
Policy mu Std                0.87454367
Policy mu Max                2.392046
Policy mu Min                -3.0293968
Policy log std Mean          -0.48098767
Policy log std Std           0.17821117
Policy log std Max           0.19957662
Policy log std Min           -1.2170558
Z mean eval                  0.14555772
Z variance eval              0.015598963
total_rewards                [3280.33477085  672.7378728  3310.24127208 3303.2593606   972.31238138
 3349.62027012 1110.65646989 3292.49879106 3293.88932884 3286.01353102]
total_rewards_mean           2587.156404862734
total_rewards_std            1097.0713169950145
total_rewards_max            3349.620270116731
total_rewards_min            672.7378727970929
Number of train steps total  1672000
Number of env steps total    2119293
Number of rollouts total     0
Train Time (s)               147.17750099208206
(Previous) Eval Time (s)     16.915999703109264
Sample Time (s)              6.75590631691739
Epoch Time (s)               170.8494070121087
Total Train Time (s)         68904.36558922939
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:38:05.720811 UTC | [2020_01_10_09_29_40] Iteration #417 | Epoch Duration: 170.93300318717957
2020-01-11 04:38:05.720953 UTC | [2020_01_10_09_29_40] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14547174
Z variance train             0.015598869
KL Divergence                8.577673
KL Loss                      0.8577673
QF Loss                      53.890556
VF Loss                      20.556086
Policy Loss                  -1539.104
Q Predictions Mean           1538.7721
Q Predictions Std            317.19775
Q Predictions Max            1804.8964
Q Predictions Min            72.74195
V Predictions Mean           1538.3616
V Predictions Std            317.3779
V Predictions Max            1804.2313
V Predictions Min            73.704796
Log Pis Mean                 -0.16425964
Log Pis Std                  1.9403276
Log Pis Max                  5.952815
Log Pis Min                  -4.2020283
Policy mu Mean               -0.15680927
Policy mu Std                0.8797074
Policy mu Max                1.742182
Policy mu Min                -2.6733558
Policy log std Mean          -0.4535551
Policy log std Std           0.17962375
Policy log std Max           0.3080627
Policy log std Min           -1.2715724
Z mean eval                  0.090370454
Z variance eval              0.015560545
total_rewards                [1444.13877817  934.14857538  856.30232781  821.78697091 1474.06387802
 1056.78775346 3269.40560292  841.11998471 2570.50728501  893.56584728]
total_rewards_mean           1416.1827003672545
total_rewards_std            800.1969500460157
total_rewards_max            3269.405602916417
total_rewards_min            821.786970910096
Number of train steps total  1676000
Number of env steps total    2129957
Number of rollouts total     0
Train Time (s)               147.95398752857
(Previous) Eval Time (s)     8.276288623921573
Sample Time (s)              7.232841524295509
Epoch Time (s)               163.46311767678708
Total Train Time (s)         69067.91761582671
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:40:49.277749 UTC | [2020_01_10_09_29_40] Iteration #418 | Epoch Duration: 163.5566794872284
2020-01-11 04:40:49.277948 UTC | [2020_01_10_09_29_40] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09153422
Z variance train             0.015558583
KL Divergence                8.081236
KL Loss                      0.8081236
QF Loss                      55.579636
VF Loss                      40.547028
Policy Loss                  -1501.5743
Q Predictions Mean           1504.2992
Q Predictions Std            302.03845
Q Predictions Max            1815.3947
Q Predictions Min            40.05286
V Predictions Mean           1504.374
V Predictions Std            300.9389
V Predictions Max            1811.3447
V Predictions Min            38.692856
Log Pis Mean                 -0.083782576
Log Pis Std                  1.9089576
Log Pis Max                  5.7672005
Log Pis Min                  -5.457401
Policy mu Mean               -0.09584093
Policy mu Std                0.9082621
Policy mu Max                1.9587853
Policy mu Min                -2.562377
Policy log std Mean          -0.47988725
Policy log std Std           0.18275242
Policy log std Max           0.034575403
Policy log std Min           -1.2173269
Z mean eval                  0.09238964
Z variance eval              0.016113246
total_rewards                [ 819.27356972  349.26655221 3314.26467307 3268.39202677 3268.40634354
  811.99426416  883.22200233  835.32365994 2885.82447924 3274.73451927]
total_rewards_mean           1971.070209025581
total_rewards_std            1244.1979710532084
total_rewards_max            3314.264673070798
total_rewards_min            349.26655221163156
Number of train steps total  1680000
Number of env steps total    2140319
Number of rollouts total     0
Train Time (s)               146.35494016576558
(Previous) Eval Time (s)     13.354848640970886
Sample Time (s)              6.489910088479519
Epoch Time (s)               166.199698895216
Total Train Time (s)         69234.21399512328
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:43:35.575908 UTC | [2020_01_10_09_29_40] Iteration #419 | Epoch Duration: 166.29782938957214
2020-01-11 04:43:35.576038 UTC | [2020_01_10_09_29_40] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.092483535
Z variance train             0.016108409
KL Divergence                7.986305
KL Loss                      0.79863054
QF Loss                      42.287758
VF Loss                      16.847322
Policy Loss                  -1506.6852
Q Predictions Mean           1507.1971
Q Predictions Std            341.2082
Q Predictions Max            1797.0598
Q Predictions Min            39.07686
V Predictions Mean           1507.7437
V Predictions Std            339.01968
V Predictions Max            1798.3416
V Predictions Min            53.37862
Log Pis Mean                 0.015474085
Log Pis Std                  1.8427925
Log Pis Max                  4.902398
Log Pis Min                  -4.633996
Policy mu Mean               -0.099470764
Policy mu Std                0.89880645
Policy mu Max                2.0298202
Policy mu Min                -2.5118325
Policy log std Mean          -0.50645274
Policy log std Std           0.17286454
Policy log std Max           0.19339362
Policy log std Min           -1.273845
Z mean eval                  0.103587344
Z variance eval              0.021650935
total_rewards                [2721.20883871 3279.49550061 3297.03481525 3313.89978382 3292.82437258
 3300.0058222  3274.97512956 3316.56464111 3296.58844964 3305.47632348]
total_rewards_mean           3239.8073676958143
total_rewards_std            173.31585596512994
total_rewards_max            3316.564641112004
total_rewards_min            2721.208838710399
Number of train steps total  1684000
Number of env steps total    2150344
Number of rollouts total     0
Train Time (s)               146.0608386467211
(Previous) Eval Time (s)     21.592415578197688
Sample Time (s)              6.613286011386663
Epoch Time (s)               174.26654023630545
Total Train Time (s)         69408.56366759026
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:46:29.929874 UTC | [2020_01_10_09_29_40] Iteration #420 | Epoch Duration: 174.3537483215332
2020-01-11 04:46:29.930001 UTC | [2020_01_10_09_29_40] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.103407845
Z variance train             0.021614134
KL Divergence                7.549478
KL Loss                      0.75494784
QF Loss                      34.40977
VF Loss                      14.732542
Policy Loss                  -1553.9658
Q Predictions Mean           1554.3927
Q Predictions Std            273.38422
Q Predictions Max            1822.595
Q Predictions Min            31.376339
V Predictions Mean           1554.6113
V Predictions Std            273.27432
V Predictions Max            1823.4795
V Predictions Min            45.2386
Log Pis Mean                 -0.14943276
Log Pis Std                  1.805079
Log Pis Max                  5.361515
Log Pis Min                  -4.6426573
Policy mu Mean               -0.045348745
Policy mu Std                0.89108735
Policy mu Max                2.0847504
Policy mu Min                -2.6161246
Policy log std Mean          -0.4929869
Policy log std Std           0.1887237
Policy log std Max           0.16854882
Policy log std Min           -1.1655513
Z mean eval                  0.044198122
Z variance eval              0.027931517
total_rewards                [1188.4749572  3230.73879292 3231.62447096 1442.42003708  645.9293135
  814.34486632  978.25283041 3237.40754031 3219.73070738 2508.81466722]
total_rewards_mean           2049.773818330355
total_rewards_std            1074.1217983829658
total_rewards_max            3237.407540309197
total_rewards_min            645.9293135019337
Number of train steps total  1688000
Number of env steps total    2158674
Number of rollouts total     0
Train Time (s)               147.28899901686236
(Previous) Eval Time (s)     11.759199125226587
Sample Time (s)              6.724035916849971
Epoch Time (s)               165.77223405893892
Total Train Time (s)         69574.42209232133
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:49:15.795465 UTC | [2020_01_10_09_29_40] Iteration #421 | Epoch Duration: 165.8653542995453
2020-01-11 04:49:15.795680 UTC | [2020_01_10_09_29_40] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04405202
Z variance train             0.027928937
KL Divergence                6.6053314
KL Loss                      0.66053313
QF Loss                      56.651665
VF Loss                      19.524755
Policy Loss                  -1541.5446
Q Predictions Mean           1543.5653
Q Predictions Std            307.47937
Q Predictions Max            1807.9878
Q Predictions Min            47.935368
V Predictions Mean           1540.7517
V Predictions Std            306.65887
V Predictions Max            1798.3717
V Predictions Min            41.96334
Log Pis Mean                 -0.12495917
Log Pis Std                  1.9446443
Log Pis Max                  5.4501696
Log Pis Min                  -5.513262
Policy mu Mean               -0.04442927
Policy mu Std                0.8970533
Policy mu Max                2.0778224
Policy mu Min                -2.7804554
Policy log std Mean          -0.48165274
Policy log std Std           0.1899599
Policy log std Max           0.07623112
Policy log std Min           -1.3326066
Z mean eval                  0.053890325
Z variance eval              0.017780576
total_rewards                [3235.42843157  869.48923268 3230.46872354 3256.05786166  347.81985699
 3236.04832562  853.93903272 3240.34236147 3223.60669275 1652.853332  ]
total_rewards_mean           2314.6053851002225
total_rewards_std            1167.6236937869537
total_rewards_max            3256.0578616625257
total_rewards_min            347.81985698861024
Number of train steps total  1692000
Number of env steps total    2168678
Number of rollouts total     0
Train Time (s)               148.27799731027335
(Previous) Eval Time (s)     15.854907721746713
Sample Time (s)              6.545215743593872
Epoch Time (s)               170.67812077561393
Total Train Time (s)         69745.18738348177
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:52:06.563856 UTC | [2020_01_10_09_29_40] Iteration #422 | Epoch Duration: 170.7680377960205
2020-01-11 04:52:06.564056 UTC | [2020_01_10_09_29_40] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056944318
Z variance train             0.017749578
KL Divergence                7.792056
KL Loss                      0.7792056
QF Loss                      65.80167
VF Loss                      29.971258
Policy Loss                  -1546.7146
Q Predictions Mean           1546.091
Q Predictions Std            266.13174
Q Predictions Max            1796.5104
Q Predictions Min            222.77652
V Predictions Mean           1549.8124
V Predictions Std            266.0737
V Predictions Max            1806.9968
V Predictions Min            233.83766
Log Pis Mean                 -0.23420042
Log Pis Std                  1.8283671
Log Pis Max                  5.8871927
Log Pis Min                  -5.35842
Policy mu Mean               -0.13425022
Policy mu Std                0.84971976
Policy mu Max                2.0806642
Policy mu Min                -2.5336702
Policy log std Mean          -0.50944287
Policy log std Std           0.18758821
Policy log std Max           0.07739398
Policy log std Min           -1.1868186
Z mean eval                  0.055634648
Z variance eval              0.013466862
total_rewards                [ 989.15658747  991.12941672 2646.46569565 2423.10097146 3237.77528211
 3220.83575587  320.68924623  313.00425954 2196.57227328 3029.05600808]
total_rewards_mean           1936.7785496397978
total_rewards_std            1112.7780920995008
total_rewards_max            3237.7752821079916
total_rewards_min            313.0042595353863
Number of train steps total  1696000
Number of env steps total    2176862
Number of rollouts total     0
Train Time (s)               145.28160374518484
(Previous) Eval Time (s)     13.563338266219944
Sample Time (s)              6.857128826901317
Epoch Time (s)               165.7020708383061
Total Train Time (s)         69910.97064085724
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:54:52.350441 UTC | [2020_01_10_09_29_40] Iteration #423 | Epoch Duration: 165.78627014160156
2020-01-11 04:54:52.350581 UTC | [2020_01_10_09_29_40] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055613317
Z variance train             0.013462663
KL Divergence                8.433369
KL Loss                      0.8433369
QF Loss                      33.557285
VF Loss                      22.815926
Policy Loss                  -1523.0188
Q Predictions Mean           1524.5374
Q Predictions Std            311.0051
Q Predictions Max            1801.1669
Q Predictions Min            26.952887
V Predictions Mean           1522.9967
V Predictions Std            310.94443
V Predictions Max            1796.8928
V Predictions Min            20.255075
Log Pis Mean                 -0.14805445
Log Pis Std                  1.8189942
Log Pis Max                  7.599844
Log Pis Min                  -5.859217
Policy mu Mean               0.03692138
Policy mu Std                0.8711099
Policy mu Max                1.9059108
Policy mu Min                -2.5419152
Policy log std Mean          -0.4850026
Policy log std Std           0.18902448
Policy log std Max           0.10538608
Policy log std Min           -1.132567
Z mean eval                  0.031291116
Z variance eval              0.017464727
total_rewards                [ 941.92700167 3295.48661296 1143.82704699  894.98672974 3271.21889316
 3285.191809   1974.71178368 3281.35637867 3284.63051245 3249.79199908]
total_rewards_mean           2462.3128767404028
total_rewards_std            1036.1970490615972
total_rewards_max            3295.4866129648117
total_rewards_min            894.9867297397313
Number of train steps total  1700000
Number of env steps total    2186960
Number of rollouts total     0
Train Time (s)               147.05644714226946
(Previous) Eval Time (s)     13.690652403049171
Sample Time (s)              6.494998177047819
Epoch Time (s)               167.24209772236645
Total Train Time (s)         70078.29034942156
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:57:39.675643 UTC | [2020_01_10_09_29_40] Iteration #424 | Epoch Duration: 167.32495522499084
2020-01-11 04:57:39.675820 UTC | [2020_01_10_09_29_40] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031345125
Z variance train             0.017479405
KL Divergence                7.7215085
KL Loss                      0.7721509
QF Loss                      48.94686
VF Loss                      31.77945
Policy Loss                  -1558.6682
Q Predictions Mean           1555.7777
Q Predictions Std            264.89893
Q Predictions Max            1796.6562
Q Predictions Min            37.331684
V Predictions Mean           1558.0448
V Predictions Std            257.39532
V Predictions Max            1798.0492
V Predictions Min            229.67007
Log Pis Mean                 -0.2898359
Log Pis Std                  1.6788673
Log Pis Max                  6.796755
Log Pis Min                  -5.420299
Policy mu Mean               -0.042593196
Policy mu Std                0.8377668
Policy mu Max                2.1931987
Policy mu Min                -2.541673
Policy log std Mean          -0.49402285
Policy log std Std           0.17405915
Policy log std Max           0.121919096
Policy log std Min           -1.2165415
Z mean eval                  0.06998213
Z variance eval              0.020659441
total_rewards                [3290.22527843 3282.19646736 3292.88013572 3300.89537215  917.50892944
  885.47135656 3296.37423543 3273.10712366 3334.87032389  949.43175165]
total_rewards_mean           2582.296097427651
total_rewards_std            1090.0830592824564
total_rewards_max            3334.8703238901985
total_rewards_min            885.4713565586396
Number of train steps total  1704000
Number of env steps total    2196888
Number of rollouts total     0
Train Time (s)               147.8799654142931
(Previous) Eval Time (s)     14.378973044920713
Sample Time (s)              6.814590128138661
Epoch Time (s)               169.07352858735248
Total Train Time (s)         70247.46271807328
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:00:28.855347 UTC | [2020_01_10_09_29_40] Iteration #425 | Epoch Duration: 169.17937898635864
2020-01-11 05:00:28.855614 UTC | [2020_01_10_09_29_40] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07005687
Z variance train             0.02064534
KL Divergence                7.400282
KL Loss                      0.7400282
QF Loss                      23.924839
VF Loss                      17.364044
Policy Loss                  -1562.3538
Q Predictions Mean           1562.1735
Q Predictions Std            286.1462
Q Predictions Max            1794.1412
Q Predictions Min            143.29651
V Predictions Mean           1559.7019
V Predictions Std            286.07156
V Predictions Max            1789.4888
V Predictions Min            149.62746
Log Pis Mean                 -0.3462788
Log Pis Std                  1.9266273
Log Pis Max                  7.525959
Log Pis Min                  -4.9482203
Policy mu Mean               -0.009305387
Policy mu Std                0.8512233
Policy mu Max                1.9544772
Policy mu Min                -2.5102193
Policy log std Mean          -0.47365513
Policy log std Std           0.17745678
Policy log std Max           -0.013104379
Policy log std Min           -1.1069598
Z mean eval                  0.10593925
Z variance eval              0.018641505
total_rewards                [ 927.32411257 3255.3090007  3231.35177087 3244.73705241 1047.09931649
 2884.66535896 3235.68060564 3235.66976519  968.03765191 1252.68302739]
total_rewards_mean           2328.255766214498
total_rewards_std            1052.7288854506746
total_rewards_max            3255.3090006986054
total_rewards_min            927.3241125745474
Number of train steps total  1708000
Number of env steps total    2204917
Number of rollouts total     0
Train Time (s)               146.2079737209715
(Previous) Eval Time (s)     15.941997786052525
Sample Time (s)              6.550552580039948
Epoch Time (s)               168.70052408706397
Total Train Time (s)         70416.23946555471
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:03:17.636339 UTC | [2020_01_10_09_29_40] Iteration #426 | Epoch Duration: 168.78055357933044
2020-01-11 05:03:17.636473 UTC | [2020_01_10_09_29_40] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.107864305
Z variance train             0.018643238
KL Divergence                7.803776
KL Loss                      0.78037757
QF Loss                      50.332924
VF Loss                      47.038506
Policy Loss                  -1539.594
Q Predictions Mean           1539.3877
Q Predictions Std            281.8368
Q Predictions Max            1790.8022
Q Predictions Min            164.66797
V Predictions Mean           1543.6971
V Predictions Std            280.5753
V Predictions Max            1797.5933
V Predictions Min            192.4012
Log Pis Mean                 -0.2262635
Log Pis Std                  2.0934567
Log Pis Max                  6.731101
Log Pis Min                  -5.8775682
Policy mu Mean               -0.0708436
Policy mu Std                0.901781
Policy mu Max                1.68715
Policy mu Min                -2.6904945
Policy log std Mean          -0.5206767
Policy log std Std           0.18729104
Policy log std Max           0.05571261
Policy log std Min           -1.2109277
Z mean eval                  0.10178349
Z variance eval              0.01721041
total_rewards                [3284.94480911 3129.49265093 3258.5845357  3247.0890392   929.47187057
 3036.89865204 3254.97059386 1056.36380903 1883.26841974 3280.47694014]
total_rewards_mean           2636.1561320309074
total_rewards_std            914.2753344513737
total_rewards_max            3284.944809105922
total_rewards_min            929.471870566507
Number of train steps total  1712000
Number of env steps total    2214378
Number of rollouts total     0
Train Time (s)               146.741305898875
(Previous) Eval Time (s)     17.494949638843536
Sample Time (s)              6.566043225582689
Epoch Time (s)               170.80229876330122
Total Train Time (s)         70587.12056288356
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:06:08.521092 UTC | [2020_01_10_09_29_40] Iteration #427 | Epoch Duration: 170.88452744483948
2020-01-11 05:06:08.521230 UTC | [2020_01_10_09_29_40] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10231905
Z variance train             0.017240653
KL Divergence                7.9500437
KL Loss                      0.79500437
QF Loss                      34.4403
VF Loss                      20.70979
Policy Loss                  -1516.578
Q Predictions Mean           1515.2693
Q Predictions Std            315.33786
Q Predictions Max            1803.4425
Q Predictions Min            32.820602
V Predictions Mean           1519.1484
V Predictions Std            313.94092
V Predictions Max            1805.9586
V Predictions Min            36.628944
Log Pis Mean                 -0.24905595
Log Pis Std                  1.7246251
Log Pis Max                  5.4997525
Log Pis Min                  -6.1248837
Policy mu Mean               -0.030272052
Policy mu Std                0.86931205
Policy mu Max                1.8365319
Policy mu Min                -2.5093179
Policy log std Mean          -0.49659476
Policy log std Std           0.18389417
Policy log std Max           0.18974668
Policy log std Min           -1.0981516
Z mean eval                  0.13420752
Z variance eval              0.015014735
total_rewards                [3297.50569183 3293.69565672 3305.64984696 3264.22839404 2026.02527278
 3272.17750037 3289.39816602 3265.01294182  642.92508801  832.1780828 ]
total_rewards_mean           2648.8796641349622
total_rewards_std            1026.5035250904286
total_rewards_max            3305.6498469581993
total_rewards_min            642.9250880128003
Number of train steps total  1716000
Number of env steps total    2222955
Number of rollouts total     0
Train Time (s)               148.03668358828872
(Previous) Eval Time (s)     17.73305792035535
Sample Time (s)              6.704067579004914
Epoch Time (s)               172.473809087649
Total Train Time (s)         70759.67698087124
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:09:01.081188 UTC | [2020_01_10_09_29_40] Iteration #428 | Epoch Duration: 172.55986833572388
2020-01-11 05:09:01.081316 UTC | [2020_01_10_09_29_40] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13415784
Z variance train             0.014940776
KL Divergence                8.305305
KL Loss                      0.83053046
QF Loss                      189.03024
VF Loss                      72.01941
Policy Loss                  -1531.8246
Q Predictions Mean           1532.1414
Q Predictions Std            283.92917
Q Predictions Max            1788.8632
Q Predictions Min            36.773136
V Predictions Mean           1531.7759
V Predictions Std            286.21097
V Predictions Max            1789.2303
V Predictions Min            22.113369
Log Pis Mean                 -0.06047357
Log Pis Std                  1.8738953
Log Pis Max                  6.78674
Log Pis Min                  -5.862071
Policy mu Mean               0.080767065
Policy mu Std                0.90587395
Policy mu Max                1.9491605
Policy mu Min                -2.6700053
Policy log std Mean          -0.50706434
Policy log std Std           0.17818195
Policy log std Max           0.11149162
Policy log std Min           -1.4697675
Z mean eval                  0.040045895
Z variance eval              0.019021187
total_rewards                [3264.9306919  3229.44195762 2805.95062564 3264.38629867 3266.54980986
 3271.45062905 1005.32551165 3239.55470818 3302.76102747 3243.25978394]
total_rewards_mean           2989.361104398091
total_rewards_std            675.3474570248673
total_rewards_max            3302.7610274742374
total_rewards_min            1005.3255116544653
Number of train steps total  1720000
Number of env steps total    2232501
Number of rollouts total     0
Train Time (s)               145.4643477043137
(Previous) Eval Time (s)     19.95307613676414
Sample Time (s)              6.856667235027999
Epoch Time (s)               172.27409107610583
Total Train Time (s)         70932.03274387028
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:11:53.446401 UTC | [2020_01_10_09_29_40] Iteration #429 | Epoch Duration: 172.36494612693787
2020-01-11 05:11:53.446747 UTC | [2020_01_10_09_29_40] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039506726
Z variance train             0.019103225
KL Divergence                7.9191256
KL Loss                      0.79191256
QF Loss                      63.418396
VF Loss                      180.72218
Policy Loss                  -1576.5399
Q Predictions Mean           1579.2961
Q Predictions Std            287.21823
Q Predictions Max            1837.2024
Q Predictions Min            29.436007
V Predictions Mean           1588.7888
V Predictions Std            287.16315
V Predictions Max            1849.5342
V Predictions Min            51.3412
Log Pis Mean                 0.022786528
Log Pis Std                  1.9809207
Log Pis Max                  8.978486
Log Pis Min                  -4.3263016
Policy mu Mean               -0.14742357
Policy mu Std                0.92681783
Policy mu Max                2.0324068
Policy mu Min                -3.1428509
Policy log std Mean          -0.49530745
Policy log std Std           0.16916645
Policy log std Max           0.21502846
Policy log std Min           -0.9787058
Z mean eval                  0.07933344
Z variance eval              0.024539739
total_rewards                [ 957.1727027   350.74133276  913.48732433 2548.15048894 3309.0476096
 1009.88966403 3328.88734373  929.04892101 3317.65729341 3332.3599675 ]
total_rewards_mean           1999.6442648015734
total_rewards_std            1200.2802232926872
total_rewards_max            3332.3599674995885
total_rewards_min            350.7413327595208
Number of train steps total  1724000
Number of env steps total    2240899
Number of rollouts total     0
Train Time (s)               146.42127005476505
(Previous) Eval Time (s)     13.467773264739662
Sample Time (s)              6.922046885360032
Epoch Time (s)               166.81109020486474
Total Train Time (s)         71098.92929275427
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:14:40.345746 UTC | [2020_01_10_09_29_40] Iteration #430 | Epoch Duration: 166.89879631996155
2020-01-11 05:14:40.345872 UTC | [2020_01_10_09_29_40] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.079462126
Z variance train             0.02457979
KL Divergence                7.051895
KL Loss                      0.7051895
QF Loss                      27.262777
VF Loss                      19.469868
Policy Loss                  -1575.7693
Q Predictions Mean           1577.0447
Q Predictions Std            227.16539
Q Predictions Max            1794.3884
Q Predictions Min            200.5323
V Predictions Mean           1576.2168
V Predictions Std            226.16734
V Predictions Max            1786.0159
V Predictions Min            199.97545
Log Pis Mean                 -0.31748477
Log Pis Std                  1.6169187
Log Pis Max                  5.371285
Log Pis Min                  -4.1164894
Policy mu Mean               -0.05939154
Policy mu Std                0.83434135
Policy mu Max                1.8463826
Policy mu Min                -2.5229151
Policy log std Mean          -0.46616492
Policy log std Std           0.18555944
Policy log std Max           0.5429688
Policy log std Min           -1.0047288
Z mean eval                  0.10108229
Z variance eval              0.019009624
total_rewards                [ 641.34297986  634.59704467 3308.52610839 1430.72105116 1245.89106113
  925.97975751 2149.86726417 1875.14888341 2307.87916745 3281.358684  ]
total_rewards_mean           1780.1312001758356
total_rewards_std            935.9534051094994
total_rewards_max            3308.526108394794
total_rewards_min            634.5970446658316
Number of train steps total  1728000
Number of env steps total    2250809
Number of rollouts total     0
Train Time (s)               145.43294464889914
(Previous) Eval Time (s)     10.208161294925958
Sample Time (s)              6.694709767121822
Epoch Time (s)               162.33581571094692
Total Train Time (s)         71261.35688698385
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:17:22.780147 UTC | [2020_01_10_09_29_40] Iteration #431 | Epoch Duration: 162.4341733455658
2020-01-11 05:17:22.780327 UTC | [2020_01_10_09_29_40] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1024541
Z variance train             0.019086096
KL Divergence                7.735961
KL Loss                      0.7735961
QF Loss                      154.21237
VF Loss                      60.272255
Policy Loss                  -1491.8892
Q Predictions Mean           1491.8651
Q Predictions Std            333.91898
Q Predictions Max            1786.1517
Q Predictions Min            69.47982
V Predictions Mean           1498.0366
V Predictions Std            334.3906
V Predictions Max            1791.6406
V Predictions Min            69.83484
Log Pis Mean                 -0.17455094
Log Pis Std                  1.8998847
Log Pis Max                  8.726641
Log Pis Min                  -5.3918033
Policy mu Mean               -0.12024916
Policy mu Std                0.8744879
Policy mu Max                1.963009
Policy mu Min                -2.5584772
Policy log std Mean          -0.4768125
Policy log std Std           0.16251378
Policy log std Max           0.14774144
Policy log std Min           -0.8962903
Z mean eval                  0.057563312
Z variance eval              0.020126827
total_rewards                [ 794.90790738 1711.79750026  952.90895564  870.88311157  964.85886921
 3249.18176816  635.8938984   794.8779716  3304.99816314 3303.17337562]
total_rewards_mean           1658.348152099007
total_rewards_std            1099.3502738792238
total_rewards_max            3304.9981631429036
total_rewards_min            635.8938983967477
Number of train steps total  1732000
Number of env steps total    2260474
Number of rollouts total     0
Train Time (s)               145.97781679732725
(Previous) Eval Time (s)     9.473804927896708
Sample Time (s)              6.578875942155719
Epoch Time (s)               162.03049766737968
Total Train Time (s)         71423.46858803974
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:20:04.896136 UTC | [2020_01_10_09_29_40] Iteration #432 | Epoch Duration: 162.11568427085876
2020-01-11 05:20:04.896296 UTC | [2020_01_10_09_29_40] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057223104
Z variance train             0.020109277
KL Divergence                7.7703586
KL Loss                      0.7770359
QF Loss                      77.72562
VF Loss                      33.85072
Policy Loss                  -1566.8193
Q Predictions Mean           1569.152
Q Predictions Std            273.6188
Q Predictions Max            1826.9545
Q Predictions Min            175.61816
V Predictions Mean           1568.9827
V Predictions Std            273.70865
V Predictions Max            1823.3396
V Predictions Min            179.37695
Log Pis Mean                 -0.47100738
Log Pis Std                  1.5858535
Log Pis Max                  5.8161697
Log Pis Min                  -4.2576103
Policy mu Mean               0.03507698
Policy mu Std                0.8381804
Policy mu Max                1.8957632
Policy mu Min                -2.5326524
Policy log std Mean          -0.47310948
Policy log std Std           0.17205168
Policy log std Max           0.06649715
Policy log std Min           -0.9923481
Z mean eval                  0.09898146
Z variance eval              0.017857542
total_rewards                [1423.93870598  945.23822055 1064.06429001 3311.68372845 3308.0213539
 1189.29148998  990.30295747 1107.96257966  797.42237381 1108.83937675]
total_rewards_mean           1524.676507655165
total_rewards_std            905.830110437242
total_rewards_max            3311.683728454737
total_rewards_min            797.422373806495
Number of train steps total  1736000
Number of env steps total    2269571
Number of rollouts total     0
Train Time (s)               148.51946880901232
(Previous) Eval Time (s)     10.230537402909249
Sample Time (s)              6.70603808760643
Epoch Time (s)               165.456044299528
Total Train Time (s)         71589.00146846147
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:22:50.431836 UTC | [2020_01_10_09_29_40] Iteration #433 | Epoch Duration: 165.53543257713318
2020-01-11 05:22:50.431962 UTC | [2020_01_10_09_29_40] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09818641
Z variance train             0.017845921
KL Divergence                8.386686
KL Loss                      0.83866864
QF Loss                      143.45305
VF Loss                      46.14865
Policy Loss                  -1562.9813
Q Predictions Mean           1561.8759
Q Predictions Std            300.11908
Q Predictions Max            1828.6008
Q Predictions Min            227.94193
V Predictions Mean           1567.1029
V Predictions Std            297.1833
V Predictions Max            1834.9272
V Predictions Min            250.7838
Log Pis Mean                 -0.04984162
Log Pis Std                  1.9115596
Log Pis Max                  6.935651
Log Pis Min                  -6.200955
Policy mu Mean               0.048875462
Policy mu Std                0.882519
Policy mu Max                2.3853889
Policy mu Min                -2.6378
Policy log std Mean          -0.49883768
Policy log std Std           0.16673787
Policy log std Max           0.38826498
Policy log std Min           -1.0098064
Z mean eval                  0.072447695
Z variance eval              0.014623153
total_rewards                [3265.38649353 2179.15414857 1909.81598491 3287.85420772  982.95128373
  928.24177946  972.66376634 3258.81119565  888.53173076 3261.45289623]
total_rewards_mean           2093.4863486894237
total_rewards_std            1042.2239726057276
total_rewards_max            3287.854207718026
total_rewards_min            888.531730755572
Number of train steps total  1740000
Number of env steps total    2278175
Number of rollouts total     0
Train Time (s)               147.01767666172236
(Previous) Eval Time (s)     11.81831204611808
Sample Time (s)              6.365373490843922
Epoch Time (s)               165.20136219868436
Total Train Time (s)         71754.28519203514
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:25:35.720409 UTC | [2020_01_10_09_29_40] Iteration #434 | Epoch Duration: 165.2883439064026
2020-01-11 05:25:35.720602 UTC | [2020_01_10_09_29_40] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07389215
Z variance train             0.014612551
KL Divergence                8.550923
KL Loss                      0.85509235
QF Loss                      38.22425
VF Loss                      18.513802
Policy Loss                  -1568.9955
Q Predictions Mean           1568.1439
Q Predictions Std            292.04776
Q Predictions Max            1806.864
Q Predictions Min            41.3271
V Predictions Mean           1566.9393
V Predictions Std            291.53958
V Predictions Max            1806.4382
V Predictions Min            41.764175
Log Pis Mean                 -0.15156454
Log Pis Std                  1.8855453
Log Pis Max                  5.9573283
Log Pis Min                  -5.26827
Policy mu Mean               -0.04598582
Policy mu Std                0.8790917
Policy mu Max                1.5885646
Policy mu Min                -2.6016533
Policy log std Mean          -0.48625398
Policy log std Std           0.17941828
Policy log std Max           0.21596408
Policy log std Min           -1.1272771
Z mean eval                  0.08240484
Z variance eval              0.015278583
total_rewards                [3147.15982947  851.32117856 1372.23203182 1145.53637646 1340.36634205
 2170.94080799 2409.64896044  585.11917207  360.37487656 2930.52144729]
total_rewards_mean           1631.322102270205
total_rewards_std            926.7515067220263
total_rewards_max            3147.1598294744617
total_rewards_min            360.3748765592547
Number of train steps total  1744000
Number of env steps total    2285745
Number of rollouts total     0
Train Time (s)               145.03862886177376
(Previous) Eval Time (s)     9.544324720278382
Sample Time (s)              6.663695190101862
Epoch Time (s)               161.246648772154
Total Train Time (s)         71915.60691873031
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:28:17.044890 UTC | [2020_01_10_09_29_40] Iteration #435 | Epoch Duration: 161.32416605949402
2020-01-11 05:28:17.045000 UTC | [2020_01_10_09_29_40] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.082995735
Z variance train             0.015251206
KL Divergence                8.42429
KL Loss                      0.842429
QF Loss                      294.61554
VF Loss                      105.881516
Policy Loss                  -1570.2814
Q Predictions Mean           1565.5635
Q Predictions Std            255.9967
Q Predictions Max            1791.1759
Q Predictions Min            192.59035
V Predictions Mean           1579.6274
V Predictions Std            257.62473
V Predictions Max            1805.3481
V Predictions Min            210.307
Log Pis Mean                 -0.21994556
Log Pis Std                  1.7008568
Log Pis Max                  5.052373
Log Pis Min                  -6.0307093
Policy mu Mean               0.06168781
Policy mu Std                0.87683
Policy mu Max                2.1732383
Policy mu Min                -2.5783231
Policy log std Mean          -0.49162254
Policy log std Std           0.16006842
Policy log std Max           0.10055292
Policy log std Min           -0.97750753
Z mean eval                  0.026999757
Z variance eval              0.014864879
total_rewards                [3306.42469222 3270.32841379 1053.09173409 2531.2245372  3295.27304585
 3307.17019675  644.74413568  883.22116618  894.56744059 3288.83040978]
total_rewards_mean           2247.4875772134183
total_rewards_std            1150.6614661199428
total_rewards_max            3307.1701967450913
total_rewards_min            644.744135676409
Number of train steps total  1748000
Number of env steps total    2294805
Number of rollouts total     0
Train Time (s)               146.7473247689195
(Previous) Eval Time (s)     14.809225684031844
Sample Time (s)              5.725708884187043
Epoch Time (s)               167.28225933713838
Total Train Time (s)         72082.96958139678
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:31:04.414347 UTC | [2020_01_10_09_29_40] Iteration #436 | Epoch Duration: 167.36924815177917
2020-01-11 05:31:04.414525 UTC | [2020_01_10_09_29_40] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02610439
Z variance train             0.014923315
KL Divergence                8.343207
KL Loss                      0.8343207
QF Loss                      139.39352
VF Loss                      34.66679
Policy Loss                  -1560.22
Q Predictions Mean           1556.5013
Q Predictions Std            265.5151
Q Predictions Max            1810.3832
Q Predictions Min            215.72304
V Predictions Mean           1559.8698
V Predictions Std            266.25183
V Predictions Max            1814.9106
V Predictions Min            215.47375
Log Pis Mean                 -0.0031874478
Log Pis Std                  1.9251921
Log Pis Max                  5.813385
Log Pis Min                  -4.6421533
Policy mu Mean               -0.097920895
Policy mu Std                0.8988962
Policy mu Max                1.8515697
Policy mu Min                -2.4502852
Policy log std Mean          -0.487054
Policy log std Std           0.16014549
Policy log std Max           0.12665397
Policy log std Min           -1.1056213
Z mean eval                  0.03789544
Z variance eval              0.01587996
total_rewards                [2271.76438201  835.99073177  847.6802399   963.76187877  665.55585009
 3335.02685429 3326.6004377   874.07812101  957.62778232 3336.15119851]
total_rewards_mean           1741.4237476375529
total_rewards_std            1123.5761434652695
total_rewards_max            3336.1511985074917
total_rewards_min            665.5558500931752
Number of train steps total  1752000
Number of env steps total    2304018
Number of rollouts total     0
Train Time (s)               147.90321059105918
(Previous) Eval Time (s)     9.577254958916456
Sample Time (s)              6.473112838342786
Epoch Time (s)               163.95357838831842
Total Train Time (s)         72246.99717123108
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:33:48.445374 UTC | [2020_01_10_09_29_40] Iteration #437 | Epoch Duration: 164.03073120117188
2020-01-11 05:33:48.445488 UTC | [2020_01_10_09_29_40] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038038507
Z variance train             0.015852023
KL Divergence                8.428925
KL Loss                      0.84289247
QF Loss                      31.402151
VF Loss                      22.013166
Policy Loss                  -1596.953
Q Predictions Mean           1597.1353
Q Predictions Std            272.8213
Q Predictions Max            1812.5267
Q Predictions Min            134.42943
V Predictions Mean           1595.1671
V Predictions Std            272.06998
V Predictions Max            1810.2609
V Predictions Min            153.6738
Log Pis Mean                 -0.25442198
Log Pis Std                  1.9175676
Log Pis Max                  4.7095013
Log Pis Min                  -6.5959826
Policy mu Mean               0.042234015
Policy mu Std                0.89911634
Policy mu Max                1.8651774
Policy mu Min                -2.6172
Policy log std Mean          -0.49662247
Policy log std Std           0.17180032
Policy log std Max           0.017023414
Policy log std Min           -1.2300096
Z mean eval                  0.08373121
Z variance eval              0.0215813
total_rewards                [3304.00158199  909.65019613  863.28753054 3323.44230376  837.34252385
  743.88387015 1287.69015871  939.00690053 3331.40396545  937.19658715]
total_rewards_mean           1647.6905618244477
total_rewards_std            1102.5678032290382
total_rewards_max            3331.403965447024
total_rewards_min            743.883870152755
Number of train steps total  1756000
Number of env steps total    2313173
Number of rollouts total     0
Train Time (s)               146.42092575179413
(Previous) Eval Time (s)     10.829162728972733
Sample Time (s)              5.408395261969417
Epoch Time (s)               162.65848374273628
Total Train Time (s)         72409.96788193146
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:36:31.425553 UTC | [2020_01_10_09_29_40] Iteration #438 | Epoch Duration: 162.97992539405823
2020-01-11 05:36:31.425866 UTC | [2020_01_10_09_29_40] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08364694
Z variance train             0.021569658
KL Divergence                8.232592
KL Loss                      0.8232592
QF Loss                      34.14145
VF Loss                      9.448513
Policy Loss                  -1533.77
Q Predictions Mean           1533.5948
Q Predictions Std            341.57138
Q Predictions Max            1827.2592
Q Predictions Min            215.01353
V Predictions Mean           1533.4396
V Predictions Std            341.72034
V Predictions Max            1824.6438
V Predictions Min            193.94658
Log Pis Mean                 -0.35027748
Log Pis Std                  1.8655771
Log Pis Max                  4.998212
Log Pis Min                  -5.8637753
Policy mu Mean               -0.0831384
Policy mu Std                0.89294934
Policy mu Max                1.4677527
Policy mu Min                -2.5147054
Policy log std Mean          -0.46077836
Policy log std Std           0.17905074
Policy log std Max           0.2822565
Policy log std Min           -1.1645206
Z mean eval                  0.11895466
Z variance eval              0.021311967
total_rewards                [ 640.15444388 3274.17985739 1019.28548093  636.63501385 3286.66116295
  896.61132808  896.33914366 1110.72556695  950.49394958 3272.22436989]
total_rewards_mean           1598.331031714537
total_rewards_std            1108.2309013870145
total_rewards_max            3286.6611629474164
total_rewards_min            636.6350138456617
Number of train steps total  1760000
Number of env steps total    2322984
Number of rollouts total     0
Train Time (s)               147.4293310972862
(Previous) Eval Time (s)     10.645280850119889
Sample Time (s)              6.490943590179086
Epoch Time (s)               164.56555553758517
Total Train Time (s)         72574.63738119043
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:39:16.103085 UTC | [2020_01_10_09_29_40] Iteration #439 | Epoch Duration: 164.67698335647583
2020-01-11 05:39:16.103277 UTC | [2020_01_10_09_29_40] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11892613
Z variance train             0.021338385
KL Divergence                7.529093
KL Loss                      0.7529093
QF Loss                      27.799902
VF Loss                      11.842678
Policy Loss                  -1557.3623
Q Predictions Mean           1556.8739
Q Predictions Std            312.1505
Q Predictions Max            1827.1377
Q Predictions Min            70.34429
V Predictions Mean           1558.7592
V Predictions Std            309.74414
V Predictions Max            1826.5938
V Predictions Min            91.89047
Log Pis Mean                 -0.31504446
Log Pis Std                  1.7336198
Log Pis Max                  5.836726
Log Pis Min                  -5.9931912
Policy mu Mean               -0.08141765
Policy mu Std                0.8767188
Policy mu Max                1.6815761
Policy mu Min                -2.4627938
Policy log std Mean          -0.47902474
Policy log std Std           0.16226676
Policy log std Max           0.14099178
Policy log std Min           -1.1607262
Z mean eval                  0.11549646
Z variance eval              0.015017867
total_rewards                [1004.77522265 1173.67532601 1448.01859274 3316.75799432 1423.43408493
 3319.25525728 2497.6556841   868.82306182  949.83228744  912.13078012]
total_rewards_mean           1691.4358291402677
total_rewards_std            929.8439781074122
total_rewards_max            3319.255257283554
total_rewards_min            868.8230618246
Number of train steps total  1764000
Number of env steps total    2330621
Number of rollouts total     0
Train Time (s)               147.5628129132092
(Previous) Eval Time (s)     11.089975379873067
Sample Time (s)              6.535976194776595
Epoch Time (s)               165.18876448785886
Total Train Time (s)         72739.92732427223
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:42:01.396647 UTC | [2020_01_10_09_29_40] Iteration #440 | Epoch Duration: 165.29326844215393
2020-01-11 05:42:01.396821 UTC | [2020_01_10_09_29_40] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11539304
Z variance train             0.015028423
KL Divergence                8.71889
KL Loss                      0.87188905
QF Loss                      30.439596
VF Loss                      12.764951
Policy Loss                  -1580.3237
Q Predictions Mean           1580.1843
Q Predictions Std            269.7606
Q Predictions Max            1827.6389
Q Predictions Min            71.4792
V Predictions Mean           1581.1614
V Predictions Std            268.80008
V Predictions Max            1829.1014
V Predictions Min            72.68565
Log Pis Mean                 -0.18083751
Log Pis Std                  1.86892
Log Pis Max                  5.702606
Log Pis Min                  -5.8701196
Policy mu Mean               -0.06804242
Policy mu Std                0.87921906
Policy mu Max                2.1665564
Policy mu Min                -2.6529696
Policy log std Mean          -0.48001432
Policy log std Std           0.18106811
Policy log std Max           0.18692046
Policy log std Min           -1.1331244
Z mean eval                  0.16798773
Z variance eval              0.018499857
total_rewards                [1219.61935603 3302.2639937  3246.84768228 1133.15752997 1184.90294277
  925.97108624 1006.91086458  939.94439735  926.87370923  949.95663999]
total_rewards_mean           1483.6448202136685
total_rewards_std            901.4854451533323
total_rewards_max            3302.263993701217
total_rewards_min            925.9710862374443
Number of train steps total  1768000
Number of env steps total    2339515
Number of rollouts total     0
Train Time (s)               145.6894788481295
(Previous) Eval Time (s)     9.454329086933285
Sample Time (s)              6.328297195956111
Epoch Time (s)               161.4721051310189
Total Train Time (s)         72901.49876043433
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:44:42.970327 UTC | [2020_01_10_09_29_40] Iteration #441 | Epoch Duration: 161.5733938217163
2020-01-11 05:44:42.970460 UTC | [2020_01_10_09_29_40] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1679342
Z variance train             0.018494785
KL Divergence                8.61957
KL Loss                      0.861957
QF Loss                      34.50677
VF Loss                      30.047413
Policy Loss                  -1587.2119
Q Predictions Mean           1586.8785
Q Predictions Std            272.75046
Q Predictions Max            1821.341
Q Predictions Min            45.873127
V Predictions Mean           1589.2463
V Predictions Std            270.5624
V Predictions Max            1827.0986
V Predictions Min            85.354454
Log Pis Mean                 -0.49417317
Log Pis Std                  1.6502584
Log Pis Max                  4.5656404
Log Pis Min                  -6.6378045
Policy mu Mean               -0.009799093
Policy mu Std                0.8118191
Policy mu Max                1.9026737
Policy mu Min                -2.5266037
Policy log std Mean          -0.45705342
Policy log std Std           0.1672208
Policy log std Max           0.27828294
Policy log std Min           -0.99513876
Z mean eval                  0.054225635
Z variance eval              0.016116362
total_rewards                [ 911.92183479 3308.35887718  994.82611488 3266.02075084 3306.37605046
  859.52922083  911.58322382 1043.06293661 3322.34790274 3256.76728993]
total_rewards_mean           2118.0794202077477
total_rewards_std            1174.9558388914622
total_rewards_max            3322.3479027419226
total_rewards_min            859.529220827874
Number of train steps total  1772000
Number of env steps total    2348065
Number of rollouts total     0
Train Time (s)               146.29729651426896
(Previous) Eval Time (s)     14.03657830087468
Sample Time (s)              6.457586378790438
Epoch Time (s)               166.79146119393408
Total Train Time (s)         73068.36877550324
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:47:29.844578 UTC | [2020_01_10_09_29_40] Iteration #442 | Epoch Duration: 166.8740291595459
2020-01-11 05:47:29.844714 UTC | [2020_01_10_09_29_40] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05451133
Z variance train             0.01609378
KL Divergence                8.343405
KL Loss                      0.8343405
QF Loss                      29.484432
VF Loss                      13.909095
Policy Loss                  -1586.2177
Q Predictions Mean           1585.4149
Q Predictions Std            256.99557
Q Predictions Max            1795.5815
Q Predictions Min            217.47395
V Predictions Mean           1586.3364
V Predictions Std            255.64412
V Predictions Max            1796.5449
V Predictions Min            269.3649
Log Pis Mean                 -0.44337237
Log Pis Std                  1.7306647
Log Pis Max                  4.58122
Log Pis Min                  -5.231899
Policy mu Mean               -0.015865358
Policy mu Std                0.87146395
Policy mu Max                1.5120143
Policy mu Min                -2.5258074
Policy log std Mean          -0.45800313
Policy log std Std           0.16566885
Policy log std Max           0.27972966
Policy log std Min           -0.95911336
Z mean eval                  0.028260734
Z variance eval              0.019443633
total_rewards                [1959.86631072  663.65025232 1694.02582289  861.73232167 1128.76234262
 3301.57317795 2960.11394458  755.80909019  627.80425891  630.35187771]
total_rewards_mean           1458.368939955687
total_rewards_std            944.717288096867
total_rewards_max            3301.573177954963
total_rewards_min            627.8042589066663
Number of train steps total  1776000
Number of env steps total    2357425
Number of rollouts total     0
Train Time (s)               145.14601003704593
(Previous) Eval Time (s)     9.92772385198623
Sample Time (s)              6.359629782382399
Epoch Time (s)               161.43336367141455
Total Train Time (s)         73229.88572078943
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:50:11.364762 UTC | [2020_01_10_09_29_40] Iteration #443 | Epoch Duration: 161.51995968818665
2020-01-11 05:50:11.364898 UTC | [2020_01_10_09_29_40] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02836294
Z variance train             0.019468803
KL Divergence                7.9115944
KL Loss                      0.79115945
QF Loss                      42.75847
VF Loss                      18.496672
Policy Loss                  -1568.8636
Q Predictions Mean           1568.5837
Q Predictions Std            317.97556
Q Predictions Max            1828.8192
Q Predictions Min            34.376007
V Predictions Mean           1569.7833
V Predictions Std            315.76898
V Predictions Max            1829.0867
V Predictions Min            34.27245
Log Pis Mean                 -0.09744367
Log Pis Std                  1.8678925
Log Pis Max                  5.0426173
Log Pis Min                  -4.3293457
Policy mu Mean               -0.011495762
Policy mu Std                0.90249133
Policy mu Max                1.8406633
Policy mu Min                -2.5478265
Policy log std Mean          -0.46013927
Policy log std Std           0.16734573
Policy log std Max           0.24787953
Policy log std Min           -0.9628965
Z mean eval                  0.07059434
Z variance eval              0.01868862
total_rewards                [ 958.89991864  651.12070076 1441.67243771  928.25348772 3300.55827866
  936.68759575 1465.39090454  639.2368527   899.50222999  870.47210584]
total_rewards_mean           1209.1794512317167
total_rewards_std            745.4032822483399
total_rewards_max            3300.558278658156
total_rewards_min            639.2368527008572
Number of train steps total  1780000
Number of env steps total    2366759
Number of rollouts total     0
Train Time (s)               145.44334936887026
(Previous) Eval Time (s)     8.220335096586496
Sample Time (s)              6.579987266100943
Epoch Time (s)               160.2436717315577
Total Train Time (s)         73390.20849729609
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:52:51.691090 UTC | [2020_01_10_09_29_40] Iteration #444 | Epoch Duration: 160.32610368728638
2020-01-11 05:52:51.691231 UTC | [2020_01_10_09_29_40] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06893106
Z variance train             0.01868406
KL Divergence                7.600689
KL Loss                      0.7600689
QF Loss                      39.31411
VF Loss                      39.067726
Policy Loss                  -1580.1947
Q Predictions Mean           1583.0618
Q Predictions Std            255.54195
Q Predictions Max            1806.7788
Q Predictions Min            48.041515
V Predictions Mean           1582.4121
V Predictions Std            256.09937
V Predictions Max            1813.7252
V Predictions Min            38.902447
Log Pis Mean                 -0.2118899
Log Pis Std                  1.8486439
Log Pis Max                  7.158531
Log Pis Min                  -5.3322515
Policy mu Mean               -0.043817624
Policy mu Std                0.888633
Policy mu Max                1.6626362
Policy mu Min                -3.1742854
Policy log std Mean          -0.47878253
Policy log std Std           0.18720894
Policy log std Max           0.22470334
Policy log std Min           -1.1529422
Z mean eval                  0.092145786
Z variance eval              0.02135866
total_rewards                [3279.46194129 3309.02847743 1052.24771622 3306.78478955  643.0503536
  893.09089569 3334.50736386 1167.74164435 2997.80906713 1010.86915973]
total_rewards_mean           2099.459140885294
total_rewards_std            1156.360878833153
total_rewards_max            3334.5073638565664
total_rewards_min            643.0503535983686
Number of train steps total  1784000
Number of env steps total    2374837
Number of rollouts total     0
Train Time (s)               146.8395396899432
(Previous) Eval Time (s)     13.794759626034647
Sample Time (s)              6.503968006931245
Epoch Time (s)               167.1382673229091
Total Train Time (s)         73557.42752499832
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:55:38.912566 UTC | [2020_01_10_09_29_40] Iteration #445 | Epoch Duration: 167.2212471961975
2020-01-11 05:55:38.912704 UTC | [2020_01_10_09_29_40] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09206449
Z variance train             0.02136818
KL Divergence                7.5666933
KL Loss                      0.75666934
QF Loss                      60.626873
VF Loss                      24.180565
Policy Loss                  -1590.5052
Q Predictions Mean           1589.5753
Q Predictions Std            277.56824
Q Predictions Max            1813.041
Q Predictions Min            43.57541
V Predictions Mean           1592.7274
V Predictions Std            275.90552
V Predictions Max            1816.2487
V Predictions Min            49.72851
Log Pis Mean                 -0.22234935
Log Pis Std                  1.8553792
Log Pis Max                  5.157713
Log Pis Min                  -4.8684893
Policy mu Mean               -0.09258228
Policy mu Std                0.87983704
Policy mu Max                1.7209259
Policy mu Min                -2.6154375
Policy log std Mean          -0.4796258
Policy log std Std           0.17243281
Policy log std Max           0.13197654
Policy log std Min           -1.0298204
Z mean eval                  0.055261385
Z variance eval              0.022462504
total_rewards                [ 968.10186334  775.10485406 3271.35569096 1157.93208328 1690.6382699
  903.96924986 3279.7106054  3321.369834    910.94409392 3283.49009454]
total_rewards_mean           1956.261663925988
total_rewards_std            1112.9029732307843
total_rewards_max            3321.369833995357
total_rewards_min            775.1048540589894
Number of train steps total  1788000
Number of env steps total    2385040
Number of rollouts total     0
Train Time (s)               147.29970602830872
(Previous) Eval Time (s)     12.99589961534366
Sample Time (s)              6.693660281598568
Epoch Time (s)               166.98926592525095
Total Train Time (s)         73724.4972257996
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:58:25.985341 UTC | [2020_01_10_09_29_40] Iteration #446 | Epoch Duration: 167.07254838943481
2020-01-11 05:58:25.985479 UTC | [2020_01_10_09_29_40] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056022055
Z variance train             0.02246655
KL Divergence                7.6600313
KL Loss                      0.76600313
QF Loss                      42.102455
VF Loss                      20.144722
Policy Loss                  -1614.7404
Q Predictions Mean           1614.7308
Q Predictions Std            273.71017
Q Predictions Max            1820.8546
Q Predictions Min            109.688156
V Predictions Mean           1615.2933
V Predictions Std            270.38196
V Predictions Max            1820.1743
V Predictions Min            114.013306
Log Pis Mean                 -0.2132928
Log Pis Std                  1.8300837
Log Pis Max                  6.181529
Log Pis Min                  -5.1238027
Policy mu Mean               0.020780277
Policy mu Std                0.88403773
Policy mu Max                1.8635321
Policy mu Min                -2.5390172
Policy log std Mean          -0.48014975
Policy log std Std           0.15711042
Policy log std Max           -0.044980645
Policy log std Min           -1.096631
Z mean eval                  0.017982827
Z variance eval              0.026521161
total_rewards                [1403.77233163 1291.2448802  1063.02910075 3020.88902191 3338.54598752
  892.73651483 3336.16489658 3351.19312843 3337.68105655 3365.84266144]
total_rewards_mean           2440.1099579856836
total_rewards_std            1054.736765011566
total_rewards_max            3365.842661444612
total_rewards_min            892.7365148265172
Number of train steps total  1792000
Number of env steps total    2394672
Number of rollouts total     0
Train Time (s)               146.94600070500746
(Previous) Eval Time (s)     13.40536033315584
Sample Time (s)              6.451255735009909
Epoch Time (s)               166.8026167731732
Total Train Time (s)         73891.38504470186
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:01:12.879179 UTC | [2020_01_10_09_29_40] Iteration #447 | Epoch Duration: 166.8936002254486
2020-01-11 06:01:12.879351 UTC | [2020_01_10_09_29_40] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017996255
Z variance train             0.026507456
KL Divergence                7.4075704
KL Loss                      0.74075705
QF Loss                      50.424797
VF Loss                      59.39091
Policy Loss                  -1608.441
Q Predictions Mean           1607.2382
Q Predictions Std            247.73708
Q Predictions Max            1825.7925
Q Predictions Min            123.40926
V Predictions Mean           1611.0718
V Predictions Std            245.31587
V Predictions Max            1828.6274
V Predictions Min            184.5328
Log Pis Mean                 -0.3925864
Log Pis Std                  1.6654418
Log Pis Max                  5.483342
Log Pis Min                  -4.155354
Policy mu Mean               -0.13892163
Policy mu Std                0.84954894
Policy mu Max                1.4834561
Policy mu Min                -2.6260977
Policy log std Mean          -0.46093607
Policy log std Std           0.16740738
Policy log std Max           0.25496534
Policy log std Min           -0.94890404
Z mean eval                  0.12884383
Z variance eval              0.021832343
total_rewards                [ 887.94478046 2326.0458679   196.27731228  438.64581317 2392.29557589
  835.03854744  796.9136855  1698.81711158  906.18044381  885.00316185]
total_rewards_mean           1136.3162299875103
total_rewards_std            711.5853140836432
total_rewards_max            2392.295575893182
total_rewards_min            196.2773122846267
Number of train steps total  1796000
Number of env steps total    2403447
Number of rollouts total     0
Train Time (s)               145.77057713270187
(Previous) Eval Time (s)     7.591639113146812
Sample Time (s)              6.4537587142549455
Epoch Time (s)               159.81597496010363
Total Train Time (s)         74051.27996783517
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:03:52.777415 UTC | [2020_01_10_09_29_40] Iteration #448 | Epoch Duration: 159.8979549407959
2020-01-11 06:03:52.777551 UTC | [2020_01_10_09_29_40] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12983625
Z variance train             0.021846216
KL Divergence                8.237324
KL Loss                      0.8237324
QF Loss                      42.83579
VF Loss                      75.12888
Policy Loss                  -1616.5886
Q Predictions Mean           1617.9647
Q Predictions Std            209.53412
Q Predictions Max            1828.0829
Q Predictions Min            20.250427
V Predictions Mean           1616.1476
V Predictions Std            205.14622
V Predictions Max            1819.2557
V Predictions Min            52.412163
Log Pis Mean                 -0.48968637
Log Pis Std                  1.6409214
Log Pis Max                  4.8076754
Log Pis Min                  -5.749201
Policy mu Mean               0.02588538
Policy mu Std                0.8236289
Policy mu Max                1.9437578
Policy mu Min                -2.3469112
Policy log std Mean          -0.4688402
Policy log std Std           0.16478328
Policy log std Max           0.06638348
Policy log std Min           -0.948071
Z mean eval                  0.082186036
Z variance eval              0.01953299
total_rewards                [1520.89472048 3321.91619552 2081.17612106  152.52794591 2640.87506246
 2077.63409598  935.42647056 1233.61324022  884.78190968  173.41551794]
total_rewards_mean           1502.2261279792995
total_rewards_std            981.6564672143752
total_rewards_max            3321.916195518297
total_rewards_min            152.52794590698787
Number of train steps total  1800000
Number of env steps total    2412032
Number of rollouts total     0
Train Time (s)               147.46218914585188
(Previous) Eval Time (s)     8.51364903524518
Sample Time (s)              6.970506550278515
Epoch Time (s)               162.94634473137558
Total Train Time (s)         74214.31514679082
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:06:35.820870 UTC | [2020_01_10_09_29_40] Iteration #449 | Epoch Duration: 163.04322004318237
2020-01-11 06:06:35.821053 UTC | [2020_01_10_09_29_40] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08217315
Z variance train             0.019538905
KL Divergence                7.691188
KL Loss                      0.7691188
QF Loss                      97.14798
VF Loss                      27.47536
Policy Loss                  -1622.957
Q Predictions Mean           1621.0597
Q Predictions Std            231.12552
Q Predictions Max            1839.825
Q Predictions Min            44.97312
V Predictions Mean           1623.3047
V Predictions Std            228.99907
V Predictions Max            1840.5305
V Predictions Min            69.21772
Log Pis Mean                 -0.28705233
Log Pis Std                  1.832733
Log Pis Max                  7.5451903
Log Pis Min                  -5.5024424
Policy mu Mean               -0.00017607708
Policy mu Std                0.88192433
Policy mu Max                2.873956
Policy mu Min                -2.6390843
Policy log std Mean          -0.44468522
Policy log std Std           0.18608178
Policy log std Max           0.22891787
Policy log std Min           -0.9463401
Z mean eval                  0.051038645
Z variance eval              0.023323674
total_rewards                [3324.59382685 3309.12627837 3333.99273516 1964.68155406 2932.51940346
 1560.89309922 1069.20303954 3295.31004538  938.95399071 2687.25359617]
total_rewards_mean           2441.652756891046
total_rewards_std            922.1348813980179
total_rewards_max            3333.992735155957
total_rewards_min            938.9539907118433
Number of train steps total  1804000
Number of env steps total    2420445
Number of rollouts total     0
Train Time (s)               146.55281446920708
(Previous) Eval Time (s)     15.670975712593645
Sample Time (s)              6.283939774148166
Epoch Time (s)               168.5077299559489
Total Train Time (s)         74382.90450567193
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:09:24.414746 UTC | [2020_01_10_09_29_40] Iteration #450 | Epoch Duration: 168.59357738494873
2020-01-11 06:09:24.414898 UTC | [2020_01_10_09_29_40] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050742935
Z variance train             0.023315879
KL Divergence                7.2390785
KL Loss                      0.7239079
QF Loss                      2910.7773
VF Loss                      9.525755
Policy Loss                  -1593.4354
Q Predictions Mean           1593.2545
Q Predictions Std            249.61394
Q Predictions Max            1817.1932
Q Predictions Min            41.00701
V Predictions Mean           1593.1294
V Predictions Std            248.06749
V Predictions Max            1820.3043
V Predictions Min            62.738976
Log Pis Mean                 -0.3334463
Log Pis Std                  1.7399158
Log Pis Max                  6.26593
Log Pis Min                  -3.9667299
Policy mu Mean               -0.05297577
Policy mu Std                0.8237525
Policy mu Max                1.9344879
Policy mu Min                -2.82108
Policy log std Mean          -0.46676484
Policy log std Std           0.17192583
Policy log std Max           0.37657225
Policy log std Min           -1.0544958
Z mean eval                  0.118107155
Z variance eval              0.028074097
total_rewards                [ 873.07221155 3341.05668044 1089.4230712   197.95468349  190.20722766
  204.9995476  2289.92329378  918.47017258 1480.3988809   177.48078496]
total_rewards_mean           1076.2986554156473
total_rewards_std            997.7662845399052
total_rewards_max            3341.0566804402406
total_rewards_min            177.48078496081155
Number of train steps total  1808000
Number of env steps total    2429221
Number of rollouts total     0
Train Time (s)               144.86052687140182
(Previous) Eval Time (s)     6.012652701698244
Sample Time (s)              6.626796152908355
Epoch Time (s)               157.49997572600842
Total Train Time (s)         74540.48646924272
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:12:02.000598 UTC | [2020_01_10_09_29_40] Iteration #451 | Epoch Duration: 157.58559679985046
2020-01-11 06:12:02.000775 UTC | [2020_01_10_09_29_40] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.119201995
Z variance train             0.028052857
KL Divergence                6.9963646
KL Loss                      0.69963646
QF Loss                      192.96512
VF Loss                      55.765915
Policy Loss                  -1595.8153
Q Predictions Mean           1596.473
Q Predictions Std            296.32257
Q Predictions Max            1845.0009
Q Predictions Min            159.69513
V Predictions Mean           1589.5544
V Predictions Std            292.1909
V Predictions Max            1832.5007
V Predictions Min            184.99261
Log Pis Mean                 -0.41181868
Log Pis Std                  1.8713424
Log Pis Max                  6.688272
Log Pis Min                  -5.189434
Policy mu Mean               -0.01938265
Policy mu Std                0.8444893
Policy mu Max                2.8553984
Policy mu Min                -2.6714513
Policy log std Mean          -0.4672726
Policy log std Std           0.15554708
Policy log std Max           0.12893337
Policy log std Min           -1.2335865
Z mean eval                  0.11504352
Z variance eval              0.027403265
total_rewards                [ 857.01134163 1222.99767263 3198.42424106  938.13268403  920.24272518
 3351.72837331 1209.3659766  3351.07803905 1646.47737435  944.60154267]
total_rewards_mean           1764.005997050072
total_rewards_std            1029.53438013544
total_rewards_max            3351.7283733149306
total_rewards_min            857.0113416253881
Number of train steps total  1812000
Number of env steps total    2437884
Number of rollouts total     0
Train Time (s)               147.05591322202235
(Previous) Eval Time (s)     11.388598803896457
Sample Time (s)              6.542368341237307
Epoch Time (s)               164.98688036715612
Total Train Time (s)         74705.5543032391
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:14:47.075108 UTC | [2020_01_10_09_29_40] Iteration #452 | Epoch Duration: 165.0742244720459
2020-01-11 06:14:47.075249 UTC | [2020_01_10_09_29_40] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11596303
Z variance train             0.027339464
KL Divergence                6.8672214
KL Loss                      0.68672216
QF Loss                      151.18585
VF Loss                      46.305363
Policy Loss                  -1596.1738
Q Predictions Mean           1594.0919
Q Predictions Std            265.22675
Q Predictions Max            1813.371
Q Predictions Min            64.20951
V Predictions Mean           1600.2666
V Predictions Std            264.25244
V Predictions Max            1821.8145
V Predictions Min            97.49499
Log Pis Mean                 -0.32676315
Log Pis Std                  1.9868709
Log Pis Max                  7.141814
Log Pis Min                  -5.4966145
Policy mu Mean               -0.16328658
Policy mu Std                0.8477921
Policy mu Max                1.5443577
Policy mu Min                -2.35863
Policy log std Mean          -0.48622584
Policy log std Std           0.15067242
Policy log std Max           -0.015428007
Policy log std Min           -0.9377104
Z mean eval                  0.18911146
Z variance eval              0.03148862
total_rewards                [3250.30776179 1133.14414616  900.21593297  856.2411154  1172.72137174
 2368.38338563 1394.38433724 3174.84367857  872.82299958 1127.3128404 ]
total_rewards_mean           1625.0377569485192
total_rewards_std            895.8619441653351
total_rewards_max            3250.3077617918566
total_rewards_min            856.2411154017201
Number of train steps total  1816000
Number of env steps total    2445231
Number of rollouts total     0
Train Time (s)               147.8269783006981
(Previous) Eval Time (s)     10.707512664142996
Sample Time (s)              5.445696804206818
Epoch Time (s)               163.98018776904792
Total Train Time (s)         74869.61462724954
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:17:31.143243 UTC | [2020_01_10_09_29_40] Iteration #453 | Epoch Duration: 164.06788659095764
2020-01-11 06:17:31.143433 UTC | [2020_01_10_09_29_40] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18872097
Z variance train             0.031629317
KL Divergence                7.177128
KL Loss                      0.7177128
QF Loss                      109.75473
VF Loss                      56.27864
Policy Loss                  -1607.8405
Q Predictions Mean           1607.8376
Q Predictions Std            215.18037
Q Predictions Max            1805.7555
Q Predictions Min            232.00171
V Predictions Mean           1601.9792
V Predictions Std            212.09525
V Predictions Max            1802.1185
V Predictions Min            282.62756
Log Pis Mean                 -0.30748594
Log Pis Std                  1.7722429
Log Pis Max                  6.5015626
Log Pis Min                  -4.3814583
Policy mu Mean               -0.060148343
Policy mu Std                0.84388024
Policy mu Max                2.0901086
Policy mu Min                -2.8872247
Policy log std Mean          -0.44287828
Policy log std Std           0.17510709
Policy log std Max           -0.008261532
Policy log std Min           -1.1535953
Z mean eval                  0.040411912
Z variance eval              0.020860106
total_rewards                [ 991.4055267   856.57228725  890.32149486 1036.10530064 1438.58683712
  923.61092396  966.13712342  930.52633809 1118.94265215 1902.66728196]
total_rewards_mean           1105.4875766159334
total_rewards_std            309.1641340685487
total_rewards_max            1902.6672819606213
total_rewards_min            856.5722872547263
Number of train steps total  1820000
Number of env steps total    2454278
Number of rollouts total     0
Train Time (s)               145.65198742970824
(Previous) Eval Time (s)     7.354038924910128
Sample Time (s)              6.52876074751839
Epoch Time (s)               159.53478710213676
Total Train Time (s)         75029.23306052061
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:20:10.765344 UTC | [2020_01_10_09_29_40] Iteration #454 | Epoch Duration: 159.62179112434387
2020-01-11 06:20:10.765476 UTC | [2020_01_10_09_29_40] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039961927
Z variance train             0.020866698
KL Divergence                7.859415
KL Loss                      0.78594154
QF Loss                      26.397257
VF Loss                      17.551971
Policy Loss                  -1607.0986
Q Predictions Mean           1607.0872
Q Predictions Std            238.31288
Q Predictions Max            1816.8318
Q Predictions Min            36.058918
V Predictions Mean           1608.4255
V Predictions Std            237.65717
V Predictions Max            1818.1954
V Predictions Min            12.966194
Log Pis Mean                 -0.22859395
Log Pis Std                  1.7582908
Log Pis Max                  7.5055933
Log Pis Min                  -5.7234583
Policy mu Mean               -0.024069862
Policy mu Std                0.84567523
Policy mu Max                1.7432483
Policy mu Min                -2.5495446
Policy log std Mean          -0.47727394
Policy log std Std           0.17235312
Policy log std Max           0.23634529
Policy log std Min           -1.3119614
Z mean eval                  0.07808298
Z variance eval              0.019939218
total_rewards                [1322.16636862 1023.787565    872.62745318 3187.18561256  861.31406633
 1402.34697625  894.26813269 1363.75422193 1008.76135361 1115.07422568]
total_rewards_mean           1305.1285975842686
total_rewards_std            656.6017936406669
total_rewards_max            3187.185612561301
total_rewards_min            861.3140663282124
Number of train steps total  1824000
Number of env steps total    2462764
Number of rollouts total     0
Train Time (s)               147.25811631930992
(Previous) Eval Time (s)     8.572511453647166
Sample Time (s)              6.386983732692897
Epoch Time (s)               162.21761150564998
Total Train Time (s)         75191.5388827459
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:22:53.074365 UTC | [2020_01_10_09_29_40] Iteration #455 | Epoch Duration: 162.30879759788513
2020-01-11 06:22:53.074528 UTC | [2020_01_10_09_29_40] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07773326
Z variance train             0.019935694
KL Divergence                7.692713
KL Loss                      0.7692713
QF Loss                      69.93196
VF Loss                      25.856022
Policy Loss                  -1621.9302
Q Predictions Mean           1618.9075
Q Predictions Std            253.88808
Q Predictions Max            1816.6554
Q Predictions Min            158.61066
V Predictions Mean           1624.2039
V Predictions Std            249.63295
V Predictions Max            1819.9797
V Predictions Min            196.38701
Log Pis Mean                 -0.27723598
Log Pis Std                  1.8298547
Log Pis Max                  8.175115
Log Pis Min                  -5.2002296
Policy mu Mean               -0.04906735
Policy mu Std                0.8625092
Policy mu Max                2.2614841
Policy mu Min                -2.6842422
Policy log std Mean          -0.4888852
Policy log std Std           0.15902162
Policy log std Max           0.07243496
Policy log std Min           -1.0430615
Z mean eval                  0.07644423
Z variance eval              0.023579288
total_rewards                [1233.08150908 1594.78964834 1432.56999543  878.74256264 1066.80030415
 1102.33953863  389.67003876 1418.14622916 1014.96389044  799.59626022]
total_rewards_mean           1093.0699976858998
total_rewards_std            335.555033832674
total_rewards_max            1594.789648341489
total_rewards_min            389.6700387609782
Number of train steps total  1828000
Number of env steps total    2472478
Number of rollouts total     0
Train Time (s)               146.4080397291109
(Previous) Eval Time (s)     6.540736919734627
Sample Time (s)              6.679330363869667
Epoch Time (s)               159.6281070127152
Total Train Time (s)         75351.25042532943
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:25:32.791800 UTC | [2020_01_10_09_29_40] Iteration #456 | Epoch Duration: 159.71715378761292
2020-01-11 06:25:32.792020 UTC | [2020_01_10_09_29_40] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07655717
Z variance train             0.023574585
KL Divergence                7.479171
KL Loss                      0.7479171
QF Loss                      41.16339
VF Loss                      26.598345
Policy Loss                  -1585.6611
Q Predictions Mean           1585.443
Q Predictions Std            212.45685
Q Predictions Max            1819.6748
Q Predictions Min            425.16843
V Predictions Mean           1587.7601
V Predictions Std            212.09631
V Predictions Max            1817.5618
V Predictions Min            449.13916
Log Pis Mean                 -0.38276508
Log Pis Std                  1.7333199
Log Pis Max                  6.499592
Log Pis Min                  -4.523863
Policy mu Mean               0.024580933
Policy mu Std                0.83517194
Policy mu Max                1.8407944
Policy mu Min                -2.4176617
Policy log std Mean          -0.47743264
Policy log std Std           0.16211756
Policy log std Max           0.23097563
Policy log std Min           -1.0316415
Z mean eval                  0.07723802
Z variance eval              0.026930083
total_rewards                [1222.28117457  832.92994249  955.68549048  790.95333833 1320.94433294
 2522.06963365 1100.19556225  871.40383626 1006.73265935  785.16158057]
total_rewards_mean           1140.835755089612
total_rewards_std            491.64181492031184
total_rewards_max            2522.0696336482233
total_rewards_min            785.1615805716663
Number of train steps total  1832000
Number of env steps total    2481214
Number of rollouts total     0
Train Time (s)               146.82257189927623
(Previous) Eval Time (s)     7.476237257011235
Sample Time (s)              6.524094271939248
Epoch Time (s)               160.8229034282267
Total Train Time (s)         75512.14826959278
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:28:13.692834 UTC | [2020_01_10_09_29_40] Iteration #457 | Epoch Duration: 160.90067672729492
2020-01-11 06:28:13.692968 UTC | [2020_01_10_09_29_40] Iteration #457 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07773218
Z variance train             0.026937108
KL Divergence                6.6918125
KL Loss                      0.6691813
QF Loss                      144.6658
VF Loss                      117.59765
Policy Loss                  -1587.4698
Q Predictions Mean           1588.5332
Q Predictions Std            288.30377
Q Predictions Max            1824.0532
Q Predictions Min            105.6413
V Predictions Mean           1577.7612
V Predictions Std            282.3334
V Predictions Max            1813.4487
V Predictions Min            144.2931
Log Pis Mean                 -0.39583063
Log Pis Std                  1.8890402
Log Pis Max                  4.842492
Log Pis Min                  -8.084431
Policy mu Mean               0.020980455
Policy mu Std                0.8479423
Policy mu Max                2.4264991
Policy mu Min                -2.5094686
Policy log std Mean          -0.47571364
Policy log std Std           0.16861172
Policy log std Max           0.089800715
Policy log std Min           -0.9948144
Z mean eval                  0.15229538
Z variance eval              0.028136661
total_rewards                [ 950.01495326  924.3872429   786.2843021   565.33366209  880.7561167
 1043.06770786  900.93551496  865.00708102  893.97819404  869.1554589 ]
total_rewards_mean           867.8920233814581
total_rewards_std            118.64718822014333
total_rewards_max            1043.0677078572207
total_rewards_min            565.3336620894227
Number of train steps total  1836000
Number of env steps total    2489501
Number of rollouts total     0
Train Time (s)               147.07936513004825
(Previous) Eval Time (s)     5.601690111216158
Sample Time (s)              6.534887902438641
Epoch Time (s)               159.21594314370304
Total Train Time (s)         75671.68677632976
Epoch                        458
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:30:53.236887 UTC | [2020_01_10_09_29_40] Iteration #458 | Epoch Duration: 159.54382157325745
2020-01-11 06:30:53.237066 UTC | [2020_01_10_09_29_40] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15281749
Z variance train             0.028104931
KL Divergence                6.8157644
KL Loss                      0.68157643
QF Loss                      129.62141
VF Loss                      17.140564
Policy Loss                  -1608.6929
Q Predictions Mean           1607.5863
Q Predictions Std            215.6442
Q Predictions Max            1820.5739
Q Predictions Min            322.02435
V Predictions Mean           1608.5352
V Predictions Std            214.6456
V Predictions Max            1825.9421
V Predictions Min            351.24518
Log Pis Mean                 -0.35446218
Log Pis Std                  1.5874996
Log Pis Max                  4.836237
Log Pis Min                  -6.3445625
Policy mu Mean               0.04381149
Policy mu Std                0.830107
Policy mu Max                2.1793854
Policy mu Min                -2.4441495
Policy log std Mean          -0.4518032
Policy log std Std           0.15491095
Policy log std Max           0.3086673
Policy log std Min           -0.9591892
Z mean eval                  0.16849345
Z variance eval              0.028726975
total_rewards                [1853.99854    1041.10783083  997.52606394 1026.41861708 1091.66341253
 3315.92642622  894.40963722 1225.91767125 1203.46583959 1132.181138  ]
total_rewards_mean           1378.2615176670274
total_rewards_std            692.3774533565048
total_rewards_max            3315.926426219294
total_rewards_min            894.4096372182964
Number of train steps total  1840000
Number of env steps total    2496679
Number of rollouts total     0
Train Time (s)               147.48625132301822
(Previous) Eval Time (s)     8.554220089688897
Sample Time (s)              6.514002553187311
Epoch Time (s)               162.55447396589443
Total Train Time (s)         75834.32406439772
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:33:35.877174 UTC | [2020_01_10_09_29_40] Iteration #459 | Epoch Duration: 162.63999223709106
2020-01-11 06:33:35.877310 UTC | [2020_01_10_09_29_40] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16622338
Z variance train             0.028811354
KL Divergence                6.839282
KL Loss                      0.6839282
QF Loss                      137.08372
VF Loss                      51.283783
Policy Loss                  -1598.8767
Q Predictions Mean           1600.9143
Q Predictions Std            247.5581
Q Predictions Max            1829.8046
Q Predictions Min            69.86646
V Predictions Mean           1600.6987
V Predictions Std            246.48387
V Predictions Max            1836.1498
V Predictions Min            73.23238
Log Pis Mean                 -0.2752613
Log Pis Std                  1.9641888
Log Pis Max                  8.854668
Log Pis Min                  -5.3517847
Policy mu Mean               -0.17035125
Policy mu Std                0.8520022
Policy mu Max                2.12343
Policy mu Min                -2.9063702
Policy log std Mean          -0.47221196
Policy log std Std           0.17728724
Policy log std Max           0.1304551
Policy log std Min           -0.997794
Z mean eval                  0.070636034
Z variance eval              0.031154146
total_rewards                [1007.63934355 1057.70173936 1350.87666517 2351.06610165 3360.42530967
  788.85302301 1008.815802   1004.44181597 1081.27048907 1861.91297658]
total_rewards_mean           1487.3003266014516
total_rewards_std            770.9119807430873
total_rewards_max            3360.425309672408
total_rewards_min            788.8530230118473
Number of train steps total  1844000
Number of env steps total    2505483
Number of rollouts total     0
Train Time (s)               147.05863691819832
(Previous) Eval Time (s)     9.589360052719712
Sample Time (s)              6.474202756769955
Epoch Time (s)               163.12219972768798
Total Train Time (s)         75997.52545495518
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:36:19.081720 UTC | [2020_01_10_09_29_40] Iteration #460 | Epoch Duration: 163.20432090759277
2020-01-11 06:36:19.081859 UTC | [2020_01_10_09_29_40] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07075763
Z variance train             0.03109304
KL Divergence                6.40186
KL Loss                      0.640186
QF Loss                      34.631737
VF Loss                      20.053364
Policy Loss                  -1605.9525
Q Predictions Mean           1603.9279
Q Predictions Std            261.47705
Q Predictions Max            1811.9869
Q Predictions Min            14.458418
V Predictions Mean           1608.3113
V Predictions Std            258.10004
V Predictions Max            1815.8033
V Predictions Min            85.56579
Log Pis Mean                 -0.26770955
Log Pis Std                  1.8064957
Log Pis Max                  5.7365446
Log Pis Min                  -4.118254
Policy mu Mean               -0.027127445
Policy mu Std                0.8587392
Policy mu Max                2.0561328
Policy mu Min                -2.443563
Policy log std Mean          -0.49809292
Policy log std Std           0.16377111
Policy log std Max           0.2807448
Policy log std Min           -1.1338344
Z mean eval                  0.033844672
Z variance eval              0.024707658
total_rewards                [1451.93162875 2258.93630052 2762.034034   1908.87355657 1416.39486359
 3349.93335729 1234.18849784 1663.74952397 1888.80213988 1552.65900803]
total_rewards_mean           1948.750291043633
total_rewards_std            632.8575755496464
total_rewards_max            3349.933357290299
total_rewards_min            1234.1884978383175
Number of train steps total  1848000
Number of env steps total    2513906
Number of rollouts total     0
Train Time (s)               145.4569273199886
(Previous) Eval Time (s)     12.748890282120556
Sample Time (s)              6.634840724058449
Epoch Time (s)               164.8406583261676
Total Train Time (s)         76162.44512022845
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:39:04.004585 UTC | [2020_01_10_09_29_40] Iteration #461 | Epoch Duration: 164.9226372241974
2020-01-11 06:39:04.004720 UTC | [2020_01_10_09_29_40] Iteration #461 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036233265
Z variance train             0.024735961
KL Divergence                7.0744615
KL Loss                      0.70744616
QF Loss                      107.799614
VF Loss                      158.50165
Policy Loss                  -1581.1641
Q Predictions Mean           1578.2756
Q Predictions Std            286.35413
Q Predictions Max            1829.8641
Q Predictions Min            99.093475
V Predictions Mean           1573.6069
V Predictions Std            282.52216
V Predictions Max            1824.8469
V Predictions Min            98.83743
Log Pis Mean                 -0.11256993
Log Pis Std                  1.9469179
Log Pis Max                  7.6979346
Log Pis Min                  -4.7939777
Policy mu Mean               -0.11661377
Policy mu Std                0.90484554
Policy mu Max                2.1359599
Policy mu Min                -2.760757
Policy log std Mean          -0.48632786
Policy log std Std           0.16840766
Policy log std Max           0.08244473
Policy log std Min           -1.1031263
Z mean eval                  0.060382463
Z variance eval              0.020471545
total_rewards                [ 983.6094424   800.00160464  819.77217987 1147.55055997 1222.4386593
 1219.98686538 1163.37650034  870.38678829 1036.89249415  843.64985711]
total_rewards_mean           1010.7664951457552
total_rewards_std            161.4103888096566
total_rewards_max            1222.4386592955157
total_rewards_min            800.0016046388117
Number of train steps total  1852000
Number of env steps total    2523131
Number of rollouts total     0
Train Time (s)               145.78307771496475
(Previous) Eval Time (s)     5.3782452922314405
Sample Time (s)              6.445812032092363
Epoch Time (s)               157.60713503928855
Total Train Time (s)         76320.14147972642
Epoch                        462
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:41:41.704916 UTC | [2020_01_10_09_29_40] Iteration #462 | Epoch Duration: 157.70009756088257
2020-01-11 06:41:41.705097 UTC | [2020_01_10_09_29_40] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062074292
Z variance train             0.020493276
KL Divergence                7.6002626
KL Loss                      0.7600263
QF Loss                      65.39641
VF Loss                      22.91488
Policy Loss                  -1573.0427
Q Predictions Mean           1571.147
Q Predictions Std            304.22662
Q Predictions Max            1822.7952
Q Predictions Min            69.71041
V Predictions Mean           1571.8337
V Predictions Std            303.91855
V Predictions Max            1825.9038
V Predictions Min            91.960594
Log Pis Mean                 -0.5289959
Log Pis Std                  1.8820624
Log Pis Max                  6.033803
Log Pis Min                  -6.1860123
Policy mu Mean               0.0053218217
Policy mu Std                0.8560412
Policy mu Max                1.7073737
Policy mu Min                -2.7296066
Policy log std Mean          -0.4587897
Policy log std Std           0.17347421
Policy log std Max           0.051590234
Policy log std Min           -0.97869617
Z mean eval                  0.052021258
Z variance eval              0.019878384
total_rewards                [1122.80281791  799.08389963 1297.40493017  936.56188175  972.53491012
  768.73879225 1317.59238478  799.35104718 1204.28840769 1043.20105242]
total_rewards_mean           1026.1560123888637
total_rewards_std            194.946560863388
total_rewards_max            1317.592384778939
total_rewards_min            768.7387922496257
Number of train steps total  1856000
Number of env steps total    2531343
Number of rollouts total     0
Train Time (s)               145.38433530414477
(Previous) Eval Time (s)     6.735305950976908
Sample Time (s)              6.7766721858642995
Epoch Time (s)               158.89631344098598
Total Train Time (s)         76479.12295905827
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:44:20.690557 UTC | [2020_01_10_09_29_40] Iteration #463 | Epoch Duration: 158.98533701896667
2020-01-11 06:44:20.690734 UTC | [2020_01_10_09_29_40] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052451402
Z variance train             0.019845096
KL Divergence                7.4972067
KL Loss                      0.7497207
QF Loss                      54.02442
VF Loss                      27.649467
Policy Loss                  -1600.6884
Q Predictions Mean           1601.6345
Q Predictions Std            240.57292
Q Predictions Max            1823.7804
Q Predictions Min            67.02008
V Predictions Mean           1602.6356
V Predictions Std            238.55577
V Predictions Max            1823.6409
V Predictions Min            93.25859
Log Pis Mean                 -0.40685445
Log Pis Std                  1.8327905
Log Pis Max                  6.3650174
Log Pis Min                  -5.190995
Policy mu Mean               0.009126137
Policy mu Std                0.8258318
Policy mu Max                2.78432
Policy mu Min                -2.2510502
Policy log std Mean          -0.4522048
Policy log std Std           0.1686838
Policy log std Max           0.15019336
Policy log std Min           -0.8797208
Z mean eval                  0.07770093
Z variance eval              0.019292906
total_rewards                [ 748.02628877  779.11112837  581.37780708 1145.19003794  765.05375422
  983.19999033  924.55483984 3355.59527704 1525.38123484 3349.65389731]
total_rewards_mean           1415.7144255746257
total_rewards_std            999.3660207952755
total_rewards_max            3355.595277044391
total_rewards_min            581.3778070843167
Number of train steps total  1860000
Number of env steps total    2539866
Number of rollouts total     0
Train Time (s)               144.27650493197143
(Previous) Eval Time (s)     9.157546095084399
Sample Time (s)              5.499172165058553
Epoch Time (s)               158.93322319211438
Total Train Time (s)         76638.14247559523
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:46:59.716583 UTC | [2020_01_10_09_29_40] Iteration #464 | Epoch Duration: 159.0257260799408
2020-01-11 06:46:59.716784 UTC | [2020_01_10_09_29_40] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07949987
Z variance train             0.019291671
KL Divergence                7.8226624
KL Loss                      0.78226626
QF Loss                      60.555252
VF Loss                      66.90411
Policy Loss                  -1619.9482
Q Predictions Mean           1618.9788
Q Predictions Std            225.9984
Q Predictions Max            1830.1124
Q Predictions Min            507.6173
V Predictions Mean           1614.8516
V Predictions Std            222.1081
V Predictions Max            1827.743
V Predictions Min            534.6394
Log Pis Mean                 -0.47613573
Log Pis Std                  1.7404788
Log Pis Max                  4.8629484
Log Pis Min                  -5.334032
Policy mu Mean               0.0014453158
Policy mu Std                0.82576776
Policy mu Max                2.5390365
Policy mu Min                -2.3927867
Policy log std Mean          -0.4804032
Policy log std Std           0.17050888
Policy log std Max           0.17010957
Policy log std Min           -1.1391811
Z mean eval                  0.066092774
Z variance eval              0.024599295
total_rewards                [1012.93313667 1389.73320369 2035.8995489  1214.56464436 1011.44844899
 3384.3843181  1649.55164098 3319.75812258 3437.83954537 2309.71402879]
total_rewards_mean           2076.5826638437266
total_rewards_std            939.5695816911015
total_rewards_max            3437.839545373675
total_rewards_min            1011.4484489909423
Number of train steps total  1864000
Number of env steps total    2550161
Number of rollouts total     0
Train Time (s)               146.3655360569246
(Previous) Eval Time (s)     13.433410276658833
Sample Time (s)              6.537255376111716
Epoch Time (s)               166.33620170969516
Total Train Time (s)         76804.56770675816
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:49:46.144613 UTC | [2020_01_10_09_29_40] Iteration #465 | Epoch Duration: 166.42770886421204
2020-01-11 06:49:46.144750 UTC | [2020_01_10_09_29_40] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06504464
Z variance train             0.024624445
KL Divergence                7.0064316
KL Loss                      0.7006432
QF Loss                      42.90432
VF Loss                      24.03995
Policy Loss                  -1595.8923
Q Predictions Mean           1595.4095
Q Predictions Std            278.3741
Q Predictions Max            1837.5223
Q Predictions Min            70.43451
V Predictions Mean           1597.7979
V Predictions Std            276.33328
V Predictions Max            1837.0367
V Predictions Min            89.79383
Log Pis Mean                 -0.17103653
Log Pis Std                  1.7443305
Log Pis Max                  6.2877016
Log Pis Min                  -6.035587
Policy mu Mean               -0.115695894
Policy mu Std                0.87531775
Policy mu Max                1.8276682
Policy mu Min                -2.5722494
Policy log std Mean          -0.48722506
Policy log std Std           0.17935272
Policy log std Max           0.11052495
Policy log std Min           -1.1391543
Z mean eval                  0.057049382
Z variance eval              0.028035456
total_rewards                [1912.81892271 1214.08505427 3099.31422294  962.72104248 1001.47464419
 3341.35035101 1188.05618647 1193.97929648 3387.06170633  892.92112379]
total_rewards_mean           1819.378255067392
total_rewards_std            991.8780009494948
total_rewards_max            3387.061706329014
total_rewards_min            892.9211237946887
Number of train steps total  1868000
Number of env steps total    2559545
Number of rollouts total     0
Train Time (s)               145.20239887805656
(Previous) Eval Time (s)     9.784585701767355
Sample Time (s)              6.647557817399502
Epoch Time (s)               161.6345423972234
Total Train Time (s)         76966.2849135208
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:52:27.872708 UTC | [2020_01_10_09_29_40] Iteration #466 | Epoch Duration: 161.7278175354004
2020-01-11 06:52:27.873051 UTC | [2020_01_10_09_29_40] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0566581
Z variance train             0.028019693
KL Divergence                7.1107335
KL Loss                      0.71107334
QF Loss                      66.33928
VF Loss                      36.413734
Policy Loss                  -1598.8431
Q Predictions Mean           1596.3984
Q Predictions Std            266.22095
Q Predictions Max            1840.7255
Q Predictions Min            199.86432
V Predictions Mean           1598.7283
V Predictions Std            259.01495
V Predictions Max            1829.3065
V Predictions Min            237.39406
Log Pis Mean                 -0.39680836
Log Pis Std                  1.7045966
Log Pis Max                  4.7988644
Log Pis Min                  -4.2285886
Policy mu Mean               0.006106397
Policy mu Std                0.8259317
Policy mu Max                1.6356485
Policy mu Min                -2.3880897
Policy log std Mean          -0.46657646
Policy log std Std           0.17609636
Policy log std Max           0.3287895
Policy log std Min           -1.2452239
Z mean eval                  0.058696467
Z variance eval              0.03461393
total_rewards                [3378.97086238  513.14892071 1022.90748856  723.39315194 3310.46911562
  713.87849054  747.85171041  499.89013418  475.57975613  754.85806816]
total_rewards_mean           1214.0947698630519
total_rewards_std            1076.2959436522126
total_rewards_max            3378.970862378052
total_rewards_min            475.5797561306682
Number of train steps total  1872000
Number of env steps total    2568631
Number of rollouts total     0
Train Time (s)               147.3170578512363
(Previous) Eval Time (s)     7.0372091378085315
Sample Time (s)              6.447527045384049
Epoch Time (s)               160.8017940344289
Total Train Time (s)         77127.20494005922
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:55:08.795814 UTC | [2020_01_10_09_29_40] Iteration #467 | Epoch Duration: 160.92254328727722
2020-01-11 06:55:08.795985 UTC | [2020_01_10_09_29_40] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05909584
Z variance train             0.03456859
KL Divergence                6.221858
KL Loss                      0.6221858
QF Loss                      45.22411
VF Loss                      46.509865
Policy Loss                  -1571.932
Q Predictions Mean           1570.9081
Q Predictions Std            279.68112
Q Predictions Max            1797.4675
Q Predictions Min            18.023
V Predictions Mean           1576.363
V Predictions Std            271.68344
V Predictions Max            1800.2174
V Predictions Min            26.024714
Log Pis Mean                 -0.35039842
Log Pis Std                  1.783373
Log Pis Max                  6.1214232
Log Pis Min                  -5.6345377
Policy mu Mean               -0.04443327
Policy mu Std                0.8406869
Policy mu Max                2.0792289
Policy mu Min                -2.4345348
Policy log std Mean          -0.4711813
Policy log std Std           0.17627646
Policy log std Max           0.25518638
Policy log std Min           -1.0610203
Z mean eval                  0.088373855
Z variance eval              0.030937862
total_rewards                [1061.85531876 1143.49454078 1097.58296273 1036.50441814 1697.73570985
 1064.74301042 3007.67664191 3281.11903172 1194.48473798 1212.16583729]
total_rewards_mean           1579.7362209592416
total_rewards_std            805.1376206160194
total_rewards_max            3281.1190317222454
total_rewards_min            1036.5044181383525
Number of train steps total  1876000
Number of env steps total    2577333
Number of rollouts total     0
Train Time (s)               146.16464805370197
(Previous) Eval Time (s)     10.504645169712603
Sample Time (s)              7.861548684537411
Epoch Time (s)               164.53084190795198
Total Train Time (s)         77291.81557883695
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:57:53.409967 UTC | [2020_01_10_09_29_40] Iteration #468 | Epoch Duration: 164.61386895179749
2020-01-11 06:57:53.410116 UTC | [2020_01_10_09_29_40] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.091775365
Z variance train             0.030923318
KL Divergence                6.4037666
KL Loss                      0.6403767
QF Loss                      66.51097
VF Loss                      50.95457
Policy Loss                  -1626.3086
Q Predictions Mean           1626.8759
Q Predictions Std            211.56058
Q Predictions Max            1823.9948
Q Predictions Min            57.007904
V Predictions Mean           1629.2119
V Predictions Std            210.45605
V Predictions Max            1816.4636
V Predictions Min            66.8843
Log Pis Mean                 -0.29212832
Log Pis Std                  1.7996182
Log Pis Max                  6.3359585
Log Pis Min                  -4.5989704
Policy mu Mean               0.09947148
Policy mu Std                0.8894536
Policy mu Max                2.7249475
Policy mu Min                -2.49583
Policy log std Mean          -0.49972394
Policy log std Std           0.16394956
Policy log std Max           0.06666243
Policy log std Min           -1.0125433
Z mean eval                  0.016700406
Z variance eval              0.02052413
total_rewards                [1713.90714665 2077.13125358 1711.20811143  889.82772567 2928.58782015
  765.21275745  982.81092679  882.53649429  867.77796026  951.02764875]
total_rewards_mean           1377.00278450206
total_rewards_std            676.3925777047826
total_rewards_max            2928.5878201492305
total_rewards_min            765.2127574544971
Number of train steps total  1880000
Number of env steps total    2587538
Number of rollouts total     0
Train Time (s)               147.25206401292235
(Previous) Eval Time (s)     7.678783184848726
Sample Time (s)              6.4742018026299775
Epoch Time (s)               161.40504900040105
Total Train Time (s)         77453.30365864513
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:00:34.907406 UTC | [2020_01_10_09_29_40] Iteration #469 | Epoch Duration: 161.49718832969666
2020-01-11 07:00:34.907587 UTC | [2020_01_10_09_29_40] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016360763
Z variance train             0.020527368
KL Divergence                7.708251
KL Loss                      0.7708251
QF Loss                      65.76316
VF Loss                      45.465015
Policy Loss                  -1615.4834
Q Predictions Mean           1615.4905
Q Predictions Std            233.10097
Q Predictions Max            1826.8663
Q Predictions Min            -12.153936
V Predictions Mean           1613.8184
V Predictions Std            230.88795
V Predictions Max            1830.28
V Predictions Min            41.39949
Log Pis Mean                 -0.30143952
Log Pis Std                  1.7359151
Log Pis Max                  5.90088
Log Pis Min                  -4.8392067
Policy mu Mean               0.002708954
Policy mu Std                0.8403044
Policy mu Max                2.3905513
Policy mu Min                -2.4200602
Policy log std Mean          -0.4634842
Policy log std Std           0.17904164
Policy log std Max           0.24563962
Policy log std Min           -1.2840852
Z mean eval                  0.087850556
Z variance eval              0.025565863
total_rewards                [1863.33878908  998.36877325 1369.84681834 1691.92393935 1403.67707476
 1716.67677962 1041.38357898 1494.45855282  976.89901714 1239.3280581 ]
total_rewards_mean           1379.5901381446265
total_rewards_std            300.1015537707297
total_rewards_max            1863.338789079415
total_rewards_min            976.8990171356381
Number of train steps total  1884000
Number of env steps total    2595962
Number of rollouts total     0
Train Time (s)               145.5814382499084
(Previous) Eval Time (s)     8.793469660915434
Sample Time (s)              6.487275045365095
Epoch Time (s)               160.86218295618892
Total Train Time (s)         77614.25511956261
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:03:15.867425 UTC | [2020_01_10_09_29_40] Iteration #470 | Epoch Duration: 160.95972633361816
2020-01-11 07:03:15.867563 UTC | [2020_01_10_09_29_40] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08805013
Z variance train             0.025539268
KL Divergence                7.705931
KL Loss                      0.7705931
QF Loss                      47.179222
VF Loss                      54.634426
Policy Loss                  -1644.5854
Q Predictions Mean           1644.4701
Q Predictions Std            154.52103
Q Predictions Max            1819.0316
Q Predictions Min            958.9858
V Predictions Mean           1643.6611
V Predictions Std            155.92162
V Predictions Max            1828.3744
V Predictions Min            976.0941
Log Pis Mean                 -0.28108433
Log Pis Std                  1.6556283
Log Pis Max                  4.5632963
Log Pis Min                  -4.69589
Policy mu Mean               0.024101838
Policy mu Std                0.8381133
Policy mu Max                1.8761116
Policy mu Min                -2.2723277
Policy log std Mean          -0.4934506
Policy log std Std           0.18014397
Policy log std Max           0.045194924
Policy log std Min           -1.127362
Z mean eval                  0.05545499
Z variance eval              0.035808325
total_rewards                [1788.78056838 1059.82204784  989.65281309 1771.45880288 1088.68812249
 3379.08850446 3330.7251334  3300.1290264  1497.44454879 1675.06114295]
total_rewards_mean           1988.085071068297
total_rewards_std            924.7620040374823
total_rewards_max            3379.0885044599268
total_rewards_min            989.652813091
Number of train steps total  1888000
Number of env steps total    2605685
Number of rollouts total     0
Train Time (s)               145.7627056259662
(Previous) Eval Time (s)     10.793310334905982
Sample Time (s)              6.453211006708443
Epoch Time (s)               163.00922696758062
Total Train Time (s)         77777.36389002064
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:05:58.983365 UTC | [2020_01_10_09_29_40] Iteration #471 | Epoch Duration: 163.1156861782074
2020-01-11 07:05:58.983571 UTC | [2020_01_10_09_29_40] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054834373
Z variance train             0.035723228
KL Divergence                7.135618
KL Loss                      0.71356183
QF Loss                      70.454384
VF Loss                      87.89413
Policy Loss                  -1633.7582
Q Predictions Mean           1633.0157
Q Predictions Std            146.3566
Q Predictions Max            1819.9854
Q Predictions Min            955.6537
V Predictions Mean           1625.5874
V Predictions Std            145.27547
V Predictions Max            1806.6202
V Predictions Min            959.03375
Log Pis Mean                 -0.5208061
Log Pis Std                  1.6927985
Log Pis Max                  5.516819
Log Pis Min                  -4.533183
Policy mu Mean               0.0628878
Policy mu Std                0.7948272
Policy mu Max                2.1370358
Policy mu Min                -2.4323702
Policy log std Mean          -0.47646555
Policy log std Std           0.16568919
Policy log std Max           0.2385999
Policy log std Min           -1.1152716
Z mean eval                  0.08025567
Z variance eval              0.03170191
total_rewards                [ 891.27884466  948.0172603  1060.95570042 1808.47289021  861.65171657
  908.62156152  911.99691194  941.58062066  888.53236589 1215.87889655]
total_rewards_mean           1043.698676870927
total_rewards_std            273.9429006600081
total_rewards_max            1808.4728902052677
total_rewards_min            861.6517165748337
Number of train steps total  1892000
Number of env steps total    2614852
Number of rollouts total     0
Train Time (s)               145.69834688398987
(Previous) Eval Time (s)     5.849926385097206
Sample Time (s)              6.728373660705984
Epoch Time (s)               158.27664692979306
Total Train Time (s)         77935.71958490787
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:08:37.346980 UTC | [2020_01_10_09_29_40] Iteration #472 | Epoch Duration: 158.363205909729
2020-01-11 07:08:37.347255 UTC | [2020_01_10_09_29_40] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.082553156
Z variance train             0.031517353
KL Divergence                7.132702
KL Loss                      0.7132702
QF Loss                      68.10605
VF Loss                      147.77716
Policy Loss                  -1641.6344
Q Predictions Mean           1640.1184
Q Predictions Std            209.08708
Q Predictions Max            1823.5905
Q Predictions Min            78.632225
V Predictions Mean           1630.6091
V Predictions Std            207.87503
V Predictions Max            1814.0957
V Predictions Min            80.02981
Log Pis Mean                 -0.5271234
Log Pis Std                  1.7037551
Log Pis Max                  5.7176695
Log Pis Min                  -3.814804
Policy mu Mean               0.052366357
Policy mu Std                0.7891768
Policy mu Max                1.7816107
Policy mu Min                -2.4407125
Policy log std Mean          -0.47492483
Policy log std Std           0.17712994
Policy log std Max           0.16407177
Policy log std Min           -1.1266654
Z mean eval                  0.14663592
Z variance eval              0.028715288
total_rewards                [ 969.27933839 1065.05494141 1210.97367782  979.83566954 1524.48721824
 1411.82363158 1262.70562018 1173.08637881 1014.80268266  940.56621382]
total_rewards_mean           1155.2615372438488
total_rewards_std            188.79648442505493
total_rewards_max            1524.487218241305
total_rewards_min            940.5662138217194
Number of train steps total  1896000
Number of env steps total    2623795
Number of rollouts total     0
Train Time (s)               146.6441191569902
(Previous) Eval Time (s)     7.1816465691663325
Sample Time (s)              6.55086042592302
Epoch Time (s)               160.37662615207955
Total Train Time (s)         78096.17786673969
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:11:17.809803 UTC | [2020_01_10_09_29_40] Iteration #473 | Epoch Duration: 160.46240186691284
2020-01-11 07:11:17.809951 UTC | [2020_01_10_09_29_40] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14630552
Z variance train             0.028744733
KL Divergence                7.8225427
KL Loss                      0.7822543
QF Loss                      41.583447
VF Loss                      58.93619
Policy Loss                  -1653.727
Q Predictions Mean           1653.6013
Q Predictions Std            161.62909
Q Predictions Max            1843.0981
Q Predictions Min            416.86493
V Predictions Mean           1652.7651
V Predictions Std            155.92201
V Predictions Max            1855.7023
V Predictions Min            585.1673
Log Pis Mean                 -0.22794056
Log Pis Std                  1.7171819
Log Pis Max                  5.3706284
Log Pis Min                  -4.356765
Policy mu Mean               -0.013169807
Policy mu Std                0.8152044
Policy mu Max                1.7876801
Policy mu Min                -2.60707
Policy log std Mean          -0.47914496
Policy log std Std           0.17496446
Policy log std Max           0.07261801
Policy log std Min           -1.0144925
Z mean eval                  0.1746003
Z variance eval              0.019646762
total_rewards                [1009.22572862  961.0745139   961.76384677  738.6385951   971.36797053
 1013.64783634 1743.47830454 2559.36624944 1730.17854012  974.16869467]
total_rewards_mean           1266.2910280028395
total_rewards_std            536.7941953413825
total_rewards_max            2559.3662494388705
total_rewards_min            738.6385950970192
Number of train steps total  1900000
Number of env steps total    2634726
Number of rollouts total     0
Train Time (s)               147.60661199176684
(Previous) Eval Time (s)     8.272924314253032
Sample Time (s)              6.406869052443653
Epoch Time (s)               162.28640535846353
Total Train Time (s)         78258.54396224627
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:14:00.178838 UTC | [2020_01_10_09_29_40] Iteration #474 | Epoch Duration: 162.3687388896942
2020-01-11 07:14:00.179057 UTC | [2020_01_10_09_29_40] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17463988
Z variance train             0.019666396
KL Divergence                7.864875
KL Loss                      0.7864875
QF Loss                      70.31769
VF Loss                      14.970029
Policy Loss                  -1651.4541
Q Predictions Mean           1650.4397
Q Predictions Std            169.16833
Q Predictions Max            1830.1547
Q Predictions Min            441.56674
V Predictions Mean           1652.0863
V Predictions Std            167.48634
V Predictions Max            1824.7325
V Predictions Min            469.74762
Log Pis Mean                 -0.20551525
Log Pis Std                  1.6270124
Log Pis Max                  5.0672717
Log Pis Min                  -3.8639393
Policy mu Mean               0.11682547
Policy mu Std                0.82805073
Policy mu Max                1.82963
Policy mu Min                -2.4851267
Policy log std Mean          -0.49367714
Policy log std Std           0.1819286
Policy log std Max           0.17009315
Policy log std Min           -1.3662713
Z mean eval                  0.14284503
Z variance eval              0.018082937
total_rewards                [ 800.64366127  786.17561806 2757.32175037 1065.32870968 1003.64830092
 1015.81090026  699.19200405  994.48415312  900.87318023 1047.56603102]
total_rewards_mean           1107.1044308990288
total_rewards_std            562.6780271989942
total_rewards_max            2757.321750372387
total_rewards_min            699.1920040515673
Number of train steps total  1904000
Number of env steps total    2643635
Number of rollouts total     0
Train Time (s)               147.13151833089069
(Previous) Eval Time (s)     6.910666301846504
Sample Time (s)              6.57093715434894
Epoch Time (s)               160.61312178708613
Total Train Time (s)         78419.242182869
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:16:40.879302 UTC | [2020_01_10_09_29_40] Iteration #475 | Epoch Duration: 160.700115442276
2020-01-11 07:16:40.879431 UTC | [2020_01_10_09_29_40] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14189054
Z variance train             0.018057656
KL Divergence                7.7884007
KL Loss                      0.77884007
QF Loss                      43.906216
VF Loss                      49.907513
Policy Loss                  -1643.8175
Q Predictions Mean           1642.0396
Q Predictions Std            199.31232
Q Predictions Max            1821.2039
Q Predictions Min            87.314514
V Predictions Mean           1639.1844
V Predictions Std            195.35072
V Predictions Max            1820.6418
V Predictions Min            99.03079
Log Pis Mean                 -0.3218308
Log Pis Std                  1.711955
Log Pis Max                  6.6348724
Log Pis Min                  -4.1439075
Policy mu Mean               0.021317167
Policy mu Std                0.8538435
Policy mu Max                2.0871868
Policy mu Min                -2.5471447
Policy log std Mean          -0.46231794
Policy log std Std           0.18116812
Policy log std Max           0.31665438
Policy log std Min           -1.3122227
Z mean eval                  0.10818668
Z variance eval              0.033389527
total_rewards                [ 898.78811207  480.36880738 1056.76208535  837.6194971   692.8641454
  671.17832148 1070.99595559  747.01752932  931.82872802  686.26549514]
total_rewards_mean           807.3688676866069
total_rewards_std            177.01853032264296
total_rewards_max            1070.9959555907592
total_rewards_min            480.3688073830978
Number of train steps total  1908000
Number of env steps total    2653057
Number of rollouts total     0
Train Time (s)               145.35987773025408
(Previous) Eval Time (s)     5.273303692694753
Sample Time (s)              6.234732429031283
Epoch Time (s)               156.86791385198012
Total Train Time (s)         78576.19330784772
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:19:17.836597 UTC | [2020_01_10_09_29_40] Iteration #476 | Epoch Duration: 156.95706915855408
2020-01-11 07:19:17.836771 UTC | [2020_01_10_09_29_40] Iteration #476 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10811059
Z variance train             0.033399228
KL Divergence                6.393088
KL Loss                      0.6393088
QF Loss                      51.300552
VF Loss                      13.791927
Policy Loss                  -1632.2231
Q Predictions Mean           1630.8875
Q Predictions Std            259.06512
Q Predictions Max            1817.8611
Q Predictions Min            -5.4333496
V Predictions Mean           1633.0878
V Predictions Std            255.01714
V Predictions Max            1821.0297
V Predictions Min            43.899216
Log Pis Mean                 -0.34721863
Log Pis Std                  1.6680111
Log Pis Max                  5.272533
Log Pis Min                  -5.9961476
Policy mu Mean               0.08106204
Policy mu Std                0.80845565
Policy mu Max                2.111527
Policy mu Min                -2.4564734
Policy log std Mean          -0.50188166
Policy log std Std           0.17623255
Policy log std Max           0.2656494
Policy log std Min           -1.4026576
Z mean eval                  0.1283386
Z variance eval              0.038685825
total_rewards                [834.65816878 855.76421731 841.21577847 813.68033817 846.17408008
 748.07242932 900.83845385 998.81931148 888.54751359 872.83790917]
total_rewards_mean           860.0608200220031
total_rewards_std            61.47825750750709
total_rewards_max            998.8193114830149
total_rewards_min            748.0724293193922
Number of train steps total  1912000
Number of env steps total    2662936
Number of rollouts total     0
Train Time (s)               146.96431008307263
(Previous) Eval Time (s)     4.720782327931374
Sample Time (s)              6.349571094382554
Epoch Time (s)               158.03466350538656
Total Train Time (s)         78734.31143400026
Epoch                        477
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:21:55.962566 UTC | [2020_01_10_09_29_40] Iteration #477 | Epoch Duration: 158.12565207481384
2020-01-11 07:21:55.962826 UTC | [2020_01_10_09_29_40] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12771761
Z variance train             0.038761366
KL Divergence                6.093754
KL Loss                      0.6093754
QF Loss                      61.75039
VF Loss                      104.66846
Policy Loss                  -1662.557
Q Predictions Mean           1661.6421
Q Predictions Std            212.6973
Q Predictions Max            1848.9557
Q Predictions Min            64.190216
V Predictions Mean           1670.2676
V Predictions Std            214.76903
V Predictions Max            1862.1655
V Predictions Min            76.09777
Log Pis Mean                 -0.44478852
Log Pis Std                  1.7407829
Log Pis Max                  6.764641
Log Pis Min                  -5.895153
Policy mu Mean               0.16640393
Policy mu Std                0.7921336
Policy mu Max                2.1528027
Policy mu Min                -2.1347091
Policy log std Mean          -0.47934487
Policy log std Std           0.15728804
Policy log std Max           0.17868182
Policy log std Min           -1.2277343
Z mean eval                  0.088409245
Z variance eval              0.030974036
total_rewards                [1092.40944823  983.50812743  965.64523253 1033.50546313  953.53102773
  971.93917024  886.6485139   978.94522525 1536.57358911  921.67024658]
total_rewards_mean           1032.4376044124201
total_rewards_std            176.31726449288433
total_rewards_max            1536.5735891097709
total_rewards_min            886.6485139022681
Number of train steps total  1916000
Number of env steps total    2673133
Number of rollouts total     0
Train Time (s)               146.74147348618135
(Previous) Eval Time (s)     6.460878545884043
Sample Time (s)              6.987279754132032
Epoch Time (s)               160.18963178619742
Total Train Time (s)         78894.58265796117
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:24:36.236144 UTC | [2020_01_10_09_29_40] Iteration #478 | Epoch Duration: 160.27316284179688
2020-01-11 07:24:36.236280 UTC | [2020_01_10_09_29_40] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.089235224
Z variance train             0.030938506
KL Divergence                6.5126815
KL Loss                      0.6512682
QF Loss                      84.80911
VF Loss                      24.685192
Policy Loss                  -1647.3564
Q Predictions Mean           1649.2346
Q Predictions Std            232.6936
Q Predictions Max            1844.5503
Q Predictions Min            98.275665
V Predictions Mean           1644.7063
V Predictions Std            227.76863
V Predictions Max            1836.9818
V Predictions Min            133.30988
Log Pis Mean                 -0.28246728
Log Pis Std                  1.7424096
Log Pis Max                  5.3691835
Log Pis Min                  -4.3631277
Policy mu Mean               0.053369854
Policy mu Std                0.84407824
Policy mu Max                2.240388
Policy mu Min                -2.215081
Policy log std Mean          -0.47715083
Policy log std Std           0.18546031
Policy log std Max           0.1309146
Policy log std Min           -1.0665145
Z mean eval                  0.075661644
Z variance eval              0.04281348
total_rewards                [1065.02884344  975.85618474  807.06348587  993.13139746  969.16415636
  959.99877784  955.73079872  931.91773341 1047.82330243  804.29857586]
total_rewards_mean           951.0013256105664
total_rewards_std            82.34480521707273
total_rewards_max            1065.0288434388149
total_rewards_min            804.2985758552647
Number of train steps total  1920000
Number of env steps total    2682747
Number of rollouts total     0
Train Time (s)               146.9181730672717
(Previous) Eval Time (s)     5.241447370965034
Sample Time (s)              6.571654070634395
Epoch Time (s)               158.73127450887114
Total Train Time (s)         79053.38729637628
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:27:15.043701 UTC | [2020_01_10_09_29_40] Iteration #479 | Epoch Duration: 158.8073353767395
2020-01-11 07:27:15.043823 UTC | [2020_01_10_09_29_40] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07690836
Z variance train             0.042692594
KL Divergence                5.8243985
KL Loss                      0.58243984
QF Loss                      156.56454
VF Loss                      336.45557
Policy Loss                  -1649.3716
Q Predictions Mean           1644.9084
Q Predictions Std            261.65726
Q Predictions Max            1856.8932
Q Predictions Min            19.90865
V Predictions Mean           1633.7107
V Predictions Std            257.25604
V Predictions Max            1831.9183
V Predictions Min            44.835136
Log Pis Mean                 -0.29132572
Log Pis Std                  1.7587967
Log Pis Max                  7.0991697
Log Pis Min                  -6.7262135
Policy mu Mean               0.10510186
Policy mu Std                0.82954496
Policy mu Max                2.2576568
Policy mu Min                -2.5535803
Policy log std Mean          -0.4712141
Policy log std Std           0.18058006
Policy log std Max           0.39127925
Policy log std Min           -1.1537012
Z mean eval                  0.053045623
Z variance eval              0.06167835
total_rewards                [ 695.30082203 1226.72770116 1753.13355441 2703.20996882 2910.21847026
 1285.25564112  644.51047057 2754.29059999  965.86459606 1234.80127404]
total_rewards_mean           1617.3313098461304
total_rewards_std            824.1306019556129
total_rewards_max            2910.2184702637974
total_rewards_min            644.5104705714231
Number of train steps total  1924000
Number of env steps total    2693660
Number of rollouts total     0
Train Time (s)               146.12207850813866
(Previous) Eval Time (s)     10.261289010290056
Sample Time (s)              5.339666202198714
Epoch Time (s)               161.72303372062743
Total Train Time (s)         79215.1885592211
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:29:56.847779 UTC | [2020_01_10_09_29_40] Iteration #480 | Epoch Duration: 161.80387043952942
2020-01-11 07:29:56.847910 UTC | [2020_01_10_09_29_40] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051532485
Z variance train             0.061651923
KL Divergence                5.2166085
KL Loss                      0.52166086
QF Loss                      38.94867
VF Loss                      75.181854
Policy Loss                  -1665.8484
Q Predictions Mean           1666.253
Q Predictions Std            178.10205
Q Predictions Max            1832.8384
Q Predictions Min            374.4655
V Predictions Mean           1673.4971
V Predictions Std            179.55797
V Predictions Max            1843.3212
V Predictions Min            369.28766
Log Pis Mean                 -0.3520254
Log Pis Std                  1.952394
Log Pis Max                  7.1569777
Log Pis Min                  -5.4134765
Policy mu Mean               -0.07992094
Policy mu Std                0.84632045
Policy mu Max                1.9882619
Policy mu Min                -2.4404914
Policy log std Mean          -0.49922797
Policy log std Std           0.17020036
Policy log std Max           0.28900546
Policy log std Min           -1.1901299
Z mean eval                  0.040196646
Z variance eval              0.050004173
total_rewards                [ 929.57337789  928.98738197  671.33223225  945.29068441 1389.44203196
  992.85897311  656.43852786 1134.20865201 2269.98967653  959.74807588]
total_rewards_mean           1087.7869613874655
total_rewards_std            441.1586267685796
total_rewards_max            2269.989676531736
total_rewards_min            656.4385278606795
Number of train steps total  1928000
Number of env steps total    2704097
Number of rollouts total     0
Train Time (s)               143.97335289837793
(Previous) Eval Time (s)     6.057283706963062
Sample Time (s)              6.845045959576964
Epoch Time (s)               156.87568256491795
Total Train Time (s)         79372.14639790589
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:32:33.814250 UTC | [2020_01_10_09_29_40] Iteration #481 | Epoch Duration: 156.96620988845825
2020-01-11 07:32:33.814544 UTC | [2020_01_10_09_29_40] Iteration #481 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0402601
Z variance train             0.049931638
KL Divergence                5.5421476
KL Loss                      0.5542148
QF Loss                      69.4469
VF Loss                      64.949936
Policy Loss                  -1603.0659
Q Predictions Mean           1604.4347
Q Predictions Std            255.97018
Q Predictions Max            1823.8225
Q Predictions Min            19.414652
V Predictions Mean           1609.7438
V Predictions Std            254.91812
V Predictions Max            1830.4568
V Predictions Min            21.83588
Log Pis Mean                 -0.40985507
Log Pis Std                  1.652513
Log Pis Max                  5.8941436
Log Pis Min                  -5.4322534
Policy mu Mean               0.07369056
Policy mu Std                0.8116801
Policy mu Max                2.2466738
Policy mu Min                -2.3124237
Policy log std Mean          -0.48122525
Policy log std Std           0.16102947
Policy log std Max           0.22010675
Policy log std Min           -1.0881552
Z mean eval                  0.03936141
Z variance eval              0.055657975
total_rewards                [2730.95725939  878.54860995 2164.74420051  865.53625607  972.8434095
 1329.76893396  938.71783127  893.59515455 1667.3553512   929.72086154]
total_rewards_mean           1337.1787867913174
total_rewards_std            618.356089161652
total_rewards_max            2730.9572593915454
total_rewards_min            865.5362560699335
Number of train steps total  1932000
Number of env steps total    2713391
Number of rollouts total     0
Train Time (s)               146.73006746312603
(Previous) Eval Time (s)     7.565671076066792
Sample Time (s)              5.659855131525546
Epoch Time (s)               159.95559367071837
Total Train Time (s)         79532.18311051978
Epoch                        482
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:35:13.858428 UTC | [2020_01_10_09_29_40] Iteration #482 | Epoch Duration: 160.04362511634827
2020-01-11 07:35:13.858709 UTC | [2020_01_10_09_29_40] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036877044
Z variance train             0.055562984
KL Divergence                5.114254
KL Loss                      0.51142544
QF Loss                      79.20883
VF Loss                      59.63775
Policy Loss                  -1640.6029
Q Predictions Mean           1639.0742
Q Predictions Std            220.59929
Q Predictions Max            1854.2803
Q Predictions Min            588.9199
V Predictions Mean           1636.6074
V Predictions Std            220.41284
V Predictions Max            1857.0289
V Predictions Min            591.5028
Log Pis Mean                 -0.3078277
Log Pis Std                  1.8447556
Log Pis Max                  7.123728
Log Pis Min                  -4.993036
Policy mu Mean               0.06354261
Policy mu Std                0.8644501
Policy mu Max                2.1411984
Policy mu Min                -2.3223653
Policy log std Mean          -0.5043889
Policy log std Std           0.18605682
Policy log std Max           0.35141057
Policy log std Min           -1.1221535
Z mean eval                  0.058918178
Z variance eval              0.058058448
total_rewards                [ 677.93478119 1621.99768493 1681.06085283  868.16989305  690.05841165
 1373.55665722  859.36202841 1315.82326718 1212.11852539 1368.97026104]
total_rewards_mean           1166.9052362896002
total_rewards_std            350.6453579351946
total_rewards_max            1681.0608528294194
total_rewards_min            677.9347811887725
Number of train steps total  1936000
Number of env steps total    2723526
Number of rollouts total     0
Train Time (s)               146.26153901219368
(Previous) Eval Time (s)     6.64305221894756
Sample Time (s)              6.577918528113514
Epoch Time (s)               159.48250975925475
Total Train Time (s)         79691.73960534856
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:37:53.417276 UTC | [2020_01_10_09_29_40] Iteration #483 | Epoch Duration: 159.55842518806458
2020-01-11 07:37:53.417408 UTC | [2020_01_10_09_29_40] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06013266
Z variance train             0.058226902
KL Divergence                4.9087257
KL Loss                      0.4908726
QF Loss                      121.64363
VF Loss                      96.66849
Policy Loss                  -1665.0791
Q Predictions Mean           1665.8096
Q Predictions Std            256.05527
Q Predictions Max            1883.7148
Q Predictions Min            327.75705
V Predictions Mean           1657.4788
V Predictions Std            255.05875
V Predictions Max            1873.0647
V Predictions Min            343.77783
Log Pis Mean                 -0.32650822
Log Pis Std                  1.7505677
Log Pis Max                  10.595498
Log Pis Min                  -4.0559525
Policy mu Mean               0.07414537
Policy mu Std                0.8555547
Policy mu Max                3.6430757
Policy mu Min                -3.5413246
Policy log std Mean          -0.4905852
Policy log std Std           0.1818711
Policy log std Max           0.47269142
Policy log std Min           -1.2992891
Z mean eval                  0.18656127
Z variance eval              0.048194133
total_rewards                [ 778.13875768  887.3921482   672.64289657  585.41412276  643.31291761
  674.91638937  933.71060225 1025.27596393  684.9538283   975.54427903]
total_rewards_mean           786.1301905704587
total_rewards_std            148.77313866532066
total_rewards_max            1025.2759639266976
total_rewards_min            585.4141227634224
Number of train steps total  1940000
Number of env steps total    2734121
Number of rollouts total     0
Train Time (s)               145.87557600205764
(Previous) Eval Time (s)     4.537462867796421
Sample Time (s)              5.540493191685528
Epoch Time (s)               155.9535320615396
Total Train Time (s)         79847.78943219688
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:40:29.474305 UTC | [2020_01_10_09_29_40] Iteration #484 | Epoch Duration: 156.05678939819336
2020-01-11 07:40:29.474509 UTC | [2020_01_10_09_29_40] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18655822
Z variance train             0.048260793
KL Divergence                5.6213026
KL Loss                      0.5621303
QF Loss                      33.825546
VF Loss                      20.267302
Policy Loss                  -1636.0504
Q Predictions Mean           1634.6848
Q Predictions Std            300.2912
Q Predictions Max            1873.3458
Q Predictions Min            114.65963
V Predictions Mean           1633.4438
V Predictions Std            299.0708
V Predictions Max            1867.6482
V Predictions Min            139.05302
Log Pis Mean                 0.017851017
Log Pis Std                  1.8276368
Log Pis Max                  6.2370753
Log Pis Min                  -5.453561
Policy mu Mean               0.07964019
Policy mu Std                0.8953371
Policy mu Max                1.997764
Policy mu Min                -2.424503
Policy log std Mean          -0.5046219
Policy log std Std           0.17330188
Policy log std Max           0.28323776
Policy log std Min           -1.1133444
Z mean eval                  0.080172606
Z variance eval              0.0616063
total_rewards                [ 939.28798323 1172.20683746  884.97402439  198.08514716 1615.38846796
 1086.56189498 1411.84700761  964.6373172   878.84472775 1206.92876995]
total_rewards_mean           1035.8762177683177
total_rewards_std            359.35094839202793
total_rewards_max            1615.3884679574057
total_rewards_min            198.0851471579364
Number of train steps total  1944000
Number of env steps total    2743861
Number of rollouts total     0
Train Time (s)               145.37700112815946
(Previous) Eval Time (s)     7.00919403322041
Sample Time (s)              6.656438134610653
Epoch Time (s)               159.04263329599053
Total Train Time (s)         80006.90701198904
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:43:08.595959 UTC | [2020_01_10_09_29_40] Iteration #485 | Epoch Duration: 159.12133145332336
2020-01-11 07:43:08.596109 UTC | [2020_01_10_09_29_40] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.080092356
Z variance train             0.061446875
KL Divergence                4.9358616
KL Loss                      0.49358615
QF Loss                      104.27398
VF Loss                      46.793453
Policy Loss                  -1636.0376
Q Predictions Mean           1634.207
Q Predictions Std            275.65585
Q Predictions Max            1850.8433
Q Predictions Min            87.13233
V Predictions Mean           1635.4332
V Predictions Std            274.86774
V Predictions Max            1859.2118
V Predictions Min            108.827705
Log Pis Mean                 -0.25575978
Log Pis Std                  1.8376124
Log Pis Max                  5.0807385
Log Pis Min                  -5.4741936
Policy mu Mean               -0.028240854
Policy mu Std                0.84080625
Policy mu Max                1.6853926
Policy mu Min                -2.4339778
Policy log std Mean          -0.50717837
Policy log std Std           0.1804651
Policy log std Max           0.27662057
Policy log std Min           -0.9431565
Z mean eval                  0.09932687
Z variance eval              0.05254832
total_rewards                [ 847.24457516  816.38044679  802.66208187 1419.99614284  677.71408896
 3177.06431386  907.15169133  865.79506555  825.54183625  819.0111093 ]
total_rewards_mean           1115.8561351908836
total_rewards_std            712.14216073181
total_rewards_max            3177.064313863485
total_rewards_min            677.7140889624727
Number of train steps total  1948000
Number of env steps total    2753711
Number of rollouts total     0
Train Time (s)               146.69983272021636
(Previous) Eval Time (s)     7.41926707001403
Sample Time (s)              6.36570207728073
Epoch Time (s)               160.48480186751112
Total Train Time (s)         80167.47326826211
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:45:49.166842 UTC | [2020_01_10_09_29_40] Iteration #486 | Epoch Duration: 160.57062101364136
2020-01-11 07:45:49.167047 UTC | [2020_01_10_09_29_40] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09757277
Z variance train             0.05247467
KL Divergence                5.7543755
KL Loss                      0.57543755
QF Loss                      71.48232
VF Loss                      40.762634
Policy Loss                  -1662.7094
Q Predictions Mean           1663.8108
Q Predictions Std            240.21223
Q Predictions Max            1860.8425
Q Predictions Min            12.670971
V Predictions Mean           1664.7842
V Predictions Std            238.6929
V Predictions Max            1864.7881
V Predictions Min            52.753517
Log Pis Mean                 -0.2522443
Log Pis Std                  1.9058797
Log Pis Max                  7.3430204
Log Pis Min                  -7.297596
Policy mu Mean               0.038082507
Policy mu Std                0.88458514
Policy mu Max                2.411975
Policy mu Min                -2.3322792
Policy log std Mean          -0.5037436
Policy log std Std           0.17713048
Policy log std Max           0.2490905
Policy log std Min           -1.0405756
Z mean eval                  0.074231565
Z variance eval              0.042644523
total_rewards                [ 787.47169313  857.44152341  780.64305725  959.17502387  929.06410137
 1351.18940227 1168.44189818  861.90921885 1891.29229976 3311.84652167]
total_rewards_mean           1289.8474739774392
total_rewards_std            747.6632734074533
total_rewards_max            3311.8465216720906
total_rewards_min            780.6430572515758
Number of train steps total  1952000
Number of env steps total    2763663
Number of rollouts total     0
Train Time (s)               147.04139701044187
(Previous) Eval Time (s)     8.500458410941064
Sample Time (s)              6.3945084367878735
Epoch Time (s)               161.9363638581708
Total Train Time (s)         80329.48397552688
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:48:31.180433 UTC | [2020_01_10_09_29_40] Iteration #487 | Epoch Duration: 162.01325845718384
2020-01-11 07:48:31.180569 UTC | [2020_01_10_09_29_40] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07431467
Z variance train             0.04277981
KL Divergence                5.965293
KL Loss                      0.5965293
QF Loss                      80.3526
VF Loss                      132.58725
Policy Loss                  -1617.5344
Q Predictions Mean           1618.7561
Q Predictions Std            188.22308
Q Predictions Max            1813.5317
Q Predictions Min            55.363693
V Predictions Mean           1606.8237
V Predictions Std            188.6413
V Predictions Max            1806.2917
V Predictions Min            45.51231
Log Pis Mean                 -0.4594233
Log Pis Std                  1.6877525
Log Pis Max                  6.4218154
Log Pis Min                  -4.6685925
Policy mu Mean               -0.028459653
Policy mu Std                0.81405896
Policy mu Max                1.918031
Policy mu Min                -2.322875
Policy log std Mean          -0.51476926
Policy log std Std           0.1728818
Policy log std Max           0.34754643
Policy log std Min           -1.1695287
Z mean eval                  0.13259551
Z variance eval              0.021018162
total_rewards                [1320.30324451  863.0963529   739.92342093 1774.55357481  879.2110636
  732.7906831  1898.71490243 1746.85434901  770.7751158   893.80864129]
total_rewards_mean           1162.003134839872
total_rewards_std            451.85739123947985
total_rewards_max            1898.7149024310806
total_rewards_min            732.7906831017763
Number of train steps total  1956000
Number of env steps total    2772815
Number of rollouts total     0
Train Time (s)               147.73243603575975
(Previous) Eval Time (s)     6.6795544368214905
Sample Time (s)              6.505408637225628
Epoch Time (s)               160.91739910980687
Total Train Time (s)         80490.4796110834
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:51:12.180784 UTC | [2020_01_10_09_29_40] Iteration #488 | Epoch Duration: 161.0001094341278
2020-01-11 07:51:12.180962 UTC | [2020_01_10_09_29_40] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1320741
Z variance train             0.021016821
KL Divergence                7.708891
KL Loss                      0.7708891
QF Loss                      85.01474
VF Loss                      73.79837
Policy Loss                  -1637.1243
Q Predictions Mean           1639.9188
Q Predictions Std            259.9699
Q Predictions Max            1862.288
Q Predictions Min            131.25403
V Predictions Mean           1634.5015
V Predictions Std            256.38052
V Predictions Max            1846.3784
V Predictions Min            149.13458
Log Pis Mean                 -0.6528039
Log Pis Std                  1.7910798
Log Pis Max                  6.3752747
Log Pis Min                  -6.873856
Policy mu Mean               0.021809155
Policy mu Std                0.82964844
Policy mu Max                2.0954783
Policy mu Min                -2.5901191
Policy log std Mean          -0.4860942
Policy log std Std           0.16333185
Policy log std Max           0.060995102
Policy log std Min           -1.0483875
Z mean eval                  0.034960672
Z variance eval              0.025997514
total_rewards                [1206.52927378  924.5116676  1224.92422554 3243.9402515   975.34492813
 1462.38808946  846.95789996  939.64790334  972.12860356 3263.24442809]
total_rewards_mean           1505.96172709521
total_rewards_std            890.9975269194688
total_rewards_max            3263.244428089745
total_rewards_min            846.9578999631568
Number of train steps total  1960000
Number of env steps total    2782588
Number of rollouts total     0
Train Time (s)               146.46539950557053
(Previous) Eval Time (s)     9.91457916609943
Sample Time (s)              6.2765684658661485
Epoch Time (s)               162.6565471375361
Total Train Time (s)         80653.22359699849
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:53:54.929032 UTC | [2020_01_10_09_29_40] Iteration #489 | Epoch Duration: 162.74794244766235
2020-01-11 07:53:54.929214 UTC | [2020_01_10_09_29_40] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034533225
Z variance train             0.026016463
KL Divergence                6.8285084
KL Loss                      0.68285084
QF Loss                      62.199776
VF Loss                      79.93037
Policy Loss                  -1598.3391
Q Predictions Mean           1598.9792
Q Predictions Std            281.59824
Q Predictions Max            1858.9464
Q Predictions Min            154.58987
V Predictions Mean           1603.4108
V Predictions Std            280.23013
V Predictions Max            1854.9069
V Predictions Min            150.02269
Log Pis Mean                 -0.03199984
Log Pis Std                  1.7821227
Log Pis Max                  6.2532206
Log Pis Min                  -6.1390357
Policy mu Mean               -0.03372656
Policy mu Std                0.8839373
Policy mu Max                2.740801
Policy mu Min                -2.466874
Policy log std Mean          -0.4941686
Policy log std Std           0.17797928
Policy log std Max           0.22298321
Policy log std Min           -1.1130874
Z mean eval                  0.050317246
Z variance eval              0.032392114
total_rewards                [ 945.15179957  928.4098664   946.78465918 1411.87193018  959.66661338
  669.54235554  672.23229181  926.54500589  669.05694342  686.09554343]
total_rewards_mean           881.5357008780371
total_rewards_std            217.25137240727292
total_rewards_max            1411.8719301768474
total_rewards_min            669.0569434191481
Number of train steps total  1964000
Number of env steps total    2791786
Number of rollouts total     0
Train Time (s)               147.20101731689647
(Previous) Eval Time (s)     5.91901054000482
Sample Time (s)              5.668535855133086
Epoch Time (s)               158.78856371203437
Total Train Time (s)         80812.1098908293
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:56:33.818752 UTC | [2020_01_10_09_29_40] Iteration #490 | Epoch Duration: 158.88942766189575
2020-01-11 07:56:33.818887 UTC | [2020_01_10_09_29_40] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052286524
Z variance train             0.032411564
KL Divergence                6.392334
KL Loss                      0.6392334
QF Loss                      24213.508
VF Loss                      126.79592
Policy Loss                  -1605.079
Q Predictions Mean           1604.4453
Q Predictions Std            257.80246
Q Predictions Max            1831.5308
Q Predictions Min            224.0369
V Predictions Mean           1602.9589
V Predictions Std            255.60852
V Predictions Max            1826.3618
V Predictions Min            239.1722
Log Pis Mean                 -0.14694579
Log Pis Std                  1.8616104
Log Pis Max                  9.707201
Log Pis Min                  -6.1483583
Policy mu Mean               0.029296616
Policy mu Std                0.8665772
Policy mu Max                3.6872935
Policy mu Min                -2.6596725
Policy log std Mean          -0.51056534
Policy log std Std           0.16778055
Policy log std Max           0.20816267
Policy log std Min           -1.1604214
Z mean eval                  0.11110232
Z variance eval              0.04409342
total_rewards                [ 954.40632987  696.97891733  936.1577886   684.46892513  692.73314158
 1473.57359089  951.88218308  997.20405084  695.21716769  674.15052154]
total_rewards_mean           875.6772616544134
total_rewards_std            237.2874377529378
total_rewards_max            1473.5735908869144
total_rewards_min            674.1505215419858
Number of train steps total  1968000
Number of env steps total    2801034
Number of rollouts total     0
Train Time (s)               146.27944370685145
(Previous) Eval Time (s)     5.842613061890006
Sample Time (s)              6.567632093559951
Epoch Time (s)               158.6896888623014
Total Train Time (s)         80970.87857814552
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:59:12.590716 UTC | [2020_01_10_09_29_40] Iteration #491 | Epoch Duration: 158.7717387676239
2020-01-11 07:59:12.590856 UTC | [2020_01_10_09_29_40] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.109359756
Z variance train             0.044131387
KL Divergence                5.716814
KL Loss                      0.57168144
QF Loss                      188.49756
VF Loss                      74.556206
Policy Loss                  -1628.2795
Q Predictions Mean           1627.4425
Q Predictions Std            261.51447
Q Predictions Max            1848.7837
Q Predictions Min            314.03546
V Predictions Mean           1635.1338
V Predictions Std            260.31082
V Predictions Max            1851.6929
V Predictions Min            323.98782
Log Pis Mean                 -0.11896337
Log Pis Std                  1.7861009
Log Pis Max                  6.0104985
Log Pis Min                  -4.652806
Policy mu Mean               -0.1424009
Policy mu Std                0.87036264
Policy mu Max                2.0907207
Policy mu Min                -2.6250448
Policy log std Mean          -0.5190702
Policy log std Std           0.19602905
Policy log std Max           0.083796084
Policy log std Min           -1.3260477
Z mean eval                  0.08221306
Z variance eval              0.044144116
total_rewards                [2045.93482661  897.74018426 3145.00692218 1421.09331459 1297.93311412
 2237.30551738  919.52882161  934.26212746 1009.20349088 1777.62356944]
total_rewards_mean           1568.5631888510284
total_rewards_std            698.9591756552211
total_rewards_max            3145.006922180617
total_rewards_min            897.7401842550054
Number of train steps total  1972000
Number of env steps total    2811290
Number of rollouts total     0
Train Time (s)               145.94017519103363
(Previous) Eval Time (s)     9.026580467354506
Sample Time (s)              6.547989576589316
Epoch Time (s)               161.51474523497745
Total Train Time (s)         81132.47333650803
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:01:54.188123 UTC | [2020_01_10_09_29_40] Iteration #492 | Epoch Duration: 161.59717893600464
2020-01-11 08:01:54.188243 UTC | [2020_01_10_09_29_40] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08170308
Z variance train             0.044228017
KL Divergence                5.7056885
KL Loss                      0.57056886
QF Loss                      36.905365
VF Loss                      23.257755
Policy Loss                  -1663.6825
Q Predictions Mean           1662.6101
Q Predictions Std            214.74065
Q Predictions Max            1855.085
Q Predictions Min            41.764633
V Predictions Mean           1660.5464
V Predictions Std            214.12622
V Predictions Max            1853.054
V Predictions Min            53.03656
Log Pis Mean                 -0.3762135
Log Pis Std                  1.7965949
Log Pis Max                  6.213236
Log Pis Min                  -5.397342
Policy mu Mean               -0.16167925
Policy mu Std                0.83182317
Policy mu Max                2.106132
Policy mu Min                -2.357589
Policy log std Mean          -0.4764215
Policy log std Std           0.17296058
Policy log std Max           0.17700142
Policy log std Min           -1.1854147
Z mean eval                  0.072109506
Z variance eval              0.032727934
total_rewards                [1021.54461221  718.35072752 3155.81223531 1990.88112435 1107.62379257
  583.04779677  962.42408976 1377.81350035  948.76099032  987.30615476]
total_rewards_mean           1285.356502389979
total_rewards_std            722.9974083870222
total_rewards_max            3155.8122353099616
total_rewards_min            583.0477967678213
Number of train steps total  1976000
Number of env steps total    2821125
Number of rollouts total     0
Train Time (s)               145.4213273911737
(Previous) Eval Time (s)     7.217760071158409
Sample Time (s)              5.404834012966603
Epoch Time (s)               158.0439214752987
Total Train Time (s)         81290.6000000923
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:04:32.319538 UTC | [2020_01_10_09_29_40] Iteration #493 | Epoch Duration: 158.13118505477905
2020-01-11 08:04:32.319753 UTC | [2020_01_10_09_29_40] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0718119
Z variance train             0.032695126
KL Divergence                6.457196
KL Loss                      0.64571965
QF Loss                      30.72311
VF Loss                      25.050816
Policy Loss                  -1649.688
Q Predictions Mean           1650.362
Q Predictions Std            209.11325
Q Predictions Max            1851.8898
Q Predictions Min            134.28467
V Predictions Mean           1652.8911
V Predictions Std            208.75722
V Predictions Max            1847.6537
V Predictions Min            127.038475
Log Pis Mean                 -0.53276885
Log Pis Std                  1.6819268
Log Pis Max                  5.8419785
Log Pis Min                  -5.786538
Policy mu Mean               0.08187098
Policy mu Std                0.8136528
Policy mu Max                1.8110514
Policy mu Min                -2.2234328
Policy log std Mean          -0.4857906
Policy log std Std           0.1670449
Policy log std Max           -0.015731037
Policy log std Min           -1.0839939
Z mean eval                  0.17929903
Z variance eval              0.031198245
total_rewards                [3152.63884688 3162.31671043 2032.48521337 3048.61693087 1232.41589487
 2427.05445516 3028.79852133  749.49905867 1167.20753716  879.2737864 ]
total_rewards_mean           2088.0306955129035
total_rewards_std            951.1059651727006
total_rewards_max            3162.3167104301656
total_rewards_min            749.4990586687057
Number of train steps total  1980000
Number of env steps total    2832072
Number of rollouts total     0
Train Time (s)               146.221732635051
(Previous) Eval Time (s)     12.453876252286136
Sample Time (s)              6.457047593314201
Epoch Time (s)               165.13265648065135
Total Train Time (s)         81455.81037472188
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:07:17.533540 UTC | [2020_01_10_09_29_40] Iteration #494 | Epoch Duration: 165.21364164352417
2020-01-11 08:07:17.533677 UTC | [2020_01_10_09_29_40] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18214558
Z variance train             0.031249603
KL Divergence                6.7518454
KL Loss                      0.67518455
QF Loss                      73.85551
VF Loss                      55.81519
Policy Loss                  -1638.4346
Q Predictions Mean           1637.8932
Q Predictions Std            275.78928
Q Predictions Max            1881.0154
Q Predictions Min            138.98247
V Predictions Mean           1632.999
V Predictions Std            271.66003
V Predictions Max            1877.2007
V Predictions Min            155.55554
Log Pis Mean                 -0.21064797
Log Pis Std                  1.6887907
Log Pis Max                  5.4490147
Log Pis Min                  -4.2204914
Policy mu Mean               0.020545619
Policy mu Std                0.8743895
Policy mu Max                1.9849281
Policy mu Min                -2.4630973
Policy log std Mean          -0.47776723
Policy log std Std           0.18245469
Policy log std Max           -0.021578252
Policy log std Min           -1.1067495
Z mean eval                  0.13290861
Z variance eval              0.02503419
total_rewards                [1704.72032152 1337.54334783 1396.28672715  713.37833736 1407.54974117
  997.40963206  874.70394458 1442.43578241 1000.9465397  1691.02285106]
total_rewards_mean           1256.599722482659
total_rewards_std            323.47994006979883
total_rewards_max            1704.7203215232528
total_rewards_min            713.378337355216
Number of train steps total  1984000
Number of env steps total    2841907
Number of rollouts total     0
Train Time (s)               146.93775297468528
(Previous) Eval Time (s)     7.070634983014315
Sample Time (s)              5.922406741417944
Epoch Time (s)               159.93079469911754
Total Train Time (s)         81615.83508745767
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:09:57.563242 UTC | [2020_01_10_09_29_40] Iteration #495 | Epoch Duration: 160.02946281433105
2020-01-11 08:09:57.563420 UTC | [2020_01_10_09_29_40] Iteration #495 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13226965
Z variance train             0.02503474
KL Divergence                7.7166357
KL Loss                      0.7716636
QF Loss                      62.993633
VF Loss                      53.30123
Policy Loss                  -1638.0171
Q Predictions Mean           1639.6262
Q Predictions Std            191.69553
Q Predictions Max            1841.3514
Q Predictions Min            176.09926
V Predictions Mean           1642.6658
V Predictions Std            192.07101
V Predictions Max            1841.2057
V Predictions Min            179.61015
Log Pis Mean                 -0.30241883
Log Pis Std                  1.8452383
Log Pis Max                  7.0933037
Log Pis Min                  -9.764909
Policy mu Mean               0.04732555
Policy mu Std                0.83100545
Policy mu Max                2.380541
Policy mu Min                -2.458896
Policy log std Mean          -0.5002894
Policy log std Std           0.16850688
Policy log std Max           -0.05235815
Policy log std Min           -1.1440418
Z mean eval                  0.11480451
Z variance eval              0.021843974
total_rewards                [ 961.31431967 1416.07660319 1968.777928   1147.71587262 1018.2742707
  821.55367827  836.4996854  1174.39871914 1243.49019136  971.6271331 ]
total_rewards_mean           1155.9728401460197
total_rewards_std            322.66213032258855
total_rewards_max            1968.7779279982394
total_rewards_min            821.5536782670765
Number of train steps total  1988000
Number of env steps total    2852968
Number of rollouts total     0
Train Time (s)               145.32732427725568
(Previous) Eval Time (s)     7.73048599390313
Sample Time (s)              7.552820647135377
Epoch Time (s)               160.6106309182942
Total Train Time (s)         81776.52036111522
Epoch                        496
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:12:38.251029 UTC | [2020_01_10_09_29_40] Iteration #496 | Epoch Duration: 160.6874978542328
2020-01-11 08:12:38.251163 UTC | [2020_01_10_09_29_40] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11445284
Z variance train             0.021785688
KL Divergence                7.723574
KL Loss                      0.7723574
QF Loss                      136.41159
VF Loss                      97.73362
Policy Loss                  -1634.5348
Q Predictions Mean           1636.2041
Q Predictions Std            226.83267
Q Predictions Max            1845.9934
Q Predictions Min            61.350353
V Predictions Mean           1628.8645
V Predictions Std            224.06935
V Predictions Max            1828.9253
V Predictions Min            67.33342
Log Pis Mean                 -0.19066072
Log Pis Std                  1.7860525
Log Pis Max                  5.9505553
Log Pis Min                  -6.7630367
Policy mu Mean               -0.093702525
Policy mu Std                0.8454272
Policy mu Max                2.018177
Policy mu Min                -2.2701924
Policy log std Mean          -0.53361285
Policy log std Std           0.17386717
Policy log std Max           0.11859697
Policy log std Min           -1.2230697
Z mean eval                  0.070281655
Z variance eval              0.032997977
total_rewards                [ 838.30126934  753.51129073  932.59043418 1554.37100968 1405.22433381
  778.09170709  891.05912759  953.30830029  968.0107762  1012.96980766]
total_rewards_mean           1008.7438056575626
total_rewards_std            250.3397079756568
total_rewards_max            1554.3710096837676
total_rewards_min            753.511290728285
Number of train steps total  1992000
Number of env steps total    2862537
Number of rollouts total     0
Train Time (s)               144.47188800899312
(Previous) Eval Time (s)     6.81393972877413
Sample Time (s)              6.43867606529966
Epoch Time (s)               157.7245038030669
Total Train Time (s)         81934.32449424965
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:15:16.058347 UTC | [2020_01_10_09_29_40] Iteration #497 | Epoch Duration: 157.8070683479309
2020-01-11 08:15:16.058482 UTC | [2020_01_10_09_29_40] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.068964005
Z variance train             0.033035297
KL Divergence                6.4585614
KL Loss                      0.64585614
QF Loss                      55.97058
VF Loss                      170.2713
Policy Loss                  -1630.2504
Q Predictions Mean           1632.0142
Q Predictions Std            194.42087
Q Predictions Max            1838.4453
Q Predictions Min            52.858326
V Predictions Mean           1642.748
V Predictions Std            192.67476
V Predictions Max            1845.6414
V Predictions Min            105.70755
Log Pis Mean                 -0.3300274
Log Pis Std                  1.790748
Log Pis Max                  4.588597
Log Pis Min                  -5.388391
Policy mu Mean               0.029847981
Policy mu Std                0.8196501
Policy mu Max                1.716908
Policy mu Min                -2.5204504
Policy log std Mean          -0.48347068
Policy log std Std           0.18414286
Policy log std Max           0.051034957
Policy log std Min           -1.1077688
Z mean eval                  0.107734874
Z variance eval              0.024834309
total_rewards                [2280.1247992  3115.78213971 3128.19213344 1460.98890697 1426.40683247
  889.20439378 1012.07402774 1286.12959456 2193.49079198  920.47701387]
total_rewards_mean           1771.287063373106
total_rewards_std            813.3257224636923
total_rewards_max            3128.1921334440917
total_rewards_min            889.2043937803586
Number of train steps total  1996000
Number of env steps total    2873279
Number of rollouts total     0
Train Time (s)               144.63584072189406
(Previous) Eval Time (s)     9.924884491134435
Sample Time (s)              7.024489321280271
Epoch Time (s)               161.58521453430876
Total Train Time (s)         82095.98595294589
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:17:57.722562 UTC | [2020_01_10_09_29_40] Iteration #498 | Epoch Duration: 161.66399574279785
2020-01-11 08:17:57.722689 UTC | [2020_01_10_09_29_40] Iteration #498 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10469109
Z variance train             0.024828846
KL Divergence                7.284741
KL Loss                      0.7284741
QF Loss                      66.06442
VF Loss                      133.32431
Policy Loss                  -1617.8022
Q Predictions Mean           1618.719
Q Predictions Std            242.32666
Q Predictions Max            1825.6627
Q Predictions Min            62.404762
V Predictions Mean           1627.8911
V Predictions Std            243.03056
V Predictions Max            1841.1582
V Predictions Min            81.92935
Log Pis Mean                 -0.30901042
Log Pis Std                  1.8514215
Log Pis Max                  6.7374153
Log Pis Min                  -6.1641655
Policy mu Mean               0.02945673
Policy mu Std                0.8161277
Policy mu Max                2.355698
Policy mu Min                -2.3509033
Policy log std Mean          -0.49618122
Policy log std Std           0.19729371
Policy log std Max           0.29308537
Policy log std Min           -1.2003617
Z mean eval                  0.042640846
Z variance eval              0.0364125
total_rewards                [ 804.68905089  993.91907068 1631.6932174  1565.87222246  848.7810336
 1299.02705294 1010.78587642 1106.57871442  812.81409865 1854.50083019]
total_rewards_mean           1192.8661167636199
total_rewards_std            356.9912589680321
total_rewards_max            1854.500830185439
total_rewards_min            804.6890508855753
Number of train steps total  2000000
Number of env steps total    2883202
Number of rollouts total     0
Train Time (s)               145.1595634170808
(Previous) Eval Time (s)     7.556219142396003
Sample Time (s)              5.539629547856748
Epoch Time (s)               158.25541210733354
Total Train Time (s)         82254.3240723908
Epoch                        499
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:20:36.064480 UTC | [2020_01_10_09_29_40] Iteration #499 | Epoch Duration: 158.3417031764984
2020-01-11 08:20:36.064616 UTC | [2020_01_10_09_29_40] Iteration #499 | Started Training: True
2020-01-11 08:20:36.423406 UTC | [2020_01_10_09_29_40] Variant:
2020-01-11 08:20:36.424153 UTC | [2020_01_10_09_29_40] {
  "env_name": "Ant-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00092889863
Z variance train             0.6928836
KL Divergence                0.14944687
KL Loss                      0.0149446875
QF Loss                      211.64459
VF Loss                      29.417334
Policy Loss                  -5.3879366
Q Predictions Mean           0.0029920149
Q Predictions Std            0.0017975824
Q Predictions Max            0.0076784114
Q Predictions Min            -0.0026010005
V Predictions Mean           0.00033025967
V Predictions Std            0.0023158917
V Predictions Max            0.007400641
V Predictions Min            -0.004998319
Log Pis Mean                 -5.4070196
Log Pis Std                  0.6253165
Log Pis Max                  -3.767221
Log Pis Min                  -6.833845
Policy mu Mean               0.0015256859
Policy mu Std                0.0016553933
Policy mu Max                0.005054727
Policy mu Min                -0.0033204472
Policy log std Mean          0.00036570974
Policy log std Std           0.0018290252
Policy log std Max           0.0050726114
Policy log std Min           -0.004632369
Z mean eval                  1.5301851
Z variance eval              0.0025412918
total_rewards                [-11.99852044 231.1790254  130.34427545  72.19508922   8.53792858
  34.25276702   7.8140692    5.92465526  62.88037106  54.77340232]
total_rewards_mean           59.59030630723432
total_rewards_std            69.6963395201281
total_rewards_max            231.17902539502074
total_rewards_min            -11.99852044170203
Number of train steps total  4000
Number of env steps total    5831
Number of rollouts total     0
Train Time (s)               141.62186042871326
(Previous) Eval Time (s)     0
Sample Time (s)              12.86952779442072
Epoch Time (s)               154.49138822313398
Total Train Time (s)         168.0706324656494
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:23:24.593867 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #0 | Epoch Duration: 168.0723021030426
2020-01-11 08:23:24.593998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.535223
Z variance train             0.002539057
KL Divergence                21.485203
KL Loss                      2.1485202
QF Loss                      223.86017
VF Loss                      38.405045
Policy Loss                  -93.17576
Q Predictions Mean           84.424446
Q Predictions Std            26.785002
Q Predictions Max            166.342
Q Predictions Min            0.011278097
V Predictions Mean           94.5982
V Predictions Std            20.81994
V Predictions Max            161.74763
V Predictions Min            15.021339
Log Pis Mean                 -2.0361335
Log Pis Std                  1.7150192
Log Pis Max                  1.6322354
Log Pis Min                  -8.368288
Policy mu Mean               -0.049447227
Policy mu Std                0.40883377
Policy mu Max                1.4428058
Policy mu Min                -1.5870926
Policy log std Mean          -0.84241354
Policy log std Std           0.10696146
Policy log std Max           -0.2869303
Policy log std Min           -1.1868913
Z mean eval                  1.5809927
Z variance eval              0.001588004
total_rewards                [-99.9503157  -12.4779703  -35.22147832 -11.84326064 -32.87498228
  -6.69572589 -66.31007209  -3.19158989 -13.46108049 -38.90492701]
total_rewards_mean           -32.093140262482144
total_rewards_std            29.07660113637623
total_rewards_max            -3.191589894287707
total_rewards_min            -99.95031570284881
Number of train steps total  8000
Number of env steps total    9819
Number of rollouts total     0
Train Time (s)               143.63312068395317
(Previous) Eval Time (s)     7.723152302205563
Sample Time (s)              7.964425989892334
Epoch Time (s)               159.32069897605106
Total Train Time (s)         327.68515238165855
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:26:04.221305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #1 | Epoch Duration: 159.62717843055725
2020-01-11 08:26:04.221544 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5847409
Z variance train             0.0015810305
KL Divergence                23.011051
KL Loss                      2.3011053
QF Loss                      222.69705
VF Loss                      65.89524
Policy Loss                  -170.9411
Q Predictions Mean           162.13777
Q Predictions Std            32.08539
Q Predictions Max            241.68143
Q Predictions Min            -7.0972652
V Predictions Mean           172.93689
V Predictions Std            28.921238
V Predictions Max            235.83528
V Predictions Min            67.134964
Log Pis Mean                 -1.2251359
Log Pis Std                  2.0212312
Log Pis Max                  3.1696727
Log Pis Min                  -8.284529
Policy mu Mean               0.019192772
Policy mu Std                0.5818333
Policy mu Max                1.7446042
Policy mu Min                -2.046539
Policy log std Mean          -0.8290905
Policy log std Std           0.116126984
Policy log std Max           -0.42125756
Policy log std Min           -1.2268164
Z mean eval                  1.56933
Z variance eval              0.0015684605
total_rewards                [-198.57388954   -8.56420794   17.38501423  -27.82821409   11.28844701
 -210.64904419 -262.30720097    0.42635258  -12.16887372 -193.56165552]
total_rewards_mean           -88.4553272144037
total_rewards_std            106.42275538715091
total_rewards_max            17.385014231902016
total_rewards_min            -262.3072009711935
Number of train steps total  12000
Number of env steps total    12747
Number of rollouts total     0
Train Time (s)               140.50160865997896
(Previous) Eval Time (s)     11.179489087779075
Sample Time (s)              7.812925790436566
Epoch Time (s)               159.4940235381946
Total Train Time (s)         487.2798255495727
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:28:43.805377 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #2 | Epoch Duration: 159.58366918563843
2020-01-11 08:28:43.805505 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5637276
Z variance train             0.0015736436
KL Divergence                22.281536
KL Loss                      2.2281537
QF Loss                      272.26343
VF Loss                      70.36281
Policy Loss                  -215.00937
Q Predictions Mean           207.462
Q Predictions Std            31.022535
Q Predictions Max            337.45187
Q Predictions Min            84.76316
V Predictions Mean           217.98495
V Predictions Std            26.762302
V Predictions Max            349.05933
V Predictions Min            126.4937
Log Pis Mean                 -1.2424325
Log Pis Std                  2.3547451
Log Pis Max                  6.6250844
Log Pis Min                  -7.117813
Policy mu Mean               -0.057376362
Policy mu Std                0.61623734
Policy mu Max                1.8418559
Policy mu Min                -2.0078223
Policy log std Mean          -0.7802205
Policy log std Std           0.13433044
Policy log std Max           -0.3382483
Policy log std Min           -1.2722962
Z mean eval                  1.5246235
Z variance eval              0.006447082
total_rewards                [ 15.76361833  -4.82105768   3.19790462  36.85960806  12.41773092
 -75.2109068   87.05118901   3.29508395 -26.68325748  14.51092664]
total_rewards_mean           6.638083956494185
total_rewards_std            39.39817359304591
total_rewards_max            87.05118900777097
total_rewards_min            -75.21090680186745
Number of train steps total  16000
Number of env steps total    16348
Number of rollouts total     0
Train Time (s)               141.14424989419058
(Previous) Eval Time (s)     6.201557786203921
Sample Time (s)              7.594909273087978
Epoch Time (s)               154.94071695348248
Total Train Time (s)         642.3184388526715
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:31:18.845530 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #3 | Epoch Duration: 155.03992128372192
2020-01-11 08:31:18.845703 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5229677
Z variance train             0.006447412
KL Divergence                21.944626
KL Loss                      2.1944625
QF Loss                      223.55347
VF Loss                      61.42443
Policy Loss                  -227.44536
Q Predictions Mean           221.08647
Q Predictions Std            35.831135
Q Predictions Max            303.8636
Q Predictions Min            9.025495
V Predictions Mean           226.3139
V Predictions Std            29.409395
V Predictions Max            308.42575
V Predictions Min            116.1748
Log Pis Mean                 -1.7763858
Log Pis Std                  1.9836893
Log Pis Max                  3.798101
Log Pis Min                  -6.8104277
Policy mu Mean               -0.020057712
Policy mu Std                0.52545786
Policy mu Max                1.8466108
Policy mu Min                -1.9005436
Policy log std Mean          -0.79882586
Policy log std Std           0.13195549
Policy log std Max           -0.35789466
Policy log std Min           -1.4384389
Z mean eval                  1.4661572
Z variance eval              0.0029452401
total_rewards                [  9.0875484    9.56543034  18.64689646  69.09405464  29.87363921
  25.58990524 -11.45955574  14.57518121   2.72133534   5.603759  ]
total_rewards_mean           17.329819412073174
total_rewards_std            20.548460759838914
total_rewards_max            69.09405464230038
total_rewards_min            -11.459555741330945
Number of train steps total  20000
Number of env steps total    19120
Number of rollouts total     0
Train Time (s)               141.4204975985922
(Previous) Eval Time (s)     3.608809073921293
Sample Time (s)              7.535192318726331
Epoch Time (s)               152.56449899123982
Total Train Time (s)         794.9778623855673
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:33:51.509020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #4 | Epoch Duration: 152.66314315795898
2020-01-11 08:33:51.509336 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #4 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4681956
Z variance train             0.0029230432
KL Divergence                22.827301
KL Loss                      2.28273
QF Loss                      232.92577
VF Loss                      80.777214
Policy Loss                  -238.6563
Q Predictions Mean           233.85172
Q Predictions Std            28.142174
Q Predictions Max            311.70865
Q Predictions Min            155.69048
V Predictions Mean           238.39505
V Predictions Std            24.666147
V Predictions Max            313.77658
V Predictions Min            160.97974
Log Pis Mean                 -1.9109137
Log Pis Std                  1.9385749
Log Pis Max                  4.23965
Log Pis Min                  -7.059726
Policy mu Mean               0.018550433
Policy mu Std                0.49743122
Policy mu Max                1.7828345
Policy mu Min                -1.8451283
Policy log std Mean          -0.79878724
Policy log std Std           0.130593
Policy log std Max           -0.39536387
Policy log std Min           -1.2830074
Z mean eval                  1.4265143
Z variance eval              0.00870553
total_rewards                [61.81620524 39.00791879 31.32552528  1.28925902 12.04592351 47.20110153
 88.62110633 23.2593107  72.04828406  4.85902427]
total_rewards_mean           38.147365872693776
total_rewards_std            27.84942743406518
total_rewards_max            88.62110632830243
total_rewards_min            1.2892590220563989
Number of train steps total  24000
Number of env steps total    21945
Number of rollouts total     0
Train Time (s)               142.34915408678353
(Previous) Eval Time (s)     9.12030332768336
Sample Time (s)              7.958405234850943
Epoch Time (s)               159.42786264931783
Total Train Time (s)         954.4953376962803
Epoch                        5
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:36:31.028090 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #5 | Epoch Duration: 159.51849365234375
2020-01-11 08:36:31.028384 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4245279
Z variance train             0.008695195
KL Divergence                19.56926
KL Loss                      1.956926
QF Loss                      182.95715
VF Loss                      60.661797
Policy Loss                  -240.242
Q Predictions Mean           232.25183
Q Predictions Std            39.559616
Q Predictions Max            330.07562
Q Predictions Min            13.048765
V Predictions Mean           240.83942
V Predictions Std            29.853954
V Predictions Max            333.95178
V Predictions Min            95.88535
Log Pis Mean                 -1.8827777
Log Pis Std                  2.479256
Log Pis Max                  10.450271
Log Pis Min                  -8.377997
Policy mu Mean               -0.057779387
Policy mu Std                0.486935
Policy mu Max                1.8166187
Policy mu Min                -2.4269278
Policy log std Mean          -0.8028295
Policy log std Std           0.13313067
Policy log std Max           -0.34320432
Policy log std Min           -1.4443687
Z mean eval                  1.3936964
Z variance eval              0.012122951
total_rewards                [ 63.08266912  -5.08313512  10.90323213  -0.78961681  -3.50698179
  19.04527882  62.1231199   70.93976698  81.16355859 196.95696796]
total_rewards_mean           49.48348597692742
total_rewards_std            58.553339896394974
total_rewards_max            196.95696796360414
total_rewards_min            -5.083135122718842
Number of train steps total  28000
Number of env steps total    25122
Number of rollouts total     0
Train Time (s)               141.0259569203481
(Previous) Eval Time (s)     12.509683795273304
Sample Time (s)              8.143986309878528
Epoch Time (s)               161.67962702549994
Total Train Time (s)         1116.2801077309996
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:39:12.810764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #6 | Epoch Duration: 161.78217101097107
2020-01-11 08:39:12.810892 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3888234
Z variance train             0.01214722
KL Divergence                21.653728
KL Loss                      2.1653728
QF Loss                      230.39511
VF Loss                      54.237774
Policy Loss                  -244.51013
Q Predictions Mean           234.93526
Q Predictions Std            42.85603
Q Predictions Max            321.99234
Q Predictions Min            44.611565
V Predictions Mean           244.38263
V Predictions Std            35.896656
V Predictions Max            343.5984
V Predictions Min            98.79386
Log Pis Mean                 -1.5492263
Log Pis Std                  2.284382
Log Pis Max                  10.800283
Log Pis Min                  -9.009415
Policy mu Mean               0.012119962
Policy mu Std                0.52301115
Policy mu Max                1.6772113
Policy mu Min                -2.2616794
Policy log std Mean          -0.82523024
Policy log std Std           0.13013531
Policy log std Max           -0.38950455
Policy log std Min           -1.6412618
Z mean eval                  1.3252556
Z variance eval              0.014640711
total_rewards                [ 26.97490129  -3.10828046  24.05578818 162.05284903 137.55739021
  22.73140524  60.38425851  -0.76946509 103.60972601   6.35335486]
total_rewards_mean           53.9841927778124
total_rewards_std            56.82880115935116
total_rewards_max            162.05284902866063
total_rewards_min            -3.108280464580658
Number of train steps total  32000
Number of env steps total    27752
Number of rollouts total     0
Train Time (s)               141.66262299614027
(Previous) Eval Time (s)     6.1946642198599875
Sample Time (s)              7.561860636807978
Epoch Time (s)               155.41914785280824
Total Train Time (s)         1271.784595437348
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:41:48.317165 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #7 | Epoch Duration: 155.50616693496704
2020-01-11 08:41:48.317334 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3260273
Z variance train             0.014675239
KL Divergence                18.621807
KL Loss                      1.8621807
QF Loss                      350.96072
VF Loss                      82.78835
Policy Loss                  -255.03926
Q Predictions Mean           245.40047
Q Predictions Std            49.360344
Q Predictions Max            343.35062
Q Predictions Min            -34.725334
V Predictions Mean           253.01462
V Predictions Std            36.268757
V Predictions Max            349.01245
V Predictions Min            78.95007
Log Pis Mean                 -2.0546694
Log Pis Std                  2.5965145
Log Pis Max                  7.766448
Log Pis Min                  -10.340362
Policy mu Mean               -0.025781583
Policy mu Std                0.4996835
Policy mu Max                1.8409452
Policy mu Min                -2.394346
Policy log std Mean          -0.7924251
Policy log std Std           0.13332906
Policy log std Max           -0.38683924
Policy log std Min           -1.3487005
Z mean eval                  1.3092388
Z variance eval              0.014167669
total_rewards                [ 66.8551516   48.77715333  34.8906112  212.01620819  80.66291007
  34.29739489  86.07957251 100.57046924  67.83447783  38.73317447]
total_rewards_mean           77.07171233402231
total_rewards_std            49.9252085420889
total_rewards_max            212.0162081946058
total_rewards_min            34.29739488554038
Number of train steps total  36000
Number of env steps total    30732
Number of rollouts total     0
Train Time (s)               141.59395197592676
(Previous) Eval Time (s)     9.97757881693542
Sample Time (s)              7.443995798006654
Epoch Time (s)               159.01552659086883
Total Train Time (s)         1430.8868555328809
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:44:27.419918 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #8 | Epoch Duration: 159.10246181488037
2020-01-11 08:44:27.420054 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3006485
Z variance train             0.0141130965
KL Divergence                20.000929
KL Loss                      2.000093
QF Loss                      157.65189
VF Loss                      55.50096
Policy Loss                  -254.50287
Q Predictions Mean           248.23474
Q Predictions Std            42.05442
Q Predictions Max            347.63684
Q Predictions Min            -27.538713
V Predictions Mean           255.735
V Predictions Std            37.110832
V Predictions Max            338.49475
V Predictions Min            43.253876
Log Pis Mean                 -1.9482127
Log Pis Std                  2.1965797
Log Pis Max                  9.361324
Log Pis Min                  -8.634858
Policy mu Mean               -0.03703468
Policy mu Std                0.5086903
Policy mu Max                1.9998645
Policy mu Min                -2.1424518
Policy log std Mean          -0.79773045
Policy log std Std           0.12146983
Policy log std Max           -0.33567077
Policy log std Min           -1.3661306
Z mean eval                  1.2752041
Z variance eval              0.016947975
total_rewards                [  2.70478373  90.67964086 146.95622658 111.71119741  29.85432744
   9.23387788 245.96026817  59.28532194  40.93132791  83.83418997]
total_rewards_mean           82.1151161893172
total_rewards_std            69.69075082615733
total_rewards_max            245.96026817052143
total_rewards_min            2.704783728490112
Number of train steps total  40000
Number of env steps total    34546
Number of rollouts total     0
Train Time (s)               140.58767930371687
(Previous) Eval Time (s)     8.869370306842029
Sample Time (s)              7.52882967563346
Epoch Time (s)               156.98587928619236
Total Train Time (s)         1587.9685080777854
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:47:04.504788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #9 | Epoch Duration: 157.08458042144775
2020-01-11 08:47:04.505105 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #9 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2716494
Z variance train             0.016949352
KL Divergence                19.9461
KL Loss                      1.9946101
QF Loss                      118.43383
VF Loss                      47.96852
Policy Loss                  -265.51157
Q Predictions Mean           256.20065
Q Predictions Std            44.505463
Q Predictions Max            347.91415
Q Predictions Min            -32.078987
V Predictions Mean           266.38898
V Predictions Std            36.518963
V Predictions Max            346.9044
V Predictions Min            130.16882
Log Pis Mean                 -2.1776364
Log Pis Std                  2.1260383
Log Pis Max                  6.473493
Log Pis Min                  -7.971364
Policy mu Mean               0.031690158
Policy mu Std                0.4746193
Policy mu Max                1.9738665
Policy mu Min                -2.08809
Policy log std Mean          -0.79450125
Policy log std Std           0.11448454
Policy log std Max           -0.42741913
Policy log std Min           -1.2942061
Z mean eval                  1.2249701
Z variance eval              0.052916147
total_rewards                [ 57.76202872  73.40496994 181.26054651  25.11614882 233.6490263
  88.3178351    3.37968662 155.59808507 100.30297112 132.17303837]
total_rewards_mean           105.0964336569937
total_rewards_std            67.75163207505022
total_rewards_max            233.64902630475905
total_rewards_min            3.3796866191873063
Number of train steps total  44000
Number of env steps total    37295
Number of rollouts total     0
Train Time (s)               141.0189774800092
(Previous) Eval Time (s)     11.385064295958728
Sample Time (s)              6.7983630443923175
Epoch Time (s)               159.20240482036024
Total Train Time (s)         1747.2674076114781
Epoch                        10
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:49:43.803550 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #10 | Epoch Duration: 159.29822492599487
2020-01-11 08:49:43.803733 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2274332
Z variance train             0.0522726
KL Divergence                18.917606
KL Loss                      1.8917607
QF Loss                      152.22437
VF Loss                      45.540207
Policy Loss                  -263.60446
Q Predictions Mean           254.6348
Q Predictions Std            47.285706
Q Predictions Max            350.06577
Q Predictions Min            -5.8703737
V Predictions Mean           264.7847
V Predictions Std            38.881603
V Predictions Max            356.51883
V Predictions Min            144.98279
Log Pis Mean                 -1.769011
Log Pis Std                  2.4823027
Log Pis Max                  13.799524
Log Pis Min                  -8.403636
Policy mu Mean               0.008301479
Policy mu Std                0.50083345
Policy mu Max                1.9684383
Policy mu Min                -2.7843988
Policy log std Mean          -0.81688654
Policy log std Std           0.1297674
Policy log std Max           -0.39615852
Policy log std Min           -1.4771612
Z mean eval                  1.194039
Z variance eval              0.04699449
total_rewards                [115.17910326  18.41261368 185.49495632 300.75029527  96.39503332
  77.76595561 171.68611045 119.93004134   6.24970028 219.63874577]
total_rewards_mean           131.1502555296516
total_rewards_std            85.98813457401033
total_rewards_max            300.7502952745831
total_rewards_min            6.249700284703346
Number of train steps total  48000
Number of env steps total    40980
Number of rollouts total     0
Train Time (s)               142.55426561599597
(Previous) Eval Time (s)     10.617417114321142
Sample Time (s)              7.6141731617972255
Epoch Time (s)               160.78585589211434
Total Train Time (s)         1908.1353521449491
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:52:24.671906 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #11 | Epoch Duration: 160.86804866790771
2020-01-11 08:52:24.672029 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1936382
Z variance train             0.046965867
KL Divergence                15.472868
KL Loss                      1.5472869
QF Loss                      172.62578
VF Loss                      42.26564
Policy Loss                  -278.46985
Q Predictions Mean           270.30652
Q Predictions Std            47.19061
Q Predictions Max            384.00308
Q Predictions Min            95.54654
V Predictions Mean           278.08527
V Predictions Std            41.89321
V Predictions Max            403.81485
V Predictions Min            138.6223
Log Pis Mean                 -2.1741982
Log Pis Std                  2.1110692
Log Pis Max                  12.234837
Log Pis Min                  -9.71999
Policy mu Mean               0.011330564
Policy mu Std                0.45181355
Policy mu Max                2.4419782
Policy mu Min                -1.5957676
Policy log std Mean          -0.80341935
Policy log std Std           0.10872408
Policy log std Max           -0.4506765
Policy log std Min           -1.2434838
Z mean eval                  1.2311864
Z variance eval              0.03882878
total_rewards                [ 31.086504   222.22875562  86.51658983  13.64942101  56.58313109
  98.59159622 339.00125684 169.91858588 105.93535643 112.35327836]
total_rewards_mean           123.58644752762237
total_rewards_std            92.65473969122814
total_rewards_max            339.0012568357105
total_rewards_min            13.649421006091753
Number of train steps total  52000
Number of env steps total    44834
Number of rollouts total     0
Train Time (s)               141.20389555813745
(Previous) Eval Time (s)     7.6674763658083975
Sample Time (s)              6.962390806060284
Epoch Time (s)               155.83376273000613
Total Train Time (s)         2064.0558333857916
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:55:00.593033 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #12 | Epoch Duration: 155.92090559005737
2020-01-11 08:55:00.593163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2292631
Z variance train             0.038883634
KL Divergence                17.949032
KL Loss                      1.7949032
QF Loss                      179.11816
VF Loss                      63.425453
Policy Loss                  -286.91293
Q Predictions Mean           279.31064
Q Predictions Std            54.804264
Q Predictions Max            391.30582
Q Predictions Min            -36.565144
V Predictions Mean           287.46466
V Predictions Std            43.118183
V Predictions Max            394.88406
V Predictions Min            117.56519
Log Pis Mean                 -2.0359697
Log Pis Std                  2.0702584
Log Pis Max                  9.949184
Log Pis Min                  -7.864011
Policy mu Mean               -0.027216857
Policy mu Std                0.45063484
Policy mu Max                1.9094499
Policy mu Min                -1.7193376
Policy log std Mean          -0.8094741
Policy log std Std           0.11764505
Policy log std Max           -0.35417628
Policy log std Min           -1.6728528
Z mean eval                  1.2352687
Z variance eval              0.05452934
total_rewards                [157.41277309   9.59449926   2.60967416 136.06163572 194.74370301
 165.84939817 184.63262655  15.41792686 159.52794001  58.48004511]
total_rewards_mean           108.4330221933601
total_rewards_std            73.78369938533017
total_rewards_max            194.74370300613242
total_rewards_min            2.6096741637623806
Number of train steps total  56000
Number of env steps total    47686
Number of rollouts total     0
Train Time (s)               141.74132389202714
(Previous) Eval Time (s)     14.031895081046969
Sample Time (s)              8.05537430010736
Epoch Time (s)               163.82859327318147
Total Train Time (s)         2227.97193700308
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:57:44.509742 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #13 | Epoch Duration: 163.91648244857788
2020-01-11 08:57:44.509876 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2521077
Z variance train             0.054572888
KL Divergence                17.619154
KL Loss                      1.7619154
QF Loss                      210.2005
VF Loss                      98.92843
Policy Loss                  -293.5371
Q Predictions Mean           280.96783
Q Predictions Std            53.73496
Q Predictions Max            378.65903
Q Predictions Min            -20.573502
V Predictions Mean           286.9347
V Predictions Std            38.751392
V Predictions Max            380.85995
V Predictions Min            180.48601
Log Pis Mean                 -1.9800464
Log Pis Std                  2.2025857
Log Pis Max                  9.677994
Log Pis Min                  -7.6182184
Policy mu Mean               0.01583523
Policy mu Std                0.47452483
Policy mu Max                2.0204568
Policy mu Min                -1.8740348
Policy log std Mean          -0.82482666
Policy log std Std           0.11782867
Policy log std Max           -0.44659817
Policy log std Min           -1.5502508
Z mean eval                  1.2409363
Z variance eval              0.027026331
total_rewards                [506.08046489 335.24534864  19.08297732 264.49959995  62.75656632
  10.709165    68.46317252  38.12536161 270.84284868 258.73018687]
total_rewards_mean           183.45356918015523
total_rewards_std            158.98740169572852
total_rewards_max            506.0804648922434
total_rewards_min            10.709164999195615
Number of train steps total  60000
Number of env steps total    50498
Number of rollouts total     0
Train Time (s)               142.0682172542438
(Previous) Eval Time (s)     11.628335029818118
Sample Time (s)              7.92507941974327
Epoch Time (s)               161.62163170380518
Total Train Time (s)         2389.684918063227
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:00:26.225030 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #14 | Epoch Duration: 161.71502447128296
2020-01-11 09:00:26.225275 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2448213
Z variance train             0.026712283
KL Divergence                17.539194
KL Loss                      1.7539195
QF Loss                      189.98056
VF Loss                      66.2955
Policy Loss                  -295.80194
Q Predictions Mean           289.14203
Q Predictions Std            52.320538
Q Predictions Max            411.57263
Q Predictions Min            -52.74068
V Predictions Mean           295.95557
V Predictions Std            42.59757
V Predictions Max            406.15912
V Predictions Min            102.23615
Log Pis Mean                 -1.7238072
Log Pis Std                  2.30844
Log Pis Max                  10.706467
Log Pis Min                  -13.135392
Policy mu Mean               -0.007913358
Policy mu Std                0.46483576
Policy mu Max                2.1267335
Policy mu Min                -2.5228608
Policy log std Mean          -0.8282003
Policy log std Std           0.108290866
Policy log std Max           -0.49230516
Policy log std Min           -1.3651485
Z mean eval                  1.0587561
Z variance eval              1.4937489
total_rewards                [346.63370201   3.40999653 300.82231335  65.24704057  40.63206447
  37.30127364 226.49318252 258.47541891 179.41056966   9.36401156]
total_rewards_mean           146.77895732239887
total_rewards_std            123.65438109333498
total_rewards_max            346.63370200744134
total_rewards_min            3.409996529751911
Number of train steps total  64000
Number of env steps total    53562
Number of rollouts total     0
Train Time (s)               143.38752017496154
(Previous) Eval Time (s)     11.41858685715124
Sample Time (s)              8.045400435570627
Epoch Time (s)               162.8515074676834
Total Train Time (s)         2552.6244476125576
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:03:09.164343 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #15 | Epoch Duration: 162.93888187408447
2020-01-11 09:03:09.164510 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0588167
Z variance train             1.4898326
KL Divergence                11.715773
KL Loss                      1.1715773
QF Loss                      2022.6699
VF Loss                      286.55435
Policy Loss                  -128.27718
Q Predictions Mean           118.53653
Q Predictions Std            67.2674
Q Predictions Max            255.98137
Q Predictions Min            -284.23486
V Predictions Mean           129.56226
V Predictions Std            57.908237
V Predictions Max            242.4132
V Predictions Min            -142.46873
Log Pis Mean                 -1.9090765
Log Pis Std                  2.458514
Log Pis Max                  9.876293
Log Pis Min                  -8.280579
Policy mu Mean               -0.040639494
Policy mu Std                0.5146521
Policy mu Max                2.6097124
Policy mu Min                -2.2331896
Policy log std Mean          -0.80797243
Policy log std Std           0.11892134
Policy log std Max           -0.28898108
Policy log std Min           -1.2553627
Z mean eval                  1.8488992
Z variance eval              0.081937194
total_rewards                [295.913051    36.29379566 202.09364123 106.99973945 345.54634259
  -5.77244881 313.10082713 327.87760705 342.17394187 226.83301881]
total_rewards_mean           219.1059515975186
total_rewards_std            124.34068170829724
total_rewards_max            345.5463425905481
total_rewards_min            -5.77244880781257
Number of train steps total  68000
Number of env steps total    57289
Number of rollouts total     0
Train Time (s)               144.97877884283662
(Previous) Eval Time (s)     13.927145711146295
Sample Time (s)              7.886932319961488
Epoch Time (s)               166.7928568739444
Total Train Time (s)         2719.5112504861318
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:05:56.053421 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #16 | Epoch Duration: 166.88872146606445
2020-01-11 09:05:56.053666 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8527167
Z variance train             0.08201
KL Divergence                19.298386
KL Loss                      1.9298385
QF Loss                      293.32727
VF Loss                      58.260406
Policy Loss                  -298.72116
Q Predictions Mean           289.9552
Q Predictions Std            63.506527
Q Predictions Max            408.04047
Q Predictions Min            -73.28572
V Predictions Mean           296.273
V Predictions Std            49.75334
V Predictions Max            415.0613
V Predictions Min            134.35818
Log Pis Mean                 -2.049823
Log Pis Std                  2.178531
Log Pis Max                  13.97377
Log Pis Min                  -7.276039
Policy mu Mean               -0.04580277
Policy mu Std                0.44421032
Policy mu Max                1.9261246
Policy mu Min                -3.279918
Policy log std Mean          -0.8269598
Policy log std Std           0.10514535
Policy log std Max           -0.36929253
Policy log std Min           -1.192596
Z mean eval                  1.614989
Z variance eval              0.025012514
total_rewards                [268.82863782 229.27390657 249.74659039 353.24339315 602.32021944
 201.7135997   66.43372248 249.13206742  37.30292237 222.0211047 ]
total_rewards_mean           248.00161640551346
total_rewards_std            147.50753406866755
total_rewards_max            602.320219442386
total_rewards_min            37.30292237426643
Number of train steps total  72000
Number of env steps total    60964
Number of rollouts total     0
Train Time (s)               143.37837423523888
(Previous) Eval Time (s)     14.41211416432634
Sample Time (s)              7.78039714274928
Epoch Time (s)               165.5708855423145
Total Train Time (s)         2885.16665915912
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:08:41.708019 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #17 | Epoch Duration: 165.65420532226562
2020-01-11 09:08:41.708205 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6186485
Z variance train             0.025127774
KL Divergence                20.569925
KL Loss                      2.0569925
QF Loss                      193.87666
VF Loss                      45.22505
Policy Loss                  -279.23798
Q Predictions Mean           270.48114
Q Predictions Std            58.081463
Q Predictions Max            420.7239
Q Predictions Min            -26.581661
V Predictions Mean           278.6746
V Predictions Std            51.00408
V Predictions Max            409.18378
V Predictions Min            101.19509
Log Pis Mean                 -1.873828
Log Pis Std                  2.2422404
Log Pis Max                  17.395588
Log Pis Min                  -7.6207347
Policy mu Mean               -0.027827777
Policy mu Std                0.44692746
Policy mu Max                2.1661773
Policy mu Min                -3.6022441
Policy log std Mean          -0.8244444
Policy log std Std           0.1083318
Policy log std Max           -0.46018952
Policy log std Min           -1.3018069
Z mean eval                  1.5015248
Z variance eval              0.7662692
total_rewards                [152.15254175 225.17801905 127.9437396  302.20359838 220.05585799
  48.43475032  98.08006492 414.18376375 519.41795981 250.04929316]
total_rewards_mean           235.7699588747831
total_rewards_std            137.81708075643488
total_rewards_max            519.4179598143894
total_rewards_min            48.4347503172058
Number of train steps total  76000
Number of env steps total    64758
Number of rollouts total     0
Train Time (s)               143.72319936798885
(Previous) Eval Time (s)     15.006077724974602
Sample Time (s)              7.306839283090085
Epoch Time (s)               166.03611637605354
Total Train Time (s)         3051.293725831434
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:11:27.836857 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #18 | Epoch Duration: 166.12850713729858
2020-01-11 09:11:27.837065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5032921
Z variance train             0.76977134
KL Divergence                18.992323
KL Loss                      1.8992323
QF Loss                      671.24695
VF Loss                      138.83588
Policy Loss                  -222.22127
Q Predictions Mean           215.94748
Q Predictions Std            59.541687
Q Predictions Max            322.37076
Q Predictions Min            -93.81781
V Predictions Mean           223.08824
V Predictions Std            56.508057
V Predictions Max            319.17032
V Predictions Min            -44.83928
Log Pis Mean                 -1.8412473
Log Pis Std                  2.5843418
Log Pis Max                  11.5242405
Log Pis Min                  -8.095678
Policy mu Mean               0.0065205633
Policy mu Std                0.4775082
Policy mu Max                3.1156282
Policy mu Min                -3.0713654
Policy log std Mean          -0.80672747
Policy log std Std           0.10518376
Policy log std Max           -0.4360979
Policy log std Min           -1.4103628
Z mean eval                  1.5659702
Z variance eval              0.08519671
total_rewards                [352.21881295 316.49720052 247.39372845 233.68928728 267.68200589
 298.18362719 369.59564698  26.08095415 434.36360688 113.38317099]
total_rewards_mean           265.90880413000997
total_rewards_std            115.040760409786
total_rewards_max            434.3636068831716
total_rewards_min            26.08095414550003
Number of train steps total  80000
Number of env steps total    68203
Number of rollouts total     0
Train Time (s)               144.4419537349604
(Previous) Eval Time (s)     14.555694070179015
Sample Time (s)              7.253929130267352
Epoch Time (s)               166.25157693540677
Total Train Time (s)         3217.6433167150244
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:14:14.187467 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #19 | Epoch Duration: 166.35027384757996
2020-01-11 09:14:14.187638 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5655575
Z variance train             0.08465521
KL Divergence                17.616304
KL Loss                      1.7616304
QF Loss                      177.31882
VF Loss                      57.578163
Policy Loss                  -294.08224
Q Predictions Mean           284.17853
Q Predictions Std            60.35532
Q Predictions Max            400.77774
Q Predictions Min            -76.69588
V Predictions Mean           293.966
V Predictions Std            52.520905
V Predictions Max            395.28995
V Predictions Min            164.30649
Log Pis Mean                 -2.2181654
Log Pis Std                  1.9603051
Log Pis Max                  8.806093
Log Pis Min                  -9.184178
Policy mu Mean               0.0016970392
Policy mu Std                0.41476235
Policy mu Max                2.1269524
Policy mu Min                -2.1040452
Policy log std Mean          -0.8174001
Policy log std Std           0.09693909
Policy log std Max           -0.4814718
Policy log std Min           -1.3366938
Z mean eval                  1.5024348
Z variance eval              0.08193548
total_rewards                [127.85180996   8.157573   111.96237289 329.87033876  86.77304458
 416.76689973 221.03051555 240.97657915   9.72749056 221.78225667]
total_rewards_mean           177.48988808466186
total_rewards_std            126.5568824072273
total_rewards_max            416.7668997278629
total_rewards_min            8.157573000407616
Number of train steps total  84000
Number of env steps total    71066
Number of rollouts total     0
Train Time (s)               142.53482521604747
(Previous) Eval Time (s)     8.342148256953806
Sample Time (s)              7.468750944826752
Epoch Time (s)               158.34572441782802
Total Train Time (s)         3376.096176865045
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:16:52.640217 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #20 | Epoch Duration: 158.45246052742004
2020-01-11 09:16:52.640346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4981943
Z variance train             0.08244977
KL Divergence                16.088373
KL Loss                      1.6088374
QF Loss                      207.05843
VF Loss                      93.13861
Policy Loss                  -294.05203
Q Predictions Mean           285.94122
Q Predictions Std            62.23448
Q Predictions Max            425.43704
Q Predictions Min            120.31994
V Predictions Mean           300.91284
V Predictions Std            59.534122
V Predictions Max            426.5782
V Predictions Min            159.7103
Log Pis Mean                 -2.2562847
Log Pis Std                  1.8100909
Log Pis Max                  6.431778
Log Pis Min                  -8.03288
Policy mu Mean               -0.012776082
Policy mu Std                0.41358668
Policy mu Max                2.6456568
Policy mu Min                -2.2154357
Policy log std Mean          -0.82336783
Policy log std Std           0.09999219
Policy log std Max           -0.52522075
Policy log std Min           -1.35631
Z mean eval                  1.4743296
Z variance eval              0.092788436
total_rewards                [293.18976313 171.11514385 334.66350532  90.31564907  26.35651398
 406.93175549 269.63931987 592.5441753   42.75987275  81.18221033]
total_rewards_mean           230.86979090843852
total_rewards_std            173.4674737006214
total_rewards_max            592.5441752960861
total_rewards_min            26.356513976082972
Number of train steps total  88000
Number of env steps total    73850
Number of rollouts total     0
Train Time (s)               143.6683506811969
(Previous) Eval Time (s)     11.781096684746444
Sample Time (s)              7.013875283300877
Epoch Time (s)               162.46332264924422
Total Train Time (s)         3538.6411225702614
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:19:35.185634 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #21 | Epoch Duration: 162.54519653320312
2020-01-11 09:19:35.185768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4752138
Z variance train             0.09330125
KL Divergence                17.032389
KL Loss                      1.7032388
QF Loss                      211.0748
VF Loss                      55.888504
Policy Loss                  -319.42764
Q Predictions Mean           309.96014
Q Predictions Std            68.95718
Q Predictions Max            444.88144
Q Predictions Min            -70.65219
V Predictions Mean           319.13043
V Predictions Std            60.189083
V Predictions Max            447.16458
V Predictions Min            5.262998
Log Pis Mean                 -2.1116743
Log Pis Std                  2.2307985
Log Pis Max                  6.1221905
Log Pis Min                  -8.911749
Policy mu Mean               0.013008196
Policy mu Std                0.44260246
Policy mu Max                2.334398
Policy mu Min                -2.5458162
Policy log std Mean          -0.8271872
Policy log std Std           0.114999756
Policy log std Max           -0.51716894
Policy log std Min           -1.3650633
Z mean eval                  1.3903623
Z variance eval              0.6875854
total_rewards                [ 63.74746979 249.96287943 438.65335772 245.88785345 250.77000321
 368.00362111 332.38331739 395.71358642 287.68479416 373.75321587]
total_rewards_mean           300.6560098567862
total_rewards_std            101.64477461835655
total_rewards_max            438.65335772234044
total_rewards_min            63.74746979119476
Number of train steps total  92000
Number of env steps total    77681
Number of rollouts total     0
Train Time (s)               142.7529658190906
(Previous) Eval Time (s)     15.884361335076392
Sample Time (s)              7.100043709855527
Epoch Time (s)               165.73737086402252
Total Train Time (s)         3704.494678440038
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:22:21.041264 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #22 | Epoch Duration: 165.85537815093994
2020-01-11 09:22:21.041416 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3871938
Z variance train             0.69348097
KL Divergence                14.421608
KL Loss                      1.4421608
QF Loss                      337.36447
VF Loss                      78.72338
Policy Loss                  -303.72055
Q Predictions Mean           292.19946
Q Predictions Std            64.52302
Q Predictions Max            430.70395
Q Predictions Min            26.926544
V Predictions Mean           302.93048
V Predictions Std            59.956234
V Predictions Max            434.84653
V Predictions Min            101.955925
Log Pis Mean                 -2.2468586
Log Pis Std                  2.124006
Log Pis Max                  10.372297
Log Pis Min                  -10.432875
Policy mu Mean               -0.004841093
Policy mu Std                0.40892076
Policy mu Max                1.7377211
Policy mu Min                -2.6567407
Policy log std Mean          -0.80307055
Policy log std Std           0.098330505
Policy log std Max           -0.44332024
Policy log std Min           -1.299946
Z mean eval                  1.4131432
Z variance eval              0.15631346
total_rewards                [246.58095466 124.03198135 395.9003044   49.09799333 316.11446728
 285.66156198 160.64477439 171.11617651 118.80788625 150.54414958]
total_rewards_mean           201.85002497209933
total_rewards_std            100.64624502868733
total_rewards_max            395.9003043983193
total_rewards_min            49.09799332662413
Number of train steps total  96000
Number of env steps total    80414
Number of rollouts total     0
Train Time (s)               141.5497364392504
(Previous) Eval Time (s)     8.805050702765584
Sample Time (s)              6.915667461231351
Epoch Time (s)               157.27045460324734
Total Train Time (s)         3861.8546038009226
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:24:58.401790 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #23 | Epoch Duration: 157.36025142669678
2020-01-11 09:24:58.401955 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4139732
Z variance train             0.15594356
KL Divergence                15.520876
KL Loss                      1.5520877
QF Loss                      192.63638
VF Loss                      54.832005
Policy Loss                  -319.97522
Q Predictions Mean           312.87827
Q Predictions Std            65.37383
Q Predictions Max            469.3539
Q Predictions Min            5.033638
V Predictions Mean           318.47568
V Predictions Std            61.24233
V Predictions Max            453.18173
V Predictions Min            -44.648167
Log Pis Mean                 -2.0431437
Log Pis Std                  2.681402
Log Pis Max                  16.09293
Log Pis Min                  -10.850538
Policy mu Mean               0.01553829
Policy mu Std                0.4562821
Policy mu Max                2.7348514
Policy mu Min                -2.2647343
Policy log std Mean          -0.8198958
Policy log std Std           0.10336813
Policy log std Max           -0.36551303
Policy log std Min           -1.2241317
Z mean eval                  1.3098786
Z variance eval              0.080687486
total_rewards                [581.86826413 541.26648134 264.38845191  66.39073959 570.76130508
 151.08914333 486.43352493  12.48396833 314.23556636 349.85761407]
total_rewards_mean           333.8775059070619
total_rewards_std            199.40444740854227
total_rewards_max            581.8682641285448
total_rewards_min            12.483968327974656
Number of train steps total  100000
Number of env steps total    83946
Number of rollouts total     0
Train Time (s)               142.9686995120719
(Previous) Eval Time (s)     16.685245614033192
Sample Time (s)              7.064676808658987
Epoch Time (s)               166.7186219347641
Total Train Time (s)         4028.660490890965
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:27:45.208505 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #24 | Epoch Duration: 166.80641984939575
2020-01-11 09:27:45.208670 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3081201
Z variance train             0.08075199
KL Divergence                18.646107
KL Loss                      1.8646107
QF Loss                      240.99005
VF Loss                      69.98252
Policy Loss                  -334.93954
Q Predictions Mean           325.36362
Q Predictions Std            71.093285
Q Predictions Max            457.85498
Q Predictions Min            13.229513
V Predictions Mean           336.22168
V Predictions Std            63.43798
V Predictions Max            449.2353
V Predictions Min            189.83778
Log Pis Mean                 -1.9100759
Log Pis Std                  2.2490897
Log Pis Max                  10.036042
Log Pis Min                  -11.21586
Policy mu Mean               -0.023853466
Policy mu Std                0.4612702
Policy mu Max                2.657051
Policy mu Min                -2.586003
Policy log std Mean          -0.8394362
Policy log std Std           0.11208384
Policy log std Max           -0.5099423
Policy log std Min           -1.4350185
Z mean eval                  1.2259628
Z variance eval              0.15652607
total_rewards                [561.21885508 213.14550686 519.51753997  10.41608691 543.15843348
 151.92207822  40.40494806 386.76133859  89.67416288 324.00214691]
total_rewards_mean           284.02210969714616
total_rewards_std            201.50834545794294
total_rewards_max            561.2188550813192
total_rewards_min            10.416086910486815
Number of train steps total  104000
Number of env steps total    87403
Number of rollouts total     0
Train Time (s)               142.75435244105756
(Previous) Eval Time (s)     12.072514201048762
Sample Time (s)              6.117637334857136
Epoch Time (s)               160.94450397696346
Total Train Time (s)         4189.697303767782
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:30:26.249137 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #25 | Epoch Duration: 161.04030323028564
2020-01-11 09:30:26.249428 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #25 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2195035
Z variance train             0.15512276
KL Divergence                17.382479
KL Loss                      1.7382479
QF Loss                      238.93893
VF Loss                      45.25714
Policy Loss                  -330.92038
Q Predictions Mean           321.8761
Q Predictions Std            77.6279
Q Predictions Max            450.77884
Q Predictions Min            -31.453953
V Predictions Mean           331.1342
V Predictions Std            65.79694
V Predictions Max            445.78934
V Predictions Min            164.49243
Log Pis Mean                 -1.9123558
Log Pis Std                  2.228312
Log Pis Max                  10.719575
Log Pis Min                  -8.109683
Policy mu Mean               0.020845769
Policy mu Std                0.4579276
Policy mu Max                2.7725403
Policy mu Min                -2.0386605
Policy log std Mean          -0.843554
Policy log std Std           0.113587715
Policy log std Max           -0.44719946
Policy log std Min           -1.5740663
Z mean eval                  1.1309605
Z variance eval              0.16333702
total_rewards                [213.92989556  68.02926084 188.59257649 125.49175944  54.9466313
 475.04275066 721.93340853 387.90477344 134.08081699 208.81590506]
total_rewards_mean           257.87677782959776
total_rewards_std            199.65706880576437
total_rewards_max            721.9334085291596
total_rewards_min            54.946631297471605
Number of train steps total  108000
Number of env steps total    91708
Number of rollouts total     0
Train Time (s)               141.64102173689753
(Previous) Eval Time (s)     8.60058242501691
Sample Time (s)              6.343710031360388
Epoch Time (s)               156.58531419327483
Total Train Time (s)         4346.379768752959
Epoch                        26
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:33:02.932888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #26 | Epoch Duration: 156.6832504272461
2020-01-11 09:33:02.933076 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1205807
Z variance train             0.16398205
KL Divergence                16.551863
KL Loss                      1.6551863
QF Loss                      173.3744
VF Loss                      65.40105
Policy Loss                  -335.28363
Q Predictions Mean           327.718
Q Predictions Std            75.40283
Q Predictions Max            463.47305
Q Predictions Min            59.821976
V Predictions Mean           339.85916
V Predictions Std            70.591255
V Predictions Max            469.45285
V Predictions Min            127.38439
Log Pis Mean                 -1.9890933
Log Pis Std                  2.3838682
Log Pis Max                  10.665473
Log Pis Min                  -7.6427603
Policy mu Mean               -0.0028432868
Policy mu Std                0.4588486
Policy mu Max                2.9649334
Policy mu Min                -2.0214546
Policy log std Mean          -0.8449781
Policy log std Std           0.11363183
Policy log std Max           -0.5502223
Policy log std Min           -1.5646765
Z mean eval                  1.1037648
Z variance eval              0.13311133
total_rewards                [ 70.51086802 219.11133819 339.46985459 120.91933211 316.57819443
 673.47218648 489.76897173 270.12625988 276.70674817  76.17429613]
total_rewards_mean           285.28380497265516
total_rewards_std            178.31765567582684
total_rewards_max            673.472186478164
total_rewards_min            70.51086801652134
Number of train steps total  112000
Number of env steps total    94507
Number of rollouts total     0
Train Time (s)               144.19412518804893
(Previous) Eval Time (s)     12.658020064700395
Sample Time (s)              8.327515542972833
Epoch Time (s)               165.17966079572216
Total Train Time (s)         4511.645366039593
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:35:48.198860 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #27 | Epoch Duration: 165.2656307220459
2020-01-11 09:35:48.199034 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1019944
Z variance train             0.1334705
KL Divergence                17.18074
KL Loss                      1.7180741
QF Loss                      214.6241
VF Loss                      49.03959
Policy Loss                  -358.36777
Q Predictions Mean           349.3233
Q Predictions Std            80.814865
Q Predictions Max            492.40616
Q Predictions Min            20.09486
V Predictions Mean           361.51193
V Predictions Std            74.49082
V Predictions Max            495.45294
V Predictions Min            208.2307
Log Pis Mean                 -2.003181
Log Pis Std                  2.085034
Log Pis Max                  5.253095
Log Pis Min                  -10.26448
Policy mu Mean               0.020853147
Policy mu Std                0.44186527
Policy mu Max                2.1138086
Policy mu Min                -2.032359
Policy log std Mean          -0.83340275
Policy log std Std           0.11321932
Policy log std Max           -0.5148459
Policy log std Min           -1.3710018
Z mean eval                  1.1192663
Z variance eval              0.108401515
total_rewards                [316.44744569  45.15213591 461.37600326 142.24978323 104.61286767
 506.50163878 329.65259699 360.12653954 348.54768216  25.94038984]
total_rewards_mean           264.0607083072814
total_rewards_std            163.09753329677372
total_rewards_max            506.5016387794414
total_rewards_min            25.940389840973236
Number of train steps total  116000
Number of env steps total    100101
Number of rollouts total     0
Train Time (s)               143.20220974413678
(Previous) Eval Time (s)     11.985057478770614
Sample Time (s)              7.961622848175466
Epoch Time (s)               163.14889007108286
Total Train Time (s)         4674.883919271175
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:38:31.437996 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #28 | Epoch Duration: 163.23882794380188
2020-01-11 09:38:31.438170 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.116224
Z variance train             0.10759542
KL Divergence                19.444387
KL Loss                      1.9444388
QF Loss                      232.53821
VF Loss                      119.171455
Policy Loss                  -360.52274
Q Predictions Mean           349.4389
Q Predictions Std            85.880936
Q Predictions Max            518.9741
Q Predictions Min            -29.775343
V Predictions Mean           368.8484
V Predictions Std            77.473694
V Predictions Max            538.94586
V Predictions Min            0.036931574
Log Pis Mean                 -2.01465
Log Pis Std                  2.733683
Log Pis Max                  19.02517
Log Pis Min                  -10.701426
Policy mu Mean               -0.012105611
Policy mu Std                0.4366371
Policy mu Max                3.1537638
Policy mu Min                -2.7296937
Policy log std Mean          -0.86076105
Policy log std Std           0.11782113
Policy log std Max           -0.43276638
Policy log std Min           -1.5738311
Z mean eval                  1.1106718
Z variance eval              0.10046746
total_rewards                [449.86018573 186.30581641 213.91841337  50.95165404 517.18930189
 402.77505018 655.61109069 409.85901451  33.90257992 219.12176694]
total_rewards_mean           313.94948736785966
total_rewards_std            194.03220327946957
total_rewards_max            655.6110906935247
total_rewards_min            33.902579924261836
Number of train steps total  120000
Number of env steps total    103341
Number of rollouts total     0
Train Time (s)               142.08452523406595
(Previous) Eval Time (s)     14.1843277993612
Sample Time (s)              8.319545150268823
Epoch Time (s)               164.58839818369597
Total Train Time (s)         4839.563770557288
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:41:16.118008 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #29 | Epoch Duration: 164.67972087860107
2020-01-11 09:41:16.118132 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1056046
Z variance train             0.099327974
KL Divergence                19.248423
KL Loss                      1.9248422
QF Loss                      338.3604
VF Loss                      113.61623
Policy Loss                  -362.89432
Q Predictions Mean           352.21918
Q Predictions Std            89.36734
Q Predictions Max            510.61313
Q Predictions Min            -26.054409
V Predictions Mean           367.72214
V Predictions Std            80.495155
V Predictions Max            517.4721
V Predictions Min            132.83145
Log Pis Mean                 -2.249192
Log Pis Std                  2.1486652
Log Pis Max                  7.29768
Log Pis Min                  -9.67733
Policy mu Mean               -0.0005794205
Policy mu Std                0.44045898
Policy mu Max                2.9191291
Policy mu Min                -2.2857935
Policy log std Mean          -0.82686794
Policy log std Std           0.113437556
Policy log std Max           -0.42223835
Policy log std Min           -1.31878
Z mean eval                  1.074774
Z variance eval              0.09478013
total_rewards                [ 210.74335057  283.60044467  299.809604   1120.881135    500.56943974
  407.56122299  405.1170959    25.00055703   76.20834919  104.03909275]
total_rewards_mean           343.35302918428147
total_rewards_std            298.3692195936439
total_rewards_max            1120.8811349985583
total_rewards_min            25.000557031206267
Number of train steps total  124000
Number of env steps total    106912
Number of rollouts total     0
Train Time (s)               143.6474451040849
(Previous) Eval Time (s)     10.709175459109247
Sample Time (s)              7.593364006374031
Epoch Time (s)               161.9499845695682
Total Train Time (s)         5001.608041541185
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:58.165383 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #30 | Epoch Duration: 162.047123670578
2020-01-11 09:43:58.165640 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0755671
Z variance train             0.09470978
KL Divergence                18.9091
KL Loss                      1.89091
QF Loss                      264.11978
VF Loss                      95.569565
Policy Loss                  -384.71353
Q Predictions Mean           375.18594
Q Predictions Std            88.98485
Q Predictions Max            559.04584
Q Predictions Min            -14.313609
V Predictions Mean           386.8661
V Predictions Std            80.2772
V Predictions Max            562.9017
V Predictions Min            179.62364
Log Pis Mean                 -1.9375725
Log Pis Std                  2.3986297
Log Pis Max                  12.750274
Log Pis Min                  -7.17223
Policy mu Mean               -0.009041311
Policy mu Std                0.45056105
Policy mu Max                2.3169467
Policy mu Min                -2.6601737
Policy log std Mean          -0.8321742
Policy log std Std           0.1185514
Policy log std Max           -0.4286998
Policy log std Min           -1.3970866
Z mean eval                  1.1547363
Z variance eval              0.12876478
total_rewards                [272.84418594 198.14864978  33.84387483 139.66647204 674.70174621
 117.6859803  110.53438757 359.0885685  458.52091433 563.14932796]
total_rewards_mean           292.81841074471515
total_rewards_std            203.60408477841216
total_rewards_max            674.7017462086388
total_rewards_min            33.843874827480235
Number of train steps total  128000
Number of env steps total    110805
Number of rollouts total     0
Train Time (s)               142.86400828510523
(Previous) Eval Time (s)     8.992753934115171
Sample Time (s)              7.71446796413511
Epoch Time (s)               159.5712301833555
Total Train Time (s)         5161.373150805477
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:37.930277 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #31 | Epoch Duration: 159.76445198059082
2020-01-11 09:46:37.930440 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1450804
Z variance train             0.12800312
KL Divergence                17.86685
KL Loss                      1.786685
QF Loss                      257.07666
VF Loss                      78.816154
Policy Loss                  -384.28223
Q Predictions Mean           375.40405
Q Predictions Std            99.13603
Q Predictions Max            552.61456
Q Predictions Min            -59.88419
V Predictions Mean           385.71667
V Predictions Std            89.25545
V Predictions Max            554.1905
V Predictions Min            24.373487
Log Pis Mean                 -1.7707058
Log Pis Std                  2.2552295
Log Pis Max                  7.109766
Log Pis Min                  -7.683359
Policy mu Mean               -0.033412416
Policy mu Std                0.43847066
Policy mu Max                1.7211605
Policy mu Min                -2.6917052
Policy log std Mean          -0.8844969
Policy log std Std           0.11824624
Policy log std Max           -0.47739404
Policy log std Min           -1.3613063
Z mean eval                  1.1032331
Z variance eval              0.106402494
total_rewards                [374.92541288 408.06952451 363.31595295 415.52254661 391.33211651
 410.37240015 576.225536   524.80027439 126.27610574 106.46515777]
total_rewards_mean           369.73050274957916
total_rewards_std            141.7811119557516
total_rewards_max            576.2255359955942
total_rewards_min            106.46515777472476
Number of train steps total  132000
Number of env steps total    113690
Number of rollouts total     0
Train Time (s)               142.8146190578118
(Previous) Eval Time (s)     13.2027652929537
Sample Time (s)              8.376736132893711
Epoch Time (s)               164.3941204836592
Total Train Time (s)         5325.858129440807
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:49:22.417775 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #32 | Epoch Duration: 164.4871861934662
2020-01-11 09:49:22.418016 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1087506
Z variance train             0.10542886
KL Divergence                18.54756
KL Loss                      1.854756
QF Loss                      264.89352
VF Loss                      67.68289
Policy Loss                  -405.21594
Q Predictions Mean           396.46823
Q Predictions Std            91.16578
Q Predictions Max            561.1896
Q Predictions Min            100.052444
V Predictions Mean           401.8074
V Predictions Std            84.94592
V Predictions Max            559.67523
V Predictions Min            232.39539
Log Pis Mean                 -1.8012497
Log Pis Std                  2.162829
Log Pis Max                  8.087252
Log Pis Min                  -8.35373
Policy mu Mean               0.025496434
Policy mu Std                0.4199973
Policy mu Max                2.3041568
Policy mu Min                -2.1440327
Policy log std Mean          -0.8576665
Policy log std Std           0.1143531
Policy log std Max           -0.53531015
Policy log std Min           -1.403902
Z mean eval                  1.1221493
Z variance eval              0.101386234
total_rewards                [284.94949633 594.59187618 685.04315966 354.66537626 443.64580125
  39.23062143  44.51729652  96.68778371  18.91409825  91.22666047]
total_rewards_mean           265.34721700517264
total_rewards_std            233.25670862552153
total_rewards_max            685.0431596570926
total_rewards_min            18.91409825049008
Number of train steps total  136000
Number of env steps total    117696
Number of rollouts total     0
Train Time (s)               142.12019307166338
(Previous) Eval Time (s)     11.238026249688119
Sample Time (s)              8.747813567053527
Epoch Time (s)               162.10603288840503
Total Train Time (s)         5488.053823657334
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:52:04.613171 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #33 | Epoch Duration: 162.19497275352478
2020-01-11 09:52:04.613337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1171304
Z variance train             0.10234468
KL Divergence                19.944416
KL Loss                      1.9944416
QF Loss                      277.0011
VF Loss                      56.285686
Policy Loss                  -397.01846
Q Predictions Mean           390.45837
Q Predictions Std            99.35573
Q Predictions Max            594.55273
Q Predictions Min            66.78801
V Predictions Mean           396.06927
V Predictions Std            93.08624
V Predictions Max            596.4248
V Predictions Min            218.38644
Log Pis Mean                 -1.7749093
Log Pis Std                  2.1505601
Log Pis Max                  6.5904665
Log Pis Min                  -7.284731
Policy mu Mean               0.029525515
Policy mu Std                0.45406467
Policy mu Max                2.8583255
Policy mu Min                -2.2743094
Policy log std Mean          -0.84704053
Policy log std Std           0.11979663
Policy log std Max           -0.36370206
Policy log std Min           -1.4752563
Z mean eval                  1.0854514
Z variance eval              0.055853046
total_rewards                [1016.03468982  102.43047738   38.81594039  155.04266388   10.63897794
  926.40723984  571.15600769 1198.28833341  337.92570883  608.54651794]
total_rewards_mean           496.5286557105069
total_rewards_std            413.271903860628
total_rewards_max            1198.2883334143291
total_rewards_min            10.63897793972126
Number of train steps total  140000
Number of env steps total    120739
Number of rollouts total     0
Train Time (s)               144.71449408773333
(Previous) Eval Time (s)     11.321788186673075
Sample Time (s)              8.24483651155606
Epoch Time (s)               164.28111878596246
Total Train Time (s)         5652.424280517735
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:54:48.986430 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #34 | Epoch Duration: 164.3729374408722
2020-01-11 09:54:48.986701 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0820919
Z variance train             0.056214966
KL Divergence                20.59255
KL Loss                      2.0592551
QF Loss                      232.02417
VF Loss                      65.56311
Policy Loss                  -388.45895
Q Predictions Mean           382.77142
Q Predictions Std            97.52831
Q Predictions Max            552.40515
Q Predictions Min            87.5926
V Predictions Mean           391.41852
V Predictions Std            93.366905
V Predictions Max            553.24976
V Predictions Min            197.76437
Log Pis Mean                 -2.0016265
Log Pis Std                  2.2006228
Log Pis Max                  8.782451
Log Pis Min                  -8.318294
Policy mu Mean               -0.018898422
Policy mu Std                0.41575983
Policy mu Max                2.4420671
Policy mu Min                -1.8765944
Policy log std Mean          -0.8600266
Policy log std Std           0.12425919
Policy log std Max           -0.4328881
Policy log std Min           -1.4726084
Z mean eval                  1.0805526
Z variance eval              0.10727088
total_rewards                [313.46257816 280.14411366 688.3029371  354.60468415 289.24591321
 267.95366718 575.48134954 397.09077334 513.63651022  23.03796012]
total_rewards_mean           370.2960486681885
total_rewards_std            177.123893139607
total_rewards_max            688.3029370965892
total_rewards_min            23.037960123213534
Number of train steps total  144000
Number of env steps total    124222
Number of rollouts total     0
Train Time (s)               144.09971705824137
(Previous) Eval Time (s)     14.909898562822491
Sample Time (s)              7.055587999988347
Epoch Time (s)               166.0652036210522
Total Train Time (s)         5818.579128027428
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:57:35.140063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #35 | Epoch Duration: 166.1531891822815
2020-01-11 09:57:35.140183 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #35 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0774615
Z variance train             0.10640633
KL Divergence                19.953634
KL Loss                      1.9953635
QF Loss                      192.32544
VF Loss                      58.29748
Policy Loss                  -404.74268
Q Predictions Mean           394.31952
Q Predictions Std            101.491356
Q Predictions Max            559.32043
Q Predictions Min            -36.205006
V Predictions Mean           407.19858
V Predictions Std            94.912636
V Predictions Max            570.7277
V Predictions Min            164.02367
Log Pis Mean                 -1.8818517
Log Pis Std                  2.4786916
Log Pis Max                  17.84372
Log Pis Min                  -8.235384
Policy mu Mean               -0.011347462
Policy mu Std                0.44506493
Policy mu Max                3.0210001
Policy mu Min                -2.646601
Policy log std Mean          -0.83684033
Policy log std Std           0.11376637
Policy log std Max           -0.42856455
Policy log std Min           -1.6592407
Z mean eval                  1.2089663
Z variance eval              0.08615413
total_rewards                [ 446.44947821  270.33032014  298.2945075   126.15877202  434.1032674
  311.3045004    95.27419322   85.39282321  347.73114975 1242.17465963]
total_rewards_mean           365.72136715047566
total_rewards_std            317.0820345079829
total_rewards_max            1242.1746596337462
total_rewards_min            85.39282321352356
Number of train steps total  148000
Number of env steps total    127664
Number of rollouts total     0
Train Time (s)               144.86841916199774
(Previous) Eval Time (s)     14.143510308116674
Sample Time (s)              7.499639661051333
Epoch Time (s)               166.51156913116574
Total Train Time (s)         5985.171309363563
Epoch                        36
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:00:21.733669 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #36 | Epoch Duration: 166.59339451789856
2020-01-11 10:00:21.733797 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2114908
Z variance train             0.085985385
KL Divergence                19.30655
KL Loss                      1.9306549
QF Loss                      364.92087
VF Loss                      50.93561
Policy Loss                  -393.2883
Q Predictions Mean           380.23694
Q Predictions Std            110.175896
Q Predictions Max            561.61304
Q Predictions Min            -38.21148
V Predictions Mean           390.89255
V Predictions Std            98.04447
V Predictions Max            567.275
V Predictions Min            149.67651
Log Pis Mean                 -2.003271
Log Pis Std                  2.65161
Log Pis Max                  21.054302
Log Pis Min                  -7.614522
Policy mu Mean               -0.0067068674
Policy mu Std                0.44692856
Policy mu Max                2.8535385
Policy mu Min                -3.140146
Policy log std Mean          -0.82663226
Policy log std Std           0.11832117
Policy log std Max           -0.26653123
Policy log std Min           -1.3466125
Z mean eval                  1.166592
Z variance eval              0.118464805
total_rewards                [ 392.78013666  496.72851534  146.27478842  484.23726545  594.59691145
  732.24569635  980.09649335 1408.65646473  856.11026762  437.91149333]
total_rewards_mean           652.9638032695893
total_rewards_std            339.5000586202499
total_rewards_max            1408.65646473404
total_rewards_min            146.2747884196358
Number of train steps total  152000
Number of env steps total    131631
Number of rollouts total     0
Train Time (s)               145.6553304749541
(Previous) Eval Time (s)     21.486014015972614
Sample Time (s)              7.998161303810775
Epoch Time (s)               175.1395057947375
Total Train Time (s)         6160.401113722008
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:03:16.967403 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #37 | Epoch Duration: 175.23349714279175
2020-01-11 10:03:16.967584 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.169514
Z variance train             0.119818665
KL Divergence                18.922022
KL Loss                      1.8922023
QF Loss                      277.3725
VF Loss                      59.06952
Policy Loss                  -432.26447
Q Predictions Mean           423.54898
Q Predictions Std            102.55293
Q Predictions Max            589.3574
Q Predictions Min            47.20288
V Predictions Mean           433.8764
V Predictions Std            97.152374
V Predictions Max            590.3503
V Predictions Min            144.30835
Log Pis Mean                 -1.824514
Log Pis Std                  2.4808707
Log Pis Max                  16.950676
Log Pis Min                  -8.916624
Policy mu Mean               -0.013823075
Policy mu Std                0.44914782
Policy mu Max                2.6909401
Policy mu Min                -2.9332314
Policy log std Mean          -0.8534274
Policy log std Std           0.12831454
Policy log std Max           -0.43703684
Policy log std Min           -1.525892
Z mean eval                  1.1108648
Z variance eval              0.14158583
total_rewards                [ 354.09818568  744.45663244  167.6259722   812.10725668   44.80068687
  312.89839213  619.32085183 1333.18439032  391.56255955  172.86063211]
total_rewards_mean           495.2915559803323
total_rewards_std            368.5287083734181
total_rewards_max            1333.184390323913
total_rewards_min            44.8006868689949
Number of train steps total  156000
Number of env steps total    135763
Number of rollouts total     0
Train Time (s)               144.78843928780407
(Previous) Eval Time (s)     16.07586873881519
Sample Time (s)              7.218191341962665
Epoch Time (s)               168.08249936858192
Total Train Time (s)         6328.583807923365
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:05.149489 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #38 | Epoch Duration: 168.18178486824036
2020-01-11 10:06:05.149620 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.107848
Z variance train             0.14127623
KL Divergence                20.28285
KL Loss                      2.028285
QF Loss                      301.11603
VF Loss                      52.111256
Policy Loss                  -399.09488
Q Predictions Mean           387.49146
Q Predictions Std            114.35835
Q Predictions Max            573.1845
Q Predictions Min            -42.548542
V Predictions Mean           399.9793
V Predictions Std            103.950195
V Predictions Max            561.6219
V Predictions Min            -35.892723
Log Pis Mean                 -1.6304306
Log Pis Std                  2.6533976
Log Pis Max                  18.23146
Log Pis Min                  -7.3345366
Policy mu Mean               0.022104356
Policy mu Std                0.49876192
Policy mu Max                2.4252317
Policy mu Min                -3.2537959
Policy log std Mean          -0.8653359
Policy log std Std           0.12933648
Policy log std Max           -0.42672294
Policy log std Min           -1.5144281
Z mean eval                  1.1532648
Z variance eval              0.21501406
total_rewards                [1181.77390096  325.19325102  389.81044161  407.94083937  500.24371839
  913.21291908  652.29230105  468.69615645  599.8552847  1461.46593674]
total_rewards_mean           690.0484749391502
total_rewards_std            358.3449634023701
total_rewards_max            1461.4659367404163
total_rewards_min            325.19325102470697
Number of train steps total  160000
Number of env steps total    139073
Number of rollouts total     0
Train Time (s)               143.53997314628214
(Previous) Eval Time (s)     23.24765849392861
Sample Time (s)              8.252730077598244
Epoch Time (s)               175.040361717809
Total Train Time (s)         6503.714907421265
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:00.281108 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #39 | Epoch Duration: 175.1313922405243
2020-01-11 10:09:00.281238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1569419
Z variance train             0.21455328
KL Divergence                18.94858
KL Loss                      1.894858
QF Loss                      253.76994
VF Loss                      60.13419
Policy Loss                  -422.27512
Q Predictions Mean           416.12405
Q Predictions Std            112.46446
Q Predictions Max            604.76
Q Predictions Min            -23.900085
V Predictions Mean           419.17084
V Predictions Std            111.00799
V Predictions Max            600.30646
V Predictions Min            -29.649628
Log Pis Mean                 -2.0392485
Log Pis Std                  2.6080012
Log Pis Max                  16.287262
Log Pis Min                  -12.933151
Policy mu Mean               -0.015865663
Policy mu Std                0.45737308
Policy mu Max                2.6745486
Policy mu Min                -2.148734
Policy log std Mean          -0.8463681
Policy log std Std           0.124303296
Policy log std Max           -0.45534164
Policy log std Min           -1.4163418
Z mean eval                  1.0344149
Z variance eval              1.0279735
total_rewards                [ 275.62267831  717.27599735  389.37949323  523.48705352  857.30717809
  625.03086375  580.60854046 1329.48598239  365.66169039  481.74051035]
total_rewards_mean           614.5599987852561
total_rewards_std            289.02053647879967
total_rewards_max            1329.4859823876536
total_rewards_min            275.6226783125579
Number of train steps total  164000
Number of env steps total    142362
Number of rollouts total     0
Train Time (s)               145.80130076408386
(Previous) Eval Time (s)     18.753162696957588
Sample Time (s)              7.356286248657852
Epoch Time (s)               171.9107497096993
Total Train Time (s)         6675.709654392209
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:11:52.276124 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #40 | Epoch Duration: 171.99479508399963
2020-01-11 10:11:52.276249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0375884
Z variance train             1.0273321
KL Divergence                16.016464
KL Loss                      1.6016464
QF Loss                      562.09424
VF Loss                      91.77645
Policy Loss                  -329.7248
Q Predictions Mean           322.99152
Q Predictions Std            105.45879
Q Predictions Max            505.58032
Q Predictions Min            38.69886
V Predictions Mean           329.2992
V Predictions Std            104.02642
V Predictions Max            498.72333
V Predictions Min            59.004265
Log Pis Mean                 -1.6766592
Log Pis Std                  2.4995358
Log Pis Max                  17.546389
Log Pis Min                  -7.8786497
Policy mu Mean               -0.016046189
Policy mu Std                0.4523378
Policy mu Max                2.1652222
Policy mu Min                -3.0731206
Policy log std Mean          -0.8728728
Policy log std Std           0.12458295
Policy log std Max           -0.43571922
Policy log std Min           -1.5650992
Z mean eval                  1.1235473
Z variance eval              0.111778006
total_rewards                [ 365.57508995  650.16445598  393.67397311  794.5175645   201.30308041
  541.70569119  458.15066747  331.55452806 1213.75443674  832.04152406]
total_rewards_mean           578.2441011460123
total_rewards_std            286.04637284982357
total_rewards_max            1213.7544367429819
total_rewards_min            201.30308040802714
Number of train steps total  168000
Number of env steps total    145495
Number of rollouts total     0
Train Time (s)               142.7106529213488
(Previous) Eval Time (s)     18.914740149397403
Sample Time (s)              7.063490350265056
Epoch Time (s)               168.68888342101127
Total Train Time (s)         6844.502658782061
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:14:41.069997 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #41 | Epoch Duration: 168.79365611076355
2020-01-11 10:14:41.070122 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1239116
Z variance train             0.11242819
KL Divergence                19.393522
KL Loss                      1.9393523
QF Loss                      336.48267
VF Loss                      55.35859
Policy Loss                  -447.10968
Q Predictions Mean           436.60904
Q Predictions Std            118.344246
Q Predictions Max            635.5365
Q Predictions Min            15.78018
V Predictions Mean           447.72296
V Predictions Std            110.6588
V Predictions Max            627.29395
V Predictions Min            138.97182
Log Pis Mean                 -1.5737216
Log Pis Std                  2.3392277
Log Pis Max                  15.517468
Log Pis Min                  -7.8833036
Policy mu Mean               -0.018977834
Policy mu Std                0.45593154
Policy mu Max                2.9571888
Policy mu Min                -2.9259932
Policy log std Mean          -0.8705722
Policy log std Std           0.13160574
Policy log std Max           -0.36511382
Policy log std Min           -1.4446695
Z mean eval                  1.1812575
Z variance eval              0.18275
total_rewards                [ 447.45003392  100.6457406   183.69656933  385.98890658  842.61548828
  505.27695373 1647.5700297   477.36416452  877.53542823  185.18689655]
total_rewards_mean           565.3330211446915
total_rewards_std            436.9314064493013
total_rewards_max            1647.5700296953087
total_rewards_min            100.64574059872149
Number of train steps total  172000
Number of env steps total    148272
Number of rollouts total     0
Train Time (s)               144.4593676137738
(Previous) Eval Time (s)     12.339523398783058
Sample Time (s)              7.748739567119628
Epoch Time (s)               164.54763057967648
Total Train Time (s)         7009.23375492543
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:17:25.804423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #42 | Epoch Duration: 164.73418736457825
2020-01-11 10:17:25.804629 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1822789
Z variance train             0.1837117
KL Divergence                19.95278
KL Loss                      1.995278
QF Loss                      326.78162
VF Loss                      60.028664
Policy Loss                  -460.39432
Q Predictions Mean           452.65707
Q Predictions Std            122.139336
Q Predictions Max            641.58484
Q Predictions Min            10.830648
V Predictions Mean           460.5127
V Predictions Std            116.1928
V Predictions Max            637.81274
V Predictions Min            24.339104
Log Pis Mean                 -1.6683629
Log Pis Std                  2.7771008
Log Pis Max                  22.87386
Log Pis Min                  -9.261114
Policy mu Mean               -0.016543102
Policy mu Std                0.46934265
Policy mu Max                3.236747
Policy mu Min                -2.8891222
Policy log std Mean          -0.8758836
Policy log std Std           0.13685928
Policy log std Max           -0.45066583
Policy log std Min           -1.3091595
Z mean eval                  1.2178797
Z variance eval              0.2217432
total_rewards                [ 80.73226569 141.28005613 137.51389543 419.31362649 166.90016491
 117.83291832 824.1877877  875.20526426 393.46608983 592.24417239]
total_rewards_mean           374.86762411563467
total_rewards_std            284.34717071425166
total_rewards_max            875.2052642632648
total_rewards_min            80.7322656850848
Number of train steps total  176000
Number of env steps total    152113
Number of rollouts total     0
Train Time (s)               144.15347577026114
(Previous) Eval Time (s)     10.012605761177838
Sample Time (s)              8.380314327776432
Epoch Time (s)               162.5463958592154
Total Train Time (s)         7171.8760355310515
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:20:08.449075 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #43 | Epoch Duration: 162.64426732063293
2020-01-11 10:20:08.449329 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2129208
Z variance train             0.22267666
KL Divergence                18.1316
KL Loss                      1.81316
QF Loss                      472.5645
VF Loss                      63.956783
Policy Loss                  -450.86716
Q Predictions Mean           440.3175
Q Predictions Std            127.359726
Q Predictions Max            656.7356
Q Predictions Min            -4.4115133
V Predictions Mean           452.6147
V Predictions Std            121.625694
V Predictions Max            654.8582
V Predictions Min            249.65504
Log Pis Mean                 -2.1662233
Log Pis Std                  2.337334
Log Pis Max                  8.707562
Log Pis Min                  -8.090741
Policy mu Mean               -0.0058332407
Policy mu Std                0.45021224
Policy mu Max                2.1389844
Policy mu Min                -1.9273968
Policy log std Mean          -0.8546637
Policy log std Std           0.13224895
Policy log std Max           -0.45453888
Policy log std Min           -1.464488
Z mean eval                  1.2265797
Z variance eval              0.15401678
total_rewards                [  55.34839188  678.86257003  218.42507828 1193.6458483   628.73320853
  542.91819965  384.77594805  850.55942109  205.60678131  109.38213257]
total_rewards_mean           486.8257579686575
total_rewards_std            343.83610204516884
total_rewards_max            1193.6458483026865
total_rewards_min            55.34839188411003
Number of train steps total  180000
Number of env steps total    155067
Number of rollouts total     0
Train Time (s)               143.78009784501046
(Previous) Eval Time (s)     13.679471131879836
Sample Time (s)              8.480724306311458
Epoch Time (s)               165.94029328320175
Total Train Time (s)         7337.909032422584
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:22:54.481600 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #44 | Epoch Duration: 166.03210139274597
2020-01-11 10:22:54.481725 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #44 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2346087
Z variance train             0.15553173
KL Divergence                21.24101
KL Loss                      2.1241012
QF Loss                      476.06665
VF Loss                      119.4325
Policy Loss                  -447.03455
Q Predictions Mean           435.75143
Q Predictions Std            141.91544
Q Predictions Max            645.5941
Q Predictions Min            -96.41351
V Predictions Mean           440.56635
V Predictions Std            127.09387
V Predictions Max            642.2706
V Predictions Min            125.50493
Log Pis Mean                 -1.6776934
Log Pis Std                  2.4760766
Log Pis Max                  16.118256
Log Pis Min                  -7.290431
Policy mu Mean               -0.029087197
Policy mu Std                0.46315044
Policy mu Max                2.4780755
Policy mu Min                -1.8865812
Policy log std Mean          -0.8612047
Policy log std Std           0.13726176
Policy log std Max           -0.51196325
Policy log std Min           -1.4981601
Z mean eval                  1.1671879
Z variance eval              0.1268945
total_rewards                [946.26200104 378.30612579 387.2850044  251.47966967 392.05165218
 554.49147957 472.187705   403.37664326 198.06694924 312.2258187 ]
total_rewards_mean           429.57330488416636
total_rewards_std            197.4794869928987
total_rewards_max            946.262001035935
total_rewards_min            198.06694924020996
Number of train steps total  184000
Number of env steps total    158522
Number of rollouts total     0
Train Time (s)               142.2499960870482
(Previous) Eval Time (s)     12.907164838165045
Sample Time (s)              6.542645736597478
Epoch Time (s)               161.69980666181073
Total Train Time (s)         7499.703178117052
Epoch                        45
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:25:36.278289 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #45 | Epoch Duration: 161.79645442962646
2020-01-11 10:25:36.278472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1664449
Z variance train             0.12658267
KL Divergence                20.287424
KL Loss                      2.0287426
QF Loss                      289.86472
VF Loss                      109.83557
Policy Loss                  -459.06097
Q Predictions Mean           455.1936
Q Predictions Std            130.3462
Q Predictions Max            703.8639
Q Predictions Min            21.09851
V Predictions Mean           464.00397
V Predictions Std            128.5451
V Predictions Max            709.96576
V Predictions Min            52.22766
Log Pis Mean                 -1.7389636
Log Pis Std                  2.3588812
Log Pis Max                  10.02162
Log Pis Min                  -9.704734
Policy mu Mean               0.01531207
Policy mu Std                0.44409183
Policy mu Max                2.6559582
Policy mu Min                -2.1453145
Policy log std Mean          -0.87302923
Policy log std Std           0.1414183
Policy log std Max           -0.39293912
Policy log std Min           -1.5950279
Z mean eval                  1.1685212
Z variance eval              0.12687364
total_rewards                [ 324.00375289  404.49662352   65.9169403    45.91591395  446.45132995
  554.91034002  132.2667169   579.83384577 1205.06759038 1204.02707024]
total_rewards_mean           496.2890123916105
total_rewards_std            396.84210438434826
total_rewards_max            1205.0675903836202
total_rewards_min            45.915913950692236
Number of train steps total  188000
Number of env steps total    162353
Number of rollouts total     0
Train Time (s)               142.82717890990898
(Previous) Eval Time (s)     14.884181051049381
Sample Time (s)              7.260327175725251
Epoch Time (s)               164.9716871366836
Total Train Time (s)         7664.786807407159
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:28:21.361692 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #46 | Epoch Duration: 165.0830910205841
2020-01-11 10:28:21.361818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1690638
Z variance train             0.12602279
KL Divergence                21.660154
KL Loss                      2.1660154
QF Loss                      634.85034
VF Loss                      80.66729
Policy Loss                  -476.44818
Q Predictions Mean           465.8277
Q Predictions Std            136.4248
Q Predictions Max            683.3386
Q Predictions Min            4.6299553
V Predictions Mean           475.81458
V Predictions Std            130.34077
V Predictions Max            687.03265
V Predictions Min            60.544838
Log Pis Mean                 -1.4601258
Log Pis Std                  2.756897
Log Pis Max                  16.965364
Log Pis Min                  -6.9199514
Policy mu Mean               0.0098048225
Policy mu Std                0.50248516
Policy mu Max                3.1438785
Policy mu Min                -3.940904
Policy log std Mean          -0.8837291
Policy log std Std           0.14938414
Policy log std Max           -0.5071338
Policy log std Min           -1.4933319
Z mean eval                  1.1742878
Z variance eval              0.19760832
total_rewards                [ 649.9848343   609.84874144 1860.09043579 1319.61534853  587.60013564
  366.31052644  724.12362074  927.06635247  968.01798401  715.68456121]
total_rewards_mean           872.8342540559457
total_rewards_std            411.07761904451445
total_rewards_max            1860.0904357867066
total_rewards_min            366.3105264377391
Number of train steps total  192000
Number of env steps total    165120
Number of rollouts total     0
Train Time (s)               145.37884745607153
(Previous) Eval Time (s)     21.1364226359874
Sample Time (s)              7.407612290699035
Epoch Time (s)               173.92288238275796
Total Train Time (s)         7838.79842199944
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:31:15.376387 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #47 | Epoch Duration: 174.01446151733398
2020-01-11 10:31:15.376576 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1728784
Z variance train             0.19838464
KL Divergence                18.426031
KL Loss                      1.8426031
QF Loss                      381.31586
VF Loss                      85.003685
Policy Loss                  -481.64392
Q Predictions Mean           472.50595
Q Predictions Std            150.38268
Q Predictions Max            680.355
Q Predictions Min            -55.04061
V Predictions Mean           486.29166
V Predictions Std            139.83498
V Predictions Max            684.70264
V Predictions Min            27.450062
Log Pis Mean                 -1.6055529
Log Pis Std                  2.7865846
Log Pis Max                  15.212225
Log Pis Min                  -7.0745764
Policy mu Mean               -0.015426891
Policy mu Std                0.46545613
Policy mu Max                3.3916767
Policy mu Min                -2.917479
Policy log std Mean          -0.87306
Policy log std Std           0.13725083
Policy log std Max           -0.53647536
Policy log std Min           -1.4637125
Z mean eval                  1.2098489
Z variance eval              0.12895748
total_rewards                [  70.61085765  191.33427564 1026.67854069  404.68192154  439.68728001
  635.13397212 1376.53680768  678.23885699  853.67510567  162.84922954]
total_rewards_mean           583.9426847516817
total_rewards_std            394.5127431903948
total_rewards_max            1376.5368076769719
total_rewards_min            70.6108576524567
Number of train steps total  196000
Number of env steps total    169752
Number of rollouts total     0
Train Time (s)               142.59764869278297
(Previous) Eval Time (s)     15.199745423160493
Sample Time (s)              8.037779527250677
Epoch Time (s)               165.83517364319414
Total Train Time (s)         8004.721827631351
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:34:01.303194 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #48 | Epoch Duration: 165.92644691467285
2020-01-11 10:34:01.303486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2125552
Z variance train             0.12765834
KL Divergence                20.270243
KL Loss                      2.0270243
QF Loss                      410.83368
VF Loss                      106.321526
Policy Loss                  -469.78656
Q Predictions Mean           459.47705
Q Predictions Std            153.11336
Q Predictions Max            677.8222
Q Predictions Min            -29.434946
V Predictions Mean           471.0127
V Predictions Std            142.72656
V Predictions Max            693.6159
V Predictions Min            17.027264
Log Pis Mean                 -1.4696815
Log Pis Std                  2.9109979
Log Pis Max                  16.687752
Log Pis Min                  -8.809909
Policy mu Mean               0.009598843
Policy mu Std                0.49257377
Policy mu Max                4.037844
Policy mu Min                -2.6921659
Policy log std Mean          -0.88788426
Policy log std Std           0.14631861
Policy log std Max           -0.52571493
Policy log std Min           -1.5694311
Z mean eval                  1.1687399
Z variance eval              0.069232896
total_rewards                [ 124.19570495 1475.23839395 1939.49671793  529.74209896   83.66546649
  525.24989924 1749.67587019   71.2675836  1979.46154038  769.57924576]
total_rewards_mean           924.757252145504
total_rewards_std            744.4541382724644
total_rewards_max            1979.46154037792
total_rewards_min            71.26758360234244
Number of train steps total  200000
Number of env steps total    172564
Number of rollouts total     0
Train Time (s)               142.71135110221803
(Previous) Eval Time (s)     12.167868859134614
Sample Time (s)              8.056229673326015
Epoch Time (s)               162.93544963467866
Total Train Time (s)         8167.748153268825
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:36:44.330491 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #49 | Epoch Duration: 163.02677536010742
2020-01-11 10:36:44.330765 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1691247
Z variance train             0.06910814
KL Divergence                20.760818
KL Loss                      2.076082
QF Loss                      285.96063
VF Loss                      63.182583
Policy Loss                  -480.4419
Q Predictions Mean           471.9278
Q Predictions Std            140.52518
Q Predictions Max            682.0389
Q Predictions Min            153.84991
V Predictions Mean           477.67657
V Predictions Std            133.59401
V Predictions Max            673.72687
V Predictions Min            239.94986
Log Pis Mean                 -1.4970994
Log Pis Std                  2.2811983
Log Pis Max                  5.89834
Log Pis Min                  -8.412144
Policy mu Mean               -0.025159663
Policy mu Std                0.46869996
Policy mu Max                3.0730767
Policy mu Min                -2.3382413
Policy log std Mean          -0.8941153
Policy log std Std           0.13692102
Policy log std Max           -0.5214796
Policy log std Min           -1.5978582
Z mean eval                  1.204637
Z variance eval              0.09859077
total_rewards                [ 410.73898781  237.38163064  316.91710966  813.85880179  514.05550493
  253.2967944   477.26272481   94.7483893   156.79962355 1487.31469467]
total_rewards_mean           476.23742615639384
total_rewards_std            390.0895684968289
total_rewards_max            1487.3146946722554
total_rewards_min            94.74838929988107
Number of train steps total  204000
Number of env steps total    175096
Number of rollouts total     0
Train Time (s)               143.06494116224349
(Previous) Eval Time (s)     13.924872046802193
Sample Time (s)              7.849474349524826
Epoch Time (s)               164.8392875585705
Total Train Time (s)         8332.691558903083
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:39:29.273391 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #50 | Epoch Duration: 164.94245219230652
2020-01-11 10:39:29.273520 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2016355
Z variance train             0.0975174
KL Divergence                21.494123
KL Loss                      2.1494124
QF Loss                      424.98697
VF Loss                      69.00369
Policy Loss                  -478.51047
Q Predictions Mean           468.61496
Q Predictions Std            143.13135
Q Predictions Max            685.3
Q Predictions Min            117.146355
V Predictions Mean           481.33978
V Predictions Std            136.73254
V Predictions Max            686.91406
V Predictions Min            219.76372
Log Pis Mean                 -1.800879
Log Pis Std                  2.5858011
Log Pis Max                  13.303343
Log Pis Min                  -8.269268
Policy mu Mean               -0.019699503
Policy mu Std                0.4663795
Policy mu Max                2.6751075
Policy mu Min                -1.8309547
Policy log std Mean          -0.86197686
Policy log std Std           0.13322358
Policy log std Max           -0.48302287
Policy log std Min           -1.472672
Z mean eval                  1.1889696
Z variance eval              0.116606906
total_rewards                [135.03279248 910.68769439 778.69223115 927.22800686 494.27036736
 394.69919017 758.02812562 512.14420801 647.49360589  90.71615135]
total_rewards_mean           564.8992373259125
total_rewards_std            280.5448594363429
total_rewards_max            927.2280068589282
total_rewards_min            90.71615134530279
Number of train steps total  208000
Number of env steps total    178693
Number of rollouts total     0
Train Time (s)               145.8926000930369
(Previous) Eval Time (s)     11.205335995182395
Sample Time (s)              7.551695164293051
Epoch Time (s)               164.64963125251234
Total Train Time (s)         8497.566082716454
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:42:14.150912 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #51 | Epoch Duration: 164.8772885799408
2020-01-11 10:42:14.151078 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1928624
Z variance train             0.11767354
KL Divergence                21.20564
KL Loss                      2.1205642
QF Loss                      445.6084
VF Loss                      84.89739
Policy Loss                  -477.75284
Q Predictions Mean           465.0235
Q Predictions Std            145.60803
Q Predictions Max            670.15985
Q Predictions Min            59.85801
V Predictions Mean           475.49896
V Predictions Std            138.14053
V Predictions Max            662.50836
V Predictions Min            177.9396
Log Pis Mean                 -1.5849783
Log Pis Std                  2.726274
Log Pis Max                  14.110834
Log Pis Min                  -8.443644
Policy mu Mean               -0.018637791
Policy mu Std                0.5119774
Policy mu Max                2.957389
Policy mu Min                -4.134094
Policy log std Mean          -0.86951673
Policy log std Std           0.13868164
Policy log std Max           -0.51493156
Policy log std Min           -1.4649253
Z mean eval                  1.2274773
Z variance eval              0.059693117
total_rewards                [1273.5646998   435.81180665  379.38996036  442.36170108  381.70752697
  199.24539452  237.51520993  483.55221433   40.01962627  258.85652593]
total_rewards_mean           413.2024665839032
total_rewards_std            314.3884002163227
total_rewards_max            1273.5646997998067
total_rewards_min            40.01962626646295
Number of train steps total  212000
Number of env steps total    181357
Number of rollouts total     0
Train Time (s)               144.65228182589635
(Previous) Eval Time (s)     14.006449289154261
Sample Time (s)              6.718503509648144
Epoch Time (s)               165.37723462469876
Total Train Time (s)         8663.037482446525
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:44:59.621483 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #52 | Epoch Duration: 165.4702866077423
2020-01-11 10:44:59.621615 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2259809
Z variance train             0.059520386
KL Divergence                22.230179
KL Loss                      2.223018
QF Loss                      408.9403
VF Loss                      98.581924
Policy Loss                  -497.87463
Q Predictions Mean           489.16974
Q Predictions Std            152.22012
Q Predictions Max            764.08716
Q Predictions Min            14.297397
V Predictions Mean           497.80804
V Predictions Std            145.71841
V Predictions Max            769.1171
V Predictions Min            195.4393
Log Pis Mean                 -1.5614474
Log Pis Std                  2.8758788
Log Pis Max                  25.8279
Log Pis Min                  -7.589221
Policy mu Mean               -0.023855131
Policy mu Std                0.48865083
Policy mu Max                3.2825649
Policy mu Min                -3.5346909
Policy log std Mean          -0.8975897
Policy log std Std           0.15578564
Policy log std Max           -0.46957773
Policy log std Min           -1.588601
Z mean eval                  1.1689332
Z variance eval              0.03220611
total_rewards                [1647.53710908 1009.33871706  243.99373022 1889.39659315  935.83655092
  210.5615695   435.83784451 1151.81494945  817.40495713  208.17475747]
total_rewards_mean           854.9896778494622
total_rewards_std            565.744485482758
total_rewards_max            1889.3965931511293
total_rewards_min            208.1747574656016
Number of train steps total  216000
Number of env steps total    185162
Number of rollouts total     0
Train Time (s)               145.0184268350713
(Previous) Eval Time (s)     15.362902639899403
Sample Time (s)              7.97019478213042
Epoch Time (s)               168.35152425710112
Total Train Time (s)         8831.496851180214
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:47:48.081153 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #53 | Epoch Duration: 168.45944786071777
2020-01-11 10:47:48.081283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1686115
Z variance train             0.032246478
KL Divergence                23.41534
KL Loss                      2.3415341
QF Loss                      479.4784
VF Loss                      109.89279
Policy Loss                  -488.93015
Q Predictions Mean           479.9027
Q Predictions Std            167.17554
Q Predictions Max            720.8208
Q Predictions Min            -29.510443
V Predictions Mean           491.87634
V Predictions Std            160.48055
V Predictions Max            719.26337
V Predictions Min            68.676056
Log Pis Mean                 -1.542728
Log Pis Std                  2.6841564
Log Pis Max                  15.118633
Log Pis Min                  -7.488576
Policy mu Mean               0.010496601
Policy mu Std                0.49727094
Policy mu Max                3.2836618
Policy mu Min                -2.7486224
Policy log std Mean          -0.878568
Policy log std Std           0.14188401
Policy log std Max           -0.47321156
Policy log std Min           -1.4945273
Z mean eval                  1.210197
Z variance eval              0.02971777
total_rewards                [ 699.71755661 1085.2120407   750.57658584  730.79696093  347.14235631
  494.33484803  763.00692842 1291.4293188   167.83732977  141.83016131]
total_rewards_mean           647.1884086719829
total_rewards_std            352.0397787380997
total_rewards_max            1291.4293188001548
total_rewards_min            141.83016131316296
Number of train steps total  220000
Number of env steps total    188505
Number of rollouts total     0
Train Time (s)               144.62049697712064
(Previous) Eval Time (s)     15.125950478948653
Sample Time (s)              7.183299260679632
Epoch Time (s)               166.92974671674892
Total Train Time (s)         8998.52644388238
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:35.114148 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #54 | Epoch Duration: 167.03275275230408
2020-01-11 10:50:35.114357 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2083272
Z variance train             0.029755052
KL Divergence                23.398241
KL Loss                      2.3398242
QF Loss                      543.2139
VF Loss                      180.6368
Policy Loss                  -514.0864
Q Predictions Mean           500.65665
Q Predictions Std            171.09041
Q Predictions Max            758.0776
Q Predictions Min            -63.255
V Predictions Mean           521.2175
V Predictions Std            156.97435
V Predictions Max            757.955
V Predictions Min            98.457
Log Pis Mean                 -1.2720447
Log Pis Std                  3.015277
Log Pis Max                  16.505337
Log Pis Min                  -8.804215
Policy mu Mean               0.024098087
Policy mu Std                0.51071084
Policy mu Max                2.820166
Policy mu Min                -2.3773272
Policy log std Mean          -0.893276
Policy log std Std           0.16153163
Policy log std Max           -0.35764182
Policy log std Min           -1.8261765
Z mean eval                  1.1876359
Z variance eval              0.033648796
total_rewards                [ 778.60465585  805.56729409  304.34159451 1879.91455406 1151.40974269
  559.44696016   63.47006349  501.63509613  985.49948559  989.74292001]
total_rewards_mean           801.9632366571807
total_rewards_std            479.1250235429383
total_rewards_max            1879.9145540589031
total_rewards_min            63.47006349070058
Number of train steps total  224000
Number of env steps total    191140
Number of rollouts total     0
Train Time (s)               145.64703004434705
(Previous) Eval Time (s)     16.744545691180974
Sample Time (s)              7.669225509278476
Epoch Time (s)               170.0608012448065
Total Train Time (s)         9168.673815289978
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:53:25.261547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #55 | Epoch Duration: 170.14702653884888
2020-01-11 10:53:25.261731 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.191396
Z variance train             0.033742674
KL Divergence                23.444592
KL Loss                      2.3444593
QF Loss                      281.79254
VF Loss                      73.51439
Policy Loss                  -508.23465
Q Predictions Mean           501.35602
Q Predictions Std            163.97076
Q Predictions Max            734.5771
Q Predictions Min            201.2461
V Predictions Mean           505.0125
V Predictions Std            159.48674
V Predictions Max            725.7277
V Predictions Min            205.18596
Log Pis Mean                 -1.5633518
Log Pis Std                  2.7111273
Log Pis Max                  10.009955
Log Pis Min                  -8.05175
Policy mu Mean               -0.018966947
Policy mu Std                0.48334798
Policy mu Max                2.3409321
Policy mu Min                -2.3813267
Policy log std Mean          -0.90132743
Policy log std Std           0.16444
Policy log std Max           -0.34631544
Policy log std Min           -1.7046839
Z mean eval                  1.2029397
Z variance eval              0.057627857
total_rewards                [1963.12866071  568.76620747 1181.20971931  459.99637155 2044.61916775
  301.69301642 1813.19258348  666.64600124 1735.26606132 2200.58364853]
total_rewards_mean           1293.5101437777903
total_rewards_std            700.7013936263695
total_rewards_max            2200.583648525958
total_rewards_min            301.69301641671944
Number of train steps total  228000
Number of env steps total    194460
Number of rollouts total     0
Train Time (s)               143.47309887502342
(Previous) Eval Time (s)     18.041773489676416
Sample Time (s)              6.5194517485797405
Epoch Time (s)               168.03432411327958
Total Train Time (s)         9337.043763888534
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:56:13.635628 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #56 | Epoch Duration: 168.37367129325867
2020-01-11 10:56:13.636012 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #56 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1986845
Z variance train             0.057873167
KL Divergence                22.263008
KL Loss                      2.226301
QF Loss                      460.4098
VF Loss                      72.19021
Policy Loss                  -525.57526
Q Predictions Mean           516.35803
Q Predictions Std            171.59584
Q Predictions Max            763.7723
Q Predictions Min            -27.108917
V Predictions Mean           528.8555
V Predictions Std            164.4663
V Predictions Max            753.67694
V Predictions Min            -17.140556
Log Pis Mean                 -1.2298514
Log Pis Std                  2.6803238
Log Pis Max                  12.328424
Log Pis Min                  -7.8007755
Policy mu Mean               -0.030963248
Policy mu Std                0.5028134
Policy mu Max                2.2610962
Policy mu Min                -2.4717991
Policy log std Mean          -0.9080126
Policy log std Std           0.16461067
Policy log std Max           -0.36675897
Policy log std Min           -1.6186333
Z mean eval                  1.2081642
Z variance eval              0.12534028
total_rewards                [ 380.49559135  547.0129587   729.77565152   61.79194898  635.8535536
  439.69651104 1384.33209655 1101.82661018  441.86165152  131.36692456]
total_rewards_mean           585.4013498007519
total_rewards_std            386.520684943556
total_rewards_max            1384.3320965462012
total_rewards_min            61.791948983798406
Number of train steps total  232000
Number of env steps total    199919
Number of rollouts total     0
Train Time (s)               145.58043051883578
(Previous) Eval Time (s)     10.963053070940077
Sample Time (s)              6.8337507313117385
Epoch Time (s)               163.3772343210876
Total Train Time (s)         9500.514939548448
Epoch                        57
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:57.107339 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #57 | Epoch Duration: 163.47110795974731
2020-01-11 10:58:57.107557 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2110854
Z variance train             0.12502155
KL Divergence                19.470215
KL Loss                      1.9470215
QF Loss                      605.7673
VF Loss                      91.20628
Policy Loss                  -525.65924
Q Predictions Mean           511.75153
Q Predictions Std            193.82027
Q Predictions Max            794.82086
Q Predictions Min            -15.523285
V Predictions Mean           528.1444
V Predictions Std            184.53658
V Predictions Max            801.66425
V Predictions Min            28.902649
Log Pis Mean                 -1.4001656
Log Pis Std                  2.9913642
Log Pis Max                  20.700794
Log Pis Min                  -8.17602
Policy mu Mean               -0.007393729
Policy mu Std                0.5172099
Policy mu Max                4.8256183
Policy mu Min                -2.8748932
Policy log std Mean          -0.88795865
Policy log std Std           0.16170108
Policy log std Max           -0.08808488
Policy log std Min           -1.5344931
Z mean eval                  1.162922
Z variance eval              0.106311664
total_rewards                [ 798.9398399  1230.17773255  591.64635929  992.94639751  612.23278298
  964.29783251  604.702612   1528.05529857  213.34985071   20.91603987]
total_rewards_mean           755.7264745874774
total_rewards_std            427.5135336557937
total_rewards_max            1528.0552985652012
total_rewards_min            20.9160398671749
Number of train steps total  236000
Number of env steps total    202346
Number of rollouts total     0
Train Time (s)               145.65775942895561
(Previous) Eval Time (s)     13.49333707196638
Sample Time (s)              7.8150487476959825
Epoch Time (s)               166.96614524861798
Total Train Time (s)         9667.579115648754
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:44.172479 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #58 | Epoch Duration: 167.06473398208618
2020-01-11 11:01:44.172708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1620739
Z variance train             0.10626538
KL Divergence                19.720673
KL Loss                      1.9720672
QF Loss                      448.07922
VF Loss                      182.11197
Policy Loss                  -505.52875
Q Predictions Mean           493.3727
Q Predictions Std            181.62595
Q Predictions Max            763.214
Q Predictions Min            -64.07356
V Predictions Mean           505.99573
V Predictions Std            173.59831
V Predictions Max            769.3136
V Predictions Min            61.100418
Log Pis Mean                 -1.2049539
Log Pis Std                  3.167538
Log Pis Max                  13.696207
Log Pis Min                  -8.312223
Policy mu Mean               -0.029980896
Policy mu Std                0.5279167
Policy mu Max                3.344237
Policy mu Min                -2.5231411
Policy log std Mean          -0.8952067
Policy log std Std           0.17648388
Policy log std Max           -0.44702458
Policy log std Min           -1.9041862
Z mean eval                  1.1940835
Z variance eval              0.050596543
total_rewards                [ 177.4461733   631.4180695  1050.7002551   230.55158745   24.50135131
  715.73023012   61.40467708  510.92590398  647.28300165  712.94055234]
total_rewards_mean           476.29018018135747
total_rewards_std            319.95672109079294
total_rewards_max            1050.7002551023743
total_rewards_min            24.50135130544469
Number of train steps total  240000
Number of env steps total    205971
Number of rollouts total     0
Train Time (s)               146.059640141204
(Previous) Eval Time (s)     8.901139779947698
Sample Time (s)              7.758357693441212
Epoch Time (s)               162.7191376145929
Total Train Time (s)         9830.381129050162
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:26.975912 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #59 | Epoch Duration: 162.8030915260315
2020-01-11 11:04:26.976035 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.193649
Z variance train             0.050615728
KL Divergence                21.815569
KL Loss                      2.181557
QF Loss                      305.5191
VF Loss                      113.45659
Policy Loss                  -530.486
Q Predictions Mean           515.4376
Q Predictions Std            180.64067
Q Predictions Max            806.4705
Q Predictions Min            -22.963858
V Predictions Mean           536.76184
V Predictions Std            169.76593
V Predictions Max            812.91315
V Predictions Min            211.92586
Log Pis Mean                 -1.1353728
Log Pis Std                  2.808301
Log Pis Max                  14.564884
Log Pis Min                  -7.0454845
Policy mu Mean               -0.0148404725
Policy mu Std                0.51081187
Policy mu Max                3.6031916
Policy mu Min                -2.3169436
Policy log std Mean          -0.89904004
Policy log std Std           0.16742921
Policy log std Max           -0.41326147
Policy log std Min           -1.8564217
Z mean eval                  1.1796849
Z variance eval              0.080148496
total_rewards                [ 540.49465547  197.25624056  334.60775719  384.15894054 1788.63924888
  368.45713707  733.82524993 2110.19041141 1064.02695804  689.86541958]
total_rewards_mean           821.1522018667907
total_rewards_std            614.990838337754
total_rewards_max            2110.190411406472
total_rewards_min            197.25624056135476
Number of train steps total  244000
Number of env steps total    208598
Number of rollouts total     0
Train Time (s)               147.5125327897258
(Previous) Eval Time (s)     14.250645985361189
Sample Time (s)              7.497349225450307
Epoch Time (s)               169.2605280005373
Total Train Time (s)         9999.731873961631
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:07:16.327105 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #60 | Epoch Duration: 169.3509771823883
2020-01-11 11:07:16.327232 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1766732
Z variance train             0.07939742
KL Divergence                22.330832
KL Loss                      2.2330832
QF Loss                      4015.3535
VF Loss                      103.6001
Policy Loss                  -537.9781
Q Predictions Mean           531.29407
Q Predictions Std            180.43587
Q Predictions Max            795.34576
Q Predictions Min            -12.932467
V Predictions Mean           542.4768
V Predictions Std            174.08707
V Predictions Max            780.2293
V Predictions Min            183.75117
Log Pis Mean                 -1.357462
Log Pis Std                  3.093511
Log Pis Max                  18.898102
Log Pis Min                  -7.7587013
Policy mu Mean               -0.025407357
Policy mu Std                0.5077554
Policy mu Max                2.5849571
Policy mu Min                -3.1531007
Policy log std Mean          -0.90022254
Policy log std Std           0.16845179
Policy log std Max           -0.5226278
Policy log std Min           -1.5226599
Z mean eval                  1.1725438
Z variance eval              0.05266854
total_rewards                [2324.11898973 1794.8145223   421.77469012  667.10284091  437.31592409
  108.25021931 1705.28564266   20.59212606  965.3831801   521.29368489]
total_rewards_mean           896.5931820166448
total_rewards_std            743.1092297604364
total_rewards_max            2324.1189897284617
total_rewards_min            20.592126060330948
Number of train steps total  248000
Number of env steps total    212184
Number of rollouts total     0
Train Time (s)               146.39338508294895
(Previous) Eval Time (s)     13.19941621599719
Sample Time (s)              7.505658559501171
Epoch Time (s)               167.0984598584473
Total Train Time (s)         10166.917104917578
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:10:03.514781 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #61 | Epoch Duration: 167.18743658065796
2020-01-11 11:10:03.514920 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1682441
Z variance train             0.052749235
KL Divergence                21.749916
KL Loss                      2.1749916
QF Loss                      448.87677
VF Loss                      70.01537
Policy Loss                  -530.75525
Q Predictions Mean           520.9248
Q Predictions Std            201.15506
Q Predictions Max            785.869
Q Predictions Min            -36.41402
V Predictions Mean           528.64514
V Predictions Std            190.6842
V Predictions Max            784.6578
V Predictions Min            59.133133
Log Pis Mean                 -1.2077556
Log Pis Std                  2.850972
Log Pis Max                  9.984343
Log Pis Min                  -7.609031
Policy mu Mean               0.0033782842
Policy mu Std                0.52997416
Policy mu Max                2.591133
Policy mu Min                -2.5500693
Policy log std Mean          -0.9090992
Policy log std Std           0.17431392
Policy log std Max           -0.5031723
Policy log std Min           -1.835084
Z mean eval                  1.1492426
Z variance eval              0.04744603
total_rewards                [1191.39094066  778.81054461  587.82954001 1718.39243651 1335.21121076
  482.53305901 1056.37137446 1356.55819144  497.7197834    87.29619094]
total_rewards_mean           909.2113271809278
total_rewards_std            478.0026509098685
total_rewards_max            1718.3924365125183
total_rewards_min            87.29619094255621
Number of train steps total  252000
Number of env steps total    215526
Number of rollouts total     0
Train Time (s)               144.87780703417957
(Previous) Eval Time (s)     11.603846397716552
Sample Time (s)              7.325318258721381
Epoch Time (s)               163.8069716906175
Total Train Time (s)         10330.817349550314
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:12:47.415571 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #62 | Epoch Duration: 163.90055465698242
2020-01-11 11:12:47.415702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #62 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1480523
Z variance train             0.047475733
KL Divergence                21.718962
KL Loss                      2.1718962
QF Loss                      454.0916
VF Loss                      59.53043
Policy Loss                  -564.6147
Q Predictions Mean           559.07605
Q Predictions Std            180.76613
Q Predictions Max            817.7505
Q Predictions Min            228.67972
V Predictions Mean           564.0128
V Predictions Std            174.2315
V Predictions Max            802.52136
V Predictions Min            240.74207
Log Pis Mean                 -1.2289044
Log Pis Std                  2.8373845
Log Pis Max                  15.109342
Log Pis Min                  -9.380263
Policy mu Mean               -0.0025259163
Policy mu Std                0.50392705
Policy mu Max                3.276153
Policy mu Min                -2.9705327
Policy log std Mean          -0.9050647
Policy log std Std           0.16990425
Policy log std Max           -0.44745532
Policy log std Min           -1.5802724
Z mean eval                  1.1764027
Z variance eval              0.036305018
total_rewards                [505.86885595 395.16073939 630.88634971  38.41663221 652.94683253
 448.63558998 255.10514806 344.79850151 435.61126649 182.81214707]
total_rewards_mean           389.02420628920356
total_rewards_std            182.45710755704067
total_rewards_max            652.9468325278463
total_rewards_min            38.41663221360851
Number of train steps total  256000
Number of env steps total    218187
Number of rollouts total     0
Train Time (s)               146.71021054219455
(Previous) Eval Time (s)     12.643354796338826
Sample Time (s)              7.611896583810449
Epoch Time (s)               166.96546192234382
Total Train Time (s)         10497.867624740116
Epoch                        63
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:15:34.466017 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #63 | Epoch Duration: 167.0502257347107
2020-01-11 11:15:34.466145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1761144
Z variance train             0.036503635
KL Divergence                22.210514
KL Loss                      2.2210515
QF Loss                      450.27777
VF Loss                      125.47168
Policy Loss                  -565.55536
Q Predictions Mean           556.4415
Q Predictions Std            192.25621
Q Predictions Max            837.07043
Q Predictions Min            1.3808293
V Predictions Mean           559.62
V Predictions Std            185.53252
V Predictions Max            832.70105
V Predictions Min            -69.207565
Log Pis Mean                 -1.1439279
Log Pis Std                  2.9237041
Log Pis Max                  12.659861
Log Pis Min                  -9.977952
Policy mu Mean               0.026167758
Policy mu Std                0.52628815
Policy mu Max                2.6626554
Policy mu Min                -2.7006483
Policy log std Mean          -0.91413736
Policy log std Std           0.18321835
Policy log std Max           -0.41981268
Policy log std Min           -1.9410775
Z mean eval                  1.2476206
Z variance eval              0.03441837
total_rewards                [ 415.08722261  388.77766089  440.662486    945.2787124    49.12853242
  683.91594638 2147.77100017  739.12653478  554.57979196  537.34829067]
total_rewards_mean           690.167617827663
total_rewards_std            536.0552401409033
total_rewards_max            2147.7710001694386
total_rewards_min            49.12853241529048
Number of train steps total  260000
Number of env steps total    222025
Number of rollouts total     0
Train Time (s)               144.99840764701366
(Previous) Eval Time (s)     17.54786908160895
Sample Time (s)              7.2969104326330125
Epoch Time (s)               169.84318716125563
Total Train Time (s)         10667.799364191946
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:24.403514 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #64 | Epoch Duration: 169.93721890449524
2020-01-11 11:18:24.403845 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #64 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2521436
Z variance train             0.03446696
KL Divergence                22.566778
KL Loss                      2.2566779
QF Loss                      566.31366
VF Loss                      68.73735
Policy Loss                  -578.7175
Q Predictions Mean           567.6881
Q Predictions Std            197.5294
Q Predictions Max            857.94165
Q Predictions Min            16.151617
V Predictions Mean           579.36426
V Predictions Std            191.58789
V Predictions Max            856.31396
V Predictions Min            121.06173
Log Pis Mean                 -1.2690308
Log Pis Std                  2.463572
Log Pis Max                  8.549877
Log Pis Min                  -7.554186
Policy mu Mean               0.010125352
Policy mu Std                0.5068425
Policy mu Max                2.4531374
Policy mu Min                -2.3228273
Policy log std Mean          -0.9109024
Policy log std Std           0.17052326
Policy log std Max           -0.42549625
Policy log std Min           -1.6141441
Z mean eval                  1.1788485
Z variance eval              0.039462756
total_rewards                [ 93.28578196 647.84227666 453.19769431 741.67999178 819.67215416
 289.29224063 103.71253846 426.73548145 644.52574783 573.28573725]
total_rewards_mean           479.3229644479655
total_rewards_std            240.59427447561384
total_rewards_max            819.6721541588771
total_rewards_min            93.2857819601447
Number of train steps total  264000
Number of env steps total    224854
Number of rollouts total     0
Train Time (s)               147.3579461509362
(Previous) Eval Time (s)     10.60470942594111
Sample Time (s)              7.1996478023938835
Epoch Time (s)               165.16230337927118
Total Train Time (s)         10833.064951566514
Epoch                        65
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:09.671911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #65 | Epoch Duration: 165.26778197288513
2020-01-11 11:21:09.672171 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1778384
Z variance train             0.039107427
KL Divergence                22.860828
KL Loss                      2.286083
QF Loss                      402.75085
VF Loss                      73.14051
Policy Loss                  -575.33655
Q Predictions Mean           568.0021
Q Predictions Std            192.05121
Q Predictions Max            894.55664
Q Predictions Min            137.97128
V Predictions Mean           572.1835
V Predictions Std            187.13562
V Predictions Max            889.22064
V Predictions Min            223.672
Log Pis Mean                 -1.3041342
Log Pis Std                  2.8242078
Log Pis Max                  16.842049
Log Pis Min                  -12.164366
Policy mu Mean               -0.018628336
Policy mu Std                0.48438618
Policy mu Max                2.9595141
Policy mu Min                -2.2498002
Policy log std Mean          -0.92169464
Policy log std Std           0.18036461
Policy log std Max           -0.4575413
Policy log std Min           -1.6247513
Z mean eval                  1.1842961
Z variance eval              0.042488027
total_rewards                [ 374.47148863 2452.65796741 1515.72093258 1053.69635779 1249.67519105
  448.93710239  737.47132337  116.25336478  248.73256577 1118.56145253]
total_rewards_mean           931.6177746299163
total_rewards_std            672.1598169858394
total_rewards_max            2452.6579674064233
total_rewards_min            116.25336477936955
Number of train steps total  268000
Number of env steps total    228597
Number of rollouts total     0
Train Time (s)               145.6176477218978
(Previous) Eval Time (s)     14.368300931993872
Sample Time (s)              7.542430481407791
Epoch Time (s)               167.52837913529947
Total Train Time (s)         11000.6951410966
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:23:57.303908 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #66 | Epoch Duration: 167.63154649734497
2020-01-11 11:23:57.304189 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #66 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1862152
Z variance train             0.041885562
KL Divergence                23.029747
KL Loss                      2.3029747
QF Loss                      412.20612
VF Loss                      82.44042
Policy Loss                  -587.6076
Q Predictions Mean           580.9691
Q Predictions Std            205.51228
Q Predictions Max            857.88245
Q Predictions Min            65.859566
V Predictions Mean           590.3017
V Predictions Std            198.85799
V Predictions Max            857.81757
V Predictions Min            227.12262
Log Pis Mean                 -1.4149303
Log Pis Std                  2.5676053
Log Pis Max                  15.8277445
Log Pis Min                  -7.327388
Policy mu Mean               -0.016270421
Policy mu Std                0.48032874
Policy mu Max                2.8190913
Policy mu Min                -3.254139
Policy log std Mean          -0.90494144
Policy log std Std           0.16896936
Policy log std Max           -0.43769157
Policy log std Min           -1.74901
Z mean eval                  1.2015154
Z variance eval              0.04447937
total_rewards                [ 874.96651345  443.91825978  711.58641014  223.8890038   275.6321617
 1710.28846265  186.8194744  1561.01342873  268.04014966  630.79575207]
total_rewards_mean           688.6949616383101
total_rewards_std            521.399729735447
total_rewards_max            1710.288462650176
total_rewards_min            186.81947440243465
Number of train steps total  272000
Number of env steps total    231399
Number of rollouts total     0
Train Time (s)               145.70753440912813
(Previous) Eval Time (s)     8.780565604101866
Sample Time (s)              7.811157495249063
Epoch Time (s)               162.29925750847906
Total Train Time (s)         11163.087145016063
Epoch                        67
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:26:39.696457 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #67 | Epoch Duration: 162.39203023910522
2020-01-11 11:26:39.696667 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1978905
Z variance train             0.044437375
KL Divergence                22.475143
KL Loss                      2.2475145
QF Loss                      597.8252
VF Loss                      156.11815
Policy Loss                  -591.7343
Q Predictions Mean           581.86096
Q Predictions Std            202.51329
Q Predictions Max            867.9819
Q Predictions Min            -78.78413
V Predictions Mean           587.0591
V Predictions Std            188.80185
V Predictions Max            854.69965
V Predictions Min            241.62602
Log Pis Mean                 -1.1974347
Log Pis Std                  3.060159
Log Pis Max                  26.74112
Log Pis Min                  -8.173272
Policy mu Mean               0.008200331
Policy mu Std                0.52975804
Policy mu Max                4.3237734
Policy mu Min                -2.9604397
Policy log std Mean          -0.90741014
Policy log std Std           0.17492327
Policy log std Max           -0.42844763
Policy log std Min           -1.6582165
Z mean eval                  1.1943462
Z variance eval              0.027115092
total_rewards                [1407.14407095 2505.32075518  628.86985125  411.52508085 1388.25345124
   91.28292072  467.64511475  766.48656747  854.39571076  242.54954106]
total_rewards_mean           876.3473064223593
total_rewards_std            683.5398180318082
total_rewards_max            2505.3207551765645
total_rewards_min            91.28292071886972
Number of train steps total  276000
Number of env steps total    234159
Number of rollouts total     0
Train Time (s)               145.34792062593624
(Previous) Eval Time (s)     15.6193733131513
Sample Time (s)              8.289206983987242
Epoch Time (s)               169.25650092307478
Total Train Time (s)         11332.435701126698
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:29:29.046277 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #68 | Epoch Duration: 169.34948205947876
2020-01-11 11:29:29.046459 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1984478
Z variance train             0.026985735
KL Divergence                24.135145
KL Loss                      2.4135146
QF Loss                      457.78085
VF Loss                      145.74036
Policy Loss                  -569.8852
Q Predictions Mean           557.9758
Q Predictions Std            209.04285
Q Predictions Max            903.32214
Q Predictions Min            -31.897861
V Predictions Mean           570.442
V Predictions Std            201.91888
V Predictions Max            893.5568
V Predictions Min            230.00691
Log Pis Mean                 -1.2580252
Log Pis Std                  3.5599291
Log Pis Max                  31.03843
Log Pis Min                  -9.049278
Policy mu Mean               -0.019928867
Policy mu Std                0.5239402
Policy mu Max                4.5744195
Policy mu Min                -2.2167838
Policy log std Mean          -0.9310645
Policy log std Std           0.19526295
Policy log std Max           -0.4760112
Policy log std Min           -1.7727239
Z mean eval                  1.1102941
Z variance eval              0.4296381
total_rewards                [1588.41654142    8.40587661 1768.91700963 1945.51808344  168.06813606
  170.68262317  270.88611468 1025.49422573  462.77102397 1010.92104497]
total_rewards_mean           842.0080679698997
total_rewards_std            690.361168712848
total_rewards_max            1945.518083444307
total_rewards_min            8.405876613803429
Number of train steps total  280000
Number of env steps total    237064
Number of rollouts total     0
Train Time (s)               147.27738384110853
(Previous) Eval Time (s)     14.961424937006086
Sample Time (s)              8.72213316615671
Epoch Time (s)               170.96094194427133
Total Train Time (s)         11503.485785778612
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:32:20.096456 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #69 | Epoch Duration: 171.04987621307373
2020-01-11 11:32:20.096589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.106844
Z variance train             0.43025368
KL Divergence                20.62694
KL Loss                      2.062694
QF Loss                      569.30347
VF Loss                      192.98987
Policy Loss                  -529.07874
Q Predictions Mean           517.68506
Q Predictions Std            195.46786
Q Predictions Max            817.6206
Q Predictions Min            188.38437
V Predictions Mean           521.36536
V Predictions Std            188.85822
V Predictions Max            805.86475
V Predictions Min            190.49971
Log Pis Mean                 -0.9981887
Log Pis Std                  2.5934327
Log Pis Max                  6.619376
Log Pis Min                  -10.872068
Policy mu Mean               -0.02070236
Policy mu Std                0.4860093
Policy mu Max                2.5311997
Policy mu Min                -1.9834288
Policy log std Mean          -0.94966525
Policy log std Std           0.17201659
Policy log std Max           -0.510164
Policy log std Min           -1.5209315
Z mean eval                  1.1928855
Z variance eval              0.033166043
total_rewards                [ 432.1705123   360.2768177   666.66277516  350.15806604 1059.20178896
  641.43408093  677.0800499   864.63138106 1008.07398936  595.61408841]
total_rewards_mean           665.530354982508
total_rewards_std            237.62457141120763
total_rewards_max            1059.2017889618478
total_rewards_min            350.1580660442629
Number of train steps total  284000
Number of env steps total    239625
Number of rollouts total     0
Train Time (s)               144.57700593862683
(Previous) Eval Time (s)     12.756388587877154
Sample Time (s)              7.448132732883096
Epoch Time (s)               164.78152725938708
Total Train Time (s)         11668.352172604296
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:35:04.965064 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #70 | Epoch Duration: 164.86834859848022
2020-01-11 11:35:04.965232 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1908218
Z variance train             0.033374347
KL Divergence                22.907366
KL Loss                      2.2907367
QF Loss                      412.74646
VF Loss                      67.2799
Policy Loss                  -594.5225
Q Predictions Mean           586.29016
Q Predictions Std            217.95517
Q Predictions Max            891.043
Q Predictions Min            -65.76719
V Predictions Mean           594.2102
V Predictions Std            209.15768
V Predictions Max            881.2198
V Predictions Min            40.102875
Log Pis Mean                 -1.2280188
Log Pis Std                  3.1310394
Log Pis Max                  14.481965
Log Pis Min                  -10.242387
Policy mu Mean               -0.032090373
Policy mu Std                0.5097552
Policy mu Max                2.8792431
Policy mu Min                -3.0756602
Policy log std Mean          -0.93487656
Policy log std Std           0.17915244
Policy log std Max           -0.5468421
Policy log std Min           -1.7792441
Z mean eval                  1.1911122
Z variance eval              0.034483347
total_rewards                [ 368.51842244 1727.35816265 2234.80780654 1480.308205    252.53931517
  278.74813517 1494.50109912    4.24924509 1670.18075287 1116.6931717 ]
total_rewards_mean           1062.790431574676
total_rewards_std            736.3118195527749
total_rewards_max            2234.807806538758
total_rewards_min            4.2492450914355056
Number of train steps total  288000
Number of env steps total    242322
Number of rollouts total     0
Train Time (s)               146.29736779723316
(Previous) Eval Time (s)     13.72249829210341
Sample Time (s)              8.127529131248593
Epoch Time (s)               168.14739522058517
Total Train Time (s)         11836.59748648433
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:37:53.211070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #71 | Epoch Duration: 168.2457127571106
2020-01-11 11:37:53.211217 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1950262
Z variance train             0.0348149
KL Divergence                23.056095
KL Loss                      2.3056095
QF Loss                      479.51233
VF Loss                      182.4699
Policy Loss                  -608.30566
Q Predictions Mean           598.341
Q Predictions Std            208.0658
Q Predictions Max            952.279
Q Predictions Min            187.40433
V Predictions Mean           616.63873
V Predictions Std            207.5545
V Predictions Max            961.76807
V Predictions Min            221.68887
Log Pis Mean                 -0.9951528
Log Pis Std                  3.018466
Log Pis Max                  13.589036
Log Pis Min                  -7.909141
Policy mu Mean               -0.0086485995
Policy mu Std                0.54513526
Policy mu Max                3.139247
Policy mu Min                -2.3188472
Policy log std Mean          -0.9403769
Policy log std Std           0.18905187
Policy log std Max           -0.37306803
Policy log std Min           -2.1724472
Z mean eval                  1.1590444
Z variance eval              0.06651694
total_rewards                [ 369.24238014  531.58858261 2157.61803733  631.45620408 1491.37391229
  101.29510071 1442.64001135 2144.66164776 1940.82154045  777.89035649]
total_rewards_mean           1158.8587773225804
total_rewards_std            730.1085206589632
total_rewards_max            2157.6180373332627
total_rewards_min            101.29510071156321
Number of train steps total  292000
Number of env steps total    245065
Number of rollouts total     0
Train Time (s)               145.56687718257308
(Previous) Eval Time (s)     15.572324868291616
Sample Time (s)              7.322826127056032
Epoch Time (s)               168.46202817792073
Total Train Time (s)         12005.14681625925
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:40:41.761877 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #72 | Epoch Duration: 168.5505485534668
2020-01-11 11:40:41.762048 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1574109
Z variance train             0.067137554
KL Divergence                20.961794
KL Loss                      2.0961795
QF Loss                      491.3337
VF Loss                      91.12757
Policy Loss                  -583.9868
Q Predictions Mean           575.80835
Q Predictions Std            218.1354
Q Predictions Max            892.04425
Q Predictions Min            118.163826
V Predictions Mean           586.2054
V Predictions Std            214.96144
V Predictions Max            891.2259
V Predictions Min            246.23174
Log Pis Mean                 -1.3174487
Log Pis Std                  2.5781205
Log Pis Max                  10.253751
Log Pis Min                  -8.097942
Policy mu Mean               0.031232849
Policy mu Std                0.47649896
Policy mu Max                2.2131138
Policy mu Min                -1.9319377
Policy log std Mean          -0.9205375
Policy log std Std           0.18173124
Policy log std Max           -0.2892357
Policy log std Min           -1.9316912
Z mean eval                  1.1755259
Z variance eval              0.12066598
total_rewards                [ 857.58087066 1249.9774407    55.04381158  441.06687821   98.21929604
  438.05557115   65.86461058 1272.20502111  878.64803022  833.84315735]
total_rewards_mean           619.050468759411
total_rewards_std            442.14520055956757
total_rewards_max            1272.2050211113647
total_rewards_min            55.04381157707085
Number of train steps total  296000
Number of env steps total    247465
Number of rollouts total     0
Train Time (s)               145.2628927147016
(Previous) Eval Time (s)     10.245931656099856
Sample Time (s)              7.09354940475896
Epoch Time (s)               162.6023737755604
Total Train Time (s)         12167.841603682842
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:43:24.457847 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #73 | Epoch Duration: 162.6956820487976
2020-01-11 11:43:24.457983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1780112
Z variance train             0.120635614
KL Divergence                19.49668
KL Loss                      1.9496679
QF Loss                      664.0967
VF Loss                      195.65477
Policy Loss                  -607.5032
Q Predictions Mean           597.9317
Q Predictions Std            211.65715
Q Predictions Max            898.25616
Q Predictions Min            18.4478
V Predictions Mean           618.2589
V Predictions Std            201.99304
V Predictions Max            911.7309
V Predictions Min            247.53888
Log Pis Mean                 -0.9022729
Log Pis Std                  2.8033662
Log Pis Max                  13.504318
Log Pis Min                  -7.383351
Policy mu Mean               -0.02652555
Policy mu Std                0.5146108
Policy mu Max                2.8369093
Policy mu Min                -2.399173
Policy log std Mean          -0.93629265
Policy log std Std           0.19222523
Policy log std Max           -0.3023929
Policy log std Min           -1.9044845
Z mean eval                  1.1955941
Z variance eval              0.037993662
total_rewards                [1053.09964403   14.29276404 2328.35643047  424.25220931  888.80937947
 1078.54162852  518.9020348   902.5058258   740.9281389   891.84111862]
total_rewards_mean           884.152917394162
total_rewards_std            572.2375614252022
total_rewards_max            2328.3564304668853
total_rewards_min            14.292764038053631
Number of train steps total  300000
Number of env steps total    250315
Number of rollouts total     0
Train Time (s)               145.34925869014114
(Previous) Eval Time (s)     11.937703642994165
Sample Time (s)              7.9312200476415455
Epoch Time (s)               165.21818238077685
Total Train Time (s)         12333.170657932758
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:46:09.788896 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #74 | Epoch Duration: 165.33080077171326
2020-01-11 11:46:09.789071 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1965722
Z variance train             0.038133193
KL Divergence                22.17488
KL Loss                      2.217488
QF Loss                      323.65573
VF Loss                      90.95753
Policy Loss                  -637.8068
Q Predictions Mean           632.38306
Q Predictions Std            221.61322
Q Predictions Max            930.2376
Q Predictions Min            229.96722
V Predictions Mean           641.1261
V Predictions Std            219.68393
V Predictions Max            923.04535
V Predictions Min            248.60034
Log Pis Mean                 -1.3949517
Log Pis Std                  2.6735637
Log Pis Max                  16.512585
Log Pis Min                  -9.400387
Policy mu Mean               -0.011744375
Policy mu Std                0.48765987
Policy mu Max                2.173401
Policy mu Min                -2.183971
Policy log std Mean          -0.9088788
Policy log std Std           0.18210602
Policy log std Max           -0.45705277
Policy log std Min           -2.0488656
Z mean eval                  1.1797367
Z variance eval              0.028470606
total_rewards                [ 898.05703698  179.07803473 2134.68032782  957.9734905  1449.31683277
 1006.56847663 2586.12410013 1989.92741536 2310.7796511    39.93069916]
total_rewards_mean           1355.2436065170675
total_rewards_std            839.5916734237022
total_rewards_max            2586.1241001265284
total_rewards_min            39.93069915692171
Number of train steps total  304000
Number of env steps total    253402
Number of rollouts total     0
Train Time (s)               142.05999666964635
(Previous) Eval Time (s)     18.496867510024458
Sample Time (s)              8.715543296653777
Epoch Time (s)               169.2724074763246
Total Train Time (s)         12502.542221820448
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:48:59.161632 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #75 | Epoch Duration: 169.3724296092987
2020-01-11 11:48:59.161799 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1787584
Z variance train             0.028506484
KL Divergence                22.44624
KL Loss                      2.244624
QF Loss                      467.267
VF Loss                      88.57054
Policy Loss                  -654.2046
Q Predictions Mean           649.178
Q Predictions Std            218.82193
Q Predictions Max            938.23
Q Predictions Min            16.882387
V Predictions Mean           650.36176
V Predictions Std            216.98122
V Predictions Max            936.8679
V Predictions Min            -25.961697
Log Pis Mean                 -0.7221592
Log Pis Std                  2.8386211
Log Pis Max                  18.145832
Log Pis Min                  -7.1435432
Policy mu Mean               -0.044053487
Policy mu Std                0.5335096
Policy mu Max                1.8864218
Policy mu Min                -3.1535828
Policy log std Mean          -0.9527377
Policy log std Std           0.19534427
Policy log std Max           -0.358438
Policy log std Min           -2.1091099
Z mean eval                  1.1629044
Z variance eval              0.029047167
total_rewards                [ 747.56575335  748.7873226    93.82500465  166.58559334 1180.07266539
  381.78688653  927.35308837 1120.39213684 1735.7401453   745.39516595]
total_rewards_mean           784.7503762322102
total_rewards_std            471.1435227253208
total_rewards_max            1735.7401452991892
total_rewards_min            93.82500465394878
Number of train steps total  308000
Number of env steps total    255772
Number of rollouts total     0
Train Time (s)               145.94489480787888
(Previous) Eval Time (s)     12.891144715249538
Sample Time (s)              6.410765573848039
Epoch Time (s)               165.24680509697646
Total Train Time (s)         12667.888774365652
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:51:44.509031 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #76 | Epoch Duration: 165.3471188545227
2020-01-11 11:51:44.509148 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1667107
Z variance train             0.029182892
KL Divergence                23.134527
KL Loss                      2.3134527
QF Loss                      516.948
VF Loss                      168.00244
Policy Loss                  -635.6484
Q Predictions Mean           622.23676
Q Predictions Std            230.87439
Q Predictions Max            951.2812
Q Predictions Min            -81.49465
V Predictions Mean           631.77124
V Predictions Std            219.59987
V Predictions Max            939.5853
V Predictions Min            47.46036
Log Pis Mean                 -0.6784406
Log Pis Std                  2.8866103
Log Pis Max                  18.232296
Log Pis Min                  -7.031427
Policy mu Mean               0.0010977632
Policy mu Std                0.5412015
Policy mu Max                4.8293347
Policy mu Min                -2.6357067
Policy log std Mean          -0.9536775
Policy log std Std           0.19188868
Policy log std Max           -0.47896048
Policy log std Min           -1.8168457
Z mean eval                  1.1334348
Z variance eval              0.03486127
total_rewards                [ 882.80109398  949.23384985 2609.83467727 1326.73255538 2809.80760598
 1403.20347188  772.78587999  657.98206205 1252.70063107  405.66690009]
total_rewards_mean           1307.0748727534678
total_rewards_std            761.2721879135897
total_rewards_max            2809.807605982538
total_rewards_min            405.66690009019646
Number of train steps total  312000
Number of env steps total    259429
Number of rollouts total     0
Train Time (s)               146.42652733437717
(Previous) Eval Time (s)     13.212060304824263
Sample Time (s)              6.477035508491099
Epoch Time (s)               166.11562314769253
Total Train Time (s)         12834.138829899486
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:54:30.761200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #77 | Epoch Duration: 166.25194454193115
2020-01-11 11:54:30.761379 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1334127
Z variance train             0.03491328
KL Divergence                21.726698
KL Loss                      2.17267
QF Loss                      587.5047
VF Loss                      118.79895
Policy Loss                  -608.1577
Q Predictions Mean           599.248
Q Predictions Std            240.47638
Q Predictions Max            918.1063
Q Predictions Min            -10.536973
V Predictions Mean           611.7899
V Predictions Std            231.19887
V Predictions Max            927.0451
V Predictions Min            62.869427
Log Pis Mean                 -0.90719885
Log Pis Std                  3.4787054
Log Pis Max                  21.747845
Log Pis Min                  -7.9671745
Policy mu Mean               -0.027473044
Policy mu Std                0.56969285
Policy mu Max                3.4802895
Policy mu Min                -3.1552327
Policy log std Mean          -0.9283242
Policy log std Std           0.19802523
Policy log std Max           -0.43912524
Policy log std Min           -2.0202146
Z mean eval                  1.123616
Z variance eval              0.04259572
total_rewards                [ 309.6076911  1017.56467836  286.69824443  174.11102425   54.98010368
  174.18478848 2701.9012492  1337.49167197  805.92842908  418.80624593]
total_rewards_mean           728.127412647789
total_rewards_std            767.43382961923
total_rewards_max            2701.9012492006714
total_rewards_min            54.98010368435315
Number of train steps total  316000
Number of env steps total    262039
Number of rollouts total     0
Train Time (s)               146.60701792640612
(Previous) Eval Time (s)     7.101592499297112
Sample Time (s)              7.718628770206124
Epoch Time (s)               161.42723919590935
Total Train Time (s)         12995.656002090313
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:57:12.278991 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #78 | Epoch Duration: 161.51748704910278
2020-01-11 11:57:12.279122 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1234571
Z variance train             0.04282393
KL Divergence                21.279045
KL Loss                      2.1279047
QF Loss                      660.9391
VF Loss                      101.64008
Policy Loss                  -640.8829
Q Predictions Mean           632.63916
Q Predictions Std            239.63953
Q Predictions Max            987.09827
Q Predictions Min            16.99297
V Predictions Mean           641.2323
V Predictions Std            233.74147
V Predictions Max            982.77844
V Predictions Min            137.69565
Log Pis Mean                 -1.0797414
Log Pis Std                  2.5968745
Log Pis Max                  11.374531
Log Pis Min                  -7.3145943
Policy mu Mean               -0.015661165
Policy mu Std                0.51131696
Policy mu Max                2.3013883
Policy mu Min                -1.8826041
Policy log std Mean          -0.92535317
Policy log std Std           0.18450071
Policy log std Max           -0.4441803
Policy log std Min           -1.7828376
Z mean eval                  1.1254175
Z variance eval              0.029694999
total_rewards                [2501.14330658 1107.66419177  249.78756715  333.1736951   183.87026633
  955.0474593  1315.40998908  709.4674421  2463.47516566 1334.67884594]
total_rewards_mean           1115.3717928998717
total_rewards_std            790.2621657631513
total_rewards_max            2501.1433065798187
total_rewards_min            183.87026632898417
Number of train steps total  320000
Number of env steps total    266853
Number of rollouts total     0
Train Time (s)               145.33782531600446
(Previous) Eval Time (s)     11.790554250124842
Sample Time (s)              8.79061400797218
Epoch Time (s)               165.91899357410148
Total Train Time (s)         13161.664081514813
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:58.292322 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #79 | Epoch Duration: 166.0130536556244
2020-01-11 11:59:58.292616 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1239557
Z variance train             0.029876536
KL Divergence                23.928654
KL Loss                      2.3928654
QF Loss                      546.9822
VF Loss                      87.734535
Policy Loss                  -656.543
Q Predictions Mean           647.76904
Q Predictions Std            243.46603
Q Predictions Max            982.89453
Q Predictions Min            4.853164
V Predictions Mean           654.6562
V Predictions Std            235.36185
V Predictions Max            973.3772
V Predictions Min            87.067894
Log Pis Mean                 -0.5896331
Log Pis Std                  3.3161938
Log Pis Max                  18.773563
Log Pis Min                  -8.539778
Policy mu Mean               0.010550283
Policy mu Std                0.5552607
Policy mu Max                2.1321833
Policy mu Min                -3.173548
Policy log std Mean          -0.9611871
Policy log std Std           0.20795907
Policy log std Max           -0.47318318
Policy log std Min           -2.083742
Z mean eval                  1.1464139
Z variance eval              0.058595754
total_rewards                [  85.94429151  329.95467555 1558.7712623   741.50338527  500.32456414
 1129.46735775  736.95887329  314.67330534 1690.92562655 1216.93700527]
total_rewards_mean           830.546034696053
total_rewards_std            520.2017369491078
total_rewards_max            1690.925626554838
total_rewards_min            85.94429150970441
Number of train steps total  324000
Number of env steps total    270538
Number of rollouts total     0
Train Time (s)               145.01222174428403
(Previous) Eval Time (s)     12.39139118976891
Sample Time (s)              8.10503421863541
Epoch Time (s)               165.50864715268835
Total Train Time (s)         13327.274320170749
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:43.900322 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #80 | Epoch Duration: 165.60749769210815
2020-01-11 12:02:43.900438 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1441114
Z variance train             0.058782004
KL Divergence                21.86949
KL Loss                      2.186949
QF Loss                      700.3443
VF Loss                      272.6529
Policy Loss                  -670.8493
Q Predictions Mean           662.6105
Q Predictions Std            224.32056
Q Predictions Max            988.322
Q Predictions Min            76.643974
V Predictions Mean           681.6992
V Predictions Std            220.95715
V Predictions Max            996.89197
V Predictions Min            87.089325
Log Pis Mean                 -0.53722
Log Pis Std                  2.9157064
Log Pis Max                  18.555622
Log Pis Min                  -9.182005
Policy mu Mean               0.017583413
Policy mu Std                0.5839557
Policy mu Max                4.9496293
Policy mu Min                -2.7460673
Policy log std Mean          -0.95473707
Policy log std Std           0.20739906
Policy log std Max           0.13755167
Policy log std Min           -1.8641407
Z mean eval                  1.1662866
Z variance eval              0.080158226
total_rewards                [1009.61114601  333.48835652 2905.89534645 1280.03361592  297.80567921
 1614.78316899  622.05893324 2834.56114781 1252.53904164 2807.29333694]
total_rewards_mean           1495.8069772714978
total_rewards_std            969.8718932352222
total_rewards_max            2905.895346446139
total_rewards_min            297.80567920732636
Number of train steps total  328000
Number of env steps total    273406
Number of rollouts total     0
Train Time (s)               145.9088009428233
(Previous) Eval Time (s)     16.56766366586089
Sample Time (s)              7.225104488898069
Epoch Time (s)               169.70156909758225
Total Train Time (s)         13497.08461338235
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:33.715093 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #81 | Epoch Duration: 169.8145170211792
2020-01-11 12:05:33.715342 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1700454
Z variance train             0.080901906
KL Divergence                20.109024
KL Loss                      2.0109024
QF Loss                      547.6885
VF Loss                      284.7756
Policy Loss                  -651.15125
Q Predictions Mean           640.9755
Q Predictions Std            254.21387
Q Predictions Max            1011.2229
Q Predictions Min            -45.124226
V Predictions Mean           647.98486
V Predictions Std            244.64342
V Predictions Max            999.21875
V Predictions Min            26.54129
Log Pis Mean                 -0.71812874
Log Pis Std                  3.2249918
Log Pis Max                  16.31097
Log Pis Min                  -7.287881
Policy mu Mean               -0.022526477
Policy mu Std                0.5321134
Policy mu Max                2.9969172
Policy mu Min                -2.571599
Policy log std Mean          -0.9470017
Policy log std Std           0.20914848
Policy log std Max           -0.3785131
Policy log std Min           -2.5000718
Z mean eval                  1.1613231
Z variance eval              0.03246496
total_rewards                [1588.24558894  405.01642554 2827.32649018  610.04430064  187.14571762
  511.03835997 1576.13162466 1190.93123057 1486.22146396 2077.2511116 ]
total_rewards_mean           1245.9352313680943
total_rewards_std            790.661983319767
total_rewards_max            2827.326490176144
total_rewards_min            187.14571761753038
Number of train steps total  332000
Number of env steps total    276287
Number of rollouts total     0
Train Time (s)               145.7578132650815
(Previous) Eval Time (s)     11.085906475782394
Sample Time (s)              8.652552721090615
Epoch Time (s)               165.4962724619545
Total Train Time (s)         13662.91829563398
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:08:19.552653 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #82 | Epoch Duration: 165.83712124824524
2020-01-11 12:08:19.552822 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1564596
Z variance train             0.032665145
KL Divergence                21.413742
KL Loss                      2.1413743
QF Loss                      634.7092
VF Loss                      124.0933
Policy Loss                  -650.3334
Q Predictions Mean           640.9228
Q Predictions Std            247.32837
Q Predictions Max            1013.30585
Q Predictions Min            120.43795
V Predictions Mean           656.0747
V Predictions Std            243.84027
V Predictions Max            1019.2425
V Predictions Min            79.43256
Log Pis Mean                 -0.55366
Log Pis Std                  3.821808
Log Pis Max                  28.09946
Log Pis Min                  -7.635487
Policy mu Mean               -0.0013755136
Policy mu Std                0.6041694
Policy mu Max                3.494892
Policy mu Min                -3.9366252
Policy log std Mean          -0.9352991
Policy log std Std           0.19903138
Policy log std Max           -0.3540693
Policy log std Min           -2.182852
Z mean eval                  1.1830701
Z variance eval              0.023309793
total_rewards                [1166.73359209 1553.86167387 2027.40216141 2622.04656101  548.80533152
  583.63927729 1363.63423219   81.7807398  1819.36245719  317.06487223]
total_rewards_mean           1208.4330898594073
total_rewards_std            779.5353829218657
total_rewards_max            2622.04656100999
total_rewards_min            81.78073980363732
Number of train steps total  336000
Number of env steps total    278805
Number of rollouts total     0
Train Time (s)               146.99228800972924
(Previous) Eval Time (s)     15.519741042051464
Sample Time (s)              7.905120305716991
Epoch Time (s)               170.4171493574977
Total Train Time (s)         13833.466852859128
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:10.097945 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #83 | Epoch Duration: 170.5450041294098
2020-01-11 12:11:10.098076 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1872823
Z variance train             0.023116682
KL Divergence                22.699482
KL Loss                      2.2699482
QF Loss                      598.1145
VF Loss                      109.138466
Policy Loss                  -699.76025
Q Predictions Mean           688.10925
Q Predictions Std            238.76738
Q Predictions Max            1028.5194
Q Predictions Min            218.72662
V Predictions Mean           695.23804
V Predictions Std            231.37582
V Predictions Max            1025.8087
V Predictions Min            221.83905
Log Pis Mean                 -0.8134088
Log Pis Std                  3.0228884
Log Pis Max                  15.970894
Log Pis Min                  -8.445982
Policy mu Mean               0.020059146
Policy mu Std                0.55988866
Policy mu Max                2.0699623
Policy mu Min                -3.0091195
Policy log std Mean          -0.95306057
Policy log std Std           0.19820295
Policy log std Max           -0.20887232
Policy log std Min           -2.2471964
Z mean eval                  1.1572545
Z variance eval              0.03840958
total_rewards                [ 184.55112184 2256.33560273  669.82955915  967.70619829 2831.84057711
 1635.13063399  969.73191601 1816.06703953 1532.01407672  527.39906593]
total_rewards_mean           1339.0605791307642
total_rewards_std            783.3309440352436
total_rewards_max            2831.8405771111466
total_rewards_min            184.5511218353626
Number of train steps total  340000
Number of env steps total    281339
Number of rollouts total     0
Train Time (s)               146.23861079197377
(Previous) Eval Time (s)     13.228446173015982
Sample Time (s)              7.517776522319764
Epoch Time (s)               166.98483348730952
Total Train Time (s)         14000.545443301555
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:13:57.180795 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #84 | Epoch Duration: 167.082617521286
2020-01-11 12:13:57.180949 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1514196
Z variance train             0.038580656
KL Divergence                22.377077
KL Loss                      2.2377079
QF Loss                      626.558
VF Loss                      193.33472
Policy Loss                  -646.2271
Q Predictions Mean           635.7528
Q Predictions Std            248.67126
Q Predictions Max            1000.27655
Q Predictions Min            1.9575622
V Predictions Mean           640.78564
V Predictions Std            240.27463
V Predictions Max            996.6964
V Predictions Min            185.79114
Log Pis Mean                 -0.7474805
Log Pis Std                  3.500153
Log Pis Max                  19.118553
Log Pis Min                  -6.795967
Policy mu Mean               0.016106602
Policy mu Std                0.5634297
Policy mu Max                3.5357828
Policy mu Min                -3.3186378
Policy log std Mean          -0.94904757
Policy log std Std           0.2029897
Policy log std Max           -0.4987305
Policy log std Min           -1.8660424
Z mean eval                  1.1339571
Z variance eval              0.01703647
total_rewards                [3011.93241248  923.45987897  745.99701452   14.93975909 1427.67758613
   67.32856126  133.73738396  458.7703334   377.10221619 1947.51734008]
total_rewards_mean           910.8462486056026
total_rewards_std            916.0252761028892
total_rewards_max            3011.9324124753703
total_rewards_min            14.939759085964628
Number of train steps total  344000
Number of env steps total    283838
Number of rollouts total     0
Train Time (s)               145.92108394484967
(Previous) Eval Time (s)     7.221071666106582
Sample Time (s)              6.445917547214776
Epoch Time (s)               159.58807315817103
Total Train Time (s)         14160.227921927348
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:16:36.864529 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #85 | Epoch Duration: 159.68343997001648
2020-01-11 12:16:36.864702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1361444
Z variance train             0.017005976
KL Divergence                23.2451
KL Loss                      2.32451
QF Loss                      610.19855
VF Loss                      157.26207
Policy Loss                  -675.98364
Q Predictions Mean           667.0516
Q Predictions Std            255.17226
Q Predictions Max            1034.1118
Q Predictions Min            -29.67717
V Predictions Mean           680.14716
V Predictions Std            252.24939
V Predictions Max            1032.1815
V Predictions Min            29.625849
Log Pis Mean                 -0.86052084
Log Pis Std                  3.207926
Log Pis Max                  12.931082
Log Pis Min                  -12.2335
Policy mu Mean               0.00025814865
Policy mu Std                0.5639686
Policy mu Max                2.2138886
Policy mu Min                -2.8003957
Policy log std Mean          -0.94029206
Policy log std Std           0.2006926
Policy log std Max           -0.33707052
Policy log std Min           -2.1112323
Z mean eval                  1.118305
Z variance eval              0.03736175
total_rewards                [1234.40283128 1045.54002548 1300.26567004 1271.15148673  441.31982877
  761.48085467 2876.02133171 1465.63929359 2560.635338   1372.28492333]
total_rewards_mean           1432.874158359309
total_rewards_std            708.969000758311
total_rewards_max            2876.0213317060425
total_rewards_min            441.31982876711226
Number of train steps total  348000
Number of env steps total    287337
Number of rollouts total     0
Train Time (s)               146.02213972015306
(Previous) Eval Time (s)     10.794711973052472
Sample Time (s)              6.946343493647873
Epoch Time (s)               163.7631951868534
Total Train Time (s)         14324.130545349792
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:20.767218 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #86 | Epoch Duration: 163.9023892879486
2020-01-11 12:19:20.767346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.120793
Z variance train             0.037114535
KL Divergence                21.512436
KL Loss                      2.1512437
QF Loss                      858.5605
VF Loss                      163.63998
Policy Loss                  -684.5798
Q Predictions Mean           673.01294
Q Predictions Std            244.36823
Q Predictions Max            1027.8954
Q Predictions Min            1.771877
V Predictions Mean           689.83344
V Predictions Std            238.9582
V Predictions Max            1023.55426
V Predictions Min            152.38753
Log Pis Mean                 -0.7973733
Log Pis Std                  3.152714
Log Pis Max                  20.5378
Log Pis Min                  -8.1095495
Policy mu Mean               -0.014202878
Policy mu Std                0.5548434
Policy mu Max                3.2039883
Policy mu Min                -2.7833405
Policy log std Mean          -0.9485576
Policy log std Std           0.2089324
Policy log std Max           -0.30112118
Policy log std Min           -1.9974856
Z mean eval                  1.1496637
Z variance eval              0.06625487
total_rewards                [1242.35414625  791.90623794  408.70349497  325.57171038  382.86744397
  709.59916015  462.14687324  536.32802198   10.36932057 1202.56467058]
total_rewards_mean           607.2411080028871
total_rewards_std            367.93918035382364
total_rewards_max            1242.354146251948
total_rewards_min            10.369320567678908
Number of train steps total  352000
Number of env steps total    290050
Number of rollouts total     0
Train Time (s)               145.77912659430876
(Previous) Eval Time (s)     11.772004297934473
Sample Time (s)              7.118670864962041
Epoch Time (s)               164.66980175720528
Total Train Time (s)         14488.88751319144
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:05.525367 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #87 | Epoch Duration: 164.75792288780212
2020-01-11 12:22:05.525499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.152003
Z variance train             0.0652714
KL Divergence                20.553986
KL Loss                      2.0553987
QF Loss                      658.4581
VF Loss                      159.36105
Policy Loss                  -677.74615
Q Predictions Mean           672.5143
Q Predictions Std            260.55643
Q Predictions Max            1012.9764
Q Predictions Min            204.30428
V Predictions Mean           674.4408
V Predictions Std            255.28354
V Predictions Max            1003.1269
V Predictions Min            197.4955
Log Pis Mean                 -0.3178062
Log Pis Std                  3.7143419
Log Pis Max                  24.468616
Log Pis Min                  -6.5106997
Policy mu Mean               -0.05316739
Policy mu Std                0.5924162
Policy mu Max                3.325255
Policy mu Min                -5.197674
Policy log std Mean          -0.96360004
Policy log std Std           0.20526576
Policy log std Max           -0.43909973
Policy log std Min           -1.7358116
Z mean eval                  1.1572117
Z variance eval              0.04384597
total_rewards                [2710.35432372 2646.3577647   745.9656204   215.39027766 1092.45519273
 2887.61901115 2820.93643564 1114.72410679  313.95080465 2445.93458911]
total_rewards_mean           1699.3688126565714
total_rewards_std            1043.3982592931745
total_rewards_max            2887.619011147355
total_rewards_min            215.3902776631208
Number of train steps total  356000
Number of env steps total    294494
Number of rollouts total     0
Train Time (s)               146.32640221202746
(Previous) Eval Time (s)     15.193536568898708
Sample Time (s)              7.154351927340031
Epoch Time (s)               168.6742907082662
Total Train Time (s)         14657.651511703618
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:24:54.289696 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #88 | Epoch Duration: 168.76410579681396
2020-01-11 12:24:54.289815 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1507107
Z variance train             0.04381284
KL Divergence                21.546776
KL Loss                      2.1546776
QF Loss                      632.627
VF Loss                      132.04419
Policy Loss                  -725.859
Q Predictions Mean           715.35315
Q Predictions Std            245.41554
Q Predictions Max            1044.6503
Q Predictions Min            256.75375
V Predictions Mean           728.7958
V Predictions Std            240.59712
V Predictions Max            1044.5939
V Predictions Min            265.7505
Log Pis Mean                 -0.2653486
Log Pis Std                  3.4064138
Log Pis Max                  17.51432
Log Pis Min                  -8.873028
Policy mu Mean               -0.022627711
Policy mu Std                0.5901002
Policy mu Max                3.1041403
Policy mu Min                -3.0744576
Policy log std Mean          -0.9740984
Policy log std Std           0.21368043
Policy log std Max           -0.36718842
Policy log std Min           -2.032976
Z mean eval                  1.177572
Z variance eval              0.048391946
total_rewards                [ 996.16016973  951.68551592  806.38856885 2798.1621086  1532.88009167
  565.77029754  925.15004504 1559.48220821 2431.18146229  158.39719706]
total_rewards_mean           1272.5257664903882
total_rewards_std            779.6302709820496
total_rewards_max            2798.162108598809
total_rewards_min            158.39719705669592
Number of train steps total  360000
Number of env steps total    297079
Number of rollouts total     0
Train Time (s)               145.8743278319016
(Previous) Eval Time (s)     17.20375247206539
Sample Time (s)              6.747130289673805
Epoch Time (s)               169.8252105936408
Total Train Time (s)         14827.616396201774
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:27:44.257084 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #89 | Epoch Duration: 169.9671688079834
2020-01-11 12:27:44.257237 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1769294
Z variance train             0.048384763
KL Divergence                20.218945
KL Loss                      2.0218945
QF Loss                      739.48926
VF Loss                      182.01231
Policy Loss                  -686.5805
Q Predictions Mean           674.91064
Q Predictions Std            268.46948
Q Predictions Max            1037.924
Q Predictions Min            24.267397
V Predictions Mean           693.0956
V Predictions Std            261.79932
V Predictions Max            1037.574
V Predictions Min            247.29588
Log Pis Mean                 -0.3302831
Log Pis Std                  3.3538265
Log Pis Max                  17.357841
Log Pis Min                  -9.317745
Policy mu Mean               -0.053360596
Policy mu Std                0.5545301
Policy mu Max                2.62041
Policy mu Min                -2.3876843
Policy log std Mean          -0.96939564
Policy log std Std           0.2192933
Policy log std Max           -0.47655138
Policy log std Min           -2.0211866
Z mean eval                  1.1690383
Z variance eval              0.03969432
total_rewards                [ 690.7911426  1127.80812824  384.47198023  430.32901901  260.96834633
 2243.6888453   399.29882398  839.23438738 1467.97711036 2562.32025053]
total_rewards_mean           1040.6888033978337
total_rewards_std            770.6006341019672
total_rewards_max            2562.3202505325185
total_rewards_min            260.96834633290825
Number of train steps total  364000
Number of env steps total    299747
Number of rollouts total     0
Train Time (s)               145.16508227493614
(Previous) Eval Time (s)     12.394671720918268
Sample Time (s)              6.292104282416403
Epoch Time (s)               163.8518582782708
Total Train Time (s)         14991.553204536438
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:30:28.194698 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #90 | Epoch Duration: 163.93734335899353
2020-01-11 12:30:28.194816 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #90 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1678836
Z variance train             0.0399056
KL Divergence                22.549728
KL Loss                      2.254973
QF Loss                      593.4066
VF Loss                      117.2023
Policy Loss                  -693.0806
Q Predictions Mean           679.49384
Q Predictions Std            271.55322
Q Predictions Max            1046.0001
Q Predictions Min            -4.348925
V Predictions Mean           693.3878
V Predictions Std            262.0332
V Predictions Max            1032.5762
V Predictions Min            185.8291
Log Pis Mean                 -0.41461897
Log Pis Std                  3.2751007
Log Pis Max                  22.26662
Log Pis Min                  -5.8123856
Policy mu Mean               -0.028186193
Policy mu Std                0.5674376
Policy mu Max                3.7860255
Policy mu Min                -3.3135376
Policy log std Mean          -0.943563
Policy log std Std           0.20416471
Policy log std Max           -0.29065013
Policy log std Min           -1.8006809
Z mean eval                  1.1952822
Z variance eval              0.010127473
total_rewards                [1513.49346233  557.36032079 1613.68153965 2332.61679267  657.4198303
 1477.11227872  599.15866479 1439.69563886 1405.04597051 1039.381693  ]
total_rewards_mean           1263.496619163091
total_rewards_std            527.4836274796226
total_rewards_max            2332.616792673744
total_rewards_min            557.360320790883
Number of train steps total  368000
Number of env steps total    302684
Number of rollouts total     0
Train Time (s)               144.4797490555793
(Previous) Eval Time (s)     10.718638488091528
Sample Time (s)              6.985424851067364
Epoch Time (s)               162.1838123947382
Total Train Time (s)         15153.822351466864
Epoch                        91
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:33:10.464866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #91 | Epoch Duration: 162.26996064186096
2020-01-11 12:33:10.464982 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1957158
Z variance train             0.010155366
KL Divergence                24.712896
KL Loss                      2.4712896
QF Loss                      501.10004
VF Loss                      151.96216
Policy Loss                  -710.2552
Q Predictions Mean           700.16626
Q Predictions Std            268.29773
Q Predictions Max            1056.0751
Q Predictions Min            49.630928
V Predictions Mean           703.09875
V Predictions Std            261.60352
V Predictions Max            1051.6449
V Predictions Min            224.73639
Log Pis Mean                 -0.5337684
Log Pis Std                  2.663738
Log Pis Max                  12.15313
Log Pis Min                  -6.6912355
Policy mu Mean               -0.005980752
Policy mu Std                0.53784007
Policy mu Max                2.4469178
Policy mu Min                -2.3142493
Policy log std Mean          -0.9636756
Policy log std Std           0.20794153
Policy log std Max           -0.4691312
Policy log std Min           -1.9651415
Z mean eval                  1.1664493
Z variance eval              0.01583558
total_rewards                [1037.48553778 1291.43275741 2876.17769455 2976.14613863 1147.77500258
  381.13055949 2778.76689813 2966.78159182   55.15575124  870.41587419]
total_rewards_mean           1638.1267805839275
total_rewards_std            1085.6370334098501
total_rewards_max            2976.146138630738
total_rewards_min            55.15575123989386
Number of train steps total  372000
Number of env steps total    305226
Number of rollouts total     0
Train Time (s)               146.0667089158669
(Previous) Eval Time (s)     19.500028122216463
Sample Time (s)              6.392521204892546
Epoch Time (s)               171.95925824297592
Total Train Time (s)         15325.869676528499
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:36:02.516318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #92 | Epoch Duration: 172.05123805999756
2020-01-11 12:36:02.516463 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.165091
Z variance train             0.015827607
KL Divergence                23.27862
KL Loss                      2.327862
QF Loss                      596.73035
VF Loss                      249.19112
Policy Loss                  -698.9291
Q Predictions Mean           693.45386
Q Predictions Std            274.28546
Q Predictions Max            1052.9686
Q Predictions Min            -4.108209
V Predictions Mean           705.33386
V Predictions Std            269.18796
V Predictions Max            1059.6
V Predictions Min            179.88629
Log Pis Mean                 -0.16160071
Log Pis Std                  3.6876628
Log Pis Max                  19.919449
Log Pis Min                  -10.157824
Policy mu Mean               -0.013657363
Policy mu Std                0.5919783
Policy mu Max                3.2827032
Policy mu Min                -4.608652
Policy log std Mean          -0.98561347
Policy log std Std           0.21637255
Policy log std Max           -0.35837084
Policy log std Min           -2.2010345
Z mean eval                  1.0984145
Z variance eval              0.03080832
total_rewards                [ 306.49413619 1036.27205492 2071.92407297  131.52504369  958.30413996
 1723.7100899  1791.24066188 1399.05838084  644.5606887  1084.00797243]
total_rewards_mean           1114.709724146773
total_rewards_std            608.1242852949645
total_rewards_max            2071.9240729657413
total_rewards_min            131.5250436852101
Number of train steps total  376000
Number of env steps total    307541
Number of rollouts total     0
Train Time (s)               146.11783630307764
(Previous) Eval Time (s)     15.072116056457162
Sample Time (s)              7.089943575207144
Epoch Time (s)               168.27989593474194
Total Train Time (s)         15494.235586226918
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:38:50.882539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #93 | Epoch Duration: 168.3659725189209
2020-01-11 12:38:50.882679 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1065959
Z variance train             0.030614942
KL Divergence                24.376501
KL Loss                      2.4376502
QF Loss                      1318.8671
VF Loss                      181.21417
Policy Loss                  -699.25824
Q Predictions Mean           684.4751
Q Predictions Std            284.08942
Q Predictions Max            1071.1694
Q Predictions Min            48.88388
V Predictions Mean           698.3362
V Predictions Std            272.47632
V Predictions Max            1051.1831
V Predictions Min            97.17395
Log Pis Mean                 -0.6645451
Log Pis Std                  3.1281502
Log Pis Max                  17.0873
Log Pis Min                  -10.864947
Policy mu Mean               -0.03710409
Policy mu Std                0.5616592
Policy mu Max                3.2425091
Policy mu Min                -3.9673727
Policy log std Mean          -0.9726176
Policy log std Std           0.21102254
Policy log std Max           -0.39001107
Policy log std Min           -2.0269694
Z mean eval                  1.1563785
Z variance eval              0.013169205
total_rewards                [2588.14191509 2988.94978087 1203.3358382   671.43822726 1064.03649011
  447.96529182  584.77872761 1650.99022915  145.03605003  430.48240274]
total_rewards_mean           1177.5154952886141
total_rewards_std            909.5411144167842
total_rewards_max            2988.949780871374
total_rewards_min            145.03605003131753
Number of train steps total  380000
Number of env steps total    310116
Number of rollouts total     0
Train Time (s)               146.2868282981217
(Previous) Eval Time (s)     12.145781306084245
Sample Time (s)              7.784666991792619
Epoch Time (s)               166.21727659599856
Total Train Time (s)         15660.545310323592
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:41:37.192990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #94 | Epoch Duration: 166.31022214889526
2020-01-11 12:41:37.193103 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.158774
Z variance train             0.012800259
KL Divergence                25.049818
KL Loss                      2.5049818
QF Loss                      372.80756
VF Loss                      160.30547
Policy Loss                  -703.6202
Q Predictions Mean           696.8865
Q Predictions Std            277.72504
Q Predictions Max            1088.8235
Q Predictions Min            51.698444
V Predictions Mean           711.5539
V Predictions Std            276.78986
V Predictions Max            1085.6079
V Predictions Min            63.374283
Log Pis Mean                 -0.86673266
Log Pis Std                  3.0326743
Log Pis Max                  11.569282
Log Pis Min                  -6.5945573
Policy mu Mean               -0.014072791
Policy mu Std                0.5430429
Policy mu Max                3.1972888
Policy mu Min                -3.3296762
Policy log std Mean          -0.948483
Policy log std Std           0.19919308
Policy log std Max           -0.4168571
Policy log std Min           -2.0011983
Z mean eval                  1.1487606
Z variance eval              0.024283882
total_rewards                [1766.33279641 2707.0132719   184.7734423   825.75728022  389.49253994
  338.72578759 2827.72355338 1342.96264683 3085.11767263 2895.68361896]
total_rewards_mean           1636.3582610153198
total_rewards_std            1111.581241601937
total_rewards_max            3085.1176726330577
total_rewards_min            184.77344230233757
Number of train steps total  384000
Number of env steps total    313768
Number of rollouts total     0
Train Time (s)               144.721858096309
(Previous) Eval Time (s)     18.09333844576031
Sample Time (s)              6.791068407241255
Epoch Time (s)               169.60626494931057
Total Train Time (s)         15830.247561837547
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:44:26.896722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #95 | Epoch Duration: 169.703528881073
2020-01-11 12:44:26.896853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1486022
Z variance train             0.024163824
KL Divergence                22.665247
KL Loss                      2.2665248
QF Loss                      1852.6862
VF Loss                      2634.5234
Policy Loss                  -757.12317
Q Predictions Mean           749.1384
Q Predictions Std            271.91025
Q Predictions Max            1093.0219
Q Predictions Min            -7.1939
V Predictions Mean           760.8563
V Predictions Std            260.05554
V Predictions Max            1086.4974
V Predictions Min            174.35805
Log Pis Mean                 -0.29968694
Log Pis Std                  3.3469603
Log Pis Max                  22.817307
Log Pis Min                  -6.745676
Policy mu Mean               -0.024890028
Policy mu Std                0.5841865
Policy mu Max                3.83722
Policy mu Min                -5.50219
Policy log std Mean          -0.98278487
Policy log std Std           0.20567176
Policy log std Max           -0.33490795
Policy log std Min           -2.0268636
Z mean eval                  1.2101891
Z variance eval              0.016104836
total_rewards                [2802.33166221 1481.06639677 3118.90561809  518.18932153 1322.24877189
  450.10555303 2881.52695648  658.9175349  2860.93220979 1278.20173412]
total_rewards_mean           1737.2425758806753
total_rewards_std            1018.3140328069459
total_rewards_max            3118.9056180906105
total_rewards_min            450.1055530281762
Number of train steps total  388000
Number of env steps total    316317
Number of rollouts total     0
Train Time (s)               146.30361416982487
(Previous) Eval Time (s)     20.63978747278452
Sample Time (s)              8.137791307177395
Epoch Time (s)               175.08119294978678
Total Train Time (s)         16005.41932959389
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:47:22.070392 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #96 | Epoch Duration: 175.17343306541443
2020-01-11 12:47:22.070563 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2090911
Z variance train             0.01620726
KL Divergence                22.381315
KL Loss                      2.2381315
QF Loss                      708.172
VF Loss                      157.56332
Policy Loss                  -708.38617
Q Predictions Mean           697.8377
Q Predictions Std            265.68808
Q Predictions Max            1066.219
Q Predictions Min            20.906893
V Predictions Mean           707.0325
V Predictions Std            256.83694
V Predictions Max            1066.9412
V Predictions Min            149.57849
Log Pis Mean                 -0.24312851
Log Pis Std                  4.055923
Log Pis Max                  27.142365
Log Pis Min                  -9.223588
Policy mu Mean               -0.0014690142
Policy mu Std                0.6104463
Policy mu Max                3.364459
Policy mu Min                -4.307612
Policy log std Mean          -0.984323
Policy log std Std           0.22234745
Policy log std Max           -0.4377197
Policy log std Min           -2.3252716
Z mean eval                  1.1952647
Z variance eval              0.013889837
total_rewards                [ 434.70138284  836.87874998  267.57227054   52.56181961 1158.03846859
  729.63317008  554.45315962 1119.19887521 2110.00399596  288.39000699]
total_rewards_mean           755.1431899419515
total_rewards_std            568.3312741096571
total_rewards_max            2110.003995963932
total_rewards_min            52.5618196058897
Number of train steps total  392000
Number of env steps total    319294
Number of rollouts total     0
Train Time (s)               146.41809606691822
(Previous) Eval Time (s)     8.218322292901576
Sample Time (s)              9.25502912281081
Epoch Time (s)               163.8914474826306
Total Train Time (s)         16169.396505737212
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:50:06.053543 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #97 | Epoch Duration: 163.98272681236267
2020-01-11 12:50:06.053682 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1973459
Z variance train             0.013905828
KL Divergence                22.65769
KL Loss                      2.265769
QF Loss                      633.28015
VF Loss                      126.27298
Policy Loss                  -753.2395
Q Predictions Mean           742.3233
Q Predictions Std            267.80133
Q Predictions Max            1099.7433
Q Predictions Min            44.12876
V Predictions Mean           754.5243
V Predictions Std            263.89697
V Predictions Max            1100.5187
V Predictions Min            91.097565
Log Pis Mean                 -0.4226552
Log Pis Std                  3.4011922
Log Pis Max                  18.999058
Log Pis Min                  -8.031449
Policy mu Mean               -0.0205201
Policy mu Std                0.5746166
Policy mu Max                2.360625
Policy mu Min                -3.1164129
Policy log std Mean          -0.9708313
Policy log std Std           0.21898258
Policy log std Max           -0.37513423
Policy log std Min           -2.6870103
Z mean eval                  1.1499422
Z variance eval              0.011868866
total_rewards                [1407.83341189 2147.23305094 1389.65267012  406.62885198 1233.61730161
  904.45695467 2154.43311456 2395.72411442 1445.88177148  997.46997807]
total_rewards_mean           1448.2931219727511
total_rewards_std            593.2964813140984
total_rewards_max            2395.7241144203294
total_rewards_min            406.62885197634427
Number of train steps total  396000
Number of env steps total    321831
Number of rollouts total     0
Train Time (s)               145.45225416403264
(Previous) Eval Time (s)     13.852588579058647
Sample Time (s)              7.584994349163026
Epoch Time (s)               166.8898370922543
Total Train Time (s)         16336.377725211903
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:52:53.033823 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #98 | Epoch Duration: 166.980046749115
2020-01-11 12:52:53.033944 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.155693
Z variance train             0.01179162
KL Divergence                23.352032
KL Loss                      2.3352032
QF Loss                      640.82153
VF Loss                      117.52988
Policy Loss                  -748.0136
Q Predictions Mean           736.937
Q Predictions Std            282.7084
Q Predictions Max            1097.2827
Q Predictions Min            -42.550358
V Predictions Mean           746.09186
V Predictions Std            274.9746
V Predictions Max            1090.6128
V Predictions Min            6.8195896
Log Pis Mean                 -0.6096846
Log Pis Std                  3.4557238
Log Pis Max                  18.691929
Log Pis Min                  -9.321843
Policy mu Mean               -0.014266798
Policy mu Std                0.58208466
Policy mu Max                3.525084
Policy mu Min                -3.0468276
Policy log std Mean          -0.94919944
Policy log std Std           0.20852037
Policy log std Max           -0.26660234
Policy log std Min           -1.8011134
Z mean eval                  1.088807
Z variance eval              0.011834802
total_rewards                [ 496.12344149 2436.60049468 2925.51939621  535.31306189 1468.77076109
 2785.32309348 2702.1824141  3158.36296297 2588.10758863 2158.38518617]
total_rewards_mean           2125.468840071323
total_rewards_std            916.5965601844817
total_rewards_max            3158.3629629731213
total_rewards_min            496.12344148570145
Number of train steps total  400000
Number of env steps total    325517
Number of rollouts total     0
Train Time (s)               144.21574826771393
(Previous) Eval Time (s)     20.791508980095387
Sample Time (s)              6.185577047523111
Epoch Time (s)               171.19283429533243
Total Train Time (s)         16507.65464559151
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:44.312488 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #99 | Epoch Duration: 171.27845120429993
2020-01-11 12:55:44.312615 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0947878
Z variance train             0.011745921
KL Divergence                22.461605
KL Loss                      2.2461605
QF Loss                      796.7204
VF Loss                      112.49472
Policy Loss                  -775.1483
Q Predictions Mean           766.2647
Q Predictions Std            275.08997
Q Predictions Max            1135.3416
Q Predictions Min            251.3718
V Predictions Mean           769.57745
V Predictions Std            272.68832
V Predictions Max            1122.2083
V Predictions Min            243.39609
Log Pis Mean                 -0.6811141
Log Pis Std                  2.6385753
Log Pis Max                  9.84305
Log Pis Min                  -7.392235
Policy mu Mean               0.0029400517
Policy mu Std                0.5481214
Policy mu Max                2.7221384
Policy mu Min                -2.2527013
Policy log std Mean          -0.9657392
Policy log std Std           0.20721012
Policy log std Max           -0.47321266
Policy log std Min           -1.997512
Z mean eval                  1.1098852
Z variance eval              0.021087835
total_rewards                [2721.30347004 1055.94075127  752.6214436  2226.22501823 3217.45034498
  655.99847982  500.88402211 3124.19547404 1642.50898292 2417.80895712]
total_rewards_mean           1831.4936944133337
total_rewards_std            991.8047989556362
total_rewards_max            3217.450344977977
total_rewards_min            500.88402211324836
Number of train steps total  404000
Number of env steps total    327921
Number of rollouts total     0
Train Time (s)               147.86903319740668
(Previous) Eval Time (s)     14.517943400889635
Sample Time (s)              7.164438769221306
Epoch Time (s)               169.55141536751762
Total Train Time (s)         16677.291517934762
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:33.954340 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #100 | Epoch Duration: 169.64157390594482
2020-01-11 12:58:33.954812 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1072153
Z variance train             0.021007728
KL Divergence                21.91859
KL Loss                      2.191859
QF Loss                      531.49695
VF Loss                      120.90107
Policy Loss                  -779.5021
Q Predictions Mean           773.59436
Q Predictions Std            286.46155
Q Predictions Max            1133.8395
Q Predictions Min            220.97748
V Predictions Mean           786.05707
V Predictions Std            281.35596
V Predictions Max            1149.4432
V Predictions Min            234.13954
Log Pis Mean                 -0.17853877
Log Pis Std                  3.4604363
Log Pis Max                  18.736485
Log Pis Min                  -10.934325
Policy mu Mean               -0.021103814
Policy mu Std                0.5886114
Policy mu Max                3.3126814
Policy mu Min                -4.747613
Policy log std Mean          -1.003055
Policy log std Std           0.22048515
Policy log std Max           -0.25547242
Policy log std Min           -1.9088387
Z mean eval                  1.1460905
Z variance eval              0.018091412
total_rewards                [2025.92646211  630.26619806 2361.3340113  3148.04023553 1181.00210876
  214.99475176  562.92368365 1477.04591492 3178.97905452 2845.18118355]
total_rewards_mean           1762.5693604150395
total_rewards_std            1051.7443545758815
total_rewards_max            3178.9790545191254
total_rewards_min            214.9947517595345
Number of train steps total  408000
Number of env steps total    330297
Number of rollouts total     0
Train Time (s)               145.16057990677655
(Previous) Eval Time (s)     20.37189507810399
Sample Time (s)              6.530568069778383
Epoch Time (s)               172.06304305465892
Total Train Time (s)         16849.45786704868
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:01:26.119977 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #101 | Epoch Duration: 172.16478300094604
2020-01-11 13:01:26.120110 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1405001
Z variance train             0.01820501
KL Divergence                22.138355
KL Loss                      2.2138355
QF Loss                      709.8332
VF Loss                      133.37119
Policy Loss                  -757.12476
Q Predictions Mean           747.2445
Q Predictions Std            304.28583
Q Predictions Max            1144.9956
Q Predictions Min            -4.924961
V Predictions Mean           761.14954
V Predictions Std            290.97586
V Predictions Max            1144.938
V Predictions Min            47.360855
Log Pis Mean                 -0.24369118
Log Pis Std                  3.1858442
Log Pis Max                  12.626875
Log Pis Min                  -9.76733
Policy mu Mean               -0.051606756
Policy mu Std                0.56956065
Policy mu Max                2.550212
Policy mu Min                -2.5201714
Policy log std Mean          -0.98977995
Policy log std Std           0.22588028
Policy log std Max           -0.42940855
Policy log std Min           -2.0093114
Z mean eval                  1.1619273
Z variance eval              0.046116155
total_rewards                [ 830.43358175 1196.76061442 1413.41595065 3016.26292126   16.50809203
  438.40379694 1280.26419892  288.77077574 1927.65799543 1008.14408534]
total_rewards_mean           1141.6622012469797
total_rewards_std            826.4787943106139
total_rewards_max            3016.2629212586544
total_rewards_min            16.50809202505524
Number of train steps total  412000
Number of env steps total    333166
Number of rollouts total     0
Train Time (s)               144.58454751130193
(Previous) Eval Time (s)     15.44269262906164
Sample Time (s)              8.581397536210716
Epoch Time (s)               168.6086376765743
Total Train Time (s)         17018.153917507734
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:04:14.817129 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #102 | Epoch Duration: 168.69692206382751
2020-01-11 13:04:14.817249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.158937
Z variance train             0.046702646
KL Divergence                21.461466
KL Loss                      2.1461465
QF Loss                      605.9132
VF Loss                      125.102325
Policy Loss                  -788.2413
Q Predictions Mean           775.64386
Q Predictions Std            290.7283
Q Predictions Max            1150.4915
Q Predictions Min            -47.808903
V Predictions Mean           791.24414
V Predictions Std            275.40735
V Predictions Max            1147.8689
V Predictions Min            181.15305
Log Pis Mean                 -0.093719505
Log Pis Std                  3.561202
Log Pis Max                  18.020082
Log Pis Min                  -6.6424947
Policy mu Mean               -0.043385252
Policy mu Std                0.61562765
Policy mu Max                3.8445044
Policy mu Min                -3.8493035
Policy log std Mean          -0.9850975
Policy log std Std           0.22398353
Policy log std Max           -0.44034627
Policy log std Min           -1.954793
Z mean eval                  1.093516
Z variance eval              0.024501178
total_rewards                [1955.23277736 2588.54866277  341.61805986 1068.53346151  595.58243997
   93.19103506 2234.63126934 3192.74230184 3008.19276865 1575.13926589]
total_rewards_mean           1665.3412042238033
total_rewards_std            1054.9523000342128
total_rewards_max            3192.742301835806
total_rewards_min            93.19103505574638
Number of train steps total  416000
Number of env steps total    335963
Number of rollouts total     0
Train Time (s)               145.69733853498474
(Previous) Eval Time (s)     18.00498979911208
Sample Time (s)              6.760023392736912
Epoch Time (s)               170.46235172683373
Total Train Time (s)         17188.70465751039
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:07:05.368555 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #103 | Epoch Duration: 170.55121421813965
2020-01-11 13:07:05.368682 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0948398
Z variance train             0.024547461
KL Divergence                22.4237
KL Loss                      2.2423701
QF Loss                      567.9689
VF Loss                      119.583374
Policy Loss                  -777.2063
Q Predictions Mean           768.7827
Q Predictions Std            289.64508
Q Predictions Max            1137.793
Q Predictions Min            -37.487392
V Predictions Mean           776.41705
V Predictions Std            280.53635
V Predictions Max            1129.8636
V Predictions Min            248.38048
Log Pis Mean                 -0.5215587
Log Pis Std                  3.0410347
Log Pis Max                  14.903803
Log Pis Min                  -9.107825
Policy mu Mean               0.00046239654
Policy mu Std                0.55645114
Policy mu Max                3.1373613
Policy mu Min                -2.1840882
Policy log std Mean          -0.9823598
Policy log std Std           0.21449608
Policy log std Max           -0.43117487
Policy log std Min           -1.9425483
Z mean eval                  1.1133336
Z variance eval              0.011859143
total_rewards                [1681.8424543  1105.47121507  556.41106065 1154.847507   3111.53200782
 1422.42333775  662.37869489 2811.6729443   925.55056714 1232.18549274]
total_rewards_mean           1466.431528165464
total_rewards_std            813.2531723120134
total_rewards_max            3111.532007820324
total_rewards_min            556.4110606544187
Number of train steps total  420000
Number of env steps total    339588
Number of rollouts total     0
Train Time (s)               146.08545700274408
(Previous) Eval Time (s)     18.629552795086056
Sample Time (s)              7.612528318539262
Epoch Time (s)               172.3275381163694
Total Train Time (s)         17361.11670349026
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:57.781707 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #104 | Epoch Duration: 172.41293597221375
2020-01-11 13:09:57.781833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #104 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1079347
Z variance train             0.0118673565
KL Divergence                22.759466
KL Loss                      2.2759466
QF Loss                      583.70074
VF Loss                      234.84769
Policy Loss                  -763.46
Q Predictions Mean           754.65735
Q Predictions Std            292.52438
Q Predictions Max            1127.5881
Q Predictions Min            14.086769
V Predictions Mean           770.3439
V Predictions Std            286.06714
V Predictions Max            1123.3588
V Predictions Min            82.5953
Log Pis Mean                 -0.4076208
Log Pis Std                  3.4565976
Log Pis Max                  17.129555
Log Pis Min                  -8.518882
Policy mu Mean               0.0023096288
Policy mu Std                0.56029576
Policy mu Max                3.868135
Policy mu Min                -2.9384136
Policy log std Mean          -0.97923774
Policy log std Std           0.21944983
Policy log std Max           -0.4104355
Policy log std Min           -1.8858435
Z mean eval                  1.0902888
Z variance eval              0.015230209
total_rewards                [281.36680639 370.00542064 268.01643439 729.07014447 622.34905031
 446.88260868 229.51411283 304.14782428 204.51546967 651.13037908]
total_rewards_mean           410.6998250744972
total_rewards_std            181.85331830944733
total_rewards_max            729.0701444704268
total_rewards_min            204.51546967258537
Number of train steps total  424000
Number of env steps total    342688
Number of rollouts total     0
Train Time (s)               145.19038172019646
(Previous) Eval Time (s)     6.6308051170781255
Sample Time (s)              8.526674808934331
Epoch Time (s)               160.3478616462089
Total Train Time (s)         17521.572602323256
Epoch                        105
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:38.240112 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #105 | Epoch Duration: 160.45818066596985
2020-01-11 13:12:38.240270 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.091731
Z variance train             0.0152480155
KL Divergence                22.108086
KL Loss                      2.2108085
QF Loss                      962.6921
VF Loss                      319.30505
Policy Loss                  -742.72955
Q Predictions Mean           733.3528
Q Predictions Std            297.1388
Q Predictions Max            1105.9468
Q Predictions Min            -50.126534
V Predictions Mean           750.77936
V Predictions Std            286.72168
V Predictions Max            1106.4374
V Predictions Min            223.31343
Log Pis Mean                 -0.11983769
Log Pis Std                  3.2451167
Log Pis Max                  13.55097
Log Pis Min                  -7.698344
Policy mu Mean               -0.03139042
Policy mu Std                0.57138175
Policy mu Max                2.9030232
Policy mu Min                -2.7540312
Policy log std Mean          -0.9834851
Policy log std Std           0.22277096
Policy log std Max           -0.41732872
Policy log std Min           -1.9762437
Z mean eval                  1.139682
Z variance eval              0.017588565
total_rewards                [ 554.5109127  1240.29252785 2111.92504271  849.35226961  339.18896132
 1734.21944634 1044.26154059 2436.69690435 1809.07181333 3318.884842  ]
total_rewards_mean           1543.8404260783377
total_rewards_std            873.5719539619129
total_rewards_max            3318.8848419972282
total_rewards_min            339.18896131567476
Number of train steps total  428000
Number of env steps total    345852
Number of rollouts total     0
Train Time (s)               146.15916937496513
(Previous) Eval Time (s)     15.702843122184277
Sample Time (s)              8.206489744130522
Epoch Time (s)               170.06850224127993
Total Train Time (s)         17691.732505166903
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:15:28.402897 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #106 | Epoch Duration: 170.1624994277954
2020-01-11 13:15:28.403070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1376431
Z variance train             0.017529521
KL Divergence                22.269829
KL Loss                      2.2269828
QF Loss                      707.5207
VF Loss                      116.84682
Policy Loss                  -784.10394
Q Predictions Mean           777.73096
Q Predictions Std            283.14798
Q Predictions Max            1126.3881
Q Predictions Min            -6.7757883
V Predictions Mean           787.70605
V Predictions Std            274.56662
V Predictions Max            1121.4684
V Predictions Min            146.53888
Log Pis Mean                 -0.3884652
Log Pis Std                  3.1416285
Log Pis Max                  16.878458
Log Pis Min                  -7.1797256
Policy mu Mean               0.004430514
Policy mu Std                0.5948968
Policy mu Max                3.108049
Policy mu Min                -2.2929935
Policy log std Mean          -0.9858088
Policy log std Std           0.21748239
Policy log std Max           -0.39260173
Policy log std Min           -1.9982555
Z mean eval                  1.110493
Z variance eval              0.015003353
total_rewards                [ 771.27427661 3171.82654543  976.73422696  669.82271994 1386.23800083
  297.84122888 1523.49884564 1003.88270597  369.22555306  336.59315975]
total_rewards_mean           1050.6937263071254
total_rewards_std            812.8507662619545
total_rewards_max            3171.826545431122
total_rewards_min            297.841228875394
Number of train steps total  432000
Number of env steps total    348305
Number of rollouts total     0
Train Time (s)               145.05629389500245
(Previous) Eval Time (s)     9.33940897276625
Sample Time (s)              6.942872306797653
Epoch Time (s)               161.33857517456636
Total Train Time (s)         17853.17759832507
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:18:09.848634 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #107 | Epoch Duration: 161.44544291496277
2020-01-11 13:18:09.848759 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1141436
Z variance train             0.014991343
KL Divergence                22.918182
KL Loss                      2.2918184
QF Loss                      557.9184
VF Loss                      104.85771
Policy Loss                  -777.14435
Q Predictions Mean           770.60657
Q Predictions Std            292.146
Q Predictions Max            1120.7074
Q Predictions Min            221.12077
V Predictions Mean           779.62994
V Predictions Std            289.98355
V Predictions Max            1125.089
V Predictions Min            241.22606
Log Pis Mean                 -0.2780812
Log Pis Std                  2.987207
Log Pis Max                  8.8146925
Log Pis Min                  -7.1192284
Policy mu Mean               -0.041338876
Policy mu Std                0.5548393
Policy mu Max                2.169575
Policy mu Min                -2.8656533
Policy log std Mean          -0.98298436
Policy log std Std           0.21430518
Policy log std Max           -0.4690602
Policy log std Min           -2.0710216
Z mean eval                  1.1347368
Z variance eval              0.01300587
total_rewards                [3358.63694515 3243.38978965 2978.02783484 2423.55026275 3249.76460213
 3099.76737293 2862.48454719 1073.34061715  254.71236961 2318.27042244]
total_rewards_mean           2486.1944763845104
total_rewards_std            984.1390712563355
total_rewards_max            3358.6369451543655
total_rewards_min            254.71236961134613
Number of train steps total  436000
Number of env steps total    351946
Number of rollouts total     0
Train Time (s)               143.3681975803338
(Previous) Eval Time (s)     22.00700111174956
Sample Time (s)              6.580912579316646
Epoch Time (s)               171.9561112714
Total Train Time (s)         18025.223663368262
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:21:01.898201 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #108 | Epoch Duration: 172.04932236671448
2020-01-11 13:21:01.898436 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1264746
Z variance train             0.012920347
KL Divergence                22.408194
KL Loss                      2.2408195
QF Loss                      664.35046
VF Loss                      130.03043
Policy Loss                  -789.0646
Q Predictions Mean           781.67914
Q Predictions Std            299.85587
Q Predictions Max            1177.6361
Q Predictions Min            220.8374
V Predictions Mean           792.731
V Predictions Std            295.84766
V Predictions Max            1182.3464
V Predictions Min            243.32999
Log Pis Mean                 -0.12940627
Log Pis Std                  3.1856086
Log Pis Max                  17.121582
Log Pis Min                  -9.211852
Policy mu Mean               0.0018686512
Policy mu Std                0.5743395
Policy mu Max                2.93911
Policy mu Min                -3.2671506
Policy log std Mean          -1.0146351
Policy log std Std           0.22208492
Policy log std Max           -0.5509609
Policy log std Min           -1.9729114
Z mean eval                  1.0632346
Z variance eval              0.06271459
total_rewards                [1419.79094407  176.68896762 2186.11792833  114.25418695 3282.41539171
 1250.32059803  309.53831837  610.35487117  637.90131921 1086.8675368 ]
total_rewards_mean           1107.4250062259362
total_rewards_std            947.0685331215664
total_rewards_max            3282.4153917103476
total_rewards_min            114.25418694830176
Number of train steps total  440000
Number of env steps total    354602
Number of rollouts total     0
Train Time (s)               147.16504768375307
(Previous) Eval Time (s)     8.912616008892655
Sample Time (s)              6.24251659354195
Epoch Time (s)               162.32018028618768
Total Train Time (s)         18187.644375630654
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:23:44.319382 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #109 | Epoch Duration: 162.4207899570465
2020-01-11 13:23:44.319508 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0650977
Z variance train             0.06351333
KL Divergence                19.299395
KL Loss                      1.9299395
QF Loss                      961.2118
VF Loss                      180.88171
Policy Loss                  -751.3659
Q Predictions Mean           744.553
Q Predictions Std            296.8538
Q Predictions Max            1149.7534
Q Predictions Min            1.8192642
V Predictions Mean           745.8214
V Predictions Std            288.94077
V Predictions Max            1142.0504
V Predictions Min            178.0063
Log Pis Mean                 -0.28806782
Log Pis Std                  3.393254
Log Pis Max                  26.303593
Log Pis Min                  -7.6877837
Policy mu Mean               -0.049852286
Policy mu Std                0.5645577
Policy mu Max                4.50384
Policy mu Min                -3.517124
Policy log std Mean          -1.001616
Policy log std Std           0.21574455
Policy log std Max           -0.40612137
Policy log std Min           -2.0201688
Z mean eval                  1.1123317
Z variance eval              0.042539693
total_rewards                [ 851.79268904   67.35586199  638.41863597  876.69348525 1830.79112419
 1364.31015282 1506.28598766  676.68070326 2890.44625121  611.92480544]
total_rewards_mean           1131.4699696838607
total_rewards_std            759.8077769461206
total_rewards_max            2890.4462512106684
total_rewards_min            67.35586198858807
Number of train steps total  444000
Number of env steps total    357321
Number of rollouts total     0
Train Time (s)               145.71812780061737
(Previous) Eval Time (s)     10.904018293134868
Sample Time (s)              7.836933283135295
Epoch Time (s)               164.45907937688753
Total Train Time (s)         18352.209876586217
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:26:28.887126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #110 | Epoch Duration: 164.56750893592834
2020-01-11 13:26:28.887296 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1142796
Z variance train             0.04244256
KL Divergence                19.936144
KL Loss                      1.9936144
QF Loss                      610.2262
VF Loss                      149.24849
Policy Loss                  -803.8073
Q Predictions Mean           799.4297
Q Predictions Std            309.98456
Q Predictions Max            1206.3232
Q Predictions Min            220.98717
V Predictions Mean           803.2378
V Predictions Std            308.94016
V Predictions Max            1216.9696
V Predictions Min            218.17996
Log Pis Mean                 -0.6016295
Log Pis Std                  2.8040755
Log Pis Max                  7.461034
Log Pis Min                  -7.844962
Policy mu Mean               -0.027157415
Policy mu Std                0.5314222
Policy mu Max                2.9167614
Policy mu Min                -2.0892131
Policy log std Mean          -0.9979858
Policy log std Std           0.23374864
Policy log std Max           -0.24660176
Policy log std Min           -2.231967
Z mean eval                  1.0962559
Z variance eval              0.068515584
total_rewards                [3127.24339342  600.10851231 1038.48258076   37.6174002  1458.20659268
  493.44647622  313.02959449  215.991175    413.33260323 2936.72091858]
total_rewards_mean           1063.4179246890267
total_rewards_std            1059.2797073051606
total_rewards_max            3127.2433934154365
total_rewards_min            37.61740020066902
Number of train steps total  448000
Number of env steps total    359640
Number of rollouts total     0
Train Time (s)               148.03547236230224
(Previous) Eval Time (s)     10.237329179886729
Sample Time (s)              7.173160215839744
Epoch Time (s)               165.44596175802872
Total Train Time (s)         18517.74702981161
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:29:14.425501 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #111 | Epoch Duration: 165.53805875778198
2020-01-11 13:29:14.425690 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1007845
Z variance train             0.06738579
KL Divergence                20.55057
KL Loss                      2.055057
QF Loss                      844.05554
VF Loss                      152.93173
Policy Loss                  -826.0296
Q Predictions Mean           812.8591
Q Predictions Std            299.61008
Q Predictions Max            1170.5828
Q Predictions Min            -54.481926
V Predictions Mean           821.66907
V Predictions Std            285.50525
V Predictions Max            1162.0289
V Predictions Min            8.166493
Log Pis Mean                 0.0015540197
Log Pis Std                  3.5131993
Log Pis Max                  18.864506
Log Pis Min                  -8.552836
Policy mu Mean               -0.031143097
Policy mu Std                0.6017298
Policy mu Max                3.779499
Policy mu Min                -3.665219
Policy log std Mean          -0.9972335
Policy log std Std           0.24193016
Policy log std Max           -0.2684976
Policy log std Min           -2.091721
Z mean eval                  1.1575718
Z variance eval              0.14074609
total_rewards                [2807.51707773  153.83197055  345.13563274  815.69711946   88.32394371
 1597.74416934 3118.54812305 1958.34781443  598.90683725 1357.65780305]
total_rewards_mean           1284.1710491319832
total_rewards_std            1025.7838074351826
total_rewards_max            3118.548123052793
total_rewards_min            88.32394371210445
Number of train steps total  452000
Number of env steps total    362101
Number of rollouts total     0
Train Time (s)               145.8675218471326
(Previous) Eval Time (s)     12.04956129193306
Sample Time (s)              7.221450561191887
Epoch Time (s)               165.13853370025754
Total Train Time (s)         18682.996818778105
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:31:59.677783 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #112 | Epoch Duration: 165.25193977355957
2020-01-11 13:31:59.678003 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #112 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.158783
Z variance train             0.14072946
KL Divergence                19.506124
KL Loss                      1.9506124
QF Loss                      637.75977
VF Loss                      82.26194
Policy Loss                  -847.2464
Q Predictions Mean           838.91724
Q Predictions Std            280.86154
Q Predictions Max            1212.4432
Q Predictions Min            214.18076
V Predictions Mean           844.8906
V Predictions Std            277.86703
V Predictions Max            1203.4551
V Predictions Min            241.79773
Log Pis Mean                 -0.21704742
Log Pis Std                  2.7732646
Log Pis Max                  7.299719
Log Pis Min                  -9.178445
Policy mu Mean               -0.016332876
Policy mu Std                0.568777
Policy mu Max                2.410482
Policy mu Min                -2.2627478
Policy log std Mean          -0.97884774
Policy log std Std           0.2239548
Policy log std Max           -0.3464225
Policy log std Min           -2.1338074
Z mean eval                  1.0762233
Z variance eval              0.04188323
total_rewards                [ 280.70772731 3152.00213053 1178.35152769 2985.4713831  1149.730792
 3182.00149219 2922.57228139   53.09297738 1341.20500724 3133.29243409]
total_rewards_mean           1937.8427752920004
total_rewards_std            1198.779966765256
total_rewards_max            3182.0014921908696
total_rewards_min            53.09297738480873
Number of train steps total  456000
Number of env steps total    364976
Number of rollouts total     0
Train Time (s)               147.0285026789643
(Previous) Eval Time (s)     18.32986605213955
Sample Time (s)              7.296320957131684
Epoch Time (s)               172.65468968823552
Total Train Time (s)         18855.742109728046
Epoch                        113
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:34:52.423708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #113 | Epoch Duration: 172.74556303024292
2020-01-11 13:34:52.423841 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0741285
Z variance train             0.041281085
KL Divergence                19.655607
KL Loss                      1.9655608
QF Loss                      1252.2927
VF Loss                      141.26262
Policy Loss                  -833.6307
Q Predictions Mean           823.9245
Q Predictions Std            325.68436
Q Predictions Max            1221.3701
Q Predictions Min            -16.45568
V Predictions Mean           828.15424
V Predictions Std            316.39224
V Predictions Max            1209.888
V Predictions Min            64.496025
Log Pis Mean                 0.026444271
Log Pis Std                  3.2785823
Log Pis Max                  24.56185
Log Pis Min                  -7.563376
Policy mu Mean               -0.050203897
Policy mu Std                0.59129006
Policy mu Max                3.6517045
Policy mu Min                -2.9535682
Policy log std Mean          -1.0252507
Policy log std Std           0.2352871
Policy log std Max           -0.30474758
Policy log std Min           -2.119114
Z mean eval                  1.1181791
Z variance eval              0.07384904
total_rewards                [3302.66407892  252.81865491 3247.90314111 2040.77039573 2508.31257012
  195.20332217 3063.16212959 2303.12298299 3005.10866679  909.86464443]
total_rewards_mean           2082.893058676354
total_rewards_std            1147.880513708567
total_rewards_max            3302.6640789234484
total_rewards_min            195.20332216799778
Number of train steps total  460000
Number of env steps total    368224
Number of rollouts total     0
Train Time (s)               143.07454365910962
(Previous) Eval Time (s)     16.752303816378117
Sample Time (s)              7.17329386388883
Epoch Time (s)               167.00014133937657
Total Train Time (s)         19022.83209104603
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:37:39.515362 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #114 | Epoch Duration: 167.09140944480896
2020-01-11 13:37:39.515559 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1198484
Z variance train             0.07357232
KL Divergence                18.869167
KL Loss                      1.8869168
QF Loss                      721.9949
VF Loss                      338.5764
Policy Loss                  -820.83325
Q Predictions Mean           811.26013
Q Predictions Std            319.23022
Q Predictions Max            1228.756
Q Predictions Min            28.432516
V Predictions Mean           816.7013
V Predictions Std            309.85477
V Predictions Max            1196.1532
V Predictions Min            106.95497
Log Pis Mean                 0.0705123
Log Pis Std                  3.5994918
Log Pis Max                  25.379889
Log Pis Min                  -8.950703
Policy mu Mean               -0.0037961444
Policy mu Std                0.5961969
Policy mu Max                3.7860563
Policy mu Min                -3.6053324
Policy log std Mean          -1.0151339
Policy log std Std           0.2359282
Policy log std Max           -0.35711545
Policy log std Min           -2.0203762
Z mean eval                  1.0442896
Z variance eval              0.033058953
total_rewards                [ 378.37100212  944.174279    999.17839212 3213.44305158  684.58483088
   72.51001301  603.22171442 3345.85031713  956.19110149 3313.25613965]
total_rewards_mean           1451.078084140583
total_rewards_std            1233.9935117437997
total_rewards_max            3345.850317133366
total_rewards_min            72.51001300757778
Number of train steps total  464000
Number of env steps total    370797
Number of rollouts total     0
Train Time (s)               141.6773382802494
(Previous) Eval Time (s)     12.781843268312514
Sample Time (s)              6.528920614160597
Epoch Time (s)               160.9881021627225
Total Train Time (s)         19183.901787471958
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:40:20.585663 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #115 | Epoch Duration: 161.06996965408325
2020-01-11 13:40:20.585788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0454704
Z variance train             0.033035774
KL Divergence                21.396027
KL Loss                      2.1396027
QF Loss                      963.95044
VF Loss                      225.24586
Policy Loss                  -813.3948
Q Predictions Mean           800.2603
Q Predictions Std            333.2494
Q Predictions Max            1195.6041
Q Predictions Min            -15.766907
V Predictions Mean           815.8063
V Predictions Std            322.7096
V Predictions Max            1201.5968
V Predictions Min            11.40728
Log Pis Mean                 0.33205962
Log Pis Std                  4.3462234
Log Pis Max                  40.76696
Log Pis Min                  -6.420763
Policy mu Mean               -0.07857177
Policy mu Std                0.65163046
Policy mu Max                4.1485887
Policy mu Min                -5.110573
Policy log std Mean          -0.99122614
Policy log std Std           0.2431058
Policy log std Max           0.5428557
Policy log std Min           -2.0877612
Z mean eval                  1.1838945
Z variance eval              0.11544298
total_rewards                [1445.60035308   39.29605364  186.83197526 1949.20775481 2008.26616561
  682.17361656  106.36151959   33.08511209   43.52855991  841.1785322 ]
total_rewards_mean           733.5529642751753
total_rewards_std            759.2759311487102
total_rewards_max            2008.2661656085897
total_rewards_min            33.08511209022925
Number of train steps total  468000
Number of env steps total    374365
Number of rollouts total     0
Train Time (s)               146.26029290491715
(Previous) Eval Time (s)     7.909762565046549
Sample Time (s)              6.757122308481485
Epoch Time (s)               160.92717777844518
Total Train Time (s)         19345.036679753568
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:43:01.722412 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #116 | Epoch Duration: 161.13653349876404
2020-01-11 13:43:01.722543 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1836476
Z variance train             0.11543697
KL Divergence                16.526268
KL Loss                      1.6526269
QF Loss                      739.63367
VF Loss                      197.33356
Policy Loss                  -806.0248
Q Predictions Mean           797.91345
Q Predictions Std            302.04163
Q Predictions Max            1134.0165
Q Predictions Min            0.45107245
V Predictions Mean           808.6334
V Predictions Std            292.07043
V Predictions Max            1146.9442
V Predictions Min            1.6439189
Log Pis Mean                 0.13778126
Log Pis Std                  3.5950212
Log Pis Max                  20.444538
Log Pis Min                  -7.1859617
Policy mu Mean               -0.036690447
Policy mu Std                0.6340593
Policy mu Max                4.841943
Policy mu Min                -3.0908892
Policy log std Mean          -1.0199001
Policy log std Std           0.21961606
Policy log std Max           -0.2550336
Policy log std Min           -2.096149
Z mean eval                  1.1245385
Z variance eval              0.018563803
total_rewards                [  90.87363243 1453.27185427  915.24731646  921.5523142   154.01014529
  166.38119978  234.86799941 1686.51649763   47.48567448   88.12179672]
total_rewards_mean           575.8328430661766
total_rewards_std            587.5612162812413
total_rewards_max            1686.516497625463
total_rewards_min            47.48567447743983
Number of train steps total  472000
Number of env steps total    378066
Number of rollouts total     0
Train Time (s)               146.6417863056995
(Previous) Eval Time (s)     7.572695892769843
Sample Time (s)              7.856334446929395
Epoch Time (s)               162.07081664539874
Total Train Time (s)         19507.19564145012
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:45:43.883471 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #117 | Epoch Duration: 162.16083240509033
2020-01-11 13:45:43.883597 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1161608
Z variance train             0.018682083
KL Divergence                21.170584
KL Loss                      2.1170585
QF Loss                      631.997
VF Loss                      100.81501
Policy Loss                  -820.82733
Q Predictions Mean           811.5981
Q Predictions Std            338.28787
Q Predictions Max            1223.0144
Q Predictions Min            89.52324
V Predictions Mean           821.6017
V Predictions Std            331.02716
V Predictions Max            1217.3214
V Predictions Min            236.9435
Log Pis Mean                 -0.36658764
Log Pis Std                  3.2789197
Log Pis Max                  20.478273
Log Pis Min                  -7.2418337
Policy mu Mean               -0.037219778
Policy mu Std                0.5633698
Policy mu Max                2.3155446
Policy mu Min                -3.43215
Policy log std Mean          -1.0098674
Policy log std Std           0.23458035
Policy log std Max           -0.36171085
Policy log std Min           -2.0146773
Z mean eval                  1.1269295
Z variance eval              0.045056604
total_rewards                [ 418.12697821  569.61335828 3509.86384287 2047.39513922  389.88038805
 2241.3259082  2615.76492054 2626.71590306  201.17810891 1677.30143501]
total_rewards_mean           1629.7165982334432
total_rewards_std            1105.5189970260021
total_rewards_max            3509.8638428677136
total_rewards_min            201.178108910236
Number of train steps total  476000
Number of env steps total    381133
Number of rollouts total     0
Train Time (s)               148.08551617199555
(Previous) Eval Time (s)     15.43709101807326
Sample Time (s)              8.425990176387131
Epoch Time (s)               171.94859736645594
Total Train Time (s)         19679.233782000374
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:48:35.923816 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #118 | Epoch Duration: 172.04010939598083
2020-01-11 13:48:35.924004 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1255352
Z variance train             0.044527154
KL Divergence                19.97147
KL Loss                      1.997147
QF Loss                      961.1246
VF Loss                      140.99274
Policy Loss                  -824.7287
Q Predictions Mean           816.0887
Q Predictions Std            323.89294
Q Predictions Max            1228.2504
Q Predictions Min            -9.066875
V Predictions Mean           830.28564
V Predictions Std            315.58185
V Predictions Max            1236.063
V Predictions Min            36.513317
Log Pis Mean                 -0.082919054
Log Pis Std                  2.9893496
Log Pis Max                  13.495417
Log Pis Min                  -8.093379
Policy mu Mean               -0.05219421
Policy mu Std                0.5883811
Policy mu Max                3.2934983
Policy mu Min                -2.9620202
Policy log std Mean          -1.0108323
Policy log std Std           0.23395935
Policy log std Max           -0.3945098
Policy log std Min           -2.0635436
Z mean eval                  1.1407721
Z variance eval              0.03402751
total_rewards                [3022.44133035 3315.6875213  1063.75965077 2841.36549823 3466.56074803
  225.52488901 3307.25621277 2780.87100139  720.65114016 3461.96743468]
total_rewards_mean           2420.6085426688114
total_rewards_std            1182.5425708307143
total_rewards_max            3466.5607480325634
total_rewards_min            225.52488901075733
Number of train steps total  480000
Number of env steps total    383581
Number of rollouts total     0
Train Time (s)               143.96217261906713
(Previous) Eval Time (s)     17.594236228149384
Sample Time (s)              7.128209902439266
Epoch Time (s)               168.68461874965578
Total Train Time (s)         19848.007953466382
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:51:24.700049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #119 | Epoch Duration: 168.7758994102478
2020-01-11 13:51:24.700238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1414484
Z variance train             0.033783328
KL Divergence                20.968521
KL Loss                      2.096852
QF Loss                      674.90845
VF Loss                      269.1487
Policy Loss                  -835.93414
Q Predictions Mean           827.09
Q Predictions Std            328.4201
Q Predictions Max            1223.7393
Q Predictions Min            -70.054184
V Predictions Mean           839.1009
V Predictions Std            316.07312
V Predictions Max            1213.3926
V Predictions Min            -9.112022
Log Pis Mean                 0.080501616
Log Pis Std                  3.5346432
Log Pis Max                  16.457699
Log Pis Min                  -9.18711
Policy mu Mean               -0.037563752
Policy mu Std                0.60551316
Policy mu Max                3.1944165
Policy mu Min                -3.0272055
Policy log std Mean          -1.0317193
Policy log std Std           0.23860542
Policy log std Max           -0.3922584
Policy log std Min           -2.154937
Z mean eval                  1.073251
Z variance eval              0.08129396
total_rewards                [ 948.75777529 1975.54616889 1159.23416239 1154.34027354  647.47727687
 1182.66854261   32.88483324  741.85757973 3154.61927747  908.25503491]
total_rewards_mean           1190.5640924917866
total_rewards_std            803.1647707301994
total_rewards_max            3154.6192774672254
total_rewards_min            32.884833240432414
Number of train steps total  484000
Number of env steps total    387606
Number of rollouts total     0
Train Time (s)               145.57640478527173
(Previous) Eval Time (s)     14.121134355664253
Sample Time (s)              7.623146479483694
Epoch Time (s)               167.32068562041968
Total Train Time (s)         20015.428012644872
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:54:12.123215 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #120 | Epoch Duration: 167.42281866073608
2020-01-11 13:54:12.123443 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0729069
Z variance train             0.08321177
KL Divergence                18.108816
KL Loss                      1.8108816
QF Loss                      622.85474
VF Loss                      125.369934
Policy Loss                  -813.2151
Q Predictions Mean           803.41187
Q Predictions Std            342.64877
Q Predictions Max            1248.558
Q Predictions Min            13.806763
V Predictions Mean           812.66315
V Predictions Std            336.6271
V Predictions Max            1233.1544
V Predictions Min            127.03731
Log Pis Mean                 -0.50808537
Log Pis Std                  2.9543962
Log Pis Max                  16.454388
Log Pis Min                  -6.6806297
Policy mu Mean               -0.02732036
Policy mu Std                0.55815727
Policy mu Max                2.9628725
Policy mu Min                -3.5620418
Policy log std Mean          -0.9801627
Policy log std Std           0.24365301
Policy log std Max           -0.361912
Policy log std Min           -2.057205
Z mean eval                  1.1151317
Z variance eval              0.07894797
total_rewards                [  95.05907767  304.36376553 1004.34782865  408.00152174  122.83969639
  324.18712049  552.55924388  237.70898025 1425.28607119  122.64061242]
total_rewards_mean           459.6993918204582
total_rewards_std            411.35304620137873
total_rewards_max            1425.2860711857527
total_rewards_min            95.05907766633435
Number of train steps total  488000
Number of env steps total    390362
Number of rollouts total     0
Train Time (s)               146.9989463458769
(Previous) Eval Time (s)     5.262980828993022
Sample Time (s)              7.287724058609456
Epoch Time (s)               159.54965123347938
Total Train Time (s)         20175.060307309963
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:56:51.755923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #121 | Epoch Duration: 159.63232851028442
2020-01-11 13:56:51.756039 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1164219
Z variance train             0.07937355
KL Divergence                19.895033
KL Loss                      1.9895033
QF Loss                      1739.0184
VF Loss                      817.15173
Policy Loss                  -867.585
Q Predictions Mean           855.7332
Q Predictions Std            307.49927
Q Predictions Max            1195.5583
Q Predictions Min            -46.832607
V Predictions Mean           871.5763
V Predictions Std            290.7815
V Predictions Max            1208.6183
V Predictions Min            230.05244
Log Pis Mean                 0.22975066
Log Pis Std                  3.5394566
Log Pis Max                  26.38594
Log Pis Min                  -6.684619
Policy mu Mean               -0.01918881
Policy mu Std                0.63364106
Policy mu Max                5.2851453
Policy mu Min                -3.029637
Policy log std Mean          -1.0065385
Policy log std Std           0.2314687
Policy log std Max           -0.27995956
Policy log std Min           -2.029803
Z mean eval                  1.0668194
Z variance eval              0.06783622
total_rewards                [1062.4289356  3110.21477301 2843.24413694  479.11089403 2609.98981695
 2415.3548893  3435.23203237 1709.81343258 2333.79040645 1597.98224855]
total_rewards_mean           2159.716156577548
total_rewards_std            885.5748970484575
total_rewards_max            3435.2320323683516
total_rewards_min            479.1108940342131
Number of train steps total  492000
Number of env steps total    394833
Number of rollouts total     0
Train Time (s)               142.38532737083733
(Previous) Eval Time (s)     15.179499710910022
Sample Time (s)              7.757077507209033
Epoch Time (s)               165.3219045889564
Total Train Time (s)         20340.472923115827
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:59:37.170297 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #122 | Epoch Duration: 165.4141561985016
2020-01-11 13:59:37.170443 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0687381
Z variance train             0.06789068
KL Divergence                19.962328
KL Loss                      1.9962329
QF Loss                      780.50134
VF Loss                      151.10512
Policy Loss                  -838.8378
Q Predictions Mean           832.03564
Q Predictions Std            299.65268
Q Predictions Max            1255.4753
Q Predictions Min            192.06326
V Predictions Mean           837.8924
V Predictions Std            296.25873
V Predictions Max            1254.7958
V Predictions Min            210.14857
Log Pis Mean                 -0.33246604
Log Pis Std                  2.8451211
Log Pis Max                  8.859657
Log Pis Min                  -9.632336
Policy mu Mean               -0.027677616
Policy mu Std                0.5703828
Policy mu Max                3.069685
Policy mu Min                -2.2959135
Policy log std Mean          -1.0018702
Policy log std Std           0.22564302
Policy log std Max           -0.37963527
Policy log std Min           -2.0936427
Z mean eval                  1.0758301
Z variance eval              0.013690069
total_rewards                [ 745.06422212  562.1530725   396.6985867  1676.47923939  723.64487368
  917.87486913  292.97391306  674.25227049 3139.11434179 1382.39964682]
total_rewards_mean           1051.065503566854
total_rewards_std            803.9512363226831
total_rewards_max            3139.114341790775
total_rewards_min            292.97391305509984
Number of train steps total  496000
Number of env steps total    397812
Number of rollouts total     0
Train Time (s)               141.68216640595347
(Previous) Eval Time (s)     13.908801851328462
Sample Time (s)              6.272847313899547
Epoch Time (s)               161.86381557118148
Total Train Time (s)         20502.4324790556
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:02:19.134277 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #123 | Epoch Duration: 161.96368312835693
2020-01-11 14:02:19.134549 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0776877
Z variance train             0.013558948
KL Divergence                21.948557
KL Loss                      2.1948557
QF Loss                      526.6697
VF Loss                      181.41837
Policy Loss                  -870.15265
Q Predictions Mean           860.02844
Q Predictions Std            314.50595
Q Predictions Max            1249.628
Q Predictions Min            54.064102
V Predictions Mean           861.9092
V Predictions Std            305.2905
V Predictions Max            1242.7592
V Predictions Min            140.40706
Log Pis Mean                 0.1633041
Log Pis Std                  3.2445288
Log Pis Max                  20.158995
Log Pis Min                  -6.945198
Policy mu Mean               -0.052530028
Policy mu Std                0.59556067
Policy mu Max                3.304717
Policy mu Min                -5.0930104
Policy log std Mean          -1.0092196
Policy log std Std           0.23429951
Policy log std Max           0.17273712
Policy log std Min           -2.1596394
Z mean eval                  1.1172683
Z variance eval              0.005452371
total_rewards                [ 199.23687495 2044.4564507  1030.8642635   400.50180825 2345.48077404
 1937.4339349   470.46960153   93.15398055  448.53792064 3368.1313813 ]
total_rewards_mean           1233.8266990371849
total_rewards_std            1060.6480093922505
total_rewards_max            3368.131381302079
total_rewards_min            93.153980552311
Number of train steps total  500000
Number of env steps total    401576
Number of rollouts total     0
Train Time (s)               141.56611986504868
(Previous) Eval Time (s)     10.903188199736178
Sample Time (s)              8.790943944826722
Epoch Time (s)               161.26025200961158
Total Train Time (s)         20663.78482319927
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:05:00.487284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #124 | Epoch Duration: 161.3525276184082
2020-01-11 14:05:00.487445 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1234288
Z variance train             0.0054776818
KL Divergence                23.82344
KL Loss                      2.382344
QF Loss                      592.87335
VF Loss                      185.36624
Policy Loss                  -815.0253
Q Predictions Mean           807.81744
Q Predictions Std            339.89758
Q Predictions Max            1226.7172
Q Predictions Min            141.98631
V Predictions Mean           811.1035
V Predictions Std            332.39633
V Predictions Max            1240.802
V Predictions Min            223.99103
Log Pis Mean                 -0.29569286
Log Pis Std                  3.5434873
Log Pis Max                  15.566323
Log Pis Min                  -11.048065
Policy mu Mean               -0.019165408
Policy mu Std                0.58340156
Policy mu Max                3.642837
Policy mu Min                -3.1660674
Policy log std Mean          -0.98768014
Policy log std Std           0.23030724
Policy log std Max           -0.39219725
Policy log std Min           -1.9991261
Z mean eval                  1.1286275
Z variance eval              0.03337378
total_rewards                [3389.50803439 3223.08325221 3251.76315809 3255.6466846  1579.38466108
 1116.04242847  100.22307189 3442.62974125 3385.95453816 1324.2836272 ]
total_rewards_mean           2406.8519197353803
total_rewards_std            1180.7215493444228
total_rewards_max            3442.6297412525537
total_rewards_min            100.22307189448901
Number of train steps total  504000
Number of env steps total    406760
Number of rollouts total     0
Train Time (s)               141.57846467290074
(Previous) Eval Time (s)     20.53754178620875
Sample Time (s)              7.892120137810707
Epoch Time (s)               170.0081265969202
Total Train Time (s)         20833.88947608741
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:07:50.593683 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #125 | Epoch Duration: 170.1061224937439
2020-01-11 14:07:50.593818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1343482
Z variance train             0.03309967
KL Divergence                20.82796
KL Loss                      2.0827959
QF Loss                      1293.2831
VF Loss                      315.43384
Policy Loss                  -794.3268
Q Predictions Mean           777.11505
Q Predictions Std            344.44034
Q Predictions Max            1243.9003
Q Predictions Min            -73.12148
V Predictions Mean           787.2961
V Predictions Std            331.43433
V Predictions Max            1237.9344
V Predictions Min            195.86707
Log Pis Mean                 0.091752306
Log Pis Std                  4.0602145
Log Pis Max                  24.249468
Log Pis Min                  -8.326549
Policy mu Mean               -0.030843586
Policy mu Std                0.62442404
Policy mu Max                4.030943
Policy mu Min                -3.6184187
Policy log std Mean          -1.017266
Policy log std Std           0.24892078
Policy log std Max           -0.25348228
Policy log std Min           -2.041908
Z mean eval                  1.0908227
Z variance eval              0.026469136
total_rewards                [2881.82594563  367.23496856  437.7637035  1113.76701859 2686.06139704
 1080.50095047  831.77489446  484.55502193  937.41036091  844.84128005]
total_rewards_mean           1166.5735541137647
total_rewards_std            846.4339261526014
total_rewards_max            2881.8259456258693
total_rewards_min            367.2349685635653
Number of train steps total  508000
Number of env steps total    410369
Number of rollouts total     0
Train Time (s)               146.25517910905182
(Previous) Eval Time (s)     11.88207471370697
Sample Time (s)              7.805329885799438
Epoch Time (s)               165.94258370855823
Total Train Time (s)         20999.92428031098
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:10:36.632901 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #126 | Epoch Duration: 166.0389473438263
2020-01-11 14:10:36.633176 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0813372
Z variance train             0.026165292
KL Divergence                19.6892
KL Loss                      1.96892
QF Loss                      1157.0641
VF Loss                      173.28865
Policy Loss                  -789.77264
Q Predictions Mean           783.16516
Q Predictions Std            328.70947
Q Predictions Max            1179.7234
Q Predictions Min            -38.91089
V Predictions Mean           790.4538
V Predictions Std            318.53275
V Predictions Max            1159.3179
V Predictions Min            -37.14457
Log Pis Mean                 -0.06526449
Log Pis Std                  3.5771663
Log Pis Max                  20.494984
Log Pis Min                  -7.79768
Policy mu Mean               0.013158861
Policy mu Std                0.59883004
Policy mu Max                4.5700884
Policy mu Min                -3.1050038
Policy log std Mean          -0.9998583
Policy log std Std           0.24548647
Policy log std Max           0.34089857
Policy log std Min           -2.6329975
Z mean eval                  1.1001133
Z variance eval              0.016725104
total_rewards                [2064.22298533  898.05903052 2811.0237179  2730.2760605   981.11036125
 3471.4722609  1392.4444691  1796.36980155  730.50913557  908.73957448]
total_rewards_mean           1778.4227397106292
total_rewards_std            912.9571910751017
total_rewards_max            3471.4722608963207
total_rewards_min            730.5091355706089
Number of train steps total  512000
Number of env steps total    413375
Number of rollouts total     0
Train Time (s)               145.3437726777047
(Previous) Eval Time (s)     14.281360452994704
Sample Time (s)              7.498569758143276
Epoch Time (s)               167.12370288884267
Total Train Time (s)         21167.1366983708
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:13:23.849153 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #127 | Epoch Duration: 167.21573114395142
2020-01-11 14:13:23.849458 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1040696
Z variance train             0.016855802
KL Divergence                21.470917
KL Loss                      2.1470916
QF Loss                      597.85693
VF Loss                      153.17017
Policy Loss                  -858.3332
Q Predictions Mean           848.6322
Q Predictions Std            347.30148
Q Predictions Max            1282.9957
Q Predictions Min            141.9191
V Predictions Mean           855.1798
V Predictions Std            340.4017
V Predictions Max            1278.3547
V Predictions Min            219.75023
Log Pis Mean                 -0.45116556
Log Pis Std                  3.7103148
Log Pis Max                  25.217896
Log Pis Min                  -10.852577
Policy mu Mean               -0.023640484
Policy mu Std                0.58197767
Policy mu Max                3.2036648
Policy mu Min                -4.715603
Policy log std Mean          -0.9739098
Policy log std Std           0.21859767
Policy log std Max           0.31138772
Policy log std Min           -2.225585
Z mean eval                  1.0820506
Z variance eval              0.025259316
total_rewards                [1245.69273832 1087.04855869  396.41342996  369.3050671   887.52492361
 1599.27448504 2414.90008269 1203.78380222  666.94594754 1576.7190237 ]
total_rewards_mean           1144.7608058870908
total_rewards_std            589.8524203038211
total_rewards_max            2414.900082692143
total_rewards_min            369.30506709680475
Number of train steps total  516000
Number of env steps total    416318
Number of rollouts total     0
Train Time (s)               146.88669124199077
(Previous) Eval Time (s)     10.444965403992683
Sample Time (s)              7.636857091449201
Epoch Time (s)               164.96851373743266
Total Train Time (s)         21332.236562591046
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:16:08.949937 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #128 | Epoch Duration: 165.10025215148926
2020-01-11 14:16:08.950142 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0776064
Z variance train             0.024712436
KL Divergence                19.517609
KL Loss                      1.9517609
QF Loss                      678.0153
VF Loss                      193.41063
Policy Loss                  -900.3369
Q Predictions Mean           891.86255
Q Predictions Std            319.9502
Q Predictions Max            1286.3334
Q Predictions Min            7.05492
V Predictions Mean           904.7825
V Predictions Std            313.1095
V Predictions Max            1292.741
V Predictions Min            49.306725
Log Pis Mean                 0.17039037
Log Pis Std                  3.5723462
Log Pis Max                  23.16174
Log Pis Min                  -7.651815
Policy mu Mean               -0.05691508
Policy mu Std                0.6162176
Policy mu Max                2.931805
Policy mu Min                -4.672957
Policy log std Mean          -1.009324
Policy log std Std           0.23739582
Policy log std Max           -0.4240585
Policy log std Min           -1.910285
Z mean eval                  1.0714653
Z variance eval              0.14678575
total_rewards                [2375.98563386 3756.06986483 3504.96890307 3260.60717511  677.53386435
 3236.47640574 3502.09975195 3554.58429978  631.86677526 3411.76366214]
total_rewards_mean           2791.1956336098206
total_rewards_std            1124.054930151527
total_rewards_max            3756.0698648322173
total_rewards_min            631.8667752589856
Number of train steps total  520000
Number of env steps total    420568
Number of rollouts total     0
Train Time (s)               146.40001259371638
(Previous) Eval Time (s)     17.767003450077027
Sample Time (s)              7.867765381932259
Epoch Time (s)               172.03478142572567
Total Train Time (s)         21504.381118422374
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:19:01.096352 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #129 | Epoch Duration: 172.14608216285706
2020-01-11 14:19:01.096488 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0666239
Z variance train             0.15018626
KL Divergence                16.946447
KL Loss                      1.6946448
QF Loss                      679.66455
VF Loss                      171.99585
Policy Loss                  -835.7912
Q Predictions Mean           826.294
Q Predictions Std            338.62723
Q Predictions Max            1296.3553
Q Predictions Min            21.108036
V Predictions Mean           842.82263
V Predictions Std            333.77036
V Predictions Max            1312.9705
V Predictions Min            61.202763
Log Pis Mean                 0.06381159
Log Pis Std                  3.4712336
Log Pis Max                  20.024662
Log Pis Min                  -9.646436
Policy mu Mean               -0.047872446
Policy mu Std                0.584355
Policy mu Max                2.972582
Policy mu Min                -2.9875093
Policy log std Mean          -1.0387838
Policy log std Std           0.24858528
Policy log std Max           0.2701428
Policy log std Min           -2.2064247
Z mean eval                  1.0743665
Z variance eval              0.012171233
total_rewards                [ 629.0461543   779.72071841 1995.64588918  958.55563393  188.25165941
  471.48056725 3410.13607095 1726.90563395 1579.03817247 1391.96226017]
total_rewards_mean           1313.0742760021462
total_rewards_std            892.3753989047267
total_rewards_max            3410.1360709505775
total_rewards_min            188.25165941399098
Number of train steps total  524000
Number of env steps total    425308
Number of rollouts total     0
Train Time (s)               146.02981862379238
(Previous) Eval Time (s)     14.004479744005948
Sample Time (s)              6.561221217736602
Epoch Time (s)               166.59551958553493
Total Train Time (s)         21671.067384866998
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:21:47.784174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #130 | Epoch Duration: 166.68756866455078
2020-01-11 14:21:47.784383 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.077776
Z variance train             0.012172719
KL Divergence                21.336037
KL Loss                      2.1336038
QF Loss                      1052.099
VF Loss                      275.60248
Policy Loss                  -857.43054
Q Predictions Mean           842.61414
Q Predictions Std            350.59988
Q Predictions Max            1287.0796
Q Predictions Min            -15.393713
V Predictions Mean           854.20215
V Predictions Std            336.51498
V Predictions Max            1273.8948
V Predictions Min            204.07817
Log Pis Mean                 -0.19452944
Log Pis Std                  3.6349907
Log Pis Max                  25.832031
Log Pis Min                  -7.9219065
Policy mu Mean               -0.061457943
Policy mu Std                0.6147943
Policy mu Max                3.9347124
Policy mu Min                -3.4646914
Policy log std Mean          -0.9988153
Policy log std Std           0.247062
Policy log std Max           -0.2500009
Policy log std Min           -2.3071997
Z mean eval                  1.013226
Z variance eval              0.025445823
total_rewards                [1223.05977836  256.74310707  453.84454223 3417.07628056 1815.81469069
  740.61606546 2760.21590017 3503.90980042 3106.43722673 3301.94035859]
total_rewards_mean           2057.9657750301267
total_rewards_std            1240.4265127743836
total_rewards_max            3503.909800416233
total_rewards_min            256.74310707293046
Number of train steps total  528000
Number of env steps total    428125
Number of rollouts total     0
Train Time (s)               145.46365906577557
(Previous) Eval Time (s)     14.382851014845073
Sample Time (s)              7.29324755910784
Epoch Time (s)               167.1397576397285
Total Train Time (s)         21838.30066230707
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:24:35.018819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #131 | Epoch Duration: 167.2342848777771
2020-01-11 14:24:35.018980 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0178199
Z variance train             0.025397757
KL Divergence                21.461376
KL Loss                      2.1461377
QF Loss                      1040.1155
VF Loss                      645.46173
Policy Loss                  -844.5999
Q Predictions Mean           828.7114
Q Predictions Std            360.9646
Q Predictions Max            1255.0575
Q Predictions Min            -117.84963
V Predictions Mean           844.8976
V Predictions Std            341.76526
V Predictions Max            1251.1912
V Predictions Min            40.148853
Log Pis Mean                 0.0019949228
Log Pis Std                  3.707959
Log Pis Max                  16.462597
Log Pis Min                  -7.5235815
Policy mu Mean               -0.030787708
Policy mu Std                0.59902877
Policy mu Max                3.6181064
Policy mu Min                -4.7618437
Policy log std Mean          -1.0059536
Policy log std Std           0.2497206
Policy log std Max           -0.104486644
Policy log std Min           -2.0820875
Z mean eval                  1.0702755
Z variance eval              0.030504659
total_rewards                [ 842.03888832 2987.81164528 1178.43959375 2098.85402494  347.90823359
  344.68871654 3548.14046372  326.60533887 1037.29713201 1261.6324185 ]
total_rewards_mean           1397.3416455514202
total_rewards_std            1072.7461589193335
total_rewards_max            3548.1404637207133
total_rewards_min            326.6053388688397
Number of train steps total  532000
Number of env steps total    432315
Number of rollouts total     0
Train Time (s)               145.03954164497554
(Previous) Eval Time (s)     13.731493039987981
Sample Time (s)              6.439945420715958
Epoch Time (s)               165.21098010567948
Total Train Time (s)         22003.727275791112
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:27:20.447448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #132 | Epoch Duration: 165.42831873893738
2020-01-11 14:27:20.447681 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0689325
Z variance train             0.030475568
KL Divergence                18.76462
KL Loss                      1.876462
QF Loss                      814.77747
VF Loss                      155.46883
Policy Loss                  -835.10895
Q Predictions Mean           825.67847
Q Predictions Std            356.61603
Q Predictions Max            1308.6227
Q Predictions Min            4.113279
V Predictions Mean           837.5078
V Predictions Std            349.8532
V Predictions Max            1312.135
V Predictions Min            182.50925
Log Pis Mean                 -0.1862099
Log Pis Std                  3.5536644
Log Pis Max                  20.385132
Log Pis Min                  -10.733339
Policy mu Mean               -0.019230228
Policy mu Std                0.61623514
Policy mu Max                4.956356
Policy mu Min                -2.8420334
Policy log std Mean          -0.9939436
Policy log std Std           0.24151841
Policy log std Max           -0.28712928
Policy log std Min           -1.956994
Z mean eval                  1.0531256
Z variance eval              0.022417242
total_rewards                [ 535.47862878 2959.65692523 3280.47845302 1834.03594634  107.49090697
 3699.4898894    54.34638754 2207.75670467 1409.97495164  923.14756278]
total_rewards_mean           1701.1856356371154
total_rewards_std            1250.8541586360154
total_rewards_max            3699.489889403752
total_rewards_min            54.34638753924109
Number of train steps total  536000
Number of env steps total    435307
Number of rollouts total     0
Train Time (s)               143.4565417780541
(Previous) Eval Time (s)     15.350889596156776
Sample Time (s)              7.741186283994466
Epoch Time (s)               166.54861765820533
Total Train Time (s)         22170.37530200137
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:30:07.097963 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #133 | Epoch Duration: 166.65011024475098
2020-01-11 14:30:07.098152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0528226
Z variance train             0.022428483
KL Divergence                19.708643
KL Loss                      1.9708643
QF Loss                      1045.9844
VF Loss                      116.39548
Policy Loss                  -899.7057
Q Predictions Mean           891.1309
Q Predictions Std            328.81146
Q Predictions Max            1280.3004
Q Predictions Min            -1.6600126
V Predictions Mean           895.4386
V Predictions Std            320.52908
V Predictions Max            1282.9127
V Predictions Min            20.396147
Log Pis Mean                 0.38298365
Log Pis Std                  2.8554902
Log Pis Max                  11.944549
Log Pis Min                  -6.701493
Policy mu Mean               -0.04820407
Policy mu Std                0.61723363
Policy mu Max                3.2609882
Policy mu Min                -2.4363813
Policy log std Mean          -1.01342
Policy log std Std           0.22432408
Policy log std Max           -0.3265152
Policy log std Min           -2.059103
Z mean eval                  1.0301087
Z variance eval              0.010641577
total_rewards                [1048.5770284  3682.84311209 2184.95965713  251.97046206  899.75629592
 1918.15022463  296.77080408 1099.34618073 3196.90616487 3399.59864459]
total_rewards_mean           1797.8878574503385
total_rewards_std            1214.0574159780083
total_rewards_max            3682.8431120873365
total_rewards_min            251.97046206227645
Number of train steps total  540000
Number of env steps total    439757
Number of rollouts total     0
Train Time (s)               145.47745918110013
(Previous) Eval Time (s)     14.86198346503079
Sample Time (s)              7.451023829635233
Epoch Time (s)               167.79046647576615
Total Train Time (s)         22338.2648482793
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:32:54.991829 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #134 | Epoch Duration: 167.89350986480713
2020-01-11 14:32:54.992086 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.030499
Z variance train             0.010638076
KL Divergence                21.582361
KL Loss                      2.1582363
QF Loss                      2003.5634
VF Loss                      669.4914
Policy Loss                  -845.4728
Q Predictions Mean           833.4863
Q Predictions Std            363.19656
Q Predictions Max            1282.897
Q Predictions Min            -74.66382
V Predictions Mean           840.946
V Predictions Std            352.69507
V Predictions Max            1270.3146
V Predictions Min            3.902381
Log Pis Mean                 -0.041905187
Log Pis Std                  3.714703
Log Pis Max                  19.30016
Log Pis Min                  -10.081629
Policy mu Mean               -0.009732099
Policy mu Std                0.62039685
Policy mu Max                4.4262223
Policy mu Min                -3.504319
Policy log std Mean          -1.0095801
Policy log std Std           0.23969087
Policy log std Max           -0.42648226
Policy log std Min           -2.0542717
Z mean eval                  1.045503
Z variance eval              0.036674023
total_rewards                [ 439.89261976  769.38130337 1182.81304503 1758.64410708 3555.66708862
 2196.93750831 3251.85559898 3455.20434256 3544.23395511 2072.58007925]
total_rewards_mean           2222.7209648073
total_rewards_std            1127.4720079576928
total_rewards_max            3555.667088623336
total_rewards_min            439.89261975980287
Number of train steps total  544000
Number of env steps total    444365
Number of rollouts total     0
Train Time (s)               143.71019597165287
(Previous) Eval Time (s)     14.271753340028226
Sample Time (s)              8.507700911257416
Epoch Time (s)               166.4896502229385
Total Train Time (s)         22504.842586792074
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:35:41.570680 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #135 | Epoch Duration: 166.5783941745758
2020-01-11 14:35:41.570874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #135 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0466923
Z variance train             0.03673465
KL Divergence                19.339718
KL Loss                      1.9339718
QF Loss                      761.0357
VF Loss                      115.14361
Policy Loss                  -846.7952
Q Predictions Mean           835.1369
Q Predictions Std            371.62543
Q Predictions Max            1289.7104
Q Predictions Min            -28.325817
V Predictions Mean           841.2892
V Predictions Std            360.29977
V Predictions Max            1261.0718
V Predictions Min            196.98982
Log Pis Mean                 0.031636655
Log Pis Std                  3.5761387
Log Pis Max                  22.015125
Log Pis Min                  -6.3432903
Policy mu Mean               -0.017054237
Policy mu Std                0.6066955
Policy mu Max                4.575958
Policy mu Min                -3.1104321
Policy log std Mean          -0.9918092
Policy log std Std           0.24000515
Policy log std Max           -0.043813884
Policy log std Min           -2.1424356
Z mean eval                  1.0396788
Z variance eval              0.020251231
total_rewards                [3226.09215629  406.35222666 2124.4871909  3280.48511378 3286.4341711
  639.08157124 3345.6098118  1934.49059371 1875.06493188 2651.06454399]
total_rewards_mean           2276.9162311352184
total_rewards_std            1034.059539086125
total_rewards_max            3345.60981180426
total_rewards_min            406.352226664304
Number of train steps total  548000
Number of env steps total    448103
Number of rollouts total     0
Train Time (s)               145.97623513592407
(Previous) Eval Time (s)     16.14906639698893
Sample Time (s)              6.975452768616378
Epoch Time (s)               169.10075430152938
Total Train Time (s)         22674.036431501154
Epoch                        136
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:38:30.766924 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #136 | Epoch Duration: 169.1959090232849
2020-01-11 14:38:30.767106 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0387517
Z variance train             0.020154072
KL Divergence                19.635569
KL Loss                      1.9635569
QF Loss                      1549.979
VF Loss                      117.59664
Policy Loss                  -857.42303
Q Predictions Mean           852.06995
Q Predictions Std            342.69305
Q Predictions Max            1296.696
Q Predictions Min            206.23958
V Predictions Mean           857.65125
V Predictions Std            339.97467
V Predictions Max            1290.546
V Predictions Min            224.94983
Log Pis Mean                 -0.35173613
Log Pis Std                  3.2960837
Log Pis Max                  15.696588
Log Pis Min                  -7.4327927
Policy mu Mean               -0.041336786
Policy mu Std                0.5768055
Policy mu Max                4.3824368
Policy mu Min                -2.8190923
Policy log std Mean          -1.0045812
Policy log std Std           0.23421967
Policy log std Max           -0.4603899
Policy log std Min           -1.9601157
Z mean eval                  1.1293623
Z variance eval              0.06525401
total_rewards                [1124.22398093 3546.78967018  533.31151912 3568.25233126    7.80417141
 2388.52006977  552.01823812 3441.93800541 3647.76881603 1016.8016046 ]
total_rewards_mean           1982.7428406841525
total_rewards_std            1405.1549349581405
total_rewards_max            3647.768816030575
total_rewards_min            7.804171414377607
Number of train steps total  552000
Number of env steps total    450815
Number of rollouts total     0
Train Time (s)               146.84205909911543
(Previous) Eval Time (s)     13.463275474961847
Sample Time (s)              7.509425484575331
Epoch Time (s)               167.8147600586526
Total Train Time (s)         22841.935249185655
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:41:18.667990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #137 | Epoch Duration: 167.90074706077576
2020-01-11 14:41:18.668174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1337483
Z variance train             0.06545262
KL Divergence                19.123844
KL Loss                      1.9123844
QF Loss                      950.26825
VF Loss                      169.93199
Policy Loss                  -845.72925
Q Predictions Mean           837.8624
Q Predictions Std            349.9945
Q Predictions Max            1273.5984
Q Predictions Min            35.546993
V Predictions Mean           842.40137
V Predictions Std            343.99197
V Predictions Max            1270.3846
V Predictions Min            167.76227
Log Pis Mean                 0.11469552
Log Pis Std                  3.8081312
Log Pis Max                  25.340189
Log Pis Min                  -6.635731
Policy mu Mean               -0.022262178
Policy mu Std                0.60143405
Policy mu Max                5.7914934
Policy mu Min                -5.3103747
Policy log std Mean          -1.0140114
Policy log std Std           0.2428866
Policy log std Max           -0.26888776
Policy log std Min           -2.3043423
Z mean eval                  1.1793628
Z variance eval              0.0076940632
total_rewards                [3406.98614955 1819.19996869 3467.48534817 1404.43144902 3598.07564974
 2138.07697109 3530.63803584 3472.60801556 3638.37602505  873.29363962]
total_rewards_mean           2734.9171252345905
total_rewards_std            1007.8473808666951
total_rewards_max            3638.3760250507476
total_rewards_min            873.2936396233317
Number of train steps total  556000
Number of env steps total    454141
Number of rollouts total     0
Train Time (s)               144.44478339422494
(Previous) Eval Time (s)     20.55428234813735
Sample Time (s)              7.569288549479097
Epoch Time (s)               172.5683542918414
Total Train Time (s)         23014.598311145324
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:44:11.335662 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #138 | Epoch Duration: 172.66730093955994
2020-01-11 14:44:11.335986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1786995
Z variance train             0.0077058515
KL Divergence                22.32508
KL Loss                      2.2325082
QF Loss                      548.3234
VF Loss                      163.52454
Policy Loss                  -844.7735
Q Predictions Mean           839.4769
Q Predictions Std            363.40192
Q Predictions Max            1305.862
Q Predictions Min            -17.110037
V Predictions Mean           850.4796
V Predictions Std            358.91223
V Predictions Max            1308.5754
V Predictions Min            118.9709
Log Pis Mean                 0.19564341
Log Pis Std                  3.3361557
Log Pis Max                  15.66604
Log Pis Min                  -7.0186396
Policy mu Mean               -0.045036845
Policy mu Std                0.59029955
Policy mu Max                2.8499224
Policy mu Min                -2.519345
Policy log std Mean          -1.0114663
Policy log std Std           0.25519297
Policy log std Max           -0.02518922
Policy log std Min           -2.164647
Z mean eval                  1.0949425
Z variance eval              0.0110892635
total_rewards                [3540.42281578 1409.25905414 1553.36969799 3364.64665053 3290.39426826
 1104.76116469 2403.52581075 3563.03681034 1134.1935802  3534.12489681]
total_rewards_mean           2489.773474947499
total_rewards_std            1027.6421021991173
total_rewards_max            3563.036810337732
total_rewards_min            1104.761164687356
Number of train steps total  560000
Number of env steps total    457065
Number of rollouts total     0
Train Time (s)               146.04261909564957
(Previous) Eval Time (s)     18.91904537891969
Sample Time (s)              7.388299082405865
Epoch Time (s)               172.34996355697513
Total Train Time (s)         23187.04237287212
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:47:03.781534 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #139 | Epoch Duration: 172.44530582427979
2020-01-11 14:47:03.781731 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0915962
Z variance train             0.011086391
KL Divergence                21.532993
KL Loss                      2.1532993
QF Loss                      773.66235
VF Loss                      109.57628
Policy Loss                  -882.66125
Q Predictions Mean           871.17065
Q Predictions Std            354.17102
Q Predictions Max            1323.8813
Q Predictions Min            199.37633
V Predictions Mean           884.26825
V Predictions Std            348.74524
V Predictions Max            1331.6399
V Predictions Min            219.66676
Log Pis Mean                 -0.10682809
Log Pis Std                  3.0977142
Log Pis Max                  14.804731
Log Pis Min                  -8.497807
Policy mu Mean               -0.039557673
Policy mu Std                0.5915027
Policy mu Max                3.8208652
Policy mu Min                -2.3051085
Policy log std Mean          -0.99523294
Policy log std Std           0.23744753
Policy log std Max           -0.24658805
Policy log std Min           -2.0389025
Z mean eval                  1.0229295
Z variance eval              0.015300326
total_rewards                [ 623.70000321 3338.30735041 1162.88506956 1503.28254095 3253.82276372
 1892.17452199 2335.59223703 3277.93332311 3420.68067025  897.81179332]
total_rewards_mean           2170.619027354733
total_rewards_std            1044.2334679298478
total_rewards_max            3420.680670251362
total_rewards_min            623.7000032078491
Number of train steps total  564000
Number of env steps total    463285
Number of rollouts total     0
Train Time (s)               147.22620432591066
(Previous) Eval Time (s)     17.131430144887418
Sample Time (s)              7.206840645056218
Epoch Time (s)               171.5644751158543
Total Train Time (s)         23358.69574013725
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:49:55.437239 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #140 | Epoch Duration: 171.65535688400269
2020-01-11 14:49:55.437418 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.020416
Z variance train             0.015197118
KL Divergence                22.026173
KL Loss                      2.2026174
QF Loss                      942.2475
VF Loss                      255.50883
Policy Loss                  -918.55536
Q Predictions Mean           911.7191
Q Predictions Std            339.45096
Q Predictions Max            1293.9685
Q Predictions Min            22.371305
V Predictions Mean           926.9483
V Predictions Std            332.5457
V Predictions Max            1299.1873
V Predictions Min            227.90984
Log Pis Mean                 0.23393166
Log Pis Std                  3.1036127
Log Pis Max                  13.935437
Log Pis Min                  -8.155075
Policy mu Mean               -0.028493125
Policy mu Std                0.6018545
Policy mu Max                3.2468712
Policy mu Min                -2.6534007
Policy log std Mean          -1.0380328
Policy log std Std           0.2484879
Policy log std Max           -0.46225977
Policy log std Min           -2.1458182
Z mean eval                  1.0729876
Z variance eval              0.02330907
total_rewards                [3542.9610627    46.07100881 3442.38601837  539.31710333 1607.93533671
 2883.76388449 3771.12353071 1809.80828989  122.97023499  269.03743968]
total_rewards_mean           1803.5373909680761
total_rewards_std            1437.147890860637
total_rewards_max            3771.123530707464
total_rewards_min            46.07100881316654
Number of train steps total  568000
Number of env steps total    468865
Number of rollouts total     0
Train Time (s)               147.08519169455394
(Previous) Eval Time (s)     16.417268407996744
Sample Time (s)              7.471918334718794
Epoch Time (s)               170.97437843726948
Total Train Time (s)         23529.760884676594
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:52:46.505072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #141 | Epoch Duration: 171.06751346588135
2020-01-11 14:52:46.505276 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0766213
Z variance train             0.02329649
KL Divergence                19.97171
KL Loss                      1.997171
QF Loss                      531.7191
VF Loss                      234.7017
Policy Loss                  -920.1173
Q Predictions Mean           905.4232
Q Predictions Std            376.57864
Q Predictions Max            1366.9839
Q Predictions Min            -29.718609
V Predictions Mean           916.1344
V Predictions Std            360.9229
V Predictions Max            1376.3794
V Predictions Min            17.807753
Log Pis Mean                 0.07356371
Log Pis Std                  4.140609
Log Pis Max                  30.234514
Log Pis Min                  -11.847918
Policy mu Mean               -0.027035631
Policy mu Std                0.6323318
Policy mu Max                4.3004665
Policy mu Min                -3.7011538
Policy log std Mean          -1.0113244
Policy log std Std           0.2492266
Policy log std Max           -0.3340072
Policy log std Min           -2.5228887
Z mean eval                  1.0645367
Z variance eval              0.021532368
total_rewards                [ 528.48561987  170.51972471 3582.812161   3533.14176619 1119.84929267
 3522.40486944 2438.90053535 2339.90592453 3716.85322656  109.56094645]
total_rewards_mean           2106.2434066777378
total_rewards_std            1420.4643759905823
total_rewards_max            3716.85322656477
total_rewards_min            109.56094644693383
Number of train steps total  572000
Number of env steps total    474594
Number of rollouts total     0
Train Time (s)               145.92203581286594
(Previous) Eval Time (s)     12.89055938506499
Sample Time (s)              7.606507691089064
Epoch Time (s)               166.41910288902
Total Train Time (s)         23696.26901618531
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:55:33.014968 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #142 | Epoch Duration: 166.50953793525696
2020-01-11 14:55:33.015150 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0673087
Z variance train             0.021616958
KL Divergence                20.872726
KL Loss                      2.0872726
QF Loss                      851.0774
VF Loss                      193.68082
Policy Loss                  -902.2844
Q Predictions Mean           898.33997
Q Predictions Std            354.7321
Q Predictions Max            1332.304
Q Predictions Min            212.9351
V Predictions Mean           903.4171
V Predictions Std            350.21072
V Predictions Max            1335.531
V Predictions Min            223.3012
Log Pis Mean                 0.21920037
Log Pis Std                  3.424659
Log Pis Max                  16.665821
Log Pis Min                  -9.987498
Policy mu Mean               -0.06348976
Policy mu Std                0.6141742
Policy mu Max                2.5657318
Policy mu Min                -3.734281
Policy log std Mean          -1.0220225
Policy log std Std           0.25726774
Policy log std Max           -0.3863293
Policy log std Min           -2.138818
Z mean eval                  1.0236701
Z variance eval              0.02859568
total_rewards                [  59.59927638 1411.16031819 1242.71485904 2375.48292211 3348.99825824
  635.8865683  3610.09670874 1978.84184638   81.45745149 3627.52508384]
total_rewards_mean           1837.1763292695352
total_rewards_std            1310.1276317324318
total_rewards_max            3627.525083835126
total_rewards_min            59.599276377047886
Number of train steps total  576000
Number of env steps total    477971
Number of rollouts total     0
Train Time (s)               147.35583726596087
(Previous) Eval Time (s)     14.299574497155845
Sample Time (s)              7.255684988107532
Epoch Time (s)               168.91109675122425
Total Train Time (s)         23865.265062215272
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:58:22.011793 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #143 | Epoch Duration: 168.99652314186096
2020-01-11 14:58:22.011925 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0223148
Z variance train             0.02841645
KL Divergence                19.424635
KL Loss                      1.9424635
QF Loss                      921.811
VF Loss                      170.48433
Policy Loss                  -866.2349
Q Predictions Mean           854.28436
Q Predictions Std            388.78653
Q Predictions Max            1334.0956
Q Predictions Min            -28.894886
V Predictions Mean           860.0853
V Predictions Std            378.65298
V Predictions Max            1325.7
V Predictions Min            -68.592224
Log Pis Mean                 0.014398254
Log Pis Std                  4.1017284
Log Pis Max                  22.636375
Log Pis Min                  -10.604227
Policy mu Mean               -0.039769858
Policy mu Std                0.6040338
Policy mu Max                3.7434342
Policy mu Min                -3.4755104
Policy log std Mean          -0.9958632
Policy log std Std           0.2558723
Policy log std Max           -0.25759363
Policy log std Min           -2.3097882
Z mean eval                  1.114846
Z variance eval              0.032235987
total_rewards                [3443.1775713   908.93425045 2696.30679473 1327.89253434 3325.76743524
 2446.95845851 3200.18995005 1400.33257112  942.64193131 3659.93504925]
total_rewards_mean           2335.213654630469
total_rewards_std            1035.2272300322572
total_rewards_max            3659.9350492490084
total_rewards_min            908.9342504519991
Number of train steps total  580000
Number of env steps total    482143
Number of rollouts total     0
Train Time (s)               145.59355967864394
(Previous) Eval Time (s)     16.29334145085886
Sample Time (s)              6.2330794907175004
Epoch Time (s)               168.1199806202203
Total Train Time (s)         24033.472576396074
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:01:10.221260 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #144 | Epoch Duration: 168.209223985672
2020-01-11 15:01:10.221379 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1163014
Z variance train             0.032209475
KL Divergence                18.854834
KL Loss                      1.8854834
QF Loss                      614.0218
VF Loss                      165.19974
Policy Loss                  -913.0286
Q Predictions Mean           907.8779
Q Predictions Std            333.33508
Q Predictions Max            1322.2578
Q Predictions Min            187.54161
V Predictions Mean           917.39514
V Predictions Std            329.3419
V Predictions Max            1318.7416
V Predictions Min            213.41771
Log Pis Mean                 -0.16911964
Log Pis Std                  2.8827767
Log Pis Max                  10.809265
Log Pis Min                  -9.817608
Policy mu Mean               0.01824072
Policy mu Std                0.5756827
Policy mu Max                2.8573537
Policy mu Min                -3.1634085
Policy log std Mean          -1.0059651
Policy log std Std           0.23122497
Policy log std Max           -0.16378051
Policy log std Min           -2.135631
Z mean eval                  1.1335471
Z variance eval              0.061374962
total_rewards                [1207.3225807   596.63397337   62.77522773 3329.26070032 1060.90609845
  157.10951847 2057.0781502   553.17338915   11.58393586 3917.93802143]
total_rewards_mean           1295.378159568469
total_rewards_std            1309.9473531971908
total_rewards_max            3917.9380214312423
total_rewards_min            11.583935859708259
Number of train steps total  584000
Number of env steps total    487508
Number of rollouts total     0
Train Time (s)               145.791696599219
(Previous) Eval Time (s)     12.805953160859644
Sample Time (s)              7.157274698838592
Epoch Time (s)               165.75492445891723
Total Train Time (s)         24199.31601434434
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:03:56.067988 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #145 | Epoch Duration: 165.84650468826294
2020-01-11 15:03:56.068163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1261622
Z variance train             0.06139929
KL Divergence                18.848808
KL Loss                      1.8848809
QF Loss                      948.1912
VF Loss                      81.424965
Policy Loss                  -885.4436
Q Predictions Mean           877.37305
Q Predictions Std            334.67123
Q Predictions Max            1284.8221
Q Predictions Min            182.61646
V Predictions Mean           886.927
V Predictions Std            326.39587
V Predictions Max            1271.8589
V Predictions Min            183.0543
Log Pis Mean                 0.37162316
Log Pis Std                  3.226595
Log Pis Max                  14.137708
Log Pis Min                  -7.0853524
Policy mu Mean               -0.041960247
Policy mu Std                0.59419614
Policy mu Max                2.3274992
Policy mu Min                -2.7791414
Policy log std Mean          -1.034875
Policy log std Std           0.24501291
Policy log std Max           -0.52664816
Policy log std Min           -2.17283
Z mean eval                  1.0243076
Z variance eval              0.059867233
total_rewards                [  91.56281817  776.1990163  1120.39330692  489.7072205  3420.78277055
 1762.32824882 1168.76236315    7.44317779 1264.68991838 1486.86363971]
total_rewards_mean           1158.8732480287997
total_rewards_std            930.586454428614
total_rewards_max            3420.782770553958
total_rewards_min            7.443177793458203
Number of train steps total  588000
Number of env steps total    493415
Number of rollouts total     0
Train Time (s)               146.73831298714504
(Previous) Eval Time (s)     17.30222067516297
Sample Time (s)              7.871552898082882
Epoch Time (s)               171.9120865603909
Total Train Time (s)         24371.34729385795
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:06:48.099611 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #146 | Epoch Duration: 172.03132486343384
2020-01-11 15:06:48.099741 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0266072
Z variance train             0.060331147
KL Divergence                16.593987
KL Loss                      1.6593987
QF Loss                      701.2877
VF Loss                      229.33794
Policy Loss                  -931.02765
Q Predictions Mean           925.3356
Q Predictions Std            359.12607
Q Predictions Max            1347.2742
Q Predictions Min            23.496582
V Predictions Mean           930.81555
V Predictions Std            356.25433
V Predictions Max            1336.1011
V Predictions Min            -28.190357
Log Pis Mean                 0.3259006
Log Pis Std                  4.099013
Log Pis Max                  38.114826
Log Pis Min                  -7.653473
Policy mu Mean               -0.019362053
Policy mu Std                0.648179
Policy mu Max                5.735602
Policy mu Min                -3.2861614
Policy log std Mean          -1.0321982
Policy log std Std           0.24108183
Policy log std Max           -0.4908539
Policy log std Min           -2.178009
Z mean eval                  1.0614374
Z variance eval              0.03115815
total_rewards                [ 741.68450713  971.93186893 2837.68746532  906.26940308 2823.33167123
 2056.32692463  816.88007649 1284.44269554  423.50094641 1876.23175963]
total_rewards_mean           1473.8287318389112
total_rewards_std            828.4441714135037
total_rewards_max            2837.6874653226814
total_rewards_min            423.5009464149108
Number of train steps total  592000
Number of env steps total    498523
Number of rollouts total     0
Train Time (s)               147.71934974798933
(Previous) Eval Time (s)     10.79808967281133
Sample Time (s)              8.283137963619083
Epoch Time (s)               166.80057738441974
Total Train Time (s)         24538.24481628323
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:09:34.999018 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #147 | Epoch Duration: 166.89918398857117
2020-01-11 15:09:34.999146 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0609343
Z variance train             0.031179596
KL Divergence                19.945595
KL Loss                      1.9945595
QF Loss                      1040.3213
VF Loss                      156.81163
Policy Loss                  -903.41266
Q Predictions Mean           898.3314
Q Predictions Std            374.79593
Q Predictions Max            1333.6637
Q Predictions Min            119.05299
V Predictions Mean           905.51184
V Predictions Std            372.26843
V Predictions Max            1311.1111
V Predictions Min            166.11989
Log Pis Mean                 -0.2869323
Log Pis Std                  2.8389924
Log Pis Max                  15.827632
Log Pis Min                  -6.483878
Policy mu Mean               -0.0677232
Policy mu Std                0.56261575
Policy mu Max                2.6376057
Policy mu Min                -3.074016
Policy log std Mean          -0.9936234
Policy log std Std           0.2383247
Policy log std Max           -0.25464898
Policy log std Min           -2.127771
Z mean eval                  1.0688426
Z variance eval              0.025392164
total_rewards                [1091.38873245 1600.30552062 3610.0465056   536.0041427   360.44408532
 3561.1779549  1829.22973208 1445.78142584 3333.04974586 3492.46383317]
total_rewards_mean           2085.9891678547597
total_rewards_std            1229.3548388351894
total_rewards_max            3610.0465055980553
total_rewards_min            360.44408532288617
Number of train steps total  596000
Number of env steps total    503027
Number of rollouts total     0
Train Time (s)               146.8357804310508
(Previous) Eval Time (s)     16.20667563378811
Sample Time (s)              7.849516668356955
Epoch Time (s)               170.89197273319587
Total Train Time (s)         24709.221241590567
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:12:25.976913 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #148 | Epoch Duration: 170.9776737689972
2020-01-11 15:12:25.977043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0628035
Z variance train             0.024990777
KL Divergence                20.833675
KL Loss                      2.0833676
QF Loss                      664.7117
VF Loss                      658.1681
Policy Loss                  -904.7617
Q Predictions Mean           894.08105
Q Predictions Std            380.8881
Q Predictions Max            1380.8807
Q Predictions Min            -28.05972
V Predictions Mean           904.7949
V Predictions Std            370.3574
V Predictions Max            1384.4958
V Predictions Min            -6.8637953
Log Pis Mean                 0.33998352
Log Pis Std                  3.9021397
Log Pis Max                  18.319302
Log Pis Min                  -7.0374517
Policy mu Mean               -0.022792464
Policy mu Std                0.61053437
Policy mu Max                3.2719455
Policy mu Min                -2.6294837
Policy log std Mean          -1.0433834
Policy log std Std           0.26937628
Policy log std Max           -0.24249423
Policy log std Min           -2.6774783
Z mean eval                  1.0612476
Z variance eval              0.018575322
total_rewards                [3513.8625909  2907.33743385  404.79330319 2449.02871765 3518.11129672
 2390.80143839  696.11873385  979.66073749 1899.35381414  115.82103318]
total_rewards_mean           1887.4889099357988
total_rewards_std            1203.8941472559256
total_rewards_max            3518.1112967234053
total_rewards_min            115.8210331825433
Number of train steps total  600000
Number of env steps total    505753
Number of rollouts total     0
Train Time (s)               146.0458785877563
(Previous) Eval Time (s)     12.023624591063708
Sample Time (s)              7.162729162722826
Epoch Time (s)               165.23223234154284
Total Train Time (s)         24874.53467641212
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:15:11.291866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #149 | Epoch Duration: 165.3147304058075
2020-01-11 15:15:11.291990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0555604
Z variance train             0.018659702
KL Divergence                19.603466
KL Loss                      1.9603466
QF Loss                      679.1388
VF Loss                      151.7841
Policy Loss                  -920.84076
Q Predictions Mean           906.9329
Q Predictions Std            380.45358
Q Predictions Max            1371.3606
Q Predictions Min            -127.322685
V Predictions Mean           917.6101
V Predictions Std            361.07928
V Predictions Max            1355.1215
V Predictions Min            -26.444483
Log Pis Mean                 0.5037019
Log Pis Std                  4.131531
Log Pis Max                  25.713167
Log Pis Min                  -8.972452
Policy mu Mean               -0.032438375
Policy mu Std                0.6712042
Policy mu Max                3.4312274
Policy mu Min                -4.7990313
Policy log std Mean          -1.0410488
Policy log std Std           0.2605232
Policy log std Max           -0.389957
Policy log std Min           -2.5845802
Z mean eval                  1.1301167
Z variance eval              0.01581174
total_rewards                [3295.7819906  3665.62754907 2387.94943571 1879.91747487   21.02856414
 2693.00179724  140.76886489  336.78442293 3586.42456875 2961.50145213]
total_rewards_mean           2096.8786120316468
total_rewards_std            1363.2780303901036
total_rewards_max            3665.627549068111
total_rewards_min            21.028564140949403
Number of train steps total  604000
Number of env steps total    511639
Number of rollouts total     0
Train Time (s)               146.1863347250037
(Previous) Eval Time (s)     16.595068603754044
Sample Time (s)              6.8234041896648705
Epoch Time (s)               169.6048075184226
Total Train Time (s)         25044.237795569003
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:18:00.998970 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #150 | Epoch Duration: 169.7068748474121
2020-01-11 15:18:00.999152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1282122
Z variance train             0.015732486
KL Divergence                20.22991
KL Loss                      2.022991
QF Loss                      776.0686
VF Loss                      150.41016
Policy Loss                  -912.5224
Q Predictions Mean           901.62024
Q Predictions Std            381.6774
Q Predictions Max            1410.3457
Q Predictions Min            0.60588324
V Predictions Mean           914.79266
V Predictions Std            374.99405
V Predictions Max            1405.2126
V Predictions Min            43.96732
Log Pis Mean                 0.24088518
Log Pis Std                  3.7708716
Log Pis Max                  21.157673
Log Pis Min                  -7.088807
Policy mu Mean               -0.076988325
Policy mu Std                0.6552569
Policy mu Max                2.6761756
Policy mu Min                -3.1246753
Policy log std Mean          -1.0039825
Policy log std Std           0.2542333
Policy log std Max           -0.3150134
Policy log std Min           -2.3362846
Z mean eval                  1.0263187
Z variance eval              0.04770874
total_rewards                [ 708.02489424  308.4852806  2251.33086871 1354.68328092 1960.58753739
 1739.60619421 1918.54824189 3656.38132713  163.55779263 3496.98316292]
total_rewards_mean           1755.81885806527
total_rewards_std            1133.4393953658403
total_rewards_max            3656.3813271288545
total_rewards_min            163.55779263471476
Number of train steps total  608000
Number of env steps total    515974
Number of rollouts total     0
Train Time (s)               146.91996286669746
(Previous) Eval Time (s)     12.31358569394797
Sample Time (s)              7.391122595407069
Epoch Time (s)               166.6246711560525
Total Train Time (s)         25210.955933788326
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:20:47.718851 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #151 | Epoch Duration: 166.7195565700531
2020-01-11 15:20:47.719027 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.025243
Z variance train             0.047292747
KL Divergence                18.224102
KL Loss                      1.8224102
QF Loss                      905.9596
VF Loss                      133.23627
Policy Loss                  -911.1662
Q Predictions Mean           908.7308
Q Predictions Std            374.68304
Q Predictions Max            1335.2754
Q Predictions Min            187.46994
V Predictions Mean           909.8522
V Predictions Std            368.79526
V Predictions Max            1338.763
V Predictions Min            189.39249
Log Pis Mean                 -0.04085712
Log Pis Std                  2.941254
Log Pis Max                  11.558731
Log Pis Min                  -5.9815345
Policy mu Mean               0.0074925143
Policy mu Std                0.5801939
Policy mu Max                2.670017
Policy mu Min                -3.1413636
Policy log std Mean          -1.0328608
Policy log std Std           0.24214345
Policy log std Max           -0.37285322
Policy log std Min           -2.317067
Z mean eval                  1.0881417
Z variance eval              0.10354197
total_rewards                [ 968.7477648  3312.39123308  666.92584017  771.24832486  782.33522527
 2934.02078397  659.22748576 1126.45298425 3714.10115742 2736.21447945]
total_rewards_mean           1767.1665279019749
total_rewards_std            1180.1130135940716
total_rewards_max            3714.10115741747
total_rewards_min            659.2274857640001
Number of train steps total  612000
Number of env steps total    521313
Number of rollouts total     0
Train Time (s)               144.93315999303013
(Previous) Eval Time (s)     12.840869260951877
Sample Time (s)              7.813450502697378
Epoch Time (s)               165.5874797566794
Total Train Time (s)         25376.64417573763
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:23:33.409391 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #152 | Epoch Duration: 165.69022035598755
2020-01-11 15:23:33.409617 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0817795
Z variance train             0.10484211
KL Divergence                18.097912
KL Loss                      1.8097912
QF Loss                      1467.2305
VF Loss                      578.17615
Policy Loss                  -881.2153
Q Predictions Mean           867.755
Q Predictions Std            377.94583
Q Predictions Max            1333.9274
Q Predictions Min            -35.368557
V Predictions Mean           878.9774
V Predictions Std            367.61334
V Predictions Max            1330.8634
V Predictions Min            220.468
Log Pis Mean                 0.2464206
Log Pis Std                  4.1141357
Log Pis Max                  24.926495
Log Pis Min                  -9.02626
Policy mu Mean               -0.05133424
Policy mu Std                0.635257
Policy mu Max                3.514416
Policy mu Min                -4.0803876
Policy log std Mean          -1.0136096
Policy log std Std           0.24909711
Policy log std Max           -0.25481987
Policy log std Min           -2.6721237
Z mean eval                  1.0305752
Z variance eval              0.012257459
total_rewards                [1477.76032362 2841.32709783 2090.03792929  959.90530349  132.55694193
 1639.28724197  548.96290515 3717.5561164  3825.58971267 2484.95438185]
total_rewards_mean           1971.793795418304
total_rewards_std            1195.9697720191061
total_rewards_max            3825.5897126679974
total_rewards_min            132.5569419257641
Number of train steps total  616000
Number of env steps total    527397
Number of rollouts total     0
Train Time (s)               146.83771431306377
(Previous) Eval Time (s)     12.29606779711321
Sample Time (s)              6.9589950437657535
Epoch Time (s)               166.09277715394273
Total Train Time (s)         25543.028284310363
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:26:19.804861 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #153 | Epoch Duration: 166.3950538635254
2020-01-11 15:26:19.805137 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0335317
Z variance train             0.012161543
KL Divergence                20.489851
KL Loss                      2.0489852
QF Loss                      578.55914
VF Loss                      155.12062
Policy Loss                  -893.19946
Q Predictions Mean           886.976
Q Predictions Std            397.74396
Q Predictions Max            1372.1996
Q Predictions Min            47.60621
V Predictions Mean           888.5237
V Predictions Std            390.24466
V Predictions Max            1365.8293
V Predictions Min            70.75145
Log Pis Mean                 0.2623803
Log Pis Std                  3.46107
Log Pis Max                  16.93002
Log Pis Min                  -7.390601
Policy mu Mean               -0.05051541
Policy mu Std                0.5771342
Policy mu Max                2.7148461
Policy mu Min                -3.2174304
Policy log std Mean          -1.0211228
Policy log std Std           0.26275402
Policy log std Max           -0.33868724
Policy log std Min           -1.9904473
Z mean eval                  1.034129
Z variance eval              0.025830645
total_rewards                [3022.62837228 2798.37044017 2145.72987219 1697.37487169  645.95474697
 1108.64382669 1865.76190023 3411.09855639 2080.1595013   907.84497422]
total_rewards_mean           1968.3567062122233
total_rewards_std            873.0619597289876
total_rewards_max            3411.0985563937766
total_rewards_min            645.9547469656804
Number of train steps total  620000
Number of env steps total    533038
Number of rollouts total     0
Train Time (s)               146.52221130765975
(Previous) Eval Time (s)     12.967440960928798
Sample Time (s)              7.337071560323238
Epoch Time (s)               166.82672382891178
Total Train Time (s)         25709.953377510887
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:29:06.727448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #154 | Epoch Duration: 166.92207169532776
2020-01-11 15:29:06.727758 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0326259
Z variance train             0.026021514
KL Divergence                20.251183
KL Loss                      2.0251184
QF Loss                      754.8179
VF Loss                      271.0355
Policy Loss                  -895.7617
Q Predictions Mean           877.8683
Q Predictions Std            391.74634
Q Predictions Max            1362.3325
Q Predictions Min            -16.924818
V Predictions Mean           889.46185
V Predictions Std            374.40604
V Predictions Max            1344.7789
V Predictions Min            226.70827
Log Pis Mean                 0.2352476
Log Pis Std                  4.519034
Log Pis Max                  35.1979
Log Pis Min                  -6.9689813
Policy mu Mean               -0.03739734
Policy mu Std                0.6263109
Policy mu Max                4.483569
Policy mu Min                -4.884084
Policy log std Mean          -1.0143359
Policy log std Std           0.26244295
Policy log std Max           -0.3781402
Policy log std Min           -2.3731623
Z mean eval                  1.0150373
Z variance eval              0.010163054
total_rewards                [1543.06996007  415.86401894 3898.68079943  225.73510929  809.89482139
 3680.93160348 2033.74195017 2666.08709547 3839.76586524 3579.84007873]
total_rewards_mean           2269.361130220824
total_rewards_std            1389.7139060475106
total_rewards_max            3898.680799431705
total_rewards_min            225.73510928913421
Number of train steps total  624000
Number of env steps total    538634
Number of rollouts total     0
Train Time (s)               145.16820212593302
(Previous) Eval Time (s)     17.028345103375614
Sample Time (s)              7.338493536226451
Epoch Time (s)               169.5350407655351
Total Train Time (s)         25879.619922273327
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:31:56.394789 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #155 | Epoch Duration: 169.66680335998535
2020-01-11 15:31:56.394986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0162117
Z variance train             0.010165891
KL Divergence                22.878101
KL Loss                      2.28781
QF Loss                      881.2187
VF Loss                      139.88512
Policy Loss                  -902.542
Q Predictions Mean           895.9642
Q Predictions Std            389.0851
Q Predictions Max            1361.634
Q Predictions Min            173.23958
V Predictions Mean           897.8376
V Predictions Std            382.5287
V Predictions Max            1344.5769
V Predictions Min            197.9155
Log Pis Mean                 -0.43856508
Log Pis Std                  2.759823
Log Pis Max                  9.191346
Log Pis Min                  -6.734139
Policy mu Mean               -0.036004987
Policy mu Std                0.5455038
Policy mu Max                1.9679315
Policy mu Min                -2.520591
Policy log std Mean          -1.0024542
Policy log std Std           0.24114756
Policy log std Max           -0.32947528
Policy log std Min           -2.1297874
Z mean eval                  1.0757169
Z variance eval              0.016526531
total_rewards                [3583.18025604 3465.43959149 3564.3639691   702.4395862  3875.69057813
 3430.01385591  383.99265979 3790.99356401 3452.14255154 3193.91656976]
total_rewards_mean           2944.217318196687
total_rewards_std            1215.970984165738
total_rewards_max            3875.6905781306123
total_rewards_min            383.99265978904725
Number of train steps total  628000
Number of env steps total    543734
Number of rollouts total     0
Train Time (s)               145.7900544158183
(Previous) Eval Time (s)     20.440146374050528
Sample Time (s)              8.097559292800725
Epoch Time (s)               174.32776008266956
Total Train Time (s)         26054.034962103236
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:34:50.811198 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #156 | Epoch Duration: 174.41607213020325
2020-01-11 15:34:50.811336 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.072747
Z variance train             0.016281174
KL Divergence                22.521084
KL Loss                      2.2521083
QF Loss                      856.4519
VF Loss                      182.82384
Policy Loss                  -919.0549
Q Predictions Mean           915.1354
Q Predictions Std            367.9211
Q Predictions Max            1395.5065
Q Predictions Min            205.41898
V Predictions Mean           923.06726
V Predictions Std            363.19086
V Predictions Max            1384.6302
V Predictions Min            223.53812
Log Pis Mean                 -0.004836049
Log Pis Std                  3.1797566
Log Pis Max                  15.833256
Log Pis Min                  -9.97748
Policy mu Mean               -0.017603036
Policy mu Std                0.60050046
Policy mu Max                2.5263307
Policy mu Min                -3.0822022
Policy log std Mean          -1.006089
Policy log std Std           0.2355408
Policy log std Max           -0.40117365
Policy log std Min           -2.3724947
Z mean eval                  1.0225799
Z variance eval              0.27554846
total_rewards                [3620.24944804 2705.30812567 3719.01443353 3455.23796229 1818.07111291
 3611.69124656 1854.32848408 3809.42271983 3564.76307831 3969.68947307]
total_rewards_mean           3212.7776084285383
total_rewards_std            757.7030009099354
total_rewards_max            3969.6894730665063
total_rewards_min            1818.0711129083475
Number of train steps total  632000
Number of env steps total    549727
Number of rollouts total     0
Train Time (s)               147.71175320912153
(Previous) Eval Time (s)     19.062790622003376
Sample Time (s)              7.235427334439009
Epoch Time (s)               174.0099711655639
Total Train Time (s)         26228.132359633688
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:37:44.912685 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #157 | Epoch Duration: 174.1012146472931
2020-01-11 15:37:44.912940 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0207021
Z variance train             0.27448314
KL Divergence                17.798773
KL Loss                      1.7798773
QF Loss                      1074.2303
VF Loss                      284.49768
Policy Loss                  -1044.9373
Q Predictions Mean           1037.0371
Q Predictions Std            407.8799
Q Predictions Max            1541.3208
Q Predictions Min            100.949326
V Predictions Mean           1040.1062
V Predictions Std            400.7808
V Predictions Max            1527.4117
V Predictions Min            272.30276
Log Pis Mean                 0.076667
Log Pis Std                  3.3777175
Log Pis Max                  18.968374
Log Pis Min                  -7.63441
Policy mu Mean               -0.044245064
Policy mu Std                0.62360173
Policy mu Max                5.4495864
Policy mu Min                -2.7068458
Policy log std Mean          -1.0170336
Policy log std Std           0.23997095
Policy log std Max           0.008474231
Policy log std Min           -2.1786551
Z mean eval                  1.0213834
Z variance eval              0.018307667
total_rewards                [ 384.72293076  234.06648719  254.55411583  243.11563198  894.81976689
 1960.53083875  318.84544121 1044.04125915   10.96828909  258.12066405]
total_rewards_mean           560.3785424900175
total_rewards_std            555.8125120131714
total_rewards_max            1960.5308387466803
total_rewards_min            10.968289090294808
Number of train steps total  636000
Number of env steps total    552984
Number of rollouts total     0
Train Time (s)               144.76395819988102
(Previous) Eval Time (s)     7.03263327293098
Sample Time (s)              7.300448587629944
Epoch Time (s)               159.09704006044194
Total Train Time (s)         26387.321364850737
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:40:24.102379 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #158 | Epoch Duration: 159.18925738334656
2020-01-11 15:40:24.102517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0205466
Z variance train             0.018261962
KL Divergence                18.996925
KL Loss                      1.8996925
QF Loss                      655.3761
VF Loss                      250.26447
Policy Loss                  -869.8758
Q Predictions Mean           858.629
Q Predictions Std            386.98648
Q Predictions Max            1331.2859
Q Predictions Min            -13.295248
V Predictions Mean           874.0095
V Predictions Std            382.9715
V Predictions Max            1341.7653
V Predictions Min            10.203704
Log Pis Mean                 -0.028251305
Log Pis Std                  3.4981213
Log Pis Max                  18.28951
Log Pis Min                  -10.00412
Policy mu Mean               -0.026927287
Policy mu Std                0.59602195
Policy mu Max                2.982004
Policy mu Min                -2.6523576
Policy log std Mean          -1.0092821
Policy log std Std           0.23889574
Policy log std Max           -0.43175638
Policy log std Min           -2.3159237
Z mean eval                  1.2451787
Z variance eval              0.010476274
total_rewards                [2351.47349518 3870.12296597  647.58084306 1964.31958251  859.82255975
 1075.70011656  549.8560084  3834.17053085  854.66912684  360.3117772 ]
total_rewards_mean           1636.8027006321731
total_rewards_std            1255.1444415139595
total_rewards_max            3870.122965973569
total_rewards_min            360.3117771997879
Number of train steps total  640000
Number of env steps total    557325
Number of rollouts total     0
Train Time (s)               148.2654293589294
(Previous) Eval Time (s)     15.725560580845922
Sample Time (s)              7.159033984411508
Epoch Time (s)               171.15002392418683
Total Train Time (s)         26558.586657957174
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:43:15.368849 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #159 | Epoch Duration: 171.26623964309692
2020-01-11 15:43:15.368981 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2415801
Z variance train             0.010316421
KL Divergence                21.700638
KL Loss                      2.1700637
QF Loss                      818.328
VF Loss                      748.35693
Policy Loss                  -917.20416
Q Predictions Mean           908.71643
Q Predictions Std            392.60144
Q Predictions Max            1449.4968
Q Predictions Min            -80.318436
V Predictions Mean           907.5782
V Predictions Std            385.13058
V Predictions Max            1434.6682
V Predictions Min            189.97577
Log Pis Mean                 -0.102384076
Log Pis Std                  3.370509
Log Pis Max                  15.931143
Log Pis Min                  -9.852452
Policy mu Mean               -0.020372787
Policy mu Std                0.60854083
Policy mu Max                3.198028
Policy mu Min                -3.170894
Policy log std Mean          -0.98624974
Policy log std Std           0.2453851
Policy log std Max           -0.24143547
Policy log std Min           -2.1569724
Z mean eval                  1.1807494
Z variance eval              0.020896753
total_rewards                [1342.3395705   573.12432722 1473.46294474 2483.63925515 1066.40156697
  376.99817265 2608.02397018 3234.1060384  3574.85911205 1332.54605666]
total_rewards_mean           1806.5501014519018
total_rewards_std            1045.44434623141
total_rewards_max            3574.859112054888
total_rewards_min            376.99817264794603
Number of train steps total  644000
Number of env steps total    562295
Number of rollouts total     0
Train Time (s)               146.3050698977895
(Previous) Eval Time (s)     10.906312722712755
Sample Time (s)              7.8084933357313275
Epoch Time (s)               165.0198759562336
Total Train Time (s)         26723.687530863564
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:46:00.471350 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #160 | Epoch Duration: 165.1022744178772
2020-01-11 15:46:00.471480 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.17746
Z variance train             0.020813847
KL Divergence                20.293633
KL Loss                      2.0293634
QF Loss                      1014.1958
VF Loss                      165.75987
Policy Loss                  -930.62695
Q Predictions Mean           921.0543
Q Predictions Std            393.38794
Q Predictions Max            1380.5564
Q Predictions Min            88.4962
V Predictions Mean           933.7384
V Predictions Std            388.70135
V Predictions Max            1383.5883
V Predictions Min            237.03706
Log Pis Mean                 0.09187248
Log Pis Std                  3.4586236
Log Pis Max                  25.115126
Log Pis Min                  -8.053253
Policy mu Mean               -0.052901104
Policy mu Std                0.59771955
Policy mu Max                2.6889617
Policy mu Min                -5.788378
Policy log std Mean          -1.0146894
Policy log std Std           0.2560321
Policy log std Max           -0.39014357
Policy log std Min           -2.0065153
Z mean eval                  1.0650456
Z variance eval              0.007897704
total_rewards                [  60.40433832  656.60356224 3414.02481773 1668.66213393   69.96017962
 1365.71881774 1040.04060131  711.75082876 3122.95552724 2016.97180259]
total_rewards_mean           1412.7092609473675
total_rewards_std            1104.3859662130817
total_rewards_max            3414.0248177337903
total_rewards_min            60.40433832455527
Number of train steps total  648000
Number of env steps total    568382
Number of rollouts total     0
Train Time (s)               146.87246039882302
(Previous) Eval Time (s)     8.66145056206733
Sample Time (s)              6.61017378885299
Epoch Time (s)               162.14408474974334
Total Train Time (s)         26885.923679097556
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:48:42.711519 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #161 | Epoch Duration: 162.2399251461029
2020-01-11 15:48:42.711710 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #161 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0675052
Z variance train             0.007910441
KL Divergence                21.377457
KL Loss                      2.1377456
QF Loss                      1086.4585
VF Loss                      206.08603
Policy Loss                  -889.2783
Q Predictions Mean           879.13434
Q Predictions Std            386.4773
Q Predictions Max            1394.8896
Q Predictions Min            -70.77731
V Predictions Mean           891.65173
V Predictions Std            381.13083
V Predictions Max            1389.2461
V Predictions Min            -7.787405
Log Pis Mean                 0.13126357
Log Pis Std                  3.6969168
Log Pis Max                  18.78806
Log Pis Min                  -8.266052
Policy mu Mean               -0.024146836
Policy mu Std                0.5979893
Policy mu Max                3.2261703
Policy mu Min                -2.6618614
Policy log std Mean          -1.0186884
Policy log std Std           0.25221285
Policy log std Max           -0.32862115
Policy log std Min           -2.2157733
Z mean eval                  1.011504
Z variance eval              0.05106209
total_rewards                [1.02833054e+03 3.88075164e+03 3.52465494e+03 2.47567690e+03
 3.55415721e+03 8.56714416e+02 1.06701824e+03 1.54665379e+03
 3.62808780e+03 3.19474857e+00]
total_rewards_mean           2156.5240224327868
total_rewards_std            1349.9480428934053
total_rewards_max            3880.7516448765036
total_rewards_min            3.1947485701845855
Number of train steps total  652000
Number of env steps total    575242
Number of rollouts total     0
Train Time (s)               146.29476325633004
(Previous) Eval Time (s)     15.31399170262739
Sample Time (s)              7.388039338868111
Epoch Time (s)               168.99679429782555
Total Train Time (s)         27055.004054404795
Epoch                        162
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:51:31.792108 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #162 | Epoch Duration: 169.08026885986328
2020-01-11 15:51:31.792227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0039468
Z variance train             0.052235283
KL Divergence                18.542982
KL Loss                      1.8542982
QF Loss                      1389.076
VF Loss                      373.6712
Policy Loss                  -895.82947
Q Predictions Mean           885.5868
Q Predictions Std            386.74188
Q Predictions Max            1340.3735
Q Predictions Min            -56.791367
V Predictions Mean           897.3336
V Predictions Std            374.07596
V Predictions Max            1323.8823
V Predictions Min            42.5532
Log Pis Mean                 0.8564706
Log Pis Std                  4.413121
Log Pis Max                  23.382425
Log Pis Min                  -7.452545
Policy mu Mean               -0.018434796
Policy mu Std                0.66184676
Policy mu Max                4.487566
Policy mu Min                -4.600228
Policy log std Mean          -1.0710766
Policy log std Std           0.2815993
Policy log std Max           -0.0986073
Policy log std Min           -2.5613475
Z mean eval                  0.97921383
Z variance eval              0.01718895
total_rewards                [ 278.56583452 3544.56309536 3555.13793756 3489.91944542  334.00811936
  177.66774895  726.37688125 1424.59152799 3527.6418119  2388.84166977]
total_rewards_mean           1944.7314072087581
total_rewards_std            1431.4782713791667
total_rewards_max            3555.1379375629635
total_rewards_min            177.66774894866737
Number of train steps total  656000
Number of env steps total    581609
Number of rollouts total     0
Train Time (s)               146.96101257996634
(Previous) Eval Time (s)     13.977749282959849
Sample Time (s)              6.19791702972725
Epoch Time (s)               167.13667889265344
Total Train Time (s)         27222.230934622232
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:54:19.024679 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #163 | Epoch Duration: 167.23234939575195
2020-01-11 15:54:19.024846 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97856253
Z variance train             0.017348927
KL Divergence                19.82147
KL Loss                      1.9821471
QF Loss                      744.87665
VF Loss                      194.91312
Policy Loss                  -862.72766
Q Predictions Mean           855.1814
Q Predictions Std            437.43115
Q Predictions Max            1382.8926
Q Predictions Min            -31.958694
V Predictions Mean           866.9739
V Predictions Std            430.8123
V Predictions Max            1392.1165
V Predictions Min            27.039894
Log Pis Mean                 0.008026306
Log Pis Std                  3.6814327
Log Pis Max                  21.384901
Log Pis Min                  -6.4326506
Policy mu Mean               -0.08002081
Policy mu Std                0.5959583
Policy mu Max                4.0297513
Policy mu Min                -2.707185
Policy log std Mean          -1.0070316
Policy log std Std           0.26590762
Policy log std Max           -0.30051267
Policy log std Min           -2.3678846
Z mean eval                  1.0872523
Z variance eval              0.020450128
total_rewards                [ 687.37624718 3548.32288387 3734.1360636  2733.18012669 3774.49298701
 1493.71565515 1040.16227936 3523.03045238 2775.00326671 3288.67352148]
total_rewards_mean           2659.8093483424127
total_rewards_std            1105.3936406929863
total_rewards_max            3774.4929870141887
total_rewards_min            687.3762471809791
Number of train steps total  660000
Number of env steps total    588663
Number of rollouts total     0
Train Time (s)               145.88213396118954
(Previous) Eval Time (s)     20.31838615424931
Sample Time (s)              7.802074397914112
Epoch Time (s)               174.00259451335296
Total Train Time (s)         27396.322958468925
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:57:13.115642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #164 | Epoch Duration: 174.09066152572632
2020-01-11 15:57:13.115811 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0981131
Z variance train             0.01949813
KL Divergence                19.322495
KL Loss                      1.9322494
QF Loss                      712.43427
VF Loss                      233.19695
Policy Loss                  -949.67755
Q Predictions Mean           942.2771
Q Predictions Std            387.02753
Q Predictions Max            1415.2144
Q Predictions Min            -3.1921413
V Predictions Mean           948.9724
V Predictions Std            382.25797
V Predictions Max            1404.9141
V Predictions Min            89.19729
Log Pis Mean                 0.26908636
Log Pis Std                  3.9962502
Log Pis Max                  27.548784
Log Pis Min                  -9.316134
Policy mu Mean               -0.042648036
Policy mu Std                0.62767106
Policy mu Max                3.3185656
Policy mu Min                -3.3527982
Policy log std Mean          -1.0187633
Policy log std Std           0.2489064
Policy log std Max           -0.30750448
Policy log std Min           -2.2095695
Z mean eval                  1.0401974
Z variance eval              0.010807996
total_rewards                [1578.04284186 3919.48210061 3715.89444154 2061.52814306  324.65855043
  786.6348297  1350.29163655 3838.89298232  110.75665972 3668.67863836]
total_rewards_mean           2135.4860824138686
total_rewards_std            1451.3226796081365
total_rewards_max            3919.482100608182
total_rewards_min            110.75665972116812
Number of train steps total  664000
Number of env steps total    594318
Number of rollouts total     0
Train Time (s)               146.02888339292258
(Previous) Eval Time (s)     13.758023425936699
Sample Time (s)              7.325979315210134
Epoch Time (s)               167.1128861340694
Total Train Time (s)         27563.52201675158
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:00:00.321339 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #165 | Epoch Duration: 167.20535588264465
2020-01-11 16:00:00.321665 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0444131
Z variance train             0.010770509
KL Divergence                20.466846
KL Loss                      2.0466847
QF Loss                      725.2663
VF Loss                      189.23865
Policy Loss                  -897.42316
Q Predictions Mean           891.1382
Q Predictions Std            398.96906
Q Predictions Max            1416.0942
Q Predictions Min            -9.518065
V Predictions Mean           900.4908
V Predictions Std            394.62643
V Predictions Max            1409.9294
V Predictions Min            28.079458
Log Pis Mean                 0.12399387
Log Pis Std                  3.4226036
Log Pis Max                  19.189423
Log Pis Min                  -7.432661
Policy mu Mean               -0.031485777
Policy mu Std                0.58605427
Policy mu Max                2.4567766
Policy mu Min                -3.4874601
Policy log std Mean          -1.0052139
Policy log std Std           0.26372254
Policy log std Max           -0.46325895
Policy log std Min           -2.4082246
Z mean eval                  1.0494113
Z variance eval              0.008640242
total_rewards                [2705.0892341  3885.10769831 3752.39511504 3616.18247437 3735.00713472
 1505.8710834   867.89981019 2887.41985177  236.74566419   61.4807555 ]
total_rewards_mean           2325.319882158394
total_rewards_std            1444.5029153841947
total_rewards_max            3885.107698307673
total_rewards_min            61.4807555049705
Number of train steps total  668000
Number of env steps total    599483
Number of rollouts total     0
Train Time (s)               147.3594272644259
(Previous) Eval Time (s)     15.091691732872277
Sample Time (s)              7.3167430106550455
Epoch Time (s)               169.76786200795323
Total Train Time (s)         27733.37846473558
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:02:50.177003 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #166 | Epoch Duration: 169.85512495040894
2020-01-11 16:02:50.177130 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0545168
Z variance train             0.008641476
KL Divergence                21.450691
KL Loss                      2.1450691
QF Loss                      1060.1661
VF Loss                      175.72388
Policy Loss                  -856.9078
Q Predictions Mean           850.2146
Q Predictions Std            426.79434
Q Predictions Max            1422.1353
Q Predictions Min            76.18966
V Predictions Mean           853.9656
V Predictions Std            420.91165
V Predictions Max            1400.925
V Predictions Min            232.92397
Log Pis Mean                 -8.291751e-05
Log Pis Std                  3.752019
Log Pis Max                  23.955425
Log Pis Min                  -7.5189147
Policy mu Mean               -0.04068973
Policy mu Std                0.5775633
Policy mu Max                4.6533318
Policy mu Min                -5.331272
Policy log std Mean          -1.009217
Policy log std Std           0.26985943
Policy log std Max           -0.4515264
Policy log std Min           -2.2992682
Z mean eval                  1.0952551
Z variance eval              0.006560459
total_rewards                [ 499.24195594  379.27899305  952.10673309 3713.32141586 3840.3376409
  379.8648501   716.86383999 1463.96048958  578.76352123 3534.3738131 ]
total_rewards_mean           1605.811325283082
total_rewards_std            1402.7967840901908
total_rewards_max            3840.3376408979607
total_rewards_min            379.27899304630546
Number of train steps total  672000
Number of env steps total    607576
Number of rollouts total     0
Train Time (s)               147.5881339898333
(Previous) Eval Time (s)     14.93535296805203
Sample Time (s)              6.442413163371384
Epoch Time (s)               168.9659001212567
Total Train Time (s)         27902.43296235893
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:05:39.233786 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #167 | Epoch Duration: 169.0565631389618
2020-01-11 16:05:39.233914 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0961616
Z variance train             0.006576507
KL Divergence                22.720278
KL Loss                      2.2720277
QF Loss                      940.95544
VF Loss                      115.264084
Policy Loss                  -902.7235
Q Predictions Mean           892.3324
Q Predictions Std            414.35382
Q Predictions Max            1442.8357
Q Predictions Min            -76.883
V Predictions Mean           901.35443
V Predictions Std            406.0282
V Predictions Max            1443.8044
V Predictions Min            117.64781
Log Pis Mean                 -0.25219402
Log Pis Std                  3.1324916
Log Pis Max                  19.576468
Log Pis Min                  -7.9276767
Policy mu Mean               -0.05748818
Policy mu Std                0.5605869
Policy mu Max                3.2707696
Policy mu Min                -2.738452
Policy log std Mean          -0.9949126
Policy log std Std           0.23804346
Policy log std Max           -0.27324492
Policy log std Min           -2.0929496
Z mean eval                  1.0530932
Z variance eval              0.0049571684
total_rewards                [3019.55517925  785.00942541  875.12187293 3708.33137788 2627.75825045
 3733.5908848   473.85659153   34.3346833   338.83468415 2127.43903827]
total_rewards_mean           1772.3831987949484
total_rewards_std            1361.9629292972904
total_rewards_max            3733.590884797442
total_rewards_min            34.33468329591827
Number of train steps total  676000
Number of env steps total    612567
Number of rollouts total     0
Train Time (s)               140.37053853506222
(Previous) Eval Time (s)     10.433592772111297
Sample Time (s)              7.717065311968327
Epoch Time (s)               158.52119661914185
Total Train Time (s)         28061.13019990083
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:08:17.935803 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #168 | Epoch Duration: 158.70175623893738
2020-01-11 16:08:17.936093 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0566355
Z variance train             0.0049720206
KL Divergence                22.867918
KL Loss                      2.2867918
QF Loss                      1329.29
VF Loss                      254.98616
Policy Loss                  -931.27466
Q Predictions Mean           927.41235
Q Predictions Std            382.3423
Q Predictions Max            1395.5898
Q Predictions Min            -14.001715
V Predictions Mean           938.0126
V Predictions Std            379.9568
V Predictions Max            1411.1932
V Predictions Min            -16.402298
Log Pis Mean                 0.10174037
Log Pis Std                  3.16448
Log Pis Max                  11.262628
Log Pis Min                  -6.9850745
Policy mu Mean               -0.070740655
Policy mu Std                0.58793384
Policy mu Max                2.55076
Policy mu Min                -2.851095
Policy log std Mean          -1.0120635
Policy log std Std           0.2572967
Policy log std Max           -0.089438975
Policy log std Min           -2.0337977
Z mean eval                  1.037844
Z variance eval              0.02331159
total_rewards                [2395.53022449 1414.71960344 3512.18751689 1480.86867635  742.61454078
 1377.56934985 2863.02521682  430.51120813  431.30331563 1036.92080192]
total_rewards_mean           1568.5250454296463
total_rewards_std            987.8449212103103
total_rewards_max            3512.1875168904535
total_rewards_min            430.5112081254691
Number of train steps total  680000
Number of env steps total    620575
Number of rollouts total     0
Train Time (s)               141.37924952199683
(Previous) Eval Time (s)     9.167286767158657
Sample Time (s)              7.689139644149691
Epoch Time (s)               158.23567593330517
Total Train Time (s)         28219.45036348654
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:10:56.256238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #169 | Epoch Duration: 158.31996417045593
2020-01-11 16:10:56.256353 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0326524
Z variance train             0.02372788
KL Divergence                18.57534
KL Loss                      1.857534
QF Loss                      1788.1694
VF Loss                      317.3422
Policy Loss                  -944.3318
Q Predictions Mean           933.1269
Q Predictions Std            375.45145
Q Predictions Max            1374.4194
Q Predictions Min            119.1539
V Predictions Mean           952.4855
V Predictions Std            367.94904
V Predictions Max            1389.2607
V Predictions Min            165.65681
Log Pis Mean                 0.4524203
Log Pis Std                  3.8473783
Log Pis Max                  22.827572
Log Pis Min                  -7.46233
Policy mu Mean               -0.03378184
Policy mu Std                0.6561189
Policy mu Max                4.5292587
Policy mu Min                -4.3155546
Policy log std Mean          -1.0276482
Policy log std Std           0.26684892
Policy log std Max           0.38626087
Policy log std Min           -2.3010616
Z mean eval                  1.1612172
Z variance eval              0.025389338
total_rewards                [2102.36064568   38.93869366  357.3759548   901.40410347 3502.91360852
 3722.46493786  275.35719474  805.96281836  680.13728821  423.76139266]
total_rewards_mean           1281.0676637968493
total_rewards_std            1282.3824275641068
total_rewards_max            3722.464937857948
total_rewards_min            38.93869366044213
Number of train steps total  684000
Number of env steps total    627572
Number of rollouts total     0
Train Time (s)               140.42691310029477
(Previous) Eval Time (s)     12.624649965204298
Sample Time (s)              6.565829759929329
Epoch Time (s)               159.6173928254284
Total Train Time (s)         28379.16231651092
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:13:35.974446 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #170 | Epoch Duration: 159.71795201301575
2020-01-11 16:13:35.974814 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.153197
Z variance train             0.025139267
KL Divergence                18.805206
KL Loss                      1.8805207
QF Loss                      1188.9418
VF Loss                      272.2414
Policy Loss                  -933.1222
Q Predictions Mean           924.9
Q Predictions Std            410.7536
Q Predictions Max            1456.4398
Q Predictions Min            -28.200495
V Predictions Mean           928.5359
V Predictions Std            398.24234
V Predictions Max            1438.349
V Predictions Min            22.547794
Log Pis Mean                 0.21642967
Log Pis Std                  3.3406596
Log Pis Max                  16.576513
Log Pis Min                  -6.5897145
Policy mu Mean               0.005930921
Policy mu Std                0.6061332
Policy mu Max                3.589585
Policy mu Min                -3.0049825
Policy log std Mean          -1.0264678
Policy log std Std           0.25717193
Policy log std Max           -0.3459018
Policy log std Min           -2.2897315
Z mean eval                  1.0436785
Z variance eval              0.03964549
total_rewards                [3834.38357239 3038.84028301 3073.17308844 3705.99553626  296.70563185
 3734.08023268 3561.04894815 2634.48154776 3951.98455528 1389.0590922 ]
total_rewards_mean           2921.975248804521
total_rewards_std            1137.4123696143645
total_rewards_max            3951.984555282734
total_rewards_min            296.7056318509827
Number of train steps total  688000
Number of env steps total    632312
Number of rollouts total     0
Train Time (s)               141.5796744269319
(Previous) Eval Time (s)     19.307071352843195
Sample Time (s)              7.551475883927196
Epoch Time (s)               168.43822166370228
Total Train Time (s)         28547.68999965256
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:16:24.503585 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #171 | Epoch Duration: 168.52855038642883
2020-01-11 16:16:24.503762 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0497516
Z variance train             0.039555643
KL Divergence                17.875889
KL Loss                      1.787589
QF Loss                      968.32324
VF Loss                      323.34094
Policy Loss                  -938.5216
Q Predictions Mean           930.1937
Q Predictions Std            384.6976
Q Predictions Max            1412.2877
Q Predictions Min            -23.235376
V Predictions Mean           938.8545
V Predictions Std            372.73117
V Predictions Max            1406.5214
V Predictions Min            16.703321
Log Pis Mean                 0.27770454
Log Pis Std                  3.5621238
Log Pis Max                  16.448612
Log Pis Min                  -7.0503244
Policy mu Mean               -0.043982163
Policy mu Std                0.58958644
Policy mu Max                2.8242571
Policy mu Min                -4.268088
Policy log std Mean          -1.0470612
Policy log std Std           0.27483407
Policy log std Max           -0.2803654
Policy log std Min           -2.5047684
Z mean eval                  0.97198343
Z variance eval              0.0059545734
total_rewards                [4080.93625384   96.42988276 3437.5332962   865.28077023  203.46465176
  704.23846064  507.51478298 1029.70545085  395.4505724   255.76579654]
total_rewards_mean           1157.6319918202223
total_rewards_std            1338.079917698776
total_rewards_max            4080.9362538426917
total_rewards_min            96.42988276291644
Number of train steps total  692000
Number of env steps total    636804
Number of rollouts total     0
Train Time (s)               146.04565305821598
(Previous) Eval Time (s)     11.740731060039252
Sample Time (s)              7.243667897302657
Epoch Time (s)               165.03005201555789
Total Train Time (s)         28712.80683875736
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:19:09.621711 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #172 | Epoch Duration: 165.11782717704773
2020-01-11 16:19:09.621833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96308887
Z variance train             0.00597347
KL Divergence                21.58579
KL Loss                      2.158579
QF Loss                      797.24365
VF Loss                      309.74048
Policy Loss                  -928.852
Q Predictions Mean           921.069
Q Predictions Std            402.18597
Q Predictions Max            1440.9935
Q Predictions Min            -24.395638
V Predictions Mean           938.9133
V Predictions Std            394.23712
V Predictions Max            1439.5829
V Predictions Min            247.56442
Log Pis Mean                 -0.031899802
Log Pis Std                  3.463646
Log Pis Max                  26.813732
Log Pis Min                  -10.962921
Policy mu Mean               -0.0043022814
Policy mu Std                0.58488274
Policy mu Max                3.2152133
Policy mu Min                -3.3189168
Policy log std Mean          -1.0146182
Policy log std Std           0.24010904
Policy log std Max           -0.4223547
Policy log std Min           -2.0560558
Z mean eval                  1.045769
Z variance eval              0.016079886
total_rewards                [ 176.75408404 3887.79423371 3902.4113901  2996.79677571 3939.98850441
 2297.93734339 1214.37433946    4.73325925 1592.22229539 3913.1766643 ]
total_rewards_mean           2392.6188889767627
total_rewards_std            1491.1879974247167
total_rewards_max            3939.988504413094
total_rewards_min            4.733259251942876
Number of train steps total  696000
Number of env steps total    645202
Number of rollouts total     0
Train Time (s)               144.8548553059809
(Previous) Eval Time (s)     15.308349866885692
Sample Time (s)              7.2540686978027225
Epoch Time (s)               167.4172738706693
Total Train Time (s)         28880.31519569084
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:21:57.130770 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #173 | Epoch Duration: 167.5088415145874
2020-01-11 16:21:57.130895 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0425448
Z variance train             0.015926283
KL Divergence                20.654385
KL Loss                      2.0654385
QF Loss                      1148.3765
VF Loss                      235.7459
Policy Loss                  -911.4351
Q Predictions Mean           901.9332
Q Predictions Std            410.71277
Q Predictions Max            1416.499
Q Predictions Min            -17.854954
V Predictions Mean           908.58014
V Predictions Std            402.9025
V Predictions Max            1409.3799
V Predictions Min            -22.043224
Log Pis Mean                 0.1284919
Log Pis Std                  3.9991665
Log Pis Max                  23.379066
Log Pis Min                  -9.485185
Policy mu Mean               -0.02780201
Policy mu Std                0.6476701
Policy mu Max                4.6460776
Policy mu Min                -3.755172
Policy log std Mean          -1.0131772
Policy log std Std           0.26208702
Policy log std Max           -0.397762
Policy log std Min           -2.165179
Z mean eval                  1.0887935
Z variance eval              0.021708129
total_rewards                [3825.2516158  3673.34677878 3930.53546795 3750.57893519 3689.32838959
 2789.6782666  3783.64184534 3500.13889929 3885.46337364 3819.05578243]
total_rewards_mean           3664.7019354594922
total_rewards_std            313.68049991401307
total_rewards_max            3930.535467946812
total_rewards_min            2789.678266595298
Number of train steps total  700000
Number of env steps total    649979
Number of rollouts total     0
Train Time (s)               146.60503164771944
(Previous) Eval Time (s)     21.41675903275609
Sample Time (s)              7.086646975949407
Epoch Time (s)               175.10843765642494
Total Train Time (s)         29055.50881022541
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:24:52.328309 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #174 | Epoch Duration: 175.19732236862183
2020-01-11 16:24:52.328423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0821835
Z variance train             0.02206498
KL Divergence                19.160473
KL Loss                      1.9160473
QF Loss                      862.7891
VF Loss                      134.52246
Policy Loss                  -960.62787
Q Predictions Mean           954.4864
Q Predictions Std            416.2058
Q Predictions Max            1438.9879
Q Predictions Min            80.730804
V Predictions Mean           961.39
V Predictions Std            410.56186
V Predictions Max            1447.2378
V Predictions Min            135.11282
Log Pis Mean                 0.33286464
Log Pis Std                  3.3137987
Log Pis Max                  16.456316
Log Pis Min                  -8.342206
Policy mu Mean               -0.049520157
Policy mu Std                0.57108974
Policy mu Max                2.9674797
Policy mu Min                -2.982294
Policy log std Mean          -1.0668929
Policy log std Std           0.27564704
Policy log std Max           -0.2720297
Policy log std Min           -2.3353682
Z mean eval                  1.127845
Z variance eval              0.012438955
total_rewards                [1803.61127528 2856.52945582 3686.89418444  828.04024025 3925.15514773
 3972.62775675 3913.58096308 1994.11715302 3787.28006266 2158.05721906]
total_rewards_mean           2892.5893458103324
total_rewards_std            1072.5118615620554
total_rewards_max            3972.62775675016
total_rewards_min            828.0402402474235
Number of train steps total  704000
Number of env steps total    655549
Number of rollouts total     0
Train Time (s)               147.43143950309604
(Previous) Eval Time (s)     16.520492401905358
Sample Time (s)              6.536128900945187
Epoch Time (s)               170.4880608059466
Total Train Time (s)         29226.091201290023
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:27:42.909570 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #175 | Epoch Duration: 170.58105945587158
2020-01-11 16:27:42.909685 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #175 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1215285
Z variance train             0.012349424
KL Divergence                20.022236
KL Loss                      2.0022237
QF Loss                      841.1379
VF Loss                      313.25223
Policy Loss                  -929.9901
Q Predictions Mean           925.0065
Q Predictions Std            399.24628
Q Predictions Max            1449.3947
Q Predictions Min            -17.746557
V Predictions Mean           924.9938
V Predictions Std            393.53394
V Predictions Max            1440.0709
V Predictions Min            -42.67958
Log Pis Mean                 0.59359145
Log Pis Std                  3.462956
Log Pis Max                  21.814137
Log Pis Min                  -6.229167
Policy mu Mean               0.003412217
Policy mu Std                0.6213056
Policy mu Max                4.0936246
Policy mu Min                -3.604299
Policy log std Mean          -1.0395772
Policy log std Std           0.26438504
Policy log std Max           -0.035505116
Policy log std Min           -2.2928233
Z mean eval                  1.0326564
Z variance eval              0.17410183
total_rewards                [ 239.24431258 2669.42866424 1436.43764601  123.41906684 4188.8686073
 1458.66202704 1511.09331084  689.04114841 4055.27847361 3746.61376656]
total_rewards_mean           2011.8087023428386
total_rewards_std            1473.1878391498894
total_rewards_max            4188.868607300512
total_rewards_min            123.41906684232455
Number of train steps total  708000
Number of env steps total    660034
Number of rollouts total     0
Train Time (s)               145.97102109203115
(Previous) Eval Time (s)     12.217901322059333
Sample Time (s)              6.0176416472531855
Epoch Time (s)               164.20656406134367
Total Train Time (s)         29390.396917414386
Epoch                        176
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:30:27.218885 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #176 | Epoch Duration: 164.3091003894806
2020-01-11 16:30:27.219035 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0366609
Z variance train             0.1728474
KL Divergence                18.314234
KL Loss                      1.8314234
QF Loss                      1002.7901
VF Loss                      336.906
Policy Loss                  -849.3077
Q Predictions Mean           843.1445
Q Predictions Std            374.07257
Q Predictions Max            1350.7921
Q Predictions Min            3.6790879
V Predictions Mean           849.83594
V Predictions Std            369.09793
V Predictions Max            1326.3549
V Predictions Min            131.13434
Log Pis Mean                 0.38858002
Log Pis Std                  3.6251945
Log Pis Max                  20.313564
Log Pis Min                  -8.855909
Policy mu Mean               -0.02037813
Policy mu Std                0.6260773
Policy mu Max                3.9823108
Policy mu Min                -3.7370064
Policy log std Mean          -1.0319916
Policy log std Std           0.25822473
Policy log std Max           -0.12756681
Policy log std Min           -2.4475892
Z mean eval                  1.0863974
Z variance eval              0.011915296
total_rewards                [3377.07191517 4073.24634784  796.77477609 3484.59863869 2783.38765377
 1098.72643664 3804.85518609 3853.70635819 3571.37387001   60.61390665]
total_rewards_mean           2690.435508913418
total_rewards_std            1393.9011310638887
total_rewards_max            4073.246347836382
total_rewards_min            60.6139066469637
Number of train steps total  712000
Number of env steps total    665782
Number of rollouts total     0
Train Time (s)               146.11748628411442
(Previous) Eval Time (s)     15.620050852186978
Sample Time (s)              6.3942778231576085
Epoch Time (s)               168.131814959459
Total Train Time (s)         29558.615296470933
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:33:15.437152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #177 | Epoch Duration: 168.217999458313
2020-01-11 16:33:15.437267 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0928411
Z variance train             0.011999942
KL Divergence                20.957636
KL Loss                      2.0957637
QF Loss                      840.2367
VF Loss                      202.91632
Policy Loss                  -939.3268
Q Predictions Mean           937.17834
Q Predictions Std            411.50522
Q Predictions Max            1437.835
Q Predictions Min            237.90097
V Predictions Mean           936.33167
V Predictions Std            408.51614
V Predictions Max            1431.1527
V Predictions Min            236.5803
Log Pis Mean                 -0.17742805
Log Pis Std                  3.2931128
Log Pis Max                  15.632788
Log Pis Min                  -8.381136
Policy mu Mean               -0.037050463
Policy mu Std                0.5664888
Policy mu Max                2.5863793
Policy mu Min                -2.6942813
Policy log std Mean          -1.0211589
Policy log std Std           0.27945223
Policy log std Max           -0.3829412
Policy log std Min           -2.320962
Z mean eval                  1.182355
Z variance eval              0.028874317
total_rewards                [1644.05209767  727.50320849 2284.8721183  3219.40736342 3759.20259334
 1109.10330957  228.54981874 3891.96727893 1854.77040238 2921.84811557]
total_rewards_mean           2164.12763064163
total_rewards_std            1205.057543637963
total_rewards_max            3891.9672789258484
total_rewards_min            228.54981873612118
Number of train steps total  716000
Number of env steps total    671741
Number of rollouts total     0
Train Time (s)               145.2770688580349
(Previous) Eval Time (s)     14.056225365959108
Sample Time (s)              6.87294396944344
Epoch Time (s)               166.20623819343746
Total Train Time (s)         29724.968650743365
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:36:01.791523 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #178 | Epoch Duration: 166.35416746139526
2020-01-11 16:36:01.791639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1765416
Z variance train             0.02934685
KL Divergence                19.633953
KL Loss                      1.9633954
QF Loss                      669.0961
VF Loss                      314.96246
Policy Loss                  -986.47186
Q Predictions Mean           981.76434
Q Predictions Std            415.02914
Q Predictions Max            1490.7592
Q Predictions Min            39.37907
V Predictions Mean           995.3113
V Predictions Std            412.12384
V Predictions Max            1497.3967
V Predictions Min            229.53162
Log Pis Mean                 0.10888404
Log Pis Std                  3.169324
Log Pis Max                  16.26733
Log Pis Min                  -8.824646
Policy mu Mean               -0.0823468
Policy mu Std                0.6073553
Policy mu Max                2.6606982
Policy mu Min                -2.437638
Policy log std Mean          -0.9903227
Policy log std Std           0.2443406
Policy log std Max           -0.26756006
Policy log std Min           -2.2065372
Z mean eval                  1.1395782
Z variance eval              0.016506335
total_rewards                [3809.78235089 2384.09851254 3999.82088338 3334.05544788 4075.73735568
 4134.27526156 4209.15786835 1974.80139738 3979.71550571 4012.77974126]
total_rewards_mean           3591.42243246475
total_rewards_std            747.7274524984346
total_rewards_max            4209.157868349629
total_rewards_min            1974.8013973829775
Number of train steps total  720000
Number of env steps total    678505
Number of rollouts total     0
Train Time (s)               146.1040901551023
(Previous) Eval Time (s)     20.42908703815192
Sample Time (s)              7.390756969340146
Epoch Time (s)               173.92393416259438
Total Train Time (s)         29899.00581888389
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:38:55.830042 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #179 | Epoch Duration: 174.03831481933594
2020-01-11 16:38:55.830165 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1345671
Z variance train             0.016285826
KL Divergence                21.380646
KL Loss                      2.1380646
QF Loss                      1203.9839
VF Loss                      650.31714
Policy Loss                  -958.142
Q Predictions Mean           949.3022
Q Predictions Std            419.4468
Q Predictions Max            1446.7035
Q Predictions Min            48.711216
V Predictions Mean           977.1466
V Predictions Std            412.0286
V Predictions Max            1445.6097
V Predictions Min            237.37793
Log Pis Mean                 0.23748542
Log Pis Std                  3.7064154
Log Pis Max                  18.95023
Log Pis Min                  -8.925896
Policy mu Mean               -0.0260934
Policy mu Std                0.6524264
Policy mu Max                3.900603
Policy mu Min                -4.4398656
Policy log std Mean          -1.0163116
Policy log std Std           0.26571813
Policy log std Max           -0.26268172
Policy log std Min           -2.1234262
Z mean eval                  0.9737461
Z variance eval              0.010422665
total_rewards                [3907.40590374 2470.78087065 2980.75630719 1622.78707531 2804.14335982
  558.92308394 4119.40467677 4029.98814078 3922.19723363 1300.76699877]
total_rewards_mean           2771.7153650602004
total_rewards_std            1205.3383192882845
total_rewards_max            4119.404676765751
total_rewards_min            558.9230839404669
Number of train steps total  724000
Number of env steps total    685525
Number of rollouts total     0
Train Time (s)               146.10189644386992
(Previous) Eval Time (s)     19.86610188893974
Sample Time (s)              6.417991494294256
Epoch Time (s)               172.3859898271039
Total Train Time (s)         30071.503635147586
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:41:48.330153 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #180 | Epoch Duration: 172.49989771842957
2020-01-11 16:41:48.330284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9780243
Z variance train             0.0103621185
KL Divergence                21.286535
KL Loss                      2.1286535
QF Loss                      1857.0121
VF Loss                      360.3691
Policy Loss                  -999.39966
Q Predictions Mean           991.53754
Q Predictions Std            364.25082
Q Predictions Max            1437.8455
Q Predictions Min            222.92053
V Predictions Mean           992.2909
V Predictions Std            358.0563
V Predictions Max            1424.6833
V Predictions Min            237.92487
Log Pis Mean                 0.3573315
Log Pis Std                  3.6017475
Log Pis Max                  27.544956
Log Pis Min                  -7.9460044
Policy mu Mean               0.0064782966
Policy mu Std                0.6398793
Policy mu Max                3.4255269
Policy mu Min                -3.1369576
Policy log std Mean          -1.0141066
Policy log std Std           0.24607025
Policy log std Max           -0.30907607
Policy log std Min           -2.1473846
Z mean eval                  1.0636911
Z variance eval              0.018732447
total_rewards                [  58.63120779  260.32706742 3111.57241929  864.77149339 3585.85740014
 1159.87167133 1800.34430004  903.38305351 3428.73871879 1059.83603795]
total_rewards_mean           1623.3333369639122
total_rewards_std            1236.5001813589938
total_rewards_max            3585.857400138214
total_rewards_min            58.63120778940441
Number of train steps total  728000
Number of env steps total    691998
Number of rollouts total     0
Train Time (s)               146.63236178085208
(Previous) Eval Time (s)     14.407768782228231
Sample Time (s)              7.797562898136675
Epoch Time (s)               168.837693461217
Total Train Time (s)         30240.435713221785
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:44:37.263456 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #181 | Epoch Duration: 168.93307280540466
2020-01-11 16:44:37.263593 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0638494
Z variance train             0.018732036
KL Divergence                20.843021
KL Loss                      2.0843022
QF Loss                      1434.2302
VF Loss                      250.05836
Policy Loss                  -968.13794
Q Predictions Mean           958.87256
Q Predictions Std            406.7001
Q Predictions Max            1465.9592
Q Predictions Min            -21.299812
V Predictions Mean           969.69965
V Predictions Std            399.11215
V Predictions Max            1459.7417
V Predictions Min            205.18161
Log Pis Mean                 -0.16992034
Log Pis Std                  3.329415
Log Pis Max                  14.679911
Log Pis Min                  -8.763121
Policy mu Mean               -0.019578956
Policy mu Std                0.5812909
Policy mu Max                3.0845659
Policy mu Min                -2.4393456
Policy log std Mean          -0.99963534
Policy log std Std           0.26569653
Policy log std Max           -0.07305372
Policy log std Min           -2.5917847
Z mean eval                  1.093415
Z variance eval              0.004322523
total_rewards                [3172.40280193 3397.09708445  581.03186357 1761.91697149 2482.43087234
  827.9248712  3643.0568588   357.95810225 2049.71276534 1411.4274854 ]
total_rewards_mean           1968.4959676784515
total_rewards_std            1128.6258771983432
total_rewards_max            3643.0568587986927
total_rewards_min            357.9581022494642
Number of train steps total  732000
Number of env steps total    697694
Number of rollouts total     0
Train Time (s)               147.66074765194207
(Previous) Eval Time (s)     12.254348682705313
Sample Time (s)              7.597250023391098
Epoch Time (s)               167.51234635803849
Total Train Time (s)         30408.035196545068
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:47:24.864922 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #182 | Epoch Duration: 167.6012260913849
2020-01-11 16:47:24.865054 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0878704
Z variance train             0.004313278
KL Divergence                24.349026
KL Loss                      2.4349027
QF Loss                      927.31055
VF Loss                      131.36526
Policy Loss                  -933.39746
Q Predictions Mean           920.49133
Q Predictions Std            415.33893
Q Predictions Max            1437.0493
Q Predictions Min            14.845974
V Predictions Mean           934.52734
V Predictions Std            406.78525
V Predictions Max            1457.6278
V Predictions Min            221.1216
Log Pis Mean                 0.2470214
Log Pis Std                  4.0465136
Log Pis Max                  24.800274
Log Pis Min                  -9.688975
Policy mu Mean               -0.033680603
Policy mu Std                0.6104729
Policy mu Max                2.9424794
Policy mu Min                -3.533311
Policy log std Mean          -1.017217
Policy log std Std           0.27176183
Policy log std Max           -0.28458428
Policy log std Min           -2.230524
Z mean eval                  1.1184976
Z variance eval              0.011788107
total_rewards                [2959.63746146 2423.35214939 2680.6059431   470.53452328  850.39342139
 4172.57165949 1148.84154054 3663.71080045 3852.62048108   72.17656592]
total_rewards_mean           2229.4444546089517
total_rewards_std            1416.2960745656362
total_rewards_max            4172.571659486271
total_rewards_min            72.17656592039644
Number of train steps total  736000
Number of env steps total    703891
Number of rollouts total     0
Train Time (s)               145.96652264520526
(Previous) Eval Time (s)     14.108174736145884
Sample Time (s)              6.543248918838799
Epoch Time (s)               166.61794630018994
Total Train Time (s)         30574.736926055513
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:50:11.569327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #183 | Epoch Duration: 166.70416927337646
2020-01-11 16:50:11.569468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #183 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1203041
Z variance train             0.011761917
KL Divergence                20.060736
KL Loss                      2.0060737
QF Loss                      677.0234
VF Loss                      209.18732
Policy Loss                  -977.12103
Q Predictions Mean           971.194
Q Predictions Std            392.9107
Q Predictions Max            1476.579
Q Predictions Min            5.910309
V Predictions Mean           980.2692
V Predictions Std            388.17862
V Predictions Max            1473.8036
V Predictions Min            250.2231
Log Pis Mean                 0.20043896
Log Pis Std                  3.29221
Log Pis Max                  16.72836
Log Pis Min                  -10.660681
Policy mu Mean               -0.03010184
Policy mu Std                0.60815895
Policy mu Max                3.3220127
Policy mu Min                -3.0905602
Policy log std Mean          -1.0429487
Policy log std Std           0.25873953
Policy log std Max           -0.45466995
Policy log std Min           -2.0846472
Z mean eval                  1.0268651
Z variance eval              0.030869815
total_rewards                [3619.72140357 4067.15490885 3788.79182746 3281.31672667 2925.702225
 3741.26323126  898.63833779 3946.53802759 1410.05039958 1440.79649589]
total_rewards_mean           2911.9973583658384
total_rewards_std            1138.9672043357475
total_rewards_max            4067.154908850328
total_rewards_min            898.6383377899281
Number of train steps total  740000
Number of env steps total    711362
Number of rollouts total     0
Train Time (s)               146.55911250179633
(Previous) Eval Time (s)     16.869463956914842
Sample Time (s)              8.017341976985335
Epoch Time (s)               171.4459184356965
Total Train Time (s)         30746.285248456523
Epoch                        184
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:53:03.118642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #184 | Epoch Duration: 171.54905557632446
2020-01-11 16:53:03.118780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0267096
Z variance train             0.030835876
KL Divergence                18.674326
KL Loss                      1.8674326
QF Loss                      1832.1958
VF Loss                      262.92474
Policy Loss                  -914.7591
Q Predictions Mean           909.9861
Q Predictions Std            426.50836
Q Predictions Max            1462.6415
Q Predictions Min            3.4498134
V Predictions Mean           916.5116
V Predictions Std            421.71942
V Predictions Max            1453.3722
V Predictions Min            221.05183
Log Pis Mean                 -0.36129743
Log Pis Std                  3.4010913
Log Pis Max                  15.120653
Log Pis Min                  -9.355655
Policy mu Mean               -0.040669385
Policy mu Std                0.5356226
Policy mu Max                2.907089
Policy mu Min                -3.215506
Policy log std Mean          -1.0272706
Policy log std Std           0.26633948
Policy log std Max           -0.3778972
Policy log std Min           -2.1304698
Z mean eval                  1.0052081
Z variance eval              0.018388005
total_rewards                [1605.63405744 4116.61753742  645.24079457 1419.05894053 1324.80387454
  554.22686193 4162.95733037 2308.92380733  242.89865522  442.66422479]
total_rewards_mean           1682.302608414559
total_rewards_std            1364.9839174262124
total_rewards_max            4162.957330370555
total_rewards_min            242.8986552193923
Number of train steps total  744000
Number of env steps total    717530
Number of rollouts total     0
Train Time (s)               146.81988630304113
(Previous) Eval Time (s)     14.099216787144542
Sample Time (s)              6.923584480769932
Epoch Time (s)               167.8426875709556
Total Train Time (s)         30914.213376005646
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:55:51.049560 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #185 | Epoch Duration: 167.9306676387787
2020-01-11 16:55:51.049727 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0079492
Z variance train             0.018385068
KL Divergence                18.869785
KL Loss                      1.8869785
QF Loss                      706.34595
VF Loss                      152.61958
Policy Loss                  -998.67804
Q Predictions Mean           991.7105
Q Predictions Std            393.92267
Q Predictions Max            1456.0555
Q Predictions Min            23.420736
V Predictions Mean           997.22534
V Predictions Std            389.96082
V Predictions Max            1440.3551
V Predictions Min            242.49477
Log Pis Mean                 0.006469533
Log Pis Std                  3.1412642
Log Pis Max                  9.996935
Log Pis Min                  -8.957094
Policy mu Mean               -0.06735483
Policy mu Std                0.58458316
Policy mu Max                2.4498684
Policy mu Min                -2.7161927
Policy log std Mean          -1.0433834
Policy log std Std           0.26773533
Policy log std Max           -0.15441525
Policy log std Min           -2.1897154
Z mean eval                  1.1083317
Z variance eval              0.014008805
total_rewards                [3636.55278586 3939.09458907 3943.67013562 1365.70189209 4226.99867884
 4122.65751051 1018.79240172 4018.22221921 3968.50288046  966.60063552]
total_rewards_mean           3120.6793728884136
total_rewards_std            1323.0065419433358
total_rewards_max            4226.998678839935
total_rewards_min            966.600635517199
Number of train steps total  748000
Number of env steps total    721629
Number of rollouts total     0
Train Time (s)               147.7424487322569
(Previous) Eval Time (s)     21.642592302057892
Sample Time (s)              7.607963056303561
Epoch Time (s)               176.99300409061834
Total Train Time (s)         31091.30095162848
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:58:48.139265 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #186 | Epoch Duration: 177.08940410614014
2020-01-11 16:58:48.139433 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.101896
Z variance train             0.013976763
KL Divergence                20.488739
KL Loss                      2.048874
QF Loss                      922.99927
VF Loss                      352.85995
Policy Loss                  -931.03
Q Predictions Mean           926.7663
Q Predictions Std            419.9715
Q Predictions Max            1498.4625
Q Predictions Min            3.7519164
V Predictions Mean           942.6742
V Predictions Std            422.8075
V Predictions Max            1520.4362
V Predictions Min            -63.28724
Log Pis Mean                 0.17105746
Log Pis Std                  3.328094
Log Pis Max                  14.299684
Log Pis Min                  -7.0381374
Policy mu Mean               -0.04137709
Policy mu Std                0.6166219
Policy mu Max                2.4432237
Policy mu Min                -3.9709206
Policy log std Mean          -1.011339
Policy log std Std           0.2579299
Policy log std Max           -0.33960956
Policy log std Min           -2.1977477
Z mean eval                  0.96466273
Z variance eval              0.011331388
total_rewards                [3764.94566272 1805.78294293 3867.98341009  320.54344279 3714.78749921
  103.52499488 2011.85880439 3697.066312   1670.94433866  443.79017797]
total_rewards_mean           2140.1227585638835
total_rewards_std            1456.4923920283306
total_rewards_max            3867.9834100856106
total_rewards_min            103.52499488188715
Number of train steps total  752000
Number of env steps total    726749
Number of rollouts total     0
Train Time (s)               146.07398964604363
(Previous) Eval Time (s)     13.761584427207708
Sample Time (s)              6.35015120357275
Epoch Time (s)               166.1857252768241
Total Train Time (s)         31257.588176565245
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:01:34.429458 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #187 | Epoch Duration: 166.28987431526184
2020-01-11 17:01:34.429696 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96566087
Z variance train             0.01133103
KL Divergence                19.94632
KL Loss                      1.994632
QF Loss                      1126.9502
VF Loss                      228.03497
Policy Loss                  -967.91223
Q Predictions Mean           958.3718
Q Predictions Std            398.83115
Q Predictions Max            1523.0443
Q Predictions Min            -37.197006
V Predictions Mean           971.5521
V Predictions Std            388.92758
V Predictions Max            1528.7806
V Predictions Min            251.6441
Log Pis Mean                 0.690408
Log Pis Std                  4.2196136
Log Pis Max                  19.424011
Log Pis Min                  -9.175593
Policy mu Mean               -0.05828146
Policy mu Std                0.6581722
Policy mu Max                3.11894
Policy mu Min                -3.5609157
Policy log std Mean          -1.0497863
Policy log std Std           0.2806452
Policy log std Max           -0.18795264
Policy log std Min           -2.2930627
Z mean eval                  1.0836462
Z variance eval              0.020322114
total_rewards                [3973.05081309 3765.12299505 3017.86831482 2377.88259006  205.61715941
 3869.472106   3972.83970042 2551.88310428 4114.47834206  655.86714082]
total_rewards_mean           2850.4082265997404
total_rewards_std            1347.0195736664027
total_rewards_max            4114.478342055876
total_rewards_min            205.61715940834716
Number of train steps total  756000
Number of env steps total    734328
Number of rollouts total     0
Train Time (s)               145.35551790799946
(Previous) Eval Time (s)     15.84976252913475
Sample Time (s)              7.466439674142748
Epoch Time (s)               168.67172011127695
Total Train Time (s)         31426.388937205542
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:04:23.232075 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #188 | Epoch Duration: 168.80219650268555
2020-01-11 17:04:23.232255 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0773983
Z variance train             0.020244721
KL Divergence                19.241018
KL Loss                      1.9241018
QF Loss                      968.2784
VF Loss                      153.89914
Policy Loss                  -897.70807
Q Predictions Mean           889.86035
Q Predictions Std            397.1716
Q Predictions Max            1417.234
Q Predictions Min            220.22862
V Predictions Mean           901.429
V Predictions Std            396.59296
V Predictions Max            1439.5269
V Predictions Min            239.74619
Log Pis Mean                 0.2321886
Log Pis Std                  3.4558337
Log Pis Max                  14.147514
Log Pis Min                  -7.5504436
Policy mu Mean               -0.028359152
Policy mu Std                0.6114945
Policy mu Max                2.6822453
Policy mu Min                -3.548996
Policy log std Mean          -1.0341537
Policy log std Std           0.27168187
Policy log std Max           -0.43618643
Policy log std Min           -2.2378774
Z mean eval                  1.0189764
Z variance eval              0.0099979
total_rewards                [2306.2119066  2917.21535532 3938.00921839  361.04891297  654.75300627
  916.83123257 3870.56287406  281.58083747 3812.7963876  2683.05644408]
total_rewards_mean           2174.2066175338086
total_rewards_std            1423.422687242945
total_rewards_max            3938.0092183918614
total_rewards_min            281.5808374743889
Number of train steps total  760000
Number of env steps total    739572
Number of rollouts total     0
Train Time (s)               146.64801422692835
(Previous) Eval Time (s)     16.3490223409608
Sample Time (s)              7.366635449696332
Epoch Time (s)               170.3636720175855
Total Train Time (s)         31596.84567185305
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:07:13.689254 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #189 | Epoch Duration: 170.4568736553192
2020-01-11 17:07:13.689395 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0095627
Z variance train             0.009995751
KL Divergence                20.775831
KL Loss                      2.077583
QF Loss                      861.33014
VF Loss                      295.53552
Policy Loss                  -950.5934
Q Predictions Mean           939.58374
Q Predictions Std            404.55777
Q Predictions Max            1467.1865
Q Predictions Min            28.791063
V Predictions Mean           952.31506
V Predictions Std            401.73288
V Predictions Max            1478.7079
V Predictions Min            216.00443
Log Pis Mean                 -0.20862114
Log Pis Std                  3.1605017
Log Pis Max                  12.030825
Log Pis Min                  -8.627219
Policy mu Mean               -0.0344094
Policy mu Std                0.5626647
Policy mu Max                2.3732119
Policy mu Min                -3.3749452
Policy log std Mean          -1.0251496
Policy log std Std           0.2578503
Policy log std Max           -0.47051072
Policy log std Min           -2.1193109
Z mean eval                  1.0944139
Z variance eval              0.018316392
total_rewards                [3797.0815918  1460.66359794 3785.95484162  336.24749936 3620.86553069
 4120.82868052 2129.98273193 3968.54468377 4177.40838573 4323.42238787]
total_rewards_mean           3172.0999931222477
total_rewards_std            1299.8650336504227
total_rewards_max            4323.422387871407
total_rewards_min            336.24749936285895
Number of train steps total  764000
Number of env steps total    749146
Number of rollouts total     0
Train Time (s)               148.34196539176628
(Previous) Eval Time (s)     19.535854670219123
Sample Time (s)              6.406825363170356
Epoch Time (s)               174.28464542515576
Total Train Time (s)         31771.241776032373
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:10:08.088248 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #190 | Epoch Duration: 174.39874958992004
2020-01-11 17:10:08.088400 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #190 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0970243
Z variance train             0.018394597
KL Divergence                18.16038
KL Loss                      1.816038
QF Loss                      682.9336
VF Loss                      310.04874
Policy Loss                  -913.47406
Q Predictions Mean           905.4927
Q Predictions Std            430.7485
Q Predictions Max            1494.6484
Q Predictions Min            7.354807
V Predictions Mean           906.3407
V Predictions Std            423.75082
V Predictions Max            1468.0415
V Predictions Min            -91.52197
Log Pis Mean                 0.15683404
Log Pis Std                  3.5692506
Log Pis Max                  22.997894
Log Pis Min                  -7.876313
Policy mu Mean               -0.027949331
Policy mu Std                0.6020087
Policy mu Max                3.6558008
Policy mu Min                -6.6989822
Policy log std Mean          -1.0321013
Policy log std Std           0.27426764
Policy log std Max           0.51896095
Policy log std Min           -2.195915
Z mean eval                  0.98097163
Z variance eval              0.0144723235
total_rewards                [3393.23182862 3631.44190049 4069.17881691  582.54567132 3311.1335783
 3865.56530574 4169.53557248 1256.73163733 1098.56653035 1552.48970013]
total_rewards_mean           2693.0420541676685
total_rewards_std            1325.212732462465
total_rewards_max            4169.535572480344
total_rewards_min            582.5456713201484
Number of train steps total  768000
Number of env steps total    754239
Number of rollouts total     0
Train Time (s)               146.28636868530884
(Previous) Eval Time (s)     16.670070738065988
Sample Time (s)              7.290587138850242
Epoch Time (s)               170.24702656222507
Total Train Time (s)         31941.596232076176
Epoch                        191
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:12:58.443221 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #191 | Epoch Duration: 170.35470461845398
2020-01-11 17:12:58.443345 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9767516
Z variance train             0.014395962
KL Divergence                19.194796
KL Loss                      1.9194796
QF Loss                      1025.941
VF Loss                      177.5672
Policy Loss                  -943.02124
Q Predictions Mean           933.9285
Q Predictions Std            423.2407
Q Predictions Max            1497.639
Q Predictions Min            22.19976
V Predictions Mean           938.96716
V Predictions Std            419.37167
V Predictions Max            1501.3877
V Predictions Min            -51.447117
Log Pis Mean                 0.05232015
Log Pis Std                  3.7756188
Log Pis Max                  22.631763
Log Pis Min                  -9.80648
Policy mu Mean               0.015368539
Policy mu Std                0.5962881
Policy mu Max                3.0854425
Policy mu Min                -3.0494678
Policy log std Mean          -1.023535
Policy log std Std           0.26947495
Policy log std Max           -0.41885006
Policy log std Min           -2.2026968
Z mean eval                  0.99962217
Z variance eval              0.0076431953
total_rewards                [4164.60003877 4094.48443453 4021.64953832 2643.60715059 3742.39398364
  720.50613637 3915.61319517 3647.90974448  899.83213222  534.72494778]
total_rewards_mean           2838.532130187523
total_rewards_std            1447.6849159104606
total_rewards_max            4164.600038772851
total_rewards_min            534.7249477820494
Number of train steps total  772000
Number of env steps total    760651
Number of rollouts total     0
Train Time (s)               145.89011958194897
(Previous) Eval Time (s)     16.767739336006343
Sample Time (s)              6.153077217750251
Epoch Time (s)               168.81093613570556
Total Train Time (s)         32110.490391077008
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:15:47.340335 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #192 | Epoch Duration: 168.89689445495605
2020-01-11 17:15:47.340450 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #192 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9984132
Z variance train             0.00762529
KL Divergence                20.746666
KL Loss                      2.0746667
QF Loss                      1306.8315
VF Loss                      467.40408
Policy Loss                  -949.427
Q Predictions Mean           937.8403
Q Predictions Std            412.3887
Q Predictions Max            1469.5573
Q Predictions Min            32.514946
V Predictions Mean           944.20996
V Predictions Std            404.65518
V Predictions Max            1469.7632
V Predictions Min            19.653816
Log Pis Mean                 0.36725026
Log Pis Std                  4.189255
Log Pis Max                  22.188837
Log Pis Min                  -8.027514
Policy mu Mean               -0.028252197
Policy mu Std                0.61431116
Policy mu Max                3.6131928
Policy mu Min                -4.2241874
Policy log std Mean          -1.0350225
Policy log std Std           0.26778758
Policy log std Max           -0.2270065
Policy log std Min           -2.5724604
Z mean eval                  1.0673708
Z variance eval              0.07364611
total_rewards                [1.47310159e+03 5.18855255e+01 4.50479985e-01 1.08428418e+03
 9.43766148e+02 1.20511526e+03 2.93501267e+03 3.69424723e+02
 1.48859248e+02 3.96633189e+03]
total_rewards_mean           1217.8231719488972
total_rewards_std            1239.5635960201396
total_rewards_max            3966.3318921171654
total_rewards_min            0.4504799852164103
Number of train steps total  776000
Number of env steps total    765341
Number of rollouts total     0
Train Time (s)               146.82905020425096
(Previous) Eval Time (s)     7.213467315770686
Sample Time (s)              6.338642593007535
Epoch Time (s)               160.38116011302918
Total Train Time (s)         32271.189930165652
Epoch                        193
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:18:28.061091 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #193 | Epoch Duration: 160.72048997879028
2020-01-11 17:18:28.061402 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.065923
Z variance train             0.07350131
KL Divergence                17.10475
KL Loss                      1.710475
QF Loss                      773.86206
VF Loss                      132.28006
Policy Loss                  -945.3285
Q Predictions Mean           935.25165
Q Predictions Std            415.5766
Q Predictions Max            1501.9779
Q Predictions Min            -2.2499056
V Predictions Mean           941.8185
V Predictions Std            409.94327
V Predictions Max            1488.7985
V Predictions Min            185.75456
Log Pis Mean                 -0.022709265
Log Pis Std                  3.3601851
Log Pis Max                  18.102911
Log Pis Min                  -6.3264027
Policy mu Mean               -0.010850308
Policy mu Std                0.5885818
Policy mu Max                4.508485
Policy mu Min                -2.7557597
Policy log std Mean          -1.0205272
Policy log std Std           0.23760498
Policy log std Max           -0.3544563
Policy log std Min           -2.0562518
Z mean eval                  0.96866035
Z variance eval              0.009717045
total_rewards                [1431.58580301 3374.73010633 3208.03113603  815.03505067  259.17220799
  244.52574456 2991.57716891  269.12610288 3922.32256221 1821.09644427]
total_rewards_mean           1833.7202326839774
total_rewards_std            1364.5006639502394
total_rewards_max            3922.322562205017
total_rewards_min            244.52574455542657
Number of train steps total  780000
Number of env steps total    771262
Number of rollouts total     0
Train Time (s)               146.3558091428131
(Previous) Eval Time (s)     10.084108541253954
Sample Time (s)              7.944081384688616
Epoch Time (s)               164.38399906875566
Total Train Time (s)         32435.724045522977
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:21:12.578906 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #194 | Epoch Duration: 164.5172781944275
2020-01-11 17:21:12.579071 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9662136
Z variance train             0.009681569
KL Divergence                19.881096
KL Loss                      1.9881096
QF Loss                      691.33435
VF Loss                      224.0809
Policy Loss                  -943.25385
Q Predictions Mean           935.45575
Q Predictions Std            424.57294
Q Predictions Max            1482.7009
Q Predictions Min            8.934256
V Predictions Mean           946.0934
V Predictions Std            419.3464
V Predictions Max            1488.8472
V Predictions Min            -37.258698
Log Pis Mean                 0.2274198
Log Pis Std                  3.5405564
Log Pis Max                  18.948536
Log Pis Min                  -6.3601847
Policy mu Mean               -0.03768345
Policy mu Std                0.6083994
Policy mu Max                3.2338173
Policy mu Min                -3.7944565
Policy log std Mean          -1.033303
Policy log std Std           0.26410025
Policy log std Max           -0.30067486
Policy log std Min           -2.27455
Z mean eval                  0.9741621
Z variance eval              0.01791097
total_rewards                [ 132.75196432 3844.70567546  697.09079872 1717.48639072  728.49181257
 1049.97505958 3014.61229154 3853.33707769 3642.51262874 4105.88346315]
total_rewards_mean           2278.6847162497666
total_rewards_std            1483.457402524984
total_rewards_max            4105.88346315249
total_rewards_min            132.75196432133401
Number of train steps total  784000
Number of env steps total    776181
Number of rollouts total     0
Train Time (s)               146.2530287830159
(Previous) Eval Time (s)     13.601720039732754
Sample Time (s)              6.4984885305166245
Epoch Time (s)               166.35323735326529
Total Train Time (s)         32602.195011248812
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:23:59.051658 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #195 | Epoch Duration: 166.47245359420776
2020-01-11 17:23:59.051834 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9734227
Z variance train             0.017906498
KL Divergence                18.46921
KL Loss                      1.846921
QF Loss                      1599.7615
VF Loss                      286.5235
Policy Loss                  -974.7819
Q Predictions Mean           966.3819
Q Predictions Std            436.6548
Q Predictions Max            1488.0323
Q Predictions Min            39.372875
V Predictions Mean           973.14514
V Predictions Std            430.43753
V Predictions Max            1490.4087
V Predictions Min            233.76215
Log Pis Mean                 0.026423603
Log Pis Std                  3.3160796
Log Pis Max                  18.96537
Log Pis Min                  -6.276272
Policy mu Mean               -0.033420686
Policy mu Std                0.61105245
Policy mu Max                3.1153047
Policy mu Min                -4.195901
Policy log std Mean          -1.022346
Policy log std Std           0.2633428
Policy log std Max           -0.40392113
Policy log std Min           -2.1647992
Z mean eval                  0.9889854
Z variance eval              0.012003005
total_rewards                [1548.45825701   54.60689007 4213.97747636 2081.85057091  329.28603675
 4250.11609654 4222.74974257  751.90969087 2278.2953916  3804.13364685]
total_rewards_mean           2353.5383799535625
total_rewards_std            1591.601275195965
total_rewards_max            4250.116096543373
total_rewards_min            54.60689007144457
Number of train steps total  788000
Number of env steps total    783214
Number of rollouts total     0
Train Time (s)               146.7023762143217
(Previous) Eval Time (s)     15.346511128358543
Sample Time (s)              7.743813758715987
Epoch Time (s)               169.79270110139623
Total Train Time (s)         32772.07292625308
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:26:48.931111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #196 | Epoch Duration: 169.87915444374084
2020-01-11 17:26:48.931246 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9851629
Z variance train             0.012068039
KL Divergence                19.595224
KL Loss                      1.9595225
QF Loss                      901.95557
VF Loss                      264.7753
Policy Loss                  -985.32635
Q Predictions Mean           979.9925
Q Predictions Std            409.26508
Q Predictions Max            1474.6364
Q Predictions Min            194.96878
V Predictions Mean           990.42834
V Predictions Std            404.73483
V Predictions Max            1478.6836
V Predictions Min            253.29065
Log Pis Mean                 0.14786525
Log Pis Std                  3.387923
Log Pis Max                  11.799272
Log Pis Min                  -8.905331
Policy mu Mean               -0.029199779
Policy mu Std                0.59352154
Policy mu Max                2.7769978
Policy mu Min                -3.2147021
Policy log std Mean          -1.0373263
Policy log std Std           0.26887637
Policy log std Max           -0.08566189
Policy log std Min           -2.252294
Z mean eval                  0.99847126
Z variance eval              0.024567526
total_rewards                [1303.50685899 2123.17623756 3797.15707558 1525.71417584 1595.68495585
  122.55772227  584.04962393  486.20242788 2763.63110778  494.61274239]
total_rewards_mean           1479.6292928073642
total_rewards_std            1099.1460745215716
total_rewards_max            3797.157075584053
total_rewards_min            122.5577222726555
Number of train steps total  792000
Number of env steps total    792083
Number of rollouts total     0
Train Time (s)               146.50620553130284
(Previous) Eval Time (s)     12.000978169031441
Sample Time (s)              6.73223778558895
Epoch Time (s)               165.23942148592323
Total Train Time (s)         32937.4480982041
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:29:34.308041 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #197 | Epoch Duration: 165.37670063972473
2020-01-11 17:29:34.308163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99859
Z variance train             0.024456374
KL Divergence                17.804579
KL Loss                      1.7804579
QF Loss                      1130.4387
VF Loss                      192.93643
Policy Loss                  -958.4227
Q Predictions Mean           954.64557
Q Predictions Std            401.41663
Q Predictions Max            1466.6393
Q Predictions Min            -42.921795
V Predictions Mean           949.5812
V Predictions Std            398.63834
V Predictions Max            1446.3124
V Predictions Min            128.43236
Log Pis Mean                 -0.34201628
Log Pis Std                  3.0247014
Log Pis Max                  12.389925
Log Pis Min                  -9.421332
Policy mu Mean               -0.03243698
Policy mu Std                0.56018585
Policy mu Max                2.7570705
Policy mu Min                -3.0637217
Policy log std Mean          -1.004919
Policy log std Std           0.23879197
Policy log std Max           -0.3493793
Policy log std Min           -2.3247275
Z mean eval                  1.106484
Z variance eval              0.0042664623
total_rewards                [1702.9879382   546.46310871 2511.89993345  487.59535737 4133.33273894
 2515.86866827 1088.5874529  4169.28989614 3813.77485203 2362.03083949]
total_rewards_mean           2333.1830785508027
total_rewards_std            1319.6534185463195
total_rewards_max            4169.289896136439
total_rewards_min            487.59535737227606
Number of train steps total  796000
Number of env steps total    797688
Number of rollouts total     0
Train Time (s)               144.84327322803438
(Previous) Eval Time (s)     15.898155812174082
Sample Time (s)              8.522996463812888
Epoch Time (s)               169.26442550402135
Total Train Time (s)         33106.79933978198
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:32:23.661422 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #198 | Epoch Duration: 169.35315346717834
2020-01-11 17:32:23.661589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0970736
Z variance train             0.004280771
KL Divergence                22.117966
KL Loss                      2.2117965
QF Loss                      1250.5499
VF Loss                      114.133194
Policy Loss                  -996.34186
Q Predictions Mean           991.72095
Q Predictions Std            429.1361
Q Predictions Max            1493.7928
Q Predictions Min            237.39876
V Predictions Mean           999.5984
V Predictions Std            425.98962
V Predictions Max            1486.3169
V Predictions Min            259.76495
Log Pis Mean                 0.14760594
Log Pis Std                  3.221073
Log Pis Max                  12.8441105
Log Pis Min                  -6.804487
Policy mu Mean               -0.027325157
Policy mu Std                0.58101726
Policy mu Max                2.586657
Policy mu Min                -2.6721663
Policy log std Mean          -1.0289016
Policy log std Std           0.26801506
Policy log std Max           -0.3486399
Policy log std Min           -2.1160467
Z mean eval                  1.0263855
Z variance eval              0.008313155
total_rewards                [2714.74482388 3789.77384212 3927.12919428  730.79581045  540.71501485
 3653.53636491  484.92620051  928.67318741 4482.35806013 1885.26747898]
total_rewards_mean           2313.791997753079
total_rewards_std            1501.2112650199206
total_rewards_max            4482.358060134872
total_rewards_min            484.9262005077487
Number of train steps total  800000
Number of env steps total    803475
Number of rollouts total     0
Train Time (s)               145.64935637405142
(Previous) Eval Time (s)     16.999195764306933
Sample Time (s)              8.29861864214763
Epoch Time (s)               170.94717078050599
Total Train Time (s)         33277.84557091165
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:35:14.711060 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #199 | Epoch Duration: 171.04932522773743
2020-01-11 17:35:14.711269 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.027518
Z variance train             0.008278322
KL Divergence                21.701307
KL Loss                      2.1701307
QF Loss                      628.155
VF Loss                      91.088776
Policy Loss                  -1003.676
Q Predictions Mean           999.21216
Q Predictions Std            408.07874
Q Predictions Max            1486.3071
Q Predictions Min            242.90819
V Predictions Mean           1004.7733
V Predictions Std            405.19714
V Predictions Max            1476.8945
V Predictions Min            253.59343
Log Pis Mean                 0.34811854
Log Pis Std                  3.2659123
Log Pis Max                  17.92765
Log Pis Min                  -12.27006
Policy mu Mean               -0.029904459
Policy mu Std                0.59747887
Policy mu Max                2.4261546
Policy mu Min                -3.383633
Policy log std Mean          -1.0208929
Policy log std Std           0.25131088
Policy log std Max           -0.29177922
Policy log std Min           -2.676908
Z mean eval                  1.075541
Z variance eval              0.02535868
total_rewards                [4376.94799064 4118.60811812 4173.20959191 2823.14213658 1862.91715523
 4146.5826598  4160.27317422 1323.87933164 4242.47496115 4153.34660599]
total_rewards_mean           3538.1381725294355
total_rewards_std            1062.8366930947036
total_rewards_max            4376.947990639165
total_rewards_min            1323.8793316435356
Number of train steps total  804000
Number of env steps total    813751
Number of rollouts total     0
Train Time (s)               146.48526863800362
(Previous) Eval Time (s)     21.096965411212295
Sample Time (s)              7.481994323898107
Epoch Time (s)               175.06422837311402
Total Train Time (s)         33453.01263969857
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:38:09.882760 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #200 | Epoch Duration: 175.1712372303009
2020-01-11 17:38:09.883160 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0867828
Z variance train             0.02567625
KL Divergence                19.715958
KL Loss                      1.9715958
QF Loss                      810.87195
VF Loss                      258.0076
Policy Loss                  -937.3791
Q Predictions Mean           932.0427
Q Predictions Std            444.6237
Q Predictions Max            1555.6837
Q Predictions Min            28.497086
V Predictions Mean           939.20526
V Predictions Std            439.44434
V Predictions Max            1550.2166
V Predictions Min            36.19485
Log Pis Mean                 0.07044952
Log Pis Std                  3.4366534
Log Pis Max                  16.753685
Log Pis Min                  -6.955448
Policy mu Mean               -0.04147126
Policy mu Std                0.5734066
Policy mu Max                2.28936
Policy mu Min                -2.6614902
Policy log std Mean          -1.038644
Policy log std Std           0.26459637
Policy log std Max           -0.3602103
Policy log std Min           -2.1046581
Z mean eval                  1.1066185
Z variance eval              0.022489024
total_rewards                [1281.83212167 4298.69081477  693.05213414 1548.94541408 4204.98026517
 3920.77890008 3034.47182173 3931.30424764 4158.56566922 3008.40087887]
total_rewards_mean           3008.1022267366984
total_rewards_std            1287.4891149803543
total_rewards_max            4298.690814765933
total_rewards_min            693.0521341371286
Number of train steps total  808000
Number of env steps total    822645
Number of rollouts total     0
Train Time (s)               146.0255455323495
(Previous) Eval Time (s)     24.59489715890959
Sample Time (s)              7.835295269731432
Epoch Time (s)               178.45573796099052
Total Train Time (s)         33631.61185153853
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:41:08.489006 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #201 | Epoch Duration: 178.60560369491577
2020-01-11 17:41:08.489241 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1041176
Z variance train             0.022293357
KL Divergence                19.224743
KL Loss                      1.9224743
QF Loss                      1273.6146
VF Loss                      123.31108
Policy Loss                  -946.47485
Q Predictions Mean           939.51807
Q Predictions Std            426.44754
Q Predictions Max            1522.5878
Q Predictions Min            -16.459303
V Predictions Mean           945.0287
V Predictions Std            420.65576
V Predictions Max            1504.9531
V Predictions Min            242.22939
Log Pis Mean                 -0.1410791
Log Pis Std                  3.2449856
Log Pis Max                  16.323524
Log Pis Min                  -6.899194
Policy mu Mean               0.006915077
Policy mu Std                0.580693
Policy mu Max                2.8404431
Policy mu Min                -2.8152485
Policy log std Mean          -1.0148822
Policy log std Std           0.25423717
Policy log std Max           -0.39867634
Policy log std Min           -2.0813046
Z mean eval                  1.0454803
Z variance eval              0.020352583
total_rewards                [3809.27065046  321.33724029 2789.4413535   357.13689604 1134.66039789
 2633.7702657   849.94889888 3783.25636765 3888.59687673  563.01905759]
total_rewards_mean           2013.0438004720163
total_rewards_std            1438.6345938220545
total_rewards_max            3888.5968767315217
total_rewards_min            321.3372402853635
Number of train steps total  812000
Number of env steps total    830590
Number of rollouts total     0
Train Time (s)               146.68654620228335
(Previous) Eval Time (s)     15.061517607886344
Sample Time (s)              8.019050480797887
Epoch Time (s)               169.76711429096758
Total Train Time (s)         33801.477300354745
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:43:58.353443 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #202 | Epoch Duration: 169.8640275001526
2020-01-11 17:43:58.353619 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0453771
Z variance train             0.020308064
KL Divergence                18.300001
KL Loss                      1.8300002
QF Loss                      1424.4958
VF Loss                      746.1086
Policy Loss                  -945.57806
Q Predictions Mean           941.87384
Q Predictions Std            448.71017
Q Predictions Max            1542.5089
Q Predictions Min            230.37842
V Predictions Mean           949.8434
V Predictions Std            444.0083
V Predictions Max            1537.6882
V Predictions Min            252.26915
Log Pis Mean                 -0.46611315
Log Pis Std                  3.2724612
Log Pis Max                  16.281427
Log Pis Min                  -8.0167885
Policy mu Mean               -0.046498343
Policy mu Std                0.5428455
Policy mu Max                2.5035605
Policy mu Min                -2.4583673
Policy log std Mean          -1.0089105
Policy log std Std           0.27272835
Policy log std Max           -0.31869024
Policy log std Min           -2.4437163
Z mean eval                  0.9780658
Z variance eval              0.011205504
total_rewards                [4086.75360879 4313.1468201  4310.20447156 3778.70035402 1721.84295239
 4185.17999961 4010.79855324 1833.39540407 4085.39544703 4037.93248235]
total_rewards_mean           3636.335009316995
total_rewards_std            941.04089804083
total_rewards_max            4313.146820102701
total_rewards_min            1721.842952391397
Number of train steps total  816000
Number of env steps total    838775
Number of rollouts total     0
Train Time (s)               145.89744283584878
(Previous) Eval Time (s)     21.86755714705214
Sample Time (s)              7.662750998046249
Epoch Time (s)               175.42775098094717
Total Train Time (s)         33977.07098672306
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:46:53.948502 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #203 | Epoch Duration: 175.59476041793823
2020-01-11 17:46:53.948638 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #203 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9799277
Z variance train             0.011154899
KL Divergence                18.766417
KL Loss                      1.8766416
QF Loss                      1088.7742
VF Loss                      139.35526
Policy Loss                  -958.74805
Q Predictions Mean           952.2605
Q Predictions Std            417.5192
Q Predictions Max            1517.7343
Q Predictions Min            -10.723867
V Predictions Mean           953.9889
V Predictions Std            415.47873
V Predictions Max            1503.8796
V Predictions Min            7.221628
Log Pis Mean                 -0.08957751
Log Pis Std                  3.0979927
Log Pis Max                  11.684072
Log Pis Min                  -8.420761
Policy mu Mean               0.004557793
Policy mu Std                0.60104746
Policy mu Max                2.694278
Policy mu Min                -2.2771592
Policy log std Mean          -1.0168535
Policy log std Std           0.26936466
Policy log std Max           -0.21294701
Policy log std Min           -2.3977795
Z mean eval                  0.9980453
Z variance eval              0.080431156
total_rewards                [3910.99702421 3954.79917678 3513.40833036 4016.54821205 3682.9316799
 4050.96328055  377.36276073 2479.29436868  413.51431712 3848.05170251]
total_rewards_mean           3024.787085288441
total_rewards_std            1384.2597750740108
total_rewards_max            4050.9632805499837
total_rewards_min            377.36276072685376
Number of train steps total  820000
Number of env steps total    844935
Number of rollouts total     0
Train Time (s)               146.13265453791246
(Previous) Eval Time (s)     16.30128585314378
Sample Time (s)              6.372339003253728
Epoch Time (s)               168.80627939430997
Total Train Time (s)         34145.996935153846
Epoch                        204
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:49:42.876661 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #204 | Epoch Duration: 168.92792510986328
2020-01-11 17:49:42.876788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.995704
Z variance train             0.081096336
KL Divergence                17.081089
KL Loss                      1.7081089
QF Loss                      899.79736
VF Loss                      195.47878
Policy Loss                  -962.31415
Q Predictions Mean           956.2511
Q Predictions Std            442.7918
Q Predictions Max            1522.8455
Q Predictions Min            -9.250956
V Predictions Mean           964.0538
V Predictions Std            435.0163
V Predictions Max            1518.8335
V Predictions Min            232.99577
Log Pis Mean                 -0.011836238
Log Pis Std                  3.482695
Log Pis Max                  24.833504
Log Pis Min                  -6.964245
Policy mu Mean               -0.028543834
Policy mu Std                0.62530756
Policy mu Max                3.2777116
Policy mu Min                -4.7068787
Policy log std Mean          -0.99544305
Policy log std Std           0.24649593
Policy log std Max           -0.25984502
Policy log std Min           -2.141951
Z mean eval                  1.0359024
Z variance eval              0.015746787
total_rewards                [4075.98492351  541.31230516 1502.30026407  112.26357208 1024.09356483
 3708.8862257  4063.72089548 2736.31663918 3969.61999225 1711.56752993]
total_rewards_mean           2344.606591217617
total_rewards_std            1473.0101102447138
total_rewards_max            4075.984923509743
total_rewards_min            112.26357208028135
Number of train steps total  824000
Number of env steps total    853282
Number of rollouts total     0
Train Time (s)               145.54116195905954
(Previous) Eval Time (s)     15.875627958681434
Sample Time (s)              6.528131159953773
Epoch Time (s)               167.94492107769474
Total Train Time (s)         34314.026555066
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:52:30.908574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #205 | Epoch Duration: 168.0316891670227
2020-01-11 17:52:30.908704 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.040638
Z variance train             0.01565608
KL Divergence                18.378765
KL Loss                      1.8378766
QF Loss                      768.3849
VF Loss                      345.0705
Policy Loss                  -962.5803
Q Predictions Mean           953.39874
Q Predictions Std            414.93826
Q Predictions Max            1500.7117
Q Predictions Min            -40.140682
V Predictions Mean           959.448
V Predictions Std            400.6816
V Predictions Max            1495.2566
V Predictions Min            249.68715
Log Pis Mean                 0.34243646
Log Pis Std                  4.515491
Log Pis Max                  48.00788
Log Pis Min                  -8.8026085
Policy mu Mean               -0.0059245154
Policy mu Std                0.657779
Policy mu Max                5.7245746
Policy mu Min                -6.163916
Policy log std Mean          -1.003534
Policy log std Std           0.26340622
Policy log std Max           -0.2306562
Policy log std Min           -2.1583846
Z mean eval                  1.0059198
Z variance eval              0.0066949725
total_rewards                [3931.93291956  401.47688526 3202.26177196 4015.25271532  181.06093872
 2921.51412261 2366.48224247 4012.68120217  755.65301201 2710.48402491]
total_rewards_mean           2449.879983498521
total_rewards_std            1420.088280779381
total_rewards_max            4015.2527153226497
total_rewards_min            181.060938715662
Number of train steps total  828000
Number of env steps total    862773
Number of rollouts total     0
Train Time (s)               146.639030165039
(Previous) Eval Time (s)     16.27844032505527
Sample Time (s)              6.789474962744862
Epoch Time (s)               169.70694545283914
Total Train Time (s)         34483.822135547176
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:55:20.706807 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #206 | Epoch Duration: 169.79799365997314
2020-01-11 17:55:20.706968 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0043907
Z variance train             0.006693515
KL Divergence                20.319082
KL Loss                      2.0319083
QF Loss                      773.3015
VF Loss                      173.11894
Policy Loss                  -979.2322
Q Predictions Mean           973.86304
Q Predictions Std            419.73102
Q Predictions Max            1508.2039
Q Predictions Min            148.55545
V Predictions Mean           972.8826
V Predictions Std            419.95264
V Predictions Max            1491.7131
V Predictions Min            230.35442
Log Pis Mean                 -0.10107297
Log Pis Std                  2.8787823
Log Pis Max                  9.710861
Log Pis Min                  -7.5364847
Policy mu Mean               0.016150726
Policy mu Std                0.56562483
Policy mu Max                2.499324
Policy mu Min                -3.3654377
Policy log std Mean          -1.0284669
Policy log std Std           0.255409
Policy log std Max           -0.23199046
Policy log std Min           -2.2083058
Z mean eval                  1.1637316
Z variance eval              0.007633727
total_rewards                [  37.34771869 2370.17035601 3084.51136216 4240.10298989 4094.97386058
 1251.67046104 2734.92715302 4328.28235895 4190.45986039 1003.92145062]
total_rewards_mean           2733.636757134423
total_rewards_std            1466.3302346584305
total_rewards_max            4328.2823589499985
total_rewards_min            37.34771868769158
Number of train steps total  832000
Number of env steps total    871228
Number of rollouts total     0
Train Time (s)               146.78137473296374
(Previous) Eval Time (s)     14.203047099057585
Sample Time (s)              6.386096029076725
Epoch Time (s)               167.37051786109805
Total Train Time (s)         34651.30522143422
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:58:08.190714 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #207 | Epoch Duration: 167.4836277961731
2020-01-11 17:58:08.190853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #207 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1742522
Z variance train             0.0076282383
KL Divergence                20.431442
KL Loss                      2.0431442
QF Loss                      806.45325
VF Loss                      318.45837
Policy Loss                  -950.83344
Q Predictions Mean           943.1322
Q Predictions Std            414.00897
Q Predictions Max            1499.8187
Q Predictions Min            247.02719
V Predictions Mean           955.1763
V Predictions Std            415.9025
V Predictions Max            1509.9717
V Predictions Min            248.59492
Log Pis Mean                 -0.04923574
Log Pis Std                  3.5895457
Log Pis Max                  23.542263
Log Pis Min                  -7.037791
Policy mu Mean               0.015211677
Policy mu Std                0.61887103
Policy mu Max                3.7216706
Policy mu Min                -3.231172
Policy log std Mean          -0.9940241
Policy log std Std           0.24438335
Policy log std Max           -0.35667104
Policy log std Min           -2.130005
Z mean eval                  1.0429016
Z variance eval              0.022797177
total_rewards                [4057.84986399 3872.17790399 4135.57264232 4286.6622705   609.4045052
 3384.61119537 4164.94459028  929.09770119 1028.86950937 4228.30267512]
total_rewards_mean           3069.7492857351726
total_rewards_std            1472.3723618859876
total_rewards_max            4286.662270501227
total_rewards_min            609.4045052017594
Number of train steps total  836000
Number of env steps total    880124
Number of rollouts total     0
Train Time (s)               144.7979057370685
(Previous) Eval Time (s)     18.401752497069538
Sample Time (s)              6.317520655691624
Epoch Time (s)               169.51717888982967
Total Train Time (s)         34820.95375069184
Epoch                        208
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:00:57.842020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #208 | Epoch Duration: 169.65105390548706
2020-01-11 18:00:57.842189 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0437009
Z variance train             0.022690216
KL Divergence                18.223358
KL Loss                      1.8223358
QF Loss                      1051.579
VF Loss                      245.05478
Policy Loss                  -921.5919
Q Predictions Mean           918.8345
Q Predictions Std            417.1945
Q Predictions Max            1487.4188
Q Predictions Min            -5.5760245
V Predictions Mean           925.89575
V Predictions Std            415.5149
V Predictions Max            1479.8955
V Predictions Min            -52.907635
Log Pis Mean                 0.34232062
Log Pis Std                  3.8996964
Log Pis Max                  21.19361
Log Pis Min                  -7.884131
Policy mu Mean               -0.042218775
Policy mu Std                0.63120115
Policy mu Max                4.350564
Policy mu Min                -2.1933577
Policy log std Mean          -1.0360794
Policy log std Std           0.27526572
Policy log std Max           -0.410267
Policy log std Min           -2.5019758
Z mean eval                  1.051468
Z variance eval              0.016265903
total_rewards                [ 420.38707957 4148.62060315 1907.64473433 4395.71758329 2340.82813478
 3427.27228875 4111.07209908 2722.15902426 3988.56563665 4050.63512184]
total_rewards_mean           3151.2902305688754
total_rewards_std            1220.4898410201629
total_rewards_max            4395.717583288467
total_rewards_min            420.387079566941
Number of train steps total  840000
Number of env steps total    888919
Number of rollouts total     0
Train Time (s)               147.0929756858386
(Previous) Eval Time (s)     19.438848675228655
Sample Time (s)              7.327887495048344
Epoch Time (s)               173.8597118561156
Total Train Time (s)         34994.97991342284
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:03:51.875210 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #209 | Epoch Duration: 174.03288626670837
2020-01-11 18:03:51.875395 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0349038
Z variance train             0.016174952
KL Divergence                21.315437
KL Loss                      2.1315439
QF Loss                      896.4804
VF Loss                      306.25653
Policy Loss                  -942.8086
Q Predictions Mean           938.2213
Q Predictions Std            440.40247
Q Predictions Max            1498.2913
Q Predictions Min            166.95935
V Predictions Mean           953.4903
V Predictions Std            439.04773
V Predictions Max            1503.3655
V Predictions Min            259.58722
Log Pis Mean                 -0.4549644
Log Pis Std                  3.2930562
Log Pis Max                  13.350702
Log Pis Min                  -11.158331
Policy mu Mean               0.013519681
Policy mu Std                0.57071036
Policy mu Max                3.0893512
Policy mu Min                -2.1267655
Policy log std Mean          -0.9795192
Policy log std Std           0.26064324
Policy log std Max           -0.28749907
Policy log std Min           -2.177227
Z mean eval                  1.0434912
Z variance eval              0.027630746
total_rewards                [3930.10400205 2260.37248    4185.2298025  3715.94113688 1575.07545012
 3963.05024039 3977.18328252 4181.66404773  802.30201667 4004.45740598]
total_rewards_mean           3259.5379864843067
total_rewards_std            1174.8952289026095
total_rewards_max            4185.229802497701
total_rewards_min            802.3020166704332
Number of train steps total  844000
Number of env steps total    894850
Number of rollouts total     0
Train Time (s)               145.49194320384413
(Previous) Eval Time (s)     17.754966165870428
Sample Time (s)              6.411332973279059
Epoch Time (s)               169.65824234299362
Total Train Time (s)         35164.796425328124
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:06:41.692932 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #210 | Epoch Duration: 169.81739163398743
2020-01-11 18:06:41.693126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.036883
Z variance train             0.027560538
KL Divergence                17.182095
KL Loss                      1.7182095
QF Loss                      1698.0054
VF Loss                      166.77667
Policy Loss                  -995.354
Q Predictions Mean           989.43677
Q Predictions Std            427.60095
Q Predictions Max            1520.2987
Q Predictions Min            -81.50049
V Predictions Mean           1001.15643
V Predictions Std            426.05408
V Predictions Max            1543.645
V Predictions Min            -56.9725
Log Pis Mean                 0.13736808
Log Pis Std                  3.225895
Log Pis Max                  17.78974
Log Pis Min                  -7.1771994
Policy mu Mean               -0.05207052
Policy mu Std                0.58144915
Policy mu Max                2.6039937
Policy mu Min                -2.3664572
Policy log std Mean          -1.0359129
Policy log std Std           0.27492467
Policy log std Max           -0.42732793
Policy log std Min           -2.333511
Z mean eval                  0.9434077
Z variance eval              0.035214305
total_rewards                [2824.05367502 3751.58212208 3697.78619529 3840.5992414   644.96411312
 2631.11180629 3560.6945424  1740.08518777 3993.75309564 3848.00456902]
total_rewards_mean           3053.263454802271
total_rewards_std            1051.2691707809836
total_rewards_max            3993.7530956378946
total_rewards_min            644.9641131228382
Number of train steps total  848000
Number of env steps total    900787
Number of rollouts total     0
Train Time (s)               145.80650324886665
(Previous) Eval Time (s)     22.397196656093
Sample Time (s)              6.416696360334754
Epoch Time (s)               174.6203962652944
Total Train Time (s)         35339.532818677835
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:09:36.431466 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #211 | Epoch Duration: 174.7382037639618
2020-01-11 18:09:36.431602 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9384774
Z variance train             0.03521506
KL Divergence                16.476719
KL Loss                      1.6476719
QF Loss                      747.20386
VF Loss                      182.75137
Policy Loss                  -982.6666
Q Predictions Mean           975.09467
Q Predictions Std            431.5608
Q Predictions Max            1542.8503
Q Predictions Min            -52.983715
V Predictions Mean           987.4769
V Predictions Std            424.82526
V Predictions Max            1548.7185
V Predictions Min            260.52777
Log Pis Mean                 -0.13841912
Log Pis Std                  3.1027045
Log Pis Max                  15.722841
Log Pis Min                  -7.538236
Policy mu Mean               -0.020329654
Policy mu Std                0.56877667
Policy mu Max                3.6308506
Policy mu Min                -2.5234232
Policy log std Mean          -1.0176331
Policy log std Std           0.25559324
Policy log std Max           -0.32128865
Policy log std Min           -2.353703
Z mean eval                  0.9658333
Z variance eval              0.020687604
total_rewards                [1314.27368662  159.88671997 3382.58891845 2662.93547639 4255.68298052
 2642.29492193 3913.28583201  661.63566607 4105.78047219 3983.14127457]
total_rewards_mean           2708.1505948720796
total_rewards_std            1432.207782616856
total_rewards_max            4255.682980519644
total_rewards_min            159.88671997092504
Number of train steps total  852000
Number of env steps total    909281
Number of rollouts total     0
Train Time (s)               147.0706221330911
(Previous) Eval Time (s)     14.69600892579183
Sample Time (s)              7.712284055072814
Epoch Time (s)               169.47891511395574
Total Train Time (s)         35509.09424235765
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:12:25.994034 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #212 | Epoch Duration: 169.56231570243835
2020-01-11 18:12:25.994161 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9675107
Z variance train             0.020514984
KL Divergence                18.00218
KL Loss                      1.800218
QF Loss                      1302.7214
VF Loss                      664.6907
Policy Loss                  -953.5173
Q Predictions Mean           947.6349
Q Predictions Std            435.16748
Q Predictions Max            1521.335
Q Predictions Min            -61.047375
V Predictions Mean           949.31067
V Predictions Std            433.55374
V Predictions Max            1487.5153
V Predictions Min            -51.22029
Log Pis Mean                 0.3676266
Log Pis Std                  4.0069036
Log Pis Max                  28.245457
Log Pis Min                  -9.583534
Policy mu Mean               -0.011084471
Policy mu Std                0.62447006
Policy mu Max                3.582476
Policy mu Min                -3.9265468
Policy log std Mean          -1.0192642
Policy log std Std           0.29067758
Policy log std Max           -0.32760358
Policy log std Min           -2.3700223
Z mean eval                  0.99005044
Z variance eval              0.009035448
total_rewards                [ 370.04605566 3423.40172356 1113.17893002 2626.1134043   323.04246051
  428.19634195 2179.49628187 1774.65451636 3958.53842785 2252.49534083]
total_rewards_mean           1844.916348290693
total_rewards_std            1220.088605128949
total_rewards_max            3958.5384278542224
total_rewards_min            323.0424605118817
Number of train steps total  856000
Number of env steps total    916208
Number of rollouts total     0
Train Time (s)               145.57289107702672
(Previous) Eval Time (s)     9.943542048335075
Sample Time (s)              6.242811040021479
Epoch Time (s)               161.75924416538328
Total Train Time (s)         35670.940750499256
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:15:07.843539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #213 | Epoch Duration: 161.84927082061768
2020-01-11 18:15:07.843702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9936268
Z variance train             0.009078755
KL Divergence                19.941801
KL Loss                      1.9941801
QF Loss                      565.26605
VF Loss                      183.22928
Policy Loss                  -942.8337
Q Predictions Mean           940.7252
Q Predictions Std            427.49207
Q Predictions Max            1524.3745
Q Predictions Min            207.2673
V Predictions Mean           939.7539
V Predictions Std            423.10202
V Predictions Max            1502.0105
V Predictions Min            169.79126
Log Pis Mean                 0.22770837
Log Pis Std                  3.971504
Log Pis Max                  30.877357
Log Pis Min                  -8.668598
Policy mu Mean               0.024126492
Policy mu Std                0.6175695
Policy mu Max                3.2272522
Policy mu Min                -4.999099
Policy log std Mean          -1.0410038
Policy log std Std           0.2667131
Policy log std Max           -0.28299993
Policy log std Min           -2.2914612
Z mean eval                  1.045465
Z variance eval              0.028712207
total_rewards                [1590.24623649 3455.37199265  795.73604114  680.41209694  950.76591799
 3505.82330652 2518.59578013 4217.89174265 2278.00370748  820.00937431]
total_rewards_mean           2081.285619629203
total_rewards_std            1242.4790329541872
total_rewards_max            4217.891742651848
total_rewards_min            680.4120969377257
Number of train steps total  860000
Number of env steps total    924283
Number of rollouts total     0
Train Time (s)               147.71462779073045
(Previous) Eval Time (s)     13.17174109024927
Sample Time (s)              7.217906290665269
Epoch Time (s)               168.10427517164499
Total Train Time (s)         35839.182670232374
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:17:56.087286 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #214 | Epoch Duration: 168.24345755577087
2020-01-11 18:17:56.087423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0412071
Z variance train             0.02859537
KL Divergence                16.53992
KL Loss                      1.653992
QF Loss                      1161.2158
VF Loss                      143.73083
Policy Loss                  -1038.7361
Q Predictions Mean           1031.1174
Q Predictions Std            420.1276
Q Predictions Max            1551.6716
Q Predictions Min            223.89914
V Predictions Mean           1039.1328
V Predictions Std            416.09253
V Predictions Max            1539.2631
V Predictions Min            203.08722
Log Pis Mean                 0.21327817
Log Pis Std                  3.1481328
Log Pis Max                  14.526326
Log Pis Min                  -8.311165
Policy mu Mean               -0.019676268
Policy mu Std                0.6030243
Policy mu Max                3.2903688
Policy mu Min                -4.0555487
Policy log std Mean          -1.0372233
Policy log std Std           0.2559656
Policy log std Max           -0.07814801
Policy log std Min           -2.3874123
Z mean eval                  0.97874326
Z variance eval              0.020125892
total_rewards                [3317.76595763 4372.06845786  514.67671256 4195.30752089 3974.66268567
 1540.05657345 4044.48200348 2242.31174475 3896.1239568  4172.71396962]
total_rewards_mean           3227.0169582685708
total_rewards_std            1264.8519472199612
total_rewards_max            4372.068457855923
total_rewards_min            514.6767125558914
Number of train steps total  864000
Number of env steps total    930536
Number of rollouts total     0
Train Time (s)               146.1511814976111
(Previous) Eval Time (s)     17.00041664671153
Sample Time (s)              7.689599138684571
Epoch Time (s)               170.8411972830072
Total Train Time (s)         36010.12835665513
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:20:47.034665 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #215 | Epoch Duration: 170.9470932483673
2020-01-11 18:20:47.034860 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9802598
Z variance train             0.020478735
KL Divergence                18.620573
KL Loss                      1.8620573
QF Loss                      705.64166
VF Loss                      228.57272
Policy Loss                  -1047.4675
Q Predictions Mean           1043.1929
Q Predictions Std            403.61258
Q Predictions Max            1541.6919
Q Predictions Min            230.68262
V Predictions Mean           1041.8447
V Predictions Std            399.1272
V Predictions Max            1534.3998
V Predictions Min            248.94852
Log Pis Mean                 0.23482168
Log Pis Std                  3.2821171
Log Pis Max                  16.42352
Log Pis Min                  -8.161525
Policy mu Mean               -0.01398657
Policy mu Std                0.60323584
Policy mu Max                3.368413
Policy mu Min                -2.3818657
Policy log std Mean          -1.0281594
Policy log std Std           0.27333885
Policy log std Max           -0.104195
Policy log std Min           -2.4677644
Z mean eval                  0.94358647
Z variance eval              0.026429478
total_rewards                [4018.25161482 4062.71286023 4155.02173433 4532.853581   2699.46772887
 4406.23007057 4178.05742591 4145.87076847 4078.05658506 4000.87800996]
total_rewards_mean           4027.740037921058
total_rewards_std            471.1707749864926
total_rewards_max            4532.853580996483
total_rewards_min            2699.4677288686735
Number of train steps total  868000
Number of env steps total    938156
Number of rollouts total     0
Train Time (s)               145.36685317009687
(Previous) Eval Time (s)     20.28902764711529
Sample Time (s)              6.744877751916647
Epoch Time (s)               172.4007585691288
Total Train Time (s)         36182.671335670166
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:23:39.578540 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #216 | Epoch Duration: 172.5435733795166
2020-01-11 18:23:39.578662 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9404192
Z variance train             0.026306856
KL Divergence                17.524797
KL Loss                      1.7524798
QF Loss                      904.2906
VF Loss                      156.1912
Policy Loss                  -999.8888
Q Predictions Mean           994.39954
Q Predictions Std            431.21356
Q Predictions Max            1544.3438
Q Predictions Min            -71.894356
V Predictions Mean           998.5069
V Predictions Std            428.92603
V Predictions Max            1542.3171
V Predictions Min            -37.74499
Log Pis Mean                 0.020344064
Log Pis Std                  3.1012943
Log Pis Max                  12.032406
Log Pis Min                  -7.57497
Policy mu Mean               -0.010150786
Policy mu Std                0.58528894
Policy mu Max                2.5832
Policy mu Min                -2.3672392
Policy log std Mean          -1.0179431
Policy log std Std           0.2575423
Policy log std Max           -0.31515104
Policy log std Min           -2.119761
Z mean eval                  0.9656919
Z variance eval              0.05048991
total_rewards                [4360.12903429 4339.05527808 1882.42626627  569.94650587 4185.15917405
 4119.23688746 4160.26101985 4010.9805693  4172.24491037 4462.14183202]
total_rewards_mean           3626.158147755931
total_rewards_std            1241.53165456881
total_rewards_max            4462.141832022984
total_rewards_min            569.9465058650374
Number of train steps total  872000
Number of env steps total    946651
Number of rollouts total     0
Train Time (s)               145.05600431608036
(Previous) Eval Time (s)     19.940419589169323
Sample Time (s)              6.636303638108075
Epoch Time (s)               171.63272754335776
Total Train Time (s)         36354.41619565943
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:26:31.325306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #217 | Epoch Duration: 171.74655437469482
2020-01-11 18:26:31.325423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97318536
Z variance train             0.050321013
KL Divergence                19.031242
KL Loss                      1.9031242
QF Loss                      774.0387
VF Loss                      292.4483
Policy Loss                  -1041.9705
Q Predictions Mean           1036.044
Q Predictions Std            393.45416
Q Predictions Max            1525.9089
Q Predictions Min            189.48254
V Predictions Mean           1037.0768
V Predictions Std            386.72345
V Predictions Max            1500.8827
V Predictions Min            249.60423
Log Pis Mean                 0.5914022
Log Pis Std                  3.729329
Log Pis Max                  20.378807
Log Pis Min                  -6.7565517
Policy mu Mean               -0.013457594
Policy mu Std                0.62525237
Policy mu Max                4.330369
Policy mu Min                -3.1950297
Policy log std Mean          -1.0575389
Policy log std Std           0.27736467
Policy log std Max           -0.07076669
Policy log std Min           -2.807071
Z mean eval                  1.0487732
Z variance eval              0.021177717
total_rewards                [4304.316247   2516.67867028 4318.61783142 2491.87520476 3718.32467215
 1721.20567338 2272.19654875 1119.06899027  558.47526794   98.32226826]
total_rewards_mean           2311.9081374210155
total_rewards_std            1407.009642003661
total_rewards_max            4318.6178314214085
total_rewards_min            98.32226825923085
Number of train steps total  876000
Number of env steps total    952968
Number of rollouts total     0
Train Time (s)               145.23225642414764
(Previous) Eval Time (s)     13.572239725384861
Sample Time (s)              6.712953218724579
Epoch Time (s)               165.51744936825708
Total Train Time (s)         36520.04682575073
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:29:16.957817 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #218 | Epoch Duration: 165.6323037147522
2020-01-11 18:29:16.957942 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.042908
Z variance train             0.021302875
KL Divergence                20.64931
KL Loss                      2.064931
QF Loss                      681.78326
VF Loss                      249.13904
Policy Loss                  -980.66644
Q Predictions Mean           974.72754
Q Predictions Std            424.03424
Q Predictions Max            1521.0164
Q Predictions Min            1.8547649
V Predictions Mean           976.19775
V Predictions Std            418.36722
V Predictions Max            1508.36
V Predictions Min            215.69499
Log Pis Mean                 0.31302404
Log Pis Std                  3.561931
Log Pis Max                  27.815178
Log Pis Min                  -6.7865963
Policy mu Mean               -0.028906882
Policy mu Std                0.60589576
Policy mu Max                3.1882758
Policy mu Min                -5.1057873
Policy log std Mean          -1.0206947
Policy log std Std           0.26130077
Policy log std Max           -0.32004857
Policy log std Min           -2.2005904
Z mean eval                  1.0653306
Z variance eval              0.027257267
total_rewards                [1475.68341424  106.36119717  942.25310361 1963.31054288 4128.14432683
 4506.17093514 4127.80436441 1719.8559402  2920.04080854 4372.91332563]
total_rewards_mean           2626.253795864321
total_rewards_std            1514.9959776233943
total_rewards_max            4506.170935142542
total_rewards_min            106.3611971683377
Number of train steps total  880000
Number of env steps total    959400
Number of rollouts total     0
Train Time (s)               145.7226967108436
(Previous) Eval Time (s)     13.510605907998979
Sample Time (s)              7.643644418567419
Epoch Time (s)               166.87694703741
Total Train Time (s)         36687.036886256654
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:32:03.949979 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #219 | Epoch Duration: 166.99194478988647
2020-01-11 18:32:03.950094 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0609596
Z variance train             0.027536362
KL Divergence                19.480434
KL Loss                      1.9480435
QF Loss                      692.3845
VF Loss                      216.72993
Policy Loss                  -959.6687
Q Predictions Mean           948.8458
Q Predictions Std            437.89444
Q Predictions Max            1540.4224
Q Predictions Min            -52.494812
V Predictions Mean           953.2883
V Predictions Std            430.17572
V Predictions Max            1548.3374
V Predictions Min            143.25229
Log Pis Mean                 -0.05853346
Log Pis Std                  3.1551557
Log Pis Max                  12.866266
Log Pis Min                  -8.90514
Policy mu Mean               0.012704821
Policy mu Std                0.59962046
Policy mu Max                2.902674
Policy mu Min                -2.9532528
Policy log std Mean          -0.9962898
Policy log std Std           0.24822684
Policy log std Max           -0.2324934
Policy log std Min           -2.180708
Z mean eval                  0.9203687
Z variance eval              0.017361213
total_rewards                [ 740.35108087 1942.81932565 3858.10468069 4111.83295467 1682.91274213
 4337.18971994 4238.45440367 4264.95079139 4342.34225854 4217.06002208]
total_rewards_mean           3373.6017979653743
total_rewards_std            1293.8377095518022
total_rewards_max            4342.3422585410635
total_rewards_min            740.3510808742108
Number of train steps total  884000
Number of env steps total    968458
Number of rollouts total     0
Train Time (s)               146.71224843384698
(Previous) Eval Time (s)     18.849456725176424
Sample Time (s)              6.892036355566233
Epoch Time (s)               172.45374151458964
Total Train Time (s)         36859.573893857654
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:34:56.488885 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #220 | Epoch Duration: 172.53870153427124
2020-01-11 18:34:56.489006 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9200531
Z variance train             0.017250273
KL Divergence                19.571552
KL Loss                      1.9571552
QF Loss                      726.3562
VF Loss                      127.21504
Policy Loss                  -998.71625
Q Predictions Mean           995.30646
Q Predictions Std            425.3295
Q Predictions Max            1565.8484
Q Predictions Min            244.4209
V Predictions Mean           992.93445
V Predictions Std            422.66058
V Predictions Max            1552.9567
V Predictions Min            230.5265
Log Pis Mean                 -0.011498123
Log Pis Std                  3.0623045
Log Pis Max                  9.094202
Log Pis Min                  -8.886045
Policy mu Mean               -0.025707187
Policy mu Std                0.5852109
Policy mu Max                2.5309849
Policy mu Min                -2.3694334
Policy log std Mean          -1.0104702
Policy log std Std           0.25985768
Policy log std Max           -0.36323208
Policy log std Min           -2.2972279
Z mean eval                  0.9893174
Z variance eval              0.005913437
total_rewards                [4020.73730559 4500.4720801  4021.75571494 4051.99713514   72.72086245
 1498.02607763   54.97639563 4127.08041997 4269.99633071 4362.21739107]
total_rewards_mean           3097.997971323868
total_rewards_std            1720.0249363367677
total_rewards_max            4500.472080104182
total_rewards_min            54.976395631711824
Number of train steps total  888000
Number of env steps total    976769
Number of rollouts total     0
Train Time (s)               145.79731831979007
(Previous) Eval Time (s)     15.796530615072697
Sample Time (s)              6.423625402152538
Epoch Time (s)               168.0174743370153
Total Train Time (s)         37027.74818301294
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:37:44.665472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #221 | Epoch Duration: 168.17635464668274
2020-01-11 18:37:44.665644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9877798
Z variance train             0.005923488
KL Divergence                19.983727
KL Loss                      1.9983727
QF Loss                      874.78766
VF Loss                      131.74072
Policy Loss                  -1025.0067
Q Predictions Mean           1019.18665
Q Predictions Std            416.07877
Q Predictions Max            1538.8539
Q Predictions Min            223.05281
V Predictions Mean           1023.14
V Predictions Std            414.15457
V Predictions Max            1526.8693
V Predictions Min            245.02327
Log Pis Mean                 -0.163708
Log Pis Std                  3.2950122
Log Pis Max                  17.749004
Log Pis Min                  -7.04422
Policy mu Mean               -0.0131352255
Policy mu Std                0.6179491
Policy mu Max                3.3218174
Policy mu Min                -3.923326
Policy log std Mean          -1.0115243
Policy log std Std           0.2692675
Policy log std Max           -0.2378279
Policy log std Min           -2.3547914
Z mean eval                  1.0034292
Z variance eval              0.023378983
total_rewards                [3726.29786156 4212.19093032 4231.84382093 3982.78234457 3967.75230067
 2931.08987758 3984.88805098 3059.98781747 4004.81813872 3847.9950814 ]
total_rewards_mean           3794.9646224190483
total_rewards_std            424.75634707927395
total_rewards_max            4231.843820930333
total_rewards_min            2931.0898775798782
Number of train steps total  892000
Number of env steps total    986437
Number of rollouts total     0
Train Time (s)               147.02670027175918
(Previous) Eval Time (s)     20.940541465301067
Sample Time (s)              7.590916075743735
Epoch Time (s)               175.55815781280398
Total Train Time (s)         37203.45205981238
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:40:40.386035 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #222 | Epoch Duration: 175.7202308177948
2020-01-11 18:40:40.386268 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9994386
Z variance train             0.02339465
KL Divergence                16.936197
KL Loss                      1.6936197
QF Loss                      674.5934
VF Loss                      113.265434
Policy Loss                  -981.37463
Q Predictions Mean           975.6465
Q Predictions Std            436.09506
Q Predictions Max            1566.4167
Q Predictions Min            -4.0685954
V Predictions Mean           984.25684
V Predictions Std            433.03217
V Predictions Max            1555.4972
V Predictions Min            -28.567371
Log Pis Mean                 0.16438583
Log Pis Std                  3.5017529
Log Pis Max                  17.700256
Log Pis Min                  -7.159913
Policy mu Mean               -0.003843802
Policy mu Std                0.6326299
Policy mu Max                2.788123
Policy mu Min                -3.4669542
Policy log std Mean          -1.0002841
Policy log std Std           0.26307765
Policy log std Max           -0.11640173
Policy log std Min           -2.3598876
Z mean eval                  0.9433527
Z variance eval              0.013235283
total_rewards                [3922.67551213 4042.64264108 4095.53902959 4188.57608125 4101.01699724
 4135.61406836 3983.84707205 3853.5722831  4228.68614753 4016.75040614]
total_rewards_mean           4056.892023848458
total_rewards_std            110.90294174959605
total_rewards_max            4228.6861475347
total_rewards_min            3853.5722831045578
Number of train steps total  896000
Number of env steps total    996413
Number of rollouts total     0
Train Time (s)               146.1544323391281
(Previous) Eval Time (s)     21.47079561976716
Sample Time (s)              8.223286824766546
Epoch Time (s)               175.8485147836618
Total Train Time (s)         37379.43737808615
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:43:36.362800 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #223 | Epoch Duration: 175.97635984420776
2020-01-11 18:43:36.362960 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94375646
Z variance train             0.01336021
KL Divergence                18.298489
KL Loss                      1.8298489
QF Loss                      1044.343
VF Loss                      759.0602
Policy Loss                  -1014.9642
Q Predictions Mean           1005.5956
Q Predictions Std            408.46753
Q Predictions Max            1530.3186
Q Predictions Min            167.50739
V Predictions Mean           1018.9532
V Predictions Std            406.5332
V Predictions Max            1549.0768
V Predictions Min            243.9079
Log Pis Mean                 0.68168116
Log Pis Std                  4.205332
Log Pis Max                  26.516987
Log Pis Min                  -7.427782
Policy mu Mean               0.058169626
Policy mu Std                0.65170574
Policy mu Max                3.6832376
Policy mu Min                -4.622685
Policy log std Mean          -1.0589261
Policy log std Std           0.28075504
Policy log std Max           -0.3507496
Policy log std Min           -2.3577676
Z mean eval                  0.86112154
Z variance eval              0.01055309
total_rewards                [2901.87755598 1265.55698814 4254.36406472 1593.37831254 2227.72771853
 4261.135814   3860.27141396 4342.23731502 2703.03847933 4146.53149552]
total_rewards_mean           3155.6119157743933
total_rewards_std            1116.20070861554
total_rewards_max            4342.237315023032
total_rewards_min            1265.5569881432284
Number of train steps total  900000
Number of env steps total    1006414
Number of rollouts total     0
Train Time (s)               146.6570232301019
(Previous) Eval Time (s)     18.62599729280919
Sample Time (s)              7.186676332727075
Epoch Time (s)               172.46969685563818
Total Train Time (s)         37551.99910792755
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:46:28.927316 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #224 | Epoch Duration: 172.56422066688538
2020-01-11 18:46:28.927508 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8592707
Z variance train             0.010570109
KL Divergence                18.990711
KL Loss                      1.8990711
QF Loss                      1407.1886
VF Loss                      559.13617
Policy Loss                  -968.2463
Q Predictions Mean           960.608
Q Predictions Std            442.01544
Q Predictions Max            1541.2609
Q Predictions Min            -25.993124
V Predictions Mean           973.5119
V Predictions Std            435.64523
V Predictions Max            1529.1666
V Predictions Min            163.11787
Log Pis Mean                 0.18863732
Log Pis Std                  4.2359576
Log Pis Max                  34.29308
Log Pis Min                  -7.3294334
Policy mu Mean               -0.006156447
Policy mu Std                0.63208103
Policy mu Max                4.51846
Policy mu Min                -4.47037
Policy log std Mean          -1.0008116
Policy log std Std           0.26712778
Policy log std Max           0.00018167496
Policy log std Min           -2.5393317
Z mean eval                  1.0655733
Z variance eval              0.00434268
total_rewards                [4242.20733808 4203.44931587 4102.2706282   274.13210895 4104.26851203
 4106.63554173 3739.37744436 4199.80695227 3636.93236943 4033.66137579]
total_rewards_mean           3664.274158669996
total_rewards_std            1145.7979588476524
total_rewards_max            4242.2073380783295
total_rewards_min            274.13210894523684
Number of train steps total  904000
Number of env steps total    1015311
Number of rollouts total     0
Train Time (s)               146.44884935580194
(Previous) Eval Time (s)     22.398210754152387
Sample Time (s)              7.320179509930313
Epoch Time (s)               176.16723961988464
Total Train Time (s)         37728.24969656626
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:49:25.179581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #225 | Epoch Duration: 176.25191068649292
2020-01-11 18:49:25.179719 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #225 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0598456
Z variance train             0.0043149064
KL Divergence                20.89642
KL Loss                      2.089642
QF Loss                      1212.5676
VF Loss                      233.10704
Policy Loss                  -992.4518
Q Predictions Mean           989.1029
Q Predictions Std            433.02277
Q Predictions Max            1546.9824
Q Predictions Min            -29.554432
V Predictions Mean           998.5112
V Predictions Std            427.4828
V Predictions Max            1550.5962
V Predictions Min            75.98149
Log Pis Mean                 -0.099717885
Log Pis Std                  3.3832448
Log Pis Max                  14.744799
Log Pis Min                  -7.5507817
Policy mu Mean               0.02630828
Policy mu Std                0.6148988
Policy mu Max                3.1204498
Policy mu Min                -3.6405149
Policy log std Mean          -1.0150365
Policy log std Std           0.28798744
Policy log std Max           -0.036203623
Policy log std Min           -2.7577748
Z mean eval                  0.961041
Z variance eval              0.020847285
total_rewards                [1975.53698736 4016.11439398 4159.34263745 2790.44596107 4340.0069264
 3581.40658795 4257.81740963 4269.09586874 3994.71665792  657.7146655 ]
total_rewards_mean           3404.219809600558
total_rewards_std            1167.8265105969115
total_rewards_max            4340.006926400145
total_rewards_min            657.7146654978844
Number of train steps total  908000
Number of env steps total    1025416
Number of rollouts total     0
Train Time (s)               146.0303494790569
(Previous) Eval Time (s)     19.266332970932126
Sample Time (s)              7.824429979082197
Epoch Time (s)               173.12111242907122
Total Train Time (s)         37901.46217547823
Epoch                        226
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:52:18.395190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #226 | Epoch Duration: 173.21534657478333
2020-01-11 18:52:18.395363 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9560245
Z variance train             0.021025252
KL Divergence                16.796597
KL Loss                      1.6796597
QF Loss                      1016.25543
VF Loss                      111.10003
Policy Loss                  -1024.9664
Q Predictions Mean           1018.49713
Q Predictions Std            417.21426
Q Predictions Max            1590.4711
Q Predictions Min            0.38982105
V Predictions Mean           1021.7682
V Predictions Std            412.1974
V Predictions Max            1576.2708
V Predictions Min            240.85207
Log Pis Mean                 0.21255374
Log Pis Std                  3.2559865
Log Pis Max                  18.761333
Log Pis Min                  -7.383958
Policy mu Mean               -0.023081891
Policy mu Std                0.58147436
Policy mu Max                2.3783994
Policy mu Min                -2.9339144
Policy log std Mean          -1.0271668
Policy log std Std           0.2765489
Policy log std Max           -0.18844104
Policy log std Min           -2.4859362
Z mean eval                  1.024226
Z variance eval              0.012876813
total_rewards                [ 417.46622397   61.3619408  3075.71446245 1925.80286765 2398.48424583
 4174.74577287   12.52647552 3665.63271399 1234.43564988 4332.59775769]
total_rewards_mean           2129.8768110650153
total_rewards_std            1577.8628244573827
total_rewards_max            4332.597757690288
total_rewards_min            12.526475521186532
Number of train steps total  912000
Number of env steps total    1035266
Number of rollouts total     0
Train Time (s)               147.0208061109297
(Previous) Eval Time (s)     15.168227126821876
Sample Time (s)              7.378477691672742
Epoch Time (s)               169.56751092942432
Total Train Time (s)         38071.127774500754
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:55:08.062400 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #227 | Epoch Duration: 169.6669201850891
2020-01-11 18:55:08.062522 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.01669
Z variance train             0.012700451
KL Divergence                19.30486
KL Loss                      1.930486
QF Loss                      864.16455
VF Loss                      184.97568
Policy Loss                  -992.3169
Q Predictions Mean           990.45264
Q Predictions Std            436.80347
Q Predictions Max            1643.7538
Q Predictions Min            213.23773
V Predictions Mean           997.0929
V Predictions Std            435.48584
V Predictions Max            1642.8173
V Predictions Min            224.01828
Log Pis Mean                 -0.21939814
Log Pis Std                  3.5422385
Log Pis Max                  13.600241
Log Pis Min                  -11.660021
Policy mu Mean               -0.018702406
Policy mu Std                0.58722574
Policy mu Max                3.2195015
Policy mu Min                -2.7128713
Policy log std Mean          -1.0155389
Policy log std Std           0.27281046
Policy log std Max           0.095128775
Policy log std Min           -2.3032808
Z mean eval                  0.9384969
Z variance eval              0.015895793
total_rewards                [1600.25739691 4102.24700383 2055.23415045 4270.74312601  585.11828925
 4288.24946841 1355.41549864 2389.30005318 4089.0953187  2903.7880507 ]
total_rewards_mean           2763.944835607576
total_rewards_std            1299.562093096283
total_rewards_max            4288.249468413739
total_rewards_min            585.1182892457191
Number of train steps total  916000
Number of env steps total    1042553
Number of rollouts total     0
Train Time (s)               145.64291860489175
(Previous) Eval Time (s)     16.390521810390055
Sample Time (s)              8.253365764394403
Epoch Time (s)               170.2868061796762
Total Train Time (s)         38241.50081086205
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:57:58.436801 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #228 | Epoch Duration: 170.37418675422668
2020-01-11 18:57:58.436939 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9428023
Z variance train             0.015919061
KL Divergence                19.54689
KL Loss                      1.954689
QF Loss                      2133.9146
VF Loss                      666.6009
Policy Loss                  -972.0207
Q Predictions Mean           967.76965
Q Predictions Std            450.3118
Q Predictions Max            1518.0835
Q Predictions Min            203.2717
V Predictions Mean           976.94586
V Predictions Std            450.946
V Predictions Max            1527.9647
V Predictions Min            210.63585
Log Pis Mean                 0.21353726
Log Pis Std                  4.1637697
Log Pis Max                  37.75535
Log Pis Min                  -7.278336
Policy mu Mean               -0.021620821
Policy mu Std                0.6001742
Policy mu Max                3.2957973
Policy mu Min                -5.445593
Policy log std Mean          -1.0296531
Policy log std Std           0.3063799
Policy log std Max           -0.32416582
Policy log std Min           -2.6088643
Z mean eval                  0.95263016
Z variance eval              0.01280502
total_rewards                [1509.30436476 1881.31238164 4487.88685072 4216.9157565   827.04620137
  917.44025713 3886.40777047  319.22283008 2268.88870961  903.58220429]
total_rewards_mean           2121.8007326567576
total_rewards_std            1463.439330098804
total_rewards_max            4487.8868507185525
total_rewards_min            319.2228300750763
Number of train steps total  920000
Number of env steps total    1053753
Number of rollouts total     0
Train Time (s)               146.21178304310888
(Previous) Eval Time (s)     12.254462011158466
Sample Time (s)              7.374903226736933
Epoch Time (s)               165.84114828100428
Total Train Time (s)         38407.4296298977
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:00:44.367540 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #229 | Epoch Duration: 165.930499792099
2020-01-11 19:00:44.367668 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9566673
Z variance train             0.0128573375
KL Divergence                18.021976
KL Loss                      1.8021977
QF Loss                      853.52563
VF Loss                      182.66855
Policy Loss                  -1026.6119
Q Predictions Mean           1016.8342
Q Predictions Std            435.9372
Q Predictions Max            1553.5588
Q Predictions Min            182.38628
V Predictions Mean           1028.227
V Predictions Std            431.6909
V Predictions Max            1545.2329
V Predictions Min            248.2841
Log Pis Mean                 0.15275638
Log Pis Std                  3.3964937
Log Pis Max                  15.705734
Log Pis Min                  -8.100323
Policy mu Mean               -0.019300718
Policy mu Std                0.60516244
Policy mu Max                4.336897
Policy mu Min                -2.5439148
Policy log std Mean          -1.0257668
Policy log std Std           0.2791975
Policy log std Max           -0.233899
Policy log std Min           -2.3462248
Z mean eval                  0.92738676
Z variance eval              0.0060947374
total_rewards                [1980.09292912 4263.44706427 1994.33745668 4278.06495754 2950.72649921
 4361.54183822 1101.62052002 1615.34866835  183.01467575 3386.71281277]
total_rewards_mean           2611.490742192567
total_rewards_std            1386.8742842136141
total_rewards_max            4361.541838224137
total_rewards_min            183.01467574908207
Number of train steps total  924000
Number of env steps total    1061081
Number of rollouts total     0
Train Time (s)               147.67494226107374
(Previous) Eval Time (s)     15.683920393232256
Sample Time (s)              7.728173624258488
Epoch Time (s)               171.08703627856448
Total Train Time (s)         38578.66467411909
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:03:35.612407 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #230 | Epoch Duration: 171.24462485313416
2020-01-11 19:03:35.612588 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92790735
Z variance train             0.006099493
KL Divergence                19.624634
KL Loss                      1.9624634
QF Loss                      1249.1793
VF Loss                      191.33328
Policy Loss                  -1084.024
Q Predictions Mean           1079.2167
Q Predictions Std            440.68756
Q Predictions Max            1625.3124
Q Predictions Min            42.435577
V Predictions Mean           1082.001
V Predictions Std            437.18143
V Predictions Max            1612.6267
V Predictions Min            201.56508
Log Pis Mean                 0.23717996
Log Pis Std                  3.25887
Log Pis Max                  13.548338
Log Pis Min                  -8.691757
Policy mu Mean               -0.049261834
Policy mu Std                0.59346753
Policy mu Max                2.2978683
Policy mu Min                -2.6810813
Policy log std Mean          -1.0362489
Policy log std Std           0.27724302
Policy log std Max           -0.2722901
Policy log std Min           -2.1860821
Z mean eval                  0.9558304
Z variance eval              0.032225437
total_rewards                [2035.42754304 4438.08905634 4493.76284223 4031.69205868 4183.12992768
 4295.00341032 4306.18043368   36.18863061 4089.31253103 4010.83246951]
total_rewards_mean           3591.961890310835
total_rewards_std            1362.5537341496768
total_rewards_max            4493.7628422268845
total_rewards_min            36.1886306136212
Number of train steps total  928000
Number of env steps total    1071091
Number of rollouts total     0
Train Time (s)               146.2061426579021
(Previous) Eval Time (s)     21.168507820926607
Sample Time (s)              8.387079305946827
Epoch Time (s)               175.76172978477553
Total Train Time (s)         38754.51622752426
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:06:31.458212 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #231 | Epoch Duration: 175.84550166130066
2020-01-11 19:06:31.458346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #231 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9494006
Z variance train             0.032194413
KL Divergence                16.157932
KL Loss                      1.6157932
QF Loss                      1179.5305
VF Loss                      201.71725
Policy Loss                  -1035.066
Q Predictions Mean           1027.8826
Q Predictions Std            426.81796
Q Predictions Max            1595.735
Q Predictions Min            -17.87179
V Predictions Mean           1035.4437
V Predictions Std            421.53622
V Predictions Max            1584.8267
V Predictions Min            250.60419
Log Pis Mean                 0.29274073
Log Pis Std                  4.075251
Log Pis Max                  40.199287
Log Pis Min                  -7.9406295
Policy mu Mean               -0.02925453
Policy mu Std                0.6219718
Policy mu Max                4.101901
Policy mu Min                -5.2407875
Policy log std Mean          -1.0358078
Policy log std Std           0.2784422
Policy log std Max           -0.2159822
Policy log std Min           -2.5156524
Z mean eval                  1.0228332
Z variance eval              0.012172385
total_rewards                [4362.78361192 1138.78268002 4400.02117074 4390.57555119  581.2925577
 4360.35950664 2662.28882274 4331.01175114 4597.40304996 4375.19928584]
total_rewards_mean           3519.9717987883278
total_rewards_std            1433.1990926347787
total_rewards_max            4597.4030499567525
total_rewards_min            581.2925577020033
Number of train steps total  932000
Number of env steps total    1079511
Number of rollouts total     0
Train Time (s)               144.84732535574585
(Previous) Eval Time (s)     17.486390025820583
Sample Time (s)              7.336270637344569
Epoch Time (s)               169.669986018911
Total Train Time (s)         38924.2927803481
Epoch                        232
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:09:21.236944 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #232 | Epoch Duration: 169.77849984169006
2020-01-11 19:09:21.237060 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0222915
Z variance train             0.012145944
KL Divergence                18.214252
KL Loss                      1.8214253
QF Loss                      1924.1965
VF Loss                      316.5085
Policy Loss                  -1003.565
Q Predictions Mean           997.28204
Q Predictions Std            447.8558
Q Predictions Max            1578.7854
Q Predictions Min            -21.07232
V Predictions Mean           1002.86194
V Predictions Std            445.62628
V Predictions Max            1565.0381
V Predictions Min            -45.203285
Log Pis Mean                 0.34606355
Log Pis Std                  3.636918
Log Pis Max                  20.552113
Log Pis Min                  -7.9634094
Policy mu Mean               -0.06326703
Policy mu Std                0.6076115
Policy mu Max                3.238687
Policy mu Min                -3.4687011
Policy log std Mean          -1.0513575
Policy log std Std           0.29997554
Policy log std Max           -0.0627383
Policy log std Min           -2.3404846
Z mean eval                  0.9988059
Z variance eval              0.005696186
total_rewards                [4160.7423743  4312.64442587 4241.62832463 2319.66246364 4393.12794301
  744.63354272 4383.32076595 1225.96631747 4411.37509578   11.10937938]
total_rewards_mean           3020.4210632758222
total_rewards_std            1675.8397919679899
total_rewards_max            4411.3750957813045
total_rewards_min            11.109379376706153
Number of train steps total  936000
Number of env steps total    1088080
Number of rollouts total     0
Train Time (s)               146.62404253007844
(Previous) Eval Time (s)     14.887587196193635
Sample Time (s)              6.277398359961808
Epoch Time (s)               167.78902808623388
Total Train Time (s)         39092.168021572754
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:12:09.114677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #233 | Epoch Duration: 167.87750840187073
2020-01-11 19:12:09.114850 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9941158
Z variance train             0.0056935
KL Divergence                20.33674
KL Loss                      2.033674
QF Loss                      840.7285
VF Loss                      178.54762
Policy Loss                  -1061.4512
Q Predictions Mean           1060.3088
Q Predictions Std            434.27225
Q Predictions Max            1622.407
Q Predictions Min            8.961076
V Predictions Mean           1062.7844
V Predictions Std            435.9841
V Predictions Max            1629.4827
V Predictions Min            -52.456936
Log Pis Mean                 0.4191382
Log Pis Std                  3.7510698
Log Pis Max                  29.755596
Log Pis Min                  -10.149435
Policy mu Mean               -0.015838912
Policy mu Std                0.65671754
Policy mu Max                4.6308303
Policy mu Min                -3.6173759
Policy log std Mean          -1.0021788
Policy log std Std           0.28130436
Policy log std Max           0.5295236
Policy log std Min           -2.2873015
Z mean eval                  0.95793164
Z variance eval              0.06339449
total_rewards                [1418.92272932 4264.4778064  2526.63517493 4255.55449485 3434.64144167
 4152.46461151  870.70012913 4151.38738301 4563.86188131 4159.02220497]
total_rewards_mean           3379.766785710184
total_rewards_std            1249.906710738533
total_rewards_max            4563.861881314311
total_rewards_min            870.7001291282197
Number of train steps total  940000
Number of env steps total    1098402
Number of rollouts total     0
Train Time (s)               147.5479020131752
(Previous) Eval Time (s)     19.491029446013272
Sample Time (s)              7.095338326878846
Epoch Time (s)               174.1342697860673
Total Train Time (s)         39266.407928356435
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:15:03.357159 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #234 | Epoch Duration: 174.24217534065247
2020-01-11 19:15:03.357303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9675128
Z variance train             0.06371976
KL Divergence                16.20248
KL Loss                      1.6202481
QF Loss                      6013.922
VF Loss                      1502.4508
Policy Loss                  -1064.0043
Q Predictions Mean           1055.6232
Q Predictions Std            441.1628
Q Predictions Max            1593.9857
Q Predictions Min            -51.127678
V Predictions Mean           1060.6787
V Predictions Std            434.20224
V Predictions Max            1587.0856
V Predictions Min            -24.833595
Log Pis Mean                 0.60260737
Log Pis Std                  3.9974759
Log Pis Max                  24.586246
Log Pis Min                  -7.576546
Policy mu Mean               -0.03068135
Policy mu Std                0.6444872
Policy mu Max                5.341866
Policy mu Min                -4.1754847
Policy log std Mean          -1.041817
Policy log std Std           0.29442427
Policy log std Max           -0.15777242
Policy log std Min           -2.534193
Z mean eval                  1.0273389
Z variance eval              0.017785195
total_rewards                [4499.57716413 2906.24941118 1611.46405474 1301.73677824  319.04605217
 1419.96298604 4213.73477824 2866.91271023  391.53290357  671.81785142]
total_rewards_mean           2020.2034689960237
total_rewards_std            1444.612977536498
total_rewards_max            4499.577164129229
total_rewards_min            319.04605217300684
Number of train steps total  944000
Number of env steps total    1106771
Number of rollouts total     0
Train Time (s)               147.1422084113583
(Previous) Eval Time (s)     13.407091628294438
Sample Time (s)              8.461460317019373
Epoch Time (s)               169.0107603566721
Total Train Time (s)         39435.53994714795
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:17:52.491165 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #235 | Epoch Duration: 169.13375163078308
2020-01-11 19:17:52.491349 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0295998
Z variance train             0.017707746
KL Divergence                17.385757
KL Loss                      1.7385758
QF Loss                      710.4623
VF Loss                      98.55083
Policy Loss                  -1078.8696
Q Predictions Mean           1075.7048
Q Predictions Std            415.34375
Q Predictions Max            1573.0167
Q Predictions Min            245.73494
V Predictions Mean           1079.0713
V Predictions Std            413.42212
V Predictions Max            1573.655
V Predictions Min            247.97192
Log Pis Mean                 0.62270695
Log Pis Std                  3.2335784
Log Pis Max                  14.302135
Log Pis Min                  -7.9242344
Policy mu Mean               -0.0018615762
Policy mu Std                0.6112214
Policy mu Max                2.9538953
Policy mu Min                -3.1244016
Policy log std Mean          -1.0718799
Policy log std Std           0.27954683
Policy log std Max           -0.35312635
Policy log std Min           -2.3990808
Z mean eval                  0.97599506
Z variance eval              0.010352868
total_rewards                [2840.73097998   38.86493999  289.07441391 3847.61699027  693.08693467
 1110.0751403  3857.01471111 4133.59105733 4131.59231326 4330.44293774]
total_rewards_mean           2527.209041855815
total_rewards_std            1690.8486922078864
total_rewards_max            4330.44293774103
total_rewards_min            38.86493999463288
Number of train steps total  948000
Number of env steps total    1114153
Number of rollouts total     0
Train Time (s)               146.41531192697585
(Previous) Eval Time (s)     19.230950470082462
Sample Time (s)              7.379418820608407
Epoch Time (s)               173.02568121766672
Total Train Time (s)         39608.6535111703
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:20:45.606726 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #236 | Epoch Duration: 173.11524510383606
2020-01-11 19:20:45.606893 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9733863
Z variance train             0.010328321
KL Divergence                18.273209
KL Loss                      1.8273209
QF Loss                      702.07214
VF Loss                      222.26018
Policy Loss                  -1085.5615
Q Predictions Mean           1077.8735
Q Predictions Std            407.35205
Q Predictions Max            1600.7599
Q Predictions Min            43.630245
V Predictions Mean           1091.1653
V Predictions Std            404.11493
V Predictions Max            1620.3085
V Predictions Min            55.035656
Log Pis Mean                 -0.022976182
Log Pis Std                  3.0902581
Log Pis Max                  11.169921
Log Pis Min                  -11.828419
Policy mu Mean               -0.025473427
Policy mu Std                0.5659599
Policy mu Max                2.3271875
Policy mu Min                -2.6697671
Policy log std Mean          -1.0302286
Policy log std Std           0.2709124
Policy log std Max           0.08503747
Policy log std Min           -2.115259
Z mean eval                  0.94122016
Z variance eval              0.010318808
total_rewards                [4103.41982797 2524.05946724 1203.96350688 4434.39478577  996.60523755
 1475.59702338  141.92926023 4169.93268116 1057.00816094  884.58878606]
total_rewards_mean           2099.1498737167726
total_rewards_std            1507.8749426062604
total_rewards_max            4434.394785766808
total_rewards_min            141.92926023067156
Number of train steps total  952000
Number of env steps total    1122254
Number of rollouts total     0
Train Time (s)               146.07024861965328
(Previous) Eval Time (s)     17.6442453074269
Sample Time (s)              8.841035245917737
Epoch Time (s)               172.55552917299792
Total Train Time (s)         39781.29946530098
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:23:38.253866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #237 | Epoch Duration: 172.64685678482056
2020-01-11 19:23:38.253994 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94458437
Z variance train             0.010396622
KL Divergence                18.074844
KL Loss                      1.8074845
QF Loss                      593.9321
VF Loss                      111.65049
Policy Loss                  -1051.604
Q Predictions Mean           1048.0048
Q Predictions Std            430.36768
Q Predictions Max            1601.8586
Q Predictions Min            266.4575
V Predictions Mean           1047.246
V Predictions Std            429.61093
V Predictions Max            1607.0498
V Predictions Min            270.26297
Log Pis Mean                 -0.11118509
Log Pis Std                  3.249723
Log Pis Max                  11.926748
Log Pis Min                  -8.372932
Policy mu Mean               -0.0037895795
Policy mu Std                0.5795754
Policy mu Max                2.5977416
Policy mu Min                -2.3566613
Policy log std Mean          -1.0378914
Policy log std Std           0.28521776
Policy log std Max           -0.15766472
Policy log std Min           -2.4407892
Z mean eval                  0.9627821
Z variance eval              0.025124049
total_rewards                [1605.08452764 3017.53882036 4299.3432254  4403.68078167 2117.28218913
 3215.72761902  337.88471538 4512.23096995  455.45275098 4083.02597952]
total_rewards_mean           2804.7251579047215
total_rewards_std            1518.8970376237053
total_rewards_max            4512.230969946475
total_rewards_min            337.88471537933526
Number of train steps total  956000
Number of env steps total    1129760
Number of rollouts total     0
Train Time (s)               146.61005096510053
(Previous) Eval Time (s)     18.332943473942578
Sample Time (s)              7.51411343831569
Epoch Time (s)               172.4571078773588
Total Train Time (s)         39953.83976902999
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:26:30.796522 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #238 | Epoch Duration: 172.54243779182434
2020-01-11 19:26:30.796652 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9620439
Z variance train             0.025043866
KL Divergence                16.810455
KL Loss                      1.6810455
QF Loss                      805.34155
VF Loss                      325.60178
Policy Loss                  -1053.1648
Q Predictions Mean           1045.8145
Q Predictions Std            423.5106
Q Predictions Max            1594.0771
Q Predictions Min            -22.682783
V Predictions Mean           1043.7382
V Predictions Std            417.4322
V Predictions Max            1582.6427
V Predictions Min            10.107955
Log Pis Mean                 0.39533108
Log Pis Std                  3.4199023
Log Pis Max                  17.918905
Log Pis Min                  -7.270591
Policy mu Mean               -0.025082616
Policy mu Std                0.6147836
Policy mu Max                3.216931
Policy mu Min                -3.7638423
Policy log std Mean          -1.0269643
Policy log std Std           0.28694725
Policy log std Max           0.70535314
Policy log std Min           -2.1811032
Z mean eval                  1.0341903
Z variance eval              0.0069256267
total_rewards                [3910.57792033 1814.37121896 4558.01514598 4071.16925799 4410.01171779
 4276.34542732 1698.5121666  3550.75212443 4548.88149058 4347.68417056]
total_rewards_mean           3718.6320640547065
total_rewards_std            1023.4763195872378
total_rewards_max            4558.015145982903
total_rewards_min            1698.5121666024802
Number of train steps total  960000
Number of env steps total    1140722
Number of rollouts total     0
Train Time (s)               145.83049253188074
(Previous) Eval Time (s)     21.45102809043601
Sample Time (s)              7.446843537501991
Epoch Time (s)               174.72836415981874
Total Train Time (s)         40128.65094364341
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:29:25.609170 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #239 | Epoch Duration: 174.81241106987
2020-01-11 19:29:25.609301 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0309461
Z variance train             0.0068198843
KL Divergence                19.981012
KL Loss                      1.9981012
QF Loss                      1745.8491
VF Loss                      276.22275
Policy Loss                  -1083.1139
Q Predictions Mean           1074.8359
Q Predictions Std            414.81683
Q Predictions Max            1639.5245
Q Predictions Min            -28.778143
V Predictions Mean           1082.0864
V Predictions Std            408.75418
V Predictions Max            1605.372
V Predictions Min            -54.70713
Log Pis Mean                 0.7386112
Log Pis Std                  3.3609364
Log Pis Max                  13.601027
Log Pis Min                  -7.657585
Policy mu Mean               -0.027632846
Policy mu Std                0.60482836
Policy mu Max                2.119181
Policy mu Min                -3.09482
Policy log std Mean          -1.0815287
Policy log std Std           0.2946858
Policy log std Max           -0.44515526
Policy log std Min           -2.459537
Z mean eval                  1.0232996
Z variance eval              0.015958577
total_rewards                [4018.38868216  132.16684438  528.75078959 4386.78057462  410.14878714
 4242.50831292 2724.03157123 4387.22407458 4285.19704488 4245.46847573]
total_rewards_mean           2936.066515722791
total_rewards_std            1752.3004657257245
total_rewards_max            4387.224074581949
total_rewards_min            132.16684437890967
Number of train steps total  964000
Number of env steps total    1150334
Number of rollouts total     0
Train Time (s)               146.05250133620575
(Previous) Eval Time (s)     17.021254133898765
Sample Time (s)              7.26451266836375
Epoch Time (s)               170.33826813846827
Total Train Time (s)         40299.08207578724
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:32:16.043335 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #240 | Epoch Duration: 170.43392634391785
2020-01-11 19:32:16.043499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #240 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.013287
Z variance train             0.015965452
KL Divergence                17.378561
KL Loss                      1.7378561
QF Loss                      1048.762
VF Loss                      290.4463
Policy Loss                  -1028.1228
Q Predictions Mean           1022.5767
Q Predictions Std            448.7762
Q Predictions Max            1620.868
Q Predictions Min            28.03347
V Predictions Mean           1038.2509
V Predictions Std            444.10416
V Predictions Max            1619.8964
V Predictions Min            71.03135
Log Pis Mean                 0.2804451
Log Pis Std                  3.7035344
Log Pis Max                  20.850582
Log Pis Min                  -8.637246
Policy mu Mean               -0.037146732
Policy mu Std                0.60327
Policy mu Max                3.0951738
Policy mu Min                -2.8046894
Policy log std Mean          -1.017071
Policy log std Std           0.28624356
Policy log std Max           -0.31221652
Policy log std Min           -2.6038618
Z mean eval                  0.91866046
Z variance eval              0.017004179
total_rewards                [4268.0926122  4533.95479926 2203.58606371  408.08371681 3515.0431381
 3719.40635647 1467.05785174    7.96618192 4299.33382923 4183.14404034]
total_rewards_mean           2860.5668589780116
total_rewards_std            1621.4825477456632
total_rewards_max            4533.954799261426
total_rewards_min            7.9661819162654055
Number of train steps total  968000
Number of env steps total    1160344
Number of rollouts total     0
Train Time (s)               145.15123662305996
(Previous) Eval Time (s)     18.64895747601986
Sample Time (s)              8.143983935471624
Epoch Time (s)               171.94417803455144
Total Train Time (s)         40471.11925569503
Epoch                        241
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:35:08.083586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #241 | Epoch Duration: 172.03995513916016
2020-01-11 19:35:08.083773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9202651
Z variance train             0.01699869
KL Divergence                18.015251
KL Loss                      1.8015251
QF Loss                      813.40027
VF Loss                      225.32971
Policy Loss                  -1084.8441
Q Predictions Mean           1082.5267
Q Predictions Std            430.12683
Q Predictions Max            1679.8333
Q Predictions Min            204.00905
V Predictions Mean           1085.0153
V Predictions Std            427.99017
V Predictions Max            1674.887
V Predictions Min            200.70541
Log Pis Mean                 -0.15367618
Log Pis Std                  2.9342158
Log Pis Max                  9.87318
Log Pis Min                  -6.6910925
Policy mu Mean               -0.011250598
Policy mu Std                0.58204937
Policy mu Max                1.997952
Policy mu Min                -3.00778
Policy log std Mean          -1.0017282
Policy log std Std           0.26973227
Policy log std Max           -0.23294032
Policy log std Min           -2.4441814
Z mean eval                  0.86652595
Z variance eval              0.00811728
total_rewards                [4248.30306152 4284.49117217 4451.38146835 2605.82131405 4247.84979499
 4483.73711289  635.91103044 3825.58074412 4247.93506656 4388.22481936]
total_rewards_mean           3741.9235584450616
total_rewards_std            1160.9983924906533
total_rewards_max            4483.737112890195
total_rewards_min            635.9110304402047
Number of train steps total  972000
Number of env steps total    1170156
Number of rollouts total     0
Train Time (s)               145.97285675583407
(Previous) Eval Time (s)     17.9671049551107
Sample Time (s)              7.949752319604158
Epoch Time (s)               171.88971403054893
Total Train Time (s)         40643.09501308529
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:38:00.061659 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #242 | Epoch Duration: 171.9777636528015
2020-01-11 19:38:00.061782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86651546
Z variance train             0.008142455
KL Divergence                18.81514
KL Loss                      1.881514
QF Loss                      609.089
VF Loss                      188.749
Policy Loss                  -1085.7247
Q Predictions Mean           1083.2278
Q Predictions Std            426.66324
Q Predictions Max            1617.18
Q Predictions Min            146.57422
V Predictions Mean           1079.5293
V Predictions Std            426.45728
V Predictions Max            1596.6516
V Predictions Min            -40.41646
Log Pis Mean                 -0.02831782
Log Pis Std                  3.1827426
Log Pis Max                  10.732838
Log Pis Min                  -7.58939
Policy mu Mean               0.054121837
Policy mu Std                0.5875688
Policy mu Max                2.989885
Policy mu Min                -2.8208785
Policy log std Mean          -1.0279546
Policy log std Std           0.27366218
Policy log std Max           -0.3498034
Policy log std Min           -2.3404634
Z mean eval                  1.0132954
Z variance eval              0.0149414195
total_rewards                [4034.0494946  4426.74852851 2984.49480599 4488.24766395 2513.27871366
 4259.86126722 3540.4035306  3999.21614142 3865.03821512 4341.55457654]
total_rewards_mean           3845.289293760645
total_rewards_std            619.477847186261
total_rewards_max            4488.2476639513925
total_rewards_min            2513.2787136589445
Number of train steps total  976000
Number of env steps total    1178557
Number of rollouts total     0
Train Time (s)               147.43829506915063
(Previous) Eval Time (s)     20.395654409192502
Sample Time (s)              6.2288283058442175
Epoch Time (s)               174.06277778418735
Total Train Time (s)         40817.562358905096
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:40:54.532000 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #243 | Epoch Duration: 174.4701042175293
2020-01-11 19:40:54.532191 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0139118
Z variance train             0.015017335
KL Divergence                18.40437
KL Loss                      1.8404369
QF Loss                      1090.948
VF Loss                      205.27509
Policy Loss                  -1035.8911
Q Predictions Mean           1028.7194
Q Predictions Std            401.55154
Q Predictions Max            1535.6595
Q Predictions Min            247.86949
V Predictions Mean           1035.593
V Predictions Std            400.02573
V Predictions Max            1534.872
V Predictions Min            261.28714
Log Pis Mean                 0.43372446
Log Pis Std                  3.2343986
Log Pis Max                  11.61652
Log Pis Min                  -8.07897
Policy mu Mean               -0.010974047
Policy mu Std                0.6242647
Policy mu Max                2.5215485
Policy mu Min                -3.185829
Policy log std Mean          -1.0422649
Policy log std Std           0.30838123
Policy log std Max           -0.39361453
Policy log std Min           -2.6011078
Z mean eval                  1.0625545
Z variance eval              0.01778194
total_rewards                [4229.83684007 4141.67776461 4009.49117636 4104.7010454  4497.31099554
 4184.04697437 4387.71316563 4109.82755842 4231.39800259 4007.7221623 ]
total_rewards_mean           4190.372568528173
total_rewards_std            147.8893433390775
total_rewards_max            4497.310995536893
total_rewards_min            4007.7221622993093
Number of train steps total  980000
Number of env steps total    1187804
Number of rollouts total     0
Train Time (s)               147.26454979507253
(Previous) Eval Time (s)     21.04808470699936
Sample Time (s)              7.644937968812883
Epoch Time (s)               175.95757247088477
Total Train Time (s)         40993.60806085123
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:43:50.580454 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #244 | Epoch Duration: 176.04810166358948
2020-01-11 19:43:50.580655 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0593954
Z variance train             0.017563183
KL Divergence                17.819427
KL Loss                      1.7819427
QF Loss                      797.7419
VF Loss                      404.57275
Policy Loss                  -1079.4124
Q Predictions Mean           1075.3345
Q Predictions Std            442.31567
Q Predictions Max            1686.8809
Q Predictions Min            46.25234
V Predictions Mean           1069.0625
V Predictions Std            435.31387
V Predictions Max            1663.6411
V Predictions Min            259.98468
Log Pis Mean                 0.18097803
Log Pis Std                  2.9370754
Log Pis Max                  15.413373
Log Pis Min                  -6.9233155
Policy mu Mean               -0.07197998
Policy mu Std                0.6138178
Policy mu Max                2.3417923
Policy mu Min                -2.7733867
Policy log std Mean          -1.0014834
Policy log std Std           0.27433306
Policy log std Max           -0.2853912
Policy log std Min           -2.4870539
Z mean eval                  0.9293969
Z variance eval              0.014581877
total_rewards                [2472.95543027 4482.20018999 2791.43295764 4601.38512737 4465.89070675
 2229.35765099 4154.55172058 2732.02903665 3477.72308243 2375.07972823]
total_rewards_mean           3378.2605630911467
total_rewards_std            917.5012468426385
total_rewards_max            4601.385127365161
total_rewards_min            2229.357650994879
Number of train steps total  984000
Number of env steps total    1197802
Number of rollouts total     0
Train Time (s)               148.64688286278397
(Previous) Eval Time (s)     19.06496981717646
Sample Time (s)              7.286512971390039
Epoch Time (s)               174.99836565135047
Total Train Time (s)         41168.69361128984
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:46:45.667357 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #245 | Epoch Duration: 175.08657002449036
2020-01-11 19:46:45.667491 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92914695
Z variance train             0.014606488
KL Divergence                17.642445
KL Loss                      1.7642444
QF Loss                      793.71985
VF Loss                      130.14348
Policy Loss                  -1091.7622
Q Predictions Mean           1088.9094
Q Predictions Std            437.44403
Q Predictions Max            1651.0687
Q Predictions Min            276.5016
V Predictions Mean           1096.4618
V Predictions Std            435.45316
V Predictions Max            1658.7385
V Predictions Min            291.78528
Log Pis Mean                 0.33919707
Log Pis Std                  3.231005
Log Pis Max                  11.602787
Log Pis Min                  -6.6461954
Policy mu Mean               -0.00079825753
Policy mu Std                0.6078011
Policy mu Max                2.541887
Policy mu Min                -2.4981968
Policy log std Mean          -1.0287838
Policy log std Std           0.30387154
Policy log std Max           -0.16015822
Policy log std Min           -2.3360624
Z mean eval                  1.0179769
Z variance eval              0.019913003
total_rewards                [4228.43733767 3420.01242158 4110.80435724 3856.61957188 4119.62014074
 3996.07407118 3671.61363582 4456.38625272 3508.07039046 4192.4402971 ]
total_rewards_mean           3956.0078476386057
total_rewards_std            318.0456070985986
total_rewards_max            4456.386252718356
total_rewards_min            3420.012421581481
Number of train steps total  988000
Number of env steps total    1208504
Number of rollouts total     0
Train Time (s)               146.53206134401262
(Previous) Eval Time (s)     23.98126071691513
Sample Time (s)              7.270837540272623
Epoch Time (s)               177.78415960120037
Total Train Time (s)         41346.58071847586
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:49:43.559313 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #246 | Epoch Duration: 177.89170742034912
2020-01-11 19:49:43.559509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0261652
Z variance train             0.019564012
KL Divergence                15.989075
KL Loss                      1.5989075
QF Loss                      1502.7212
VF Loss                      327.36554
Policy Loss                  -1020.6663
Q Predictions Mean           1014.298
Q Predictions Std            412.9972
Q Predictions Max            1605.0183
Q Predictions Min            260.04834
V Predictions Mean           1023.54987
V Predictions Std            412.60925
V Predictions Max            1605.5525
V Predictions Min            278.26624
Log Pis Mean                 0.4766187
Log Pis Std                  3.4106631
Log Pis Max                  18.942196
Log Pis Min                  -6.652478
Policy mu Mean               -0.08954369
Policy mu Std                0.61776054
Policy mu Max                2.6827006
Policy mu Min                -2.955787
Policy log std Mean          -1.04257
Policy log std Std           0.3081608
Policy log std Max           -0.24649101
Policy log std Min           -2.3729746
Z mean eval                  0.91435397
Z variance eval              0.056240357
total_rewards                [4512.67448183 4260.01166078 4468.75917007 2246.89624464 4230.20301145
 1664.11956551 4545.27900163 4308.51395768 1371.25113044 4158.20237668]
total_rewards_mean           3576.5910600690395
total_rewards_std            1211.114664851031
total_rewards_max            4545.279001627012
total_rewards_min            1371.2511304359575
Number of train steps total  992000
Number of env steps total    1218718
Number of rollouts total     0
Train Time (s)               147.2243572738953
(Previous) Eval Time (s)     21.35556802712381
Sample Time (s)              7.497987689450383
Epoch Time (s)               176.07791299046949
Total Train Time (s)         41522.76627980871
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:52:39.746323 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #247 | Epoch Duration: 176.1866888999939
2020-01-11 19:52:39.746461 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90533257
Z variance train             0.056747325
KL Divergence                15.350549
KL Loss                      1.5350549
QF Loss                      835.79016
VF Loss                      126.58269
Policy Loss                  -1120.425
Q Predictions Mean           1117.5168
Q Predictions Std            440.33005
Q Predictions Max            1679.6375
Q Predictions Min            290.24472
V Predictions Mean           1123.6907
V Predictions Std            436.99942
V Predictions Max            1685.9689
V Predictions Min            299.87616
Log Pis Mean                 0.19202426
Log Pis Std                  3.3651092
Log Pis Max                  11.762138
Log Pis Min                  -7.283245
Policy mu Mean               -0.008985084
Policy mu Std                0.62372005
Policy mu Max                2.285076
Policy mu Min                -2.8096368
Policy log std Mean          -1.0385087
Policy log std Std           0.32338214
Policy log std Max           -0.2869581
Policy log std Min           -2.5728998
Z mean eval                  1.100898
Z variance eval              0.039867256
total_rewards                [3985.35928997 2738.50144722 3524.68769235  411.43393053 3880.31784861
 3913.12399328 4010.29442199 4155.8428048  4276.0309342  1436.57941896]
total_rewards_mean           3233.2171781920206
total_rewards_std            1245.3651906307916
total_rewards_max            4276.030934203834
total_rewards_min            411.43393053280795
Number of train steps total  996000
Number of env steps total    1228335
Number of rollouts total     0
Train Time (s)               145.74972484493628
(Previous) Eval Time (s)     21.48528989776969
Sample Time (s)              7.218408292159438
Epoch Time (s)               174.4534230348654
Total Train Time (s)         41697.312095772475
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:55:34.293757 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #248 | Epoch Duration: 174.5472002029419
2020-01-11 19:55:34.293886 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1033568
Z variance train             0.040050767
KL Divergence                17.991192
KL Loss                      1.7991192
QF Loss                      898.0348
VF Loss                      209.35579
Policy Loss                  -1131.1276
Q Predictions Mean           1126.5759
Q Predictions Std            432.71606
Q Predictions Max            1679.9542
Q Predictions Min            290.3745
V Predictions Mean           1124.2477
V Predictions Std            429.26056
V Predictions Max            1680.1964
V Predictions Min            282.71097
Log Pis Mean                 0.23347111
Log Pis Std                  3.2816443
Log Pis Max                  10.236598
Log Pis Min                  -7.829558
Policy mu Mean               0.0132647175
Policy mu Std                0.6415854
Policy mu Max                2.734565
Policy mu Min                -2.9233751
Policy log std Mean          -0.98964983
Policy log std Std           0.31094348
Policy log std Max           -0.15930963
Policy log std Min           -2.6903193
Z mean eval                  0.93672454
Z variance eval              0.023198634
total_rewards                [1450.00376544 4475.32232404 3002.59547457 4010.19063131 2058.78667139
 3364.13685685 1669.49991219 4448.0515459     9.60114315 4247.04212969]
total_rewards_mean           2873.523045453209
total_rewards_std            1443.0091224488376
total_rewards_max            4475.322324041925
total_rewards_min            9.601143151293625
Number of train steps total  1000000
Number of env steps total    1238375
Number of rollouts total     0
Train Time (s)               146.81984106916934
(Previous) Eval Time (s)     19.465709306765348
Sample Time (s)              7.7242831834591925
Epoch Time (s)               174.00983355939388
Total Train Time (s)         41871.48201493174
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:58:28.470140 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #249 | Epoch Duration: 174.176123380661
2020-01-11 19:58:28.470414 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94127923
Z variance train             0.02317489
KL Divergence                18.633175
KL Loss                      1.8633175
QF Loss                      1177.4875
VF Loss                      443.55054
Policy Loss                  -1115.9393
Q Predictions Mean           1109.4062
Q Predictions Std            437.04623
Q Predictions Max            1668.5916
Q Predictions Min            -15.254794
V Predictions Mean           1106.764
V Predictions Std            431.19083
V Predictions Max            1658.9905
V Predictions Min            261.12546
Log Pis Mean                 0.48031124
Log Pis Std                  3.3822827
Log Pis Max                  15.293879
Log Pis Min                  -6.8280396
Policy mu Mean               -0.021881498
Policy mu Std                0.62485504
Policy mu Max                4.142482
Policy mu Min                -2.5434213
Policy log std Mean          -1.0294762
Policy log std Std           0.30609238
Policy log std Max           0.029337764
Policy log std Min           -2.2511153
Z mean eval                  0.97074556
Z variance eval              0.013057654
total_rewards                [4528.54452671 4228.62345394 4186.85051198   46.82407801 4598.25203609
 4398.89608458 4426.45739743 4632.76419963 4410.07397939 4374.32780996]
total_rewards_mean           3983.161407770787
total_rewards_std            1319.047671981071
total_rewards_max            4632.76419962732
total_rewards_min            46.82407800682871
Number of train steps total  1004000
Number of env steps total    1247818
Number of rollouts total     0
Train Time (s)               146.48079588031396
(Previous) Eval Time (s)     19.099742677994072
Sample Time (s)              7.19110423931852
Epoch Time (s)               172.77164279762655
Total Train Time (s)         42044.348155037966
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:01:21.339683 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #250 | Epoch Duration: 172.8690629005432
2020-01-11 20:01:21.339899 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9691205
Z variance train             0.013067807
KL Divergence                19.163073
KL Loss                      1.9163073
QF Loss                      1778.814
VF Loss                      167.08963
Policy Loss                  -1115.7184
Q Predictions Mean           1112.929
Q Predictions Std            419.6323
Q Predictions Max            1634.1139
Q Predictions Min            39.92983
V Predictions Mean           1120.8274
V Predictions Std            418.87387
V Predictions Max            1629.9501
V Predictions Min            33.499413
Log Pis Mean                 0.21818577
Log Pis Std                  3.6680205
Log Pis Max                  15.486919
Log Pis Min                  -9.367874
Policy mu Mean               -0.009119308
Policy mu Std                0.62826675
Policy mu Max                2.5271566
Policy mu Min                -3.5467157
Policy log std Mean          -1.039386
Policy log std Std           0.31556103
Policy log std Max           -0.2240771
Policy log std Min           -2.5088105
Z mean eval                  0.8573019
Z variance eval              0.042831298
total_rewards                [ 774.32964976 3841.68038926 2621.65534481 4312.69701354 4755.97740129
 4510.42304306 4356.30233057 1136.67483916 3952.03825122 4249.2921773 ]
total_rewards_mean           3451.1070439967625
total_rewards_std            1365.168696809845
total_rewards_max            4755.977401293763
total_rewards_min            774.3296497588053
Number of train steps total  1008000
Number of env steps total    1256725
Number of rollouts total     0
Train Time (s)               147.45018149679527
(Previous) Eval Time (s)     19.552846777718514
Sample Time (s)              7.339808419812471
Epoch Time (s)               174.34283669432625
Total Train Time (s)         42218.79587793443
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:04:15.792463 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #251 | Epoch Duration: 174.45240998268127
2020-01-11 20:04:15.792629 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #251 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8592002
Z variance train             0.042893596
KL Divergence                18.563404
KL Loss                      1.8563404
QF Loss                      853.5449
VF Loss                      116.51091
Policy Loss                  -1123.5487
Q Predictions Mean           1116.6765
Q Predictions Std            427.0953
Q Predictions Max            1708.7864
Q Predictions Min            93.54506
V Predictions Mean           1125.2947
V Predictions Std            420.76804
V Predictions Max            1701.8102
V Predictions Min            268.90463
Log Pis Mean                 0.19383426
Log Pis Std                  3.3412945
Log Pis Max                  15.584903
Log Pis Min                  -8.080096
Policy mu Mean               -0.05581699
Policy mu Std                0.6342359
Policy mu Max                2.5300424
Policy mu Min                -4.318058
Policy log std Mean          -1.0327736
Policy log std Std           0.29640225
Policy log std Max           -0.31723744
Policy log std Min           -2.3486009
Z mean eval                  0.94762355
Z variance eval              0.022436421
total_rewards                [4446.06875375 4374.88038622 4493.08869478 4275.26805594 4212.4786033
 4246.05703237 4353.02896302 4079.40515798 4374.5862238  4318.30103012]
total_rewards_mean           4317.316290128301
total_rewards_std            113.92170710510139
total_rewards_max            4493.088694777314
total_rewards_min            4079.4051579805723
Number of train steps total  1012000
Number of env steps total    1266426
Number of rollouts total     0
Train Time (s)               147.50997381005436
(Previous) Eval Time (s)     21.36624225322157
Sample Time (s)              7.0913719376549125
Epoch Time (s)               175.96758800093085
Total Train Time (s)         42394.85327819083
Epoch                        252
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:07:11.852205 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #252 | Epoch Duration: 176.0594446659088
2020-01-11 20:07:11.852380 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9470359
Z variance train             0.022579536
KL Divergence                17.372972
KL Loss                      1.7372973
QF Loss                      763.8219
VF Loss                      200.3288
Policy Loss                  -1137.3307
Q Predictions Mean           1133.5803
Q Predictions Std            413.665
Q Predictions Max            1665.4664
Q Predictions Min            307.13608
V Predictions Mean           1146.3306
V Predictions Std            412.29962
V Predictions Max            1681.3022
V Predictions Min            315.90997
Log Pis Mean                 0.50852525
Log Pis Std                  3.2479546
Log Pis Max                  13.331638
Log Pis Min                  -9.138624
Policy mu Mean               0.0050601256
Policy mu Std                0.66593575
Policy mu Max                3.564655
Policy mu Min                -2.8676784
Policy log std Mean          -1.0019801
Policy log std Std           0.30380166
Policy log std Max           -0.2307018
Policy log std Min           -2.3763907
Z mean eval                  0.9971959
Z variance eval              0.021251108
total_rewards                [ 438.05100603 3647.40861085 1634.6377949  4180.05935112 2497.71912036
 4532.11474834  149.60789529 4429.75478262 4367.33699026 4485.09199571]
total_rewards_mean           3036.17822954879
total_rewards_std            1645.299066772955
total_rewards_max            4532.114748341041
total_rewards_min            149.6078952944051
Number of train steps total  1016000
Number of env steps total    1273640
Number of rollouts total     0
Train Time (s)               146.3016569148749
(Previous) Eval Time (s)     17.99060367932543
Sample Time (s)              6.26476133055985
Epoch Time (s)               170.5570219247602
Total Train Time (s)         42565.5018360191
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:10:02.503619 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #253 | Epoch Duration: 170.65109419822693
2020-01-11 20:10:02.503814 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0037895
Z variance train             0.021340525
KL Divergence                17.218513
KL Loss                      1.7218513
QF Loss                      704.4727
VF Loss                      524.2762
Policy Loss                  -1151.3225
Q Predictions Mean           1145.0879
Q Predictions Std            434.04483
Q Predictions Max            1718.0822
Q Predictions Min            4.490333
V Predictions Mean           1139.5605
V Predictions Std            425.94235
V Predictions Max            1703.1023
V Predictions Min            198.33945
Log Pis Mean                 0.39734748
Log Pis Std                  3.503488
Log Pis Max                  15.63241
Log Pis Min                  -5.8304586
Policy mu Mean               -0.0145085715
Policy mu Std                0.64235663
Policy mu Max                3.2596831
Policy mu Min                -2.720138
Policy log std Mean          -0.99742323
Policy log std Std           0.30719855
Policy log std Max           -0.22557563
Policy log std Min           -2.6816368
Z mean eval                  1.0270063
Z variance eval              0.06744175
total_rewards                [4452.90637249 4157.07680945 4331.49036714 4003.8235707  4383.66368894
 3468.68246394 4487.67651263 2626.62301001 4379.25206073 4212.645744  ]
total_rewards_mean           4050.384060003556
total_rewards_std            552.8880067835343
total_rewards_max            4487.676512633479
total_rewards_min            2626.623010006086
Number of train steps total  1020000
Number of env steps total    1283148
Number of rollouts total     0
Train Time (s)               147.54227703204378
(Previous) Eval Time (s)     22.983533864840865
Sample Time (s)              7.146630925126374
Epoch Time (s)               177.67244182201102
Total Train Time (s)         42743.2702697115
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:13:00.273586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #254 | Epoch Duration: 177.7696464061737
2020-01-11 20:13:00.273721 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0279866
Z variance train             0.067596644
KL Divergence                14.438133
KL Loss                      1.4438133
QF Loss                      1348.3362
VF Loss                      251.4993
Policy Loss                  -1141.7559
Q Predictions Mean           1131.8129
Q Predictions Std            407.04077
Q Predictions Max            1658.98
Q Predictions Min            -127.43465
V Predictions Mean           1148.1307
V Predictions Std            393.38132
V Predictions Max            1655.0269
V Predictions Min            314.98343
Log Pis Mean                 0.34548885
Log Pis Std                  3.2159317
Log Pis Max                  10.343415
Log Pis Min                  -7.0897675
Policy mu Mean               0.0020529283
Policy mu Std                0.60239565
Policy mu Max                2.3435147
Policy mu Min                -2.4025385
Policy log std Mean          -1.0555253
Policy log std Std           0.306878
Policy log std Max           -0.2993058
Policy log std Min           -2.3424277
Z mean eval                  1.2960942
Z variance eval              0.04282055
total_rewards                [4048.58630616 4181.55134748 3332.26353518 4088.4807113  4518.46344474
 4021.49803022 4232.16491846 4334.20689638 4318.71216665 4427.41463364]
total_rewards_mean           4150.334199021217
total_rewards_std            313.3912333961228
total_rewards_max            4518.463444743996
total_rewards_min            3332.263535180362
Number of train steps total  1024000
Number of env steps total    1290474
Number of rollouts total     0
Train Time (s)               146.26396775292233
(Previous) Eval Time (s)     23.40992822498083
Sample Time (s)              7.28491714829579
Epoch Time (s)               176.95881312619895
Total Train Time (s)         42920.31344360253
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:15:57.318511 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #255 | Epoch Duration: 177.044695854187
2020-01-11 20:15:57.318663 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2929863
Z variance train             0.04319607
KL Divergence                15.346523
KL Loss                      1.5346524
QF Loss                      1584.2355
VF Loss                      221.89978
Policy Loss                  -1071.1216
Q Predictions Mean           1069.9791
Q Predictions Std            446.4245
Q Predictions Max            1680.2035
Q Predictions Min            44.187607
V Predictions Mean           1067.7559
V Predictions Std            447.06735
V Predictions Max            1676.7153
V Predictions Min            -46.725864
Log Pis Mean                 0.22994272
Log Pis Std                  3.2666073
Log Pis Max                  14.50222
Log Pis Min                  -7.969261
Policy mu Mean               -0.05209135
Policy mu Std                0.61995345
Policy mu Max                2.4483922
Policy mu Min                -3.3787751
Policy log std Mean          -0.98048836
Policy log std Std           0.32510883
Policy log std Max           1.3500888
Policy log std Min           -2.563734
Z mean eval                  1.018167
Z variance eval              0.009569755
total_rewards                [4379.28457146 4078.27324676 1004.49979896 4170.88719553 4580.03041116
 4356.97915883 4317.37257979 4325.68700334 4164.92967019 4292.45147162]
total_rewards_mean           3967.0395107633717
total_rewards_std            996.2298867451351
total_rewards_max            4580.030411159158
total_rewards_min            1004.4997989596882
Number of train steps total  1028000
Number of env steps total    1301312
Number of rollouts total     0
Train Time (s)               146.7376505723223
(Previous) Eval Time (s)     22.5881544072181
Sample Time (s)              7.689836053177714
Epoch Time (s)               177.01564103271812
Total Train Time (s)         43097.42858724808
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:18:54.436900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #256 | Epoch Duration: 177.11813235282898
2020-01-11 20:18:54.437073 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0219178
Z variance train             0.009619473
KL Divergence                19.785685
KL Loss                      1.9785684
QF Loss                      3371.6538
VF Loss                      251.25902
Policy Loss                  -1165.2856
Q Predictions Mean           1160.3109
Q Predictions Std            423.3956
Q Predictions Max            1705.0002
Q Predictions Min            316.92062
V Predictions Mean           1159.5723
V Predictions Std            421.39917
V Predictions Max            1699.4365
V Predictions Min            312.383
Log Pis Mean                 0.37744647
Log Pis Std                  3.3212285
Log Pis Max                  10.687199
Log Pis Min                  -7.066723
Policy mu Mean               -0.003321642
Policy mu Std                0.6275904
Policy mu Max                2.6110582
Policy mu Min                -2.7537615
Policy log std Mean          -1.0376563
Policy log std Std           0.32187802
Policy log std Max           -0.3124156
Policy log std Min           -2.8807156
Z mean eval                  1.0102334
Z variance eval              0.0073967925
total_rewards                [1481.16164444  975.94169234  218.43640422 4328.48465407 4507.83037437
 4193.93366654 1047.31322279 4109.50828198 4420.11893955 4157.33451226]
total_rewards_mean           2944.0063392560855
total_rewards_std            1672.5274852024402
total_rewards_max            4507.8303743699635
total_rewards_min            218.4364042223415
Number of train steps total  1032000
Number of env steps total    1310724
Number of rollouts total     0
Train Time (s)               147.15652562864125
(Previous) Eval Time (s)     14.766544472891837
Sample Time (s)              7.728897288907319
Epoch Time (s)               169.6519673904404
Total Train Time (s)         43267.16612913646
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:21:44.176127 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #257 | Epoch Duration: 169.73893690109253
2020-01-11 20:21:44.176248 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0100113
Z variance train             0.007402307
KL Divergence                19.19442
KL Loss                      1.919442
QF Loss                      4884.5986
VF Loss                      187.91927
Policy Loss                  -1127.4374
Q Predictions Mean           1121.5948
Q Predictions Std            426.59177
Q Predictions Max            1722.4338
Q Predictions Min            326.66382
V Predictions Mean           1123.3616
V Predictions Std            426.29733
V Predictions Max            1704.5193
V Predictions Min            322.02353
Log Pis Mean                 0.031171829
Log Pis Std                  3.5989046
Log Pis Max                  21.317953
Log Pis Min                  -7.545041
Policy mu Mean               0.005151487
Policy mu Std                0.6276264
Policy mu Max                3.2822797
Policy mu Min                -3.3084316
Policy log std Mean          -1.002588
Policy log std Std           0.33855635
Policy log std Max           -0.33620638
Policy log std Min           -2.681993
Z mean eval                  0.9859125
Z variance eval              0.016806953
total_rewards                [4459.16779485 4411.43512521 3231.5787441  4207.06417487 4068.04979338
 4142.6370034   618.78146818 2078.06162719   22.04962209 4337.19029109]
total_rewards_mean           3157.601564436244
total_rewards_std            1581.3398730877736
total_rewards_max            4459.167794854027
total_rewards_min            22.049622090380282
Number of train steps total  1036000
Number of env steps total    1319508
Number of rollouts total     0
Train Time (s)               146.56487093539909
(Previous) Eval Time (s)     18.196633127052337
Sample Time (s)              6.486884186044335
Epoch Time (s)               171.24838824849576
Total Train Time (s)         43438.50256376015
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:24:35.514326 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #258 | Epoch Duration: 171.3379831314087
2020-01-11 20:24:35.514459 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #258 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.986677
Z variance train             0.0168983
KL Divergence                19.124317
KL Loss                      1.9124317
QF Loss                      852.0931
VF Loss                      119.929016
Policy Loss                  -1110.7959
Q Predictions Mean           1109.3545
Q Predictions Std            458.40945
Q Predictions Max            1739.598
Q Predictions Min            317.6572
V Predictions Mean           1115.7808
V Predictions Std            456.06815
V Predictions Max            1745.8883
V Predictions Min            320.6856
Log Pis Mean                 0.35704118
Log Pis Std                  3.715355
Log Pis Max                  13.387763
Log Pis Min                  -6.3125362
Policy mu Mean               0.020841891
Policy mu Std                0.62449545
Policy mu Max                2.5945132
Policy mu Min                -2.4068003
Policy log std Mean          -0.99227434
Policy log std Std           0.33707392
Policy log std Max           -0.3742658
Policy log std Min           -2.6402123
Z mean eval                  0.94171417
Z variance eval              0.009236179
total_rewards                [4339.12937344 4362.0658885  3057.34575262 4586.13820698 4374.3773682
 4627.7162367  4588.0856022  4351.71186718 4409.30795754 4242.94746795]
total_rewards_mean           4293.882572130916
total_rewards_std            429.51999746992857
total_rewards_max            4627.716236704336
total_rewards_min            3057.345752620726
Number of train steps total  1040000
Number of env steps total    1330262
Number of rollouts total     0
Train Time (s)               148.270577641204
(Previous) Eval Time (s)     23.535495267715305
Sample Time (s)              7.740566095337272
Epoch Time (s)               179.54663900425658
Total Train Time (s)         43618.137316721026
Epoch                        259
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:27:35.150852 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #259 | Epoch Duration: 179.6363022327423
2020-01-11 20:27:35.150983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9433359
Z variance train             0.009206794
KL Divergence                18.779007
KL Loss                      1.8779007
QF Loss                      858.5246
VF Loss                      167.47978
Policy Loss                  -1146.8309
Q Predictions Mean           1142.1843
Q Predictions Std            420.73972
Q Predictions Max            1732.139
Q Predictions Min            136.91258
V Predictions Mean           1142.5938
V Predictions Std            412.7966
V Predictions Max            1708.9252
V Predictions Min            313.77292
Log Pis Mean                 0.29545128
Log Pis Std                  3.2125852
Log Pis Max                  15.087541
Log Pis Min                  -6.5465217
Policy mu Mean               -0.020437974
Policy mu Std                0.6186801
Policy mu Max                2.3346488
Policy mu Min                -2.689066
Policy log std Mean          -1.0161712
Policy log std Std           0.30725574
Policy log std Max           -0.09345025
Policy log std Min           -2.2703063
Z mean eval                  1.1209414
Z variance eval              0.113998935
total_rewards                [ 802.00421455 4077.22003404 4068.28413706  596.18152485 4080.96515606
 3937.42248944 1316.68342638 1495.55981614 3100.76462604 3882.17995835]
total_rewards_mean           2735.72653829016
total_rewards_std            1419.3412078451545
total_rewards_max            4080.9651560563634
total_rewards_min            596.181524846306
Number of train steps total  1044000
Number of env steps total    1339096
Number of rollouts total     0
Train Time (s)               148.38101520994678
(Previous) Eval Time (s)     18.45090964017436
Sample Time (s)              7.10623259562999
Epoch Time (s)               173.93815744575113
Total Train Time (s)         43792.16483684257
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:30:29.182091 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #260 | Epoch Duration: 174.03101468086243
2020-01-11 20:30:29.182224 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #260 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.128196
Z variance train             0.11377736
KL Divergence                18.15481
KL Loss                      1.8154811
QF Loss                      1255.1829
VF Loss                      491.5666
Policy Loss                  -1135.0283
Q Predictions Mean           1129.8325
Q Predictions Std            413.30453
Q Predictions Max            1685.0956
Q Predictions Min            116.43638
V Predictions Mean           1134.2512
V Predictions Std            414.5101
V Predictions Max            1680.1493
V Predictions Min            -14.179445
Log Pis Mean                 0.3754841
Log Pis Std                  3.905049
Log Pis Max                  25.359497
Log Pis Min                  -8.034541
Policy mu Mean               -0.0383934
Policy mu Std                0.65924644
Policy mu Max                3.315299
Policy mu Min                -5.3310647
Policy log std Mean          -1.0184097
Policy log std Std           0.3347244
Policy log std Max           -0.1413393
Policy log std Min           -2.803409
Z mean eval                  0.89686763
Z variance eval              0.030058226
total_rewards                [4475.96544411 4710.3423894  4530.28846068 2463.95462952  798.6022118
 4322.24592894 2135.79123027 4556.95747734 4492.60150642 4379.49351213]
total_rewards_mean           3686.6242790616934
total_rewards_std            1300.563916026686
total_rewards_max            4710.342389396306
total_rewards_min            798.6022118049916
Number of train steps total  1048000
Number of env steps total    1346500
Number of rollouts total     0
Train Time (s)               146.71242997981608
(Previous) Eval Time (s)     21.305976774077863
Sample Time (s)              7.111092755105346
Epoch Time (s)               175.1294995089993
Total Train Time (s)         43967.3827996715
Epoch                        261
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:33:24.401358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #261 | Epoch Duration: 175.21904373168945
2020-01-11 20:33:24.401489 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8961288
Z variance train             0.030088132
KL Divergence                16.514505
KL Loss                      1.6514505
QF Loss                      656.5442
VF Loss                      145.4957
Policy Loss                  -1115.6351
Q Predictions Mean           1115.1085
Q Predictions Std            429.09473
Q Predictions Max            1721.2126
Q Predictions Min            -42.9246
V Predictions Mean           1113.6073
V Predictions Std            427.74097
V Predictions Max            1707.8604
V Predictions Min            34.522877
Log Pis Mean                 0.3480028
Log Pis Std                  3.2320657
Log Pis Max                  11.734987
Log Pis Min                  -7.3293524
Policy mu Mean               -0.060075745
Policy mu Std                0.63784665
Policy mu Max                2.7057407
Policy mu Min                -2.7363198
Policy log std Mean          -0.9713747
Policy log std Std           0.3106738
Policy log std Max           -0.22701722
Policy log std Min           -2.2358599
Z mean eval                  1.0149002
Z variance eval              0.01040545
total_rewards                [1924.43315211 2658.23015373    9.94633324  667.1044197   477.68759754
 2359.99473457 3268.85032124 1881.26389968  852.8374887  1775.86109079]
total_rewards_mean           1587.6209191324126
total_rewards_std            995.6237834512247
total_rewards_max            3268.850321240693
total_rewards_min            9.946333243638316
Number of train steps total  1052000
Number of env steps total    1353740
Number of rollouts total     0
Train Time (s)               146.73345384001732
(Previous) Eval Time (s)     10.329560341779143
Sample Time (s)              7.083407093305141
Epoch Time (s)               164.1464212751016
Total Train Time (s)         44131.628434270155
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:36:08.649343 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #262 | Epoch Duration: 164.24775910377502
2020-01-11 20:36:08.649479 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0141652
Z variance train             0.010385767
KL Divergence                18.45645
KL Loss                      1.845645
QF Loss                      556.9972
VF Loss                      198.45592
Policy Loss                  -1110.815
Q Predictions Mean           1105.1619
Q Predictions Std            453.32257
Q Predictions Max            1718.3137
Q Predictions Min            325.30853
V Predictions Mean           1112.4336
V Predictions Std            451.09204
V Predictions Max            1724.2728
V Predictions Min            347.91385
Log Pis Mean                 0.044137046
Log Pis Std                  3.3782635
Log Pis Max                  18.326237
Log Pis Min                  -7.284975
Policy mu Mean               -0.029220888
Policy mu Std                0.6590816
Policy mu Max                3.8651662
Policy mu Min                -2.474481
Policy log std Mean          -0.9468399
Policy log std Std           0.29570788
Policy log std Max           -0.28425592
Policy log std Min           -2.1748457
Z mean eval                  0.9428541
Z variance eval              0.06651505
total_rewards                [4237.4221331  2938.94440036 3202.46249436 1840.31139788 2623.04879053
 2069.0902497  1263.07301663 2429.9579375  1104.87391055  887.79254859]
total_rewards_mean           2259.697687919281
total_rewards_std            992.159593681203
total_rewards_max            4237.422133101038
total_rewards_min            887.7925485875161
Number of train steps total  1056000
Number of env steps total    1362430
Number of rollouts total     0
Train Time (s)               146.42877370817587
(Previous) Eval Time (s)     14.378263796214014
Sample Time (s)              8.314320221543312
Epoch Time (s)               169.1213577259332
Total Train Time (s)         44300.833723211195
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:38:57.856294 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #263 | Epoch Duration: 169.20672178268433
2020-01-11 20:38:57.856422 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9404007
Z variance train             0.0670267
KL Divergence                15.714238
KL Loss                      1.5714239
QF Loss                      1173.0531
VF Loss                      137.63773
Policy Loss                  -1123.2875
Q Predictions Mean           1117.6155
Q Predictions Std            429.1225
Q Predictions Max            1701.3795
Q Predictions Min            307.05338
V Predictions Mean           1122.7883
V Predictions Std            426.9914
V Predictions Max            1698.7855
V Predictions Min            323.6064
Log Pis Mean                 0.506147
Log Pis Std                  3.749727
Log Pis Max                  18.072224
Log Pis Min                  -7.097206
Policy mu Mean               -0.038235225
Policy mu Std                0.6565168
Policy mu Max                3.575375
Policy mu Min                -2.642206
Policy log std Mean          -1.020422
Policy log std Std           0.32813695
Policy log std Max           -0.33027363
Policy log std Min           -2.5096562
Z mean eval                  0.95016825
Z variance eval              0.014505103
total_rewards                [1250.55030804 3914.41086018 3312.80019506 1602.91906519 4172.78903361
  832.51020524  944.18514104 4333.71956265 1529.77352713   32.0504729 ]
total_rewards_mean           2192.570837104472
total_rewards_std            1499.1964856618465
total_rewards_max            4333.719562646661
total_rewards_min            32.05047290044072
Number of train steps total  1060000
Number of env steps total    1372387
Number of rollouts total     0
Train Time (s)               146.35894423909485
(Previous) Eval Time (s)     12.791376804932952
Sample Time (s)              7.074752783402801
Epoch Time (s)               166.2250738274306
Total Train Time (s)         44467.14862900507
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:41:44.174124 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #264 | Epoch Duration: 166.31759333610535
2020-01-11 20:41:44.174294 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9473232
Z variance train             0.014480854
KL Divergence                17.647182
KL Loss                      1.7647183
QF Loss                      4433.6113
VF Loss                      144.52019
Policy Loss                  -1158.9492
Q Predictions Mean           1155.1057
Q Predictions Std            449.2296
Q Predictions Max            1771.96
Q Predictions Min            -86.93773
V Predictions Mean           1162.2019
V Predictions Std            444.5176
V Predictions Max            1759.5994
V Predictions Min            221.57582
Log Pis Mean                 0.6435192
Log Pis Std                  4.1244855
Log Pis Max                  34.67414
Log Pis Min                  -6.671764
Policy mu Mean               -0.07853302
Policy mu Std                0.6803481
Policy mu Max                4.805861
Policy mu Min                -3.5569074
Policy log std Mean          -0.98774827
Policy log std Std           0.3116123
Policy log std Max           -0.3772503
Policy log std Min           -2.271185
Z mean eval                  1.0968996
Z variance eval              0.031094069
total_rewards                [4349.64684983 4307.95832685 4411.32831888 4094.10131735 3093.42298545
 4234.4626267  4436.44723504 4310.27021825 4264.35167891 4711.75858338]
total_rewards_mean           4221.3748140647585
total_rewards_std            405.60568371090517
total_rewards_max            4711.758583379301
total_rewards_min            3093.422985450584
Number of train steps total  1064000
Number of env steps total    1381394
Number of rollouts total     0
Train Time (s)               146.96019587200135
(Previous) Eval Time (s)     20.323211524635553
Sample Time (s)              7.891727025154978
Epoch Time (s)               175.17513442179188
Total Train Time (s)         44642.42370063299
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:44:39.453418 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #265 | Epoch Duration: 175.27893352508545
2020-01-11 20:44:39.453699 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1022826
Z variance train             0.03178001
KL Divergence                16.295086
KL Loss                      1.6295086
QF Loss                      900.4951
VF Loss                      225.74036
Policy Loss                  -1179.8679
Q Predictions Mean           1178.4576
Q Predictions Std            408.44437
Q Predictions Max            1707.6599
Q Predictions Min            94.26474
V Predictions Mean           1189.4314
V Predictions Std            407.34113
V Predictions Max            1707.8981
V Predictions Min            259.2364
Log Pis Mean                 0.33639395
Log Pis Std                  3.284208
Log Pis Max                  15.646261
Log Pis Min                  -7.8306146
Policy mu Mean               -0.017997038
Policy mu Std                0.6494714
Policy mu Max                4.0563903
Policy mu Min                -2.4056742
Policy log std Mean          -1.0047563
Policy log std Std           0.3131669
Policy log std Max           -0.33029294
Policy log std Min           -2.4844766
Z mean eval                  0.9263061
Z variance eval              0.011754667
total_rewards                [2019.78381858 2031.54996877 4192.03604468 4368.23340725 1964.66565678
 1967.08706917  421.17264286  774.71400528 2047.33006565 4377.57399996]
total_rewards_mean           2416.4146678980464
total_rewards_std            1353.9711284114933
total_rewards_max            4377.573999961158
total_rewards_min            421.17264285751594
Number of train steps total  1068000
Number of env steps total    1389923
Number of rollouts total     0
Train Time (s)               146.1001144940965
(Previous) Eval Time (s)     15.826924783177674
Sample Time (s)              7.196328193880618
Epoch Time (s)               169.12336747115478
Total Train Time (s)         44811.631549803074
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:47:28.661630 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #266 | Epoch Duration: 169.20778059959412
2020-01-11 20:47:28.661767 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92560273
Z variance train             0.011784827
KL Divergence                17.78503
KL Loss                      1.7785031
QF Loss                      565.50964
VF Loss                      177.73929
Policy Loss                  -1142.7854
Q Predictions Mean           1137.4473
Q Predictions Std            443.95837
Q Predictions Max            1779.0409
Q Predictions Min            348.71844
V Predictions Mean           1133.9215
V Predictions Std            440.8478
V Predictions Max            1751.4801
V Predictions Min            344.73373
Log Pis Mean                 0.1555936
Log Pis Std                  3.9202907
Log Pis Max                  14.420998
Log Pis Min                  -11.114471
Policy mu Mean               -0.012200167
Policy mu Std                0.6611486
Policy mu Max                3.257173
Policy mu Min                -2.4357615
Policy log std Mean          -0.9866599
Policy log std Std           0.33799714
Policy log std Max           -0.33970082
Policy log std Min           -2.271665
Z mean eval                  0.9741597
Z variance eval              0.013943994
total_rewards                [4220.37251957  322.11860992 1034.02804359 3318.69902271 4122.08392424
 4287.55923252 4045.97037974 4296.2481519  4139.33477302  662.58984677]
total_rewards_mean           3044.9004503980304
total_rewards_std            1583.021682990914
total_rewards_max            4296.248151904822
total_rewards_min            322.1186099195971
Number of train steps total  1072000
Number of env steps total    1398490
Number of rollouts total     0
Train Time (s)               148.10178962396458
(Previous) Eval Time (s)     17.16161915520206
Sample Time (s)              6.888672499917448
Epoch Time (s)               172.1520812790841
Total Train Time (s)         44983.88793778373
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:50:20.923281 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #267 | Epoch Duration: 172.2613866329193
2020-01-11 20:50:20.923502 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9744317
Z variance train             0.013959968
KL Divergence                18.282578
KL Loss                      1.8282578
QF Loss                      887.6925
VF Loss                      153.13823
Policy Loss                  -1142.0348
Q Predictions Mean           1135.3306
Q Predictions Std            447.4254
Q Predictions Max            1731.1276
Q Predictions Min            278.55887
V Predictions Mean           1139.6395
V Predictions Std            442.98846
V Predictions Max            1728.5602
V Predictions Min            326.18375
Log Pis Mean                 0.0739103
Log Pis Std                  3.158101
Log Pis Max                  12.768229
Log Pis Min                  -6.6887865
Policy mu Mean               -0.013030654
Policy mu Std                0.6635215
Policy mu Max                3.5497868
Policy mu Min                -2.7954724
Policy log std Mean          -0.94886243
Policy log std Std           0.3031791
Policy log std Max           -0.2460559
Policy log std Min           -2.2727726
Z mean eval                  1.0581477
Z variance eval              0.028678874
total_rewards                [4262.10842672 4557.77556195 4165.11352476 4150.81485791 4337.57936996
 4072.56127447 4556.97910718 4366.98712579 2738.79215507 4249.54290583]
total_rewards_mean           4145.825430962251
total_rewards_std            493.37800670634084
total_rewards_max            4557.775561952345
total_rewards_min            2738.7921550650244
Number of train steps total  1076000
Number of env steps total    1408001
Number of rollouts total     0
Train Time (s)               144.96030478691682
(Previous) Eval Time (s)     20.19533340772614
Sample Time (s)              7.414458393584937
Epoch Time (s)               172.5700965882279
Total Train Time (s)         45156.568349016365
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:53:13.605411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #268 | Epoch Duration: 172.6817409992218
2020-01-11 20:53:13.605586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0591815
Z variance train             0.028675128
KL Divergence                16.982267
KL Loss                      1.6982268
QF Loss                      1770.044
VF Loss                      599.49634
Policy Loss                  -1149.4468
Q Predictions Mean           1139.7043
Q Predictions Std            445.04245
Q Predictions Max            1803.4467
Q Predictions Min            -9.526175
V Predictions Mean           1150.2798
V Predictions Std            432.5167
V Predictions Max            1793.3346
V Predictions Min            346.65933
Log Pis Mean                 0.58656824
Log Pis Std                  3.5090275
Log Pis Max                  13.404198
Log Pis Min                  -8.2099
Policy mu Mean               -0.08429426
Policy mu Std                0.6610568
Policy mu Max                3.4715316
Policy mu Min                -2.8687613
Policy log std Mean          -0.98110133
Policy log std Std           0.33798745
Policy log std Max           -0.13806939
Policy log std Min           -2.7002826
Z mean eval                  1.1286669
Z variance eval              0.07005249
total_rewards                [4092.03052758  416.87981173 1360.12027964  922.67273212 1108.81364007
 4367.57923958 2349.09917043 4011.96617028 3965.43012578 4249.7408535 ]
total_rewards_mean           2684.4332550709687
total_rewards_std            1525.1958799827642
total_rewards_max            4367.579239579516
total_rewards_min            416.8798117338823
Number of train steps total  1080000
Number of env steps total    1417280
Number of rollouts total     0
Train Time (s)               147.5775320008397
(Previous) Eval Time (s)     16.64904216118157
Sample Time (s)              7.0274433312006295
Epoch Time (s)               171.2540174932219
Total Train Time (s)         45327.91236397484
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:56:04.953296 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #269 | Epoch Duration: 171.34757781028748
2020-01-11 20:56:04.953474 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1285583
Z variance train             0.07015107
KL Divergence                17.831491
KL Loss                      1.7831491
QF Loss                      1769.3744
VF Loss                      150.4033
Policy Loss                  -1130.3785
Q Predictions Mean           1121.2108
Q Predictions Std            445.48032
Q Predictions Max            1719.9297
Q Predictions Min            242.54335
V Predictions Mean           1135.021
V Predictions Std            441.7517
V Predictions Max            1719.3229
V Predictions Min            347.75876
Log Pis Mean                 0.22224465
Log Pis Std                  3.5284643
Log Pis Max                  26.965668
Log Pis Min                  -6.109211
Policy mu Mean               -0.004096137
Policy mu Std                0.6605712
Policy mu Max                4.8647118
Policy mu Min                -2.5478058
Policy log std Mean          -0.9774147
Policy log std Std           0.32067636
Policy log std Max           -0.12111068
Policy log std Min           -2.3250813
Z mean eval                  0.9775585
Z variance eval              0.018024711
total_rewards                [4280.82749394 2468.70487266 2905.82036655  954.56406539  312.75287656
  551.97540839 1581.99905682 4055.37532514 3129.64669576 4445.76649446]
total_rewards_mean           2468.7432655669445
total_rewards_std            1474.4100056067543
total_rewards_max            4445.766494462931
total_rewards_min            312.75287655580894
Number of train steps total  1084000
Number of env steps total    1427005
Number of rollouts total     0
Train Time (s)               145.9544948930852
(Previous) Eval Time (s)     15.00322597194463
Sample Time (s)              7.942456430755556
Epoch Time (s)               168.9001772957854
Total Train Time (s)         45496.9026970882
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:58:53.944238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #270 | Epoch Duration: 168.9906361103058
2020-01-11 20:58:53.944376 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98269635
Z variance train             0.01790497
KL Divergence                19.063803
KL Loss                      1.9063803
QF Loss                      1063.343
VF Loss                      136.46136
Policy Loss                  -1140.8613
Q Predictions Mean           1133.9075
Q Predictions Std            417.04337
Q Predictions Max            1745.381
Q Predictions Min            348.44266
V Predictions Mean           1135.1334
V Predictions Std            417.1756
V Predictions Max            1745.2552
V Predictions Min            346.85962
Log Pis Mean                 0.2630294
Log Pis Std                  3.2204607
Log Pis Max                  13.331836
Log Pis Min                  -7.2170415
Policy mu Mean               -0.020193536
Policy mu Std                0.65858775
Policy mu Max                3.0385575
Policy mu Min                -2.5636652
Policy log std Mean          -0.9519787
Policy log std Std           0.3081624
Policy log std Max           -0.33268565
Policy log std Min           -2.457098
Z mean eval                  0.94071734
Z variance eval              0.0273203
total_rewards                [4634.41426153 4312.449955   3827.28702782 2028.96263169 4678.58329724
  309.11295683 2645.80266451 4415.57639942 4699.35050597  208.96935514]
total_rewards_mean           3176.050905514492
total_rewards_std            1690.4639750369793
total_rewards_max            4699.3505059671825
total_rewards_min            208.96935514124468
Number of train steps total  1088000
Number of env steps total    1437755
Number of rollouts total     0
Train Time (s)               147.72090937197208
(Previous) Eval Time (s)     18.573327265214175
Sample Time (s)              7.3824713178910315
Epoch Time (s)               173.6767079550773
Total Train Time (s)         45670.667294098996
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:01:47.711527 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #271 | Epoch Duration: 173.76703691482544
2020-01-11 21:01:47.711712 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94318753
Z variance train             0.027548825
KL Divergence                15.664148
KL Loss                      1.5664148
QF Loss                      757.6127
VF Loss                      122.32384
Policy Loss                  -1187.5764
Q Predictions Mean           1182.6006
Q Predictions Std            424.52725
Q Predictions Max            1723.0847
Q Predictions Min            103.25302
V Predictions Mean           1187.1274
V Predictions Std            418.9898
V Predictions Max            1711.5181
V Predictions Min            331.67422
Log Pis Mean                 0.7689548
Log Pis Std                  3.6959164
Log Pis Max                  23.279388
Log Pis Min                  -6.131775
Policy mu Mean               -0.03642066
Policy mu Std                0.68257177
Policy mu Max                4.1228704
Policy mu Min                -4.335272
Policy log std Mean          -0.9964815
Policy log std Std           0.34108716
Policy log std Max           0.0625329
Policy log std Min           -2.3681421
Z mean eval                  1.08131
Z variance eval              0.046757378
total_rewards                [ 707.95131715 4229.39917566 2276.68450045 1535.22920286  505.18201397
 4282.73451311 4238.33807227 4024.47454488 4230.13857299 4210.22209253]
total_rewards_mean           3024.035400586293
total_rewards_std            1511.8962796365158
total_rewards_max            4282.734513110182
total_rewards_min            505.182013968621
Number of train steps total  1092000
Number of env steps total    1448684
Number of rollouts total     0
Train Time (s)               148.6182382311672
(Previous) Eval Time (s)     20.864127542357892
Sample Time (s)              7.220027382019907
Epoch Time (s)               176.702393155545
Total Train Time (s)         45847.45952413604
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:04:44.505105 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #272 | Epoch Duration: 176.7932629585266
2020-01-11 21:04:44.505255 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #272 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.084923
Z variance train             0.046691723
KL Divergence                16.77632
KL Loss                      1.677632
QF Loss                      672.6117
VF Loss                      253.04082
Policy Loss                  -1173.9298
Q Predictions Mean           1166.937
Q Predictions Std            403.20044
Q Predictions Max            1706.3263
Q Predictions Min            366.75262
V Predictions Mean           1162.374
V Predictions Std            403.69348
V Predictions Max            1685.2992
V Predictions Min            364.41934
Log Pis Mean                 0.191989
Log Pis Std                  3.3346345
Log Pis Max                  18.17884
Log Pis Min                  -10.589483
Policy mu Mean               -0.08686644
Policy mu Std                0.67118627
Policy mu Max                3.0725784
Policy mu Min                -2.5293732
Policy log std Mean          -0.96955097
Policy log std Std           0.2954006
Policy log std Max           -0.06163299
Policy log std Min           -2.1959596
Z mean eval                  0.88982487
Z variance eval              0.091698326
total_rewards                [4494.88554482 1893.98195062 4224.69738926  331.25239109  256.8718931
 1352.77489602 4311.62421479 4543.47038522 4243.22646702 3707.31947009]
total_rewards_mean           2936.010460203345
total_rewards_std            1685.9947730331196
total_rewards_max            4543.470385222956
total_rewards_min            256.8718931040406
Number of train steps total  1096000
Number of env steps total    1458618
Number of rollouts total     0
Train Time (s)               145.23074169130996
(Previous) Eval Time (s)     17.54971670312807
Sample Time (s)              7.1905355378985405
Epoch Time (s)               169.97099393233657
Total Train Time (s)         46017.523163932376
Epoch                        273
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:07:34.571998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #273 | Epoch Duration: 170.0666275024414
2020-01-11 21:07:34.572180 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88869333
Z variance train             0.09146588
KL Divergence                15.193004
KL Loss                      1.5193003
QF Loss                      1423.4294
VF Loss                      391.70273
Policy Loss                  -1213.6799
Q Predictions Mean           1207.8809
Q Predictions Std            433.61777
Q Predictions Max            1822.0225
Q Predictions Min            378.4889
V Predictions Mean           1225.8695
V Predictions Std            433.25262
V Predictions Max            1822.9874
V Predictions Min            386.14923
Log Pis Mean                 0.3764603
Log Pis Std                  3.1012714
Log Pis Max                  9.131445
Log Pis Min                  -6.5792847
Policy mu Mean               0.0345107
Policy mu Std                0.6619528
Policy mu Max                2.0564408
Policy mu Min                -2.0549836
Policy log std Mean          -0.9643013
Policy log std Std           0.30717143
Policy log std Max           -0.22974896
Policy log std Min           -2.335571
Z mean eval                  0.93254423
Z variance eval              0.026656892
total_rewards                [4614.24486243 3728.08473229 4330.20970549  611.27416558 2471.81658153
 4401.58459125 4252.38635915 1914.55080617 2773.90688251 1948.00536955]
total_rewards_mean           3104.606405595904
total_rewards_std            1290.342484001343
total_rewards_max            4614.244862432828
total_rewards_min            611.2741655795862
Number of train steps total  1100000
Number of env steps total    1467382
Number of rollouts total     0
Train Time (s)               146.86795000219718
(Previous) Eval Time (s)     15.462015244178474
Sample Time (s)              8.1062379674986
Epoch Time (s)               170.43620321387425
Total Train Time (s)         46188.05287295021
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:10:25.106844 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #274 | Epoch Duration: 170.53452491760254
2020-01-11 21:10:25.107018 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92612964
Z variance train             0.026767096
KL Divergence                16.898443
KL Loss                      1.6898444
QF Loss                      733.6765
VF Loss                      107.75291
Policy Loss                  -1209.0922
Q Predictions Mean           1205.2308
Q Predictions Std            365.14484
Q Predictions Max            1763.3422
Q Predictions Min            360.27374
V Predictions Mean           1206.7548
V Predictions Std            364.00735
V Predictions Max            1765.532
V Predictions Min            357.9936
Log Pis Mean                 0.64186364
Log Pis Std                  3.3831387
Log Pis Max                  11.199612
Log Pis Min                  -9.661334
Policy mu Mean               -0.064541265
Policy mu Std                0.66997004
Policy mu Max                2.5595143
Policy mu Min                -2.8112855
Policy log std Mean          -1.0424216
Policy log std Std           0.3391062
Policy log std Max           -0.31282115
Policy log std Min           -2.5060024
Z mean eval                  1.0963145
Z variance eval              0.031902798
total_rewards                [1440.98074847 1739.79560628  156.29296187  938.73000229 3455.87346471
   53.77309964   79.76536303 2419.95029822 1631.61878524 2509.71104551]
total_rewards_mean           1442.6491375251258
total_rewards_std            1093.887322250876
total_rewards_max            3455.8734647078845
total_rewards_min            53.773099638542746
Number of train steps total  1104000
Number of env steps total    1474771
Number of rollouts total     0
Train Time (s)               145.20890124002472
(Previous) Eval Time (s)     7.967034950852394
Sample Time (s)              7.290004758164287
Epoch Time (s)               160.4659409490414
Total Train Time (s)         46348.61026244424
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:13:05.666329 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #275 | Epoch Duration: 160.55917930603027
2020-01-11 21:13:05.666470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0976098
Z variance train             0.031931624
KL Divergence                16.550276
KL Loss                      1.6550276
QF Loss                      2372.5918
VF Loss                      246.2145
Policy Loss                  -1264.8466
Q Predictions Mean           1256.928
Q Predictions Std            385.97754
Q Predictions Max            1816.0344
Q Predictions Min            373.5944
V Predictions Mean           1268.0581
V Predictions Std            383.91223
V Predictions Max            1813.1102
V Predictions Min            378.7427
Log Pis Mean                 0.9298934
Log Pis Std                  3.1629553
Log Pis Max                  14.373794
Log Pis Min                  -6.052595
Policy mu Mean               -0.046419054
Policy mu Std                0.70043784
Policy mu Max                2.9213667
Policy mu Min                -2.5949
Policy log std Mean          -1.0126033
Policy log std Std           0.3126029
Policy log std Max           -0.25413376
Policy log std Min           -2.7954702
Z mean eval                  1.0101526
Z variance eval              0.038192164
total_rewards                [4052.07018994 4436.76740966 4622.55306333 4416.67542494 4611.89950185
 4747.01897816 4648.49287388 1295.66329053 2202.48061269 2643.14746236]
total_rewards_mean           3767.676880734957
total_rewards_std            1181.2489424410642
total_rewards_max            4747.018978163746
total_rewards_min            1295.6632905285767
Number of train steps total  1108000
Number of env steps total    1482876
Number of rollouts total     0
Train Time (s)               146.63740848563612
(Previous) Eval Time (s)     20.581478687003255
Sample Time (s)              7.818465983495116
Epoch Time (s)               175.0373531561345
Total Train Time (s)         46523.73084392818
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:16:00.788280 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #276 | Epoch Duration: 175.12170600891113
2020-01-11 21:16:00.788424 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #276 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9955395
Z variance train             0.03829254
KL Divergence                16.368355
KL Loss                      1.6368355
QF Loss                      451.40665
VF Loss                      144.3924
Policy Loss                  -1219.409
Q Predictions Mean           1214.4849
Q Predictions Std            374.51105
Q Predictions Max            1768.5447
Q Predictions Min            369.47815
V Predictions Mean           1217.7816
V Predictions Std            371.0828
V Predictions Max            1766.9049
V Predictions Min            375.44424
Log Pis Mean                 0.7767528
Log Pis Std                  3.4040108
Log Pis Max                  13.658365
Log Pis Min                  -7.2354465
Policy mu Mean               -0.051056013
Policy mu Std                0.6880907
Policy mu Max                2.3941293
Policy mu Min                -3.1121275
Policy log std Mean          -1.0179574
Policy log std Std           0.3195513
Policy log std Max           -0.37805462
Policy log std Min           -2.6460905
Z mean eval                  0.8806367
Z variance eval              0.10436282
total_rewards                [2740.07980016 4117.18760617 4700.28467879 2273.13986124 4552.1883183
 4707.24994084 4097.33979025 3080.38717092   55.61400502 1148.67040755]
total_rewards_mean           3147.2141579239697
total_rewards_std            1521.5018245390959
total_rewards_max            4707.249940839705
total_rewards_min            55.61400502441656
Number of train steps total  1112000
Number of env steps total    1493651
Number of rollouts total     0
Train Time (s)               146.5680402610451
(Previous) Eval Time (s)     14.763072116766125
Sample Time (s)              7.980215663090348
Epoch Time (s)               169.31132804090157
Total Train Time (s)         46693.13343126234
Epoch                        277
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:18:50.193276 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #277 | Epoch Duration: 169.4047474861145
2020-01-11 21:18:50.193416 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8775045
Z variance train             0.10520079
KL Divergence                14.345541
KL Loss                      1.4345541
QF Loss                      1024.2255
VF Loss                      111.063736
Policy Loss                  -1273.5486
Q Predictions Mean           1270.5432
Q Predictions Std            351.6302
Q Predictions Max            1776.0792
Q Predictions Min            410.62552
V Predictions Mean           1270.5286
V Predictions Std            346.96176
V Predictions Max            1766.694
V Predictions Min            411.246
Log Pis Mean                 0.53300184
Log Pis Std                  2.7407146
Log Pis Max                  9.683456
Log Pis Min                  -7.516048
Policy mu Mean               -0.053839944
Policy mu Std                0.6595485
Policy mu Max                2.91558
Policy mu Min                -3.4325163
Policy log std Mean          -1.010909
Policy log std Std           0.29836503
Policy log std Max           -0.08324635
Policy log std Min           -2.386089
Z mean eval                  1.0322889
Z variance eval              0.025119081
total_rewards                [ 860.40413092  479.27799965 2750.12506931  553.65028329  854.20754209
  489.38318053  717.24156839 1359.30538571 2284.6084946    17.61561216]
total_rewards_mean           1036.581926665025
total_rewards_std            815.2151618071492
total_rewards_max            2750.12506931285
total_rewards_min            17.615612155994647
Number of train steps total  1116000
Number of env steps total    1501941
Number of rollouts total     0
Train Time (s)               148.0414316416718
(Previous) Eval Time (s)     12.48893048800528
Sample Time (s)              7.55954808415845
Epoch Time (s)               168.08991021383554
Total Train Time (s)         46861.30616657343
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:21:38.367748 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #278 | Epoch Duration: 168.17422556877136
2020-01-11 21:21:38.367908 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0277702
Z variance train             0.025104245
KL Divergence                16.719086
KL Loss                      1.6719086
QF Loss                      796.9271
VF Loss                      268.3891
Policy Loss                  -1263.8694
Q Predictions Mean           1256.9426
Q Predictions Std            370.15494
Q Predictions Max            1813.9977
Q Predictions Min            418.06476
V Predictions Mean           1273.6865
V Predictions Std            370.00528
V Predictions Max            1833.0492
V Predictions Min            430.1274
Log Pis Mean                 0.6181531
Log Pis Std                  3.3336165
Log Pis Max                  14.364885
Log Pis Min                  -7.262858
Policy mu Mean               -0.07333669
Policy mu Std                0.6859316
Policy mu Max                3.131158
Policy mu Min                -3.14339
Policy log std Mean          -1.0360769
Policy log std Std           0.308776
Policy log std Max           -0.36930937
Policy log std Min           -2.567837
Z mean eval                  0.9770354
Z variance eval              0.043801356
total_rewards                [3724.98508876 4570.07443919 3558.81224641 4051.6282748  4445.45015938
   74.10237137 1761.05367017 2175.56964421 2228.41467513 1199.39164466]
total_rewards_mean           2778.9482214083773
total_rewards_std            1436.0606626981032
total_rewards_max            4570.074439186541
total_rewards_min            74.10237137289275
Number of train steps total  1120000
Number of env steps total    1511531
Number of rollouts total     0
Train Time (s)               145.7694364078343
(Previous) Eval Time (s)     16.665472181979567
Sample Time (s)              7.53368469607085
Epoch Time (s)               169.9685932858847
Total Train Time (s)         47031.36852926621
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:24:28.434983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #279 | Epoch Duration: 170.06695413589478
2020-01-11 21:24:28.435184 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97758454
Z variance train             0.04393481
KL Divergence                16.059486
KL Loss                      1.6059487
QF Loss                      2124.6113
VF Loss                      1088.2827
Policy Loss                  -1231.3158
Q Predictions Mean           1214.0013
Q Predictions Std            382.0637
Q Predictions Max            1761.7324
Q Predictions Min            -31.581083
V Predictions Mean           1225.3721
V Predictions Std            364.488
V Predictions Max            1739.3939
V Predictions Min            422.21475
Log Pis Mean                 0.8598805
Log Pis Std                  3.480936
Log Pis Max                  14.87495
Log Pis Min                  -9.173561
Policy mu Mean               -0.0520688
Policy mu Std                0.7345334
Policy mu Max                2.490214
Policy mu Min                -2.5656745
Policy log std Mean          -0.9887862
Policy log std Std           0.35093817
Policy log std Max           -0.25643367
Policy log std Min           -3.0869303
Z mean eval                  1.1258335
Z variance eval              0.032236997
total_rewards                [3506.65786096 3081.12485807 4183.01061615 4120.37433549 4756.06773947
  556.40756815 3335.41030772 2172.13295274 2633.81833943 4232.24842012]
total_rewards_mean           3257.725299831263
total_rewards_std            1172.9927483555693
total_rewards_max            4756.067739471862
total_rewards_min            556.407568154477
Number of train steps total  1124000
Number of env steps total    1519573
Number of rollouts total     0
Train Time (s)               147.2042684671469
(Previous) Eval Time (s)     16.89814347261563
Sample Time (s)              7.9101687567308545
Epoch Time (s)               172.0125806964934
Total Train Time (s)         47203.47901192028
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:27:20.548985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #280 | Epoch Duration: 172.11364555358887
2020-01-11 21:27:20.549169 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #280 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.128101
Z variance train             0.032471407
KL Divergence                17.315884
KL Loss                      1.7315884
QF Loss                      686.48535
VF Loss                      203.08109
Policy Loss                  -1278.9642
Q Predictions Mean           1270.9198
Q Predictions Std            357.86374
Q Predictions Max            1849.5055
Q Predictions Min            371.3961
V Predictions Mean           1273.2346
V Predictions Std            348.11172
V Predictions Max            1824.4324
V Predictions Min            442.3211
Log Pis Mean                 0.63479185
Log Pis Std                  3.0305896
Log Pis Max                  10.802414
Log Pis Min                  -7.9321384
Policy mu Mean               -0.09647989
Policy mu Std                0.71684974
Policy mu Max                3.0641484
Policy mu Min                -3.0637593
Policy log std Mean          -0.9652214
Policy log std Std           0.3013801
Policy log std Max           -0.2329821
Policy log std Min           -2.403359
Z mean eval                  1.0506774
Z variance eval              0.03785058
total_rewards                [2524.78113917 4679.13505493  749.87307183 1876.79025107 3914.3037107
  204.403454   1075.63683455 1586.95124418 4724.88711166  526.90845597]
total_rewards_mean           2186.367032805987
total_rewards_std            1618.4134766387301
total_rewards_max            4724.88711165661
total_rewards_min            204.40345400308394
Number of train steps total  1128000
Number of env steps total    1526975
Number of rollouts total     0
Train Time (s)               146.52337898314
(Previous) Eval Time (s)     13.055217769928277
Sample Time (s)              7.774307522922754
Epoch Time (s)               167.35290427599102
Total Train Time (s)         47370.92160793254
Epoch                        281
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:30:07.993224 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #281 | Epoch Duration: 167.44392895698547
2020-01-11 21:30:07.993368 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0425439
Z variance train             0.037682775
KL Divergence                15.281745
KL Loss                      1.5281745
QF Loss                      17257.602
VF Loss                      355.27707
Policy Loss                  -1238.4761
Q Predictions Mean           1234.6265
Q Predictions Std            337.23593
Q Predictions Max            1798.9377
Q Predictions Min            316.53015
V Predictions Mean           1252.2509
V Predictions Std            335.34384
V Predictions Max            1805.4666
V Predictions Min            457.0152
Log Pis Mean                 0.765005
Log Pis Std                  3.1587932
Log Pis Max                  18.192286
Log Pis Min                  -6.694874
Policy mu Mean               -0.055852216
Policy mu Std                0.72772837
Policy mu Max                2.7704148
Policy mu Min                -3.1429696
Policy log std Mean          -0.94403243
Policy log std Std           0.2936014
Policy log std Max           -0.30825162
Policy log std Min           -2.519052
Z mean eval                  0.9240494
Z variance eval              0.034794938
total_rewards                [ 807.47462709 4739.65935219  821.13783132 4365.78081237  279.12200855
 4102.22758726 2387.99193231 1695.92097061  880.48034643  520.08262288]
total_rewards_mean           2059.9878090999578
total_rewards_std            1641.5164637363293
total_rewards_max            4739.659352191017
total_rewards_min            279.1220085522588
Number of train steps total  1132000
Number of env steps total    1538078
Number of rollouts total     0
Train Time (s)               147.3251128909178
(Previous) Eval Time (s)     18.65664907824248
Sample Time (s)              7.351099050138146
Epoch Time (s)               173.33286101929843
Total Train Time (s)         47544.34824939119
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:33:01.422325 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #282 | Epoch Duration: 173.42885279655457
2020-01-11 21:33:01.422470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9239976
Z variance train             0.034872655
KL Divergence                17.87719
KL Loss                      1.787719
QF Loss                      600.08453
VF Loss                      132.25883
Policy Loss                  -1295.377
Q Predictions Mean           1290.7642
Q Predictions Std            344.68692
Q Predictions Max            1808.6904
Q Predictions Min            482.81686
V Predictions Mean           1292.6584
V Predictions Std            340.17175
V Predictions Max            1790.1953
V Predictions Min            468.45853
Log Pis Mean                 0.75145346
Log Pis Std                  3.2181656
Log Pis Max                  12.598814
Log Pis Min                  -9.317303
Policy mu Mean               -0.044638958
Policy mu Std                0.7336563
Policy mu Max                2.4999213
Policy mu Min                -3.2882085
Policy log std Mean          -0.9741525
Policy log std Std           0.31850654
Policy log std Max           -0.23205036
Policy log std Min           -2.4349625
Z mean eval                  0.99787724
Z variance eval              0.06389628
total_rewards                [ 583.61785438 1393.05003603 4419.79736946 1084.17283622 4594.49062178
 1859.81940438  356.34615525 1738.71710266 1954.79403808 2188.75322223]
total_rewards_mean           2017.3558640451552
total_rewards_std            1364.7066843015573
total_rewards_max            4594.490621778346
total_rewards_min            356.34615524992313
Number of train steps total  1136000
Number of env steps total    1547617
Number of rollouts total     0
Train Time (s)               146.57607553014532
(Previous) Eval Time (s)     13.179027860052884
Sample Time (s)              8.175880417227745
Epoch Time (s)               167.93098380742595
Total Train Time (s)         47712.37358769821
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:35:49.449401 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #283 | Epoch Duration: 168.0268268585205
2020-01-11 21:35:49.449545 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99865615
Z variance train             0.06394179
KL Divergence                13.949895
KL Loss                      1.3949895
QF Loss                      763.52594
VF Loss                      222.78818
Policy Loss                  -1223.6401
Q Predictions Mean           1218.2527
Q Predictions Std            358.39307
Q Predictions Max            1831.6936
Q Predictions Min            486.12448
V Predictions Mean           1222.1721
V Predictions Std            353.10114
V Predictions Max            1821.3197
V Predictions Min            493.8457
Log Pis Mean                 0.9025279
Log Pis Std                  3.456265
Log Pis Max                  15.860298
Log Pis Min                  -8.472961
Policy mu Mean               -0.0037215792
Policy mu Std                0.7268796
Policy mu Max                3.2918873
Policy mu Min                -2.6750853
Policy log std Mean          -0.97819656
Policy log std Std           0.33007598
Policy log std Max           -0.11472094
Policy log std Min           -2.5059252
Z mean eval                  0.9743775
Z variance eval              0.050813884
total_rewards                [4778.11860142 3629.18412899 3312.0754057  4729.82047745 4882.58901019
 4811.16509742 3916.40946133 4385.14649952 4827.07621863 1482.30981385]
total_rewards_mean           4075.3894714502176
total_rewards_std            1015.2394666316644
total_rewards_max            4882.589010186801
total_rewards_min            1482.3098138469895
Number of train steps total  1140000
Number of env steps total    1557672
Number of rollouts total     0
Train Time (s)               145.76147775910795
(Previous) Eval Time (s)     19.74851156398654
Sample Time (s)              7.451717985793948
Epoch Time (s)               172.96170730888844
Total Train Time (s)         47885.42450973578
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:38:42.505321 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #284 | Epoch Duration: 173.05566358566284
2020-01-11 21:38:42.505490 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97810125
Z variance train             0.05065454
KL Divergence                15.548472
KL Loss                      1.5548472
QF Loss                      1086.0105
VF Loss                      272.3382
Policy Loss                  -1328.6017
Q Predictions Mean           1322.6892
Q Predictions Std            330.34335
Q Predictions Max            1831.4264
Q Predictions Min            513.8395
V Predictions Mean           1315.3513
V Predictions Std            329.1992
V Predictions Max            1796.0342
V Predictions Min            499.3964
Log Pis Mean                 0.8935463
Log Pis Std                  2.9306948
Log Pis Max                  12.405571
Log Pis Min                  -6.851465
Policy mu Mean               -0.03375514
Policy mu Std                0.7022397
Policy mu Max                2.6817508
Policy mu Min                -2.915538
Policy log std Mean          -1.0049185
Policy log std Std           0.29927033
Policy log std Max           -0.17607152
Policy log std Min           -2.4006646
Z mean eval                  0.9239848
Z variance eval              0.13948569
total_rewards                [2481.41017411    5.91060148 1517.38757617  709.98276503 1363.63892046
 2399.69687345 1681.93217726  943.93052417 4943.60361354 4515.05076529]
total_rewards_mean           2056.2543990974937
total_rewards_std            1511.4564964451476
total_rewards_max            4943.603613539975
total_rewards_min            5.910601482637778
Number of train steps total  1144000
Number of env steps total    1568424
Number of rollouts total     0
Train Time (s)               145.99299418041483
(Previous) Eval Time (s)     11.076981991995126
Sample Time (s)              7.167903167195618
Epoch Time (s)               164.23787933960557
Total Train Time (s)         48049.75348283304
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:41:26.837799 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #285 | Epoch Duration: 164.33218145370483
2020-01-11 21:41:26.837941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92564696
Z variance train             0.13836086
KL Divergence                13.164676
KL Loss                      1.3164676
QF Loss                      631.4576
VF Loss                      134.8497
Policy Loss                  -1247.1287
Q Predictions Mean           1235.8137
Q Predictions Std            347.6415
Q Predictions Max            1794.9312
Q Predictions Min            521.30817
V Predictions Mean           1243.6833
V Predictions Std            345.0569
V Predictions Max            1790.4412
V Predictions Min            518.55884
Log Pis Mean                 0.33694202
Log Pis Std                  3.0357287
Log Pis Max                  9.172141
Log Pis Min                  -8.508741
Policy mu Mean               -0.0312373
Policy mu Std                0.71139455
Policy mu Max                2.379537
Policy mu Min                -2.467075
Policy log std Mean          -0.93515
Policy log std Std           0.2975628
Policy log std Max           -0.23446858
Policy log std Min           -2.4215536
Z mean eval                  0.93564254
Z variance eval              0.13464984
total_rewards                [2237.93623704 2770.53351996 1425.64906137   59.39521047 3387.24466304
 4516.43288655 4668.41903958 4739.60909174 4468.19135071 4420.72812938]
total_rewards_mean           3269.413918984239
total_rewards_std            1531.8857047796116
total_rewards_max            4739.609091741345
total_rewards_min            59.395210474816096
Number of train steps total  1148000
Number of env steps total    1579011
Number of rollouts total     0
Train Time (s)               145.28708236431703
(Previous) Eval Time (s)     15.052160209044814
Sample Time (s)              8.015410169027746
Epoch Time (s)               168.3546527423896
Total Train Time (s)         48218.196142129134
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:44:15.283941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #286 | Epoch Duration: 168.4458830356598
2020-01-11 21:44:15.284127 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9382143
Z variance train             0.13651244
KL Divergence                13.954954
KL Loss                      1.3954954
QF Loss                      894.09656
VF Loss                      147.591
Policy Loss                  -1320.3932
Q Predictions Mean           1314.1274
Q Predictions Std            321.4939
Q Predictions Max            1815.102
Q Predictions Min            513.4399
V Predictions Mean           1315.1365
V Predictions Std            317.87405
V Predictions Max            1821.9281
V Predictions Min            513.80035
Log Pis Mean                 0.79907906
Log Pis Std                  3.2583475
Log Pis Max                  11.013003
Log Pis Min                  -11.136676
Policy mu Mean               -0.07215124
Policy mu Std                0.7125048
Policy mu Max                2.8725014
Policy mu Min                -2.4367743
Policy log std Mean          -1.01135
Policy log std Std           0.32540432
Policy log std Max           -0.077153385
Policy log std Min           -2.333698
Z mean eval                  1.1089679
Z variance eval              0.045928583
total_rewards                [4777.3453363  4338.49035085 4433.18523723 1596.82713348  307.19609223
 4218.45045639 3275.81581408 2739.34238349 4326.22804223 4679.58935296]
total_rewards_mean           3469.2470199239806
total_rewards_std            1422.36533969236
total_rewards_max            4777.34533629946
total_rewards_min            307.1960922281471
Number of train steps total  1152000
Number of env steps total    1587261
Number of rollouts total     0
Train Time (s)               148.4136372790672
(Previous) Eval Time (s)     21.05340237636119
Sample Time (s)              7.554789314512163
Epoch Time (s)               177.02182896994054
Total Train Time (s)         48395.30428005336
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:47:12.394266 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #287 | Epoch Duration: 177.11000037193298
2020-01-11 21:47:12.394448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #287 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1028721
Z variance train             0.046023123
KL Divergence                19.602936
KL Loss                      1.9602937
QF Loss                      3814.1592
VF Loss                      652.4685
Policy Loss                  -1429.9473
Q Predictions Mean           1421.3511
Q Predictions Std            320.4668
Q Predictions Max            1898.7877
Q Predictions Min            548.8375
V Predictions Mean           1432.822
V Predictions Std            322.9548
V Predictions Max            1894.0709
V Predictions Min            547.7222
Log Pis Mean                 1.9042876
Log Pis Std                  4.5400667
Log Pis Max                  21.933918
Log Pis Min                  -8.440806
Policy mu Mean               -0.04590103
Policy mu Std                0.90525687
Policy mu Max                3.5910769
Policy mu Min                -3.5224319
Policy log std Mean          -0.9399719
Policy log std Std           0.31820694
Policy log std Max           -0.11543536
Policy log std Min           -2.5315742
Z mean eval                  1.4474126
Z variance eval              0.031921107
total_rewards                [-1535.32497057 -1486.26086635 -1472.89484457 -1644.07160797
 -1455.789664   -1736.79389399 -1462.26572922 -1399.68365941
 -1636.80796649 -1331.38981872]
total_rewards_mean           -1516.1283021300137
total_rewards_std            117.04087835629323
total_rewards_max            -1331.389818722455
total_rewards_min            -1736.793893992721
Number of train steps total  1156000
Number of env steps total    1598507
Number of rollouts total     0
Train Time (s)               148.85470127128065
(Previous) Eval Time (s)     21.788122777361423
Sample Time (s)              6.348791559226811
Epoch Time (s)               176.99161560786888
Total Train Time (s)         48572.37964604888
Epoch                        288
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:50:09.471830 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #288 | Epoch Duration: 177.07725954055786
2020-01-11 21:50:09.471967 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #288 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4372994
Z variance train             0.0319615
KL Divergence                26.977486
KL Loss                      2.6977487
QF Loss                      7076.667
VF Loss                      1504.2931
Policy Loss                  -1670.3481
Q Predictions Mean           1643.633
Q Predictions Std            411.12036
Q Predictions Max            3102.335
Q Predictions Min            1.3296599
V Predictions Mean           1672.0459
V Predictions Std            416.5203
V Predictions Max            3210.5215
V Predictions Min            101.87795
Log Pis Mean                 5.9629173
Log Pis Std                  5.1506658
Log Pis Max                  22.391712
Log Pis Min                  -8.766833
Policy mu Mean               0.022586903
Policy mu Std                1.2899424
Policy mu Max                3.9411077
Policy mu Min                -4.0068994
Policy log std Mean          -0.91594815
Policy log std Std           0.3672049
Policy log std Max           -0.011440635
Policy log std Min           -2.9280276
Z mean eval                  1.5681753
Z variance eval              0.19111936
total_rewards                [-1114.07205567 -1203.10780063 -1296.59737548 -1213.61903712
 -1241.25191378 -1162.22690752 -1170.47352242 -1260.23857363
 -1136.88410326 -1153.77349228]
total_rewards_mean           -1195.2244781792422
total_rewards_std            55.16455116237726
total_rewards_max            -1114.0720556669935
total_rewards_min            -1296.5973754760403
Number of train steps total  1160000
Number of env steps total    1607749
Number of rollouts total     0
Train Time (s)               146.97784119611606
(Previous) Eval Time (s)     22.071965645998716
Sample Time (s)              6.314002501778305
Epoch Time (s)               175.36380934389308
Total Train Time (s)         48747.82645272277
Epoch                        289
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:53:04.920962 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #289 | Epoch Duration: 175.44888997077942
2020-01-11 21:53:04.921106 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #289 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5834609
Z variance train             0.19279785
KL Divergence                31.493559
KL Loss                      3.149356
QF Loss                      4469.7617
VF Loss                      1995.85
Policy Loss                  -2482.317
Q Predictions Mean           2438.5234
Q Predictions Std            612.47473
Q Predictions Max            4333.6943
Q Predictions Min            -14.199838
V Predictions Mean           2454.568
V Predictions Std            629.6601
V Predictions Max            4401.0737
V Predictions Min            103.126785
Log Pis Mean                 5.925164
Log Pis Std                  4.992517
Log Pis Max                  21.436659
Log Pis Min                  -7.326764
Policy mu Mean               0.14324266
Policy mu Std                1.2805895
Policy mu Max                3.4314854
Policy mu Min                -3.7894733
Policy log std Mean          -0.9362962
Policy log std Std           0.32650626
Policy log std Max           -0.12187278
Policy log std Min           -3.0489762
Z mean eval                  1.4652681
Z variance eval              2.3237207
total_rewards                [ -554.34087125  -852.76423305 -1310.34803872  -710.60856366
  -569.36779579  -844.38293302 -1146.16408356  -768.02980664
 -1258.2248066   -558.95483592]
total_rewards_mean           -857.3185968207159
total_rewards_std            272.5453494044112
total_rewards_max            -554.3408712486508
total_rewards_min            -1310.3480387245418
Number of train steps total  1164000
Number of env steps total    1617393
Number of rollouts total     0
Train Time (s)               148.0759176230058
(Previous) Eval Time (s)     21.363641135860234
Sample Time (s)              7.101829651277512
Epoch Time (s)               176.54138841014355
Total Train Time (s)         48924.45999995433
Epoch                        290
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:56:01.556589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #290 | Epoch Duration: 176.63537979125977
2020-01-11 21:56:01.556718 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #290 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4677285
Z variance train             2.3234887
KL Divergence                24.373768
KL Loss                      2.4373767
QF Loss                      10382.73
VF Loss                      2588.1316
Policy Loss                  -2195.4922
Q Predictions Mean           2161.3306
Q Predictions Std            498.8016
Q Predictions Max            3698.3423
Q Predictions Min            937.3373
V Predictions Mean           2198.7678
V Predictions Std            508.5437
V Predictions Max            3714.4712
V Predictions Min            679.08417
Log Pis Mean                 7.112216
Log Pis Std                  4.527546
Log Pis Max                  20.060766
Log Pis Min                  -4.940266
Policy mu Mean               0.26884487
Policy mu Std                1.3809208
Policy mu Max                3.8427994
Policy mu Min                -3.8149383
Policy log std Mean          -0.88918227
Policy log std Std           0.37644082
Policy log std Max           0.20297956
Policy log std Min           -2.7834063
Z mean eval                  1.3705697
Z variance eval              0.3049125
total_rewards                [-1327.00754715  -806.49842061  -712.71007613 -1422.08563938
  -749.97580457  -807.9346726   -659.68399135  -969.39160843
  -588.13545259  -684.00971563]
total_rewards_mean           -872.74329284474
total_rewards_std            269.9557745583445
total_rewards_max            -588.135452594238
total_rewards_min            -1422.085639378371
Number of train steps total  1168000
Number of env steps total    1626965
Number of rollouts total     0
Train Time (s)               147.94645152287558
(Previous) Eval Time (s)     25.215393932070583
Sample Time (s)              6.131930119823664
Epoch Time (s)               179.29377557476982
Total Train Time (s)         49103.844886641484
Epoch                        291
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:59:00.943659 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #291 | Epoch Duration: 179.38683772087097
2020-01-11 21:59:00.943806 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #291 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3748269
Z variance train             0.29954323
KL Divergence                23.335796
KL Loss                      2.3335798
QF Loss                      4174.333
VF Loss                      935.7433
Policy Loss                  -2846.0557
Q Predictions Mean           2815.2642
Q Predictions Std            587.0243
Q Predictions Max            4593.0854
Q Predictions Min            20.266645
V Predictions Mean           2852.3872
V Predictions Std            587.60614
V Predictions Max            4675.4346
V Predictions Min            1674.3516
Log Pis Mean                 5.195445
Log Pis Std                  3.8198056
Log Pis Max                  18.971266
Log Pis Min                  -3.8585544
Policy mu Mean               0.011324417
Policy mu Std                1.2283967
Policy mu Max                6.0798545
Policy mu Min                -4.741788
Policy log std Mean          -0.8905854
Policy log std Std           0.2913815
Policy log std Max           1.0767236
Policy log std Min           -2.1977715
Z mean eval                  1.4691288
Z variance eval              0.37213054
total_rewards                [ -823.34271024 -1059.1860443   -916.47675961 -1461.96184341
 -1013.30127141   -40.78857995  -829.56975513 -1018.98948927
  -969.43173857  -599.82254026]
total_rewards_mean           -873.2870732141491
total_rewards_std            347.17156613346214
total_rewards_max            -40.788579947661766
total_rewards_min            -1461.9618434125823
Number of train steps total  1172000
Number of env steps total    1636630
Number of rollouts total     0
Train Time (s)               145.98842718731612
(Previous) Eval Time (s)     19.63837729487568
Sample Time (s)              7.321823233738542
Epoch Time (s)               172.94862771593034
Total Train Time (s)         49276.876635574736
Epoch                        292
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:01:53.980163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #292 | Epoch Duration: 173.0362536907196
2020-01-11 22:01:53.980301 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4705343
Z variance train             0.3656986
KL Divergence                23.376616
KL Loss                      2.3376615
QF Loss                      9437.897
VF Loss                      2175.3228
Policy Loss                  -2622.178
Q Predictions Mean           2593.9104
Q Predictions Std            782.5557
Q Predictions Max            5189.893
Q Predictions Min            -128.80507
V Predictions Mean           2618.041
V Predictions Std            794.3922
V Predictions Max            5295.633
V Predictions Min            70.342255
Log Pis Mean                 5.0731406
Log Pis Std                  4.638546
Log Pis Max                  26.957993
Log Pis Min                  -5.9676156
Policy mu Mean               0.035334162
Policy mu Std                1.2165282
Policy mu Max                5.3413854
Policy mu Min                -3.3482006
Policy log std Mean          -0.892297
Policy log std Std           0.343081
Policy log std Max           -0.09678888
Policy log std Min           -2.8179595
Z mean eval                  1.47295
Z variance eval              0.27322912
total_rewards                [-1436.24924097 -1453.64083133 -1440.5112689  -1397.62293987
 -1460.75330575 -1355.36934137 -1488.00070875 -1443.39722799
   -22.37850512 -1448.80983729]
total_rewards_mean           -1294.6733207346763
total_rewards_std            425.4920390886097
total_rewards_max            -22.378505124111364
total_rewards_min            -1488.0007087547306
Number of train steps total  1176000
Number of env steps total    1645923
Number of rollouts total     0
Train Time (s)               145.66189459897578
(Previous) Eval Time (s)     22.53112614573911
Sample Time (s)              6.128050295636058
Epoch Time (s)               174.32107104035094
Total Train Time (s)         49451.28438588558
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:04:48.391273 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #293 | Epoch Duration: 174.41085600852966
2020-01-11 22:04:48.391461 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4703493
Z variance train             0.2727143
KL Divergence                25.102695
KL Loss                      2.5102696
QF Loss                      5195.939
VF Loss                      1415.503
Policy Loss                  -3233.016
Q Predictions Mean           3196.2092
Q Predictions Std            1024.8037
Q Predictions Max            6309.906
Q Predictions Min            2530.2734
V Predictions Mean           3247.9824
V Predictions Std            1046.4147
V Predictions Max            6439.1064
V Predictions Min            2561.8552
Log Pis Mean                 6.4528656
Log Pis Std                  5.4689016
Log Pis Max                  34.624687
Log Pis Min                  -7.188274
Policy mu Mean               0.066150635
Policy mu Std                1.413343
Policy mu Max                5.852337
Policy mu Min                -3.9203355
Policy log std Mean          -0.78034186
Policy log std Std           0.34466195
Policy log std Max           0.020953298
Policy log std Min           -2.264494
Z mean eval                  1.8376122
Z variance eval              0.054943837
total_rewards                [-1447.10654761 -1513.21882939 -1844.8600162  -1975.43322047
  -364.35929333 -1589.87687862 -1670.05028264 -1707.49752189
 -1505.83812507  -759.61146766]
total_rewards_mean           -1437.7852182883485
total_rewards_std            471.9290299103957
total_rewards_max            -364.35929332657093
total_rewards_min            -1975.4332204714121
Number of train steps total  1180000
Number of env steps total    1656370
Number of rollouts total     0
Train Time (s)               145.87996910512447
(Previous) Eval Time (s)     18.438940646126866
Sample Time (s)              6.831290741451085
Epoch Time (s)               171.15020049270242
Total Train Time (s)         49622.63439352531
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:07:39.744979 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #294 | Epoch Duration: 171.35337352752686
2020-01-11 22:07:39.745181 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #294 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8282124
Z variance train             0.05516833
KL Divergence                39.272186
KL Loss                      3.9272187
QF Loss                      167251.25
VF Loss                      1483.7528
Policy Loss                  -4319.4062
Q Predictions Mean           4231.576
Q Predictions Std            1031.5785
Q Predictions Max            7760.5127
Q Predictions Min            3430.5703
V Predictions Mean           4332.001
V Predictions Std            1030.9373
V Predictions Max            7954.756
V Predictions Min            3387.2974
Log Pis Mean                 11.602487
Log Pis Std                  4.8549056
Log Pis Max                  27.968838
Log Pis Min                  0.2793876
Policy mu Mean               0.50747395
Policy mu Std                1.6807781
Policy mu Max                3.743859
Policy mu Min                -3.8106494
Policy log std Mean          -0.88314855
Policy log std Std           0.32355475
Policy log std Max           0.027792692
Policy log std Min           -2.131713
Z mean eval                  1.8060287
Z variance eval              0.13243847
total_rewards                [-1274.57803842 -1203.61280747 -1095.13242763 -1134.3638991
 -1141.36985004 -1198.13525335 -1181.82260157 -1241.35533919
 -1281.50444986 -1103.28888944]
total_rewards_mean           -1185.5163556064058
total_rewards_std            63.45088654237649
total_rewards_max            -1095.1324276252476
total_rewards_min            -1281.5044498557386
Number of train steps total  1184000
Number of env steps total    1666063
Number of rollouts total     0
Train Time (s)               147.312837630976
(Previous) Eval Time (s)     25.361640891060233
Sample Time (s)              7.7323966678231955
Epoch Time (s)               180.40687518985942
Total Train Time (s)         49803.12929731794
Epoch                        295
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:10:40.241797 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #295 | Epoch Duration: 180.49647450447083
2020-01-11 22:10:40.241942 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #295 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8001859
Z variance train             0.13126925
KL Divergence                34.246376
KL Loss                      3.4246376
QF Loss                      8644.882
VF Loss                      1734.8226
Policy Loss                  -4481.6934
Q Predictions Mean           4435.1377
Q Predictions Std            1341.3667
Q Predictions Max            9531.867
Q Predictions Min            3661.3286
V Predictions Mean           4500.2524
V Predictions Std            1402.4724
V Predictions Max            9780.72
V Predictions Min            3657.2637
Log Pis Mean                 5.9290304
Log Pis Std                  5.22035
Log Pis Max                  31.689037
Log Pis Min                  -4.9085593
Policy mu Mean               -0.22972777
Policy mu Std                1.2784195
Policy mu Max                4.3050356
Policy mu Min                -4.469911
Policy log std Mean          -0.9230219
Policy log std Std           0.32303342
Policy log std Max           -0.07920349
Policy log std Min           -2.426426
Z mean eval                  1.7707589
Z variance eval              0.08733277
total_rewards                [-1380.72690672 -1317.3619163  -1287.36380452 -1252.42020347
 -1325.61393874 -1347.72555838 -1331.04720801 -1393.00685398
 -1754.25718204 -1320.76575217]
total_rewards_mean           -1371.0289324330104
total_rewards_std            133.46141702585408
total_rewards_max            -1252.420203468123
total_rewards_min            -1754.257182039447
Number of train steps total  1188000
Number of env steps total    1674530
Number of rollouts total     0
Train Time (s)               146.10446573700756
(Previous) Eval Time (s)     21.97185482410714
Sample Time (s)              7.267474823165685
Epoch Time (s)               175.34379538428038
Total Train Time (s)         49978.56348946644
Epoch                        296
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:13:35.679061 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #296 | Epoch Duration: 175.43700432777405
2020-01-11 22:13:35.679247 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #296 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7749516
Z variance train             0.0873004
KL Divergence                36.8548
KL Loss                      3.68548
QF Loss                      168759.22
VF Loss                      6124.65
Policy Loss                  -4746.076
Q Predictions Mean           4662.05
Q Predictions Std            1949.8497
Q Predictions Max            11863.786
Q Predictions Min            3037.4834
V Predictions Mean           4741.006
V Predictions Std            1993.0494
V Predictions Max            11960.178
V Predictions Min            3657.4487
Log Pis Mean                 9.325398
Log Pis Std                  5.1120625
Log Pis Max                  49.542503
Log Pis Min                  -1.6411572
Policy mu Mean               -0.1866849
Policy mu Std                1.5788121
Policy mu Max                5.454931
Policy mu Min                -5.189317
Policy log std Mean          -0.87040216
Policy log std Std           0.39715374
Policy log std Max           1.8131903
Policy log std Min           -2.7001216
Z mean eval                  1.8015779
Z variance eval              0.0886098
total_rewards                [ -189.21374721  -772.08886719   -22.45176973 -2140.39729455
 -2208.1040177    -37.03182622  -202.13368598 -1894.4536349
 -1773.4998047  -1679.40547032]
total_rewards_mean           -1091.8780118508366
total_rewards_std            881.1562515110511
total_rewards_max            -22.451769730061404
total_rewards_min            -2208.104017702929
Number of train steps total  1192000
Number of env steps total    1684012
Number of rollouts total     0
Train Time (s)               145.77445944398642
(Previous) Eval Time (s)     12.348823888227344
Sample Time (s)              7.226844496559352
Epoch Time (s)               165.3501278287731
Total Train Time (s)         50144.00635154825
Epoch                        297
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:16:21.130360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #297 | Epoch Duration: 165.4509415626526
2020-01-11 22:16:21.130714 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #297 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8037369
Z variance train             0.08763436
KL Divergence                40.79087
KL Loss                      4.0790873
QF Loss                      20117.371
VF Loss                      4162.272
Policy Loss                  -5882.899
Q Predictions Mean           5770.125
Q Predictions Std            2694.8342
Q Predictions Max            13504.87
Q Predictions Min            1273.9305
V Predictions Mean           5893.6016
V Predictions Std            2727.1265
V Predictions Max            13715.232
V Predictions Min            4211.744
Log Pis Mean                 11.416975
Log Pis Std                  6.754746
Log Pis Max                  88.24317
Log Pis Min                  -0.35089672
Policy mu Mean               -0.6088247
Policy mu Std                1.7268494
Policy mu Max                6.5340614
Policy mu Min                -11.998314
Policy log std Mean          -0.8075667
Policy log std Std           0.4406755
Policy log std Max           0.17160296
Policy log std Min           -2.488113
Z mean eval                  1.9159473
Z variance eval              0.13862526
total_rewards                [  -65.50630567 -1842.67101958  -956.11833126 -1562.0743823
  -847.79531416 -1837.26012676  -592.13000389 -1866.94246438
   -44.4948878  -1593.31348702]
total_rewards_mean           -1120.8306322831563
total_rewards_std            682.8143654715116
total_rewards_max            -44.49488780092185
total_rewards_min            -1866.9424643802317
Number of train steps total  1196000
Number of env steps total    1692216
Number of rollouts total     0
Train Time (s)               149.3781035770662
(Previous) Eval Time (s)     20.630559459794313
Sample Time (s)              7.074871667660773
Epoch Time (s)               177.0835347045213
Total Train Time (s)         50321.17785491748
Epoch                        298
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:19:18.302549 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #298 | Epoch Duration: 177.17161417007446
2020-01-11 22:19:18.302702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #298 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9179633
Z variance train             0.13783698
KL Divergence                46.3808
KL Loss                      4.63808
QF Loss                      26691.566
VF Loss                      4810.63
Policy Loss                  -6493.1987
Q Predictions Mean           6400.619
Q Predictions Std            1970.345
Q Predictions Max            13842.249
Q Predictions Min            1528.6555
V Predictions Mean           6499.765
V Predictions Std            1963.3602
V Predictions Max            13962.963
V Predictions Min            2768.969
Log Pis Mean                 12.191017
Log Pis Std                  5.195045
Log Pis Max                  26.703358
Log Pis Min                  0.7238295
Policy mu Mean               -0.5111244
Policy mu Std                1.7114322
Policy mu Max                4.6054664
Policy mu Min                -5.0510273
Policy log std Mean          -0.92567
Policy log std Std           0.42340797
Policy log std Max           0.08606827
Policy log std Min           -3.956058
Z mean eval                  1.9446176
Z variance eval              0.16745134
total_rewards                [  -13.43115979 -2142.80205873 -1801.24150022   -73.36153442
   -64.73554138  -159.91682721  -126.46676038   -39.7563706
 -1984.9594697    -38.86573603]
total_rewards_mean           -644.5536958469671
total_rewards_std            876.1308339342444
total_rewards_max            -13.431159793559917
total_rewards_min            -2142.802058726201
Number of train steps total  1200000
Number of env steps total    1702263
Number of rollouts total     0
Train Time (s)               147.71863425988704
(Previous) Eval Time (s)     8.61633661808446
Sample Time (s)              6.683053941465914
Epoch Time (s)               163.01802481943741
Total Train Time (s)         50484.28215849493
Epoch                        299
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:22:01.409306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #299 | Epoch Duration: 163.10649728775024
2020-01-11 22:22:01.409452 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #299 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9468362
Z variance train             0.1660969
KL Divergence                41.891994
KL Loss                      4.1891994
QF Loss                      14592.258
VF Loss                      4586.804
Policy Loss                  -6718.3975
Q Predictions Mean           6652.2188
Q Predictions Std            1942.9297
Q Predictions Max            12780.8545
Q Predictions Min            5385.829
V Predictions Mean           6756.868
V Predictions Std            1962.099
V Predictions Max            13191.1045
V Predictions Min            5446.4985
Log Pis Mean                 10.032294
Log Pis Std                  4.3471007
Log Pis Max                  23.762165
Log Pis Min                  -3.9015303
Policy mu Mean               -0.32103515
Policy mu Std                1.5607295
Policy mu Max                4.5680466
Policy mu Min                -4.068689
Policy log std Mean          -0.9915967
Policy log std Std           0.40246376
Policy log std Max           0.028214216
Policy log std Min           -2.372683
Z mean eval                  1.9456857
Z variance eval              0.07168164
total_rewards                [  -45.07979303 -1177.71403269  -831.32361437   -66.49622817
 -1298.07292923  -951.54270778  -908.28830495    -4.03423705
 -1076.19801356  -200.96933918]
total_rewards_mean           -655.9719200009386
total_rewards_std            489.4479795025284
total_rewards_max            -4.034237048974907
total_rewards_min            -1298.072929229784
Number of train steps total  1204000
Number of env steps total    1713354
Number of rollouts total     0
Train Time (s)               146.8543333192356
(Previous) Eval Time (s)     13.765488039236516
Sample Time (s)              8.16590332891792
Epoch Time (s)               168.78572468739003
Total Train Time (s)         50653.16112051206
Epoch                        300
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:24:50.292276 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #300 | Epoch Duration: 168.88270783424377
2020-01-11 22:24:50.292462 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #300 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9270773
Z variance train             0.071876705
KL Divergence                43.214664
KL Loss                      4.3214664
QF Loss                      17220.824
VF Loss                      2594.4902
Policy Loss                  -6498.175
Q Predictions Mean           6443.7124
Q Predictions Std            1900.8823
Q Predictions Max            11978.812
Q Predictions Min            5185.9116
V Predictions Mean           6515.8164
V Predictions Std            1927.474
V Predictions Max            12126.815
V Predictions Min            5219.3945
Log Pis Mean                 8.349392
Log Pis Std                  4.3194003
Log Pis Max                  20.54311
Log Pis Min                  -3.0115483
Policy mu Mean               -0.19331649
Policy mu Std                1.3999476
Policy mu Max                3.5065217
Policy mu Min                -3.5453544
Policy log std Mean          -1.1108749
Policy log std Std           0.4046388
Policy log std Max           -0.17945588
Policy log std Min           -2.815064
Z mean eval                  1.7388579
Z variance eval              0.13935098
total_rewards                [  -30.1908181  -1731.52410461   -38.74699892 -1244.26096549
 -1876.66684129   -38.41970861  -855.765004     -10.04442324
 -1695.61332343   -16.70163532]
total_rewards_mean           -753.7933822986558
total_rewards_std            774.4612246875176
total_rewards_max            -10.044423235338348
total_rewards_min            -1876.6668412866957
Number of train steps total  1208000
Number of env steps total    1722181
Number of rollouts total     0
Train Time (s)               149.2702007777989
(Previous) Eval Time (s)     11.367855042684823
Sample Time (s)              7.267506462987512
Epoch Time (s)               167.90556228347123
Total Train Time (s)         50821.61365345586
Epoch                        301
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:27:38.749252 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #301 | Epoch Duration: 168.45663046836853
2020-01-11 22:27:38.749504 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #301 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7375953
Z variance train             0.13938165
KL Divergence                39.14741
KL Loss                      3.9147413
QF Loss                      31489.99
VF Loss                      4569.7295
Policy Loss                  -6093.928
Q Predictions Mean           6036.678
Q Predictions Std            1765.3285
Q Predictions Max            12482.012
Q Predictions Min            -1130.5518
V Predictions Mean           6129.755
V Predictions Std            1799.11
V Predictions Max            12618.258
V Predictions Min            -1215.7433
Log Pis Mean                 8.491453
Log Pis Std                  4.8583837
Log Pis Max                  47.764954
Log Pis Min                  -4.4505954
Policy mu Mean               -0.34185082
Policy mu Std                1.3808324
Policy mu Max                8.173066
Policy mu Min                -3.7729495
Policy log std Mean          -1.0902814
Policy log std Std           0.4084714
Policy log std Max           2.0
Policy log std Min           -2.842235
Z mean eval                  1.7829126
Z variance eval              0.029655516
total_rewards                [-1291.52459199   -51.54222605 -1138.62114104 -1159.07688174
   -20.03665623 -1333.20981387   -64.57609527  -721.26844925
  -647.00524714  -173.35688179]
total_rewards_mean           -660.02179843731
total_rewards_std            520.1190701089032
total_rewards_max            -20.0366562306336
total_rewards_min            -1333.2098138727295
Number of train steps total  1212000
Number of env steps total    1731906
Number of rollouts total     0
Train Time (s)               146.6409672871232
(Previous) Eval Time (s)     13.785419372841716
Sample Time (s)              7.358621511142701
Epoch Time (s)               167.78500817110762
Total Train Time (s)         50989.496354174335
Epoch                        302
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:30:26.636955 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #302 | Epoch Duration: 167.88724994659424
2020-01-11 22:30:26.637212 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.783777
Z variance train             0.029662732
KL Divergence                42.512203
KL Loss                      4.25122
QF Loss                      55979.316
VF Loss                      3703.2166
Policy Loss                  -6447.5713
Q Predictions Mean           6335.3115
Q Predictions Std            1788.531
Q Predictions Max            12326.102
Q Predictions Min            1845.621
V Predictions Mean           6457.575
V Predictions Std            1802.3582
V Predictions Max            12475.985
V Predictions Min            4883.4697
Log Pis Mean                 10.11697
Log Pis Std                  4.7860847
Log Pis Max                  23.890268
Log Pis Min                  -0.7724893
Policy mu Mean               -0.48587537
Policy mu Std                1.54565
Policy mu Max                3.807965
Policy mu Min                -5.341216
Policy log std Mean          -1.0263463
Policy log std Std           0.45147306
Policy log std Max           0.24949217
Policy log std Min           -3.0806403
Z mean eval                  1.8449663
Z variance eval              0.032244395
total_rewards                [-665.0891743  -471.00043375 -595.31278049   -3.49188095  -12.05868624
 -548.95640548 -669.26468962  -47.0096525  -810.91811244 -830.17967854]
total_rewards_mean           -465.3281494322151
total_rewards_std            308.4966474139683
total_rewards_max            -3.4918809515594855
total_rewards_min            -830.1796785409971
Number of train steps total  1216000
Number of env steps total    1741943
Number of rollouts total     0
Train Time (s)               146.30859878705814
(Previous) Eval Time (s)     17.434488971717656
Sample Time (s)              7.4936567642726
Epoch Time (s)               171.2367445230484
Total Train Time (s)         51160.82391157979
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:33:17.966513 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #303 | Epoch Duration: 171.32912397384644
2020-01-11 22:33:17.966696 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #303 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8529679
Z variance train             0.032461975
KL Divergence                45.385567
KL Loss                      4.5385566
QF Loss                      61953.473
VF Loss                      6593.84
Policy Loss                  -6613.0127
Q Predictions Mean           6547.315
Q Predictions Std            1398.9225
Q Predictions Max            11257.584
Q Predictions Min            2865.6548
V Predictions Mean           6586.8765
V Predictions Std            1371.5537
V Predictions Max            11310.298
V Predictions Min            4059.5845
Log Pis Mean                 9.200558
Log Pis Std                  4.5772524
Log Pis Max                  21.987827
Log Pis Min                  -1.5004852
Policy mu Mean               -0.02171776
Policy mu Std                1.4444871
Policy mu Max                3.8819659
Policy mu Min                -4.379889
Policy log std Mean          -1.170323
Policy log std Std           0.45912287
Policy log std Max           -0.13386619
Policy log std Min           -3.3125162
Z mean eval                  1.7934376
Z variance eval              0.0019835366
total_rewards                [ -817.67416136  -629.93192757    -4.72424128  -339.71751911
  -690.16191369  -629.20493263  -824.47199251  -732.45511908
  -749.19487171 -1790.86569394]
total_rewards_mean           -720.840237287786
total_rewards_std            429.1490269840196
total_rewards_max            -4.724241279160923
total_rewards_min            -1790.8656939366876
Number of train steps total  1220000
Number of env steps total    1751698
Number of rollouts total     0
Train Time (s)               147.9800033532083
(Previous) Eval Time (s)     22.174818924162537
Sample Time (s)              7.939627035986632
Epoch Time (s)               178.09444931335747
Total Train Time (s)         51339.01005285885
Epoch                        304
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:36:16.154171 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #304 | Epoch Duration: 178.1873619556427
2020-01-11 22:36:16.154317 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #304 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7917324
Z variance train             0.0019838489
KL Divergence                50.120224
KL Loss                      5.0120225
QF Loss                      17355.691
VF Loss                      2969.8542
Policy Loss                  -6482.211
Q Predictions Mean           6431.715
Q Predictions Std            1074.3088
Q Predictions Max            10047.117
Q Predictions Min            4503.3193
V Predictions Mean           6476.1943
V Predictions Std            1074.4916
V Predictions Max            10084.5
V Predictions Min            4552.9463
Log Pis Mean                 8.427306
Log Pis Std                  3.9229057
Log Pis Max                  22.005919
Log Pis Min                  -1.6019808
Policy mu Mean               0.033011787
Policy mu Std                1.2821436
Policy mu Max                3.949666
Policy mu Min                -3.5991104
Policy log std Mean          -1.3010708
Policy log std Std           0.44552675
Policy log std Max           -0.13558614
Policy log std Min           -3.6457782
Z mean eval                  1.8043363
Z variance eval              0.0024508976
total_rewards                [   47.48535661    27.92430233   -17.95925516   -96.23545432
 -1146.0878455   -801.65306241  -510.30474312    96.67155897
  -143.94106112    70.02970442]
total_rewards_mean           -247.40704993130976
total_rewards_std            406.4554626930612
total_rewards_max            96.67155896561124
total_rewards_min            -1146.0878454997526
Number of train steps total  1224000
Number of env steps total    1760772
Number of rollouts total     0
Train Time (s)               147.50814508507028
(Previous) Eval Time (s)     13.477028962690383
Sample Time (s)              7.451967275701463
Epoch Time (s)               168.43714132346213
Total Train Time (s)         51507.54740552837
Epoch                        305
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:39:04.694635 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #305 | Epoch Duration: 168.54020190238953
2020-01-11 22:39:04.694786 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #305 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8049663
Z variance train             0.0024292655
KL Divergence                48.812943
KL Loss                      4.8812943
QF Loss                      267088.3
VF Loss                      4582.8037
Policy Loss                  -5959.773
Q Predictions Mean           5924.0537
Q Predictions Std            925.5464
Q Predictions Max            8513.357
Q Predictions Min            3167.7634
V Predictions Mean           5991.465
V Predictions Std            919.04083
V Predictions Max            8585.467
V Predictions Min            3972.6948
Log Pis Mean                 7.269739
Log Pis Std                  4.1852274
Log Pis Max                  25.603554
Log Pis Min                  -5.847557
Policy mu Mean               0.17593843
Policy mu Std                1.224836
Policy mu Max                3.9922793
Policy mu Min                -3.4149024
Policy log std Mean          -1.24285
Policy log std Std           0.41316816
Policy log std Max           0.120312095
Policy log std Min           -2.8200765
Z mean eval                  1.7309244
Z variance eval              0.0005906224
total_rewards                [-421.59621099  198.82584801 -375.11223083   34.72474704  -89.0396673
 -463.5148933  -270.60444046  376.81666774 -173.64012237   59.41651758]
total_rewards_mean           -112.37237848766866
total_rewards_std            265.4406637765849
total_rewards_max            376.8166677350313
total_rewards_min            -463.51489329774716
Number of train steps total  1228000
Number of env steps total    1769514
Number of rollouts total     0
Train Time (s)               147.3799429940991
(Previous) Eval Time (s)     15.396379912737757
Sample Time (s)              7.519636561628431
Epoch Time (s)               170.2959594684653
Total Train Time (s)         51677.94855779363
Epoch                        306
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:41:55.099238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #306 | Epoch Duration: 170.40433835983276
2020-01-11 22:41:55.099417 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #306 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7325588
Z variance train             0.0005846906
KL Divergence                48.271088
KL Loss                      4.827109
QF Loss                      8252.471
VF Loss                      2050.8843
Policy Loss                  -5468.796
Q Predictions Mean           5442.4644
Q Predictions Std            786.91473
Q Predictions Max            7554.452
Q Predictions Min            3585.6848
V Predictions Mean           5454.9043
V Predictions Std            788.8425
V Predictions Max            7618.283
V Predictions Min            3592.783
Log Pis Mean                 5.5911026
Log Pis Std                  3.3691998
Log Pis Max                  14.611496
Log Pis Min                  -7.3833256
Policy mu Mean               0.08987868
Policy mu Std                1.0432847
Policy mu Max                4.151522
Policy mu Min                -3.5225449
Policy log std Mean          -1.2873824
Policy log std Std           0.37667415
Policy log std Max           0.1700263
Policy log std Min           -3.3156538
Z mean eval                  1.9525398
Z variance eval              0.043398883
total_rewards                [ -178.87344331    -6.0387004   -332.08107271  -160.41489669
  -136.75893249  -298.83687204  -499.925542   -1039.82933771
    69.37024934   244.07634423]
total_rewards_mean           -233.9312203786173
total_rewards_std            335.31587615292153
total_rewards_max            244.07634423044436
total_rewards_min            -1039.8293377129
Number of train steps total  1232000
Number of env steps total    1780043
Number of rollouts total     0
Train Time (s)               147.0838155504316
(Previous) Eval Time (s)     21.271355958189815
Sample Time (s)              7.391451851464808
Epoch Time (s)               175.74662336008623
Total Train Time (s)         51853.77743425919
Epoch                        307
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:44:50.930678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #307 | Epoch Duration: 175.83108830451965
2020-01-11 22:44:50.930825 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9514427
Z variance train             0.043244127
KL Divergence                39.615887
KL Loss                      3.9615886
QF Loss                      164762.38
VF Loss                      1408.8174
Policy Loss                  -4661.502
Q Predictions Mean           4635.5146
Q Predictions Std            592.53033
Q Predictions Max            6213.236
Q Predictions Min            2962.2717
V Predictions Mean           4640.4653
V Predictions Std            592.9201
V Predictions Max            6171.443
V Predictions Min            2990.31
Log Pis Mean                 5.413865
Log Pis Std                  3.3411517
Log Pis Max                  18.738571
Log Pis Min                  -1.5117756
Policy mu Mean               0.0191763
Policy mu Std                1.0844342
Policy mu Max                3.321663
Policy mu Min                -3.083198
Policy log std Mean          -1.1544338
Policy log std Std           0.34792674
Policy log std Max           -0.08712149
Policy log std Min           -2.441941
Z mean eval                  1.5780848
Z variance eval              0.16829112
total_rewards                [ 189.85200312 -156.75123444 -285.11979092 -100.34057222  165.59431516
 -400.29543925   28.13370775  -80.86524867 -138.66129918   31.48538497]
total_rewards_mean           -74.69681736638117
total_rewards_std            176.46161286732664
total_rewards_max            189.85200312454393
total_rewards_min            -400.2954392453049
Number of train steps total  1236000
Number of env steps total    1790894
Number of rollouts total     0
Train Time (s)               146.0516262408346
(Previous) Eval Time (s)     15.623306553810835
Sample Time (s)              7.408313598483801
Epoch Time (s)               169.08324639312923
Total Train Time (s)         52022.957472418435
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:47:40.113482 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #308 | Epoch Duration: 169.18253779411316
2020-01-11 22:47:40.113660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5881584
Z variance train             0.16649857
KL Divergence                30.01832
KL Loss                      3.001832
QF Loss                      7518.1475
VF Loss                      1573.7915
Policy Loss                  -4165.2085
Q Predictions Mean           4146.155
Q Predictions Std            488.23602
Q Predictions Max            5403.65
Q Predictions Min            2605.1365
V Predictions Mean           4173.355
V Predictions Std            499.96545
V Predictions Max            5486.8906
V Predictions Min            2623.727
Log Pis Mean                 4.2530055
Log Pis Std                  3.3455126
Log Pis Max                  21.350538
Log Pis Min                  -4.3252873
Policy mu Mean               -0.02428137
Policy mu Std                0.99071884
Policy mu Max                3.4839709
Policy mu Min                -3.1511445
Policy log std Mean          -1.1760696
Policy log std Std           0.33719885
Policy log std Max           -0.22517896
Policy log std Min           -3.1612854
Z mean eval                  1.2648399
Z variance eval              0.04958586
total_rewards                [-110.69389643 -619.69779696 -454.40629169  144.47295123  -39.88304853
 -535.7204165  -337.77576487 -269.8833931  -347.69286493 -347.47543602]
total_rewards_mean           -291.87559577881956
total_rewards_std            221.10369017567447
total_rewards_max            144.47295123471196
total_rewards_min            -619.6977969582176
Number of train steps total  1240000
Number of env steps total    1801091
Number of rollouts total     0
Train Time (s)               145.71941566793248
(Previous) Eval Time (s)     19.836949784774333
Sample Time (s)              7.7338505373336375
Epoch Time (s)               173.29021599004045
Total Train Time (s)         52196.340033627115
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:50:33.501640 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #309 | Epoch Duration: 173.38781309127808
2020-01-11 22:50:33.501946 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2672219
Z variance train             0.049493887
KL Divergence                29.351826
KL Loss                      2.9351826
QF Loss                      2902.1445
VF Loss                      1195.4296
Policy Loss                  -3621.0396
Q Predictions Mean           3610.9163
Q Predictions Std            399.43402
Q Predictions Max            4518.9014
Q Predictions Min            2186.2568
V Predictions Mean           3640.783
V Predictions Std            395.2529
V Predictions Max            4524.8936
V Predictions Min            2241.2808
Log Pis Mean                 3.8637714
Log Pis Std                  3.8490953
Log Pis Max                  22.96457
Log Pis Min                  -5.5393095
Policy mu Mean               0.07831739
Policy mu Std                0.98513615
Policy mu Max                3.4913783
Policy mu Min                -3.2436435
Policy log std Mean          -1.0901656
Policy log std Std           0.31488612
Policy log std Max           -0.26166856
Policy log std Min           -3.2017136
Z mean eval                  1.3074256
Z variance eval              0.047720205
total_rewards                [ 433.94747755 -461.76908216 -618.75932459   12.44241198 -546.23305124
  105.41997317   74.75420208  706.00184169 -394.75144713 -475.88245146]
total_rewards_mean           -116.48294501224109
total_rewards_std            429.49735388460783
total_rewards_max            706.0018416920032
total_rewards_min            -618.7593245868597
Number of train steps total  1244000
Number of env steps total    1811330
Number of rollouts total     0
Train Time (s)               146.55285779992118
(Previous) Eval Time (s)     18.055747935082763
Sample Time (s)              7.367747941054404
Epoch Time (s)               171.97635367605835
Total Train Time (s)         52368.409453118686
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:53:25.572223 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #310 | Epoch Duration: 172.07008481025696
2020-01-11 22:53:25.572367 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3095644
Z variance train             0.04772564
KL Divergence                27.473534
KL Loss                      2.7473533
QF Loss                      8015.201
VF Loss                      1070.3129
Policy Loss                  -3162.9128
Q Predictions Mean           3152.152
Q Predictions Std            382.21915
Q Predictions Max            3860.3557
Q Predictions Min            -82.64643
V Predictions Mean           3142.0452
V Predictions Std            375.3397
V Predictions Max            3934.2424
V Predictions Min            124.64289
Log Pis Mean                 2.547193
Log Pis Std                  4.084989
Log Pis Max                  46.017582
Log Pis Min                  -8.802771
Policy mu Mean               0.102047786
Policy mu Std                0.9184503
Policy mu Max                6.626835
Policy mu Min                -3.007111
Policy log std Mean          -1.0076087
Policy log std Std           0.3218537
Policy log std Max           1.7699908
Policy log std Min           -2.7610388
Z mean eval                  1.2039325
Z variance eval              0.20600334
total_rewards                [ 151.1498175    42.23808736  352.71322415  712.06567797  -10.78344636
 -498.47956096  119.75135245 -347.85881553  410.96598574  292.01932295]
total_rewards_mean           122.37816452561847
total_rewards_std            338.2932077113404
total_rewards_max            712.0656779673034
total_rewards_min            -498.4795609612061
Number of train steps total  1248000
Number of env steps total    1822704
Number of rollouts total     0
Train Time (s)               147.26664629392326
(Previous) Eval Time (s)     13.900149689987302
Sample Time (s)              7.167522139847279
Epoch Time (s)               168.33431812375784
Total Train Time (s)         52536.82961558178
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:56:14.005099 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #311 | Epoch Duration: 168.4325726032257
2020-01-11 22:56:14.005442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2112627
Z variance train             0.20595463
KL Divergence                24.644442
KL Loss                      2.4644442
QF Loss                      5713.248
VF Loss                      1007.6089
Policy Loss                  -2782.1294
Q Predictions Mean           2769.9587
Q Predictions Std            347.8097
Q Predictions Max            3286.281
Q Predictions Min            -355.11316
V Predictions Mean           2791.064
V Predictions Std            316.16168
V Predictions Max            3322.854
V Predictions Min            861.62756
Log Pis Mean                 2.0052056
Log Pis Std                  3.245419
Log Pis Max                  29.867401
Log Pis Min                  -8.446955
Policy mu Mean               0.095979646
Policy mu Std                0.794008
Policy mu Max                4.935875
Policy mu Min                -4.619303
Policy log std Mean          -1.0621445
Policy log std Std           0.26800504
Policy log std Max           -0.25086737
Policy log std Min           -2.4581785
Z mean eval                  1.1646271
Z variance eval              0.2218494
total_rewards                [-207.19655314   90.05555352  108.66990748  397.63803114  360.72859069
  462.06771606  158.75081741  408.66109763  273.2091683   827.85331961]
total_rewards_mean           288.04376487071534
total_rewards_std            262.1250151536881
total_rewards_max            827.8533196090376
total_rewards_min            -207.1965531442708
Number of train steps total  1252000
Number of env steps total    1832228
Number of rollouts total     0
Train Time (s)               147.22047175234184
(Previous) Eval Time (s)     14.23296682536602
Sample Time (s)              7.56058840546757
Epoch Time (s)               169.01402698317543
Total Train Time (s)         52705.93466326175
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:59:03.111659 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #312 | Epoch Duration: 169.1059765815735
2020-01-11 22:59:03.111841 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1628256
Z variance train             0.22236972
KL Divergence                21.58506
KL Loss                      2.1585062
QF Loss                      33697.42
VF Loss                      564.22125
Policy Loss                  -2471.8
Q Predictions Mean           2466.1838
Q Predictions Std            215.02577
Q Predictions Max            2968.6226
Q Predictions Min            1589.807
V Predictions Mean           2466.4248
V Predictions Std            209.96187
V Predictions Max            2952.5132
V Predictions Min            1592.907
Log Pis Mean                 1.8870476
Log Pis Std                  2.8314574
Log Pis Max                  12.012062
Log Pis Min                  -6.6775184
Policy mu Mean               -0.06476596
Policy mu Std                0.8049144
Policy mu Max                2.3842943
Policy mu Min                -2.914473
Policy log std Mean          -1.0289633
Policy log std Std           0.28634942
Policy log std Max           -0.14401805
Policy log std Min           -2.5400343
Z mean eval                  1.0511076
Z variance eval              0.40147248
total_rewards                [ 585.38809957   79.5873803   464.59164987 -103.58692817 -364.98851935
 -290.1288404    40.67141998  304.65532022  190.42952411 -423.8905096 ]
total_rewards_mean           48.272859653200065
total_rewards_std            328.6477294692536
total_rewards_max            585.388099573987
total_rewards_min            -423.89050959624024
Number of train steps total  1256000
Number of env steps total    1841284
Number of rollouts total     0
Train Time (s)               146.572114800103
(Previous) Eval Time (s)     16.327398115303367
Sample Time (s)              7.641575900837779
Epoch Time (s)               170.54108881624416
Total Train Time (s)         52876.623283020686
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:01:53.803938 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #313 | Epoch Duration: 170.69195222854614
2020-01-11 23:01:53.804122 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.053671
Z variance train             0.4034068
KL Divergence                20.991322
KL Loss                      2.0991323
QF Loss                      1490.1758
VF Loss                      258.6008
Policy Loss                  -2179.5508
Q Predictions Mean           2170.1553
Q Predictions Std            229.13217
Q Predictions Max            2687.8516
Q Predictions Min            1399.6719
V Predictions Mean           2179.9155
V Predictions Std            222.24622
V Predictions Max            2679.1404
V Predictions Min            1389.9471
Log Pis Mean                 2.1104827
Log Pis Std                  2.8036683
Log Pis Max                  10.099522
Log Pis Min                  -5.7854843
Policy mu Mean               -0.010004459
Policy mu Std                0.82338804
Policy mu Max                2.6963906
Policy mu Min                -2.5945466
Policy log std Mean          -1.0202792
Policy log std Std           0.28262693
Policy log std Max           -0.2548337
Policy log std Min           -2.270737
Z mean eval                  1.0442302
Z variance eval              0.08231369
total_rewards                [ 146.00853719  712.70300702  467.96924912 1968.77813313  147.36566007
  420.32761794 1372.65579787   59.88789508  495.28331576  333.69114154]
total_rewards_mean           612.4670354715477
total_rewards_std            575.8476980712506
total_rewards_max            1968.778133125684
total_rewards_min            59.88789508103847
Number of train steps total  1260000
Number of env steps total    1850592
Number of rollouts total     0
Train Time (s)               148.20588567573577
(Previous) Eval Time (s)     17.034307185094804
Sample Time (s)              7.725020913872868
Epoch Time (s)               172.96521377470344
Total Train Time (s)         53049.75728629809
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:04:46.939404 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #314 | Epoch Duration: 173.13515329360962
2020-01-11 23:04:46.939543 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0435195
Z variance train             0.08224428
KL Divergence                19.866901
KL Loss                      1.9866902
QF Loss                      889.6085
VF Loss                      155.33226
Policy Loss                  -1979.5051
Q Predictions Mean           1974.833
Q Predictions Std            213.81346
Q Predictions Max            2497.5818
Q Predictions Min            1309.5892
V Predictions Mean           1977.6375
V Predictions Std            209.70863
V Predictions Max            2466.711
V Predictions Min            1309.3052
Log Pis Mean                 1.0540221
Log Pis Std                  2.6655354
Log Pis Max                  10.34655
Log Pis Min                  -6.065371
Policy mu Mean               -0.015462375
Policy mu Std                0.78972214
Policy mu Max                2.8451061
Policy mu Min                -2.429911
Policy log std Mean          -0.982617
Policy log std Std           0.26460844
Policy log std Max           -0.112072945
Policy log std Min           -2.404418
Z mean eval                  1.0352814
Z variance eval              0.16017422
total_rewards                [ 502.31254492  344.61260341 3005.35330255  -17.49563051 1304.36714444
   43.97545894  756.02540312  417.17353876 2092.86308366 1506.83078266]
total_rewards_mean           995.6018231963078
total_rewards_std            926.8673562362479
total_rewards_max            3005.353302547954
total_rewards_min            -17.49563050859021
Number of train steps total  1264000
Number of env steps total    1862063
Number of rollouts total     0
Train Time (s)               147.1542550851591
(Previous) Eval Time (s)     10.908383755013347
Sample Time (s)              7.8609797223471105
Epoch Time (s)               165.92361856251955
Total Train Time (s)         53215.76887389133
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:07:32.954598 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #315 | Epoch Duration: 166.01493859291077
2020-01-11 23:07:32.954790 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0323981
Z variance train             0.15916112
KL Divergence                19.701149
KL Loss                      1.970115
QF Loss                      876.3711
VF Loss                      252.21461
Policy Loss                  -1829.4469
Q Predictions Mean           1822.131
Q Predictions Std            211.72272
Q Predictions Max            2343.445
Q Predictions Min            1197.5708
V Predictions Mean           1829.6718
V Predictions Std            213.37854
V Predictions Max            2351.0566
V Predictions Min            1208.2986
Log Pis Mean                 0.9388865
Log Pis Std                  2.7088597
Log Pis Max                  10.274335
Log Pis Min                  -9.155021
Policy mu Mean               0.026115403
Policy mu Std                0.73340285
Policy mu Max                2.1419954
Policy mu Min                -2.271729
Policy log std Mean          -1.0138057
Policy log std Std           0.24629793
Policy log std Max           -0.34988415
Policy log std Min           -2.4135416
Z mean eval                  1.0202343
Z variance eval              0.13141298
total_rewards                [ 140.15222398 1457.80519564  215.47390087   93.33307932  198.47329136
 1283.44253249  -15.27158058  312.93766194   66.74455141 -505.53173442]
total_rewards_mean           324.75591220233144
total_rewards_std            564.8107140939245
total_rewards_max            1457.8051956418055
total_rewards_min            -505.53173441841386
Number of train steps total  1268000
Number of env steps total    1872653
Number of rollouts total     0
Train Time (s)               146.94891093997285
(Previous) Eval Time (s)     12.404849644750357
Sample Time (s)              7.4229874005541205
Epoch Time (s)               166.77674798527732
Total Train Time (s)         53382.79987205472
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:10:19.997357 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #316 | Epoch Duration: 167.04243755340576
2020-01-11 23:10:19.997499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.017922
Z variance train             0.1304279
KL Divergence                20.02987
KL Loss                      2.002987
QF Loss                      20317.293
VF Loss                      163.55203
Policy Loss                  -1718.2338
Q Predictions Mean           1713.2212
Q Predictions Std            214.76422
Q Predictions Max            2300.586
Q Predictions Min            1152.6152
V Predictions Mean           1716.9121
V Predictions Std            212.87253
V Predictions Max            2248.291
V Predictions Min            1140.6493
Log Pis Mean                 1.5883901
Log Pis Std                  3.1169362
Log Pis Max                  28.580187
Log Pis Min                  -5.8840456
Policy mu Mean               -0.018971909
Policy mu Std                0.7643543
Policy mu Max                3.1948957
Policy mu Min                -3.299154
Policy log std Mean          -1.0149907
Policy log std Std           0.2472709
Policy log std Max           -0.17066228
Policy log std Min           -2.2744308
Z mean eval                  0.878201
Z variance eval              0.2538444
total_rewards                [  50.15277308   92.19379445  268.44614707  135.27056034   85.07105908
  304.26240533   42.43072143  507.08342193 1031.84398177  852.56204065]
total_rewards_mean           336.9316905140281
total_rewards_std            334.13433065324915
total_rewards_max            1031.8439817709543
total_rewards_min            42.43072143137276
Number of train steps total  1272000
Number of env steps total    1882674
Number of rollouts total     0
Train Time (s)               148.12561930622905
(Previous) Eval Time (s)     13.819327123928815
Sample Time (s)              7.743436414282769
Epoch Time (s)               169.68838284444064
Total Train Time (s)         53552.59140594071
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:13:09.781678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #317 | Epoch Duration: 169.7840723991394
2020-01-11 23:13:09.781821 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8812494
Z variance train             0.25433102
KL Divergence                16.740318
KL Loss                      1.6740319
QF Loss                      1450.9243
VF Loss                      174.02794
Policy Loss                  -1599.5304
Q Predictions Mean           1590.4445
Q Predictions Std            232.9651
Q Predictions Max            2134.5735
Q Predictions Min            696.444
V Predictions Mean           1597.1714
V Predictions Std            221.5737
V Predictions Max            2131.5532
V Predictions Min            1045.3723
Log Pis Mean                 0.98942083
Log Pis Std                  2.6492057
Log Pis Max                  10.349371
Log Pis Min                  -6.721818
Policy mu Mean               0.0048799813
Policy mu Std                0.7539199
Policy mu Max                2.5554936
Policy mu Min                -2.4000168
Policy log std Mean          -0.97839177
Policy log std Std           0.26277006
Policy log std Max           -0.18199646
Policy log std Min           -2.2876973
Z mean eval                  0.91171753
Z variance eval              0.078388676
total_rewards                [1603.02502961 1795.40162731   50.10568534 1128.32780497 2456.21517745
   46.8687975   116.0945134  2382.48330683  982.42375826  841.523003  ]
total_rewards_mean           1140.246870367491
total_rewards_std            864.0238967252103
total_rewards_max            2456.215177453519
total_rewards_min            46.86879750096613
Number of train steps total  1276000
Number of env steps total    1892756
Number of rollouts total     0
Train Time (s)               146.90646971669048
(Previous) Eval Time (s)     15.977511621080339
Sample Time (s)              7.371195117011666
Epoch Time (s)               170.2551764547825
Total Train Time (s)         53722.95009424398
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:16:00.143922 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #318 | Epoch Duration: 170.36196851730347
2020-01-11 23:16:00.144151 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9136504
Z variance train             0.07815689
KL Divergence                18.444841
KL Loss                      1.8444842
QF Loss                      4002.9143
VF Loss                      312.8582
Policy Loss                  -1507.7645
Q Predictions Mean           1496.7312
Q Predictions Std            274.05072
Q Predictions Max            2077.3857
Q Predictions Min            447.07718
V Predictions Mean           1497.3757
V Predictions Std            266.01968
V Predictions Max            2067.3323
V Predictions Min            809.5095
Log Pis Mean                 1.0289931
Log Pis Std                  2.6442711
Log Pis Max                  11.302591
Log Pis Min                  -6.707478
Policy mu Mean               0.017272262
Policy mu Std                0.75315875
Policy mu Max                2.699137
Policy mu Min                -2.7416193
Policy log std Mean          -0.97023755
Policy log std Std           0.2594325
Policy log std Max           -0.1972605
Policy log std Min           -2.2214923
Z mean eval                  0.959638
Z variance eval              0.08548773
total_rewards                [ 324.04449229 1599.85959752  978.6409846   112.1677908  3628.59805897
 1134.28157127   23.31400846 3087.53518787 3963.19881676 2047.86965072]
total_rewards_mean           1689.9510159251506
total_rewards_std            1377.061421862588
total_rewards_max            3963.1988167561585
total_rewards_min            23.314008462612247
Number of train steps total  1280000
Number of env steps total    1904095
Number of rollouts total     0
Train Time (s)               147.99234098521993
(Previous) Eval Time (s)     16.05110703688115
Sample Time (s)              7.858181536663324
Epoch Time (s)               171.9016295587644
Total Train Time (s)         53894.9597605099
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:18:52.155557 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #319 | Epoch Duration: 172.01124596595764
2020-01-11 23:18:52.155707 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96301067
Z variance train             0.08545898
KL Divergence                18.344814
KL Loss                      1.8344815
QF Loss                      1021.7194
VF Loss                      366.21136
Policy Loss                  -1438.3759
Q Predictions Mean           1429.4719
Q Predictions Std            277.83408
Q Predictions Max            1978.5875
Q Predictions Min            687.4882
V Predictions Mean           1423.9839
V Predictions Std            275.82977
V Predictions Max            1973.169
V Predictions Min            663.39154
Log Pis Mean                 0.64417946
Log Pis Std                  2.9964445
Log Pis Max                  18.07029
Log Pis Min                  -6.5048285
Policy mu Mean               0.03235081
Policy mu Std                0.72175556
Policy mu Max                3.2700794
Policy mu Min                -2.5592027
Policy log std Mean          -0.9748167
Policy log std Std           0.27036703
Policy log std Max           -0.056922674
Policy log std Min           -2.366851
Z mean eval                  1.0848806
Z variance eval              0.04426209
total_rewards                [ 835.59717283 1983.25605488  535.30677971   79.43248129  769.27814604
 2898.42577841  253.94844573    4.23283838 1778.90730306 2021.10834517]
total_rewards_mean           1115.949334550437
total_rewards_std            936.8841782105765
total_rewards_max            2898.4257784066353
total_rewards_min            4.232838379481967
Number of train steps total  1284000
Number of env steps total    1914593
Number of rollouts total     0
Train Time (s)               147.60735634202138
(Previous) Eval Time (s)     13.815360829234123
Sample Time (s)              7.79811128647998
Epoch Time (s)               169.22082845773548
Total Train Time (s)         54064.287124222144
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:21:41.488157 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #320 | Epoch Duration: 169.3322970867157
2020-01-11 23:21:41.488409 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #320 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0850571
Z variance train             0.04421246
KL Divergence                19.566544
KL Loss                      1.9566544
QF Loss                      544.88257
VF Loss                      83.047134
Policy Loss                  -1369.6443
Q Predictions Mean           1363.8042
Q Predictions Std            287.47684
Q Predictions Max            1942.7955
Q Predictions Min            676.89966
V Predictions Mean           1370.0814
V Predictions Std            285.81754
V Predictions Max            1933.6606
V Predictions Min            681.04364
Log Pis Mean                 0.32137793
Log Pis Std                  2.764617
Log Pis Max                  8.382547
Log Pis Min                  -7.3767366
Policy mu Mean               -0.0056893197
Policy mu Std                0.7163101
Policy mu Max                2.71974
Policy mu Min                -2.5959241
Policy log std Mean          -0.93886644
Policy log std Std           0.26221922
Policy log std Max           -0.14944363
Policy log std Min           -1.9820838
Z mean eval                  0.97741354
Z variance eval              0.06345091
total_rewards                [3426.3612099  1478.46677644 4087.75988039 1902.12466782 3528.712638
  271.04896503 3982.41812311 3794.97635843 4113.44354532 2943.70708167]
total_rewards_mean           2952.9019246106404
total_rewards_std            1242.1749374475564
total_rewards_max            4113.443545322668
total_rewards_min            271.04896503098263
Number of train steps total  1288000
Number of env steps total    1924753
Number of rollouts total     0
Train Time (s)               148.04920337582007
(Previous) Eval Time (s)     21.592609444167465
Sample Time (s)              8.28820772934705
Epoch Time (s)               177.93002054933459
Total Train Time (s)         54242.30848222412
Epoch                        321
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:24:39.511076 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #321 | Epoch Duration: 178.0224974155426
2020-01-11 23:24:39.511222 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9772949
Z variance train             0.0625888
KL Divergence                19.152435
KL Loss                      1.9152435
QF Loss                      1161.6145
VF Loss                      137.89627
Policy Loss                  -1332.3201
Q Predictions Mean           1323.0054
Q Predictions Std            306.85168
Q Predictions Max            1909.099
Q Predictions Min            497.55624
V Predictions Mean           1331.5103
V Predictions Std            297.24368
V Predictions Max            1925.5121
V Predictions Min            569.3144
Log Pis Mean                 1.2966082
Log Pis Std                  3.3581455
Log Pis Max                  16.179428
Log Pis Min                  -6.348009
Policy mu Mean               0.074395046
Policy mu Std                0.769191
Policy mu Max                3.289919
Policy mu Min                -3.4364138
Policy log std Mean          -0.9901093
Policy log std Std           0.28612408
Policy log std Max           -0.04681456
Policy log std Min           -2.2943113
Z mean eval                  0.8910154
Z variance eval              0.072200075
total_rewards                [4088.87239304 1883.70716899 2974.1080965  -178.76043738  372.28904127
  944.70837838 3993.62495866 3036.70184878   37.29661504  159.61565633]
total_rewards_mean           1731.2163719598673
total_rewards_std            1593.7986954990324
total_rewards_max            4088.8723930355786
total_rewards_min            -178.76043737778556
Number of train steps total  1292000
Number of env steps total    1935273
Number of rollouts total     0
Train Time (s)               146.90641234675422
(Previous) Eval Time (s)     13.84284047409892
Sample Time (s)              7.316383676137775
Epoch Time (s)               168.06563649699092
Total Train Time (s)         54410.46505069686
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:27:27.671780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #322 | Epoch Duration: 168.1604359149933
2020-01-11 23:27:27.671973 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89375037
Z variance train             0.072145976
KL Divergence                19.239727
KL Loss                      1.9239727
QF Loss                      1692.5864
VF Loss                      124.37163
Policy Loss                  -1296.6472
Q Predictions Mean           1289.8246
Q Predictions Std            293.46463
Q Predictions Max            1861.6499
Q Predictions Min            570.255
V Predictions Mean           1292.0549
V Predictions Std            289.32715
V Predictions Max            1839.9963
V Predictions Min            577.9767
Log Pis Mean                 0.35833868
Log Pis Std                  2.9348125
Log Pis Max                  12.970873
Log Pis Min                  -9.636341
Policy mu Mean               0.021240419
Policy mu Std                0.69738
Policy mu Max                2.1527154
Policy mu Min                -3.4842005
Policy log std Mean          -0.9525012
Policy log std Std           0.27409607
Policy log std Max           -0.15000486
Policy log std Min           -2.4802382
Z mean eval                  0.8369177
Z variance eval              0.0699278
total_rewards                [1838.11778111  309.4891879   551.66931074 4475.21600666 3930.26441283
 3833.51231416 3321.58464388 4284.78133453 2469.77885517  503.95891719]
total_rewards_mean           2551.8372764161913
total_rewards_std            1567.688612216386
total_rewards_max            4475.216006660529
total_rewards_min            309.48918789508986
Number of train steps total  1296000
Number of env steps total    1946711
Number of rollouts total     0
Train Time (s)               146.5247127711773
(Previous) Eval Time (s)     16.12750907614827
Sample Time (s)              7.597140606492758
Epoch Time (s)               170.24936245381832
Total Train Time (s)         54580.83546741633
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:30:18.045660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #323 | Epoch Duration: 170.3735375404358
2020-01-11 23:30:18.045840 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8472818
Z variance train             0.06793254
KL Divergence                18.573635
KL Loss                      1.8573636
QF Loss                      484.47247
VF Loss                      116.61221
Policy Loss                  -1240.444
Q Predictions Mean           1233.315
Q Predictions Std            300.89246
Q Predictions Max            1799.9622
Q Predictions Min            520.8384
V Predictions Mean           1239.8579
V Predictions Std            301.7578
V Predictions Max            1786.351
V Predictions Min            516.3882
Log Pis Mean                 0.2535359
Log Pis Std                  2.704838
Log Pis Max                  7.5391083
Log Pis Min                  -8.189453
Policy mu Mean               0.029113282
Policy mu Std                0.6702684
Policy mu Max                2.3648937
Policy mu Min                -2.629012
Policy log std Mean          -0.96953905
Policy log std Std           0.27256104
Policy log std Max           -0.21493196
Policy log std Min           -2.094601
Z mean eval                  0.9534513
Z variance eval              0.051078808
total_rewards                [ 331.13710898 3601.69497315 2746.35755948   48.71791312 4294.04139972
  523.42537638 4027.23366617  957.81873673 3471.02872225 3758.32016222]
total_rewards_mean           2375.977561820058
total_rewards_std            1618.5123488974261
total_rewards_max            4294.041399720729
total_rewards_min            48.717913117932355
Number of train steps total  1300000
Number of env steps total    1957251
Number of rollouts total     0
Train Time (s)               148.14928887225688
(Previous) Eval Time (s)     15.282562816981226
Sample Time (s)              7.271054292563349
Epoch Time (s)               170.70290598180145
Total Train Time (s)         54751.63307580957
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:33:08.844717 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #324 | Epoch Duration: 170.79875373840332
2020-01-11 23:33:08.844849 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94727707
Z variance train             0.05087892
KL Divergence                18.887669
KL Loss                      1.8887669
QF Loss                      549.0199
VF Loss                      113.80948
Policy Loss                  -1223.4694
Q Predictions Mean           1221.1931
Q Predictions Std            306.85526
Q Predictions Max            1777.9941
Q Predictions Min            468.5901
V Predictions Mean           1222.5039
V Predictions Std            305.20105
V Predictions Max            1755.256
V Predictions Min            475.46445
Log Pis Mean                 0.25571674
Log Pis Std                  2.8710084
Log Pis Max                  10.944456
Log Pis Min                  -10.345185
Policy mu Mean               -0.014348394
Policy mu Std                0.6608209
Policy mu Max                2.5520506
Policy mu Min                -2.4397764
Policy log std Mean          -0.9707607
Policy log std Std           0.27370617
Policy log std Max           -0.051133037
Policy log std Min           -2.3906202
Z mean eval                  0.81371385
Z variance eval              0.0153417485
total_rewards                [ 927.54294056  188.13244342 1637.39717718 3966.74545217 3820.62346073
 4070.35825209  386.60342806 3655.35981702 1367.65735514 3434.55880883]
total_rewards_mean           2345.497913520264
total_rewards_std            1504.694071286276
total_rewards_max            4070.3582520920204
total_rewards_min            188.13244342326982
Number of train steps total  1304000
Number of env steps total    1969251
Number of rollouts total     0
Train Time (s)               145.7871784348972
(Previous) Eval Time (s)     16.668000624980778
Sample Time (s)              6.018572765402496
Epoch Time (s)               168.4737518252805
Total Train Time (s)         54920.19519368
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:35:57.410238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #325 | Epoch Duration: 168.56528306007385
2020-01-11 23:35:57.410389 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.814226
Z variance train             0.015242465
KL Divergence                19.53102
KL Loss                      1.953102
QF Loss                      1482.4375
VF Loss                      161.05815
Policy Loss                  -1202.0215
Q Predictions Mean           1199.168
Q Predictions Std            331.66245
Q Predictions Max            1815.3534
Q Predictions Min            429.128
V Predictions Mean           1203.7769
V Predictions Std            328.77182
V Predictions Max            1810.0471
V Predictions Min            402.74426
Log Pis Mean                 0.6190971
Log Pis Std                  3.220203
Log Pis Max                  20.117947
Log Pis Min                  -10.133417
Policy mu Mean               0.010414464
Policy mu Std                0.7084001
Policy mu Max                3.2575126
Policy mu Min                -2.9308639
Policy log std Mean          -0.9610095
Policy log std Std           0.2864014
Policy log std Max           -0.2748655
Policy log std Min           -2.2885425
Z mean eval                  0.8698932
Z variance eval              0.03086916
total_rewards                [2060.86183187 4160.71814864 1314.86649448 4292.6519572  4142.85409991
 3713.32253017 4186.32062851 1116.5640425  1248.38940521  543.16105278]
total_rewards_mean           2677.9710191294853
total_rewards_std            1468.9000626936818
total_rewards_max            4292.651957200419
total_rewards_min            543.1610527800159
Number of train steps total  1308000
Number of env steps total    1981026
Number of rollouts total     0
Train Time (s)               147.7304720338434
(Previous) Eval Time (s)     18.473284938838333
Sample Time (s)              7.241693580988795
Epoch Time (s)               173.44545055367053
Total Train Time (s)         55093.73308283882
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:38:50.949887 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #326 | Epoch Duration: 173.53939199447632
2020-01-11 23:38:50.950032 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86947024
Z variance train             0.030825373
KL Divergence                19.076862
KL Loss                      1.9076862
QF Loss                      5039.883
VF Loss                      149.59706
Policy Loss                  -1208.6388
Q Predictions Mean           1202.4495
Q Predictions Std            317.3281
Q Predictions Max            1786.6345
Q Predictions Min            437.2012
V Predictions Mean           1204.5146
V Predictions Std            314.87735
V Predictions Max            1788.74
V Predictions Min            451.63364
Log Pis Mean                 0.34310052
Log Pis Std                  3.0067606
Log Pis Max                  12.294863
Log Pis Min                  -9.8151455
Policy mu Mean               0.051348574
Policy mu Std                0.67048615
Policy mu Max                2.8439386
Policy mu Min                -2.6503289
Policy log std Mean          -1.0072913
Policy log std Std           0.28393474
Policy log std Max           -0.18743336
Policy log std Min           -2.4673562
Z mean eval                  0.8646758
Z variance eval              0.022909204
total_rewards                [ 503.83896828 1415.92036393 -144.78725872 4395.91658528 2080.49928309
   81.3423754  2942.63187399 1321.18360472 1244.86718904  481.00650992]
total_rewards_mean           1432.2419494936562
total_rewards_std            1327.0766380375935
total_rewards_max            4395.916585284314
total_rewards_min            -144.787258716343
Number of train steps total  1312000
Number of env steps total    1988655
Number of rollouts total     0
Train Time (s)               145.25094787729904
(Previous) Eval Time (s)     10.994665694888681
Sample Time (s)              7.060962551739067
Epoch Time (s)               163.3065761239268
Total Train Time (s)         55257.27790492214
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:41:34.515572 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #327 | Epoch Duration: 163.56542825698853
2020-01-11 23:41:34.515725 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8570148
Z variance train             0.023053631
KL Divergence                19.811228
KL Loss                      1.9811229
QF Loss                      526.2406
VF Loss                      163.47797
Policy Loss                  -1219.5792
Q Predictions Mean           1215.6948
Q Predictions Std            325.31488
Q Predictions Max            1755.4333
Q Predictions Min            400.66818
V Predictions Mean           1228.1108
V Predictions Std            322.90088
V Predictions Max            1776.0735
V Predictions Min            410.61496
Log Pis Mean                 0.45188898
Log Pis Std                  2.7309878
Log Pis Max                  9.504321
Log Pis Min                  -7.2507386
Policy mu Mean               0.017024979
Policy mu Std                0.6613792
Policy mu Max                2.396735
Policy mu Min                -2.6138258
Policy log std Mean          -0.9969796
Policy log std Std           0.28674847
Policy log std Max           0.008518338
Policy log std Min           -2.1452122
Z mean eval                  0.81593466
Z variance eval              0.018288944
total_rewards                [ 481.90636022 3450.55642089   46.4617137  4243.30373546 4090.48548158
 4463.5646454  2934.55340048  284.88219466 4144.01207688 3023.78586534]
total_rewards_mean           2716.3511894619214
total_rewards_std            1674.0692992715458
total_rewards_max            4463.564645404922
total_rewards_min            46.461713703668266
Number of train steps total  1316000
Number of env steps total    2000442
Number of rollouts total     0
Train Time (s)               145.71286549558863
(Previous) Eval Time (s)     18.224572575185448
Sample Time (s)              7.9497071034274995
Epoch Time (s)               171.88714517420158
Total Train Time (s)         55429.27641887823
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:44:26.498474 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #328 | Epoch Duration: 171.9826455116272
2020-01-11 23:44:26.498628 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81508625
Z variance train             0.018355884
KL Divergence                20.837357
KL Loss                      2.0837357
QF Loss                      913.1086
VF Loss                      695.7258
Policy Loss                  -1167.4119
Q Predictions Mean           1158.8223
Q Predictions Std            364.78284
Q Predictions Max            1771.871
Q Predictions Min            -36.418266
V Predictions Mean           1168.0334
V Predictions Std            358.1898
V Predictions Max            1764.087
V Predictions Min            -22.089987
Log Pis Mean                 0.5503401
Log Pis Std                  3.4887693
Log Pis Max                  28.785498
Log Pis Min                  -7.1708403
Policy mu Mean               -0.0016491197
Policy mu Std                0.71469384
Policy mu Max                3.695374
Policy mu Min                -4.373354
Policy log std Mean          -0.948784
Policy log std Std           0.30448756
Policy log std Max           0.0111095905
Policy log std Min           -2.6702127
Z mean eval                  0.86595917
Z variance eval              0.10026487
total_rewards                [ 455.3396815  4072.0703742  3486.02953788 4670.086764    792.16273318
  927.76778999 4432.73098535   40.42802395 1670.05201057  134.55435711]
total_rewards_mean           2068.1222257727113
total_rewards_std            1786.7876244090069
total_rewards_max            4670.086763997537
total_rewards_min            40.42802394909534
Number of train steps total  1320000
Number of env steps total    2012442
Number of rollouts total     0
Train Time (s)               146.85378240188584
(Previous) Eval Time (s)     12.535754450131208
Sample Time (s)              7.290455584879965
Epoch Time (s)               166.679992436897
Total Train Time (s)         55596.04669505637
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:47:13.272005 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #329 | Epoch Duration: 166.7732572555542
2020-01-11 23:47:13.272189 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86693925
Z variance train             0.09948023
KL Divergence                19.278397
KL Loss                      1.9278396
QF Loss                      412.886
VF Loss                      85.35206
Policy Loss                  -1194.8667
Q Predictions Mean           1190.9868
Q Predictions Std            332.6518
Q Predictions Max            1792.0802
Q Predictions Min            405.80096
V Predictions Mean           1196.2598
V Predictions Std            331.28476
V Predictions Max            1739.5742
V Predictions Min            418.39777
Log Pis Mean                 0.6332325
Log Pis Std                  2.7845309
Log Pis Max                  11.431604
Log Pis Min                  -8.631292
Policy mu Mean               0.011179162
Policy mu Std                0.67918605
Policy mu Max                2.4620097
Policy mu Min                -2.4093904
Policy log std Mean          -0.98651034
Policy log std Std           0.27547035
Policy log std Max           -0.25743973
Policy log std Min           -2.41427
Z mean eval                  0.9567236
Z variance eval              0.015301602
total_rewards                [ 782.03819804 4358.15516194 4288.83328801  480.62278412  698.94624388
 1505.26424013 3976.19611893 4254.85647262 2439.84884493 4066.93967577]
total_rewards_mean           2685.1701028370944
total_rewards_std            1590.2814453941628
total_rewards_max            4358.155161941941
total_rewards_min            480.62278412442186
Number of train steps total  1324000
Number of env steps total    2023017
Number of rollouts total     0
Train Time (s)               145.70889100292698
(Previous) Eval Time (s)     16.747438713908195
Sample Time (s)              6.171395462937653
Epoch Time (s)               168.62772517977282
Total Train Time (s)         55764.81092862971
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:50:02.044767 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #330 | Epoch Duration: 168.77244400978088
2020-01-11 23:50:02.044933 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96514714
Z variance train             0.01544403
KL Divergence                20.829334
KL Loss                      2.0829334
QF Loss                      421.62137
VF Loss                      97.66629
Policy Loss                  -1156.3907
Q Predictions Mean           1148.631
Q Predictions Std            344.96503
Q Predictions Max            1776.8281
Q Predictions Min            402.47772
V Predictions Mean           1155.7771
V Predictions Std            344.0329
V Predictions Max            1762.874
V Predictions Min            367.37045
Log Pis Mean                 0.3683898
Log Pis Std                  3.256419
Log Pis Max                  14.100241
Log Pis Min                  -8.912943
Policy mu Mean               0.044665754
Policy mu Std                0.68518126
Policy mu Max                2.7214592
Policy mu Min                -2.7323842
Policy log std Mean          -0.9718415
Policy log std Std           0.2923876
Policy log std Max           -0.20922816
Policy log std Min           -2.5786405
Z mean eval                  0.856949
Z variance eval              0.019588456
total_rewards                [4456.1757452  3942.29517847 2646.60015816 1284.25305759 1576.48373241
 4447.75317863 4571.12158155 2509.65827318 4523.49638972  648.53872091]
total_rewards_mean           3060.637601580698
total_rewards_std            1439.5115524209061
total_rewards_max            4571.1215815454125
total_rewards_min            648.5387209093562
Number of train steps total  1328000
Number of env steps total    2031318
Number of rollouts total     0
Train Time (s)               146.53207987267524
(Previous) Eval Time (s)     17.616217301692814
Sample Time (s)              6.266449803020805
Epoch Time (s)               170.41474697738886
Total Train Time (s)         55935.319089399185
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:52:52.549985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #331 | Epoch Duration: 170.50492668151855
2020-01-11 23:52:52.550130 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8577673
Z variance train             0.01955318
KL Divergence                19.93611
KL Loss                      1.993611
QF Loss                      520.63055
VF Loss                      116.79106
Policy Loss                  -1151.6063
Q Predictions Mean           1146.1804
Q Predictions Std            358.01895
Q Predictions Max            1767.9456
Q Predictions Min            376.42807
V Predictions Mean           1156.9023
V Predictions Std            359.1485
V Predictions Max            1770.489
V Predictions Min            369.7459
Log Pis Mean                 0.33833566
Log Pis Std                  2.710297
Log Pis Max                  10.116886
Log Pis Min                  -5.9194565
Policy mu Mean               0.047619164
Policy mu Std                0.6534418
Policy mu Max                1.8335816
Policy mu Min                -2.3690352
Policy log std Mean          -0.96727663
Policy log std Std           0.26097357
Policy log std Max           -0.29627478
Policy log std Min           -2.6295748
Z mean eval                  0.8853494
Z variance eval              0.04844123
total_rewards                [3722.72263465 1631.43920979  376.07480341  571.84638732  363.84669569
  494.56193641 3373.68780699 1823.22136518  389.31478169   41.54250918]
total_rewards_mean           1278.8258130312113
total_rewards_std            1259.79827469183
total_rewards_max            3722.7226346462944
total_rewards_min            41.5425091845373
Number of train steps total  1332000
Number of env steps total    2042954
Number of rollouts total     0
Train Time (s)               147.04136352567002
(Previous) Eval Time (s)     11.013989276252687
Sample Time (s)              8.01367171946913
Epoch Time (s)               166.06902452139184
Total Train Time (s)         56101.48277036473
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:55:38.716065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #332 | Epoch Duration: 166.16582441329956
2020-01-11 23:55:38.716225 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8830358
Z variance train             0.048213933
KL Divergence                19.038166
KL Loss                      1.9038166
QF Loss                      847.5651
VF Loss                      70.62959
Policy Loss                  -1176.0958
Q Predictions Mean           1171.1548
Q Predictions Std            373.82956
Q Predictions Max            1816.466
Q Predictions Min            374.8177
V Predictions Mean           1177.3835
V Predictions Std            374.13998
V Predictions Max            1814.7799
V Predictions Min            370.8343
Log Pis Mean                 0.042937703
Log Pis Std                  2.86467
Log Pis Max                  9.353043
Log Pis Min                  -8.490092
Policy mu Mean               -0.045687966
Policy mu Std                0.6313777
Policy mu Max                2.0543284
Policy mu Min                -2.6131077
Policy log std Mean          -0.9724909
Policy log std Std           0.28641465
Policy log std Max           -0.09150946
Policy log std Min           -2.469812
Z mean eval                  0.88689727
Z variance eval              0.028703058
total_rewards                [ 259.47590289 1104.61534327  594.96225723 2313.71705325 4270.48994033
  193.19938059  544.55704675  260.50118178  491.3761652   308.60999242]
total_rewards_mean           1034.150426370516
total_rewards_std            1235.9450911886865
total_rewards_max            4270.489940334315
total_rewards_min            193.19938058655308
Number of train steps total  1336000
Number of env steps total    2052926
Number of rollouts total     0
Train Time (s)               146.24039129912853
(Previous) Eval Time (s)     9.348403637763113
Sample Time (s)              6.9878098466433585
Epoch Time (s)               162.576604783535
Total Train Time (s)         56264.15022847988
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:58:21.387518 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #333 | Epoch Duration: 162.67118287086487
2020-01-11 23:58:21.387671 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8781045
Z variance train             0.027311895
KL Divergence                19.931253
KL Loss                      1.9931253
QF Loss                      690.6566
VF Loss                      163.70374
Policy Loss                  -1163.2562
Q Predictions Mean           1154.5695
Q Predictions Std            350.28
Q Predictions Max            1775.8998
Q Predictions Min            380.8173
V Predictions Mean           1157.9858
V Predictions Std            349.60855
V Predictions Max            1771.3251
V Predictions Min            392.5477
Log Pis Mean                 0.60312486
Log Pis Std                  3.2147062
Log Pis Max                  12.4890585
Log Pis Min                  -6.521179
Policy mu Mean               -0.021401266
Policy mu Std                0.6966776
Policy mu Max                2.4817746
Policy mu Min                -3.5243871
Policy log std Mean          -0.9773704
Policy log std Std           0.30267584
Policy log std Max           -0.1979444
Policy log std Min           -2.3632288
Z mean eval                  0.8832741
Z variance eval              0.011963798
total_rewards                [3773.16854547  647.42646997 2093.84815989 3488.35258775 2079.14769426
 4438.90140929  173.2950934  1375.12276667  276.78866008 4599.37441295]
total_rewards_mean           2294.5425799730774
total_rewards_std            1604.3086021152894
total_rewards_max            4599.374412947117
total_rewards_min            173.29509340208278
Number of train steps total  1340000
Number of env steps total    2063472
Number of rollouts total     0
Train Time (s)               146.93631789414212
(Previous) Eval Time (s)     15.524911739863455
Sample Time (s)              7.182041538413614
Epoch Time (s)               169.6432711724192
Total Train Time (s)         56433.8809567811
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:01:11.120684 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #334 | Epoch Duration: 169.73289465904236
2020-01-12 00:01:11.120869 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88501275
Z variance train             0.011992437
KL Divergence                21.350977
KL Loss                      2.1350977
QF Loss                      421.91785
VF Loss                      162.32248
Policy Loss                  -1217.8923
Q Predictions Mean           1209.26
Q Predictions Std            347.44785
Q Predictions Max            1807.0702
Q Predictions Min            371.6218
V Predictions Mean           1208.2251
V Predictions Std            344.91937
V Predictions Max            1778.6526
V Predictions Min            366.17145
Log Pis Mean                 0.5435771
Log Pis Std                  2.755996
Log Pis Max                  11.609392
Log Pis Min                  -6.31339
Policy mu Mean               -0.013037108
Policy mu Std                0.66888994
Policy mu Max                2.4184961
Policy mu Min                -2.2450724
Policy log std Mean          -0.9706821
Policy log std Std           0.27033326
Policy log std Max           -0.24424231
Policy log std Min           -2.1765437
Z mean eval                  0.878026
Z variance eval              0.030809289
total_rewards                [3737.80100248  858.80057602 1326.78360576 3249.07670731    7.02429273
 4632.42417641 4658.93632599 2955.13063746 1466.53973747 3754.56212336]
total_rewards_mean           2664.7079184988806
total_rewards_std            1554.4847842799318
total_rewards_max            4658.936325987293
total_rewards_min            7.024292730351411
Number of train steps total  1344000
Number of env steps total    2075344
Number of rollouts total     0
Train Time (s)               145.76593072433025
(Previous) Eval Time (s)     20.9531925288029
Sample Time (s)              8.45602976018563
Epoch Time (s)               175.17515301331878
Total Train Time (s)         56609.14342043409
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:04:06.385281 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #335 | Epoch Duration: 175.26428890228271
2020-01-12 00:04:06.385417 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8852866
Z variance train             0.030800337
KL Divergence                18.934666
KL Loss                      1.8934666
QF Loss                      3102.005
VF Loss                      106.21297
Policy Loss                  -1133.0221
Q Predictions Mean           1124.1702
Q Predictions Std            379.49826
Q Predictions Max            1776.6082
Q Predictions Min            314.35367
V Predictions Mean           1129.543
V Predictions Std            373.33423
V Predictions Max            1760.8755
V Predictions Min            384.02713
Log Pis Mean                 0.110610165
Log Pis Std                  3.0609756
Log Pis Max                  10.596675
Log Pis Min                  -7.0507708
Policy mu Mean               0.050190702
Policy mu Std                0.63607115
Policy mu Max                2.6599298
Policy mu Min                -3.5411494
Policy log std Mean          -0.9358233
Policy log std Std           0.28111917
Policy log std Max           0.10281432
Policy log std Min           -2.2617574
Z mean eval                  1.2030725
Z variance eval              0.0300376
total_rewards                [1691.70013592 1056.58557315 2651.00531211  963.14230743 1577.00386466
 2650.44990935  739.05655107 1223.24699622 2215.08919775   57.23924681]
total_rewards_mean           1482.4519094468446
total_rewards_std            801.3312829380579
total_rewards_max            2651.0053121091446
total_rewards_min            57.23924681380505
Number of train steps total  1348000
Number of env steps total    2086516
Number of rollouts total     0
Train Time (s)               145.58664253586903
(Previous) Eval Time (s)     12.12291733827442
Sample Time (s)              6.924528729636222
Epoch Time (s)               164.63408860377967
Total Train Time (s)         56773.865404771175
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:06:51.111819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #336 | Epoch Duration: 164.72628712654114
2020-01-12 00:06:51.111993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.201483
Z variance train             0.029940521
KL Divergence                19.653204
KL Loss                      1.9653205
QF Loss                      763.17847
VF Loss                      265.4216
Policy Loss                  -1132.8431
Q Predictions Mean           1127.7393
Q Predictions Std            388.826
Q Predictions Max            1754.924
Q Predictions Min            -53.5899
V Predictions Mean           1125.1499
V Predictions Std            386.84583
V Predictions Max            1756.9028
V Predictions Min            23.07779
Log Pis Mean                 0.4364574
Log Pis Std                  3.4328578
Log Pis Max                  19.663292
Log Pis Min                  -7.779198
Policy mu Mean               0.026880832
Policy mu Std                0.63447756
Policy mu Max                2.576042
Policy mu Min                -3.3860486
Policy log std Mean          -0.9837197
Policy log std Std           0.34845805
Policy log std Max           -0.26544523
Policy log std Min           -4.3668838
Z mean eval                  0.8579667
Z variance eval              0.06074942
total_rewards                [2260.23050656 4717.50134784 2698.38885251 4682.63898251 4860.12232719
 1889.14094649 1546.86879935 4024.47294946 4182.5205827  4415.94304602]
total_rewards_mean           3527.78283406253
total_rewards_std            1220.3365712435884
total_rewards_max            4860.122327188052
total_rewards_min            1546.8687993455706
Number of train steps total  1352000
Number of env steps total    2097444
Number of rollouts total     0
Train Time (s)               146.0694644539617
(Previous) Eval Time (s)     17.516963745933026
Sample Time (s)              7.289663682691753
Epoch Time (s)               170.87609188258648
Total Train Time (s)         56944.82501091994
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:09:42.073399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #337 | Epoch Duration: 170.96128034591675
2020-01-12 00:09:42.073534 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85700977
Z variance train             0.060599536
KL Divergence                17.453232
KL Loss                      1.7453232
QF Loss                      779.14417
VF Loss                      109.4717
Policy Loss                  -1184.4596
Q Predictions Mean           1177.1138
Q Predictions Std            335.57782
Q Predictions Max            1736.1039
Q Predictions Min            364.97214
V Predictions Mean           1184.2051
V Predictions Std            335.79562
V Predictions Max            1735.8866
V Predictions Min            371.2045
Log Pis Mean                 0.35938263
Log Pis Std                  3.1021826
Log Pis Max                  10.536713
Log Pis Min                  -9.612883
Policy mu Mean               -8.389191e-05
Policy mu Std                0.63096887
Policy mu Max                2.0327194
Policy mu Min                -2.3753705
Policy log std Mean          -1.0139048
Policy log std Std           0.29533502
Policy log std Max           -0.25331837
Policy log std Min           -2.2448573
Z mean eval                  0.7745789
Z variance eval              0.015214831
total_rewards                [4327.46192504 1680.05035599 4202.37408695 2169.6072025  4310.59131147
  948.37069556 4562.65645752   29.9475791  2320.91688821 4361.12581252]
total_rewards_mean           2891.3102314854345
total_rewards_std            1581.938669365955
total_rewards_max            4562.656457517129
total_rewards_min            29.947579101889534
Number of train steps total  1356000
Number of env steps total    2107805
Number of rollouts total     0
Train Time (s)               147.31582065066323
(Previous) Eval Time (s)     16.91281518433243
Sample Time (s)              6.409549590200186
Epoch Time (s)               170.63818542519584
Total Train Time (s)         57115.56227524951
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:12:32.816382 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #338 | Epoch Duration: 170.74271965026855
2020-01-12 00:12:32.816609 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77412385
Z variance train             0.015261541
KL Divergence                19.340652
KL Loss                      1.9340652
QF Loss                      1079.5549
VF Loss                      263.2934
Policy Loss                  -1164.5032
Q Predictions Mean           1157.943
Q Predictions Std            379.12726
Q Predictions Max            1800.9005
Q Predictions Min            362.74484
V Predictions Mean           1156.3025
V Predictions Std            375.9773
V Predictions Max            1791.8578
V Predictions Min            356.71487
Log Pis Mean                 0.3356163
Log Pis Std                  3.347885
Log Pis Max                  14.155209
Log Pis Min                  -6.6674914
Policy mu Mean               0.05192075
Policy mu Std                0.65422046
Policy mu Max                2.8664513
Policy mu Min                -3.0258143
Policy log std Mean          -0.9841486
Policy log std Std           0.30385107
Policy log std Max           -0.16019201
Policy log std Min           -2.516805
Z mean eval                  0.8275207
Z variance eval              0.015241469
total_rewards                [4183.35129434 2080.56714646 4544.57338056 4027.07720688 1506.28322315
 4508.3967107  4359.67343217  638.23869805 4526.68632395 4826.32451513]
total_rewards_mean           3520.1171931391027
total_rewards_std            1434.5857845014236
total_rewards_max            4826.324515131429
total_rewards_min            638.2386980494177
Number of train steps total  1360000
Number of env steps total    2118367
Number of rollouts total     0
Train Time (s)               147.14156302902848
(Previous) Eval Time (s)     19.33837390411645
Sample Time (s)              6.763312291819602
Epoch Time (s)               173.24324922496453
Total Train Time (s)         57288.89289236022
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:15:26.150073 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #339 | Epoch Duration: 173.33330297470093
2020-01-12 00:15:26.150215 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8296939
Z variance train             0.015245144
KL Divergence                19.69871
KL Loss                      1.9698709
QF Loss                      761.8573
VF Loss                      77.483315
Policy Loss                  -1152.9342
Q Predictions Mean           1147.2207
Q Predictions Std            377.91006
Q Predictions Max            1754.643
Q Predictions Min            365.98734
V Predictions Mean           1149.0826
V Predictions Std            378.29105
V Predictions Max            1737.3022
V Predictions Min            372.2701
Log Pis Mean                 0.35326508
Log Pis Std                  3.2061584
Log Pis Max                  11.161019
Log Pis Min                  -9.869419
Policy mu Mean               0.037992835
Policy mu Std                0.64773285
Policy mu Max                2.2199464
Policy mu Min                -2.5918574
Policy log std Mean          -0.9927501
Policy log std Std           0.3004231
Policy log std Max           -0.24593729
Policy log std Min           -2.3898423
Z mean eval                  1.0518869
Z variance eval              0.014451268
total_rewards                [ 799.38577218 2263.06813216  431.42941649 4162.2359842  2117.87013691
  841.69954067 3626.39435113 3553.07584293 3798.71747829 4395.23781795]
total_rewards_mean           2598.9114472907995
total_rewards_std            1429.8501155674269
total_rewards_max            4395.237817953042
total_rewards_min            431.4294164898539
Number of train steps total  1364000
Number of env steps total    2129154
Number of rollouts total     0
Train Time (s)               148.73900257702917
(Previous) Eval Time (s)     16.19365428108722
Sample Time (s)              7.233699174597859
Epoch Time (s)               172.16635603271425
Total Train Time (s)         57461.14436163055
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:18:18.405241 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #340 | Epoch Duration: 172.25491166114807
2020-01-12 00:18:18.405420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0486189
Z variance train             0.014387804
KL Divergence                20.706299
KL Loss                      2.0706298
QF Loss                      876.34326
VF Loss                      636.973
Policy Loss                  -1197.0018
Q Predictions Mean           1186.7812
Q Predictions Std            375.29572
Q Predictions Max            1763.5209
Q Predictions Min            -1.4505906
V Predictions Mean           1190.418
V Predictions Std            372.7187
V Predictions Max            1756.5496
V Predictions Min            218.62743
Log Pis Mean                 0.9240529
Log Pis Std                  3.6681082
Log Pis Max                  25.206884
Log Pis Min                  -8.781702
Policy mu Mean               -0.09620677
Policy mu Std                0.7132138
Policy mu Max                2.944569
Policy mu Min                -4.169911
Policy log std Mean          -1.0158788
Policy log std Std           0.30525672
Policy log std Max           -0.22207999
Policy log std Min           -2.7541375
Z mean eval                  0.8605564
Z variance eval              0.009854101
total_rewards                [4220.14374882 1808.72573467 4870.32364044   98.01070964 4737.90831408
 1795.66037325 4884.09643377 2431.33581567   38.82753795 2923.88171736]
total_rewards_mean           2780.891402563811
total_rewards_std            1773.8586652720805
total_rewards_max            4884.096433769937
total_rewards_min            38.82753794816068
Number of train steps total  1368000
Number of env steps total    2138881
Number of rollouts total     0
Train Time (s)               146.54965856065974
(Previous) Eval Time (s)     14.757382126990706
Sample Time (s)              7.035609394777566
Epoch Time (s)               168.342650082428
Total Train Time (s)         57629.571093541104
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:21:06.834173 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #341 | Epoch Duration: 168.42862749099731
2020-01-12 00:21:06.834316 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8656378
Z variance train             0.009841555
KL Divergence                20.622484
KL Loss                      2.0622485
QF Loss                      575.19714
VF Loss                      103.50422
Policy Loss                  -1188.9308
Q Predictions Mean           1183.5732
Q Predictions Std            366.90344
Q Predictions Max            1785.4689
Q Predictions Min            353.11368
V Predictions Mean           1188.6643
V Predictions Std            363.38196
V Predictions Max            1782.3552
V Predictions Min            356.74194
Log Pis Mean                 0.41610828
Log Pis Std                  3.0185797
Log Pis Max                  17.980957
Log Pis Min                  -14.089735
Policy mu Mean               -0.0021124794
Policy mu Std                0.6485228
Policy mu Max                2.2621634
Policy mu Min                -2.466523
Policy log std Mean          -1.0148894
Policy log std Std           0.2840742
Policy log std Max           -0.2550658
Policy log std Min           -2.4856758
Z mean eval                  0.7947877
Z variance eval              0.0070349225
total_rewards                [3089.90103926 4831.69034208 2614.707769   4654.87981096 4726.24243289
 4448.71672918 4907.38199707 5066.93253301 4850.68447164  350.75543376]
total_rewards_mean           3954.1892558850695
total_rewards_std            1434.5039804833714
total_rewards_max            5066.932533005276
total_rewards_min            350.7554337597216
Number of train steps total  1372000
Number of env steps total    2150418
Number of rollouts total     0
Train Time (s)               150.09449787205085
(Previous) Eval Time (s)     19.20082108490169
Sample Time (s)              7.162753284908831
Epoch Time (s)               176.45807224186137
Total Train Time (s)         57806.122397014406
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:24:03.392236 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #342 | Epoch Duration: 176.55775928497314
2020-01-12 00:24:03.392525 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79314935
Z variance train             0.0070457743
KL Divergence                20.350035
KL Loss                      2.0350034
QF Loss                      589.59973
VF Loss                      132.80554
Policy Loss                  -1155.6733
Q Predictions Mean           1150.0659
Q Predictions Std            378.87802
Q Predictions Max            1801.3458
Q Predictions Min            356.10345
V Predictions Mean           1162.374
V Predictions Std            378.28564
V Predictions Max            1790.1526
V Predictions Min            357.92667
Log Pis Mean                 0.22964352
Log Pis Std                  3.0244186
Log Pis Max                  13.731737
Log Pis Min                  -8.45373
Policy mu Mean               -0.008949212
Policy mu Std                0.6361093
Policy mu Max                2.8256927
Policy mu Min                -2.4776924
Policy log std Mean          -0.9910944
Policy log std Std           0.270682
Policy log std Max           -0.27829236
Policy log std Min           -2.331399
Z mean eval                  0.781846
Z variance eval              0.007819963
total_rewards                [ 189.35841771 4634.72803826 1472.92081255 4594.0048505  4833.70505852
 4455.02421155 4723.4458513  4456.2620288  1920.00533984 3323.08415444]
total_rewards_mean           3460.2538763474477
total_rewards_std            1586.4373324512144
total_rewards_max            4833.705058520491
total_rewards_min            189.35841770839417
Number of train steps total  1376000
Number of env steps total    2160822
Number of rollouts total     0
Train Time (s)               145.38466403400525
(Previous) Eval Time (s)     17.86054772976786
Sample Time (s)              6.641034216154367
Epoch Time (s)               169.88624597992748
Total Train Time (s)         57976.09285411937
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:26:53.365055 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #343 | Epoch Duration: 169.9723358154297
2020-01-12 00:26:53.365201 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.785807
Z variance train             0.007867673
KL Divergence                20.617998
KL Loss                      2.0617998
QF Loss                      10087.098
VF Loss                      95.08764
Policy Loss                  -1205.049
Q Predictions Mean           1201.4524
Q Predictions Std            370.55536
Q Predictions Max            1784.6522
Q Predictions Min            343.7836
V Predictions Mean           1206.1855
V Predictions Std            371.41318
V Predictions Max            1784.7098
V Predictions Min            332.85468
Log Pis Mean                 0.36736166
Log Pis Std                  3.1035948
Log Pis Max                  11.22212
Log Pis Min                  -8.969408
Policy mu Mean               -0.0055273334
Policy mu Std                0.657621
Policy mu Max                2.1029916
Policy mu Min                -2.167325
Policy log std Mean          -0.9939595
Policy log std Std           0.3056148
Policy log std Max           -0.29287267
Policy log std Min           -2.4609356
Z mean eval                  1.1104783
Z variance eval              0.0044197687
total_rewards                [4784.71216666 3848.09008224 3583.64267729 3447.63220455 4607.30525645
 4715.71469157 1544.95939488 2011.68548825  642.01842618  653.58944529]
total_rewards_mean           2983.934983336613
total_rewards_std            1553.3712448677034
total_rewards_max            4784.712166663672
total_rewards_min            642.0184261848646
Number of train steps total  1380000
Number of env steps total    2171732
Number of rollouts total     0
Train Time (s)               145.80378750804812
(Previous) Eval Time (s)     15.365430916193873
Sample Time (s)              6.805514784064144
Epoch Time (s)               167.97473320830613
Total Train Time (s)         58144.157686454244
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:29:41.435104 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #344 | Epoch Duration: 168.0697886943817
2020-01-12 00:29:41.435291 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1051219
Z variance train             0.0044188453
KL Divergence                22.432163
KL Loss                      2.2432163
QF Loss                      493.0785
VF Loss                      87.25375
Policy Loss                  -1213.6759
Q Predictions Mean           1207.2296
Q Predictions Std            365.83936
Q Predictions Max            1776.547
Q Predictions Min            316.22455
V Predictions Mean           1208.7297
V Predictions Std            366.21213
V Predictions Max            1759.1311
V Predictions Min            314.50134
Log Pis Mean                 0.73971313
Log Pis Std                  2.7799184
Log Pis Max                  9.733143
Log Pis Min                  -6.179607
Policy mu Mean               0.055143423
Policy mu Std                0.6581439
Policy mu Max                2.9831538
Policy mu Min                -2.4524066
Policy log std Mean          -1.0132117
Policy log std Std           0.26747602
Policy log std Max           -0.17965972
Policy log std Min           -2.1541843
Z mean eval                  0.69227487
Z variance eval              0.006309843
total_rewards                [ 484.50435959 2906.19417637   42.85565825  107.90067425 2472.10970069
 3512.60631556  205.63957849 2660.75339499   96.19761369  341.86856604]
total_rewards_mean           1283.063003790454
total_rewards_std            1339.0084157339522
total_rewards_max            3512.6063155553466
total_rewards_min            42.85565824535088
Number of train steps total  1384000
Number of env steps total    2183732
Number of rollouts total     0
Train Time (s)               146.71021055569872
(Previous) Eval Time (s)     6.289163914043456
Sample Time (s)              7.136965253856033
Epoch Time (s)               160.1363397235982
Total Train Time (s)         58304.383126396686
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:32:21.669119 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #345 | Epoch Duration: 160.23365807533264
2020-01-12 00:32:21.669420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6904358
Z variance train             0.006327614
KL Divergence                21.043703
KL Loss                      2.1043704
QF Loss                      1415.3394
VF Loss                      157.84447
Policy Loss                  -1215.8768
Q Predictions Mean           1211.812
Q Predictions Std            398.89673
Q Predictions Max            1819.6683
Q Predictions Min            351.7279
V Predictions Mean           1223.8666
V Predictions Std            398.47968
V Predictions Max            1840.5402
V Predictions Min            370.35968
Log Pis Mean                 0.31118238
Log Pis Std                  3.3414762
Log Pis Max                  11.354091
Log Pis Min                  -7.2862225
Policy mu Mean               -0.025794066
Policy mu Std                0.6656714
Policy mu Max                2.631468
Policy mu Min                -2.7998095
Policy log std Mean          -1.0069661
Policy log std Std           0.3284527
Policy log std Max           -0.24941039
Policy log std Min           -2.487647
Z mean eval                  0.7189653
Z variance eval              0.0096107265
total_rewards                [4641.28727314 4735.70554857 1279.32650773 4952.50079113 4757.98096222
 4782.35700276 4808.85970463 4763.9151435   788.04195684 4797.61733091]
total_rewards_mean           4030.7592221447267
total_rewards_std            1504.3164094288675
total_rewards_max            4952.50079113356
total_rewards_min            788.0419568415092
Number of train steps total  1388000
Number of env steps total    2193364
Number of rollouts total     0
Train Time (s)               148.66670306911692
(Previous) Eval Time (s)     20.487687902059406
Sample Time (s)              7.534273363184184
Epoch Time (s)               176.6886643343605
Total Train Time (s)         58481.16358675202
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:35:18.450503 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #346 | Epoch Duration: 176.7808701992035
2020-01-12 00:35:18.450656 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7121069
Z variance train             0.009623617
KL Divergence                20.151142
KL Loss                      2.0151143
QF Loss                      1933.2607
VF Loss                      204.86838
Policy Loss                  -1188.9576
Q Predictions Mean           1184.4056
Q Predictions Std            366.7068
Q Predictions Max            1737.1343
Q Predictions Min            357.00055
V Predictions Mean           1195.5942
V Predictions Std            367.17795
V Predictions Max            1739.7577
V Predictions Min            361.75443
Log Pis Mean                 0.4805575
Log Pis Std                  3.0485437
Log Pis Max                  11.724588
Log Pis Min                  -6.554317
Policy mu Mean               0.007321927
Policy mu Std                0.6546408
Policy mu Max                2.071593
Policy mu Min                -2.2961068
Policy log std Mean          -1.0110993
Policy log std Std           0.28994384
Policy log std Max           -0.2958355
Policy log std Min           -2.472105
Z mean eval                  0.7961201
Z variance eval              0.008659029
total_rewards                [4372.2501412  3086.7713451  1932.34203869 4478.24886217 3964.09306714
  983.13740781  183.1856367  4862.91413621 4829.02701225 2248.78470586]
total_rewards_mean           3094.0754353134607
total_rewards_std            1594.9601150386538
total_rewards_max            4862.91413620645
total_rewards_min            183.18563670298795
Number of train steps total  1392000
Number of env steps total    2205364
Number of rollouts total     0
Train Time (s)               146.64613626059145
(Previous) Eval Time (s)     16.028877512086183
Sample Time (s)              7.13362842798233
Epoch Time (s)               169.80864220065996
Total Train Time (s)         58651.06167791411
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:38:08.352539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #347 | Epoch Duration: 169.90176010131836
2020-01-12 00:38:08.352734 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7964935
Z variance train             0.008678497
KL Divergence                21.104599
KL Loss                      2.11046
QF Loss                      561.8111
VF Loss                      148.69293
Policy Loss                  -1193.8558
Q Predictions Mean           1184.158
Q Predictions Std            404.14114
Q Predictions Max            1800.7644
Q Predictions Min            -85.8404
V Predictions Mean           1194.804
V Predictions Std            396.67166
V Predictions Max            1799.6917
V Predictions Min            366.78723
Log Pis Mean                 0.43943754
Log Pis Std                  3.1982646
Log Pis Max                  10.919508
Log Pis Min                  -7.3434954
Policy mu Mean               0.068600126
Policy mu Std                0.6294259
Policy mu Max                2.600304
Policy mu Min                -2.7282374
Policy log std Mean          -1.0293331
Policy log std Std           0.31100893
Policy log std Max           -0.2532581
Policy log std Min           -2.372453
Z mean eval                  0.868752
Z variance eval              0.0043228865
total_rewards                [3518.51476455 4447.93022566 4564.16953    1034.2696875  4546.74136819
 1087.91976223  224.44738737 1707.01912501 4138.92537714  890.39358786]
total_rewards_mean           2616.033081549613
total_rewards_std            1684.4381053646032
total_rewards_max            4564.169529998683
total_rewards_min            224.44738736528257
Number of train steps total  1396000
Number of env steps total    2217447
Number of rollouts total     0
Train Time (s)               147.31049879593775
(Previous) Eval Time (s)     12.105296682100743
Sample Time (s)              7.471280115190893
Epoch Time (s)               166.88707559322938
Total Train Time (s)         58818.0374295013
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:40:55.333348 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #348 | Epoch Duration: 166.9804708957672
2020-01-12 00:40:55.333529 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8624355
Z variance train             0.0043186815
KL Divergence                22.08338
KL Loss                      2.208338
QF Loss                      434.78036
VF Loss                      102.517235
Policy Loss                  -1197.413
Q Predictions Mean           1194.7711
Q Predictions Std            402.96674
Q Predictions Max            1810.693
Q Predictions Min            345.16046
V Predictions Mean           1196.7153
V Predictions Std            402.16656
V Predictions Max            1801.3431
V Predictions Min            346.20435
Log Pis Mean                 0.051344126
Log Pis Std                  3.2243738
Log Pis Max                  12.044588
Log Pis Min                  -10.086383
Policy mu Mean               -0.007220291
Policy mu Std                0.62020874
Policy mu Max                2.0744908
Policy mu Min                -2.765799
Policy log std Mean          -0.99139947
Policy log std Std           0.28202432
Policy log std Max           -0.26075816
Policy log std Min           -2.4407074
Z mean eval                  0.81437606
Z variance eval              0.015987385
total_rewards                [4728.85240322 4845.26982652 2925.47619037 4616.03354489 4718.06781673
 5042.3642378  4966.89178222  -31.30274761 4557.05139097 4627.19016063]
total_rewards_mean           4099.589460573863
total_rewards_std            1489.0508705022016
total_rewards_max            5042.36423779506
total_rewards_min            -31.30274760683555
Number of train steps total  1400000
Number of env steps total    2229052
Number of rollouts total     0
Train Time (s)               147.15054362500086
(Previous) Eval Time (s)     20.550031268037856
Sample Time (s)              7.534005630761385
Epoch Time (s)               175.2345805238001
Total Train Time (s)         58993.36074822908
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:43:50.660560 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #349 | Epoch Duration: 175.32689499855042
2020-01-12 00:43:50.660743 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81151164
Z variance train             0.016316589
KL Divergence                18.681093
KL Loss                      1.8681093
QF Loss                      690.22754
VF Loss                      229.49907
Policy Loss                  -1204.9528
Q Predictions Mean           1199.1675
Q Predictions Std            377.5673
Q Predictions Max            1777.367
Q Predictions Min            262.6304
V Predictions Mean           1209.7583
V Predictions Std            376.2929
V Predictions Max            1786.8989
V Predictions Min            292.88516
Log Pis Mean                 0.6651711
Log Pis Std                  3.1540534
Log Pis Max                  13.108055
Log Pis Min                  -6.9948215
Policy mu Mean               0.036536068
Policy mu Std                0.65290093
Policy mu Max                2.9268847
Policy mu Min                -2.259869
Policy log std Mean          -1.0293585
Policy log std Std           0.32057568
Policy log std Max           -0.083207846
Policy log std Min           -3.0154605
Z mean eval                  0.84709835
Z variance eval              0.011538526
total_rewards                [4903.37626528 4236.7380827  3558.94266929 4708.14148318 4680.54281521
 4847.10300883  398.0006179  4665.10356342 2196.01640795  726.51580437]
total_rewards_mean           3492.0480718140534
total_rewards_std            1659.9854764790098
total_rewards_max            4903.376265276403
total_rewards_min            398.0006178960972
Number of train steps total  1404000
Number of env steps total    2238068
Number of rollouts total     0
Train Time (s)               145.61300478409976
(Previous) Eval Time (s)     15.997023827861995
Sample Time (s)              7.576132407411933
Epoch Time (s)               169.18616101937369
Total Train Time (s)         59162.643802545965
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:46:39.948301 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #350 | Epoch Duration: 169.28741979599
2020-01-12 00:46:39.948488 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84804994
Z variance train             0.011586519
KL Divergence                19.845524
KL Loss                      1.9845524
QF Loss                      1427.1172
VF Loss                      85.515045
Policy Loss                  -1265.4885
Q Predictions Mean           1256.7897
Q Predictions Std            396.22824
Q Predictions Max            1831.0911
Q Predictions Min            70.225746
V Predictions Mean           1265.1879
V Predictions Std            390.8123
V Predictions Max            1822.6115
V Predictions Min            370.54147
Log Pis Mean                 0.49639344
Log Pis Std                  3.1375537
Log Pis Max                  13.169416
Log Pis Min                  -9.400563
Policy mu Mean               0.029333469
Policy mu Std                0.65214574
Policy mu Max                2.1068017
Policy mu Min                -2.9683683
Policy log std Mean          -1.0418382
Policy log std Std           0.3029545
Policy log std Max           -0.28248358
Policy log std Min           -2.3246841
Z mean eval                  0.72915363
Z variance eval              0.016176125
total_rewards                [ 880.61153653  668.83625397 2447.98273775  378.17053714 1912.89218757
 1512.27705839  397.9510443  2081.71393118  637.11920262   94.53328165]
total_rewards_mean           1101.2087771102854
total_rewards_std            780.0472493238664
total_rewards_max            2447.982737752602
total_rewards_min            94.53328164825862
Number of train steps total  1408000
Number of env steps total    2248329
Number of rollouts total     0
Train Time (s)               148.50059083569795
(Previous) Eval Time (s)     8.088789233006537
Sample Time (s)              8.259154424536973
Epoch Time (s)               164.84853449324146
Total Train Time (s)         59327.58715402987
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:49:24.894858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #351 | Epoch Duration: 164.9461648464203
2020-01-12 00:49:24.895209 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #351 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72741413
Z variance train             0.016185503
KL Divergence                20.975178
KL Loss                      2.0975177
QF Loss                      12783.348
VF Loss                      265.26224
Policy Loss                  -1214.0287
Q Predictions Mean           1207.5698
Q Predictions Std            403.08374
Q Predictions Max            1819.5194
Q Predictions Min            170.26314
V Predictions Mean           1217.6853
V Predictions Std            398.85703
V Predictions Max            1813.5264
V Predictions Min            333.30188
Log Pis Mean                 0.56937927
Log Pis Std                  3.0086777
Log Pis Max                  10.473054
Log Pis Min                  -7.904763
Policy mu Mean               -0.004578448
Policy mu Std                0.6713352
Policy mu Max                3.2698448
Policy mu Min                -2.4029582
Policy log std Mean          -0.99915516
Policy log std Std           0.28222597
Policy log std Max           -0.18379259
Policy log std Min           -2.2346587
Z mean eval                  0.7104204
Z variance eval              0.009724943
total_rewards                [ 952.98561475 4640.12912874 4683.69090314 2045.06199721 4781.9655727
 2466.73938985 4394.89273141  560.74371953 3391.18015914 1340.49922118]
total_rewards_mean           2925.7888437640363
total_rewards_std            1575.8924458260246
total_rewards_max            4781.96557270133
total_rewards_min            560.7437195296076
Number of train steps total  1412000
Number of env steps total    2260217
Number of rollouts total     0
Train Time (s)               144.75988972187042
(Previous) Eval Time (s)     15.083329332061112
Sample Time (s)              7.662995295599103
Epoch Time (s)               167.50621434953064
Total Train Time (s)         59495.47169443406
Epoch                        352
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:52:12.782725 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #352 | Epoch Duration: 167.88730430603027
2020-01-12 00:52:12.782917 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7155746
Z variance train             0.0097011095
KL Divergence                19.913094
KL Loss                      1.9913094
QF Loss                      2623.8628
VF Loss                      91.43964
Policy Loss                  -1260.1654
Q Predictions Mean           1251.0718
Q Predictions Std            399.88263
Q Predictions Max            1842.284
Q Predictions Min            108.82054
V Predictions Mean           1256.1254
V Predictions Std            397.28937
V Predictions Max            1809.869
V Predictions Min            209.15915
Log Pis Mean                 0.8976985
Log Pis Std                  3.4542985
Log Pis Max                  13.899317
Log Pis Min                  -8.24123
Policy mu Mean               0.023877852
Policy mu Std                0.6557392
Policy mu Max                2.7437944
Policy mu Min                -4.3778224
Policy log std Mean          -1.0662171
Policy log std Std           0.32776922
Policy log std Max           -0.18527901
Policy log std Min           -2.4231353
Z mean eval                  0.8380555
Z variance eval              0.0075451345
total_rewards                [4977.04799529  540.74871218 2618.79352994 5056.08969687 4800.41918606
 3944.53883669 4894.69087609 1368.55687083  663.10867481 4527.64120527]
total_rewards_mean           3339.163558403468
total_rewards_std            1770.8475787079935
total_rewards_max            5056.089696869296
total_rewards_min            540.7487121835685
Number of train steps total  1416000
Number of env steps total    2271492
Number of rollouts total     0
Train Time (s)               147.8868845421821
(Previous) Eval Time (s)     18.28835282707587
Sample Time (s)              7.601177999284118
Epoch Time (s)               173.77641536854208
Total Train Time (s)         59669.41332519753
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:55:06.730719 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #353 | Epoch Duration: 173.94760751724243
2020-01-12 00:55:06.730986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8353798
Z variance train             0.007539963
KL Divergence                19.85494
KL Loss                      1.985494
QF Loss                      419.6316
VF Loss                      99.72792
Policy Loss                  -1174.8425
Q Predictions Mean           1170.8562
Q Predictions Std            416.39566
Q Predictions Max            1795.3467
Q Predictions Min            320.17804
V Predictions Mean           1179.5474
V Predictions Std            416.7333
V Predictions Max            1785.7561
V Predictions Min            314.98663
Log Pis Mean                 0.33344492
Log Pis Std                  2.8200796
Log Pis Max                  10.096947
Log Pis Min                  -7.334688
Policy mu Mean               0.02696227
Policy mu Std                0.60690475
Policy mu Max                2.3485126
Policy mu Min                -2.242031
Policy log std Mean          -1.0192578
Policy log std Std           0.27908292
Policy log std Max           -0.35403562
Policy log std Min           -2.130613
Z mean eval                  1.0628748
Z variance eval              0.026267573
total_rewards                [3161.77611085 1201.60529    1796.36920688 4701.8361606    29.90542162
 4749.66156038  418.17823332 2995.18069618 4760.49773279 4628.36271683]
total_rewards_mean           2844.3373129445536
total_rewards_std            1779.3982514032775
total_rewards_max            4760.497732788144
total_rewards_min            29.905421617520556
Number of train steps total  1420000
Number of env steps total    2282376
Number of rollouts total     0
Train Time (s)               147.34125082427636
(Previous) Eval Time (s)     14.491617104969919
Sample Time (s)              6.637808640487492
Epoch Time (s)               168.47067656973377
Total Train Time (s)         59837.99421269167
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:57:55.313780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #354 | Epoch Duration: 168.58264756202698
2020-01-12 00:57:55.313967 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0601591
Z variance train             0.026688779
KL Divergence                21.086824
KL Loss                      2.1086824
QF Loss                      444.78336
VF Loss                      103.27963
Policy Loss                  -1260.2672
Q Predictions Mean           1255.485
Q Predictions Std            413.1634
Q Predictions Max            1852.4792
Q Predictions Min            344.0437
V Predictions Mean           1265.475
V Predictions Std            409.66083
V Predictions Max            1851.6788
V Predictions Min            370.33997
Log Pis Mean                 0.44180232
Log Pis Std                  3.1002672
Log Pis Max                  11.782956
Log Pis Min                  -6.31938
Policy mu Mean               0.011864728
Policy mu Std                0.6329826
Policy mu Max                2.2430658
Policy mu Min                -2.5524306
Policy log std Mean          -1.0265965
Policy log std Std           0.290979
Policy log std Max           -0.31844968
Policy log std Min           -2.435605
Z mean eval                  0.8176945
Z variance eval              0.010254879
total_rewards                [4769.90896421 2159.41724334 2243.27011756  514.41780108 4927.55994194
 4550.83630228 3435.36884393 4779.53853071  430.79444977 4658.50761373]
total_rewards_mean           3246.9619808538905
total_rewards_std            1697.3026406024148
total_rewards_max            4927.559941942083
total_rewards_min            430.7944497724775
Number of train steps total  1424000
Number of env steps total    2292575
Number of rollouts total     0
Train Time (s)               146.57912730798125
(Previous) Eval Time (s)     16.749800668098032
Sample Time (s)              7.011990837752819
Epoch Time (s)               170.3409188138321
Total Train Time (s)         60008.42266753223
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:00:45.745702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #355 | Epoch Duration: 170.4315960407257
2020-01-12 01:00:45.745856 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #355 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8173169
Z variance train             0.01026914
KL Divergence                20.7769
KL Loss                      2.07769
QF Loss                      726.81384
VF Loss                      79.56623
Policy Loss                  -1280.4231
Q Predictions Mean           1274.2985
Q Predictions Std            391.8367
Q Predictions Max            1874.639
Q Predictions Min            353.134
V Predictions Mean           1279.3823
V Predictions Std            391.23984
V Predictions Max            1887.7836
V Predictions Min            354.22366
Log Pis Mean                 0.4676776
Log Pis Std                  3.0215554
Log Pis Max                  15.077216
Log Pis Min                  -6.151383
Policy mu Mean               -0.012491744
Policy mu Std                0.6546099
Policy mu Max                3.4298859
Policy mu Min                -2.9539366
Policy log std Mean          -1.0201483
Policy log std Std           0.30234545
Policy log std Max           -0.2370807
Policy log std Min           -2.5772648
Z mean eval                  0.81978875
Z variance eval              0.025946358
total_rewards                [5129.4901497  1567.99987607 4994.23299415 4901.25098315 4979.7432718
 5091.13166911 5039.05565898 4805.40349245 1951.17584176 4740.06620274]
total_rewards_mean           4319.955013991937
total_rewards_std            1288.08261126749
total_rewards_max            5129.490149698948
total_rewards_min            1567.9998760698397
Number of train steps total  1428000
Number of env steps total    2302996
Number of rollouts total     0
Train Time (s)               146.75400393409654
(Previous) Eval Time (s)     21.35971216019243
Sample Time (s)              7.810678380075842
Epoch Time (s)               175.92439447436482
Total Train Time (s)         60184.44745798828
Epoch                        356
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:03:41.773198 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #356 | Epoch Duration: 176.02722811698914
2020-01-12 01:03:41.773345 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8119354
Z variance train             0.026208043
KL Divergence                18.995491
KL Loss                      1.8995491
QF Loss                      1442.3534
VF Loss                      2059.4893
Policy Loss                  -1228.6837
Q Predictions Mean           1223.3344
Q Predictions Std            382.12988
Q Predictions Max            1852.8292
Q Predictions Min            339.94928
V Predictions Mean           1235.9939
V Predictions Std            380.88364
V Predictions Max            1864.118
V Predictions Min            354.4592
Log Pis Mean                 0.44947296
Log Pis Std                  3.245839
Log Pis Max                  10.986495
Log Pis Min                  -7.017172
Policy mu Mean               0.006341461
Policy mu Std                0.67443204
Policy mu Max                2.9840438
Policy mu Min                -2.5111606
Policy log std Mean          -1.0190961
Policy log std Std           0.29541114
Policy log std Max           -0.29431462
Policy log std Min           -2.3048816
Z mean eval                  0.94102114
Z variance eval              0.015682044
total_rewards                [4336.63049572 4188.55565859 2046.71412061 3959.07998707 4471.94566251
   29.81025916 4548.56766745 1072.89935685 2995.36034442 4159.43487124]
total_rewards_mean           3180.8998423619296
total_rewards_std            1521.358836106271
total_rewards_max            4548.567667446387
total_rewards_min            29.810259159296454
Number of train steps total  1432000
Number of env steps total    2311192
Number of rollouts total     0
Train Time (s)               146.55415153875947
(Previous) Eval Time (s)     19.938137784134597
Sample Time (s)              7.0150096118450165
Epoch Time (s)               173.50729893473908
Total Train Time (s)         60358.04343648534
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:06:35.371983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #357 | Epoch Duration: 173.5985312461853
2020-01-12 01:06:35.372126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9368477
Z variance train             0.015717108
KL Divergence                21.092924
KL Loss                      2.1092925
QF Loss                      702.8002
VF Loss                      93.465355
Policy Loss                  -1252.4467
Q Predictions Mean           1246.0167
Q Predictions Std            414.50684
Q Predictions Max            1840.7517
Q Predictions Min            347.67874
V Predictions Mean           1253.5522
V Predictions Std            414.60535
V Predictions Max            1840.7855
V Predictions Min            362.30673
Log Pis Mean                 0.6432882
Log Pis Std                  3.2054937
Log Pis Max                  11.848946
Log Pis Min                  -6.895895
Policy mu Mean               -0.036071494
Policy mu Std                0.6647908
Policy mu Max                2.5512981
Policy mu Min                -2.8661914
Policy log std Mean          -1.0224402
Policy log std Std           0.31878945
Policy log std Max           -0.157009
Policy log std Min           -2.3953643
Z mean eval                  0.82123244
Z variance eval              0.009617038
total_rewards                [4846.29400207 4607.98363374  511.15357595 4830.63086595 4877.35243846
 4749.42658559 5131.90751393 2044.10582387 4802.20245152 4767.0101721 ]
total_rewards_mean           4116.806706316272
total_rewards_std            1465.652554686146
total_rewards_max            5131.907513927825
total_rewards_min            511.15357595186435
Number of train steps total  1436000
Number of env steps total    2322428
Number of rollouts total     0
Train Time (s)               147.87216954864562
(Previous) Eval Time (s)     17.64730933587998
Sample Time (s)              7.957919913344085
Epoch Time (s)               173.47739879786968
Total Train Time (s)         60531.61665474996
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:09:28.950936 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #358 | Epoch Duration: 173.57869720458984
2020-01-12 01:09:28.951110 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82054394
Z variance train             0.009612043
KL Divergence                19.97781
KL Loss                      1.997781
QF Loss                      490.8568
VF Loss                      88.5172
Policy Loss                  -1248.7632
Q Predictions Mean           1240.1793
Q Predictions Std            353.81512
Q Predictions Max            1815.9141
Q Predictions Min            334.72223
V Predictions Mean           1250.1921
V Predictions Std            354.41052
V Predictions Max            1805.9225
V Predictions Min            342.39957
Log Pis Mean                 0.91833407
Log Pis Std                  3.3590505
Log Pis Max                  12.250242
Log Pis Min                  -6.5835996
Policy mu Mean               0.061195917
Policy mu Std                0.69842774
Policy mu Max                2.6128833
Policy mu Min                -2.520661
Policy log std Mean          -1.0041671
Policy log std Std           0.30609426
Policy log std Max           -0.29528773
Policy log std Min           -2.2961302
Z mean eval                  0.8682722
Z variance eval              0.03305182
total_rewards                [4842.0219325  1047.99707157 3471.09253497 4520.088445   4818.49473338
 4743.81864551 4699.0882074  4762.74553517 1531.84007391 5121.12618961]
total_rewards_mean           3955.8313369014772
total_rewards_std            1399.8746674760623
total_rewards_max            5121.1261896147535
total_rewards_min            1047.9970715652732
Number of train steps total  1440000
Number of env steps total    2332842
Number of rollouts total     0
Train Time (s)               148.0082333148457
(Previous) Eval Time (s)     20.310661736875772
Sample Time (s)              7.199247779324651
Epoch Time (s)               175.51814283104613
Total Train Time (s)         60707.234896736685
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:12:24.575420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #359 | Epoch Duration: 175.62417483329773
2020-01-12 01:12:24.575568 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86727065
Z variance train             0.03308148
KL Divergence                17.672613
KL Loss                      1.7672614
QF Loss                      663.0005
VF Loss                      100.6379
Policy Loss                  -1242.2074
Q Predictions Mean           1233.9143
Q Predictions Std            389.36917
Q Predictions Max            1825.2069
Q Predictions Min            334.01913
V Predictions Mean           1239.5437
V Predictions Std            387.08038
V Predictions Max            1813.3877
V Predictions Min            343.2258
Log Pis Mean                 0.60622317
Log Pis Std                  3.2718656
Log Pis Max                  13.150175
Log Pis Min                  -8.1399555
Policy mu Mean               -0.004418103
Policy mu Std                0.6456485
Policy mu Max                2.5652912
Policy mu Min                -2.6671445
Policy log std Mean          -1.0384904
Policy log std Std           0.29975432
Policy log std Max           -0.2991352
Policy log std Min           -2.4019706
Z mean eval                  1.05607
Z variance eval              0.018468266
total_rewards                [4630.65692352 4700.67651051 4725.54101278  119.44404205 1458.13497834
 4764.77281213 2917.17966516 4572.39578999 4817.3660624  1789.55176094]
total_rewards_mean           3449.5719557816165
total_rewards_std            1659.649073477119
total_rewards_max            4817.366062403568
total_rewards_min            119.44404205035394
Number of train steps total  1444000
Number of env steps total    2342877
Number of rollouts total     0
Train Time (s)               147.51963291224092
(Previous) Eval Time (s)     18.084133984986693
Sample Time (s)              7.106908892747015
Epoch Time (s)               172.71067578997463
Total Train Time (s)         60880.03143783659
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:15:17.375823 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #360 | Epoch Duration: 172.80013799667358
2020-01-12 01:15:17.376017 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0525295
Z variance train             0.018513272
KL Divergence                18.736595
KL Loss                      1.8736595
QF Loss                      605.3694
VF Loss                      167.54184
Policy Loss                  -1201.5698
Q Predictions Mean           1195.834
Q Predictions Std            416.35135
Q Predictions Max            1794.4305
Q Predictions Min            295.5183
V Predictions Mean           1208.5995
V Predictions Std            415.79446
V Predictions Max            1808.0701
V Predictions Min            309.4735
Log Pis Mean                 0.5087544
Log Pis Std                  3.0233643
Log Pis Max                  9.781357
Log Pis Min                  -8.322241
Policy mu Mean               0.013991604
Policy mu Std                0.645799
Policy mu Max                1.8936138
Policy mu Min                -2.5430589
Policy log std Mean          -1.0061129
Policy log std Std           0.30590484
Policy log std Max           -0.27350318
Policy log std Min           -2.1364057
Z mean eval                  0.8741587
Z variance eval              0.0117382
total_rewards                [3848.47908782  935.92387032   28.48793941 1582.44630335 1335.18518164
 4674.28423963 1367.2368116  1329.85775055 4843.08130102 4645.2109579 ]
total_rewards_mean           2459.0193443240723
total_rewards_std            1732.826112973665
total_rewards_max            4843.081301023471
total_rewards_min            28.48793940837515
Number of train steps total  1448000
Number of env steps total    2352849
Number of rollouts total     0
Train Time (s)               147.63158975867555
(Previous) Eval Time (s)     14.46956318616867
Sample Time (s)              6.8624456617981195
Epoch Time (s)               168.96359860664234
Total Train Time (s)         61049.107815413736
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:18:06.455374 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #361 | Epoch Duration: 169.07920670509338
2020-01-12 01:18:06.455603 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8734924
Z variance train             0.011820272
KL Divergence                20.823248
KL Loss                      2.0823247
QF Loss                      454.4291
VF Loss                      165.0368
Policy Loss                  -1247.9054
Q Predictions Mean           1238.4274
Q Predictions Std            406.7087
Q Predictions Max            1842.3197
Q Predictions Min            -120.030235
V Predictions Mean           1240.3485
V Predictions Std            407.7818
V Predictions Max            1848.8081
V Predictions Min            -21.138584
Log Pis Mean                 0.2792078
Log Pis Std                  3.6045198
Log Pis Max                  27.879375
Log Pis Min                  -7.730074
Policy mu Mean               0.01623575
Policy mu Std                0.66103524
Policy mu Max                2.750353
Policy mu Min                -4.6996245
Policy log std Mean          -1.0015057
Policy log std Std           0.29918775
Policy log std Max           -0.06940687
Policy log std Min           -2.7336516
Z mean eval                  0.7493123
Z variance eval              0.009734927
total_rewards                [1998.12686049 1439.91773867  570.58723112 1937.72464973 4997.87261734
  290.89459339 4685.78431244 4910.05444826 4039.88223738 1279.56869554]
total_rewards_mean           2615.0413384339954
total_rewards_std            1756.3687780097923
total_rewards_max            4997.872617339474
total_rewards_min            290.8945933863141
Number of train steps total  1452000
Number of env steps total    2362032
Number of rollouts total     0
Train Time (s)               146.17989639705047
(Previous) Eval Time (s)     13.412928679957986
Sample Time (s)              7.439627469982952
Epoch Time (s)               167.0324525469914
Total Train Time (s)         61216.23382338602
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:20:53.585626 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #362 | Epoch Duration: 167.1298544406891
2020-01-12 01:20:53.585808 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7515138
Z variance train             0.009756066
KL Divergence                21.225883
KL Loss                      2.1225884
QF Loss                      677.59454
VF Loss                      106.80152
Policy Loss                  -1246.539
Q Predictions Mean           1239.8732
Q Predictions Std            403.3569
Q Predictions Max            1843.4325
Q Predictions Min            319.52707
V Predictions Mean           1248.6555
V Predictions Std            400.8034
V Predictions Max            1852.3508
V Predictions Min            324.22293
Log Pis Mean                 0.5726246
Log Pis Std                  3.4054117
Log Pis Max                  21.560738
Log Pis Min                  -8.517424
Policy mu Mean               0.01085331
Policy mu Std                0.64329785
Policy mu Max                2.7616076
Policy mu Min                -3.0708277
Policy log std Mean          -1.0349512
Policy log std Std           0.2856676
Policy log std Max           0.0781399
Policy log std Min           -2.3200545
Z mean eval                  1.0754273
Z variance eval              0.0052718455
total_rewards                [  32.93742335 1325.43432257  626.54985195 4728.2621889   441.19755684
 4045.83079215 3049.59306797 4757.80883077 4548.96921547 3503.25605241]
total_rewards_mean           2705.9839302371097
total_rewards_std            1809.681946626812
total_rewards_max            4757.80883076654
total_rewards_min            32.93742334955412
Number of train steps total  1456000
Number of env steps total    2371033
Number of rollouts total     0
Train Time (s)               145.66188507713377
(Previous) Eval Time (s)     17.609649267047644
Sample Time (s)              6.390405961312354
Epoch Time (s)               169.66194030549377
Total Train Time (s)         61385.98437411059
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:23:43.338079 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #363 | Epoch Duration: 169.75214385986328
2020-01-12 01:23:43.338222 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0741556
Z variance train             0.0052922545
KL Divergence                23.028053
KL Loss                      2.3028054
QF Loss                      2292.3584
VF Loss                      113.814674
Policy Loss                  -1314.259
Q Predictions Mean           1307.6711
Q Predictions Std            379.19626
Q Predictions Max            1917.5327
Q Predictions Min            348.90668
V Predictions Mean           1313.6844
V Predictions Std            378.00336
V Predictions Max            1899.6096
V Predictions Min            350.85406
Log Pis Mean                 0.5273882
Log Pis Std                  3.1144488
Log Pis Max                  10.706358
Log Pis Min                  -7.7299976
Policy mu Mean               -0.018264253
Policy mu Std                0.67595315
Policy mu Max                3.64414
Policy mu Min                -2.7970555
Policy log std Mean          -0.98738223
Policy log std Std           0.27433684
Policy log std Max           -0.35303771
Policy log std Min           -2.2288275
Z mean eval                  0.98156035
Z variance eval              0.0032866027
total_rewards                [ 840.01735531  842.29597318 4603.53070948  343.86870394  158.81551665
 2463.76044462 4471.95774951 4674.63515897 1996.89712909 4328.13641536]
total_rewards_mean           2472.391515610143
total_rewards_std            1796.244836637729
total_rewards_max            4674.635158970684
total_rewards_min            158.81551664863852
Number of train steps total  1460000
Number of env steps total    2381587
Number of rollouts total     0
Train Time (s)               145.88371850317344
(Previous) Eval Time (s)     21.077565680257976
Sample Time (s)              7.188151601701975
Epoch Time (s)               174.1494357851334
Total Train Time (s)         61560.23367656488
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:26:37.589358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #364 | Epoch Duration: 174.25103163719177
2020-01-12 01:26:37.589501 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9832331
Z variance train             0.0032863363
KL Divergence                20.494698
KL Loss                      2.0494697
QF Loss                      712.4331
VF Loss                      118.82176
Policy Loss                  -1174.8744
Q Predictions Mean           1167.8649
Q Predictions Std            360.4236
Q Predictions Max            1739.9755
Q Predictions Min            323.52377
V Predictions Mean           1169.6913
V Predictions Std            363.04385
V Predictions Max            1744.5472
V Predictions Min            317.20993
Log Pis Mean                 0.3414628
Log Pis Std                  3.0071352
Log Pis Max                  10.197086
Log Pis Min                  -6.4008894
Policy mu Mean               0.023761082
Policy mu Std                0.5926702
Policy mu Max                2.3355248
Policy mu Min                -2.3401697
Policy log std Mean          -1.0629143
Policy log std Std           0.31048298
Policy log std Max           -0.26022375
Policy log std Min           -2.5414987
Z mean eval                  0.7885691
Z variance eval              0.003914159
total_rewards                [2029.82800105 4597.88976964 4633.18009416 4821.93915998 3405.81917742
 4295.54044138 4392.50058352 4860.79917274 4830.45115851 4325.51548153]
total_rewards_mean           4219.3463039921435
total_rewards_std            834.5932702437399
total_rewards_max            4860.799172738715
total_rewards_min            2029.8280010451138
Number of train steps total  1464000
Number of env steps total    2392340
Number of rollouts total     0
Train Time (s)               144.55025326972827
(Previous) Eval Time (s)     20.015367562882602
Sample Time (s)              7.227496782783419
Epoch Time (s)               171.7931176153943
Total Train Time (s)         61732.11100794235
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:29:29.469507 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #365 | Epoch Duration: 171.87990045547485
2020-01-12 01:29:29.469649 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7915006
Z variance train             0.0039008749
KL Divergence                22.215391
KL Loss                      2.2215393
QF Loss                      668.9231
VF Loss                      170.71503
Policy Loss                  -1288.7445
Q Predictions Mean           1281.511
Q Predictions Std            391.8876
Q Predictions Max            1874.6964
Q Predictions Min            311.66824
V Predictions Mean           1293.5408
V Predictions Std            390.0541
V Predictions Max            1867.4893
V Predictions Min            320.51486
Log Pis Mean                 0.66438276
Log Pis Std                  3.033164
Log Pis Max                  11.422869
Log Pis Min                  -7.252203
Policy mu Mean               0.0013969154
Policy mu Std                0.670887
Policy mu Max                2.3131022
Policy mu Min                -2.611953
Policy log std Mean          -1.0279169
Policy log std Std           0.30817863
Policy log std Max           -0.31258094
Policy log std Min           -2.8175302
Z mean eval                  0.6999781
Z variance eval              0.013297481
total_rewards                [  92.22615871 2437.44498939 1012.77570304 3123.51530475 4980.45933071
 4707.46415936 4951.12113711 4855.01932579 4380.17850081 4770.36323712]
total_rewards_mean           3531.0567846782787
total_rewards_std            1704.1250627737418
total_rewards_max            4980.4593307064015
total_rewards_min            92.22615870949122
Number of train steps total  1468000
Number of env steps total    2402211
Number of rollouts total     0
Train Time (s)               144.0057005425915
(Previous) Eval Time (s)     17.205030767712742
Sample Time (s)              6.3359408136457205
Epoch Time (s)               167.54667212394997
Total Train Time (s)         61899.74870817503
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:32:17.110497 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #366 | Epoch Duration: 167.64073514938354
2020-01-12 01:32:17.110687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.69611394
Z variance train             0.012948659
KL Divergence                19.711884
KL Loss                      1.9711884
QF Loss                      567.9243
VF Loss                      101.960266
Policy Loss                  -1234.4869
Q Predictions Mean           1229.0085
Q Predictions Std            388.95425
Q Predictions Max            1838.2123
Q Predictions Min            332.53137
V Predictions Mean           1237.8162
V Predictions Std            389.98627
V Predictions Max            1848.77
V Predictions Min            329.35626
Log Pis Mean                 0.74822843
Log Pis Std                  2.8503084
Log Pis Max                  8.94998
Log Pis Min                  -7.459894
Policy mu Mean               0.009103371
Policy mu Std                0.68702215
Policy mu Max                2.145847
Policy mu Min                -2.3780217
Policy log std Mean          -1.0190077
Policy log std Std           0.28675213
Policy log std Max           -0.1600318
Policy log std Min           -2.4031053
Z mean eval                  1.0333391
Z variance eval              0.017658437
total_rewards                [ 127.61104818 4954.62485724 4779.5829316  2351.2108417  4945.59488135
 1052.87178211 4745.07107743 3386.51489168 1875.86321539 2248.52957553]
total_rewards_mean           3046.7475102203143
total_rewards_std            1680.3830510851537
total_rewards_max            4954.624857243355
total_rewards_min            127.61104817981332
Number of train steps total  1472000
Number of env steps total    2410813
Number of rollouts total     0
Train Time (s)               145.5438879681751
(Previous) Eval Time (s)     19.125644634943455
Sample Time (s)              6.4438608437776566
Epoch Time (s)               171.11339344689623
Total Train Time (s)         62070.956669100095
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:35:08.320976 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #367 | Epoch Duration: 171.21016025543213
2020-01-12 01:35:08.321126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0314426
Z variance train             0.017715184
KL Divergence                21.091793
KL Loss                      2.1091793
QF Loss                      394.97034
VF Loss                      91.21582
Policy Loss                  -1264.209
Q Predictions Mean           1258.6729
Q Predictions Std            403.60706
Q Predictions Max            1859.3179
Q Predictions Min            332.79993
V Predictions Mean           1265.7351
V Predictions Std            405.46094
V Predictions Max            1867.7101
V Predictions Min            335.4713
Log Pis Mean                 0.44833267
Log Pis Std                  2.9052262
Log Pis Max                  9.696117
Log Pis Min                  -7.2374496
Policy mu Mean               0.012163539
Policy mu Std                0.63274056
Policy mu Max                2.6189892
Policy mu Min                -2.6908972
Policy log std Mean          -1.034296
Policy log std Std           0.30007368
Policy log std Max           -0.28384173
Policy log std Min           -2.156721
Z mean eval                  0.7612752
Z variance eval              0.019519988
total_rewards                [3655.85620906 1659.33193195 4958.25568276  982.80128419 2572.12831506
 3914.32502375 1306.60235757 1857.7450288  4948.99072221 4932.75973243]
total_rewards_mean           3078.87962877811
total_rewards_std            1509.7915649647482
total_rewards_max            4958.255682755098
total_rewards_min            982.801284194986
Number of train steps total  1476000
Number of env steps total    2423032
Number of rollouts total     0
Train Time (s)               144.66416506515816
(Previous) Eval Time (s)     17.426686168648303
Sample Time (s)              7.820175892673433
Epoch Time (s)               169.9110271264799
Total Train Time (s)         62240.95906572975
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:37:58.325948 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #368 | Epoch Duration: 170.0047197341919
2020-01-12 01:37:58.326089 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75923175
Z variance train             0.019401522
KL Divergence                20.597078
KL Loss                      2.0597079
QF Loss                      476.7411
VF Loss                      90.8852
Policy Loss                  -1302.8676
Q Predictions Mean           1294.9336
Q Predictions Std            342.74448
Q Predictions Max            1889.8755
Q Predictions Min            326.66907
V Predictions Mean           1303.2881
V Predictions Std            341.29556
V Predictions Max            1880.2202
V Predictions Min            328.2769
Log Pis Mean                 0.7477976
Log Pis Std                  2.8467207
Log Pis Max                  9.561072
Log Pis Min                  -5.958342
Policy mu Mean               0.038304016
Policy mu Std                0.6611287
Policy mu Max                2.15474
Policy mu Min                -2.4804428
Policy log std Mean          -1.0365831
Policy log std Std           0.2846414
Policy log std Max           -0.2886994
Policy log std Min           -2.572917
Z mean eval                  0.74418324
Z variance eval              0.0118476255
total_rewards                [4938.95627022  363.40777067 5094.18158796 5168.87417539  125.96239217
 4915.40571874 4812.48881199 4740.12089759 5107.98354684 4630.11732466]
total_rewards_mean           3989.749849623274
total_rewards_std            1880.0962438562688
total_rewards_max            5168.874175393914
total_rewards_min            125.96239217266228
Number of train steps total  1480000
Number of env steps total    2434854
Number of rollouts total     0
Train Time (s)               144.55714851943776
(Previous) Eval Time (s)     19.604538405314088
Sample Time (s)              6.661934916395694
Epoch Time (s)               170.82362184114754
Total Train Time (s)         62411.87435544282
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:40:49.245101 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #369 | Epoch Duration: 170.91889834403992
2020-01-12 01:40:49.245287 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7473689
Z variance train             0.011854308
KL Divergence                18.706589
KL Loss                      1.8706589
QF Loss                      610.04724
VF Loss                      97.406204
Policy Loss                  -1288.3306
Q Predictions Mean           1278.6772
Q Predictions Std            326.31903
Q Predictions Max            1837.4556
Q Predictions Min            338.99106
V Predictions Mean           1285.8291
V Predictions Std            322.74374
V Predictions Max            1830.1074
V Predictions Min            344.2451
Log Pis Mean                 1.0907784
Log Pis Std                  3.045084
Log Pis Max                  9.224752
Log Pis Min                  -8.36199
Policy mu Mean               0.026222294
Policy mu Std                0.69147176
Policy mu Max                2.5071156
Policy mu Min                -2.360757
Policy log std Mean          -1.0754362
Policy log std Std           0.2878993
Policy log std Max           -0.044682145
Policy log std Min           -2.760048
Z mean eval                  1.1021739
Z variance eval              0.0066022747
total_rewards                [4613.93969684 3238.52210524 4513.43306546 2828.91979784 4653.76397218
 4650.73461016 4770.55343037 4773.73905541 4812.05959617 4793.28205732]
total_rewards_mean           4364.894738698113
total_rewards_std            677.6692389472493
total_rewards_max            4812.059596169401
total_rewards_min            2828.919797842618
Number of train steps total  1484000
Number of env steps total    2445868
Number of rollouts total     0
Train Time (s)               145.77456622291356
(Previous) Eval Time (s)     23.650099745951593
Sample Time (s)              7.305976883973926
Epoch Time (s)               176.73064285283908
Total Train Time (s)         62588.694853557274
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:43:46.066950 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #370 | Epoch Duration: 176.82153820991516
2020-01-12 01:43:46.067097 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1091951
Z variance train             0.006639219
KL Divergence                21.371965
KL Loss                      2.1371965
QF Loss                      8477.633
VF Loss                      115.751396
Policy Loss                  -1363.4594
Q Predictions Mean           1353.013
Q Predictions Std            349.71948
Q Predictions Max            1915.8153
Q Predictions Min            14.209589
V Predictions Mean           1366.9324
V Predictions Std            341.41138
V Predictions Max            1917.4268
V Predictions Min            375.7009
Log Pis Mean                 1.087031
Log Pis Std                  2.7643209
Log Pis Max                  10.088692
Log Pis Min                  -7.773112
Policy mu Mean               0.015549336
Policy mu Std                0.6856392
Policy mu Max                2.456172
Policy mu Min                -2.6368887
Policy log std Mean          -1.0650191
Policy log std Std           0.28909874
Policy log std Max           -0.29367244
Policy log std Min           -2.599098
Z mean eval                  0.88134336
Z variance eval              0.004762362
total_rewards                [4698.96124501 5038.79456333 1830.03985771 2024.37144871 4987.45108267
 5271.96707985 4949.62321719 4979.83300349 4800.02910422  510.54192957]
total_rewards_mean           3909.16125317482
total_rewards_std            1654.3319024461637
total_rewards_max            5271.967079847705
total_rewards_min            510.54192957069074
Number of train steps total  1488000
Number of env steps total    2457617
Number of rollouts total     0
Train Time (s)               146.20432912698016
(Previous) Eval Time (s)     20.900712608825415
Sample Time (s)              7.592525147367269
Epoch Time (s)               174.69756688317284
Total Train Time (s)         62763.6003376157
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:46:40.974967 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #371 | Epoch Duration: 174.9077663421631
2020-01-12 01:46:40.975161 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8761438
Z variance train             0.0047534117
KL Divergence                21.504612
KL Loss                      2.1504612
QF Loss                      563.2135
VF Loss                      205.87997
Policy Loss                  -1364.7158
Q Predictions Mean           1358.029
Q Predictions Std            340.74283
Q Predictions Max            1883.0756
Q Predictions Min            373.56934
V Predictions Mean           1367.8787
V Predictions Std            341.38718
V Predictions Max            1879.3583
V Predictions Min            372.5618
Log Pis Mean                 0.935929
Log Pis Std                  3.2111669
Log Pis Max                  12.930843
Log Pis Min                  -8.627723
Policy mu Mean               -0.014367593
Policy mu Std                0.6783569
Policy mu Max                2.6589603
Policy mu Min                -3.3120763
Policy log std Mean          -1.0752691
Policy log std Std           0.30439484
Policy log std Max           -0.27791357
Policy log std Min           -2.7156491
Z mean eval                  0.7073299
Z variance eval              0.0073301555
total_rewards                [5127.86111761 4961.15943564 4962.97029793 3037.66119465 5000.8807027
 4868.76256719 5062.09972301 5038.11730742 4783.9054444  5170.38657823]
total_rewards_mean           4801.380436879286
total_rewards_std            597.8098626841207
total_rewards_max            5170.386578228245
total_rewards_min            3037.6611946543626
Number of train steps total  1492000
Number of env steps total    2466852
Number of rollouts total     0
Train Time (s)               148.01739215292037
(Previous) Eval Time (s)     20.5864213174209
Sample Time (s)              6.973716826643795
Epoch Time (s)               175.57753029698506
Total Train Time (s)         62939.26834280556
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:49:36.647913 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #372 | Epoch Duration: 175.6725459098816
2020-01-12 01:49:36.648282 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.70596236
Z variance train             0.0073274323
KL Divergence                19.35779
KL Loss                      1.935779
QF Loss                      511.83044
VF Loss                      118.00159
Policy Loss                  -1318.19
Q Predictions Mean           1310.2069
Q Predictions Std            318.85327
Q Predictions Max            1852.2081
Q Predictions Min            232.33655
V Predictions Mean           1312.9226
V Predictions Std            313.29364
V Predictions Max            1837.7604
V Predictions Min            370.5992
Log Pis Mean                 0.84778816
Log Pis Std                  2.9458208
Log Pis Max                  17.573986
Log Pis Min                  -9.453226
Policy mu Mean               0.011620384
Policy mu Std                0.66214424
Policy mu Max                2.9963245
Policy mu Min                -2.5718002
Policy log std Mean          -1.0627996
Policy log std Std           0.28424388
Policy log std Max           -0.19584036
Policy log std Min           -2.2770832
Z mean eval                  0.8233635
Z variance eval              0.007504523
total_rewards                [ 671.52611241 4019.2105371  5081.33415698 5102.50972811 4949.67253454
 4938.62781179 4866.71232233 5012.06314429  741.86979231 3314.1445378 ]
total_rewards_mean           3869.7670677669644
total_rewards_std            1671.4809264035034
total_rewards_max            5102.509728108227
total_rewards_min            671.5261124104594
Number of train steps total  1496000
Number of env steps total    2475898
Number of rollouts total     0
Train Time (s)               146.09084956999868
(Previous) Eval Time (s)     21.297854518983513
Sample Time (s)              7.263164343312383
Epoch Time (s)               174.65186843229458
Total Train Time (s)         63114.00972626731
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:52:31.390178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #373 | Epoch Duration: 174.74166250228882
2020-01-12 01:52:31.390318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8241603
Z variance train             0.00754394
KL Divergence                20.195063
KL Loss                      2.0195062
QF Loss                      2315.9924
VF Loss                      170.77232
Policy Loss                  -1360.8455
Q Predictions Mean           1349.7241
Q Predictions Std            344.5723
Q Predictions Max            1898.428
Q Predictions Min            388.63098
V Predictions Mean           1356.3044
V Predictions Std            341.73724
V Predictions Max            1890.7753
V Predictions Min            394.6768
Log Pis Mean                 1.2502661
Log Pis Std                  3.0759346
Log Pis Max                  11.954191
Log Pis Min                  -8.157226
Policy mu Mean               -0.013544799
Policy mu Std                0.6771997
Policy mu Max                2.2843604
Policy mu Min                -2.232836
Policy log std Mean          -1.1065539
Policy log std Std           0.31113705
Policy log std Max           -0.20006025
Policy log std Min           -2.7625825
Z mean eval                  0.7689575
Z variance eval              0.0067520454
total_rewards                [5176.19665306 3076.72677166 1972.99060151 4267.26488895 5232.18667189
 4533.35706929 4747.10494744 4977.1957823  4699.80570669 4926.42284917]
total_rewards_mean           4360.9251941948
total_rewards_std            988.7981677262269
total_rewards_max            5232.186671890914
total_rewards_min            1972.990601508076
Number of train steps total  1500000
Number of env steps total    2485638
Number of rollouts total     0
Train Time (s)               147.06661586323753
(Previous) Eval Time (s)     19.36895801499486
Sample Time (s)              7.141583304386586
Epoch Time (s)               173.57715718261898
Total Train Time (s)         63287.674859651364
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:55:25.059129 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #374 | Epoch Duration: 173.668696641922
2020-01-12 01:55:25.059304 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.76924527
Z variance train             0.0067378515
KL Divergence                19.924446
KL Loss                      1.9924446
QF Loss                      454.49103
VF Loss                      77.178825
Policy Loss                  -1309.7571
Q Predictions Mean           1298.9429
Q Predictions Std            346.20892
Q Predictions Max            1928.9899
Q Predictions Min            -82.094086
V Predictions Mean           1310.4546
V Predictions Std            338.74847
V Predictions Max            1944.2258
V Predictions Min            373.76218
Log Pis Mean                 1.259598
Log Pis Std                  3.092232
Log Pis Max                  17.459509
Log Pis Min                  -5.8103065
Policy mu Mean               -0.011853274
Policy mu Std                0.6890797
Policy mu Max                4.047874
Policy mu Min                -2.7460167
Policy log std Mean          -1.090495
Policy log std Std           0.2786505
Policy log std Max           -0.3412361
Policy log std Min           -2.5169716
Z mean eval                  0.79143834
Z variance eval              0.035245508
total_rewards                [ 705.8479172  3250.81129344  473.91797217 4460.40790175 2534.20743875
 5013.5805854  5208.15719283 5313.83090225  711.19190557 5062.27012795]
total_rewards_mean           3273.4223237310885
total_rewards_std            1925.7509120826855
total_rewards_max            5313.830902252645
total_rewards_min            473.91797216686496
Number of train steps total  1504000
Number of env steps total    2495843
Number of rollouts total     0
Train Time (s)               146.23585331067443
(Previous) Eval Time (s)     15.596790416631848
Sample Time (s)              7.079811271745712
Epoch Time (s)               168.912454999052
Total Train Time (s)         63456.67508039996
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:58:14.061835 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #375 | Epoch Duration: 169.0024058818817
2020-01-12 01:58:14.061974 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #375 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79256403
Z variance train             0.035863835
KL Divergence                19.930336
KL Loss                      1.9930336
QF Loss                      1518.76
VF Loss                      193.15872
Policy Loss                  -1326.0881
Q Predictions Mean           1319.875
Q Predictions Std            367.08438
Q Predictions Max            1925.8602
Q Predictions Min            373.62973
V Predictions Mean           1321.0857
V Predictions Std            369.74268
V Predictions Max            1918.4161
V Predictions Min            306.71964
Log Pis Mean                 0.85131645
Log Pis Std                  3.1887193
Log Pis Max                  23.284739
Log Pis Min                  -7.447454
Policy mu Mean               0.022292085
Policy mu Std                0.7101104
Policy mu Max                3.043583
Policy mu Min                -5.297733
Policy log std Mean          -1.0419364
Policy log std Std           0.30783266
Policy log std Max           0.348418
Policy log std Min           -2.5779738
Z mean eval                  0.98058164
Z variance eval              0.0015765165
total_rewards                [5002.94982116 4793.83952498 4959.43752596 4934.06755379 5188.4776674
 4826.15025968 4692.44901102 4888.91451442 3911.89639174 4952.69003294]
total_rewards_mean           4815.087230308915
total_rewards_std            326.41366014097906
total_rewards_max            5188.4776673981105
total_rewards_min            3911.8963917363894
Number of train steps total  1508000
Number of env steps total    2507738
Number of rollouts total     0
Train Time (s)               146.14692103210837
(Previous) Eval Time (s)     20.914437311235815
Sample Time (s)              6.177472996525466
Epoch Time (s)               173.23883133986965
Total Train Time (s)         63630.006743000355
Epoch                        376
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:01:07.397004 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #376 | Epoch Duration: 173.33491706848145
2020-01-12 02:01:07.397180 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.974723
Z variance train             0.0015731457
KL Divergence                22.853401
KL Loss                      2.28534
QF Loss                      746.0452
VF Loss                      362.48743
Policy Loss                  -1296.4127
Q Predictions Mean           1288.7698
Q Predictions Std            356.68173
Q Predictions Max            1886.3992
Q Predictions Min            380.89706
V Predictions Mean           1296.8427
V Predictions Std            357.2188
V Predictions Max            1885.9595
V Predictions Min            383.77606
Log Pis Mean                 0.9812993
Log Pis Std                  2.8460965
Log Pis Max                  13.7738905
Log Pis Min                  -7.1113586
Policy mu Mean               0.03630564
Policy mu Std                0.6697497
Policy mu Max                2.3324792
Policy mu Min                -2.257752
Policy log std Mean          -1.0525994
Policy log std Std           0.28126296
Policy log std Max           -0.0681963
Policy log std Min           -2.2865012
Z mean eval                  0.7537792
Z variance eval              0.0064333477
total_rewards                [3852.90925396 3120.87175639 4556.53213185 4767.94466383 4848.57945957
 4925.72669861 4894.89834344 4872.43671576 4771.42231053 4748.06170994]
total_rewards_mean           4535.938304388526
total_rewards_std            558.1581412605997
total_rewards_max            4925.72669860779
total_rewards_min            3120.8717563904565
Number of train steps total  1512000
Number of env steps total    2518841
Number of rollouts total     0
Train Time (s)               145.9913209839724
(Previous) Eval Time (s)     23.15682313265279
Sample Time (s)              7.390402570366859
Epoch Time (s)               176.53854668699205
Total Train Time (s)         63806.64255538676
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:04:04.035480 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #377 | Epoch Duration: 176.63817143440247
2020-01-12 02:04:04.035637 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7545326
Z variance train             0.0064288303
KL Divergence                20.262524
KL Loss                      2.0262525
QF Loss                      516.4385
VF Loss                      133.08777
Policy Loss                  -1365.9769
Q Predictions Mean           1359.8489
Q Predictions Std            339.26825
Q Predictions Max            1908.9349
Q Predictions Min            393.2228
V Predictions Mean           1369.3918
V Predictions Std            337.0015
V Predictions Max            1904.1687
V Predictions Min            398.16702
Log Pis Mean                 1.1673816
Log Pis Std                  2.673228
Log Pis Max                  11.845209
Log Pis Min                  -5.1881094
Policy mu Mean               -0.016316012
Policy mu Std                0.6653296
Policy mu Max                2.6920872
Policy mu Min                -2.3503363
Policy log std Mean          -1.1065754
Policy log std Std           0.28779456
Policy log std Max           -0.31202412
Policy log std Min           -2.484353
Z mean eval                  0.7599846
Z variance eval              0.008071923
total_rewards                [5201.33094872   93.66204697 -375.60347646 2840.58825564 4953.01928816
 3984.11381072 5048.46179048  957.48537045 5075.37648693 1572.59996906]
total_rewards_mean           2935.1034490673937
total_rewards_std            2101.574124709779
total_rewards_max            5201.330948715695
total_rewards_min            -375.6034764591159
Number of train steps total  1516000
Number of env steps total    2528490
Number of rollouts total     0
Train Time (s)               148.32555911317468
(Previous) Eval Time (s)     16.78034031484276
Sample Time (s)              7.23319932911545
Epoch Time (s)               172.3390987571329
Total Train Time (s)         63979.07230887702
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:06:56.467104 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #378 | Epoch Duration: 172.43135952949524
2020-01-12 02:06:56.467247 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7599183
Z variance train             0.007998211
KL Divergence                20.046814
KL Loss                      2.0046813
QF Loss                      621.8684
VF Loss                      114.07994
Policy Loss                  -1346.0957
Q Predictions Mean           1340.2292
Q Predictions Std            339.6772
Q Predictions Max            1935.3914
Q Predictions Min            391.40158
V Predictions Mean           1348.6481
V Predictions Std            340.18204
V Predictions Max            1915.0121
V Predictions Min            394.96704
Log Pis Mean                 1.6596993
Log Pis Std                  3.347984
Log Pis Max                  22.188665
Log Pis Min                  -6.294301
Policy mu Mean               0.08826348
Policy mu Std                0.7350475
Policy mu Max                3.400574
Policy mu Min                -5.515213
Policy log std Mean          -1.075126
Policy log std Std           0.3062119
Policy log std Max           1.0755727
Policy log std Min           -2.2274988
Z mean eval                  0.74666053
Z variance eval              0.011997945
total_rewards                [4869.57129537 1601.60483235 4776.94678456 5163.22793243 5127.87353368
 4928.88903417 5293.02544203 1185.620217   4962.68571677 2853.52635243]
total_rewards_mean           4076.2971140785994
total_rewards_std            1495.8520704558905
total_rewards_max            5293.025442025633
total_rewards_min            1185.6202170002848
Number of train steps total  1520000
Number of env steps total    2538561
Number of rollouts total     0
Train Time (s)               145.55372556392103
(Previous) Eval Time (s)     20.31787985190749
Sample Time (s)              6.11322166910395
Epoch Time (s)               171.98482708493248
Total Train Time (s)         64151.15260756202
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:09:48.549951 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #379 | Epoch Duration: 172.08259987831116
2020-01-12 02:09:48.550102 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74868476
Z variance train             0.012022452
KL Divergence                19.007517
KL Loss                      1.9007517
QF Loss                      613.6813
VF Loss                      238.86674
Policy Loss                  -1299.4485
Q Predictions Mean           1288.545
Q Predictions Std            367.65588
Q Predictions Max            1852.6919
Q Predictions Min            351.5601
V Predictions Mean           1287.1868
V Predictions Std            364.8024
V Predictions Max            1844.3474
V Predictions Min            367.6342
Log Pis Mean                 0.8590969
Log Pis Std                  2.868417
Log Pis Max                  12.77152
Log Pis Min                  -9.201452
Policy mu Mean               -0.034052666
Policy mu Std                0.635462
Policy mu Max                1.8901132
Policy mu Min                -3.5016832
Policy log std Mean          -1.0905095
Policy log std Std           0.2889898
Policy log std Max           -0.16789007
Policy log std Min           -2.3243878
Z mean eval                  0.6840142
Z variance eval              0.003160121
total_rewards                [2287.69498702 5202.61669549 5279.0158525  5360.46181823 5413.03272416
 4968.83514168 5100.6107882  5151.48819923 4943.85645887 5340.13881838]
total_rewards_mean           4904.7751483753445
total_rewards_std            885.3384579471905
total_rewards_max            5413.032724158657
total_rewards_min            2287.6949870214025
Number of train steps total  1524000
Number of env steps total    2551009
Number of rollouts total     0
Train Time (s)               143.33714977884665
(Previous) Eval Time (s)     23.428322554565966
Sample Time (s)              8.578353198710829
Epoch Time (s)               175.34382553212345
Total Train Time (s)         64326.59199747816
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:12:43.996811 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #380 | Epoch Duration: 175.4465765953064
2020-01-12 02:12:43.997063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67857325
Z variance train             0.003162269
KL Divergence                21.274082
KL Loss                      2.1274083
QF Loss                      680.6668
VF Loss                      199.93199
Policy Loss                  -1321.3396
Q Predictions Mean           1312.7712
Q Predictions Std            328.24936
Q Predictions Max            1910.8943
Q Predictions Min            387.2707
V Predictions Mean           1324.9336
V Predictions Std            331.34973
V Predictions Max            1886.5977
V Predictions Min            382.2311
Log Pis Mean                 1.033503
Log Pis Std                  3.2709177
Log Pis Max                  15.213512
Log Pis Min                  -7.329135
Policy mu Mean               0.023459315
Policy mu Std                0.67998964
Policy mu Max                2.585738
Policy mu Min                -2.505069
Policy log std Mean          -1.1023406
Policy log std Std           0.29992503
Policy log std Max           -0.28367043
Policy log std Min           -2.7505658
Z mean eval                  0.9146017
Z variance eval              0.011220587
total_rewards                [4881.48211375 4924.5251469  5162.17654017 4879.76662077 4915.99006413
 4963.65119942 5094.97198301 1498.41853211 1535.53469532   29.12864501]
total_rewards_mean           3788.5645540602795
total_rewards_std            1854.0575793455396
total_rewards_max            5162.176540174952
total_rewards_min            29.12864501061992
Number of train steps total  1528000
Number of env steps total    2561694
Number of rollouts total     0
Train Time (s)               145.17412716615945
(Previous) Eval Time (s)     18.86483663180843
Sample Time (s)              7.047614839859307
Epoch Time (s)               171.0865786378272
Total Train Time (s)         64497.776958542876
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:15:35.185613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #381 | Epoch Duration: 171.18836736679077
2020-01-12 02:15:35.185817 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.916893
Z variance train             0.011139457
KL Divergence                19.674215
KL Loss                      1.9674215
QF Loss                      15629.807
VF Loss                      148.24406
Policy Loss                  -1347.2234
Q Predictions Mean           1343.3235
Q Predictions Std            327.68796
Q Predictions Max            1902.9819
Q Predictions Min            386.40024
V Predictions Mean           1349.843
V Predictions Std            326.4153
V Predictions Max            1921.5026
V Predictions Min            393.07565
Log Pis Mean                 1.110074
Log Pis Std                  2.8054519
Log Pis Max                  11.312769
Log Pis Min                  -5.6033177
Policy mu Mean               -0.027219502
Policy mu Std                0.70866424
Policy mu Max                2.3497505
Policy mu Min                -2.5438032
Policy log std Mean          -1.0683924
Policy log std Std           0.30099756
Policy log std Max           -0.22439921
Policy log std Min           -2.6994562
Z mean eval                  0.9934617
Z variance eval              0.0048946464
total_rewards                [  62.29624585 1296.87177463  198.52582621 4732.48808439  802.12117651
 2171.82245865 2962.28357549 1993.74415668 4864.67623177 4922.08722542]
total_rewards_mean           2400.691675560344
total_rewards_std            1802.5198028267487
total_rewards_max            4922.087225420301
total_rewards_min            62.29624585134559
Number of train steps total  1532000
Number of env steps total    2573330
Number of rollouts total     0
Train Time (s)               144.75332352984697
(Previous) Eval Time (s)     10.585104211233556
Sample Time (s)              8.431138406973332
Epoch Time (s)               163.76956614805385
Total Train Time (s)         64661.63712349953
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:18:19.054948 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #382 | Epoch Duration: 163.86893892288208
2020-01-12 02:18:19.055219 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99696314
Z variance train             0.004908249
KL Divergence                22.75034
KL Loss                      2.275034
QF Loss                      525.668
VF Loss                      95.425186
Policy Loss                  -1390.6334
Q Predictions Mean           1384.212
Q Predictions Std            322.64374
Q Predictions Max            1924.7273
Q Predictions Min            377.99246
V Predictions Mean           1387.6163
V Predictions Std            318.97263
V Predictions Max            1902.6455
V Predictions Min            396.40604
Log Pis Mean                 1.239989
Log Pis Std                  2.9963753
Log Pis Max                  13.580122
Log Pis Min                  -8.227466
Policy mu Mean               0.06741379
Policy mu Std                0.6721918
Policy mu Max                2.538734
Policy mu Min                -2.809733
Policy log std Mean          -1.1061666
Policy log std Std           0.3075305
Policy log std Max           -0.15533328
Policy log std Min           -2.4734352
Z mean eval                  0.7328458
Z variance eval              0.018192522
total_rewards                [5242.88164438 5156.35324806 5163.14948108 4918.86318186 5074.74402914
 5081.88691073 5151.9007268  5191.75533598 5127.1900212  5174.61453251]
total_rewards_mean           5128.3339111723935
total_rewards_std            84.11091034605644
total_rewards_max            5242.88164437805
total_rewards_min            4918.863181860494
Number of train steps total  1536000
Number of env steps total    2585370
Number of rollouts total     0
Train Time (s)               146.43903620122
(Previous) Eval Time (s)     21.21510009514168
Sample Time (s)              7.171048602554947
Epoch Time (s)               174.82518489891663
Total Train Time (s)         64836.5568094952
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:21:13.977687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #383 | Epoch Duration: 174.92233061790466
2020-01-12 02:21:13.977875 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7415156
Z variance train             0.018387636
KL Divergence                17.170359
KL Loss                      1.7170359
QF Loss                      747.30115
VF Loss                      176.6693
Policy Loss                  -1322.4465
Q Predictions Mean           1316.2352
Q Predictions Std            289.9676
Q Predictions Max            1830.9727
Q Predictions Min            368.19763
V Predictions Mean           1327.2954
V Predictions Std            286.23395
V Predictions Max            1826.8871
V Predictions Min            380.9793
Log Pis Mean                 1.2643354
Log Pis Std                  2.9012704
Log Pis Max                  8.708987
Log Pis Min                  -7.663479
Policy mu Mean               0.037401885
Policy mu Std                0.6908161
Policy mu Max                2.9873977
Policy mu Min                -2.2239342
Policy log std Mean          -1.0885781
Policy log std Std           0.2867281
Policy log std Max           -0.22801125
Policy log std Min           -2.2183251
Z mean eval                  0.8064724
Z variance eval              0.028298184
total_rewards                [4895.9553783  4854.38912205 2158.13302059 4775.34474263  681.04315303
 4691.73172359 5002.66528344 1014.57377668 4712.02693646 4717.79699551]
total_rewards_mean           3750.3660132284376
total_rewards_std            1653.4046267636713
total_rewards_max            5002.665283438539
total_rewards_min            681.0431530306806
Number of train steps total  1540000
Number of env steps total    2594041
Number of rollouts total     0
Train Time (s)               144.8728587110527
(Previous) Eval Time (s)     19.066420681774616
Sample Time (s)              7.049888646695763
Epoch Time (s)               170.98916803952307
Total Train Time (s)         65007.641030048486
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:24:05.066032 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #384 | Epoch Duration: 171.08802795410156
2020-01-12 02:24:05.066178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8021649
Z variance train             0.028214354
KL Divergence                20.582172
KL Loss                      2.0582173
QF Loss                      673.6754
VF Loss                      105.7528
Policy Loss                  -1412.1749
Q Predictions Mean           1405.551
Q Predictions Std            305.0404
Q Predictions Max            1954.9095
Q Predictions Min            389.2151
V Predictions Mean           1414.2021
V Predictions Std            304.0874
V Predictions Max            1939.6626
V Predictions Min            392.29422
Log Pis Mean                 1.4071367
Log Pis Std                  3.139805
Log Pis Max                  11.715664
Log Pis Min                  -11.550369
Policy mu Mean               0.00052641914
Policy mu Std                0.7084108
Policy mu Max                2.519195
Policy mu Min                -2.5382507
Policy log std Mean          -1.0910244
Policy log std Std           0.3044257
Policy log std Max           -0.16467035
Policy log std Min           -2.5563142
Z mean eval                  0.7820159
Z variance eval              0.0045304275
total_rewards                [4900.77681285 1925.65526263 4710.93209922 5000.77486842  681.31566103
 4817.2444753  4726.37401168 4982.68110889 4915.03218002 4920.85694489]
total_rewards_mean           4158.164342493391
total_rewards_std            1457.093586383227
total_rewards_max            5000.774868421028
total_rewards_min            681.3156610337911
Number of train steps total  1544000
Number of env steps total    2605603
Number of rollouts total     0
Train Time (s)               147.1550318012014
(Previous) Eval Time (s)     18.169641037937254
Sample Time (s)              7.2240771246142685
Epoch Time (s)               172.54874996375293
Total Train Time (s)         65180.39455628162
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:26:57.843368 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #385 | Epoch Duration: 172.7769422531128
2020-01-12 02:26:57.843844 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78823066
Z variance train             0.0045419834
KL Divergence                21.035345
KL Loss                      2.1035345
QF Loss                      436.4382
VF Loss                      99.27544
Policy Loss                  -1413.84
Q Predictions Mean           1405.2561
Q Predictions Std            324.7887
Q Predictions Max            1979.1001
Q Predictions Min            387.51147
V Predictions Mean           1414.6995
V Predictions Std            329.44556
V Predictions Max            1971.3534
V Predictions Min            378.17932
Log Pis Mean                 1.2844224
Log Pis Std                  3.0634005
Log Pis Max                  13.369812
Log Pis Min                  -8.598906
Policy mu Mean               0.017353507
Policy mu Std                0.68340266
Policy mu Max                2.5164795
Policy mu Min                -2.4760842
Policy log std Mean          -1.1000214
Policy log std Std           0.28410622
Policy log std Max           -0.4255544
Policy log std Min           -2.7346354
Z mean eval                  1.0342205
Z variance eval              0.0036778215
total_rewards                [4862.84397963 4839.53093693 4854.22443273 2518.69764092 4805.43829033
 3714.32484535 4688.06654741 3554.40918736 4929.46924485 5013.12721632]
total_rewards_mean           4378.013232183075
total_rewards_std            789.7465203299913
total_rewards_max            5013.127216315686
total_rewards_min            2518.6976409200925
Number of train steps total  1548000
Number of env steps total    2614144
Number of rollouts total     0
Train Time (s)               147.56508763413876
(Previous) Eval Time (s)     22.117426068987697
Sample Time (s)              6.385454374365509
Epoch Time (s)               176.06796807749197
Total Train Time (s)         65356.56316134846
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:29:53.997146 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #386 | Epoch Duration: 176.15306067466736
2020-01-12 02:29:53.997277 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0322235
Z variance train             0.0036991711
KL Divergence                22.306479
KL Loss                      2.2306478
QF Loss                      791.69324
VF Loss                      78.63958
Policy Loss                  -1370.3439
Q Predictions Mean           1359.4412
Q Predictions Std            334.32736
Q Predictions Max            1884.3896
Q Predictions Min            400.7314
V Predictions Mean           1368.8823
V Predictions Std            332.08963
V Predictions Max            1872.8468
V Predictions Min            401.68408
Log Pis Mean                 1.2275244
Log Pis Std                  2.9902625
Log Pis Max                  17.01796
Log Pis Min                  -8.310878
Policy mu Mean               0.03780952
Policy mu Std                0.69161797
Policy mu Max                2.5113401
Policy mu Min                -3.6525946
Policy log std Mean          -1.0944521
Policy log std Std           0.29902875
Policy log std Max           -0.08020961
Policy log std Min           -2.6181178
Z mean eval                  0.8682294
Z variance eval              0.0082515795
total_rewards                [5173.5022337  5131.43942871 5141.17555378 5177.1407587  5196.76608216
 1804.3712357  5089.8003938  5289.429092   5224.53366098 5153.8758943 ]
total_rewards_mean           4838.203433383868
total_rewards_std            1012.6003160328821
total_rewards_max            5289.429092003107
total_rewards_min            1804.371235700867
Number of train steps total  1552000
Number of env steps total    2623775
Number of rollouts total     0
Train Time (s)               145.48044216493145
(Previous) Eval Time (s)     24.6339092371054
Sample Time (s)              7.061593112070113
Epoch Time (s)               177.17594451410696
Total Train Time (s)         65533.82569946442
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:32:51.262298 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #387 | Epoch Duration: 177.26493072509766
2020-01-12 02:32:51.262429 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.865466
Z variance train             0.008314975
KL Divergence                19.543606
KL Loss                      1.9543606
QF Loss                      5077.959
VF Loss                      142.48885
Policy Loss                  -1355.0065
Q Predictions Mean           1351.6436
Q Predictions Std            307.22775
Q Predictions Max            1893.7692
Q Predictions Min            382.32596
V Predictions Mean           1358.9761
V Predictions Std            305.52405
V Predictions Max            1904.9589
V Predictions Min            389.461
Log Pis Mean                 1.165601
Log Pis Std                  3.1696193
Log Pis Max                  18.159332
Log Pis Min                  -6.6491194
Policy mu Mean               0.059024133
Policy mu Std                0.6449818
Policy mu Max                2.2581263
Policy mu Min                -3.4205508
Policy log std Mean          -1.1499299
Policy log std Std           0.29760808
Policy log std Max           -0.31140316
Policy log std Min           -2.6048343
Z mean eval                  1.0696143
Z variance eval              0.012701613
total_rewards                [4221.8542742  4606.22575895 4875.7250542  5014.55757169 5099.29645719
 4397.92716052 4264.76665591 1109.48033025 4859.55536747 4771.12224016]
total_rewards_mean           4322.051087054143
total_rewards_std            1109.1100219572681
total_rewards_max            5099.296457193187
total_rewards_min            1109.480330253011
Number of train steps total  1556000
Number of env steps total    2634386
Number of rollouts total     0
Train Time (s)               146.09365746704862
(Previous) Eval Time (s)     18.771953872404993
Sample Time (s)              7.201709533110261
Epoch Time (s)               172.06732087256387
Total Train Time (s)         65705.99277922185
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:35:43.433628 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #388 | Epoch Duration: 172.17108583450317
2020-01-12 02:35:43.433837 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0608925
Z variance train             0.012710996
KL Divergence                20.849533
KL Loss                      2.0849533
QF Loss                      570.3154
VF Loss                      231.24132
Policy Loss                  -1418.8951
Q Predictions Mean           1414.4515
Q Predictions Std            351.97534
Q Predictions Max            1972.0363
Q Predictions Min            408.64877
V Predictions Mean           1430.3561
V Predictions Std            350.96603
V Predictions Max            1986.1401
V Predictions Min            419.08002
Log Pis Mean                 1.1443399
Log Pis Std                  2.9613535
Log Pis Max                  13.468388
Log Pis Min                  -6.9352503
Policy mu Mean               0.0078241695
Policy mu Std                0.6511874
Policy mu Max                2.6185791
Policy mu Min                -2.507619
Policy log std Mean          -1.0874327
Policy log std Std           0.31241184
Policy log std Max           -0.19178224
Policy log std Min           -2.3626146
Z mean eval                  0.6219728
Z variance eval              0.013268545
total_rewards                [4451.12706354 4895.4817971  5018.23811657 5213.34941141 4982.58773983
 4956.81218309 4960.76451137 4923.88398078 4966.09245782 1659.44992746]
total_rewards_mean           4602.77871889722
total_rewards_std            997.502613962269
total_rewards_max            5213.34941141013
total_rewards_min            1659.449927456986
Number of train steps total  1560000
Number of env steps total    2646539
Number of rollouts total     0
Train Time (s)               146.6369881699793
(Previous) Eval Time (s)     22.852989279665053
Sample Time (s)              7.5761809181421995
Epoch Time (s)               177.06615836778656
Total Train Time (s)         65883.35707950965
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:38:40.806681 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #389 | Epoch Duration: 177.37269616127014
2020-01-12 02:38:40.806828 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6203886
Z variance train             0.013285038
KL Divergence                18.584
KL Loss                      1.8584
QF Loss                      557.47253
VF Loss                      133.18361
Policy Loss                  -1394.1184
Q Predictions Mean           1388.1367
Q Predictions Std            314.64124
Q Predictions Max            1906.8851
Q Predictions Min            322.22446
V Predictions Mean           1400.0515
V Predictions Std            314.1824
V Predictions Max            1916.3479
V Predictions Min            338.24698
Log Pis Mean                 1.2933978
Log Pis Std                  3.2144094
Log Pis Max                  10.827578
Log Pis Min                  -7.557035
Policy mu Mean               0.016448975
Policy mu Std                0.6813783
Policy mu Max                2.471297
Policy mu Min                -2.4118783
Policy log std Mean          -1.1189902
Policy log std Std           0.32189056
Policy log std Max           -0.19662833
Policy log std Min           -2.7375884
Z mean eval                  0.7942023
Z variance eval              0.015781542
total_rewards                [2263.15091146  195.15296191   57.77946117 4804.50660517 4896.49479279
  277.64352572 4391.59221268  134.31853437  612.20227198 4880.8326616 ]
total_rewards_mean           2251.3673938860875
total_rewards_std            2124.0102964920984
total_rewards_max            4896.494792794802
total_rewards_min            57.77946117492823
Number of train steps total  1564000
Number of env steps total    2658725
Number of rollouts total     0
Train Time (s)               145.35066037997603
(Previous) Eval Time (s)     11.957744940184057
Sample Time (s)              7.811469622887671
Epoch Time (s)               165.11987494304776
Total Train Time (s)         66048.58984371647
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:41:26.039837 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #390 | Epoch Duration: 165.232896566391
2020-01-12 02:41:26.040023 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7869297
Z variance train             0.015761962
KL Divergence                20.22962
KL Loss                      2.022962
QF Loss                      599.9821
VF Loss                      93.34365
Policy Loss                  -1452.2661
Q Predictions Mean           1445.0662
Q Predictions Std            332.7692
Q Predictions Max            1961.7917
Q Predictions Min            419.0251
V Predictions Mean           1453.8579
V Predictions Std            331.23575
V Predictions Max            1991.3064
V Predictions Min            415.57703
Log Pis Mean                 1.0114799
Log Pis Std                  2.9957974
Log Pis Max                  11.779205
Log Pis Min                  -9.300364
Policy mu Mean               -0.0018803165
Policy mu Std                0.6885948
Policy mu Max                3.0947144
Policy mu Min                -3.0441315
Policy log std Mean          -1.0616369
Policy log std Std           0.28709716
Policy log std Max           0.017912626
Policy log std Min           -2.4534879
Z mean eval                  0.77650654
Z variance eval              0.011170566
total_rewards                [1403.79007724 4869.13435784 4924.30789004 5070.47241175 5215.17287697
 5008.4196088  5107.24917485 4900.95426037  538.78376552 4782.95052026]
total_rewards_mean           4182.123494365232
total_rewards_std            1621.375063479944
total_rewards_max            5215.172876974664
total_rewards_min            538.7837655235628
Number of train steps total  1568000
Number of env steps total    2670932
Number of rollouts total     0
Train Time (s)               146.3053671871312
(Previous) Eval Time (s)     17.7742008282803
Sample Time (s)              7.781457832548767
Epoch Time (s)               171.86102584796026
Total Train Time (s)         66220.53479151335
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:44:17.987615 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #391 | Epoch Duration: 171.94746947288513
2020-01-12 02:44:17.987755 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78236544
Z variance train             0.011196155
KL Divergence                20.49557
KL Loss                      2.049557
QF Loss                      4403.857
VF Loss                      151.8154
Policy Loss                  -1455.5564
Q Predictions Mean           1449.426
Q Predictions Std            354.6884
Q Predictions Max            1996.3584
Q Predictions Min            428.95276
V Predictions Mean           1446.969
V Predictions Std            353.74054
V Predictions Max            1977.2421
V Predictions Min            423.50217
Log Pis Mean                 1.2095286
Log Pis Std                  2.9628935
Log Pis Max                  15.1513
Log Pis Min                  -8.494425
Policy mu Mean               0.03911607
Policy mu Std                0.69622475
Policy mu Max                3.7149327
Policy mu Min                -2.5318305
Policy log std Mean          -1.0851316
Policy log std Std           0.3136049
Policy log std Max           -0.0027526617
Policy log std Min           -2.4124885
Z mean eval                  0.81023467
Z variance eval              0.009764462
total_rewards                [-463.79278235 2024.49310213 2134.04112575 5003.58672777  210.92986826
  924.4051747  2242.69554669 2063.82260994 2947.17606472 3113.46413336]
total_rewards_mean           2020.082157096521
total_rewards_std            1471.8674397863529
total_rewards_max            5003.586727774875
total_rewards_min            -463.7927823547527
Number of train steps total  1572000
Number of env steps total    2681570
Number of rollouts total     0
Train Time (s)               146.4287578132935
(Previous) Eval Time (s)     12.3540272382088
Sample Time (s)              6.589574210811406
Epoch Time (s)               165.3723592623137
Total Train Time (s)         66385.99350465275
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:47:03.450348 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #392 | Epoch Duration: 165.4624810218811
2020-01-12 02:47:03.450533 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82142943
Z variance train             0.010073864
KL Divergence                20.134394
KL Loss                      2.0134394
QF Loss                      18847.941
VF Loss                      140.26323
Policy Loss                  -1408.6492
Q Predictions Mean           1401.9255
Q Predictions Std            347.81955
Q Predictions Max            1965.9313
Q Predictions Min            380.72726
V Predictions Mean           1404.8501
V Predictions Std            343.75287
V Predictions Max            1943.8496
V Predictions Min            379.2811
Log Pis Mean                 1.3414991
Log Pis Std                  2.9342477
Log Pis Max                  9.828578
Log Pis Min                  -6.1047187
Policy mu Mean               0.020790637
Policy mu Std                0.69208807
Policy mu Max                2.5673904
Policy mu Min                -2.1850786
Policy log std Mean          -1.0888664
Policy log std Std           0.31210142
Policy log std Max           -0.1349119
Policy log std Min           -2.6892917
Z mean eval                  0.6656255
Z variance eval              0.0041668555
total_rewards                [2221.46525192 5179.44703767 4977.88756447 5350.18175691 5429.60945236
 5291.52344725 5253.36634678 5359.08486153 4846.31768679 1042.74793217]
total_rewards_mean           4495.163133784659
total_rewards_std            1465.370909375456
total_rewards_max            5429.609452360422
total_rewards_min            1042.7479321729293
Number of train steps total  1576000
Number of env steps total    2691499
Number of rollouts total     0
Train Time (s)               145.43125837715343
(Previous) Eval Time (s)     19.456647179089487
Sample Time (s)              7.112905432935804
Epoch Time (s)               172.00081098917872
Total Train Time (s)         66558.12146960013
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:49:55.583566 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #393 | Epoch Duration: 172.1328902244568
2020-01-12 02:49:55.583749 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.66499126
Z variance train             0.004159567
KL Divergence                21.468048
KL Loss                      2.1468048
QF Loss                      763.98096
VF Loss                      336.1373
Policy Loss                  -1430.6495
Q Predictions Mean           1420.3374
Q Predictions Std            343.88947
Q Predictions Max            1953.7341
Q Predictions Min            390.66034
V Predictions Mean           1427.0671
V Predictions Std            340.68652
V Predictions Max            1943.7751
V Predictions Min            402.88107
Log Pis Mean                 1.2214408
Log Pis Std                  2.7800977
Log Pis Max                  9.217782
Log Pis Min                  -7.39006
Policy mu Mean               -0.0062081874
Policy mu Std                0.6319298
Policy mu Max                2.1595619
Policy mu Min                -2.4861026
Policy log std Mean          -1.1429206
Policy log std Std           0.27679765
Policy log std Max           -0.34372652
Policy log std Min           -2.4536932
Z mean eval                  0.76452637
Z variance eval              0.005629602
total_rewards                [ 822.86203675 4852.41730244 4916.95953117 1217.01724802 4454.17583588
  827.78200405 4562.37323872 4736.84061843 4893.64428278 4371.61253317]
total_rewards_mean           3565.568463139768
total_rewards_std            1720.0132997081173
total_rewards_max            4916.9595311688345
total_rewards_min            822.8620367485089
Number of train steps total  1580000
Number of env steps total    2703499
Number of rollouts total     0
Train Time (s)               146.51483275694773
(Previous) Eval Time (s)     15.698599773924798
Sample Time (s)              7.032410653773695
Epoch Time (s)               169.24584318464622
Total Train Time (s)         66727.45722890086
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:52:44.923722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #394 | Epoch Duration: 169.33984065055847
2020-01-12 02:52:44.923888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7665829
Z variance train             0.005623917
KL Divergence                20.576624
KL Loss                      2.0576625
QF Loss                      510.38034
VF Loss                      88.74224
Policy Loss                  -1462.7921
Q Predictions Mean           1455.0345
Q Predictions Std            331.60867
Q Predictions Max            1978.2659
Q Predictions Min            409.18793
V Predictions Mean           1464.8462
V Predictions Std            331.74835
V Predictions Max            1983.9314
V Predictions Min            409.92447
Log Pis Mean                 1.5112479
Log Pis Std                  2.990692
Log Pis Max                  14.185801
Log Pis Min                  -6.8548813
Policy mu Mean               -0.052537005
Policy mu Std                0.6912971
Policy mu Max                2.465443
Policy mu Min                -2.5246139
Policy log std Mean          -1.1384103
Policy log std Std           0.29669496
Policy log std Max           -0.250278
Policy log std Min           -2.6389127
Z mean eval                  0.70837414
Z variance eval              0.0018839777
total_rewards                [1928.73330449 3677.19644361 3188.29969515 5136.29203631 2954.24533902
 4877.34885818 5200.15559915 5007.0067027  4799.27609106 5290.73825768]
total_rewards_mean           4205.929232734091
total_rewards_std            1119.9519480161782
total_rewards_max            5290.73825768393
total_rewards_min            1928.7333044853435
Number of train steps total  1584000
Number of env steps total    2713950
Number of rollouts total     0
Train Time (s)               146.75949004199356
(Previous) Eval Time (s)     17.818572842981666
Sample Time (s)              7.942671089433134
Epoch Time (s)               172.52073397440836
Total Train Time (s)         66900.05919144163
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:55:37.527993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #395 | Epoch Duration: 172.60399103164673
2020-01-12 02:55:37.528116 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.71555114
Z variance train             0.0018857915
KL Divergence                23.207434
KL Loss                      2.3207433
QF Loss                      677.37866
VF Loss                      131.64514
Policy Loss                  -1489.2717
Q Predictions Mean           1480.4474
Q Predictions Std            337.35406
Q Predictions Max            1973.7896
Q Predictions Min            391.39935
V Predictions Mean           1487.9885
V Predictions Std            334.52734
V Predictions Max            1962.9789
V Predictions Min            386.02145
Log Pis Mean                 1.637589
Log Pis Std                  3.1717398
Log Pis Max                  15.5233965
Log Pis Min                  -5.059027
Policy mu Mean               -0.06041562
Policy mu Std                0.7230229
Policy mu Max                2.47314
Policy mu Min                -2.3699722
Policy log std Mean          -1.1191592
Policy log std Std           0.30978137
Policy log std Max           -0.18995333
Policy log std Min           -2.616829
Z mean eval                  0.8133764
Z variance eval              0.005648868
total_rewards                [5189.97388824 4978.70874444 5014.29895522 5203.22088125 5013.75058719
 1459.83445875 5017.60797266 2409.8314902   777.35787699 5143.94534901]
total_rewards_mean           4020.8530203953865
total_rewards_std            1660.8560851640977
total_rewards_max            5203.220881253851
total_rewards_min            777.3578769947796
Number of train steps total  1588000
Number of env steps total    2725307
Number of rollouts total     0
Train Time (s)               148.3620524443686
(Previous) Eval Time (s)     19.69620075682178
Sample Time (s)              6.247810335829854
Epoch Time (s)               174.30606353702024
Total Train Time (s)         67074.45536735049
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:58:31.926497 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #396 | Epoch Duration: 174.3982720375061
2020-01-12 02:58:31.926631 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8126377
Z variance train             0.005643573
KL Divergence                22.57146
KL Loss                      2.2571461
QF Loss                      457.05396
VF Loss                      135.9136
Policy Loss                  -1461.4846
Q Predictions Mean           1454.4973
Q Predictions Std            370.29025
Q Predictions Max            1979.769
Q Predictions Min            401.32275
V Predictions Mean           1464.7146
V Predictions Std            371.14734
V Predictions Max            1975.3882
V Predictions Min            410.06592
Log Pis Mean                 1.4818687
Log Pis Std                  3.0446546
Log Pis Max                  11.837296
Log Pis Min                  -5.9625864
Policy mu Mean               0.0002398286
Policy mu Std                0.72164416
Policy mu Max                2.439536
Policy mu Min                -3.3988566
Policy log std Mean          -1.0731837
Policy log std Std           0.30817616
Policy log std Max           -0.11557984
Policy log std Min           -2.7704158
Z mean eval                  0.74008524
Z variance eval              0.005097526
total_rewards                [5096.76114961 1347.70628799 5047.84713948 4090.57978281 3699.96222863
 5002.22668169 5127.81802596 5102.42371009 1070.86437663 4871.55139939]
total_rewards_mean           4045.7740782266046
total_rewards_std            1491.442673397451
total_rewards_max            5127.818025962005
total_rewards_min            1070.8643766312027
Number of train steps total  1592000
Number of env steps total    2736555
Number of rollouts total     0
Train Time (s)               146.28058337699622
(Previous) Eval Time (s)     17.051648961845785
Sample Time (s)              7.37910999218002
Epoch Time (s)               170.71134233102202
Total Train Time (s)         67245.25618702685
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:01:22.732091 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #397 | Epoch Duration: 170.80534839630127
2020-01-12 03:01:22.732280 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.743568
Z variance train             0.005093875
KL Divergence                20.850895
KL Loss                      2.0850894
QF Loss                      662.1229
VF Loss                      220.1666
Policy Loss                  -1417.0077
Q Predictions Mean           1408.2081
Q Predictions Std            333.54147
Q Predictions Max            1979.2705
Q Predictions Min            181.61569
V Predictions Mean           1409.9331
V Predictions Std            334.84564
V Predictions Max            1922.1802
V Predictions Min            338.79
Log Pis Mean                 1.3696141
Log Pis Std                  3.0990934
Log Pis Max                  14.623285
Log Pis Min                  -6.2549663
Policy mu Mean               0.040769484
Policy mu Std                0.6869657
Policy mu Max                2.430766
Policy mu Min                -2.4681678
Policy log std Mean          -1.1115707
Policy log std Std           0.3015694
Policy log std Max           -0.15113711
Policy log std Min           -2.6663842
Z mean eval                  0.73047966
Z variance eval              0.0038166787
total_rewards                [5138.94714739 5048.24463472 5000.27142192 5084.23420026 5019.43580263
 4752.25726574 5099.0138889  5027.77217641 5161.39458176 5134.5218163 ]
total_rewards_mean           5046.6092936019795
total_rewards_std            111.12094900244031
total_rewards_max            5161.394581764131
total_rewards_min            4752.257265737951
Number of train steps total  1596000
Number of env steps total    2748579
Number of rollouts total     0
Train Time (s)               145.94727589190006
(Previous) Eval Time (s)     21.2755510751158
Sample Time (s)              6.334518387448043
Epoch Time (s)               173.5573453544639
Total Train Time (s)         67418.90174405696
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:04:16.384497 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #398 | Epoch Duration: 173.65201210975647
2020-01-12 03:04:16.384785 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #398 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73346347
Z variance train             0.0038138952
KL Divergence                21.515509
KL Loss                      2.151551
QF Loss                      384.32773
VF Loss                      82.02098
Policy Loss                  -1456.6674
Q Predictions Mean           1448.5095
Q Predictions Std            310.39017
Q Predictions Max            1949.7749
Q Predictions Min            378.0573
V Predictions Mean           1458.118
V Predictions Std            311.5511
V Predictions Max            1933.3667
V Predictions Min            380.82977
Log Pis Mean                 1.7290857
Log Pis Std                  3.023264
Log Pis Max                  11.515589
Log Pis Min                  -8.024206
Policy mu Mean               -0.039336544
Policy mu Std                0.69747937
Policy mu Max                2.1204267
Policy mu Min                -2.5819616
Policy log std Mean          -1.1391015
Policy log std Std           0.31149155
Policy log std Max           -0.2546749
Policy log std Min           -2.722652
Z mean eval                  0.66682005
Z variance eval              0.0028726268
total_rewards                [4930.57970036  105.38716225 4997.85041513 2013.11088824 1400.1991825
 4958.70321437 5128.55287255 3518.99346867 4784.73963858 4834.54164097]
total_rewards_mean           3667.265818362662
total_rewards_std            1742.5743093445046
total_rewards_max            5128.552872547844
total_rewards_min            105.38716225486635
Number of train steps total  1600000
Number of env steps total    2758216
Number of rollouts total     0
Train Time (s)               147.99738539382815
(Previous) Eval Time (s)     15.42835337901488
Sample Time (s)              7.308953108731657
Epoch Time (s)               170.7346918815747
Total Train Time (s)         67589.72699274216
Epoch                        399
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:07:07.213418 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #399 | Epoch Duration: 170.82845497131348
2020-01-12 03:07:07.213599 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67170113
Z variance train             0.0028692812
KL Divergence                21.819887
KL Loss                      2.1819887
QF Loss                      502.2466
VF Loss                      87.95842
Policy Loss                  -1440.2034
Q Predictions Mean           1432.8313
Q Predictions Std            334.93112
Q Predictions Max            1954.7767
Q Predictions Min            -69.33951
V Predictions Mean           1435.7339
V Predictions Std            334.80865
V Predictions Max            1946.4587
V Predictions Min            3.3822138
Log Pis Mean                 1.3463216
Log Pis Std                  3.0110984
Log Pis Max                  21.21548
Log Pis Min                  -6.5403514
Policy mu Mean               -0.038091213
Policy mu Std                0.69465846
Policy mu Max                2.6796412
Policy mu Min                -2.735403
Policy log std Mean          -1.0999515
Policy log std Std           0.31606436
Policy log std Max           -0.071917534
Policy log std Min           -3.7375307
Z mean eval                  0.71438277
Z variance eval              0.021146294
total_rewards                [3606.20444464 4913.34349805 5046.71189354 4930.56963021 5075.7402218
 5098.94946987 5023.69281279  737.50979367 5060.88547558 5140.6419392 ]
total_rewards_mean           4463.424917934626
total_rewards_std            1314.779398728278
total_rewards_max            5140.641939203874
total_rewards_min            737.5097936718588
Number of train steps total  1604000
Number of env steps total    2768905
Number of rollouts total     0
Train Time (s)               147.11370355589315
(Previous) Eval Time (s)     20.343438003212214
Sample Time (s)              7.523493902757764
Epoch Time (s)               174.98063546186313
Total Train Time (s)         67764.80296825059
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:10:02.291932 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #400 | Epoch Duration: 175.07820415496826
2020-01-12 03:10:02.292075 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7177113
Z variance train             0.020536436
KL Divergence                17.660406
KL Loss                      1.7660407
QF Loss                      34896.9
VF Loss                      134.17026
Policy Loss                  -1447.8492
Q Predictions Mean           1441.1213
Q Predictions Std            300.1311
Q Predictions Max            1980.616
Q Predictions Min            400.29865
V Predictions Mean           1454.8301
V Predictions Std            301.69135
V Predictions Max            1981.1309
V Predictions Min            398.5491
Log Pis Mean                 1.8858241
Log Pis Std                  3.099018
Log Pis Max                  11.512299
Log Pis Min                  -6.4845085
Policy mu Mean               -0.090477385
Policy mu Std                0.72512656
Policy mu Max                2.4788496
Policy mu Min                -2.671973
Policy log std Mean          -1.1185715
Policy log std Std           0.30034798
Policy log std Max           -0.17981517
Policy log std Min           -2.5034842
Z mean eval                  0.91745174
Z variance eval              0.020620113
total_rewards                [4623.99093742 2967.74801124  954.10007673  775.53670797 2030.04294728
 2111.18742897  614.17224833 4561.45676506 2460.93935132 1526.22459583]
total_rewards_mean           2262.5399070154886
total_rewards_std            1365.9276110761746
total_rewards_max            4623.99093742028
total_rewards_min            614.1722483313564
Number of train steps total  1608000
Number of env steps total    2778818
Number of rollouts total     0
Train Time (s)               150.71942071663216
(Previous) Eval Time (s)     12.127068034373224
Sample Time (s)              7.2549362746067345
Epoch Time (s)               170.10142502561212
Total Train Time (s)         67934.99341393448
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:12:52.485351 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #401 | Epoch Duration: 170.19312357902527
2020-01-12 03:12:52.485566 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91849643
Z variance train             0.020624837
KL Divergence                22.09441
KL Loss                      2.209441
QF Loss                      22129.285
VF Loss                      137.79228
Policy Loss                  -1581.3137
Q Predictions Mean           1568.3201
Q Predictions Std            334.07376
Q Predictions Max            2028.35
Q Predictions Min            -65.46024
V Predictions Mean           1578.7528
V Predictions Std            312.43436
V Predictions Max            2041.5111
V Predictions Min            430.8729
Log Pis Mean                 1.4953024
Log Pis Std                  3.2774942
Log Pis Max                  15.657244
Log Pis Min                  -8.410081
Policy mu Mean               0.07243295
Policy mu Std                0.7291982
Policy mu Max                3.0521436
Policy mu Min                -2.9643693
Policy log std Mean          -1.1031976
Policy log std Std           0.30086094
Policy log std Max           -0.17348099
Policy log std Min           -2.490458
Z mean eval                  0.7176725
Z variance eval              0.026901778
total_rewards                [ 118.07206478 3319.64883853 5060.35220908  420.94135331 3761.68638904
  222.0232439  4994.4685417  5120.11015955 4865.20362887 5093.63966633]
total_rewards_mean           3297.614609508684
total_rewards_std            2074.8720121770384
total_rewards_max            5120.110159553675
total_rewards_min            118.07206477597045
Number of train steps total  1612000
Number of env steps total    2789229
Number of rollouts total     0
Train Time (s)               146.6551733831875
(Previous) Eval Time (s)     13.925467865075916
Sample Time (s)              7.5184118817560375
Epoch Time (s)               168.09905313001946
Total Train Time (s)         68103.18379193358
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:15:40.678956 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #402 | Epoch Duration: 168.1932601928711
2020-01-12 03:15:40.679161 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.71689606
Z variance train             0.02670208
KL Divergence                18.983326
KL Loss                      1.8983326
QF Loss                      940.1367
VF Loss                      142.81642
Policy Loss                  -1453.0892
Q Predictions Mean           1445.032
Q Predictions Std            313.86966
Q Predictions Max            1976.3899
Q Predictions Min            378.74213
V Predictions Mean           1457.6896
V Predictions Std            309.3136
V Predictions Max            1966.641
V Predictions Min            382.0165
Log Pis Mean                 1.5674272
Log Pis Std                  3.1787558
Log Pis Max                  12.184686
Log Pis Min                  -6.858984
Policy mu Mean               -0.02190898
Policy mu Std                0.7396747
Policy mu Max                2.653219
Policy mu Min                -3.099168
Policy log std Mean          -1.1133704
Policy log std Std           0.3032084
Policy log std Max           -0.30189168
Policy log std Min           -2.787762
Z mean eval                  0.87966603
Z variance eval              0.024657533
total_rewards                [4586.2548442  2952.80882022   39.95782505 4455.10216723  639.4879753
 1641.29174915 3394.78842488 4334.89158309 4763.75831313 2142.06710605]
total_rewards_mean           2895.040880829911
total_rewards_std            1627.5819509981873
total_rewards_max            4763.758313128728
total_rewards_min            39.9578250482586
Number of train steps total  1616000
Number of env steps total    2799244
Number of rollouts total     0
Train Time (s)               144.3509547119029
(Previous) Eval Time (s)     13.435003852006048
Sample Time (s)              7.372791329398751
Epoch Time (s)               165.1587498933077
Total Train Time (s)         68268.43049683655
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:18:25.935259 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #403 | Epoch Duration: 165.2559597492218
2020-01-12 03:18:25.935448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.879024
Z variance train             0.024638347
KL Divergence                19.295897
KL Loss                      1.9295896
QF Loss                      719.0486
VF Loss                      102.33582
Policy Loss                  -1561.4048
Q Predictions Mean           1554.0337
Q Predictions Std            349.8584
Q Predictions Max            2056.7144
Q Predictions Min            433.40787
V Predictions Mean           1559.7921
V Predictions Std            347.8161
V Predictions Max            2039.8096
V Predictions Min            429.8111
Log Pis Mean                 1.307968
Log Pis Std                  3.1781838
Log Pis Max                  13.221403
Log Pis Min                  -9.150104
Policy mu Mean               -0.0017917659
Policy mu Std                0.71588004
Policy mu Max                2.6039872
Policy mu Min                -2.6549895
Policy log std Mean          -1.07139
Policy log std Std           0.31144896
Policy log std Max           -0.23697233
Policy log std Min           -2.7273917
Z mean eval                  0.72308946
Z variance eval              0.002538824
total_rewards                [5028.75845471 5019.59114665 1767.03625173 1974.64013763 2243.20531231
 5195.13144051 5079.65109354 5287.93339017   38.01649096 5166.13871077]
total_rewards_mean           3680.010242899078
total_rewards_std            1858.990687064592
total_rewards_max            5287.933390168082
total_rewards_min            38.016490957191415
Number of train steps total  1620000
Number of env steps total    2810800
Number of rollouts total     0
Train Time (s)               146.575421505142
(Previous) Eval Time (s)     17.79077014606446
Sample Time (s)              8.287510800175369
Epoch Time (s)               172.65370245138183
Total Train Time (s)         68441.17512616795
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:21:18.686259 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #404 | Epoch Duration: 172.75067973136902
2020-01-12 03:21:18.686424 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7204145
Z variance train             0.00253561
KL Divergence                22.480145
KL Loss                      2.2480145
QF Loss                      453.112
VF Loss                      157.15369
Policy Loss                  -1520.6312
Q Predictions Mean           1513.6467
Q Predictions Std            318.5298
Q Predictions Max            1973.5372
Q Predictions Min            420.99033
V Predictions Mean           1513.106
V Predictions Std            314.2319
V Predictions Max            1947.16
V Predictions Min            407.07956
Log Pis Mean                 1.7744161
Log Pis Std                  3.1302211
Log Pis Max                  16.212934
Log Pis Min                  -7.8706656
Policy mu Mean               -0.04392327
Policy mu Std                0.7123841
Policy mu Max                2.4971523
Policy mu Min                -2.7787843
Policy log std Mean          -1.1301999
Policy log std Std           0.2972784
Policy log std Max           -0.21149337
Policy log std Min           -2.719478
Z mean eval                  0.83889645
Z variance eval              0.0020976537
total_rewards                [5212.88381515 5120.83494982 5272.53766668 1951.50366677 5247.32908583
 5087.13525653 5238.60332303 5030.5703986  5098.83099933 3490.54993631]
total_rewards_mean           4675.077909806752
total_rewards_std            1038.5865884080085
total_rewards_max            5272.537666682183
total_rewards_min            1951.503666774286
Number of train steps total  1624000
Number of env steps total    2821105
Number of rollouts total     0
Train Time (s)               144.84953891811892
(Previous) Eval Time (s)     22.17181507591158
Sample Time (s)              6.402410811278969
Epoch Time (s)               173.42376480530947
Total Train Time (s)         68614.68194012204
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:24:12.196975 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #405 | Epoch Duration: 173.5104365348816
2020-01-12 03:24:12.197104 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84058523
Z variance train             0.0020593237
KL Divergence                22.144573
KL Loss                      2.2144573
QF Loss                      6442.4824
VF Loss                      214.59134
Policy Loss                  -1487.1816
Q Predictions Mean           1477.0875
Q Predictions Std            300.76135
Q Predictions Max            1971.4149
Q Predictions Min            23.311666
V Predictions Mean           1481.72
V Predictions Std            286.53418
V Predictions Max            1948.777
V Predictions Min            364.9577
Log Pis Mean                 1.8584789
Log Pis Std                  3.007438
Log Pis Max                  16.237732
Log Pis Min                  -6.7261252
Policy mu Mean               -0.059479598
Policy mu Std                0.7253486
Policy mu Max                2.636671
Policy mu Min                -3.900075
Policy log std Mean          -1.1407237
Policy log std Std           0.3246822
Policy log std Max           0.49943805
Policy log std Min           -2.8738458
Z mean eval                  0.56018794
Z variance eval              0.0059634396
total_rewards                [4707.5274545  4722.14316278 5002.89796503 4909.59847686 4928.07234866
 4231.33950641 5010.51037403 4963.91695538 4912.70883442 4905.59060763]
total_rewards_mean           4829.430568570662
total_rewards_std            222.24851237479055
total_rewards_max            5010.5103740324685
total_rewards_min            4231.339506409353
Number of train steps total  1628000
Number of env steps total    2832180
Number of rollouts total     0
Train Time (s)               145.26609877543524
(Previous) Eval Time (s)     22.789640955161303
Sample Time (s)              7.701411138288677
Epoch Time (s)               175.75715086888522
Total Train Time (s)         68790.5249032965
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:27:08.043947 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #406 | Epoch Duration: 175.8467252254486
2020-01-12 03:27:08.044193 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.55712664
Z variance train             0.0059891827
KL Divergence                18.388342
KL Loss                      1.8388342
QF Loss                      443.03113
VF Loss                      133.08653
Policy Loss                  -1364.8772
Q Predictions Mean           1360.9786
Q Predictions Std            330.21774
Q Predictions Max            1888.131
Q Predictions Min            331.69006
V Predictions Mean           1367.3958
V Predictions Std            330.47687
V Predictions Max            1888.3372
V Predictions Min            332.86816
Log Pis Mean                 1.8714064
Log Pis Std                  2.7457044
Log Pis Max                  10.732697
Log Pis Min                  -5.7682776
Policy mu Mean               -0.0855383
Policy mu Std                0.67603874
Policy mu Max                1.9501613
Policy mu Min                -2.451242
Policy log std Mean          -1.1557789
Policy log std Std           0.31437847
Policy log std Max           -0.19639337
Policy log std Min           -2.6679373
Z mean eval                  0.8054611
Z variance eval              0.0022740695
total_rewards                [5308.20290416 3705.27183886 4959.50714358 3013.11869155  198.17268876
 4935.80346952 5406.32797856 1033.27619391 3189.88982462 5322.91638164]
total_rewards_mean           3707.248711515507
total_rewards_std            1770.622174431701
total_rewards_max            5406.327978560865
total_rewards_min            198.17268876006094
Number of train steps total  1632000
Number of env steps total    2841428
Number of rollouts total     0
Train Time (s)               148.17863484006375
(Previous) Eval Time (s)     17.7250909130089
Sample Time (s)              7.198150406591594
Epoch Time (s)               173.10187615966424
Total Train Time (s)         68963.71787828393
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:30:01.241346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #407 | Epoch Duration: 173.19701099395752
2020-01-12 03:30:01.241532 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8109811
Z variance train             0.002274802
KL Divergence                23.191704
KL Loss                      2.3191705
QF Loss                      439.901
VF Loss                      204.94989
Policy Loss                  -1560.5245
Q Predictions Mean           1556.9961
Q Predictions Std            300.05792
Q Predictions Max            2037.8192
Q Predictions Min            432.74902
V Predictions Mean           1570.0193
V Predictions Std            296.89203
V Predictions Max            2035.0565
V Predictions Min            448.1795
Log Pis Mean                 1.5733973
Log Pis Std                  2.8645184
Log Pis Max                  12.9334755
Log Pis Min                  -8.2367115
Policy mu Mean               -0.01685827
Policy mu Std                0.69476134
Policy mu Max                3.6784575
Policy mu Min                -2.6184924
Policy log std Mean          -1.1148494
Policy log std Std           0.2936313
Policy log std Max           -0.27872908
Policy log std Min           -2.557632
Z mean eval                  0.79611015
Z variance eval              0.0009710025
total_rewards                [4754.21178808 5083.86728979   91.14653304 4959.9040745    38.10329101
 5328.68402035 1830.28178506 5075.04473222 4794.51106627 2940.78354074]
total_rewards_mean           3489.6538121058547
total_rewards_std            2010.4286875137134
total_rewards_max            5328.684020352491
total_rewards_min            38.10329100783704
Number of train steps total  1636000
Number of env steps total    2851826
Number of rollouts total     0
Train Time (s)               145.5702260080725
(Previous) Eval Time (s)     19.249406876042485
Sample Time (s)              7.140501058660448
Epoch Time (s)               171.96013394277543
Total Train Time (s)         69135.76754698856
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:32:53.293730 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #408 | Epoch Duration: 172.05207443237305
2020-01-12 03:32:53.293916 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7967931
Z variance train             0.0009707602
KL Divergence                24.63247
KL Loss                      2.463247
QF Loss                      467.8899
VF Loss                      185.51262
Policy Loss                  -1590.2113
Q Predictions Mean           1581.3126
Q Predictions Std            295.88965
Q Predictions Max            2034.1354
Q Predictions Min            421.68225
V Predictions Mean           1597.9819
V Predictions Std            295.80246
V Predictions Max            2047.3743
V Predictions Min            428.46936
Log Pis Mean                 1.6264764
Log Pis Std                  3.1658864
Log Pis Max                  14.388968
Log Pis Min                  -8.72247
Policy mu Mean               -0.033090435
Policy mu Std                0.71285576
Policy mu Max                2.263373
Policy mu Min                -2.5300274
Policy log std Mean          -1.1305561
Policy log std Std           0.3096807
Policy log std Max           -0.14727318
Policy log std Min           -2.4809427
Z mean eval                  0.8361312
Z variance eval              0.0009345895
total_rewards                [ 458.74975792  130.53328778 5106.87608501   41.63628226 3108.15495246
 -219.54253589 4834.77832405 5266.10138492 1986.3483592   636.83834917]
total_rewards_mean           2135.047424687661
total_rewards_std            2142.241966029483
total_rewards_max            5266.101384924528
total_rewards_min            -219.54253589224766
Number of train steps total  1640000
Number of env steps total    2863963
Number of rollouts total     0
Train Time (s)               144.6834209128283
(Previous) Eval Time (s)     13.23227471113205
Sample Time (s)              7.721024237573147
Epoch Time (s)               165.6367198615335
Total Train Time (s)         69301.49142276682
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:35:39.020646 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #409 | Epoch Duration: 165.72663378715515
2020-01-12 03:35:39.020778 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8367103
Z variance train             0.0009357518
KL Divergence                23.819702
KL Loss                      2.3819702
QF Loss                      2446.8938
VF Loss                      143.24178
Policy Loss                  -1545.0258
Q Predictions Mean           1538.8894
Q Predictions Std            307.68515
Q Predictions Max            2015.0759
Q Predictions Min            403.24182
V Predictions Mean           1552.321
V Predictions Std            307.64505
V Predictions Max            2012.4075
V Predictions Min            407.5663
Log Pis Mean                 1.6404982
Log Pis Std                  2.9125462
Log Pis Max                  12.572451
Log Pis Min                  -7.032861
Policy mu Mean               0.020629298
Policy mu Std                0.7202593
Policy mu Max                2.4605598
Policy mu Min                -2.8771782
Policy log std Mean          -1.107391
Policy log std Std           0.29068506
Policy log std Max           -0.16032362
Policy log std Min           -2.7209063
Z mean eval                  0.9469188
Z variance eval              0.0033660694
total_rewards                [ 555.21497154 4478.265852   4935.05518886 2099.8069535  4801.77802304
  619.65265461  712.74715873 1158.70839751 4699.23163933  798.64149456]
total_rewards_mean           2485.91023336849
total_rewards_std            1879.942878807526
total_rewards_max            4935.055188859709
total_rewards_min            555.2149715412861
Number of train steps total  1644000
Number of env steps total    2874971
Number of rollouts total     0
Train Time (s)               144.9728096537292
(Previous) Eval Time (s)     13.089803349226713
Sample Time (s)              7.1973643116652966
Epoch Time (s)               165.2599773146212
Total Train Time (s)         69466.84410400223
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:38:24.379269 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #410 | Epoch Duration: 165.35836124420166
2020-01-12 03:38:24.379537 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9477048
Z variance train             0.0033555713
KL Divergence                22.977476
KL Loss                      2.2977476
QF Loss                      21423.229
VF Loss                      253.1627
Policy Loss                  -1563.0986
Q Predictions Mean           1557.3826
Q Predictions Std            349.31323
Q Predictions Max            2084.678
Q Predictions Min            232.91882
V Predictions Mean           1563.5527
V Predictions Std            343.41507
V Predictions Max            2071.7454
V Predictions Min            430.7131
Log Pis Mean                 1.9809996
Log Pis Std                  3.4999788
Log Pis Max                  22.355545
Log Pis Min                  -6.162012
Policy mu Mean               -0.009021029
Policy mu Std                0.77782834
Policy mu Max                3.2654
Policy mu Min                -3.2972353
Policy log std Mean          -1.0956068
Policy log std Std           0.3410672
Policy log std Max           0.28687382
Policy log std Min           -3.0265546
Z mean eval                  0.7571994
Z variance eval              0.014816704
total_rewards                [ 878.90887228  294.99995828 2330.02533383  149.18450538 4115.32527563
 1556.78890436 -115.89142205   80.31405267    7.54768428 1274.58493396]
total_rewards_mean           1057.1788098636637
total_rewards_std            1270.3742834701366
total_rewards_max            4115.3252756315005
total_rewards_min            -115.89142204620902
Number of train steps total  1648000
Number of env steps total    2883746
Number of rollouts total     0
Train Time (s)               146.35093718674034
(Previous) Eval Time (s)     10.226900428999215
Sample Time (s)              8.038410728797317
Epoch Time (s)               164.61624834453687
Total Train Time (s)         69631.55012261588
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:41:09.087342 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #411 | Epoch Duration: 164.70762729644775
2020-01-12 03:41:09.087469 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74419934
Z variance train             0.014885962
KL Divergence                21.69435
KL Loss                      2.169435
QF Loss                      37252.195
VF Loss                      114.98615
Policy Loss                  -1539.4126
Q Predictions Mean           1536.2699
Q Predictions Std            309.55026
Q Predictions Max            2025.0361
Q Predictions Min            430.77985
V Predictions Mean           1545.5278
V Predictions Std            308.49414
V Predictions Max            2018.5308
V Predictions Min            438.96768
Log Pis Mean                 2.0261557
Log Pis Std                  3.198274
Log Pis Max                  13.613819
Log Pis Min                  -4.9688196
Policy mu Mean               -0.049113676
Policy mu Std                0.71129614
Policy mu Max                2.4523268
Policy mu Min                -2.5289955
Policy log std Mean          -1.1521688
Policy log std Std           0.31868175
Policy log std Max           -0.14024496
Policy log std Min           -2.5947804
Z mean eval                  1.1542828
Z variance eval              0.012072579
total_rewards                [1159.20104595  878.40085287 5076.90918945 3853.14950849 2111.57729636
 1268.03318109  976.22358964  855.70895868 3473.67307292   22.36818211]
total_rewards_mean           1967.5244877564182
total_rewards_std            1544.1631771168793
total_rewards_max            5076.909189451334
total_rewards_min            22.368182113957843
Number of train steps total  1652000
Number of env steps total    2894347
Number of rollouts total     0
Train Time (s)               145.91106817917898
(Previous) Eval Time (s)     12.537192672025412
Sample Time (s)              6.960133398417383
Epoch Time (s)               165.40839424962178
Total Train Time (s)         69797.04571133805
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:43:54.587024 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #412 | Epoch Duration: 165.49944138526917
2020-01-12 03:43:54.587211 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1385765
Z variance train             0.010924558
KL Divergence                23.721521
KL Loss                      2.372152
QF Loss                      575.83154
VF Loss                      159.9451
Policy Loss                  -1644.465
Q Predictions Mean           1633.4839
Q Predictions Std            321.4805
Q Predictions Max            2106.3975
Q Predictions Min            374.69406
V Predictions Mean           1639.0237
V Predictions Std            313.05048
V Predictions Max            2078.268
V Predictions Min            390.35
Log Pis Mean                 1.8068756
Log Pis Std                  3.5623553
Log Pis Max                  30.197454
Log Pis Min                  -8.851902
Policy mu Mean               0.0042422432
Policy mu Std                0.7767693
Policy mu Max                6.19961
Policy mu Min                -2.9501593
Policy log std Mean          -1.0940449
Policy log std Std           0.34941706
Policy log std Max           0.6158017
Policy log std Min           -2.794778
Z mean eval                  1.2338499
Z variance eval              0.004646658
total_rewards                [2643.75290384 1572.21779604 3165.26841095 4735.05146555 4749.54193397
 4773.92404331 4731.8769972  3913.18749844 4883.06351701 4703.20281816]
total_rewards_mean           3987.1087384468724
total_rewards_std            1093.0322738049406
total_rewards_max            4883.063517005675
total_rewards_min            1572.2177960438084
Number of train steps total  1656000
Number of env steps total    2905346
Number of rollouts total     0
Train Time (s)               145.98363327980042
(Previous) Eval Time (s)     21.526000387966633
Sample Time (s)              7.131125876214355
Epoch Time (s)               174.6407595439814
Total Train Time (s)         69971.84721312346
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:46:49.396819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #413 | Epoch Duration: 174.80946254730225
2020-01-12 03:46:49.397003 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2320383
Z variance train             0.004642927
KL Divergence                22.947863
KL Loss                      2.2947862
QF Loss                      528.5543
VF Loss                      139.95471
Policy Loss                  -1578.3444
Q Predictions Mean           1567.4282
Q Predictions Std            327.95804
Q Predictions Max            2038.8256
Q Predictions Min            400.11633
V Predictions Mean           1570.4304
V Predictions Std            328.17126
V Predictions Max            2025.9736
V Predictions Min            386.0583
Log Pis Mean                 1.886134
Log Pis Std                  2.9622195
Log Pis Max                  13.427475
Log Pis Min                  -7.002635
Policy mu Mean               -0.14815854
Policy mu Std                0.75389796
Policy mu Max                2.788493
Policy mu Min                -2.3579924
Policy log std Mean          -1.0861225
Policy log std Std           0.31721935
Policy log std Max           -0.09631348
Policy log std Min           -2.713345
Z mean eval                  0.70260435
Z variance eval              0.0072122514
total_rewards                [4954.39637372 5103.93353972  673.84529889 5153.62904841 4991.98145491
 1922.94411195 4997.71824288 4956.49289764 1482.04765272 1219.0684029 ]
total_rewards_mean           3545.605702375108
total_rewards_std            1836.8761061528207
total_rewards_max            5153.62904841442
total_rewards_min            673.8452988879856
Number of train steps total  1660000
Number of env steps total    2915625
Number of rollouts total     0
Train Time (s)               144.91871770936996
(Previous) Eval Time (s)     16.90781654184684
Sample Time (s)              7.276261904742569
Epoch Time (s)               169.10279615595937
Total Train Time (s)         70141.0395877217
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:49:38.593915 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #414 | Epoch Duration: 169.19677567481995
2020-01-12 03:49:38.594098 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6978456
Z variance train             0.007171914
KL Divergence                19.97446
KL Loss                      1.9974461
QF Loss                      6556.0303
VF Loss                      124.65078
Policy Loss                  -1581.6227
Q Predictions Mean           1574.5433
Q Predictions Std            328.42285
Q Predictions Max            2074.0984
Q Predictions Min            439.5237
V Predictions Mean           1580.0294
V Predictions Std            324.02853
V Predictions Max            2056.8506
V Predictions Min            452.59036
Log Pis Mean                 1.4374309
Log Pis Std                  2.5242841
Log Pis Max                  8.2096615
Log Pis Min                  -6.600837
Policy mu Mean               -0.0065326868
Policy mu Std                0.68471014
Policy mu Max                2.1148295
Policy mu Min                -2.6078548
Policy log std Mean          -1.1068778
Policy log std Std           0.28277782
Policy log std Max           -0.27180505
Policy log std Min           -2.5482316
Z mean eval                  0.75428313
Z variance eval              0.0018059714
total_rewards                [5320.00047972 2746.40700141 4932.30399068 2620.06159801 5144.47040375
 2258.22635049 4883.32327179 4540.26711582 4921.23855992 5061.14821667]
total_rewards_mean           4242.744698827185
total_rewards_std            1135.276179656244
total_rewards_max            5320.000479723347
total_rewards_min            2258.2263504911393
Number of train steps total  1664000
Number of env steps total    2925681
Number of rollouts total     0
Train Time (s)               145.60921049304307
(Previous) Eval Time (s)     18.44629265507683
Sample Time (s)              8.207994858268648
Epoch Time (s)               172.26349800638855
Total Train Time (s)         70313.39074959466
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:52:30.953749 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #415 | Epoch Duration: 172.35949730873108
2020-01-12 03:52:30.953996 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74223703
Z variance train             0.0018188494
KL Divergence                22.50549
KL Loss                      2.250549
QF Loss                      482.741
VF Loss                      83.747505
Policy Loss                  -1582.3625
Q Predictions Mean           1577.0046
Q Predictions Std            322.07193
Q Predictions Max            2075.9878
Q Predictions Min            438.03482
V Predictions Mean           1585.1029
V Predictions Std            322.87982
V Predictions Max            2072.0847
V Predictions Min            436.6774
Log Pis Mean                 1.870609
Log Pis Std                  3.2432125
Log Pis Max                  14.753156
Log Pis Min                  -5.1867256
Policy mu Mean               -0.029164173
Policy mu Std                0.723862
Policy mu Max                2.79405
Policy mu Min                -2.97456
Policy log std Mean          -1.1395876
Policy log std Std           0.3336326
Policy log std Max           -0.1891582
Policy log std Min           -2.710427
Z mean eval                  0.8977364
Z variance eval              0.011171386
total_rewards                [4849.58719567 5218.56671907 4842.69979921  574.02431532 1171.73005515
 4958.22249628 5155.75373763 4939.8611909  3063.71944056 4925.91628824]
total_rewards_mean           3970.0081238035737
total_rewards_std            1658.7799649566286
total_rewards_max            5218.56671907433
total_rewards_min            574.02431532371
Number of train steps total  1668000
Number of env steps total    2934943
Number of rollouts total     0
Train Time (s)               146.0237389788963
(Previous) Eval Time (s)     19.471093044616282
Sample Time (s)              7.216885422356427
Epoch Time (s)               172.711717445869
Total Train Time (s)         70486.19075849699
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:55:23.756281 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #416 | Epoch Duration: 172.80211901664734
2020-01-12 03:55:23.756418 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8876691
Z variance train             0.011269845
KL Divergence                18.899502
KL Loss                      1.8899502
QF Loss                      18267.164
VF Loss                      101.335495
Policy Loss                  -1504.8052
Q Predictions Mean           1497.8798
Q Predictions Std            303.95416
Q Predictions Max            1965.047
Q Predictions Min            401.64325
V Predictions Mean           1509.5474
V Predictions Std            302.6574
V Predictions Max            1972.8575
V Predictions Min            401.27628
Log Pis Mean                 1.519271
Log Pis Std                  2.8410313
Log Pis Max                  10.827694
Log Pis Min                  -6.9420433
Policy mu Mean               -0.05061402
Policy mu Std                0.68136424
Policy mu Max                2.4863715
Policy mu Min                -2.5633616
Policy log std Mean          -1.1436596
Policy log std Std           0.31463125
Policy log std Max           0.2539884
Policy log std Min           -2.6451387
Z mean eval                  0.6520039
Z variance eval              0.054286398
total_rewards                [1932.99773851 2086.00970709 2989.68682352 4920.30648084 5240.65875782
 4682.54676918 1597.89722035 4780.98541065 5138.44670943 5097.98006363]
total_rewards_mean           3846.751568102841
total_rewards_std            1430.226012079891
total_rewards_max            5240.658757820878
total_rewards_min            1597.8972203494232
Number of train steps total  1672000
Number of env steps total    2946125
Number of rollouts total     0
Train Time (s)               145.07525118999183
(Previous) Eval Time (s)     17.465798298828304
Sample Time (s)              7.154764585196972
Epoch Time (s)               169.6958140740171
Total Train Time (s)         70655.99779767031
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:58:13.568730 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #417 | Epoch Duration: 169.81218957901
2020-01-12 03:58:13.568962 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.64225394
Z variance train             0.054449856
KL Divergence                17.631552
KL Loss                      1.7631552
QF Loss                      38007.28
VF Loss                      199.65028
Policy Loss                  -1532.6261
Q Predictions Mean           1526.394
Q Predictions Std            327.50928
Q Predictions Max            2014.5016
Q Predictions Min            399.532
V Predictions Mean           1524.0303
V Predictions Std            325.06793
V Predictions Max            2002.1306
V Predictions Min            387.30386
Log Pis Mean                 1.3022639
Log Pis Std                  2.9717152
Log Pis Max                  11.153976
Log Pis Min                  -7.1033335
Policy mu Mean               -0.050320536
Policy mu Std                0.64025897
Policy mu Max                2.4114416
Policy mu Min                -2.8184373
Policy log std Mean          -1.1743121
Policy log std Std           0.30587506
Policy log std Max           -0.19670594
Policy log std Min           -2.669764
Z mean eval                  0.87316036
Z variance eval              0.001428975
total_rewards                [4823.18297099 4978.67585731 4176.07930561 2345.47349465 4981.00900277
 5247.84224318   56.06769751 4631.79640019 5216.77777608  919.33624821]
total_rewards_mean           3737.62409964869
total_rewards_std            1820.9827653920868
total_rewards_max            5247.842243180339
total_rewards_min            56.06769751190819
Number of train steps total  1676000
Number of env steps total    2958125
Number of rollouts total     0
Train Time (s)               145.79775725817308
(Previous) Eval Time (s)     21.16659086709842
Sample Time (s)              7.170896745286882
Epoch Time (s)               174.13524487055838
Total Train Time (s)         70830.21868547704
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:01:07.791671 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #418 | Epoch Duration: 174.22255110740662
2020-01-12 04:01:07.791800 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8697649
Z variance train             0.0014303534
KL Divergence                23.890364
KL Loss                      2.3890364
QF Loss                      825.71747
VF Loss                      118.86955
Policy Loss                  -1577.2601
Q Predictions Mean           1569.853
Q Predictions Std            339.77637
Q Predictions Max            2070.5928
Q Predictions Min            398.61548
V Predictions Mean           1581.3579
V Predictions Std            338.46527
V Predictions Max            2076.295
V Predictions Min            420.63647
Log Pis Mean                 1.5590284
Log Pis Std                  3.316954
Log Pis Max                  17.54594
Log Pis Min                  -7.233261
Policy mu Mean               -0.098209545
Policy mu Std                0.6934965
Policy mu Max                2.6808906
Policy mu Min                -4.3422666
Policy log std Mean          -1.1498156
Policy log std Std           0.31770518
Policy log std Max           0.09974587
Policy log std Min           -2.5661762
Z mean eval                  0.6354225
Z variance eval              0.048039716
total_rewards                [1355.46955165  202.79720718 5169.18911377 3090.02206147 5213.83483793
 4919.85217168 5069.39455118 5118.46765667 5108.74351668 1147.22445658]
total_rewards_mean           3639.499512478961
total_rewards_std            1907.6028277118153
total_rewards_max            5213.834837930777
total_rewards_min            202.79720718326757
Number of train steps total  1680000
Number of env steps total    2968538
Number of rollouts total     0
Train Time (s)               145.04600468603894
(Previous) Eval Time (s)     17.35518134990707
Sample Time (s)              7.212138489354402
Epoch Time (s)               169.6133245253004
Total Train Time (s)         70999.91851822473
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:03:57.497480 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #419 | Epoch Duration: 169.70556235313416
2020-01-12 04:03:57.497672 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6339642
Z variance train             0.047712438
KL Divergence                20.429035
KL Loss                      2.0429037
QF Loss                      17564.498
VF Loss                      107.50444
Policy Loss                  -1558.9647
Q Predictions Mean           1549.5509
Q Predictions Std            324.57455
Q Predictions Max            2049.8774
Q Predictions Min            410.82635
V Predictions Mean           1556.6089
V Predictions Std            323.55112
V Predictions Max            2046.9004
V Predictions Min            409.0888
Log Pis Mean                 1.7201046
Log Pis Std                  2.876433
Log Pis Max                  10.243247
Log Pis Min                  -6.6860332
Policy mu Mean               -0.11538939
Policy mu Std                0.70913
Policy mu Max                2.2146637
Policy mu Min                -2.6208336
Policy log std Mean          -1.1541989
Policy log std Std           0.30322602
Policy log std Max           -0.3388847
Policy log std Min           -2.6007013
Z mean eval                  0.79189855
Z variance eval              0.00041442233
total_rewards                [ 235.25924411 1374.95094489  297.35047318  898.44570082 5253.38958778
 2011.75593953 5001.58226743  -10.03205451 4237.61054509 3016.67990399]
total_rewards_mean           2231.6992552300217
total_rewards_std            1917.1732851308768
total_rewards_max            5253.389587776081
total_rewards_min            -10.032054512906214
Number of train steps total  1684000
Number of env steps total    2980262
Number of rollouts total     0
Train Time (s)               146.7145840441808
(Previous) Eval Time (s)     16.287910589948297
Sample Time (s)              7.368622147012502
Epoch Time (s)               170.3711167811416
Total Train Time (s)         71170.38059911132
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:06:47.961833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #420 | Epoch Duration: 170.46401810646057
2020-01-12 04:06:47.961978 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7931878
Z variance train             0.00041478747
KL Divergence                25.078358
KL Loss                      2.5078359
QF Loss                      430.39474
VF Loss                      85.98187
Policy Loss                  -1591.6055
Q Predictions Mean           1583.2864
Q Predictions Std            368.5857
Q Predictions Max            2093.936
Q Predictions Min            394.0773
V Predictions Mean           1591.3049
V Predictions Std            367.6957
V Predictions Max            2092.9314
V Predictions Min            393.3464
Log Pis Mean                 1.6275828
Log Pis Std                  2.9286437
Log Pis Max                  11.733465
Log Pis Min                  -10.318203
Policy mu Mean               -0.07845767
Policy mu Std                0.727349
Policy mu Max                2.764383
Policy mu Min                -2.572224
Policy log std Mean          -1.1057099
Policy log std Std           0.3020643
Policy log std Max           -0.12978578
Policy log std Min           -2.229281
Z mean eval                  0.6890775
Z variance eval              0.00399763
total_rewards                [1028.63977926 2216.35710507 2888.0201555  4846.69153864  547.22273294
  335.69134924 5187.5655491  1694.92094748 1149.44806918 4865.47866929]
total_rewards_mean           2476.003589569522
total_rewards_std            1780.0373152612428
total_rewards_max            5187.565549102041
total_rewards_min            335.69134923709913
Number of train steps total  1688000
Number of env steps total    2990707
Number of rollouts total     0
Train Time (s)               146.980985165108
(Previous) Eval Time (s)     15.598799663130194
Sample Time (s)              7.203854168299586
Epoch Time (s)               169.78363899653777
Total Train Time (s)         71340.2736970447
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:09:37.857867 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #421 | Epoch Duration: 169.89579057693481
2020-01-12 04:09:37.858001 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6836119
Z variance train             0.0039955555
KL Divergence                22.70946
KL Loss                      2.270946
QF Loss                      464.46875
VF Loss                      73.35926
Policy Loss                  -1575.6176
Q Predictions Mean           1572.262
Q Predictions Std            399.04953
Q Predictions Max            2058.7478
Q Predictions Min            386.77258
V Predictions Mean           1575.4277
V Predictions Std            397.00378
V Predictions Max            2048.1858
V Predictions Min            393.77124
Log Pis Mean                 1.5683085
Log Pis Std                  3.1866932
Log Pis Max                  14.469618
Log Pis Min                  -7.001284
Policy mu Mean               -0.03815359
Policy mu Std                0.7139933
Policy mu Max                2.536083
Policy mu Min                -2.6951005
Policy log std Mean          -1.1131254
Policy log std Std           0.31747535
Policy log std Max           -0.093024254
Policy log std Min           -2.359977
Z mean eval                  0.7307411
Z variance eval              0.00056531216
total_rewards                [2254.07257621 2387.00877993 4964.171241   5063.98355704 5156.95008785
  842.66129353 5028.53469709 5205.18435709 5078.13875443 5134.46147144]
total_rewards_mean           4111.516681560215
total_rewards_std            1544.4866755311502
total_rewards_max            5205.184357085793
total_rewards_min            842.6612935280629
Number of train steps total  1692000
Number of env steps total    3000161
Number of rollouts total     0
Train Time (s)               145.5743971033953
(Previous) Eval Time (s)     17.02493701176718
Sample Time (s)              7.265382143203169
Epoch Time (s)               169.86471625836566
Total Train Time (s)         71510.22627286799
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:12:27.814268 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #422 | Epoch Duration: 169.95615530014038
2020-01-12 04:12:27.814453 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.71577233
Z variance train             0.00056768965
KL Divergence                22.20165
KL Loss                      2.220165
QF Loss                      449.14685
VF Loss                      100.2287
Policy Loss                  -1444.3438
Q Predictions Mean           1435.0322
Q Predictions Std            303.76495
Q Predictions Max            1913.7474
Q Predictions Min            322.89362
V Predictions Mean           1446.4131
V Predictions Std            303.06012
V Predictions Max            1932.1866
V Predictions Min            324.3943
Log Pis Mean                 1.7746701
Log Pis Std                  3.0394475
Log Pis Max                  12.831759
Log Pis Min                  -7.4054337
Policy mu Mean               -0.098647654
Policy mu Std                0.71170205
Policy mu Max                2.6767766
Policy mu Min                -2.5247736
Policy log std Mean          -1.1626713
Policy log std Std           0.32470176
Policy log std Max           -0.22660983
Policy log std Min           -2.698326
Z mean eval                  0.9457814
Z variance eval              0.005990573
total_rewards                [1655.83892037 4779.8938614  1977.27173927 3056.01563842 4813.35185862
 4774.63628797 2766.41075053 4307.99927936 4632.02472867 1853.30312991]
total_rewards_mean           3461.6746194523525
total_rewards_std            1267.8284926308677
total_rewards_max            4813.351858622081
total_rewards_min            1655.83892037483
Number of train steps total  1696000
Number of env steps total    3012036
Number of rollouts total     0
Train Time (s)               148.2645442900248
(Previous) Eval Time (s)     16.847666489891708
Sample Time (s)              7.454730371478945
Epoch Time (s)               172.56694115139544
Total Train Time (s)         71682.89430586156
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:15:20.487481 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #423 | Epoch Duration: 172.67287755012512
2020-01-12 04:15:20.487701 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95321447
Z variance train             0.0059454623
KL Divergence                23.925722
KL Loss                      2.3925722
QF Loss                      439.46567
VF Loss                      132.87512
Policy Loss                  -1731.3461
Q Predictions Mean           1722.4626
Q Predictions Std            332.21945
Q Predictions Max            2214.8608
Q Predictions Min            486.95648
V Predictions Mean           1738.3892
V Predictions Std            330.69223
V Predictions Max            2218.0881
V Predictions Min            496.32632
Log Pis Mean                 2.2058935
Log Pis Std                  2.9311795
Log Pis Max                  11.7554
Log Pis Min                  -5.125422
Policy mu Mean               0.028682558
Policy mu Std                0.8036944
Policy mu Max                2.736034
Policy mu Min                -2.5991788
Policy log std Mean          -1.0766944
Policy log std Std           0.3179384
Policy log std Max           -0.16566265
Policy log std Min           -2.4956894
Z mean eval                  0.78971815
Z variance eval              0.011560693
total_rewards                [4985.85153508 4797.33071678 4913.92103307 3422.30626463 5167.37203544
 4892.6001252  5076.43120681 5241.47481268 4772.4469356  4810.67904296]
total_rewards_mean           4808.041370824578
total_rewards_std            485.864563765774
total_rewards_max            5241.474812677274
total_rewards_min            3422.3062646268368
Number of train steps total  1700000
Number of env steps total    3023227
Number of rollouts total     0
Train Time (s)               145.7851431760937
(Previous) Eval Time (s)     21.189988129772246
Sample Time (s)              7.395105344243348
Epoch Time (s)               174.3702366501093
Total Train Time (s)         71857.63173481775
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:18:15.244285 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #424 | Epoch Duration: 174.75642132759094
2020-01-12 04:18:15.244457 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79352206
Z variance train             0.011522347
KL Divergence                18.954899
KL Loss                      1.8954899
QF Loss                      30970.697
VF Loss                      270.89703
Policy Loss                  -1366.9275
Q Predictions Mean           1363.8706
Q Predictions Std            318.90436
Q Predictions Max            1880.6343
Q Predictions Min            327.66333
V Predictions Mean           1378.0505
V Predictions Std            318.24097
V Predictions Max            1894.8656
V Predictions Min            330.91098
Log Pis Mean                 1.7424884
Log Pis Std                  2.5095263
Log Pis Max                  8.94629
Log Pis Min                  -6.497115
Policy mu Mean               -0.18932107
Policy mu Std                0.6297611
Policy mu Max                1.8513918
Policy mu Min                -2.3556418
Policy log std Mean          -1.1762357
Policy log std Std           0.29227167
Policy log std Max           -0.25309217
Policy log std Min           -2.496706
Z mean eval                  2.2920344
Z variance eval              0.0006349455
total_rewards                [3452.06909975 4620.48179237 4536.53707576 3192.39086748  435.36302078
   33.52519157 4217.8786076  1746.72836456 4461.35572175 3578.71260755]
total_rewards_mean           3027.5042349182822
total_rewards_std            1616.243974742307
total_rewards_max            4620.481792369004
total_rewards_min            33.52519157151889
Number of train steps total  1704000
Number of env steps total    3033445
Number of rollouts total     0
Train Time (s)               146.2397422818467
(Previous) Eval Time (s)     19.312967439182103
Sample Time (s)              7.062718774192035
Epoch Time (s)               172.61542849522084
Total Train Time (s)         72030.37536812946
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:21:07.976255 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #425 | Epoch Duration: 172.73166871070862
2020-01-12 04:21:07.976424 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.299745
Z variance train             0.0006315218
KL Divergence                33.70497
KL Loss                      3.3704972
QF Loss                      747.4696
VF Loss                      176.50607
Policy Loss                  -1625.445
Q Predictions Mean           1617.7483
Q Predictions Std            280.1688
Q Predictions Max            2068.2776
Q Predictions Min            418.54984
V Predictions Mean           1617.2075
V Predictions Std            275.11603
V Predictions Max            2045.575
V Predictions Min            415.25235
Log Pis Mean                 2.2363558
Log Pis Std                  2.891068
Log Pis Max                  12.479318
Log Pis Min                  -6.8505898
Policy mu Mean               -0.08048675
Policy mu Std                0.72442544
Policy mu Max                2.6955283
Policy mu Min                -2.8463712
Policy log std Mean          -1.2023633
Policy log std Std           0.30022597
Policy log std Max           -0.29873908
Policy log std Min           -2.5570388
Z mean eval                  1.2220528
Z variance eval              0.00015674111
total_rewards                [4404.17672485 3391.27493861 4819.34104099 4438.07882097 3009.34328214
 4538.82417077   48.84799512 4766.97831775 4646.2831383   226.63617005]
total_rewards_mean           3428.9784599552013
total_rewards_std            1739.6559556818313
total_rewards_max            4819.34104099149
total_rewards_min            48.847995122960405
Number of train steps total  1708000
Number of env steps total    3045445
Number of rollouts total     0
Train Time (s)               146.2040701857768
(Previous) Eval Time (s)     14.850963093806058
Sample Time (s)              7.166495017707348
Epoch Time (s)               168.2215282972902
Total Train Time (s)         72198.68723578006
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:23:56.294889 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #426 | Epoch Duration: 168.3183298110962
2020-01-12 04:23:56.295065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2305998
Z variance train             0.00015776901
KL Divergence                30.028635
KL Loss                      3.0028636
QF Loss                      832.6028
VF Loss                      165.89531
Policy Loss                  -1707.6672
Q Predictions Mean           1697.7544
Q Predictions Std            246.19264
Q Predictions Max            2398.19
Q Predictions Min            476.9846
V Predictions Mean           1713.1824
V Predictions Std            245.76105
V Predictions Max            2471.566
V Predictions Min            501.10248
Log Pis Mean                 1.8891647
Log Pis Std                  3.1029963
Log Pis Max                  11.539145
Log Pis Min                  -8.745475
Policy mu Mean               -0.123076685
Policy mu Std                0.7305985
Policy mu Max                2.2868745
Policy mu Min                -2.957632
Policy log std Mean          -1.1493759
Policy log std Std           0.29118782
Policy log std Max           -0.0982641
Policy log std Min           -2.604617
Z mean eval                  1.3829663
Z variance eval              0.0009162318
total_rewards                [4735.38145926  386.61876172 4909.31680559 1000.47581193 -256.89722578
 4610.23034621 1374.19875545 4784.96240059 1376.46963231 4033.5840266 ]
total_rewards_mean           2695.4340773894505
total_rewards_std            1982.1953106759343
total_rewards_max            4909.316805585676
total_rewards_min            -256.8972257793997
Number of train steps total  1712000
Number of env steps total    3057203
Number of rollouts total     0
Train Time (s)               147.06489003868774
(Previous) Eval Time (s)     15.914757262915373
Sample Time (s)              7.532650416251272
Epoch Time (s)               170.51229771785438
Total Train Time (s)         72369.28797266167
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:26:46.900131 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #427 | Epoch Duration: 170.6049325466156
2020-01-12 04:26:46.900308 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3652494
Z variance train             0.0009122662
KL Divergence                28.944656
KL Loss                      2.8944657
QF Loss                      481.46402
VF Loss                      257.24515
Policy Loss                  -1789.6669
Q Predictions Mean           1783.8684
Q Predictions Std            214.68279
Q Predictions Max            2922.404
Q Predictions Min            604.4234
V Predictions Mean           1801.1101
V Predictions Std            215.97075
V Predictions Max            3007.6155
V Predictions Min            604.60803
Log Pis Mean                 2.1397247
Log Pis Std                  3.2882884
Log Pis Max                  13.113173
Log Pis Min                  -7.463291
Policy mu Mean               0.012728716
Policy mu Std                0.76598686
Policy mu Max                2.622921
Policy mu Min                -2.8935075
Policy log std Mean          -1.1339576
Policy log std Std           0.2947419
Policy log std Max           -0.2624601
Policy log std Min           -2.5979028
Z mean eval                  0.66613823
Z variance eval              0.0004798597
total_rewards                [2920.20271304 5078.4896748   764.86360317  285.8209467  5089.60060544
 5170.5880266  1083.26626559  820.31128166 2435.07464265 5069.1610313 ]
total_rewards_mean           2871.7378790963894
total_rewards_std            1965.3991982849416
total_rewards_max            5170.588026596277
total_rewards_min            285.820946704708
Number of train steps total  1716000
Number of env steps total    3068065
Number of rollouts total     0
Train Time (s)               147.61962771601975
(Previous) Eval Time (s)     14.857337021268904
Sample Time (s)              7.742148268036544
Epoch Time (s)               170.2191130053252
Total Train Time (s)         72539.60155873792
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:29:37.220484 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #428 | Epoch Duration: 170.3200237751007
2020-01-12 04:29:37.220723 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6743254
Z variance train             0.00047910315
KL Divergence                24.634382
KL Loss                      2.4634383
QF Loss                      883.95654
VF Loss                      214.98317
Policy Loss                  -1771.9501
Q Predictions Mean           1757.7534
Q Predictions Std            309.55402
Q Predictions Max            3583.625
Q Predictions Min            1075.8406
V Predictions Mean           1774.1023
V Predictions Std            311.7523
V Predictions Max            3680.3374
V Predictions Min            1095.3458
Log Pis Mean                 2.5247219
Log Pis Std                  3.175313
Log Pis Max                  12.527702
Log Pis Min                  -7.3874893
Policy mu Mean               -0.06641866
Policy mu Std                0.7736442
Policy mu Max                2.697403
Policy mu Min                -2.5428033
Policy log std Mean          -1.1769588
Policy log std Std           0.2985675
Policy log std Max           -0.19280922
Policy log std Min           -2.5949895
Z mean eval                  0.8126408
Z variance eval              0.9573016
total_rewards                [4654.42623069 4823.70618304 4786.70520033 -815.58845609 5027.16997241
  241.44851214 2881.22472679 4975.79632673 5208.37381764 4487.47400282]
total_rewards_mean           3627.073651650051
total_rewards_std            2064.1764559747567
total_rewards_max            5208.37381763724
total_rewards_min            -815.588456088375
Number of train steps total  1720000
Number of env steps total    3079365
Number of rollouts total     0
Train Time (s)               145.11895228084177
(Previous) Eval Time (s)     20.8350589168258
Sample Time (s)              7.421326611191034
Epoch Time (s)               173.3753378088586
Total Train Time (s)         72713.08004327863
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:32:30.705907 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #429 | Epoch Duration: 173.48498439788818
2020-01-12 04:32:30.706155 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80428445
Z variance train             0.9442587
KL Divergence                19.33506
KL Loss                      1.933506
QF Loss                      4090.7646
VF Loss                      858.9716
Policy Loss                  -1713.2004
Q Predictions Mean           1702.6805
Q Predictions Std            492.99448
Q Predictions Max            4469.3545
Q Predictions Min            1020.3621
V Predictions Mean           1715.1707
V Predictions Std            532.5364
V Predictions Max            4707.5664
V Predictions Min            1036.1628
Log Pis Mean                 2.0682786
Log Pis Std                  3.3234189
Log Pis Max                  14.389982
Log Pis Min                  -6.1929474
Policy mu Mean               -0.11685049
Policy mu Std                0.7796704
Policy mu Max                2.197881
Policy mu Min                -2.792061
Policy log std Mean          -1.1377363
Policy log std Std           0.2674063
Policy log std Max           -0.30442452
Policy log std Min           -2.584589
Z mean eval                  1.7540951
Z variance eval              0.0024623272
total_rewards                [-1995.54100875  -979.36013674 -2099.4975522  -2013.86090279
 -2068.93646748 -1916.57362077 -1919.78770893 -2171.24768466
 -1937.25677519 -1953.35918193]
total_rewards_mean           -1905.5421039436562
total_rewards_std            318.77556618170297
total_rewards_max            -979.3601367352207
total_rewards_min            -2171.247684663364
Number of train steps total  1724000
Number of env steps total    3090778
Number of rollouts total     0
Train Time (s)               145.02663035411388
(Previous) Eval Time (s)     24.52430673222989
Sample Time (s)              7.0456146015785635
Epoch Time (s)               176.59655168792233
Total Train Time (s)         72889.79957074765
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:35:27.433205 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #430 | Epoch Duration: 176.72686433792114
2020-01-12 04:35:27.433385 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #430 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7550373
Z variance train             0.002450968
KL Divergence                35.041794
KL Loss                      3.5041795
QF Loss                      531101.2
VF Loss                      3596.5425
Policy Loss                  -3883.7776
Q Predictions Mean           3515.726
Q Predictions Std            635.5844
Q Predictions Max            8599.8545
Q Predictions Min            2244.5627
V Predictions Mean           3871.178
V Predictions Std            657.4535
V Predictions Max            8882.267
V Predictions Min            2435.9495
Log Pis Mean                 20.948547
Log Pis Std                  5.064551
Log Pis Max                  37.180473
Log Pis Min                  7.94468
Policy mu Mean               0.7144475
Policy mu Std                2.3025243
Policy mu Max                4.80477
Policy mu Min                -5.021761
Policy log std Mean          -0.87813777
Policy log std Std           0.39054176
Policy log std Max           0.250165
Policy log std Min           -2.535801
Z mean eval                  3.471377
Z variance eval              0.00018478485
total_rewards                [-2177.07027471 -1909.63609781  -977.31345489 -1758.39938462
 -2007.31525892 -1898.68428989  -777.93214615 -1686.50676071
  -966.34839327 -2117.68505677]
total_rewards_mean           -1627.6891117733562
total_rewards_std            494.1614940773749
total_rewards_max            -777.9321461516541
total_rewards_min            -2177.070274707926
Number of train steps total  1728000
Number of env steps total    3101989
Number of rollouts total     0
Train Time (s)               145.58745687128976
(Previous) Eval Time (s)     23.45302583090961
Sample Time (s)              8.21802874142304
Epoch Time (s)               177.2585114436224
Total Train Time (s)         73067.21574440645
Epoch                        431
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:38:24.855275 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #431 | Epoch Duration: 177.42175793647766
2020-01-12 04:38:24.855439 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #431 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4781146
Z variance train             0.0001858965
KL Divergence                78.40022
KL Loss                      7.8400226
QF Loss                      11687.418
VF Loss                      2284.6824
Policy Loss                  -6904.556
Q Predictions Mean           6784.0522
Q Predictions Std            890.7818
Q Predictions Max            11759.768
Q Predictions Min            3864.103
V Predictions Mean           6887.207
V Predictions Std            930.1692
V Predictions Max            12068.618
V Predictions Min            3864.6094
Log Pis Mean                 10.742569
Log Pis Std                  4.8900604
Log Pis Max                  26.24218
Log Pis Min                  -2.6092582
Policy mu Mean               0.2613918
Policy mu Std                1.5649059
Policy mu Max                5.0321555
Policy mu Min                -4.717443
Policy log std Mean          -1.1160878
Policy log std Std           0.42385516
Policy log std Max           0.17147005
Policy log std Min           -2.3038583
Z mean eval                  4.1335683
Z variance eval              0.009696908
total_rewards                [-2612.69264894 -2541.58521907 -2622.09759396 -2527.02273773
 -2643.81983876 -2688.71211694 -2606.63643768 -2635.47253929
 -2683.05788786 -2546.06624535]
total_rewards_mean           -2610.7163265570402
total_rewards_std            53.98036848954277
total_rewards_max            -2527.022737726956
total_rewards_min            -2688.7121169368993
Number of train steps total  1732000
Number of env steps total    3113322
Number of rollouts total     0
Train Time (s)               144.48542744200677
(Previous) Eval Time (s)     22.907133212778717
Sample Time (s)              7.308692616876215
Epoch Time (s)               174.7012532716617
Total Train Time (s)         73242.00837512128
Epoch                        432
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:41:19.651915 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #432 | Epoch Duration: 174.79634642601013
2020-01-12 04:41:19.652083 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.129953
Z variance train             0.009639475
KL Divergence                94.82266
KL Loss                      9.482266
QF Loss                      59434.57
VF Loss                      4303.7236
Policy Loss                  -9463.307
Q Predictions Mean           9178.258
Q Predictions Std            1781.7865
Q Predictions Max            19026.34
Q Predictions Min            5677.2183
V Predictions Mean           9488.273
V Predictions Std            1849.4775
V Predictions Max            19697.63
V Predictions Min            5798.0093
Log Pis Mean                 18.841719
Log Pis Std                  5.296691
Log Pis Max                  33.50625
Log Pis Min                  6.980826
Policy mu Mean               1.0390592
Policy mu Std                1.9810315
Policy mu Max                4.870183
Policy mu Min                -4.713033
Policy log std Mean          -0.9287987
Policy log std Std           0.41758853
Policy log std Max           0.09936392
Policy log std Min           -2.4759483
Z mean eval                  5.6726456
Z variance eval              0.04975379
total_rewards                [  -35.41410289 -1668.52216918   -42.83990879   -26.56134252
 -1906.41748603 -1913.26373716   -16.63740851 -2349.54570678
 -2799.58272177   -14.55839982]
total_rewards_mean           -1077.3342983441119
total_rewards_std            1087.8783112178842
total_rewards_max            -14.558399815654424
total_rewards_min            -2799.582721769659
Number of train steps total  1736000
Number of env steps total    3124114
Number of rollouts total     0
Train Time (s)               146.13274789694697
(Previous) Eval Time (s)     12.458496208302677
Sample Time (s)              7.696730681695044
Epoch Time (s)               166.2879747869447
Total Train Time (s)         73408.39015727304
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:44:06.039025 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #433 | Epoch Duration: 166.3867495059967
2020-01-12 04:44:06.039305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #433 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.6756177
Z variance train             0.04993195
KL Divergence                156.54851
KL Loss                      15.654851
QF Loss                      104318.75
VF Loss                      12549.678
Policy Loss                  -15332.486
Q Predictions Mean           14961.838
Q Predictions Std            2537.6594
Q Predictions Max            29761.451
Q Predictions Min            10835.898
V Predictions Mean           15289.343
V Predictions Std            2684.246
V Predictions Max            30655.76
V Predictions Min            11229.861
Log Pis Mean                 19.453457
Log Pis Std                  6.2629857
Log Pis Max                  41.020195
Log Pis Min                  4.6606655
Policy mu Mean               0.23101369
Policy mu Std                2.292625
Policy mu Max                5.3194666
Policy mu Min                -9.002875
Policy log std Mean          -1.1249485
Policy log std Std           0.54980916
Policy log std Max           0.3992287
Policy log std Min           -2.947424
Z mean eval                  6.5944796
Z variance eval              0.005723192
total_rewards                [-1952.63880273 -1676.29567918   -80.45247058 -1856.94007598
 -2005.2200322    -50.99487438   -15.57648186 -1936.81343277
 -1623.13131234   -32.38908414]
total_rewards_mean           -1123.045224618452
total_rewards_std            887.4547787475071
total_rewards_max            -15.576481857551949
total_rewards_min            -2005.2200322010588
Number of train steps total  1740000
Number of env steps total    3133439
Number of rollouts total     0
Train Time (s)               146.15135749895126
(Previous) Eval Time (s)     15.002347789239138
Sample Time (s)              7.3792273425497115
Epoch Time (s)               168.5329326307401
Total Train Time (s)         73577.02281209733
Epoch                        434
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:46:54.677172 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #434 | Epoch Duration: 168.63768982887268
2020-01-12 04:46:54.677346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #434 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.5942736
Z variance train             0.00570998
KL Divergence                205.76437
KL Loss                      20.576437
QF Loss                      89030.45
VF Loss                      15145.445
Policy Loss                  -21853.326
Q Predictions Mean           21495.424
Q Predictions Std            2631.3975
Q Predictions Max            36547.215
Q Predictions Min            15064.201
V Predictions Mean           21889.703
V Predictions Std            2665.1125
V Predictions Max            37444.227
V Predictions Min            15633.442
Log Pis Mean                 19.797628
Log Pis Std                  6.8690658
Log Pis Max                  40.69568
Log Pis Min                  1.3120418
Policy mu Mean               0.0706637
Policy mu Std                2.2725885
Policy mu Max                6.219165
Policy mu Min                -6.78705
Policy log std Mean          -1.2177066
Policy log std Std           0.57817227
Policy log std Max           0.5328969
Policy log std Min           -3.05928
Z mean eval                  6.4069147
Z variance eval              0.009940053
total_rewards                [  -17.07018488   -19.31750581 -2159.77618237 -1894.10719697
 -1961.59329322 -1571.58760717 -1917.75377628   -35.4738485
   -32.36677943   -18.07429547]
total_rewards_mean           -962.7120670083286
total_rewards_std            947.7838695106354
total_rewards_max            -17.07018487578929
total_rewards_min            -2159.776182366435
Number of train steps total  1744000
Number of env steps total    3143446
Number of rollouts total     0
Train Time (s)               146.05217060865834
(Previous) Eval Time (s)     11.128413479309529
Sample Time (s)              7.6327703963033855
Epoch Time (s)               164.81335448427126
Total Train Time (s)         73741.92306153523
Epoch                        435
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:49:39.579318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #435 | Epoch Duration: 164.90185022354126
2020-01-12 04:49:39.579451 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.408212
Z variance train             0.009949248
KL Divergence                197.63837
KL Loss                      19.763838
QF Loss                      141647.9
VF Loss                      16014.122
Policy Loss                  -23338.242
Q Predictions Mean           22984.52
Q Predictions Std            1445.6964
Q Predictions Max            32451.527
Q Predictions Min            17154.232
V Predictions Mean           23323.531
V Predictions Std            1436.8428
V Predictions Max            32471.79
V Predictions Min            17466.479
Log Pis Mean                 17.047968
Log Pis Std                  4.937743
Log Pis Max                  33.75503
Log Pis Min                  4.840475
Policy mu Mean               -0.055574566
Policy mu Std                2.0502555
Policy mu Max                6.3854733
Policy mu Min                -6.0630054
Policy log std Mean          -1.3416897
Policy log std Std           0.6296386
Policy log std Max           0.70649123
Policy log std Min           -3.5736613
Z mean eval                  5.704064
Z variance eval              0.035582382
total_rewards                [-1175.10060851  -702.45860941 -1688.28505793  -901.80420159
   -42.06130202 -1672.41510981   -28.72359578 -1579.87275837
  -669.82375612  -702.95033428]
total_rewards_mean           -916.3495333821465
total_rewards_std            581.314853290411
total_rewards_max            -28.723595784827047
total_rewards_min            -1688.2850579316132
Number of train steps total  1748000
Number of env steps total    3155351
Number of rollouts total     0
Train Time (s)               146.04611129127443
(Previous) Eval Time (s)     18.271445041988045
Sample Time (s)              6.396338503807783
Epoch Time (s)               170.71389483707026
Total Train Time (s)         73912.73101319466
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:52:30.395337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #436 | Epoch Duration: 170.81572031974792
2020-01-12 04:52:30.395603 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.695534
Z variance train             0.03607651
KL Divergence                163.81552
KL Loss                      16.381552
QF Loss                      49645.023
VF Loss                      15914.999
Policy Loss                  -21658.592
Q Predictions Mean           21520.492
Q Predictions Std            2168.1921
Q Predictions Max            31840.781
Q Predictions Min            15775.78
V Predictions Mean           21731.629
V Predictions Std            2209.244
V Predictions Max            32867.098
V Predictions Min            16174.719
Log Pis Mean                 12.144533
Log Pis Std                  4.651496
Log Pis Max                  28.563679
Log Pis Min                  1.9501543
Policy mu Mean               0.23563093
Policy mu Std                1.4369409
Policy mu Max                5.0063233
Policy mu Min                -4.199363
Policy log std Mean          -1.6280864
Policy log std Std           0.5156766
Policy log std Max           -0.021588802
Policy log std Min           -3.564745
Z mean eval                  4.830753
Z variance eval              0.017717663
total_rewards                [ -774.50475587   -43.2891728  -1449.26988657  -175.12374072
 -1553.18329967 -1516.38828783  -118.98595785   -18.93630638
 -1464.14903433 -1129.82827846]
total_rewards_mean           -824.3658720488824
total_rewards_std            639.0277431622733
total_rewards_max            -18.936306378551016
total_rewards_min            -1553.183299669537
Number of train steps total  1752000
Number of env steps total    3165152
Number of rollouts total     0
Train Time (s)               146.80822027707472
(Previous) Eval Time (s)     14.126766034867615
Sample Time (s)              7.975065133534372
Epoch Time (s)               168.9100514454767
Total Train Time (s)         74081.73484264081
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:55:19.404325 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #437 | Epoch Duration: 169.00856590270996
2020-01-12 04:55:19.404494 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #437 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.8338785
Z variance train             0.017701812
KL Divergence                131.16486
KL Loss                      13.116486
QF Loss                      106729.14
VF Loss                      15493.879
Policy Loss                  -18627.842
Q Predictions Mean           18510.168
Q Predictions Std            2521.4658
Q Predictions Max            33833.934
Q Predictions Min            14917.626
V Predictions Mean           18608.693
V Predictions Std            2597.535
V Predictions Max            34198.027
V Predictions Min            14018.253
Log Pis Mean                 11.63492
Log Pis Std                  4.8742127
Log Pis Max                  24.955196
Log Pis Min                  0.63839984
Policy mu Mean               -0.3851117
Policy mu Std                1.509134
Policy mu Max                4.5077276
Policy mu Min                -5.066772
Policy log std Mean          -1.3784444
Policy log std Std           0.52490413
Policy log std Max           0.14204156
Policy log std Min           -3.485415
Z mean eval                  4.181504
Z variance eval              0.003880451
total_rewards                [-6.99361973e+02 -1.04923338e+00 -9.39549405e+02 -1.09964271e+03
 -1.23560968e+03 -1.35858197e+03 -1.51064028e+03 -5.44666569e+02
 -3.49223414e+00 -1.58483688e+03]
total_rewards_mean           -897.7430940019749
total_rewards_std            546.30952202514
total_rewards_max            -1.0492333836238528
total_rewards_min            -1584.8368801428057
Number of train steps total  1756000
Number of env steps total    3176763
Number of rollouts total     0
Train Time (s)               146.20783561002463
(Previous) Eval Time (s)     17.58585170377046
Sample Time (s)              8.39365133875981
Epoch Time (s)               172.1873386525549
Total Train Time (s)         74254.02731567249
Epoch                        438
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:58:11.701311 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #438 | Epoch Duration: 172.2966752052307
2020-01-12 04:58:11.701530 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #438 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.183284
Z variance train             0.0039010223
KL Divergence                108.44554
KL Loss                      10.844554
QF Loss                      52708.953
VF Loss                      10252.897
Policy Loss                  -16385.965
Q Predictions Mean           16247.611
Q Predictions Std            2520.4202
Q Predictions Max            33109.906
Q Predictions Min            15050.413
V Predictions Mean           16356.311
V Predictions Std            2579.2495
V Predictions Max            33745.477
V Predictions Min            15129.651
Log Pis Mean                 10.895493
Log Pis Std                  5.3816366
Log Pis Max                  36.031734
Log Pis Min                  -3.6799955
Policy mu Mean               -0.109772384
Policy mu Std                1.4694654
Policy mu Max                5.271853
Policy mu Min                -4.835328
Policy log std Mean          -1.4327644
Policy log std Std           0.5194802
Policy log std Max           0.05260575
Policy log std Min           -2.9368668
Z mean eval                  3.9588878
Z variance eval              0.00070502557
total_rewards                [-2106.74796288 -2036.06314116 -2055.75357476 -2069.29588069
 -1845.93202885 -1921.47728967 -1523.88281699 -2008.54928076
 -1996.31191101 -1922.34981145]
total_rewards_mean           -1948.636369823469
total_rewards_std            160.29048773125226
total_rewards_max            -1523.8828169909223
total_rewards_min            -2106.747962882509
Number of train steps total  1760000
Number of env steps total    3188326
Number of rollouts total     0
Train Time (s)               146.63115145405754
(Previous) Eval Time (s)     21.486421186011285
Sample Time (s)              7.258388078771532
Epoch Time (s)               175.37596071884036
Total Train Time (s)         74429.49374551652
Epoch                        439
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:01:07.173047 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #439 | Epoch Duration: 175.47133994102478
2020-01-12 05:01:07.173284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9599411
Z variance train             0.00070296694
KL Divergence                101.98286
KL Loss                      10.198286
QF Loss                      5487153.5
VF Loss                      17748.682
Policy Loss                  -15744.579
Q Predictions Mean           15498.181
Q Predictions Std            2868.4937
Q Predictions Max            34180.945
Q Predictions Min            13087.716
V Predictions Mean           15792.473
V Predictions Std            2926.8027
V Predictions Max            34580.125
V Predictions Min            13149.689
Log Pis Mean                 16.609505
Log Pis Std                  6.139339
Log Pis Max                  37.01304
Log Pis Min                  2.697989
Policy mu Mean               -0.07878831
Policy mu Std                2.0332046
Policy mu Max                6.697605
Policy mu Min                -6.7494683
Policy log std Mean          -1.2433422
Policy log std Std           0.5590462
Policy log std Max           0.81623936
Policy log std Min           -3.043282
Z mean eval                  3.7116764
Z variance eval              0.014078736
total_rewards                [ -115.56080194 -1731.60876995   -36.57023971 -1663.22503721
 -1331.66891009    -4.40118326  -766.56691862  -903.71747587
 -1770.23321299   -15.33628918]
total_rewards_mean           -833.888883882689
total_rewards_std            716.7582461954227
total_rewards_max            -4.401183261930522
total_rewards_min            -1770.2332129944043
Number of train steps total  1764000
Number of env steps total    3198490
Number of rollouts total     0
Train Time (s)               146.25396741786972
(Previous) Eval Time (s)     15.313383894972503
Sample Time (s)              6.743091267067939
Epoch Time (s)               168.31044257991016
Total Train Time (s)         74597.89227709034
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:03:55.574708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #440 | Epoch Duration: 168.4012587070465
2020-01-12 05:03:55.574848 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #440 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7128265
Z variance train             0.014048512
KL Divergence                101.97301
KL Loss                      10.197301
QF Loss                      71917.875
VF Loss                      10889.714
Policy Loss                  -17095.549
Q Predictions Mean           16890.227
Q Predictions Std            3538.5986
Q Predictions Max            35763.523
Q Predictions Min            11792.311
V Predictions Mean           17063.504
V Predictions Std            3597.476
V Predictions Max            35856.19
V Predictions Min            11020.823
Log Pis Mean                 13.857359
Log Pis Std                  4.764735
Log Pis Max                  30.85064
Log Pis Min                  3.573462
Policy mu Mean               0.15905496
Policy mu Std                1.6448426
Policy mu Max                5.750464
Policy mu Min                -5.2052207
Policy log std Mean          -1.5226454
Policy log std Std           0.5944913
Policy log std Max           0.3505485
Policy log std Min           -3.4854684
Z mean eval                  3.498506
Z variance eval              0.0039988165
total_rewards                [-1257.47896777 -1234.05262526 -1108.6801336    -21.37966899
  -492.95760629  -742.11522514    -1.95724857  -627.14130717
 -1175.14499787 -1277.67956094]
total_rewards_mean           -793.8587341602936
total_rewards_std            472.4546700574425
total_rewards_max            -1.9572485670220807
total_rewards_min            -1277.6795609441847
Number of train steps total  1768000
Number of env steps total    3209921
Number of rollouts total     0
Train Time (s)               146.39874137286097
(Previous) Eval Time (s)     20.557727883104235
Sample Time (s)              7.888922833837569
Epoch Time (s)               174.84539208980277
Total Train Time (s)         74772.83247647015
Epoch                        441
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:06:50.517337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #441 | Epoch Duration: 174.94238996505737
2020-01-12 05:06:50.517476 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4992485
Z variance train             0.0040383125
KL Divergence                98.66675
KL Loss                      9.866675
QF Loss                      47530.297
VF Loss                      9768.822
Policy Loss                  -16730.121
Q Predictions Mean           16520.447
Q Predictions Std            3116.8582
Q Predictions Max            34753.34
Q Predictions Min            8171.8896
V Predictions Mean           16767.73
V Predictions Std            3133.1873
V Predictions Max            35037.01
V Predictions Min            12970.608
Log Pis Mean                 12.536368
Log Pis Std                  4.3789263
Log Pis Max                  24.738354
Log Pis Min                  0.21317673
Policy mu Mean               0.16723834
Policy mu Std                1.5619
Policy mu Max                4.4043055
Policy mu Min                -5.1317005
Policy log std Mean          -1.4494131
Policy log std Std           0.5277626
Policy log std Max           0.05635929
Policy log std Min           -3.3885307
Z mean eval                  3.1461701
Z variance eval              0.0030822377
total_rewards                [-1201.85439656  -848.62104419   -60.902981    -889.09114685
 -1031.72352506 -1090.05866346 -1022.03098918  -899.70813305
  -851.26891458  -894.80385495]
total_rewards_mean           -879.0063648881217
total_rewards_std            293.99287504321086
total_rewards_max            -60.902981002733874
total_rewards_min            -1201.8543965594602
Number of train steps total  1772000
Number of env steps total    3220377
Number of rollouts total     0
Train Time (s)               146.1420074547641
(Previous) Eval Time (s)     23.2620105240494
Sample Time (s)              7.273829255718738
Epoch Time (s)               176.67784723453224
Total Train Time (s)         74949.6016744203
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:09:47.289978 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #442 | Epoch Duration: 176.77240681648254
2020-01-12 05:09:47.290115 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1498966
Z variance train             0.0031042497
KL Divergence                91.5237
KL Loss                      9.1523695
QF Loss                      34914.93
VF Loss                      6382.571
Policy Loss                  -15462.459
Q Predictions Mean           15317.637
Q Predictions Std            2188.7131
Q Predictions Max            32593.48
Q Predictions Min            11548.524
V Predictions Mean           15480.327
V Predictions Std            2206.06
V Predictions Max            32857.496
V Predictions Min            11278.038
Log Pis Mean                 11.430877
Log Pis Std                  3.7699313
Log Pis Max                  22.478724
Log Pis Min                  2.6989324
Policy mu Mean               0.021657798
Policy mu Std                1.4201154
Policy mu Max                4.1847787
Policy mu Min                -4.6408463
Policy log std Mean          -1.5849261
Policy log std Std           0.5202785
Policy log std Max           0.48430932
Policy log std Min           -3.4560518
Z mean eval                  2.744637
Z variance eval              0.0062919543
total_rewards                [-926.7462529  -343.24663617 -639.73393029 -391.83042217 -733.80820967
 -125.75564308 -772.24081914 -986.46171045 -675.93375466 -716.34209944]
total_rewards_mean           -631.2099477974762
total_rewards_std            254.75311052574318
total_rewards_max            -125.75564308181232
total_rewards_min            -986.4617104486946
Number of train steps total  1776000
Number of env steps total    3230934
Number of rollouts total     0
Train Time (s)               146.17595764109865
(Previous) Eval Time (s)     21.58991393027827
Sample Time (s)              7.61448587756604
Epoch Time (s)               175.38035744894296
Total Train Time (s)         75125.06550750742
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:12:42.757051 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #443 | Epoch Duration: 175.46683621406555
2020-01-12 05:12:42.757173 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.750032
Z variance train             0.0064071333
KL Divergence                77.667244
KL Loss                      7.7667246
QF Loss                      38698.14
VF Loss                      9804.894
Policy Loss                  -14066.432
Q Predictions Mean           13947.085
Q Predictions Std            2771.287
Q Predictions Max            30709.986
Q Predictions Min            -197.16055
V Predictions Mean           14041.064
V Predictions Std            2822.972
V Predictions Max            31191.033
V Predictions Min            -409.8197
Log Pis Mean                 10.037181
Log Pis Std                  4.1448355
Log Pis Max                  35.303947
Log Pis Min                  -0.23568368
Policy mu Mean               -0.24921075
Policy mu Std                1.2936836
Policy mu Max                4.937652
Policy mu Min                -4.3390627
Policy log std Mean          -1.540437
Policy log std Std           0.5343765
Policy log std Max           -0.06211996
Policy log std Min           -5.213005
Z mean eval                  2.5240855
Z variance eval              0.0020491586
total_rewards                [ -750.48518736 -1728.93880615 -1138.16572388   -44.63296329
   -11.65783802 -1747.12393906 -1785.71036013  -801.84624339
    -4.19626505 -1562.55067979]
total_rewards_mean           -957.5308006112639
total_rewards_std            707.6084704535012
total_rewards_max            -4.196265051579463
total_rewards_min            -1785.71036013405
Number of train steps total  1780000
Number of env steps total    3242333
Number of rollouts total     0
Train Time (s)               146.03167852014303
(Previous) Eval Time (s)     17.811282538808882
Sample Time (s)              6.233801917172968
Epoch Time (s)               170.07676297612488
Total Train Time (s)         75295.23301257752
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:15:32.929493 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #444 | Epoch Duration: 170.17221665382385
2020-01-12 05:15:32.929664 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5239875
Z variance train             0.002055422
KL Divergence                72.33089
KL Loss                      7.233089
QF Loss                      61926.086
VF Loss                      6485.6924
Policy Loss                  -13005.107
Q Predictions Mean           12892.124
Q Predictions Std            2771.93
Q Predictions Max            28876.705
Q Predictions Min            10061.565
V Predictions Mean           13036.995
V Predictions Std            2813.2295
V Predictions Max            29387.238
V Predictions Min            10402.891
Log Pis Mean                 11.583679
Log Pis Std                  4.9700365
Log Pis Max                  28.70847
Log Pis Min                  -1.6484032
Policy mu Mean               -0.17878067
Policy mu Std                1.6050091
Policy mu Max                6.121757
Policy mu Min                -4.315014
Policy log std Mean          -1.2711775
Policy log std Std           0.5241708
Policy log std Max           0.539639
Policy log std Min           -3.4207773
Z mean eval                  2.5024116
Z variance eval              0.000110567504
total_rewards                [-2576.8497597  -2621.55340408 -2574.31595288 -2583.98545268
 -2599.39775919 -2579.13769385 -2580.77406849 -2580.25061714
 -2553.55148126 -2565.4102924 ]
total_rewards_mean           -2581.5226481681325
total_rewards_std            17.46905661566207
total_rewards_max            -2553.551481261864
total_rewards_min            -2621.553404076362
Number of train steps total  1784000
Number of env steps total    3254105
Number of rollouts total     0
Train Time (s)               146.51367920124903
(Previous) Eval Time (s)     24.954811876174062
Sample Time (s)              6.383232038002461
Epoch Time (s)               177.85172311542556
Total Train Time (s)         75473.16570045473
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:18:30.866100 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #445 | Epoch Duration: 177.9363191127777
2020-01-12 05:18:30.866228 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5145075
Z variance train             0.00011123928
KL Divergence                77.109024
KL Loss                      7.7109027
QF Loss                      74366.56
VF Loss                      29222.23
Policy Loss                  -13806.3
Q Predictions Mean           13576.277
Q Predictions Std            3054.5713
Q Predictions Max            30282.055
Q Predictions Min            -768.863
V Predictions Mean           13866.576
V Predictions Std            2961.8376
V Predictions Max            30810.807
V Predictions Min            11627.619
Log Pis Mean                 16.303083
Log Pis Std                  5.2006025
Log Pis Max                  36.93043
Log Pis Min                  2.7129729
Policy mu Mean               -0.8359095
Policy mu Std                1.8730669
Policy mu Max                5.17195
Policy mu Min                -5.2665095
Policy log std Mean          -1.0571315
Policy log std Std           0.5472672
Policy log std Max           0.34870636
Policy log std Min           -4.614561
Z mean eval                  2.8167706
Z variance eval              4.547991e-05
total_rewards                [  -28.53176666  -579.352255   -1973.83169379  -789.25853375
 -1647.12345519 -1696.88857178  -506.92899052 -2391.13196055
   -64.95318111   -22.91042799]
total_rewards_mean           -970.0910836344107
total_rewards_std            837.6345228929764
total_rewards_max            -22.910427992587792
total_rewards_min            -2391.131960547497
Number of train steps total  1788000
Number of env steps total    3266105
Number of rollouts total     0
Train Time (s)               147.42211386794224
(Previous) Eval Time (s)     14.91639585280791
Sample Time (s)              7.335120516829193
Epoch Time (s)               169.67363023757935
Total Train Time (s)         75643.07434324734
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:21:20.785305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #446 | Epoch Duration: 169.91896200180054
2020-01-12 05:21:20.785507 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #446 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.8123312
Z variance train             4.530639e-05
KL Divergence                81.94016
KL Loss                      8.194016
QF Loss                      288629.75
VF Loss                      23183.996
Policy Loss                  -15911.197
Q Predictions Mean           15644.469
Q Predictions Std            3635.8845
Q Predictions Max            31498.955
Q Predictions Min            12109.769
V Predictions Mean           15972.396
V Predictions Std            3707.9949
V Predictions Max            32044.215
V Predictions Min            12296.827
Log Pis Mean                 18.294172
Log Pis Std                  7.186336
Log Pis Max                  40.545578
Log Pis Min                  2.417825
Policy mu Mean               -0.19822964
Policy mu Std                2.1564424
Policy mu Max                5.051123
Policy mu Min                -5.101853
Policy log std Mean          -1.108131
Policy log std Std           0.62227017
Policy log std Max           0.23397207
Policy log std Min           -4.0603924
Z mean eval                  3.177539
Z variance eval              4.1674775e-06
total_rewards                [-1607.61401791 -2145.94891354  -282.92578314   -58.98495954
 -1248.97554234  -279.55611324 -2436.8120883    -19.3716748
  -436.32083133   -43.58665188]
total_rewards_mean           -856.0096576013768
total_rewards_std            878.3117931933225
total_rewards_max            -19.371674798229066
total_rewards_min            -2436.812088302189
Number of train steps total  1792000
Number of env steps total    3277083
Number of rollouts total     0
Train Time (s)               147.17941076867282
(Previous) Eval Time (s)     18.057910887058824
Sample Time (s)              7.7339125336147845
Epoch Time (s)               172.97123418934643
Total Train Time (s)         75816.1411503707
Epoch                        447
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:24:13.850575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #447 | Epoch Duration: 173.06493163108826
2020-01-12 05:24:13.850713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #447 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.169096
Z variance train             4.1752264e-06
KL Divergence                94.47655
KL Loss                      9.447655
QF Loss                      135426.9
VF Loss                      36055.81
Policy Loss                  -18798.98
Q Predictions Mean           18532.871
Q Predictions Std            2610.8613
Q Predictions Max            33249.57
Q Predictions Min            12222.873
V Predictions Mean           18806.436
V Predictions Std            2607.4373
V Predictions Max            33328.67
V Predictions Min            13728.453
Log Pis Mean                 16.07774
Log Pis Std                  5.473627
Log Pis Max                  36.190434
Log Pis Min                  4.7707143
Policy mu Mean               -0.45545468
Policy mu Std                1.9455062
Policy mu Max                6.6590266
Policy mu Min                -5.1433506
Policy log std Mean          -1.2832937
Policy log std Std           0.64408416
Policy log std Max           0.8660445
Policy log std Min           -3.8213143
Z mean eval                  2.6204126
Z variance eval              2.1718301e-06
total_rewards                [    9.73966394  -287.38415648 -1269.30850119  -858.90320832
  -109.12168961  -256.70031413 -1211.93418008 -1706.90957224
   -10.93320761  -461.6907485 ]
total_rewards_mean           -616.3145914235688
total_rewards_std            575.0227623537594
total_rewards_max            9.739663935353907
total_rewards_min            -1706.9095722378654
Number of train steps total  1796000
Number of env steps total    3288080
Number of rollouts total     0
Train Time (s)               146.3765486162156
(Previous) Eval Time (s)     17.15408883197233
Sample Time (s)              8.162907546386123
Epoch Time (s)               171.69354499457404
Total Train Time (s)         75987.93744861986
Epoch                        448
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:27:05.650275 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #448 | Epoch Duration: 171.79944849014282
2020-01-12 05:27:05.650470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6226938
Z variance train             2.1859069e-06
KL Divergence                86.255264
KL Loss                      8.625526
QF Loss                      115668.69
VF Loss                      12059.089
Policy Loss                  -18177.072
Q Predictions Mean           18011.352
Q Predictions Std            2109.2737
Q Predictions Max            28686.516
Q Predictions Min            14186.135
V Predictions Mean           18137.496
V Predictions Std            2149.418
V Predictions Max            29130.064
V Predictions Min            14284.079
Log Pis Mean                 13.040653
Log Pis Std                  4.723013
Log Pis Max                  51.77312
Log Pis Min                  0.47716177
Policy mu Mean               -0.37666327
Policy mu Std                1.5279837
Policy mu Max                8.29914
Policy mu Min                -5.1006184
Policy log std Mean          -1.5654783
Policy log std Std           0.61325115
Policy log std Max           0.25869906
Policy log std Min           -5.7164516
Z mean eval                  2.9118333
Z variance eval              0.14080402
total_rewards                [    4.03173936  -430.57118328 -1467.27989712 -1099.37135242
    44.2721646    -57.67521794   -26.18248132  -966.65610906
   -64.12624854   -16.9108486 ]
total_rewards_mean           -408.0469434323357
total_rewards_std            531.667805001038
total_rewards_max            44.272164601286825
total_rewards_min            -1467.2798971162483
Number of train steps total  1800000
Number of env steps total    3299466
Number of rollouts total     0
Train Time (s)               146.3088096487336
(Previous) Eval Time (s)     13.721461206674576
Sample Time (s)              8.426753422245383
Epoch Time (s)               168.45702427765355
Total Train Time (s)         76156.48099002708
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:29:54.202532 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #449 | Epoch Duration: 168.55189538002014
2020-01-12 05:29:54.202820 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #449 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9246013
Z variance train             0.14032002
KL Divergence                72.21074
KL Loss                      7.221074
QF Loss                      40033.863
VF Loss                      7894.2944
Policy Loss                  -16195.8
Q Predictions Mean           16095.319
Q Predictions Std            2136.0015
Q Predictions Max            26088.506
Q Predictions Min            12895.813
V Predictions Mean           16191.322
V Predictions Std            2129.0203
V Predictions Max            26033.307
V Predictions Min            12953.095
Log Pis Mean                 11.619814
Log Pis Std                  4.2492476
Log Pis Max                  28.98731
Log Pis Min                  2.3970046
Policy mu Mean               -0.17983578
Policy mu Std                1.3984631
Policy mu Max                4.5653963
Policy mu Min                -4.6634355
Policy log std Mean          -1.6228683
Policy log std Std           0.5795719
Policy log std Max           -0.01262331
Policy log std Min           -4.587324
Z mean eval                  2.4543614
Z variance eval              0.008449772
total_rewards                [-1013.19510896  -607.28395308    -9.24096525  -801.07345444
  -884.48318125  -813.03216149  -962.38108058  -100.5143934
 -1494.17847972 -1168.23499915]
total_rewards_mean           -785.3617777327336
total_rewards_std            429.6726204531113
total_rewards_max            -9.24096525161631
total_rewards_min            -1494.1784797178925
Number of train steps total  1804000
Number of env steps total    3310599
Number of rollouts total     0
Train Time (s)               146.90830183494836
(Previous) Eval Time (s)     21.623331416398287
Sample Time (s)              7.934999136719853
Epoch Time (s)               176.4666323880665
Total Train Time (s)         76333.03172734892
Epoch                        450
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:32:50.756036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #450 | Epoch Duration: 176.55302000045776
2020-01-12 05:32:50.756170 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4298728
Z variance train             0.008409331
KL Divergence                67.307785
KL Loss                      6.7307787
QF Loss                      96696.484
VF Loss                      101983.6
Policy Loss                  -15029.347
Q Predictions Mean           14931.639
Q Predictions Std            1831.0798
Q Predictions Max            23669.732
Q Predictions Min            2401.5054
V Predictions Mean           15094.238
V Predictions Std            1739.7596
V Predictions Max            23745.531
V Predictions Min            6638.25
Log Pis Mean                 11.121911
Log Pis Std                  4.3145514
Log Pis Max                  32.952343
Log Pis Min                  0.46673965
Policy mu Mean               -0.33489537
Policy mu Std                1.3017316
Policy mu Max                4.5237403
Policy mu Min                -5.3972497
Policy log std Mean          -1.6881117
Policy log std Std           0.5432375
Policy log std Max           0.16043484
Policy log std Min           -3.527259
Z mean eval                  1.794108
Z variance eval              0.0009912222
total_rewards                [  46.22542966    4.25415006   12.76973632 -560.53234271   94.11637811
   72.70796315  181.9195166    -5.28100741 -751.9004691   -14.64968182]
total_rewards_mean           -92.0370327133999
total_rewards_std            290.6272830152391
total_rewards_max            181.91951660268293
total_rewards_min            -751.9004691006419
Number of train steps total  1808000
Number of env steps total    3321317
Number of rollouts total     0
Train Time (s)               147.43919320683926
(Previous) Eval Time (s)     9.880653691943735
Sample Time (s)              8.055355079006404
Epoch Time (s)               165.3752019777894
Total Train Time (s)         76498.49048432661
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:35:36.218318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #451 | Epoch Duration: 165.46205592155457
2020-01-12 05:35:36.218434 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #451 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7890213
Z variance train             0.0009844888
KL Divergence                64.62528
KL Loss                      6.462528
QF Loss                      29216.717
VF Loss                      40409.594
Policy Loss                  -13652.304
Q Predictions Mean           13569.321
Q Predictions Std            1573.3043
Q Predictions Max            20978.492
Q Predictions Min            6319.6514
V Predictions Mean           13735.918
V Predictions Std            1564.593
V Predictions Max            21104.51
V Predictions Min            7445.0093
Log Pis Mean                 10.465073
Log Pis Std                  4.626096
Log Pis Max                  27.929724
Log Pis Min                  0.3451984
Policy mu Mean               -0.22690597
Policy mu Std                1.2771848
Policy mu Max                5.0597425
Policy mu Min                -4.153219
Policy log std Mean          -1.6409681
Policy log std Std           0.5408365
Policy log std Max           0.056263685
Policy log std Min           -3.899415
Z mean eval                  1.7360255
Z variance eval              3.5078767e-05
total_rewards                [ -476.17112454  -671.54706848  -455.40235917  -464.84073864
  -512.11656475 -1541.92895313  -506.23370711  -540.64398084
  -536.1002359   -313.52561526]
total_rewards_mean           -601.8510347814963
total_rewards_std            324.5018447358936
total_rewards_max            -313.52561525888257
total_rewards_min            -1541.9289531305626
Number of train steps total  1812000
Number of env steps total    3332880
Number of rollouts total     0
Train Time (s)               147.01227779174224
(Previous) Eval Time (s)     21.72341394983232
Sample Time (s)              6.8405166463926435
Epoch Time (s)               175.5762083879672
Total Train Time (s)         76674.1983273644
Epoch                        452
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:38:31.933868 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #452 | Epoch Duration: 175.71532654762268
2020-01-12 05:38:31.934042 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7292362
Z variance train             3.46924e-05
KL Divergence                58.227554
KL Loss                      5.8227553
QF Loss                      25024.824
VF Loss                      7626.9634
Policy Loss                  -12088.788
Q Predictions Mean           11995.692
Q Predictions Std            1561.3035
Q Predictions Max            18045.857
Q Predictions Min            8159.9316
V Predictions Mean           12109.349
V Predictions Std            1594.7563
V Predictions Max            18419.756
V Predictions Min            8554.337
Log Pis Mean                 10.242242
Log Pis Std                  3.9133856
Log Pis Max                  36.35959
Log Pis Min                  -0.13569117
Policy mu Mean               -0.2973951
Policy mu Std                1.3015682
Policy mu Max                4.959135
Policy mu Min                -4.5047746
Policy log std Mean          -1.530805
Policy log std Std           0.5265787
Policy log std Max           0.11584973
Policy log std Min           -2.981544
Z mean eval                  1.6029915
Z variance eval              1.6233354e-05
total_rewards                [-620.11609423 -259.83976286 -457.41179454 -647.31916306  176.60608897
 -977.27535724 -341.87094077 -605.27297248  151.86555419 -459.9369468 ]
total_rewards_mean           -404.0571388813939
total_rewards_std            339.3787992784334
total_rewards_max            176.60608897460884
total_rewards_min            -977.2753572417247
Number of train steps total  1816000
Number of env steps total    3342877
Number of rollouts total     0
Train Time (s)               145.92712062317878
(Previous) Eval Time (s)     25.128967294935137
Sample Time (s)              7.676974641624838
Epoch Time (s)               178.73306255973876
Total Train Time (s)         76853.14351782482
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:41:30.882998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #453 | Epoch Duration: 178.9488341808319
2020-01-12 05:41:30.883134 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5868251
Z variance train             1.6007782e-05
KL Divergence                57.47695
KL Loss                      5.7476954
QF Loss                      19306.059
VF Loss                      6251.462
Policy Loss                  -11282.833
Q Predictions Mean           11176.244
Q Predictions Std            1182.7104
Q Predictions Max            16966.848
Q Predictions Min            8427.915
V Predictions Mean           11306.018
V Predictions Std            1157.9906
V Predictions Max            16775.805
V Predictions Min            8469.179
Log Pis Mean                 10.361773
Log Pis Std                  3.7954512
Log Pis Max                  23.792835
Log Pis Min                  -2.9418762
Policy mu Mean               -0.27821594
Policy mu Std                1.2887793
Policy mu Max                4.3008275
Policy mu Min                -4.5640497
Policy log std Mean          -1.5511725
Policy log std Std           0.52315587
Policy log std Max           0.16681242
Policy log std Min           -3.0562432
Z mean eval                  2.061781
Z variance eval              2.9425963e-05
total_rewards                [  -19.43209992  -217.38441959    -3.44993789  -306.71082321
  -216.79163976 -1180.76139104  -619.43154908   -65.23232503
   227.44930094   -62.22003054]
total_rewards_mean           -246.39649151140162
total_rewards_std            376.74341504412433
total_rewards_max            227.44930093635546
total_rewards_min            -1180.761391035908
Number of train steps total  1820000
Number of env steps total    3352131
Number of rollouts total     0
Train Time (s)               145.78925307607278
(Previous) Eval Time (s)     20.047460792120546
Sample Time (s)              7.246700704563409
Epoch Time (s)               173.08341457275674
Total Train Time (s)         77026.31634276127
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:44:24.060393 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #454 | Epoch Duration: 173.17715287208557
2020-01-12 05:44:24.060560 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0530872
Z variance train             2.939298e-05
KL Divergence                52.992966
KL Loss                      5.299297
QF Loss                      193186.83
VF Loss                      5397.0186
Policy Loss                  -9568.955
Q Predictions Mean           9494.264
Q Predictions Std            1033.8013
Q Predictions Max            14290.559
Q Predictions Min            -388.57944
V Predictions Mean           9588.315
V Predictions Std            886.1786
V Predictions Max            14622.286
V Predictions Min            4934.4067
Log Pis Mean                 8.186817
Log Pis Std                  3.681702
Log Pis Max                  20.380922
Log Pis Min                  -4.957546
Policy mu Mean               -0.086449556
Policy mu Std                1.0767112
Policy mu Max                3.7904594
Policy mu Min                -3.8989463
Policy log std Mean          -1.597639
Policy log std Std           0.44611943
Policy log std Max           -0.31057537
Policy log std Min           -3.4104724
Z mean eval                  1.6948588
Z variance eval              6.676519e-05
total_rewards                [-198.38549473  331.13246009 -134.11434825 -748.53         58.61012913
 -891.06337319 -268.81386521   57.37153729 -281.49078275  207.33968505]
total_rewards_mean           -186.7944052577759
total_rewards_std            370.61787694026555
total_rewards_max            331.1324600914199
total_rewards_min            -891.0633731935433
Number of train steps total  1824000
Number of env steps total    3363168
Number of rollouts total     0
Train Time (s)               146.05887089390308
(Previous) Eval Time (s)     19.719667359255254
Sample Time (s)              7.795685305260122
Epoch Time (s)               173.57422355841845
Total Train Time (s)         77199.97899722587
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:47:17.726778 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #455 | Epoch Duration: 173.66609358787537
2020-01-12 05:47:17.726925 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6914593
Z variance train             6.679787e-05
KL Divergence                49.680565
KL Loss                      4.9680567
QF Loss                      13253.221
VF Loss                      8500.084
Policy Loss                  -8963.512
Q Predictions Mean           8900.557
Q Predictions Std            1052.7482
Q Predictions Max            12958.75
Q Predictions Min            7270.321
V Predictions Mean           9008.532
V Predictions Std            1060.1085
V Predictions Max            13054.311
V Predictions Min            7369.385
Log Pis Mean                 7.948876
Log Pis Std                  3.8565063
Log Pis Max                  34.978676
Log Pis Min                  -0.22804058
Policy mu Mean               0.061341878
Policy mu Std                1.0998744
Policy mu Max                5.357719
Policy mu Min                -4.0932245
Policy log std Mean          -1.5422435
Policy log std Std           0.43174136
Policy log std Max           0.15872097
Policy log std Min           -3.048265
Z mean eval                  1.3175683
Z variance eval              1.2797976e-05
total_rewards                [ -353.15543397 -1060.72874339  -113.22489447    44.96489384
  -155.51289877   102.37367357  -441.43335339    -9.60585948
  -157.16543333  -590.19238311]
total_rewards_mean           -273.36804325081715
total_rewards_std            334.6719896501662
total_rewards_max            102.37367356877786
total_rewards_min            -1060.7287433939553
Number of train steps total  1828000
Number of env steps total    3374956
Number of rollouts total     0
Train Time (s)               146.29200620297343
(Previous) Eval Time (s)     22.754002775996923
Sample Time (s)              7.671928936615586
Epoch Time (s)               176.71793791558594
Total Train Time (s)         77376.79108318314
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:50:14.541191 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #456 | Epoch Duration: 176.81416153907776
2020-01-12 05:50:14.541334 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3170848
Z variance train             1.2820639e-05
KL Divergence                48.26046
KL Loss                      4.826046
QF Loss                      14721.473
VF Loss                      9463.82
Policy Loss                  -8004.7393
Q Predictions Mean           7958.622
Q Predictions Std            1117.4237
Q Predictions Max            12538.038
Q Predictions Min            888.0793
V Predictions Mean           8026.4463
V Predictions Std            1080.2533
V Predictions Max            12637.199
V Predictions Min            3758.3691
Log Pis Mean                 7.2042193
Log Pis Std                  4.2617836
Log Pis Max                  27.451197
Log Pis Min                  -3.895843
Policy mu Mean               0.10188183
Policy mu Std                1.0790746
Policy mu Max                4.419904
Policy mu Min                -3.515598
Policy log std Mean          -1.4606872
Policy log std Std           0.43783656
Policy log std Max           0.19650364
Policy log std Min           -3.0148416
Z mean eval                  1.4034693
Z variance eval              3.221829e-05
total_rewards                [-1264.29149752    43.69248283    48.06726012  -119.59634702
     4.73503127  -329.06146567    23.04690522   -26.68917677
    53.13777462 -1235.56420278]
total_rewards_mean           -280.2523235692039
total_rewards_std            497.04446338335936
total_rewards_max            53.137774616594115
total_rewards_min            -1264.2914975248757
Number of train steps total  1832000
Number of env steps total    3385244
Number of rollouts total     0
Train Time (s)               146.09103992208838
(Previous) Eval Time (s)     13.560337670147419
Sample Time (s)              7.386509743053466
Epoch Time (s)               167.03788733528927
Total Train Time (s)         77543.93565673754
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:53:01.692113 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #457 | Epoch Duration: 167.15068364143372
2020-01-12 05:53:01.692243 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4005997
Z variance train             3.2197124e-05
KL Divergence                47.651302
KL Loss                      4.7651305
QF Loss                      374555.12
VF Loss                      1912.5496
Policy Loss                  -7450.8296
Q Predictions Mean           7420.302
Q Predictions Std            942.6638
Q Predictions Max            12382.502
Q Predictions Min            6630.718
V Predictions Mean           7472.214
V Predictions Std            963.10345
V Predictions Max            12523.312
V Predictions Min            6567.529
Log Pis Mean                 6.5249743
Log Pis Std                  3.9554632
Log Pis Max                  20.283068
Log Pis Min                  -3.7443883
Policy mu Mean               0.09905371
Policy mu Std                1.0550758
Policy mu Max                4.059328
Policy mu Min                -4.020302
Policy log std Mean          -1.3913436
Policy log std Std           0.3951242
Policy log std Max           -0.014699459
Policy log std Min           -2.9664788
Z mean eval                  1.7151556
Z variance eval              2.1028041e-05
total_rewards                [   9.08114733 -382.14207551 -631.48239719 -200.73074227 -214.28919449
 -290.13618401 -297.5494116  -258.66574792   30.70975535  -38.20680021]
total_rewards_mean           -227.34116505098854
total_rewards_std            188.7546457667827
total_rewards_max            30.70975534603627
total_rewards_min            -631.4823971882541
Number of train steps total  1836000
Number of env steps total    3397148
Number of rollouts total     0
Train Time (s)               146.52086417982355
(Previous) Eval Time (s)     16.091428239364177
Sample Time (s)              7.107653570361435
Epoch Time (s)               169.71994598954916
Total Train Time (s)         77713.74379717559
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:55:51.507063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #458 | Epoch Duration: 169.81471252441406
2020-01-12 05:55:51.507239 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7281606
Z variance train             2.036372e-05
KL Divergence                49.33898
KL Loss                      4.9338984
QF Loss                      9900.723
VF Loss                      5009.6006
Policy Loss                  -6669.5967
Q Predictions Mean           6614.151
Q Predictions Std            823.26416
Q Predictions Max            11976.901
Q Predictions Min            5917.614
V Predictions Mean           6613.8335
V Predictions Std            823.7718
V Predictions Max            12105.953
V Predictions Min            5931.428
Log Pis Mean                 5.462008
Log Pis Std                  3.9669225
Log Pis Max                  25.14159
Log Pis Min                  -2.941768
Policy mu Mean               0.16660544
Policy mu Std                1.0484205
Policy mu Max                3.8428762
Policy mu Min                -3.3055444
Policy log std Mean          -1.2613108
Policy log std Std           0.37791604
Policy log std Max           -0.08272004
Policy log std Min           -2.8863864
Z mean eval                  1.1354798
Z variance eval              9.6497184e-05
total_rewards                [-1122.72978416  -318.5255489   -690.60329431  -802.84712192
  -392.7348654   -211.11623376  -785.03398251  -862.33632261
  -111.44213297  -943.30117199]
total_rewards_mean           -624.0670458531083
total_rewards_std            324.0107719440093
total_rewards_max            -111.44213296883053
total_rewards_min            -1122.7297841581694
Number of train steps total  1840000
Number of env steps total    3408357
Number of rollouts total     0
Train Time (s)               147.3369079111144
(Previous) Eval Time (s)     25.679945884738117
Sample Time (s)              7.484742459375411
Epoch Time (s)               180.50159625522792
Total Train Time (s)         77894.33199971588
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:58:52.100024 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #459 | Epoch Duration: 180.59264969825745
2020-01-12 05:58:52.100215 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #459 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1327207
Z variance train             9.855106e-05
KL Divergence                43.100006
KL Loss                      4.310001
QF Loss                      7695.8345
VF Loss                      3087.828
Policy Loss                  -5811.592
Q Predictions Mean           5796.9863
Q Predictions Std            1083.3958
Q Predictions Max            10913.339
Q Predictions Min            4747.3687
V Predictions Mean           5792.9536
V Predictions Std            1116.4513
V Predictions Max            11106.774
V Predictions Min            4736.735
Log Pis Mean                 5.0451717
Log Pis Std                  3.930085
Log Pis Max                  20.928652
Log Pis Min                  -3.1727087
Policy mu Mean               0.06292183
Policy mu Std                0.9455979
Policy mu Max                3.7121198
Policy mu Min                -3.794617
Policy log std Mean          -1.3509965
Policy log std Std           0.36512655
Policy log std Max           -0.2872311
Policy log std Min           -2.8928356
Z mean eval                  1.1472846
Z variance eval              3.3984456e-05
total_rewards                [-761.56884696 -794.17440682 -749.60733006  102.46628555 -623.1770524
 -836.46570008 -772.13170784  -20.4893438  -705.6036648  -686.1385419 ]
total_rewards_mean           -584.6890309124226
total_rewards_std            319.0285694655475
total_rewards_max            102.46628554718617
total_rewards_min            -836.465700082257
Number of train steps total  1844000
Number of env steps total    3419690
Number of rollouts total     0
Train Time (s)               147.88033078797162
(Previous) Eval Time (s)     20.300722646992654
Sample Time (s)              7.074214982334524
Epoch Time (s)               175.2552684172988
Total Train Time (s)         78069.67629746674
Epoch                        460
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:01:47.448660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #460 | Epoch Duration: 175.34825110435486
2020-01-12 06:01:47.448937 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1574014
Z variance train             3.419119e-05
KL Divergence                42.39788
KL Loss                      4.239788
QF Loss                      14846.684
VF Loss                      2142.1958
Policy Loss                  -5200.585
Q Predictions Mean           5171.8877
Q Predictions Std            1201.1398
Q Predictions Max            10750.772
Q Predictions Min            1175.2297
V Predictions Mean           5210.0146
V Predictions Std            1228.4471
V Predictions Max            10784.753
V Predictions Min            1004.5196
Log Pis Mean                 5.0492516
Log Pis Std                  4.19934
Log Pis Max                  33.8483
Log Pis Min                  -4.6032085
Policy mu Mean               0.10513145
Policy mu Std                0.9850745
Policy mu Max                3.9554517
Policy mu Min                -4.457886
Policy log std Mean          -1.2859433
Policy log std Std           0.34704494
Policy log std Max           -0.12815595
Policy log std Min           -2.5572848
Z mean eval                  1.1576014
Z variance eval              2.1908434e-05
total_rewards                [   37.52189556  -814.23386532    23.6082852     14.49294861
 -1079.68519715  -640.88626148  -311.32783911  -540.50395523
  -743.43319988   226.33285185]
total_rewards_mean           -382.8114336947735
total_rewards_std            420.61270733717845
total_rewards_max            226.33285185343559
total_rewards_min            -1079.6851971484773
Number of train steps total  1848000
Number of env steps total    3431920
Number of rollouts total     0
Train Time (s)               149.59490084694698
(Previous) Eval Time (s)     15.938684701919556
Sample Time (s)              7.9460911033675075
Epoch Time (s)               173.47967665223405
Total Train Time (s)         78243.24795878027
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:04:41.022689 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #461 | Epoch Duration: 173.57360243797302
2020-01-12 06:04:41.022854 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #461 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1547865
Z variance train             2.192722e-05
KL Divergence                41.030304
KL Loss                      4.1030307
QF Loss                      2541.3975
VF Loss                      1016.4119
Policy Loss                  -4304.47
Q Predictions Mean           4278.4883
Q Predictions Std            689.2874
Q Predictions Max            9156.021
Q Predictions Min            3123.9824
V Predictions Mean           4319.6523
V Predictions Std            701.5471
V Predictions Max            9228.539
V Predictions Min            3495.8074
Log Pis Mean                 4.5611057
Log Pis Std                  3.865164
Log Pis Max                  19.694267
Log Pis Min                  -5.991001
Policy mu Mean               -0.035196792
Policy mu Std                0.9674481
Policy mu Max                4.2804704
Policy mu Min                -3.5264714
Policy log std Mean          -1.2396631
Policy log std Std           0.32900515
Policy log std Max           -0.15724456
Policy log std Min           -2.7067096
Z mean eval                  0.92981815
Z variance eval              1.9091789e-05
total_rewards                [ -607.48736272  -860.04338699    15.32875814  -137.22204508
 -1181.23047615  -928.93958173  -456.97963293  -278.56095595
 -1014.17855701  -953.63801777]
total_rewards_mean           -640.2951258195346
total_rewards_std            388.6703348840695
total_rewards_max            15.328758135397806
total_rewards_min            -1181.2304761549963
Number of train steps total  1852000
Number of env steps total    3441995
Number of rollouts total     0
Train Time (s)               147.96116839908063
(Previous) Eval Time (s)     23.064367739018053
Sample Time (s)              7.402572041377425
Epoch Time (s)               178.4281081794761
Total Train Time (s)         78421.76760578854
Epoch                        462
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:07:39.545983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #462 | Epoch Duration: 178.52296257019043
2020-01-12 06:07:39.546206 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9258952
Z variance train             1.9362193e-05
KL Divergence                40.283863
KL Loss                      4.0283866
QF Loss                      3243.7522
VF Loss                      1243.317
Policy Loss                  -4209.087
Q Predictions Mean           4196.4756
Q Predictions Std            979.08954
Q Predictions Max            9672.684
Q Predictions Min            3260.3972
V Predictions Mean           4201.9727
V Predictions Std            983.8823
V Predictions Max            9743.548
V Predictions Min            3324.26
Log Pis Mean                 5.1130905
Log Pis Std                  4.022194
Log Pis Max                  20.997517
Log Pis Min                  -5.657748
Policy mu Mean               -0.05548782
Policy mu Std                1.0081506
Policy mu Max                3.1292713
Policy mu Min                -3.728882
Policy log std Mean          -1.258951
Policy log std Std           0.3721746
Policy log std Max           -0.09613621
Policy log std Min           -2.8686378
Z mean eval                  1.5090271
Z variance eval              1.5809333e-05
total_rewards                [ 202.57884397    7.91787699 -881.9902462  -402.29003377 -613.34638689
 -559.53880455 -561.89526834 -467.48362741   63.70792901 -750.29582953]
total_rewards_mean           -396.26355467201995
total_rewards_std            346.57526303268236
total_rewards_max            202.5788439682106
total_rewards_min            -881.9902462030275
Number of train steps total  1856000
Number of env steps total    3451684
Number of rollouts total     0
Train Time (s)               147.74874881887808
(Previous) Eval Time (s)     18.239955348894
Sample Time (s)              7.548594252672046
Epoch Time (s)               173.53729842044413
Total Train Time (s)         78595.39672843413
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:10:33.177724 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #463 | Epoch Duration: 173.63140058517456
2020-01-12 06:10:33.177851 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4994686
Z variance train             1.5746857e-05
KL Divergence                38.377583
KL Loss                      3.8377583
QF Loss                      4214.973
VF Loss                      4125.9023
Policy Loss                  -3353.6804
Q Predictions Mean           3329.7395
Q Predictions Std            803.21985
Q Predictions Max            7286.461
Q Predictions Min            893.28864
V Predictions Mean           3366.0107
V Predictions Std            801.8903
V Predictions Max            7408.3833
V Predictions Min            1875.2008
Log Pis Mean                 5.1767054
Log Pis Std                  3.76785
Log Pis Max                  21.9856
Log Pis Min                  -6.1795816
Policy mu Mean               -0.17194065
Policy mu Std                1.001279
Policy mu Max                3.691813
Policy mu Min                -3.5993419
Policy log std Mean          -1.2809994
Policy log std Std           0.38625908
Policy log std Max           -0.03670454
Policy log std Min           -2.7010503
Z mean eval                  0.96549445
Z variance eval              9.125089e-06
total_rewards                [ 132.84059192  -34.42391129 -489.54787605 -163.04889242  158.77434823
 -504.75368673  254.16799528 -453.78197036 -412.4764091   138.54505265]
total_rewards_mean           -137.37047578921369
total_rewards_std            289.17187979886637
total_rewards_max            254.1679952761551
total_rewards_min            -504.75368673446883
Number of train steps total  1860000
Number of env steps total    3462087
Number of rollouts total     0
Train Time (s)               147.94108371483162
(Previous) Eval Time (s)     20.08233520993963
Sample Time (s)              7.203730748500675
Epoch Time (s)               175.22714967327192
Total Train Time (s)         78770.71365261683
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:13:28.501600 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #464 | Epoch Duration: 175.3236482143402
2020-01-12 06:13:28.501757 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9551504
Z variance train             9.318214e-06
KL Divergence                39.60658
KL Loss                      3.9606578
QF Loss                      12148.119
VF Loss                      1051.9581
Policy Loss                  -3764.4045
Q Predictions Mean           3748.8787
Q Predictions Std            849.8222
Q Predictions Max            7840.539
Q Predictions Min            3193.2156
V Predictions Mean           3775.6555
V Predictions Std            853.0434
V Predictions Max            7857.2544
V Predictions Min            3224.1377
Log Pis Mean                 5.0653524
Log Pis Std                  3.368479
Log Pis Max                  14.476103
Log Pis Min                  -3.5609164
Policy mu Mean               -0.107543156
Policy mu Std                0.9599206
Policy mu Max                3.4613993
Policy mu Min                -3.317113
Policy log std Mean          -1.3172626
Policy log std Std           0.35825303
Policy log std Max           -0.15791035
Policy log std Min           -2.481338
Z mean eval                  1.0569147
Z variance eval              0.000105465515
total_rewards                [-1299.52920038    34.24982653  -636.03294494  -824.46849858
  -563.53103828  -742.01064919  -260.83359251  -422.30944916
   220.62056535    15.10898449]
total_rewards_mean           -447.87359966846634
total_rewards_std            439.5174599946144
total_rewards_max            220.6205653539569
total_rewards_min            -1299.5292003832105
Number of train steps total  1864000
Number of env steps total    3472840
Number of rollouts total     0
Train Time (s)               148.25935381278396
(Previous) Eval Time (s)     25.225129560101777
Sample Time (s)              7.602202809881419
Epoch Time (s)               181.08668618276715
Total Train Time (s)         78951.89425248234
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:16:29.686075 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #465 | Epoch Duration: 181.1842017173767
2020-01-12 06:16:29.686204 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0539323
Z variance train             0.00010523584
KL Divergence                36.098812
KL Loss                      3.6098812
QF Loss                      4981.9316
VF Loss                      1348.3865
Policy Loss                  -3298.2686
Q Predictions Mean           3276.1504
Q Predictions Std            582.7932
Q Predictions Max            6237.283
Q Predictions Min            2336.5322
V Predictions Mean           3298.624
V Predictions Std            591.2781
V Predictions Max            6257.392
V Predictions Min            2395.7898
Log Pis Mean                 5.2309866
Log Pis Std                  3.8362017
Log Pis Max                  26.001112
Log Pis Min                  -2.790714
Policy mu Mean               -0.10872041
Policy mu Std                0.9446148
Policy mu Max                4.106602
Policy mu Min                -3.8281949
Policy log std Mean          -1.3859906
Policy log std Std           0.37649116
Policy log std Max           -0.010946274
Policy log std Min           -3.289177
Z mean eval                  1.2305691
Z variance eval              2.3314875e-05
total_rewards                [-322.28767892  492.73153365 1550.73511705 1463.08740562 -128.66302961
  678.28998156 -182.14519729  189.23724705  436.03764751  -22.33954277]
total_rewards_mean           415.4683483862138
total_rewards_std            624.6731429254168
total_rewards_max            1550.7351170489583
total_rewards_min            -322.28767891709504
Number of train steps total  1868000
Number of env steps total    3483560
Number of rollouts total     0
Train Time (s)               148.37941644480452
(Previous) Eval Time (s)     24.335750740021467
Sample Time (s)              8.036660219542682
Epoch Time (s)               180.75182740436867
Total Train Time (s)         79132.73753037583
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:19:30.533022 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #466 | Epoch Duration: 180.84672164916992
2020-01-12 06:19:30.533154 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2279422
Z variance train             2.3268725e-05
KL Divergence                40.190323
KL Loss                      4.0190325
QF Loss                      2715.5747
VF Loss                      2001.3383
Policy Loss                  -3373.5725
Q Predictions Mean           3357.6685
Q Predictions Std            556.1645
Q Predictions Max            6185.07
Q Predictions Min            2348.686
V Predictions Mean           3372.3494
V Predictions Std            575.632
V Predictions Max            6296.702
V Predictions Min            2339.7039
Log Pis Mean                 4.394955
Log Pis Std                  3.1805375
Log Pis Max                  14.775993
Log Pis Min                  -4.6789703
Policy mu Mean               0.040857304
Policy mu Std                0.85894054
Policy mu Max                3.6340773
Policy mu Min                -2.9677343
Policy log std Mean          -1.343392
Policy log std Std           0.33896926
Policy log std Max           -0.22128332
Policy log std Min           -2.421115
Z mean eval                  1.0943086
Z variance eval              1.2356977e-05
total_rewards                [-737.50673027 1250.69387254  912.54718606 1579.94953372 -280.43479193
 1331.17018342  135.31019959 -493.77863171  -38.95233124  224.51931642]
total_rewards_mean           388.3517806608657
total_rewards_std            780.6198373734544
total_rewards_max            1579.9495337208339
total_rewards_min            -737.5067302694127
Number of train steps total  1872000
Number of env steps total    3492749
Number of rollouts total     0
Train Time (s)               148.5564217949286
(Previous) Eval Time (s)     21.680115068797022
Sample Time (s)              7.325391119346023
Epoch Time (s)               177.56192798307166
Total Train Time (s)         79310.38192781108
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:22:28.179687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #467 | Epoch Duration: 177.64644026756287
2020-01-12 06:22:28.179809 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0784762
Z variance train             1.2407478e-05
KL Divergence                39.40237
KL Loss                      3.940237
QF Loss                      5016.715
VF Loss                      949.90216
Policy Loss                  -3092.9502
Q Predictions Mean           3084.7666
Q Predictions Std            268.71045
Q Predictions Max            5098.5176
Q Predictions Min            1926.8027
V Predictions Mean           3099.1116
V Predictions Std            260.92377
V Predictions Max            5101.6533
V Predictions Min            2131.5063
Log Pis Mean                 4.209127
Log Pis Std                  2.9792848
Log Pis Max                  26.261244
Log Pis Min                  -2.751596
Policy mu Mean               -0.015820354
Policy mu Std                0.8582002
Policy mu Max                3.8742726
Policy mu Min                -2.2604735
Policy log std Mean          -1.3310077
Policy log std Std           0.30308282
Policy log std Max           -0.2577517
Policy log std Min           -2.583698
Z mean eval                  1.0023615
Z variance eval              0.054663103
total_rewards                [ -88.88664673  639.86836902 2392.84612285  251.13748257 -357.07548354
  131.90880189 2415.61128116   74.15089031  -80.26346922 1784.52822496]
total_rewards_mean           716.3825573264322
total_rewards_std            1012.4543220977065
total_rewards_max            2415.611281160659
total_rewards_min            -357.0754835448942
Number of train steps total  1876000
Number of env steps total    3503278
Number of rollouts total     0
Train Time (s)               147.37645858665928
(Previous) Eval Time (s)     22.63912422209978
Sample Time (s)              6.730565048754215
Epoch Time (s)               176.74614785751328
Total Train Time (s)         79487.21542976052
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:25:25.018330 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #468 | Epoch Duration: 176.83842706680298
2020-01-12 06:25:25.018464 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9967818
Z variance train             0.06525721
KL Divergence                31.416542
KL Loss                      3.1416543
QF Loss                      145429.4
VF Loss                      719.0478
Policy Loss                  -2852.6611
Q Predictions Mean           2834.5422
Q Predictions Std            438.0053
Q Predictions Max            4822.3604
Q Predictions Min            1861.226
V Predictions Mean           2846.1787
V Predictions Std            417.65533
V Predictions Max            4755.096
V Predictions Min            1980.6215
Log Pis Mean                 3.9660702
Log Pis Std                  3.1616852
Log Pis Max                  13.215675
Log Pis Min                  -5.879257
Policy mu Mean               0.042169616
Policy mu Std                0.8310432
Policy mu Max                2.8404677
Policy mu Min                -3.2024853
Policy log std Mean          -1.3161659
Policy log std Std           0.3080628
Policy log std Max           0.11121917
Policy log std Min           -2.2790267
Z mean eval                  4.3726573
Z variance eval              0.033479948
total_rewards                [   53.35163098  -480.3486464    269.96295214   139.87270756
   294.03881174    11.1793596   -482.71896603   458.19613323
   109.64278957 -1887.01881561]
total_rewards_mean           -151.38420432249544
total_rewards_std            648.0170109350369
total_rewards_max            458.19613322513453
total_rewards_min            -1887.0188156092875
Number of train steps total  1880000
Number of env steps total    3513499
Number of rollouts total     0
Train Time (s)               148.69299873430282
(Previous) Eval Time (s)     8.755449851974845
Sample Time (s)              7.134631438180804
Epoch Time (s)               164.58308002445847
Total Train Time (s)         79651.94008287974
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:28:09.747917 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #469 | Epoch Duration: 164.72934460639954
2020-01-12 06:28:09.748108 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.352763
Z variance train             0.033467196
KL Divergence                80.96639
KL Loss                      8.09664
QF Loss                      2279.2183
VF Loss                      486.78687
Policy Loss                  -1097.6683
Q Predictions Mean           1072.3721
Q Predictions Std            229.13681
Q Predictions Max            1824.2246
Q Predictions Min            746.92474
V Predictions Mean           1093.6838
V Predictions Std            219.44992
V Predictions Max            1738.6879
V Predictions Min            719.26447
Log Pis Mean                 4.753346
Log Pis Std                  3.4652436
Log Pis Max                  19.319237
Log Pis Min                  -4.339289
Policy mu Mean               -0.1484845
Policy mu Std                1.140071
Policy mu Max                3.0796206
Policy mu Min                -3.5822253
Policy log std Mean          -0.97626984
Policy log std Std           0.29687476
Policy log std Max           -0.061787367
Policy log std Min           -2.1852715
Z mean eval                  1.6314484
Z variance eval              0.016657451
total_rewards                [  -26.66652577   484.83598436    93.49426726   835.92166878
   402.03948279  1411.97709421  1213.12088704   100.39154233
 -1568.9045929    995.378037  ]
total_rewards_mean           394.15878451033404
total_rewards_std            804.9202844016546
total_rewards_max            1411.977094213046
total_rewards_min            -1568.904592902341
Number of train steps total  1884000
Number of env steps total    3523514
Number of rollouts total     0
Train Time (s)               148.00580214103684
(Previous) Eval Time (s)     20.01201645284891
Sample Time (s)              8.188794095534831
Epoch Time (s)               176.20661268942058
Total Train Time (s)         79828.24390609143
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:31:06.054871 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #470 | Epoch Duration: 176.30663418769836
2020-01-12 06:31:06.055003 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6306814
Z variance train             0.016467448
KL Divergence                34.005615
KL Loss                      3.4005616
QF Loss                      2950.9585
VF Loss                      197.84042
Policy Loss                  -2344.9434
Q Predictions Mean           2335.1084
Q Predictions Std            241.28413
Q Predictions Max            3273.1865
Q Predictions Min            1746.0428
V Predictions Mean           2343.9465
V Predictions Std            239.04588
V Predictions Max            3297.701
V Predictions Min            1775.909
Log Pis Mean                 3.2666926
Log Pis Std                  3.2386642
Log Pis Max                  17.917362
Log Pis Min                  -4.1171694
Policy mu Mean               0.008279169
Policy mu Std                0.78749657
Policy mu Max                4.144146
Policy mu Min                -3.6668134
Policy log std Mean          -1.2762353
Policy log std Std           0.3238139
Policy log std Max           0.03944397
Policy log std Min           -2.4430203
Z mean eval                  0.9293734
Z variance eval              0.026882296
total_rewards                [1902.60667557  268.81134388  139.76560193 2411.01114904  273.89677449
  333.26267176  364.70864226 1038.58077465 -284.86284235   78.32248709]
total_rewards_mean           652.6103278307373
total_rewards_std            821.6267769800756
total_rewards_max            2411.0111490403096
total_rewards_min            -284.8628423542582
Number of train steps total  1888000
Number of env steps total    3535373
Number of rollouts total     0
Train Time (s)               147.34190712310374
(Previous) Eval Time (s)     12.74972628382966
Sample Time (s)              7.208061465993524
Epoch Time (s)               167.29969487292692
Total Train Time (s)         79995.63554300042
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:33:53.450182 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #471 | Epoch Duration: 167.39508628845215
2020-01-12 06:33:53.450324 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9083227
Z variance train             0.026760513
KL Divergence                31.51176
KL Loss                      3.1511762
QF Loss                      46625.53
VF Loss                      392.1058
Policy Loss                  -2407.3115
Q Predictions Mean           2395.0195
Q Predictions Std            249.65828
Q Predictions Max            3492.727
Q Predictions Min            1517.3749
V Predictions Mean           2410.3784
V Predictions Std            247.30292
V Predictions Max            3488.4456
V Predictions Min            1611.9113
Log Pis Mean                 2.6479366
Log Pis Std                  2.9909267
Log Pis Max                  12.265888
Log Pis Min                  -6.665866
Policy mu Mean               -0.0007388771
Policy mu Std                0.7207685
Policy mu Max                2.82962
Policy mu Min                -2.5394475
Policy log std Mean          -1.2723607
Policy log std Std           0.29238427
Policy log std Max           -0.31548524
Policy log std Min           -2.4171224
Z mean eval                  1.0737073
Z variance eval              0.0074240416
total_rewards                [ 186.26533952 -165.38053772 -177.71759509  151.7749352   630.85367299
 -325.91988184  295.76176163 1102.40165845  675.79512105  105.28418756]
total_rewards_mean           247.91186617516004
total_rewards_std            421.52225418243677
total_rewards_max            1102.4016584527058
total_rewards_min            -325.9198818420859
Number of train steps total  1892000
Number of env steps total    3545232
Number of rollouts total     0
Train Time (s)               148.18306762399152
(Previous) Eval Time (s)     10.056848865002394
Sample Time (s)              7.464128938969225
Epoch Time (s)               165.70404542796314
Total Train Time (s)         80161.42807221832
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:36:39.245504 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #472 | Epoch Duration: 165.79508113861084
2020-01-12 06:36:39.245634 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #472 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0759951
Z variance train             0.007401912
KL Divergence                33.45966
KL Loss                      3.345966
QF Loss                      2026.6256
VF Loss                      793.011
Policy Loss                  -2283.5405
Q Predictions Mean           2277.9944
Q Predictions Std            271.85495
Q Predictions Max            3461.3577
Q Predictions Min            1472.5406
V Predictions Mean           2272.0293
V Predictions Std            273.1846
V Predictions Max            3438.6763
V Predictions Min            1477.1775
Log Pis Mean                 2.8064208
Log Pis Std                  3.0497808
Log Pis Max                  14.59741
Log Pis Min                  -5.683853
Policy mu Mean               0.0043203947
Policy mu Std                0.76620173
Policy mu Max                3.2244473
Policy mu Min                -2.742072
Policy log std Mean          -1.2311889
Policy log std Std           0.2934198
Policy log std Max           0.23904967
Policy log std Min           -2.3915927
Z mean eval                  0.7250615
Z variance eval              0.0017858429
total_rewards                [ 1567.73889406   801.17276252  1507.66872396  1419.39992544
   805.47936668 -1131.56364305  -203.08008236  3190.93346563
  1932.36445864  3000.35295145]
total_rewards_mean           1289.0466822965102
total_rewards_std            1251.3877136252408
total_rewards_max            3190.933465625347
total_rewards_min            -1131.5636430508039
Number of train steps total  1896000
Number of env steps total    3556031
Number of rollouts total     0
Train Time (s)               148.0598990637809
(Previous) Eval Time (s)     17.75516542000696
Sample Time (s)              8.492174487560987
Epoch Time (s)               174.30723897134885
Total Train Time (s)         80335.86148270546
Epoch                        473
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:39:33.683490 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #473 | Epoch Duration: 174.43774151802063
2020-01-12 06:39:33.683679 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72177136
Z variance train             0.0017787669
KL Divergence                30.614096
KL Loss                      3.0614097
QF Loss                      4744.1797
VF Loss                      324.89352
Policy Loss                  -1999.3098
Q Predictions Mean           1981.769
Q Predictions Std            253.34741
Q Predictions Max            2968.3328
Q Predictions Min            1092.359
V Predictions Mean           1988.6
V Predictions Std            254.04167
V Predictions Max            3007.21
V Predictions Min            1112.7642
Log Pis Mean                 2.8246558
Log Pis Std                  2.7499878
Log Pis Max                  14.556831
Log Pis Min                  -7.037307
Policy mu Mean               0.012996391
Policy mu Std                0.78874195
Policy mu Max                2.810055
Policy mu Min                -2.6626244
Policy log std Mean          -1.2065735
Policy log std Std           0.28828874
Policy log std Max           -0.3933034
Policy log std Min           -2.3986626
Z mean eval                  0.7807868
Z variance eval              0.0013069129
total_rewards                [2620.38599555  738.0556222  3510.63284715 1243.1319328  3983.37492127
 1195.85381495  224.80631784 2181.50440476  337.45649925 1725.37180321]
total_rewards_mean           1776.0574158989034
total_rewards_std            1222.0841058693366
total_rewards_max            3983.3749212697317
total_rewards_min            224.80631783866914
Number of train steps total  1900000
Number of env steps total    3566729
Number of rollouts total     0
Train Time (s)               147.87957631098107
(Previous) Eval Time (s)     19.754882929380983
Sample Time (s)              7.485087345354259
Epoch Time (s)               175.1195465857163
Total Train Time (s)         80511.06927484553
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:42:28.897579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #474 | Epoch Duration: 175.2137634754181
2020-01-12 06:42:28.897720 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77016014
Z variance train             0.0013092465
KL Divergence                30.715298
KL Loss                      3.0715299
QF Loss                      1184.5117
VF Loss                      614.28076
Policy Loss                  -1824.6278
Q Predictions Mean           1822.4198
Q Predictions Std            266.44592
Q Predictions Max            2454.1724
Q Predictions Min            919.93176
V Predictions Mean           1838.176
V Predictions Std            260.95572
V Predictions Max            2486.6052
V Predictions Min            930.20856
Log Pis Mean                 2.2418122
Log Pis Std                  3.091918
Log Pis Max                  15.062527
Log Pis Min                  -7.1998997
Policy mu Mean               0.0093769375
Policy mu Std                0.7573174
Policy mu Max                3.1426742
Policy mu Min                -3.150075
Policy log std Mean          -1.1672088
Policy log std Std           0.28319004
Policy log std Max           0.08154464
Policy log std Min           -2.157644
Z mean eval                  3.7560525
Z variance eval              0.000104471306
total_rewards                [ 254.56742838  725.7187769   919.53661666   69.31660474  964.33795823
 3215.15551981 -446.38284     387.24478308  995.36505043  487.82230259]
total_rewards_mean           757.2682200822109
total_rewards_std            924.7910135267713
total_rewards_max            3215.155519811881
total_rewards_min            -446.3828399998052
Number of train steps total  1904000
Number of env steps total    3577367
Number of rollouts total     0
Train Time (s)               147.76922325091437
(Previous) Eval Time (s)     9.39796139812097
Sample Time (s)              7.745114170946181
Epoch Time (s)               164.91229881998152
Total Train Time (s)         80676.07030671462
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:45:13.902749 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #475 | Epoch Duration: 165.00492930412292
2020-01-12 06:45:13.902880 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7432067
Z variance train             0.00010404787
KL Divergence                73.51783
KL Loss                      7.3517833
QF Loss                      1143.5797
VF Loss                      292.3486
Policy Loss                  -762.49915
Q Predictions Mean           753.40564
Q Predictions Std            162.53308
Q Predictions Max            1262.8206
Q Predictions Min            342.90094
V Predictions Mean           758.5608
V Predictions Std            161.12038
V Predictions Max            1267.8557
V Predictions Min            353.55807
Log Pis Mean                 2.6541603
Log Pis Std                  2.8581727
Log Pis Max                  13.175014
Log Pis Min                  -6.9284825
Policy mu Mean               -0.1371724
Policy mu Std                0.88565075
Policy mu Max                3.4231815
Policy mu Min                -3.4328964
Policy log std Mean          -1.033627
Policy log std Std           0.29605305
Policy log std Max           0.15848732
Policy log std Min           -2.5004168
Z mean eval                  2.0469708
Z variance eval              0.00011012895
total_rewards                [ 218.14691016 1220.57878533  751.94948988 1764.00949388 -671.10043501
 1213.30249924 2339.77116256  862.08406905 1072.53376366 -571.4569651 ]
total_rewards_mean           819.9818773644723
total_rewards_std            900.4412198648915
total_rewards_max            2339.7711625583306
total_rewards_min            -671.1004350143589
Number of train steps total  1908000
Number of env steps total    3586622
Number of rollouts total     0
Train Time (s)               145.43824985018
(Previous) Eval Time (s)     21.424984036944807
Sample Time (s)              6.422847305890173
Epoch Time (s)               173.28608119301498
Total Train Time (s)         80849.44187368872
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:48:07.277317 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #476 | Epoch Duration: 173.37434077262878
2020-01-12 06:48:07.277448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.041883
Z variance train             0.000110955225
KL Divergence                43.52166
KL Loss                      4.352166
QF Loss                      1007.87866
VF Loss                      431.36966
Policy Loss                  -2233.109
Q Predictions Mean           2228.6262
Q Predictions Std            261.53937
Q Predictions Max            2721.5044
Q Predictions Min            921.7295
V Predictions Mean           2242.5393
V Predictions Std            261.4387
V Predictions Max            2700.1614
V Predictions Min            976.18634
Log Pis Mean                 2.03581
Log Pis Std                  2.899427
Log Pis Max                  13.671572
Log Pis Min                  -5.776041
Policy mu Mean               0.02242396
Policy mu Std                0.7411155
Policy mu Max                2.5568094
Policy mu Min                -3.297153
Policy log std Mean          -1.1377571
Policy log std Std           0.27544606
Policy log std Max           0.16444623
Policy log std Min           -2.341895
Z mean eval                  4.276595
Z variance eval              1.8196619e-05
total_rewards                [  -11.139314    -314.15600987  -350.15942436  -296.25200662
  -439.93441316  -270.31738184 -1277.39219394     1.52483582
     1.9512256    -22.99234174]
total_rewards_mean           -297.88670241058315
total_rewards_std            363.4156647883195
total_rewards_max            1.9512255958822973
total_rewards_min            -1277.3921939374527
Number of train steps total  1912000
Number of env steps total    3598677
Number of rollouts total     0
Train Time (s)               147.12546565989032
(Previous) Eval Time (s)     12.471411161124706
Sample Time (s)              7.471262346487492
Epoch Time (s)               167.06813916750252
Total Train Time (s)         81016.59344373085
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:50:54.433898 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #477 | Epoch Duration: 167.15633940696716
2020-01-12 06:50:54.434071 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #477 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2765174
Z variance train             1.8225715e-05
KL Divergence                90.067566
KL Loss                      9.006757
QF Loss                      710.65717
VF Loss                      188.68486
Policy Loss                  -594.6512
Q Predictions Mean           588.29626
Q Predictions Std            116.0164
Q Predictions Max            1004.65985
Q Predictions Min            227.66417
V Predictions Mean           594.5247
V Predictions Std            116.492836
V Predictions Max            1051.9854
V Predictions Min            231.57603
Log Pis Mean                 1.2965288
Log Pis Std                  2.703315
Log Pis Max                  15.923839
Log Pis Min                  -7.174333
Policy mu Mean               -0.013288058
Policy mu Std                0.76411396
Policy mu Max                3.029242
Policy mu Min                -2.4143348
Policy log std Mean          -1.0110337
Policy log std Std           0.25971153
Policy log std Max           0.18275666
Policy log std Min           -1.7793123
Z mean eval                  3.1301136
Z variance eval              4.364759e-05
total_rewards                [  95.47938779  -53.48653415  185.8194328   544.00401473 1249.0264813
  187.92644614 1198.63845053  -46.87657729   30.8311574    41.74675508]
total_rewards_mean           343.3109014332203
total_rewards_std            469.13015279539877
total_rewards_max            1249.0264813045324
total_rewards_min            -53.486534154216486
Number of train steps total  1916000
Number of env steps total    3609722
Number of rollouts total     0
Train Time (s)               148.1644321968779
(Previous) Eval Time (s)     13.099777644965798
Sample Time (s)              7.455973946023732
Epoch Time (s)               168.72018378786743
Total Train Time (s)         81185.40628422657
Epoch                        478
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:53:43.250485 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #478 | Epoch Duration: 168.8162841796875
2020-01-12 06:53:43.250647 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.13111
Z variance train             4.4186563e-05
KL Divergence                62.83021
KL Loss                      6.2830215
QF Loss                      575.8749
VF Loss                      149.67357
Policy Loss                  -767.12494
Q Predictions Mean           761.13763
Q Predictions Std            136.32983
Q Predictions Max            1343.6929
Q Predictions Min            347.4822
V Predictions Mean           768.02234
V Predictions Std            135.09897
V Predictions Max            1345.1726
V Predictions Min            346.19867
Log Pis Mean                 1.526191
Log Pis Std                  2.4258063
Log Pis Max                  8.457172
Log Pis Min                  -8.532937
Policy mu Mean               -0.028038785
Policy mu Std                0.7323719
Policy mu Max                2.4611783
Policy mu Min                -2.596137
Policy log std Mean          -1.0775986
Policy log std Std           0.25648832
Policy log std Max           -0.09913957
Policy log std Min           -1.865125
Z mean eval                  1.1484871
Z variance eval              0.00023350058
total_rewards                [  64.70596076  474.67150267  496.27394366   39.94361243 -134.75418009
   58.05653707 1615.95888556  -57.49992448  919.96887211  175.42343157]
total_rewards_mean           365.27486412632004
total_rewards_std            515.4028201500986
total_rewards_max            1615.9588855599818
total_rewards_min            -134.75418008732336
Number of train steps total  1920000
Number of env steps total    3618603
Number of rollouts total     0
Train Time (s)               147.56905968906358
(Previous) Eval Time (s)     12.935387190897018
Sample Time (s)              7.931770177092403
Epoch Time (s)               168.436217057053
Total Train Time (s)         81353.93990368396
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:56:31.788561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #479 | Epoch Duration: 168.53779435157776
2020-01-12 06:56:31.788743 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1523349
Z variance train             0.00023349149
KL Divergence                35.04637
KL Loss                      3.5046372
QF Loss                      943.7732
VF Loss                      278.89392
Policy Loss                  -1397.843
Q Predictions Mean           1387.0132
Q Predictions Std            232.46278
Q Predictions Max            2026.8099
Q Predictions Min            584.7229
V Predictions Mean           1401.9569
V Predictions Std            232.20575
V Predictions Max            2017.0903
V Predictions Min            597.7649
Log Pis Mean                 2.962514
Log Pis Std                  2.7312894
Log Pis Max                  17.004028
Log Pis Min                  -6.547989
Policy mu Mean               0.0065829693
Policy mu Std                0.811399
Policy mu Max                2.6741061
Policy mu Min                -2.918825
Policy log std Mean          -1.1891177
Policy log std Std           0.31084508
Policy log std Max           -0.03864324
Policy log std Min           -2.5626302
Z mean eval                  0.7470652
Z variance eval              0.00047368027
total_rewards                [2503.29474589  845.92053506 2074.63868072  445.76361764 4050.91634562
 1483.86739578 4161.27858646 4363.53887155 3839.62602434 4075.04852369]
total_rewards_mean           2784.3893326760162
total_rewards_std            1423.8645496673646
total_rewards_max            4363.538871553705
total_rewards_min            445.7636176371449
Number of train steps total  1924000
Number of env steps total    3627879
Number of rollouts total     0
Train Time (s)               150.912281868048
(Previous) Eval Time (s)     20.05512822372839
Sample Time (s)              7.923218499403447
Epoch Time (s)               178.89062859117985
Total Train Time (s)         81532.93747878866
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:59:30.793502 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #480 | Epoch Duration: 179.00462293624878
2020-01-12 06:59:30.793678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7447759
Z variance train             0.00046936033
KL Divergence                31.357918
KL Loss                      3.1357918
QF Loss                      866.93994
VF Loss                      235.91064
Policy Loss                  -1714.0767
Q Predictions Mean           1705.1559
Q Predictions Std            334.99237
Q Predictions Max            2345.0806
Q Predictions Min            673.29614
V Predictions Mean           1708.0537
V Predictions Std            333.88647
V Predictions Max            2329.2292
V Predictions Min            665.0971
Log Pis Mean                 2.1858706
Log Pis Std                  2.4921672
Log Pis Max                  11.157324
Log Pis Min                  -8.776588
Policy mu Mean               0.029982854
Policy mu Std                0.71071154
Policy mu Max                3.8488703
Policy mu Min                -2.5493598
Policy log std Mean          -1.1818678
Policy log std Std           0.27880347
Policy log std Max           0.096624136
Policy log std Min           -2.080783
Z mean eval                  0.87781334
Z variance eval              0.0008011276
total_rewards                [3875.83539304 1210.25751198 1545.71697299 2435.59244522  997.53279549
  765.14490773 3693.98155356 3007.3188194   931.77176607  145.2962176 ]
total_rewards_mean           1860.8448383073824
total_rewards_std            1238.5489033069841
total_rewards_max            3875.8353930356893
total_rewards_min            145.29621759728656
Number of train steps total  1928000
Number of env steps total    3639586
Number of rollouts total     0
Train Time (s)               148.44545076508075
(Previous) Eval Time (s)     14.969400434289128
Sample Time (s)              7.319969943724573
Epoch Time (s)               170.73482114309445
Total Train Time (s)         81703.76266089687
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:02:21.628087 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #481 | Epoch Duration: 170.8342764377594
2020-01-12 07:02:21.628264 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88254166
Z variance train             0.0008066627
KL Divergence                31.676344
KL Loss                      3.1676345
QF Loss                      842.8109
VF Loss                      768.60925
Policy Loss                  -1741.992
Q Predictions Mean           1736.8402
Q Predictions Std            360.48676
Q Predictions Max            2314.2126
Q Predictions Min            163.80457
V Predictions Mean           1756.2056
V Predictions Std            361.46115
V Predictions Max            2317.0593
V Predictions Min            220.02525
Log Pis Mean                 2.163561
Log Pis Std                  3.304251
Log Pis Max                  27.403683
Log Pis Min                  -8.431429
Policy mu Mean               0.07786353
Policy mu Std                0.75352055
Policy mu Max                3.5522356
Policy mu Min                -4.2575274
Policy log std Mean          -1.1571522
Policy log std Std           0.31010526
Policy log std Max           0.1562475
Policy log std Min           -2.596126
Z mean eval                  1.0390561
Z variance eval              0.0061808093
total_rewards                [3956.05102917  744.13267026  536.87567758  109.39620075 4294.40410632
   50.04665731  105.74909994 3105.61932949 1910.57628479   85.98983487]
total_rewards_mean           1489.8840890476442
total_rewards_std            1614.4625046785557
total_rewards_max            4294.404106321908
total_rewards_min            50.04665730814504
Number of train steps total  1932000
Number of env steps total    3650140
Number of rollouts total     0
Train Time (s)               147.19460494909436
(Previous) Eval Time (s)     11.56326539022848
Sample Time (s)              7.355616648681462
Epoch Time (s)               166.1134869880043
Total Train Time (s)         81869.97229603399
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:05:07.843265 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #482 | Epoch Duration: 166.21486163139343
2020-01-12 07:05:07.843478 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0335186
Z variance train             0.0061742575
KL Divergence                30.395512
KL Loss                      3.0395513
QF Loss                      752.3572
VF Loss                      228.6752
Policy Loss                  -1695.6562
Q Predictions Mean           1691.027
Q Predictions Std            369.30737
Q Predictions Max            2232.3374
Q Predictions Min            194.14897
V Predictions Mean           1701.3983
V Predictions Std            370.37134
V Predictions Max            2258.2954
V Predictions Min            229.04828
Log Pis Mean                 1.6569676
Log Pis Std                  2.7750838
Log Pis Max                  13.04154
Log Pis Min                  -4.9883757
Policy mu Mean               0.017659161
Policy mu Std                0.72016126
Policy mu Max                2.891527
Policy mu Min                -2.6098416
Policy log std Mean          -1.1116905
Policy log std Std           0.29587635
Policy log std Max           -0.05945921
Policy log std Min           -2.3153398
Z mean eval                  1.2678344
Z variance eval              0.0005871254
total_rewards                [4313.59436812 4383.15773809  822.52214235  132.34204084 2131.93233313
 4290.9115444  2124.20370856  226.81093107 1761.31327941 2230.41383964]
total_rewards_mean           2241.720192560461
total_rewards_std            1544.598436999867
total_rewards_max            4383.1577380882245
total_rewards_min            132.34204084167288
Number of train steps total  1936000
Number of env steps total    3661948
Number of rollouts total     0
Train Time (s)               147.9894919139333
(Previous) Eval Time (s)     16.09445940889418
Sample Time (s)              7.744697603397071
Epoch Time (s)               171.82864892622456
Total Train Time (s)         82041.97669424582
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:07:59.852692 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #483 | Epoch Duration: 172.00904846191406
2020-01-12 07:07:59.852879 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2090839
Z variance train             0.0005839865
KL Divergence                33.706856
KL Loss                      3.3706856
QF Loss                      931.8572
VF Loss                      898.4773
Policy Loss                  -1826.4126
Q Predictions Mean           1831.1147
Q Predictions Std            350.5873
Q Predictions Max            2396.1382
Q Predictions Min            516.37213
V Predictions Mean           1852.2332
V Predictions Std            352.53198
V Predictions Max            2406.1436
V Predictions Min            533.5156
Log Pis Mean                 1.8057795
Log Pis Std                  2.995319
Log Pis Max                  13.018604
Log Pis Min                  -6.814311
Policy mu Mean               -0.02694207
Policy mu Std                0.67580605
Policy mu Max                2.815382
Policy mu Min                -2.7232077
Policy log std Mean          -1.2005147
Policy log std Std           0.2839719
Policy log std Max           -0.4343784
Policy log std Min           -2.3314278
Z mean eval                  1.1778948
Z variance eval              0.0021689497
total_rewards                [1474.3654776  3492.88993239  174.67515718 2053.08056164  874.61993329
 2198.1402436    19.65749301  389.61728932 4489.35193148 2687.5848855 ]
total_rewards_mean           1785.3982905021435
total_rewards_std            1409.594841650258
total_rewards_max            4489.351931483272
total_rewards_min            19.65749301347842
Number of train steps total  1940000
Number of env steps total    3674232
Number of rollouts total     0
Train Time (s)               148.59835044387728
(Previous) Eval Time (s)     14.604545267298818
Sample Time (s)              8.685066388454288
Epoch Time (s)               171.88796209963039
Total Train Time (s)         82213.95579956844
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:10:51.834591 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #484 | Epoch Duration: 171.9815878868103
2020-01-12 07:10:51.834735 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1852463
Z variance train             0.002170634
KL Divergence                33.570854
KL Loss                      3.3570855
QF Loss                      30971.719
VF Loss                      212.37012
Policy Loss                  -1818.9877
Q Predictions Mean           1812.9434
Q Predictions Std            403.72964
Q Predictions Max            2410.7126
Q Predictions Min            505.34897
V Predictions Mean           1820.7864
V Predictions Std            403.08698
V Predictions Max            2409.9158
V Predictions Min            514.165
Log Pis Mean                 1.5815868
Log Pis Std                  3.114634
Log Pis Max                  12.980673
Log Pis Min                  -7.4958863
Policy mu Mean               0.13938433
Policy mu Std                0.6936424
Policy mu Max                3.2079983
Policy mu Min                -2.9079006
Policy log std Mean          -1.1406002
Policy log std Std           0.29251626
Policy log std Max           -0.14528227
Policy log std Min           -2.467614
Z mean eval                  3.5461006
Z variance eval              0.2614442
total_rewards                [ 252.03740693  273.66773478  317.84258744  346.32450446  714.94760191
 1442.2299172   838.31550615  293.09273536 4146.87344278 1108.45145772]
total_rewards_mean           973.378289473542
total_rewards_std            1126.4903880465395
total_rewards_max            4146.8734427774025
total_rewards_min            252.03740692732595
Number of train steps total  1944000
Number of env steps total    3686531
Number of rollouts total     0
Train Time (s)               145.81285720178857
(Previous) Eval Time (s)     11.916416425723583
Sample Time (s)              8.219166533090174
Epoch Time (s)               165.94844016060233
Total Train Time (s)         82380.01275336603
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:13:37.899498 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #485 | Epoch Duration: 166.06465554237366
2020-01-12 07:13:37.899685 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5532928
Z variance train             0.26123995
KL Divergence                62.326057
KL Loss                      6.232606
QF Loss                      774.3185
VF Loss                      149.54071
Policy Loss                  -754.26984
Q Predictions Mean           744.22485
Q Predictions Std            193.81529
Q Predictions Max            1356.1444
Q Predictions Min            258.1305
V Predictions Mean           752.8896
V Predictions Std            193.46252
V Predictions Max            1304.7366
V Predictions Min            220.46204
Log Pis Mean                 1.9933733
Log Pis Std                  3.5366213
Log Pis Max                  13.050797
Log Pis Min                  -7.6824155
Policy mu Mean               -0.020621983
Policy mu Std                0.7589687
Policy mu Max                3.1527832
Policy mu Min                -2.8876565
Policy log std Mean          -1.1635702
Policy log std Std           0.3018236
Policy log std Max           -0.29313374
Policy log std Min           -2.1334562
Z mean eval                  1.010023
Z variance eval              0.0032056808
total_rewards                [ 511.33056493 2237.40689941 3676.24795018 4188.82023985  713.16737978
 4228.59319518 4330.12189947  950.00933565  177.08317648 2345.31280011]
total_rewards_mean           2335.809344103221
total_rewards_std            1591.9278174233289
total_rewards_max            4330.121899466346
total_rewards_min            177.08317648091463
Number of train steps total  1948000
Number of env steps total    3698080
Number of rollouts total     0
Train Time (s)               145.1800966169685
(Previous) Eval Time (s)     20.964144784025848
Sample Time (s)              7.379982060287148
Epoch Time (s)               173.5242234612815
Total Train Time (s)         82553.63752280362
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:16:31.527088 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #486 | Epoch Duration: 173.6272623538971
2020-01-12 07:16:31.527302 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9990159
Z variance train             0.003214125
KL Divergence                29.784126
KL Loss                      2.9784126
QF Loss                      1008.01624
VF Loss                      128.21083
Policy Loss                  -1743.462
Q Predictions Mean           1741.9373
Q Predictions Std            394.40363
Q Predictions Max            2291.6167
Q Predictions Min            -194.57936
V Predictions Mean           1745.7861
V Predictions Std            392.7489
V Predictions Max            2294.4663
V Predictions Min            -195.35919
Log Pis Mean                 1.6579638
Log Pis Std                  2.9153285
Log Pis Max                  20.637623
Log Pis Min                  -5.757896
Policy mu Mean               0.053509377
Policy mu Std                0.68322974
Policy mu Max                2.7734656
Policy mu Min                -2.543579
Policy log std Mean          -1.1292312
Policy log std Std           0.28780398
Policy log std Max           -0.14728642
Policy log std Min           -3.8495703
Z mean eval                  1.4514439
Z variance eval              0.19534752
total_rewards                [2200.03509521 1949.63708718  622.22373271  271.56422213   35.98932062
  685.00101932 1439.77860152 3803.08609571 4587.28013723 4235.76199491]
total_rewards_mean           1983.0357306542817
total_rewards_std            1605.2915073905203
total_rewards_max            4587.280137228105
total_rewards_min            35.989320623590295
Number of train steps total  1952000
Number of env steps total    3708221
Number of rollouts total     0
Train Time (s)               147.93314632680267
(Previous) Eval Time (s)     14.411400654353201
Sample Time (s)              7.625954094808549
Epoch Time (s)               169.97050107596442
Total Train Time (s)         82723.70414316375
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:19:21.600780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #487 | Epoch Duration: 170.07331705093384
2020-01-12 07:19:21.600952 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.464046
Z variance train             0.19579275
KL Divergence                31.810072
KL Loss                      3.1810071
QF Loss                      724.48706
VF Loss                      129.60905
Policy Loss                  -1194.7191
Q Predictions Mean           1189.8246
Q Predictions Std            348.1931
Q Predictions Max            1808.5208
Q Predictions Min            266.4425
V Predictions Mean           1199.527
V Predictions Std            349.25406
V Predictions Max            1812.09
V Predictions Min            289.28625
Log Pis Mean                 1.640445
Log Pis Std                  3.0119839
Log Pis Max                  9.580215
Log Pis Min                  -9.203449
Policy mu Mean               0.018839886
Policy mu Std                0.7171907
Policy mu Max                2.6967702
Policy mu Min                -2.6225286
Policy log std Mean          -1.0950708
Policy log std Std           0.2866935
Policy log std Max           -0.2671939
Policy log std Min           -2.2073963
Z mean eval                  1.4156498
Z variance eval              0.017092502
total_rewards                [2317.3212445   190.26911136  950.08832695  374.66913638 2043.55556462
  282.07786654 2416.73665904  370.20415998 4362.99991232 1930.44570595]
total_rewards_mean           1523.836768763022
total_rewards_std            1273.7418586016706
total_rewards_max            4362.99991231706
total_rewards_min            190.2691113562581
Number of train steps total  1956000
Number of env steps total    3718661
Number of rollouts total     0
Train Time (s)               148.08507724432275
(Previous) Eval Time (s)     11.63279083603993
Sample Time (s)              8.052288131788373
Epoch Time (s)               167.77015621215105
Total Train Time (s)         82891.55837963521
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:22:09.459356 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #488 | Epoch Duration: 167.85828375816345
2020-01-12 07:22:09.459492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4131119
Z variance train             0.017141007
KL Divergence                31.610252
KL Loss                      3.1610253
QF Loss                      598.3048
VF Loss                      125.571236
Policy Loss                  -1263.7819
Q Predictions Mean           1258.5188
Q Predictions Std            379.96854
Q Predictions Max            1941.6661
Q Predictions Min            273.53137
V Predictions Mean           1262.0903
V Predictions Std            379.774
V Predictions Max            1937.7208
V Predictions Min            278.61404
Log Pis Mean                 1.3741374
Log Pis Std                  3.262221
Log Pis Max                  11.483229
Log Pis Min                  -8.585823
Policy mu Mean               -0.012794446
Policy mu Std                0.68105763
Policy mu Max                2.8508832
Policy mu Min                -2.9166825
Policy log std Mean          -1.1269408
Policy log std Std           0.30768296
Policy log std Max           -0.19283366
Policy log std Min           -2.1393175
Z mean eval                  0.8679975
Z variance eval              0.4953869
total_rewards                [4071.29632402 4515.18718798 2509.6279215   877.90395325 4792.62004836
 4659.35664986 3587.69379507 4149.89241148 4513.35468928  962.09101583]
total_rewards_mean           3463.9023996624264
total_rewards_std            1418.2056690983927
total_rewards_max            4792.6200483560915
total_rewards_min            877.9039532526297
Number of train steps total  1960000
Number of env steps total    3729421
Number of rollouts total     0
Train Time (s)               146.95435428526253
(Previous) Eval Time (s)     19.237291450146586
Sample Time (s)              6.600353478919715
Epoch Time (s)               172.79199921432883
Total Train Time (s)         83064.69567492837
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:25:02.604460 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #489 | Epoch Duration: 173.144868850708
2020-01-12 07:25:02.604601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8646577
Z variance train             0.5005713
KL Divergence                25.31678
KL Loss                      2.531678
QF Loss                      512.0836
VF Loss                      449.39786
Policy Loss                  -1565.422
Q Predictions Mean           1560.3062
Q Predictions Std            395.86136
Q Predictions Max            2145.902
Q Predictions Min            309.75006
V Predictions Mean           1568.5415
V Predictions Std            396.31793
V Predictions Max            2111.752
V Predictions Min            315.39255
Log Pis Mean                 1.8050379
Log Pis Std                  2.8014326
Log Pis Max                  13.614277
Log Pis Min                  -8.775051
Policy mu Mean               -0.05016654
Policy mu Std                0.70092416
Policy mu Max                2.7902944
Policy mu Min                -2.4415867
Policy log std Mean          -1.1124582
Policy log std Std           0.29138714
Policy log std Max           -0.30718017
Policy log std Min           -2.361404
Z mean eval                  0.4888385
Z variance eval              0.10167529
total_rewards                [4924.42690387 1530.45800615 5060.53753665 4901.71716655 1582.94593772
 1211.60897435 4512.94369156 4559.92767258 1947.27155934 5007.43897038]
total_rewards_mean           3523.9276419151865
total_rewards_std            1613.9120169636426
total_rewards_max            5060.5375366484905
total_rewards_min            1211.6089743540906
Number of train steps total  1964000
Number of env steps total    3740350
Number of rollouts total     0
Train Time (s)               147.10625339578837
(Previous) Eval Time (s)     15.976161134429276
Sample Time (s)              7.42403304297477
Epoch Time (s)               170.50644757319242
Total Train Time (s)         83235.28714502836
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:27:53.207697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #490 | Epoch Duration: 170.60298013687134
2020-01-12 07:27:53.207888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.49620676
Z variance train             0.10428455
KL Divergence                25.511757
KL Loss                      2.5511758
QF Loss                      1436.1199
VF Loss                      120.0926
Policy Loss                  -1354.4996
Q Predictions Mean           1347.9609
Q Predictions Std            369.89316
Q Predictions Max            1930.9016
Q Predictions Min            254.51685
V Predictions Mean           1358.4292
V Predictions Std            372.1489
V Predictions Max            1933.7333
V Predictions Min            266.631
Log Pis Mean                 1.6085682
Log Pis Std                  3.0204895
Log Pis Max                  13.758949
Log Pis Min                  -5.616496
Policy mu Mean               -0.02219968
Policy mu Std                0.6846234
Policy mu Max                2.8908534
Policy mu Min                -2.482982
Policy log std Mean          -1.1392503
Policy log std Std           0.3037102
Policy log std Max           -0.09597373
Policy log std Min           -2.1305988
Z mean eval                  1.4394076
Z variance eval              0.017965864
total_rewards                [3167.13347583 4871.60269745   11.91905326  751.21827949 1214.71381828
 1484.031952   4725.89247554 1425.67225203 1175.35466084   59.67416882]
total_rewards_mean           1888.7212833543658
total_rewards_std            1675.844221324993
total_rewards_max            4871.602697450991
total_rewards_min            11.919053259703208
Number of train steps total  1968000
Number of env steps total    3750595
Number of rollouts total     0
Train Time (s)               146.96826511621475
(Previous) Eval Time (s)     11.860376592725515
Sample Time (s)              7.310079728253186
Epoch Time (s)               166.13872143719345
Total Train Time (s)         83401.52573323296
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:30:39.455337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #491 | Epoch Duration: 166.2473042011261
2020-01-12 07:30:39.455517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4453449
Z variance train             0.017982112
KL Divergence                30.961546
KL Loss                      3.0961547
QF Loss                      12741.916
VF Loss                      137.21207
Policy Loss                  -1193.2203
Q Predictions Mean           1189.7903
Q Predictions Std            313.12158
Q Predictions Max            1750.4458
Q Predictions Min            263.00836
V Predictions Mean           1189.7415
V Predictions Std            313.2628
V Predictions Max            1740.6393
V Predictions Min            263.56528
Log Pis Mean                 1.3164126
Log Pis Std                  2.860289
Log Pis Max                  10.954117
Log Pis Min                  -6.1998453
Policy mu Mean               -0.036580548
Policy mu Std                0.6358658
Policy mu Max                3.193204
Policy mu Min                -2.2612188
Policy log std Mean          -1.1690855
Policy log std Std           0.29844263
Policy log std Max           -0.23241162
Policy log std Min           -2.4231486
Z mean eval                  0.33781177
Z variance eval              0.10966823
total_rewards                [3852.57720875 1995.4686826  4870.68855646  424.32825452 3536.71887065
 2957.33740342 4809.80997526 1375.10500475 4891.1949001  2643.65682192]
total_rewards_mean           3135.688567844264
total_rewards_std            1469.5101072103305
total_rewards_max            4891.19490010397
total_rewards_min            424.32825452366137
Number of train steps total  1972000
Number of env steps total    3761926
Number of rollouts total     0
Train Time (s)               149.56243213824928
(Previous) Eval Time (s)     19.645630285143852
Sample Time (s)              7.469434321857989
Epoch Time (s)               176.67749674525112
Total Train Time (s)         83578.29465367226
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:33:36.228158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #492 | Epoch Duration: 176.77250981330872
2020-01-12 07:33:36.228330 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.34300265
Z variance train             0.11181966
KL Divergence                23.976063
KL Loss                      2.3976064
QF Loss                      4145.4355
VF Loss                      262.0165
Policy Loss                  -1401.0067
Q Predictions Mean           1392.1416
Q Predictions Std            398.15442
Q Predictions Max            2022.5564
Q Predictions Min            262.80148
V Predictions Mean           1397.6978
V Predictions Std            397.72647
V Predictions Max            2033.7867
V Predictions Min            284.45593
Log Pis Mean                 1.1640658
Log Pis Std                  3.0761955
Log Pis Max                  15.036184
Log Pis Min                  -7.047559
Policy mu Mean               -0.0008147614
Policy mu Std                0.65654933
Policy mu Max                3.191936
Policy mu Min                -2.8292804
Policy log std Mean          -1.147896
Policy log std Std           0.2906691
Policy log std Max           -0.28721583
Policy log std Min           -2.446361
Z mean eval                  1.0343907
Z variance eval              0.002695325
total_rewards                [1463.79421165  735.72864086 2814.57703273 1920.38643646 4228.23833574
  412.12453912  963.17149032  281.242703    590.95448869  421.57436007]
total_rewards_mean           1383.1792238647938
total_rewards_std            1214.2267250534533
total_rewards_max            4228.238335741614
total_rewards_min            281.2427030020437
Number of train steps total  1976000
Number of env steps total    3772357
Number of rollouts total     0
Train Time (s)               147.640893147327
(Previous) Eval Time (s)     9.782124819699675
Sample Time (s)              8.187155195046216
Epoch Time (s)               165.6101731620729
Total Train Time (s)         83743.99404935353
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:36:21.929123 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #493 | Epoch Duration: 165.70067358016968
2020-01-12 07:36:21.929254 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0356895
Z variance train             0.0026972299
KL Divergence                30.243847
KL Loss                      3.0243847
QF Loss                      496.63678
VF Loss                      104.75297
Policy Loss                  -1666.2958
Q Predictions Mean           1660.0144
Q Predictions Std            350.5199
Q Predictions Max            2188.9844
Q Predictions Min            338.09195
V Predictions Mean           1664.5636
V Predictions Std            350.85898
V Predictions Max            2189.2961
V Predictions Min            341.45837
Log Pis Mean                 1.5997434
Log Pis Std                  2.952762
Log Pis Max                  11.958553
Log Pis Min                  -8.010288
Policy mu Mean               0.0025382824
Policy mu Std                0.63937336
Policy mu Max                3.0993586
Policy mu Min                -2.756807
Policy log std Mean          -1.1885933
Policy log std Std           0.28474742
Policy log std Max           -0.32511866
Policy log std Min           -2.3588343
Z mean eval                  0.33141202
Z variance eval              0.006238822
total_rewards                [ 663.63342567 1656.66405715  704.87594721 1741.05040997 4872.93405792
 2681.36275087 1539.42625087 4721.78479729 4821.10057198 4913.33023572]
total_rewards_mean           2831.6162504660942
total_rewards_std            1718.04097659761
total_rewards_max            4913.330235718235
total_rewards_min            663.6334256724186
Number of train steps total  1980000
Number of env steps total    3783082
Number of rollouts total     0
Train Time (s)               147.76219649706036
(Previous) Eval Time (s)     12.655892425216734
Sample Time (s)              7.5904675796628
Epoch Time (s)               168.0085565019399
Total Train Time (s)         83912.08532856731
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:39:10.023694 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #494 | Epoch Duration: 168.09434604644775
2020-01-12 07:39:10.023818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.33860102
Z variance train             0.0063318657
KL Divergence                26.982538
KL Loss                      2.6982539
QF Loss                      708.66736
VF Loss                      178.8175
Policy Loss                  -1331.2059
Q Predictions Mean           1327.2095
Q Predictions Std            401.0477
Q Predictions Max            1952.9856
Q Predictions Min            286.3334
V Predictions Mean           1330.0262
V Predictions Std            398.212
V Predictions Max            1922.3804
V Predictions Min            285.44437
Log Pis Mean                 1.2361981
Log Pis Std                  2.7481287
Log Pis Max                  10.855075
Log Pis Min                  -6.389551
Policy mu Mean               -0.05751233
Policy mu Std                0.62823117
Policy mu Max                2.6963363
Policy mu Min                -2.4726808
Policy log std Mean          -1.1642945
Policy log std Std           0.2931184
Policy log std Max           -0.23003232
Policy log std Min           -2.2272346
Z mean eval                  0.31114113
Z variance eval              0.028745184
total_rewards                [4428.82500134 4738.84179176 4725.13453435 4654.9810649  4984.65701339
 4558.55765219 4571.00042874 4933.85831251 5154.17031418 4464.04548047]
total_rewards_mean           4721.4071593820545
total_rewards_std            225.2624495115364
total_rewards_max            5154.170314180788
total_rewards_min            4428.825001340917
Number of train steps total  1984000
Number of env steps total    3795243
Number of rollouts total     0
Train Time (s)               145.69008072605357
(Previous) Eval Time (s)     24.708455719053745
Sample Time (s)              6.9280183208175
Epoch Time (s)               177.3265547659248
Total Train Time (s)         84089.50082438253
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:42:07.443562 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #495 | Epoch Duration: 177.4196422100067
2020-01-12 07:42:07.443730 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.31629068
Z variance train             0.028682208
KL Divergence                25.017754
KL Loss                      2.5017755
QF Loss                      699.4601
VF Loss                      210.84119
Policy Loss                  -1357.3849
Q Predictions Mean           1351.2063
Q Predictions Std            370.3923
Q Predictions Max            1993.9916
Q Predictions Min            135.21536
V Predictions Mean           1367.5378
V Predictions Std            372.75793
V Predictions Max            1990.5847
V Predictions Min            -54.853706
Log Pis Mean                 1.6127293
Log Pis Std                  3.2420163
Log Pis Max                  12.22593
Log Pis Min                  -6.5194263
Policy mu Mean               -0.011756899
Policy mu Std                0.6697468
Policy mu Max                3.280729
Policy mu Min                -3.2254093
Policy log std Mean          -1.1567332
Policy log std Std           0.32936028
Policy log std Max           -0.18505788
Policy log std Min           -2.6278546
Z mean eval                  0.47955447
Z variance eval              0.07981412
total_rewards                [4731.50035406 4380.82214451 2570.3535663  4716.10582154 4642.10905651
 4599.3114846  1243.33936169 2510.26541835  366.41079566 2380.06732264]
total_rewards_mean           3214.028532587071
total_rewards_std            1532.2017148699151
total_rewards_max            4731.500354062693
total_rewards_min            366.4107956649272
Number of train steps total  1988000
Number of env steps total    3806012
Number of rollouts total     0
Train Time (s)               147.82051986223087
(Previous) Eval Time (s)     17.178379779215902
Sample Time (s)              7.138551706913859
Epoch Time (s)               172.13745134836063
Total Train Time (s)         84261.73052478768
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:44:59.678458 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #496 | Epoch Duration: 172.2345907688141
2020-01-12 07:44:59.678687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4847427
Z variance train             0.07771575
KL Divergence                26.340864
KL Loss                      2.6340864
QF Loss                      16933.832
VF Loss                      119.20764
Policy Loss                  -1371.5347
Q Predictions Mean           1366.4329
Q Predictions Std            337.17322
Q Predictions Max            1872.3079
Q Predictions Min            299.64746
V Predictions Mean           1365.128
V Predictions Std            336.49637
V Predictions Max            1865.4323
V Predictions Min            301.5001
Log Pis Mean                 1.5339147
Log Pis Std                  3.023833
Log Pis Max                  12.883462
Log Pis Min                  -9.019521
Policy mu Mean               0.029792266
Policy mu Std                0.66988385
Policy mu Max                2.6905794
Policy mu Min                -2.6240766
Policy log std Mean          -1.1247096
Policy log std Std           0.30469528
Policy log std Max           -0.045041203
Policy log std Min           -2.0350547
Z mean eval                  0.27896374
Z variance eval              0.5502301
total_rewards                [  40.50835394 2661.87721131 5145.19644898 3464.02151878  191.82392443
  656.69175541 2128.38327228 3967.04228309 4693.18276252 1031.9210648 ]
total_rewards_mean           2398.0648595533817
total_rewards_std            1785.465707462741
total_rewards_max            5145.196448976614
total_rewards_min            40.50835393907107
Number of train steps total  1992000
Number of env steps total    3816886
Number of rollouts total     0
Train Time (s)               146.91875397320837
(Previous) Eval Time (s)     14.600557076279074
Sample Time (s)              8.065306153148413
Epoch Time (s)               169.58461720263585
Total Train Time (s)         84431.40394073166
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:47:49.355405 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #497 | Epoch Duration: 169.67657327651978
2020-01-12 07:47:49.355586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27957895
Z variance train             0.5438705
KL Divergence                23.367897
KL Loss                      2.3367898
QF Loss                      541.4241
VF Loss                      156.85388
Policy Loss                  -1365.4443
Q Predictions Mean           1358.7671
Q Predictions Std            339.27353
Q Predictions Max            1934.9692
Q Predictions Min            242.13803
V Predictions Mean           1366.8793
V Predictions Std            334.33
V Predictions Max            1941.2062
V Predictions Min            250.71121
Log Pis Mean                 1.5079403
Log Pis Std                  3.0633235
Log Pis Max                  9.615995
Log Pis Min                  -12.752978
Policy mu Mean               -0.02051493
Policy mu Std                0.6568341
Policy mu Max                2.846649
Policy mu Min                -2.7223325
Policy log std Mean          -1.1793082
Policy log std Std           0.30021957
Policy log std Max           -0.2733494
Policy log std Min           -2.1863093
Z mean eval                  0.552767
Z variance eval              0.06808157
total_rewards                [ 642.08334609  724.65482285 4271.73471802  279.08397444 3370.42205204
 4820.02506299 5105.02856349 5085.29019876 3305.86851317 4770.43636569]
total_rewards_mean           3237.462761753368
total_rewards_std            1861.4794886288605
total_rewards_max            5105.028563485324
total_rewards_min            279.08397444182754
Number of train steps total  1996000
Number of env steps total    3828029
Number of rollouts total     0
Train Time (s)               148.77000781800598
(Previous) Eval Time (s)     16.69438911601901
Sample Time (s)              7.6455993433482945
Epoch Time (s)               173.10999627737328
Total Train Time (s)         84604.71127361897
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:50:42.668693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #498 | Epoch Duration: 173.31296706199646
2020-01-12 07:50:42.668888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.55178154
Z variance train             0.0683264
KL Divergence                25.566435
KL Loss                      2.5566435
QF Loss                      807.694
VF Loss                      151.03351
Policy Loss                  -1413.6597
Q Predictions Mean           1409.6565
Q Predictions Std            361.69766
Q Predictions Max            1990.7399
Q Predictions Min            268.77762
V Predictions Mean           1411.0841
V Predictions Std            356.34442
V Predictions Max            1987.4231
V Predictions Min            271.4487
Log Pis Mean                 1.4153818
Log Pis Std                  3.0421119
Log Pis Max                  13.042715
Log Pis Min                  -7.260951
Policy mu Mean               -0.0031173602
Policy mu Std                0.6385447
Policy mu Max                2.7560406
Policy mu Min                -2.8285222
Policy log std Mean          -1.1654239
Policy log std Std           0.2984774
Policy log std Max           -0.29311252
Policy log std Min           -2.6187878
Z mean eval                  0.24908392
Z variance eval              0.3965269
total_rewards                [ 738.63578456 4857.51349558 5068.93967921 4899.76685139 2553.80842108
  134.31446177 4824.27246075 3328.35091987 4932.20732582  354.68571764]
total_rewards_mean           3169.2495117666595
total_rewards_std            1968.3859805390066
total_rewards_max            5068.939679209161
total_rewards_min            134.31446176682036
Number of train steps total  2000000
Number of env steps total    3838995
Number of rollouts total     0
Train Time (s)               147.29843754693866
(Previous) Eval Time (s)     20.102085867896676
Sample Time (s)              7.656092692166567
Epoch Time (s)               175.0566161070019
Total Train Time (s)         84779.85693617072
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:53:37.817630 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #499 | Epoch Duration: 175.1486110687256
2020-01-12 07:53:37.817761 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #499 | Started Training: True
2020-01-12 07:53:38.385535 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Variant:
2020-01-12 07:53:38.385828 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019175082
Z variance train             0.6939387
KL Divergence                0.14828885
KL Loss                      0.014828885
QF Loss                      46.709827
VF Loss                      16.167742
Policy Loss                  -3.9816623
Q Predictions Mean           -0.0026792148
Q Predictions Std            0.0026757657
Q Predictions Max            0.0040889876
Q Predictions Min            -0.010387832
V Predictions Mean           -0.001651519
V Predictions Std            0.001290455
V Predictions Max            0.0017824029
V Predictions Min            -0.0049177175
Log Pis Mean                 -4.0086207
Log Pis Std                  0.54835194
Log Pis Max                  -2.2180557
Log Pis Min                  -5.7349057
Policy mu Mean               -0.0001299685
Policy mu Std                0.0013389915
Policy mu Max                0.0041198926
Policy mu Min                -0.004545611
Policy log std Mean          -0.00054704404
Policy log std Std           0.0011561852
Policy log std Max           0.0023886173
Policy log std Min           -0.0044405647
Z mean eval                  0.8570304
Z variance eval              0.047355607
total_rewards                [-119.80486682 -136.9792466  -158.74689445 -140.93463933 -123.38789593
 -141.5424727  -149.58532802 -151.90958377 -119.03849759 -164.97905753]
total_rewards_mean           -140.6908482719261
total_rewards_std            15.296767846030868
total_rewards_max            -119.0384975864594
total_rewards_min            -164.97905752784447
Number of train steps total  4000
Number of env steps total    14000
Number of rollouts total     0
Train Time (s)               141.9527783249505
(Previous) Eval Time (s)     0
Sample Time (s)              10.93709594849497
Epoch Time (s)               152.88987427344546
Total Train Time (s)         170.62058700295165
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:56:29.084136 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #0 | Epoch Duration: 170.62382292747498
2020-01-12 07:56:29.084306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90167505
Z variance train             0.041856658
KL Divergence                9.360006
KL Loss                      0.93600065
QF Loss                      47.1469
VF Loss                      9.294404
Policy Loss                  -48.83809
Q Predictions Mean           44.240807
Q Predictions Std            17.82905
Q Predictions Max            99.00708
Q Predictions Min            -16.574621
V Predictions Mean           49.184624
V Predictions Std            17.31221
V Predictions Max            101.537
V Predictions Min            -8.512872
Log Pis Mean                 -3.2385275
Log Pis Std                  1.2206479
Log Pis Max                  -0.06476468
Log Pis Min                  -8.254299
Policy mu Mean               0.06723497
Policy mu Std                0.3628978
Policy mu Max                1.6284689
Policy mu Min                -1.2889998
Policy log std Mean          -0.31089845
Policy log std Std           0.06466471
Policy log std Max           -0.16806349
Policy log std Min           -0.5761995
Z mean eval                  1.0705801
Z variance eval              0.023435056
total_rewards                [-140.71860726  -66.55020744 -116.91921201 -100.35151368  -46.52522974
 -136.85984412 -110.46513159 -127.80643182 -129.03688426 -108.42813742]
total_rewards_mean           -108.36611993377657
total_rewards_std            28.945547516274093
total_rewards_max            -46.52522973505119
total_rewards_min            -140.7186072572156
Number of train steps total  8000
Number of env steps total    26000
Number of rollouts total     0
Train Time (s)               141.15574117889628
(Previous) Eval Time (s)     17.725766093004495
Sample Time (s)              5.554469279013574
Epoch Time (s)               164.43597655091435
Total Train Time (s)         335.1402840889059
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:59:13.605309 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #1 | Epoch Duration: 164.5208625793457
2020-01-12 07:59:13.605506 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #1 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0627549
Z variance train             0.023334749
KL Divergence                12.617655
KL Loss                      1.2617655
QF Loss                      77.44399
VF Loss                      28.448317
Policy Loss                  -88.40505
Q Predictions Mean           84.29179
Q Predictions Std            26.726316
Q Predictions Max            182.0234
Q Predictions Min            20.158403
V Predictions Mean           91.97092
V Predictions Std            27.315807
V Predictions Max            176.4221
V Predictions Min            32.280903
Log Pis Mean                 -3.2033463
Log Pis Std                  1.3965696
Log Pis Max                  1.9968648
Log Pis Min                  -6.9521055
Policy mu Mean               0.023217214
Policy mu Std                0.44225755
Policy mu Max                1.6368394
Policy mu Min                -1.8417437
Policy log std Mean          -0.3282062
Policy log std Std           0.076840825
Policy log std Max           -0.10830869
Policy log std Min           -0.680839
Z mean eval                  1.1768091
Z variance eval              0.03133611
total_rewards                [-52.09384411 -20.17585418 -70.50107003 -56.87156973  -4.5261226
 -86.1482204   -4.72648553 -38.32399383  41.84297799 -71.25432327]
total_rewards_mean           -36.27785056900022
total_rewards_std            37.31738041555544
total_rewards_max            41.8429779925883
total_rewards_min            -86.14822039934562
Number of train steps total  12000
Number of env steps total    38000
Number of rollouts total     0
Train Time (s)               142.3822284513153
(Previous) Eval Time (s)     20.99292907398194
Sample Time (s)              6.486303466837853
Epoch Time (s)               169.8614609921351
Total Train Time (s)         505.0999261382967
Epoch                        2
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:02:03.564764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #2 | Epoch Duration: 169.95912408828735
2020-01-12 08:02:03.564903 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.173344
Z variance train             0.031380285
KL Divergence                13.744539
KL Loss                      1.3744539
QF Loss                      53.716454
VF Loss                      28.074799
Policy Loss                  -128.45241
Q Predictions Mean           124.663605
Q Predictions Std            39.311035
Q Predictions Max            223.57649
Q Predictions Min            49.962246
V Predictions Mean           131.93298
V Predictions Std            39.126827
V Predictions Max            227.50276
V Predictions Min            64.5722
Log Pis Mean                 -3.0888681
Log Pis Std                  1.2659762
Log Pis Max                  1.723346
Log Pis Min                  -6.025714
Policy mu Mean               0.010516976
Policy mu Std                0.41898605
Policy mu Max                1.791188
Policy mu Min                -1.301242
Policy log std Mean          -0.33096814
Policy log std Std           0.0815935
Policy log std Max           -0.16474834
Policy log std Min           -0.69333816
Z mean eval                  1.2243838
Z variance eval              0.034015235
total_rewards                [215.12223097 116.96737152 175.28799707  94.11691416 221.12375198
  46.61422166  79.10989942  49.36864236  80.11590951  67.35587742]
total_rewards_mean           114.51828160639369
total_rewards_std            62.544431445440715
total_rewards_max            221.12375197785596
total_rewards_min            46.61422165789635
Number of train steps total  16000
Number of env steps total    50000
Number of rollouts total     0
Train Time (s)               143.11390058416873
(Previous) Eval Time (s)     20.959214230068028
Sample Time (s)              6.4461075672879815
Epoch Time (s)               170.51922238152474
Total Train Time (s)         675.7064033807255
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:04:54.172490 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #3 | Epoch Duration: 170.60749053955078
2020-01-12 08:04:54.172618 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2231514
Z variance train             0.03410511
KL Divergence                14.648917
KL Loss                      1.4648918
QF Loss                      46.83977
VF Loss                      10.9094715
Policy Loss                  -149.63753
Q Predictions Mean           143.59972
Q Predictions Std            42.67657
Q Predictions Max            274.90213
Q Predictions Min            71.712555
V Predictions Mean           150.32635
V Predictions Std            41.4437
V Predictions Max            273.18155
V Predictions Min            81.26038
Log Pis Mean                 -3.2629328
Log Pis Std                  1.4189438
Log Pis Max                  2.3022041
Log Pis Min                  -7.2082367
Policy mu Mean               0.012199369
Policy mu Std                0.38947287
Policy mu Max                1.7695112
Policy mu Min                -1.4258059
Policy log std Mean          -0.32613477
Policy log std Std           0.085294366
Policy log std Max           -0.07732354
Policy log std Min           -0.7754878
Z mean eval                  1.27453
Z variance eval              0.036229327
total_rewards                [377.42888561 577.56733452 207.63355706 158.23362038 404.82230909
 246.98884586 410.91484624 323.08229238 157.35252815  62.43087185]
total_rewards_mean           292.6455091142385
total_rewards_std            146.47437471863918
total_rewards_max            577.5673345246104
total_rewards_min            62.43087185137737
Number of train steps total  20000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               140.82227462902665
(Previous) Eval Time (s)     21.069865269120783
Sample Time (s)              5.542368256952614
Epoch Time (s)               167.43450815510005
Total Train Time (s)         843.2300534984097
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:07:41.696785 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #4 | Epoch Duration: 167.52407312393188
2020-01-12 08:07:41.696921 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2748578
Z variance train             0.03630378
KL Divergence                15.50745
KL Loss                      1.550745
QF Loss                      68.44155
VF Loss                      19.164122
Policy Loss                  -191.49336
Q Predictions Mean           186.28488
Q Predictions Std            52.588593
Q Predictions Max            334.50677
Q Predictions Min            100.755165
V Predictions Mean           190.23953
V Predictions Std            52.079636
V Predictions Max            327.00708
V Predictions Min            99.7673
Log Pis Mean                 -3.179522
Log Pis Std                  1.3542868
Log Pis Max                  2.3836563
Log Pis Min                  -7.610919
Policy mu Mean               -0.03514818
Policy mu Std                0.44905213
Policy mu Max                1.946063
Policy mu Min                -1.8796372
Policy log std Mean          -0.3404627
Policy log std Std           0.09354306
Policy log std Max           -0.032215998
Policy log std Min           -0.8408439
Z mean eval                  1.3176636
Z variance eval              0.03010225
total_rewards                [1359.03449963 1683.98054731  698.55417239 1282.31917818 1284.74318036
 1253.42464325 1276.47792498 1467.87376846 1610.50044553  717.21644516]
total_rewards_mean           1263.412480522977
total_rewards_std            310.92981283036073
total_rewards_max            1683.9805473055778
total_rewards_min            698.5541723887386
Number of train steps total  24000
Number of env steps total    74000
Number of rollouts total     0
Train Time (s)               141.90008722618222
(Previous) Eval Time (s)     17.662372660823166
Sample Time (s)              6.5747709991410375
Epoch Time (s)               166.13723088614643
Total Train Time (s)         1009.4530332400464
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:10:27.923233 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #5 | Epoch Duration: 166.22619891166687
2020-01-12 08:10:27.923441 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.315428
Z variance train             0.029934848
KL Divergence                16.201488
KL Loss                      1.6201489
QF Loss                      302.90747
VF Loss                      50.24353
Policy Loss                  -223.01384
Q Predictions Mean           216.83366
Q Predictions Std            72.6502
Q Predictions Max            432.32693
Q Predictions Min            111.42569
V Predictions Mean           228.04527
V Predictions Std            71.72269
V Predictions Max            427.9796
V Predictions Min            116.36963
Log Pis Mean                 -2.908556
Log Pis Std                  1.8381262
Log Pis Max                  5.4552507
Log Pis Min                  -8.615093
Policy mu Mean               -0.006876013
Policy mu Std                0.5119946
Policy mu Max                2.0630612
Policy mu Min                -1.704877
Policy log std Mean          -0.35600626
Policy log std Std           0.10570439
Policy log std Max           -0.124134116
Policy log std Min           -0.89694417
Z mean eval                  1.3300673
Z variance eval              0.050965853
total_rewards                [1717.4468697   957.23179952 2182.97970855 2026.76438238 2364.95295906
 1805.16370186 2174.37854872  556.20935944 1851.90103585  813.99279666]
total_rewards_mean           1645.102116173703
total_rewards_std            604.6910074424577
total_rewards_max            2364.9529590588845
total_rewards_min            556.209359444083
Number of train steps total  28000
Number of env steps total    86000
Number of rollouts total     0
Train Time (s)               141.37778852460906
(Previous) Eval Time (s)     19.815300669055432
Sample Time (s)              6.597711309790611
Epoch Time (s)               167.7908005034551
Total Train Time (s)         1177.3287200927734
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:13:15.797750 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #6 | Epoch Duration: 167.87416124343872
2020-01-12 08:13:15.797921 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3293868
Z variance train             0.051017683
KL Divergence                14.408234
KL Loss                      1.4408234
QF Loss                      129.80072
VF Loss                      33.496193
Policy Loss                  -262.55328
Q Predictions Mean           254.32748
Q Predictions Std            104.98196
Q Predictions Max            570.5655
Q Predictions Min            135.75388
V Predictions Mean           263.52344
V Predictions Std            104.4851
V Predictions Max            579.60455
V Predictions Min            140.23055
Log Pis Mean                 -2.628164
Log Pis Std                  1.8245932
Log Pis Max                  4.3250685
Log Pis Min                  -6.169155
Policy mu Mean               -0.017206943
Policy mu Std                0.5317824
Policy mu Max                1.7189984
Policy mu Min                -2.1563804
Policy log std Mean          -0.36801186
Policy log std Std           0.13275558
Policy log std Max           -0.06561345
Policy log std Min           -1.3202304
Z mean eval                  1.4363272
Z variance eval              0.023656022
total_rewards                [2653.94428115 2711.7415817  2650.90073385 2677.82463629 2718.87350692
 2753.16561472 2621.09594926  844.33412152 2472.45300589 2696.02910001]
total_rewards_mean           2480.036253130594
total_rewards_std            550.0926172467537
total_rewards_max            2753.1656147219624
total_rewards_min            844.3341215245425
Number of train steps total  32000
Number of env steps total    98000
Number of rollouts total     0
Train Time (s)               142.3745892061852
(Previous) Eval Time (s)     17.83722969610244
Sample Time (s)              6.397122672293335
Epoch Time (s)               166.60894157458097
Total Train Time (s)         1344.0142849930562
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:16:02.486677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #7 | Epoch Duration: 166.6886112689972
2020-01-12 08:16:02.486818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4365635
Z variance train             0.023555791
KL Divergence                18.323
KL Loss                      1.8323001
QF Loss                      119.078415
VF Loss                      56.591427
Policy Loss                  -284.66232
Q Predictions Mean           275.00464
Q Predictions Std            114.12933
Q Predictions Max            679.53375
Q Predictions Min            142.85335
V Predictions Mean           279.9147
V Predictions Std            115.98067
V Predictions Max            685.7592
V Predictions Min            158.8588
Log Pis Mean                 -2.4140596
Log Pis Std                  2.1078944
Log Pis Max                  6.48071
Log Pis Min                  -7.6143284
Policy mu Mean               -0.010068208
Policy mu Std                0.5826307
Policy mu Max                2.2576063
Policy mu Min                -1.8932884
Policy log std Mean          -0.382583
Policy log std Std           0.1403378
Policy log std Max           -0.059430644
Policy log std Min           -1.187321
Z mean eval                  1.570262
Z variance eval              0.026734218
total_rewards                [2925.51027445 2980.84446605 2906.78806712 2941.08159982 2890.42442532
  682.37579128 2917.04663503 2833.37568792 3108.70423823 3084.19761975]
total_rewards_mean           2727.034880496346
total_rewards_std            686.2882399905322
total_rewards_max            3108.704238229665
total_rewards_min            682.3757912759372
Number of train steps total  36000
Number of env steps total    110000
Number of rollouts total     0
Train Time (s)               141.39585772203282
(Previous) Eval Time (s)     17.810863703954965
Sample Time (s)              5.681655390653759
Epoch Time (s)               164.88837681664154
Total Train Time (s)         1508.9887186517008
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:18:47.461094 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #8 | Epoch Duration: 164.97414755821228
2020-01-12 08:18:47.461321 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5714668
Z variance train             0.026570031
KL Divergence                18.710285
KL Loss                      1.8710285
QF Loss                      102.72793
VF Loss                      36.4113
Policy Loss                  -319.53604
Q Predictions Mean           312.20898
Q Predictions Std            157.32193
Q Predictions Max            809.073
Q Predictions Min            162.68185
V Predictions Mean           315.6676
V Predictions Std            157.63722
V Predictions Max            802.6678
V Predictions Min            178.22974
Log Pis Mean                 -2.2060304
Log Pis Std                  2.28106
Log Pis Max                  5.391802
Log Pis Min                  -6.3220606
Policy mu Mean               -0.043104004
Policy mu Std                0.58388966
Policy mu Max                1.9197209
Policy mu Min                -2.170544
Policy log std Mean          -0.39043918
Policy log std Std           0.16912653
Policy log std Max           -0.16119978
Policy log std Min           -1.5250498
Z mean eval                  1.6815469
Z variance eval              0.039277457
total_rewards                [3247.66095674 3338.15260218 3211.673153   3226.83353884 3144.61281778
  880.26929528 3360.72621857 3269.68389065 3201.73817106 3182.73076804]
total_rewards_mean           3006.408141213126
total_rewards_std            711.5226084700234
total_rewards_max            3360.7262185714835
total_rewards_min            880.2692952814242
Number of train steps total  40000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               142.4535206318833
(Previous) Eval Time (s)     17.709922744892538
Sample Time (s)              6.519831718411297
Epoch Time (s)               166.68327509518713
Total Train Time (s)         1675.75117145665
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:21:34.223158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #9 | Epoch Duration: 166.76168417930603
2020-01-12 08:21:34.223280 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #9 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6836075
Z variance train             0.03931024
KL Divergence                18.877396
KL Loss                      1.8877395
QF Loss                      184.54936
VF Loss                      41.86239
Policy Loss                  -396.34106
Q Predictions Mean           390.6626
Q Predictions Std            204.74251
Q Predictions Max            951.7623
Q Predictions Min            178.26329
V Predictions Mean           396.48065
V Predictions Std            205.25139
V Predictions Max            935.0167
V Predictions Min            184.77711
Log Pis Mean                 -1.6992711
Log Pis Std                  2.6339643
Log Pis Max                  8.966895
Log Pis Min                  -6.1031294
Policy mu Mean               -0.037009757
Policy mu Std                0.66445965
Policy mu Max                2.1140459
Policy mu Min                -2.4695745
Policy log std Mean          -0.41836834
Policy log std Std           0.17262731
Policy log std Max           -0.1683233
Policy log std Min           -1.6283408
Z mean eval                  1.8004423
Z variance eval              0.025630694
total_rewards                [3197.58308723 3180.13771558 3200.83346392 3350.73068538 3225.9101789
 3194.85224419 3266.06561277 3119.33723773 3179.48128653 3221.9817852 ]
total_rewards_mean           3213.691329742958
total_rewards_std            58.06846005912471
total_rewards_max            3350.7306853787322
total_rewards_min            3119.337237726468
Number of train steps total  44000
Number of env steps total    134000
Number of rollouts total     0
Train Time (s)               142.48910357616842
(Previous) Eval Time (s)     20.946224097162485
Sample Time (s)              5.543400122784078
Epoch Time (s)               168.97872779611498
Total Train Time (s)         1844.8138136649504
Epoch                        10
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:24:23.286598 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #10 | Epoch Duration: 169.0632243156433
2020-01-12 08:24:23.286748 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7987705
Z variance train             0.025562212
KL Divergence                21.54616
KL Loss                      2.154616
QF Loss                      255.54514
VF Loss                      44.870293
Policy Loss                  -419.74313
Q Predictions Mean           409.26196
Q Predictions Std            239.83783
Q Predictions Max            999.7389
Q Predictions Min            179.36961
V Predictions Mean           417.6826
V Predictions Std            242.16188
V Predictions Max            989.6034
V Predictions Min            180.6841
Log Pis Mean                 -1.6384289
Log Pis Std                  2.9173105
Log Pis Max                  9.976688
Log Pis Min                  -6.883501
Policy mu Mean               0.0390093
Policy mu Std                0.7015887
Policy mu Max                2.232673
Policy mu Min                -2.88056
Policy log std Mean          -0.43228927
Policy log std Std           0.17674474
Policy log std Max           -0.15156235
Policy log std Min           -1.5816116
Z mean eval                  1.8647034
Z variance eval              0.041358586
total_rewards                [3496.06408563 3386.06200743 3396.06383101 3379.52744395 3429.18691467
 3183.10183791 3411.18558081 3361.47100881 3626.09294958 3570.80664561]
total_rewards_mean           3423.956230539804
total_rewards_std            115.72268855520052
total_rewards_max            3626.0929495760342
total_rewards_min            3183.1018379089323
Number of train steps total  48000
Number of env steps total    146000
Number of rollouts total     0
Train Time (s)               142.06342723593116
(Previous) Eval Time (s)     17.73807872692123
Sample Time (s)              6.663839919026941
Epoch Time (s)               166.46534588187933
Total Train Time (s)         2011.3705884623341
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:27:09.846437 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #11 | Epoch Duration: 166.55957293510437
2020-01-12 08:27:09.846654 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8670645
Z variance train             0.041168876
KL Divergence                22.36293
KL Loss                      2.236293
QF Loss                      266.77255
VF Loss                      64.75019
Policy Loss                  -486.61905
Q Predictions Mean           482.40308
Q Predictions Std            303.24554
Q Predictions Max            1171.0256
Q Predictions Min            181.78835
V Predictions Mean           490.1347
V Predictions Std            303.90918
V Predictions Max            1179.5087
V Predictions Min            189.39278
Log Pis Mean                 -1.6668222
Log Pis Std                  2.8095558
Log Pis Max                  8.014477
Log Pis Min                  -6.818327
Policy mu Mean               -0.0012474066
Policy mu Std                0.69911116
Policy mu Max                2.413759
Policy mu Min                -2.1176836
Policy log std Mean          -0.4259226
Policy log std Std           0.18999746
Policy log std Max           -0.18290961
Policy log std Min           -1.7285247
Z mean eval                  1.9208361
Z variance eval              0.062533356
total_rewards                [3647.83754964 1986.71218261 3453.38915687 3731.92363645 3952.03275232
 3601.31676996 3894.62698816 3779.96119087 3853.15682137 3728.71648566]
total_rewards_mean           3562.9673533903215
total_rewards_std            543.5022192927119
total_rewards_max            3952.03275231869
total_rewards_min            1986.712182612499
Number of train steps total  52000
Number of env steps total    158000
Number of rollouts total     0
Train Time (s)               140.4986516800709
(Previous) Eval Time (s)     17.891712713986635
Sample Time (s)              6.539673796389252
Epoch Time (s)               164.9300381904468
Total Train Time (s)         2176.3850927725434
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:29:54.860620 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #12 | Epoch Duration: 165.0138087272644
2020-01-12 08:29:54.860793 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #12 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9238151
Z variance train             0.06255022
KL Divergence                21.104979
KL Loss                      2.110498
QF Loss                      192.47461
VF Loss                      53.167927
Policy Loss                  -499.34152
Q Predictions Mean           489.2808
Q Predictions Std            315.59253
Q Predictions Max            1245.9806
Q Predictions Min            180.39574
V Predictions Mean           497.90594
V Predictions Std            320.7221
V Predictions Max            1239.2789
V Predictions Min            192.77258
Log Pis Mean                 -1.6713185
Log Pis Std                  2.9008896
Log Pis Max                  7.919036
Log Pis Min                  -6.565384
Policy mu Mean               0.0073697814
Policy mu Std                0.69410866
Policy mu Max                2.2955432
Policy mu Min                -2.45524
Policy log std Mean          -0.42986774
Policy log std Std           0.19321421
Policy log std Max           -0.08899097
Policy log std Min           -1.7646841
Z mean eval                  1.9908984
Z variance eval              0.044801436
total_rewards                [3597.56510471 3754.33492186 3886.7450577  3917.08730919 1525.849065
 3699.59665719 3682.37350865 3618.87022995 3724.97316285  632.87361478]
total_rewards_mean           3204.0268631866247
total_rewards_std            1085.2310993010149
total_rewards_max            3917.087309185161
total_rewards_min            632.8736147781527
Number of train steps total  56000
Number of env steps total    170000
Number of rollouts total     0
Train Time (s)               142.7484659468755
(Previous) Eval Time (s)     17.47962373821065
Sample Time (s)              5.485343575943261
Epoch Time (s)               165.71343326102942
Total Train Time (s)         2342.293415383436
Epoch                        13
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:32:40.773009 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #13 | Epoch Duration: 165.91203117370605
2020-01-12 08:32:40.773346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9899276
Z variance train             0.044774417
KL Divergence                22.732903
KL Loss                      2.2732904
QF Loss                      213.39098
VF Loss                      78.78076
Policy Loss                  -572.7304
Q Predictions Mean           562.2091
Q Predictions Std            352.63538
Q Predictions Max            1348.5013
Q Predictions Min            166.63504
V Predictions Mean           576.347
V Predictions Std            356.1466
V Predictions Max            1359.0101
V Predictions Min            178.96198
Log Pis Mean                 -1.3015859
Log Pis Std                  3.0637565
Log Pis Max                  8.39757
Log Pis Min                  -7.7917633
Policy mu Mean               -0.0063744714
Policy mu Std                0.7601129
Policy mu Max                2.5440035
Policy mu Min                -2.5537932
Policy log std Mean          -0.44454932
Policy log std Std           0.19278629
Policy log std Max           -0.18689111
Policy log std Min           -1.6942906
Z mean eval                  1.9935968
Z variance eval              0.022119524
total_rewards                [3994.11953706 4009.57377319 3939.00621871 3846.97152189 4206.60503925
 3986.57180254 3913.63253053 4112.39257128 3591.71382445 4027.5646049 ]
total_rewards_mean           3962.8151423793547
total_rewards_std            156.15756602388578
total_rewards_max            4206.605039250798
total_rewards_min            3591.7138244491184
Number of train steps total  60000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               143.7748798429966
(Previous) Eval Time (s)     17.678873215802014
Sample Time (s)              6.872498502954841
Epoch Time (s)               168.32625156175345
Total Train Time (s)         2510.7047553318553
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:35:29.185577 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #14 | Epoch Duration: 168.41198301315308
2020-01-12 08:35:29.185810 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9973282
Z variance train             0.022061782
KL Divergence                25.375153
KL Loss                      2.5375154
QF Loss                      278.40143
VF Loss                      120.32531
Policy Loss                  -590.9313
Q Predictions Mean           580.3989
Q Predictions Std            387.98715
Q Predictions Max            1374.031
Q Predictions Min            197.42363
V Predictions Mean           582.9354
V Predictions Std            392.8555
V Predictions Max            1374.2429
V Predictions Min            182.33005
Log Pis Mean                 -1.8189039
Log Pis Std                  2.9065118
Log Pis Max                  9.886803
Log Pis Min                  -9.42384
Policy mu Mean               0.02803404
Policy mu Std                0.6917555
Policy mu Max                2.6575043
Policy mu Min                -2.3253694
Policy log std Mean          -0.4342667
Policy log std Std           0.20232873
Policy log std Max           -0.14432487
Policy log std Min           -1.814332
Z mean eval                  2.0189488
Z variance eval              0.020484768
total_rewards                [4089.35527728 3969.20606861 3892.96665691 3945.35581067 4154.40706829
 4091.61760454 4029.99428848 4089.70896751 3998.36152585 4052.11362906]
total_rewards_mean           4031.3086897186668
total_rewards_std            75.81135439617427
total_rewards_max            4154.407068286706
total_rewards_min            3892.9666569096507
Number of train steps total  64000
Number of env steps total    194000
Number of rollouts total     0
Train Time (s)               141.4555628071539
(Previous) Eval Time (s)     17.70490838587284
Sample Time (s)              6.405570060014725
Epoch Time (s)               165.56604125304148
Total Train Time (s)         2676.358530738391
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:38:14.839205 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #15 | Epoch Duration: 165.6531822681427
2020-01-12 08:38:14.839475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0222774
Z variance train             0.020504672
KL Divergence                26.754631
KL Loss                      2.6754632
QF Loss                      240.58748
VF Loss                      62.769855
Policy Loss                  -581.881
Q Predictions Mean           573.33453
Q Predictions Std            419.62024
Q Predictions Max            1431.6758
Q Predictions Min            180.37498
V Predictions Mean           577.6216
V Predictions Std            419.91595
V Predictions Max            1438.6364
V Predictions Min            193.83583
Log Pis Mean                 -1.6598133
Log Pis Std                  2.9547858
Log Pis Max                  7.375328
Log Pis Min                  -7.093722
Policy mu Mean               -0.012869437
Policy mu Std                0.7047756
Policy mu Max                3.1364698
Policy mu Min                -2.551782
Policy log std Mean          -0.4289706
Policy log std Std           0.20139201
Policy log std Max           0.0058861375
Policy log std Min           -1.7983794
Z mean eval                  2.015856
Z variance eval              0.024991319
total_rewards                [4114.56073325 4070.33360968 4153.26172274 4144.03621273 4028.69383079
 4259.75024172 4104.84860212 4150.12714683 4295.24025268 3953.23815284]
total_rewards_mean           4127.409050538331
total_rewards_std            95.47475772704307
total_rewards_max            4295.240252678438
total_rewards_min            3953.2381528432056
Number of train steps total  68000
Number of env steps total    206000
Number of rollouts total     0
Train Time (s)               138.40331477764994
(Previous) Eval Time (s)     20.69219624903053
Sample Time (s)              6.5194888999685645
Epoch Time (s)               165.61499992664903
Total Train Time (s)         2842.0592373525724
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:41:00.541037 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #16 | Epoch Duration: 165.70138359069824
2020-01-12 08:41:00.541267 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0182343
Z variance train             0.025100445
KL Divergence                25.548069
KL Loss                      2.554807
QF Loss                      452.11264
VF Loss                      75.35474
Policy Loss                  -670.85315
Q Predictions Mean           659.8121
Q Predictions Std            445.31833
Q Predictions Max            1507.5543
Q Predictions Min            179.56554
V Predictions Mean           669.7782
V Predictions Std            444.68677
V Predictions Max            1508.9167
V Predictions Min            182.09344
Log Pis Mean                 -1.2252969
Log Pis Std                  3.0463333
Log Pis Max                  9.89942
Log Pis Min                  -6.402498
Policy mu Mean               0.015006158
Policy mu Std                0.75904214
Policy mu Max                2.5791357
Policy mu Min                -2.4907227
Policy log std Mean          -0.4502164
Policy log std Std           0.21949393
Policy log std Max           -0.1407725
Policy log std Min           -1.9273262
Z mean eval                  2.0372725
Z variance eval              0.036213472
total_rewards                [4170.19527401 4160.97827397 4436.13019125 4274.02923458 4346.11147862
 3048.00019551 4248.92151438 4117.69155094 4079.86585307 4188.52261099]
total_rewards_mean           4107.04461773277
total_rewards_std            367.34531893871576
total_rewards_max            4436.130191250258
total_rewards_min            3048.0001955116168
Number of train steps total  72000
Number of env steps total    218000
Number of rollouts total     0
Train Time (s)               141.87035724613816
(Previous) Eval Time (s)     17.881520632188767
Sample Time (s)              6.634430787991732
Epoch Time (s)               166.38630866631866
Total Train Time (s)         3008.5308165517636
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:43:47.014301 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #17 | Epoch Duration: 166.47281789779663
2020-01-12 08:43:47.014578 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0378158
Z variance train             0.036215726
KL Divergence                24.724936
KL Loss                      2.4724936
QF Loss                      374.02994
VF Loss                      76.496376
Policy Loss                  -647.4341
Q Predictions Mean           642.9774
Q Predictions Std            468.45865
Q Predictions Max            1586.17
Q Predictions Min            171.4921
V Predictions Mean           645.7477
V Predictions Std            470.40665
V Predictions Max            1587.5881
V Predictions Min            184.52608
Log Pis Mean                 -1.4477639
Log Pis Std                  3.1816647
Log Pis Max                  12.205077
Log Pis Min                  -8.441115
Policy mu Mean               -0.028402278
Policy mu Std                0.72741604
Policy mu Max                2.8540606
Policy mu Min                -2.7232344
Policy log std Mean          -0.43199572
Policy log std Std           0.21164581
Policy log std Max           -0.06852865
Policy log std Min           -1.9186136
Z mean eval                  2.052632
Z variance eval              0.031677354
total_rewards                [4423.29883442 4639.7374459  4596.92142487 4585.55192501 4452.78936389
  357.0784464  4611.41226796 4639.93532078 4725.60387926 4694.20164616]
total_rewards_mean           4172.653055465287
total_rewards_std            1275.0371020760185
total_rewards_max            4725.603879259614
total_rewards_min            357.07844640025763
Number of train steps total  76000
Number of env steps total    230000
Number of rollouts total     0
Train Time (s)               143.2174494159408
(Previous) Eval Time (s)     20.94682462280616
Sample Time (s)              6.389730323571712
Epoch Time (s)               170.55400436231866
Total Train Time (s)         3179.1718197641894
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:46:37.657065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #18 | Epoch Duration: 170.64227199554443
2020-01-12 08:46:37.657384 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0513146
Z variance train             0.03166527
KL Divergence                25.73482
KL Loss                      2.573482
QF Loss                      713.3954
VF Loss                      104.504196
Policy Loss                  -735.2631
Q Predictions Mean           724.59595
Q Predictions Std            487.6482
Q Predictions Max            1631.7289
Q Predictions Min            156.41557
V Predictions Mean           736.07623
V Predictions Std            488.02353
V Predictions Max            1630.2549
V Predictions Min            165.74829
Log Pis Mean                 -1.0247283
Log Pis Std                  3.1998994
Log Pis Max                  11.451237
Log Pis Min                  -5.8777943
Policy mu Mean               -0.0056029856
Policy mu Std                0.8005643
Policy mu Max                2.5224411
Policy mu Min                -2.9216983
Policy log std Mean          -0.46340272
Policy log std Std           0.21830687
Policy log std Max           -0.18346441
Policy log std Min           -1.8705614
Z mean eval                  2.0377026
Z variance eval              0.029175634
total_rewards                [4494.37355246 4542.25351847 4710.45495347 4572.37737284 4437.07986685
 4583.15881631 4385.16812602 4538.85797426 1563.01554507 4645.52914923]
total_rewards_mean           4247.226887498035
total_rewards_std            899.1680254196839
total_rewards_max            4710.454953471471
total_rewards_min            1563.015545065152
Number of train steps total  80000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               144.04432352632284
(Previous) Eval Time (s)     17.662697550375015
Sample Time (s)              5.488814770244062
Epoch Time (s)               167.19583584694192
Total Train Time (s)         3346.4538402222097
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:49:24.937351 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #19 | Epoch Duration: 167.27975988388062
2020-01-12 08:49:24.937478 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.038317
Z variance train             0.029166698
KL Divergence                26.68172
KL Loss                      2.6681721
QF Loss                      641.4892
VF Loss                      146.53987
Policy Loss                  -671.963
Q Predictions Mean           665.6077
Q Predictions Std            481.8907
Q Predictions Max            1700.374
Q Predictions Min            156.67418
V Predictions Mean           674.1025
V Predictions Std            487.74765
V Predictions Max            1713.3905
V Predictions Min            162.89917
Log Pis Mean                 -1.2450749
Log Pis Std                  3.4889727
Log Pis Max                  17.339317
Log Pis Min                  -6.065465
Policy mu Mean               0.013075356
Policy mu Std                0.7786593
Policy mu Max                3.379003
Policy mu Min                -2.5032597
Policy log std Mean          -0.44531807
Policy log std Std           0.20463842
Policy log std Max           -0.12810335
Policy log std Min           -1.8942711
Z mean eval                  2.0361876
Z variance eval              0.013548319
total_rewards                [4760.88826166 4807.56384841 4764.86397556 4604.2524492  4596.94859848
 4850.72336513 4810.88148502 4660.62932514 4570.57482272 4758.09768673]
total_rewards_mean           4718.542381803219
total_rewards_std            96.18845413896143
total_rewards_max            4850.723365126467
total_rewards_min            4570.574822723481
Number of train steps total  84000
Number of env steps total    254000
Number of rollouts total     0
Train Time (s)               142.0042720111087
(Previous) Eval Time (s)     17.802587168756872
Sample Time (s)              5.6005626055411994
Epoch Time (s)               165.40742178540677
Total Train Time (s)         3511.9494775370695
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:52:10.434581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #20 | Epoch Duration: 165.4969961643219
2020-01-12 08:52:10.434788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0380793
Z variance train             0.013576733
KL Divergence                29.003494
KL Loss                      2.9003494
QF Loss                      434.9151
VF Loss                      56.841743
Policy Loss                  -610.7264
Q Predictions Mean           601.98413
Q Predictions Std            510.05133
Q Predictions Max            1693.618
Q Predictions Min            124.833755
V Predictions Mean           609.64
V Predictions Std            510.94025
V Predictions Max            1680.4326
V Predictions Min            135.87263
Log Pis Mean                 -1.9410557
Log Pis Std                  2.8054404
Log Pis Max                  8.169623
Log Pis Min                  -7.3368673
Policy mu Mean               -0.02429389
Policy mu Std                0.67474085
Policy mu Max                2.4181688
Policy mu Min                -2.2684376
Policy log std Mean          -0.4195682
Policy log std Std           0.20062496
Policy log std Max           -0.16138537
Policy log std Min           -1.7702808
Z mean eval                  2.025179
Z variance eval              0.015457749
total_rewards                [4642.04754859 4672.63591211 4704.63247448 4620.64115103 4752.66093323
 4602.03838834 5079.6816223  4497.61826388 4786.90901841 4648.51359052]
total_rewards_mean           4700.737890289772
total_rewards_std            147.68591752773307
total_rewards_max            5079.681622304998
total_rewards_min            4497.618263882255
Number of train steps total  88000
Number of env steps total    266000
Number of rollouts total     0
Train Time (s)               142.99548460543156
(Previous) Eval Time (s)     17.859015784226358
Sample Time (s)              6.667985321488231
Epoch Time (s)               167.52248571114615
Total Train Time (s)         3679.6615470452234
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:54:58.147837 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #21 | Epoch Duration: 167.71291279792786
2020-01-12 08:54:58.147998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.023418
Z variance train             0.015453505
KL Divergence                27.739176
KL Loss                      2.7739177
QF Loss                      547.84827
VF Loss                      152.75642
Policy Loss                  -651.7789
Q Predictions Mean           642.58344
Q Predictions Std            538.62616
Q Predictions Max            1812.4312
Q Predictions Min            96.81076
V Predictions Mean           657.5343
V Predictions Std            541.4896
V Predictions Max            1816.8794
V Predictions Min            128.5691
Log Pis Mean                 -1.495946
Log Pis Std                  3.176322
Log Pis Max                  10.926348
Log Pis Min                  -7.9325523
Policy mu Mean               0.018956264
Policy mu Std                0.7482804
Policy mu Max                2.8720756
Policy mu Min                -2.2401588
Policy log std Mean          -0.44692007
Policy log std Std           0.2161793
Policy log std Max           -0.14366439
Policy log std Min           -1.8633794
Z mean eval                  2.0281339
Z variance eval              0.01714147
total_rewards                [4597.09641947 4687.12053559 4561.88036722 4486.31165808 4745.18781628
 4584.36826656 4614.64885838 4638.46529576 4635.273062   4764.83699843]
total_rewards_mean           4631.518927775065
total_rewards_std            79.67156455104514
total_rewards_max            4764.836998426894
total_rewards_min            4486.31165808141
Number of train steps total  92000
Number of env steps total    278000
Number of rollouts total     0
Train Time (s)               143.04083065968007
(Previous) Eval Time (s)     20.841031291987747
Sample Time (s)              5.558446064591408
Epoch Time (s)               169.44030801625922
Total Train Time (s)         3849.189192353748
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:57:47.676545 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #22 | Epoch Duration: 169.52843403816223
2020-01-12 08:57:47.676697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0243769
Z variance train             0.01729947
KL Divergence                28.261993
KL Loss                      2.8261993
QF Loss                      409.73837
VF Loss                      193.96175
Policy Loss                  -746.556
Q Predictions Mean           740.37976
Q Predictions Std            556.5069
Q Predictions Max            1789.7455
Q Predictions Min            101.513115
V Predictions Mean           750.61646
V Predictions Std            560.095
V Predictions Max            1823.0089
V Predictions Min            119.21659
Log Pis Mean                 -1.3957946
Log Pis Std                  2.9787452
Log Pis Max                  8.2895355
Log Pis Min                  -5.977763
Policy mu Mean               -0.03283703
Policy mu Std                0.7476174
Policy mu Max                2.4543555
Policy mu Min                -2.4720156
Policy log std Mean          -0.466127
Policy log std Std           0.22201559
Policy log std Max           -0.1286805
Policy log std Min           -1.826636
Z mean eval                  2.0326412
Z variance eval              0.028896078
total_rewards                [4669.05711737 4852.18490254 4774.42824169 4946.57610971 4715.19232555
 4836.29778806 4619.8709596  4870.40027789 4814.16670865 4784.92612985]
total_rewards_mean           4788.310056091102
total_rewards_std            93.26397161865265
total_rewards_max            4946.576109708171
total_rewards_min            4619.870959600222
Number of train steps total  96000
Number of env steps total    290000
Number of rollouts total     0
Train Time (s)               141.10860030306503
(Previous) Eval Time (s)     20.56366327079013
Sample Time (s)              6.3761213487014174
Epoch Time (s)               168.04838492255658
Total Train Time (s)         4017.3202581135556
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:00:35.807636 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #23 | Epoch Duration: 168.13083934783936
2020-01-12 09:00:35.807768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0306573
Z variance train             0.029026305
KL Divergence                26.534168
KL Loss                      2.6534169
QF Loss                      337.837
VF Loss                      205.6247
Policy Loss                  -713.5992
Q Predictions Mean           708.9459
Q Predictions Std            557.4165
Q Predictions Max            1774.2218
Q Predictions Min            102.92879
V Predictions Mean           722.3935
V Predictions Std            560.33765
V Predictions Max            1766.4296
V Predictions Min            109.6126
Log Pis Mean                 -1.3685559
Log Pis Std                  3.2782125
Log Pis Max                  10.387593
Log Pis Min                  -6.2781324
Policy mu Mean               -0.011731562
Policy mu Std                0.7513631
Policy mu Max                3.3826246
Policy mu Min                -2.598694
Policy log std Mean          -0.4469289
Policy log std Std           0.20790525
Policy log std Max           -0.08461824
Policy log std Min           -1.7412851
Z mean eval                  2.047018
Z variance eval              0.013464752
total_rewards                [4493.17581748 4903.17742806 4902.48281753 4903.70523446 4824.49535493
 5015.17877966 4862.99264961 5055.62232655 4693.74234792 4912.4287529 ]
total_rewards_mean           4856.700150910781
total_rewards_std            152.9832616733558
total_rewards_max            5055.622326550684
total_rewards_min            4493.1758174775705
Number of train steps total  100000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               142.7698723897338
(Previous) Eval Time (s)     20.68376092100516
Sample Time (s)              6.422889966983348
Epoch Time (s)               169.8765232777223
Total Train Time (s)         4187.292667977046
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:03:25.781355 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #24 | Epoch Duration: 169.9734947681427
2020-01-12 09:03:25.781486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.049327
Z variance train             0.013461389
KL Divergence                29.153847
KL Loss                      2.9153848
QF Loss                      619.75793
VF Loss                      74.08905
Policy Loss                  -737.48126
Q Predictions Mean           732.8335
Q Predictions Std            595.222
Q Predictions Max            1905.4208
Q Predictions Min            97.762924
V Predictions Mean           734.8203
V Predictions Std            602.84515
V Predictions Max            1892.0446
V Predictions Min            89.38137
Log Pis Mean                 -1.4506104
Log Pis Std                  2.9830441
Log Pis Max                  9.500827
Log Pis Min                  -11.382517
Policy mu Mean               -0.025762184
Policy mu Std                0.7205925
Policy mu Max                2.56592
Policy mu Min                -2.437033
Policy log std Mean          -0.45581213
Policy log std Std           0.2215566
Policy log std Max           -0.10289693
Policy log std Min           -1.7334188
Z mean eval                  2.0222604
Z variance eval              0.013711552
total_rewards                [4981.23265904 4943.10141212 5007.24569139 5063.85853729 4656.56662369
 4819.71382857 5021.85060958 4961.23376933 4920.53993101 4880.39479163]
total_rewards_mean           4925.573785364833
total_rewards_std            111.97170480004746
total_rewards_max            5063.858537289605
total_rewards_min            4656.566623687077
Number of train steps total  104000
Number of env steps total    314000
Number of rollouts total     0
Train Time (s)               141.62008549598977
(Previous) Eval Time (s)     18.15337662398815
Sample Time (s)              6.579955822322518
Epoch Time (s)               166.35341794230044
Total Train Time (s)         4353.729885804933
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:06:12.220284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #25 | Epoch Duration: 166.43868494033813
2020-01-12 09:06:12.220463 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0234795
Z variance train             0.013727216
KL Divergence                29.582672
KL Loss                      2.9582672
QF Loss                      472.3687
VF Loss                      152.70818
Policy Loss                  -657.65674
Q Predictions Mean           646.95654
Q Predictions Std            594.7751
Q Predictions Max            1871.282
Q Predictions Min            74.429436
V Predictions Mean           651.1465
V Predictions Std            594.6614
V Predictions Max            1871.5942
V Predictions Min            75.58759
Log Pis Mean                 -1.2451394
Log Pis Std                  3.6449473
Log Pis Max                  16.5498
Log Pis Min                  -6.4693623
Policy mu Mean               -0.052829474
Policy mu Std                0.7481135
Policy mu Max                3.615227
Policy mu Min                -2.6340947
Policy log std Mean          -0.44625163
Policy log std Std           0.21348017
Policy log std Max           -0.13894868
Policy log std Min           -2.0049624
Z mean eval                  2.0357692
Z variance eval              0.012407092
total_rewards                [4832.67316982 4854.17474441 4925.39359424 4775.88037532 4861.57829159
 4812.29789474 5009.44890185 4743.83523951 4775.74990292 4654.94663439]
total_rewards_mean           4824.597874878151
total_rewards_std            93.19452094767739
total_rewards_max            5009.448901854064
total_rewards_min            4654.9466343894865
Number of train steps total  108000
Number of env steps total    326000
Number of rollouts total     0
Train Time (s)               141.2612595348619
(Previous) Eval Time (s)     20.997426039073616
Sample Time (s)              6.409218803979456
Epoch Time (s)               168.66790437791497
Total Train Time (s)         4522.480996177066
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:09:00.971810 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #26 | Epoch Duration: 168.751207113266
2020-01-12 09:09:00.971994 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0352776
Z variance train             0.012401191
KL Divergence                30.053246
KL Loss                      3.0053246
QF Loss                      263.26642
VF Loss                      54.5548
Policy Loss                  -710.5604
Q Predictions Mean           699.81146
Q Predictions Std            621.94183
Q Predictions Max            1934.0841
Q Predictions Min            57.98015
V Predictions Mean           714.37573
V Predictions Std            622.8636
V Predictions Max            1925.218
V Predictions Min            61.315956
Log Pis Mean                 -1.4607358
Log Pis Std                  3.2791247
Log Pis Max                  9.323282
Log Pis Min                  -6.436953
Policy mu Mean               -0.03982942
Policy mu Std                0.6925763
Policy mu Max                2.63727
Policy mu Min                -2.20095
Policy log std Mean          -0.45009172
Policy log std Std           0.21778397
Policy log std Max           -0.16445899
Policy log std Min           -2.0487385
Z mean eval                  2.0214164
Z variance eval              0.010071065
total_rewards                [5182.63918377 5091.50331903 5103.22119622 5039.1372463  5151.28000896
 5128.72296529 5039.69001429 5098.48234197 5255.90866963 5008.14275095]
total_rewards_mean           5109.872769643438
total_rewards_std            70.34264464468178
total_rewards_max            5255.90866963438
total_rewards_min            5008.142750953293
Number of train steps total  112000
Number of env steps total    338000
Number of rollouts total     0
Train Time (s)               141.0411677430384
(Previous) Eval Time (s)     18.003767985850573
Sample Time (s)              6.6133713675662875
Epoch Time (s)               165.65830709645525
Total Train Time (s)         4688.2212854032405
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:11:46.712660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #27 | Epoch Duration: 165.74053406715393
2020-01-12 09:11:46.712831 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #27 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0188687
Z variance train             0.010054784
KL Divergence                30.087471
KL Loss                      3.008747
QF Loss                      266.87878
VF Loss                      121.0192
Policy Loss                  -702.7262
Q Predictions Mean           691.6536
Q Predictions Std            639.0264
Q Predictions Max            2008.6222
Q Predictions Min            50.822777
V Predictions Mean           699.0124
V Predictions Std            641.7784
V Predictions Max            2003.8915
V Predictions Min            52.57433
Log Pis Mean                 -1.7039969
Log Pis Std                  2.9844642
Log Pis Max                  12.922958
Log Pis Min                  -7.612914
Policy mu Mean               -0.059568897
Policy mu Std                0.70399445
Policy mu Max                2.367546
Policy mu Min                -2.6718206
Policy log std Mean          -0.42861238
Policy log std Std           0.2138189
Policy log std Max           -0.10575122
Policy log std Min           -2.140331
Z mean eval                  2.027985
Z variance eval              0.01118052
total_rewards                [4410.39408363 4657.48944395 4767.114662   4921.24410369 4892.8415199
 4743.08554605 4855.15624898 4897.55695556 4526.66983644 4369.1545255 ]
total_rewards_mean           4704.0706925700915
total_rewards_std            195.0935319340546
total_rewards_max            4921.244103687312
total_rewards_min            4369.154525503183
Number of train steps total  116000
Number of env steps total    350000
Number of rollouts total     0
Train Time (s)               140.86426348332316
(Previous) Eval Time (s)     17.746226230170578
Sample Time (s)              6.709316718857735
Epoch Time (s)               165.31980643235147
Total Train Time (s)         4853.639465515502
Epoch                        28
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:14:32.134787 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #28 | Epoch Duration: 165.4217963218689
2020-01-12 09:14:32.135095 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0266674
Z variance train             0.011172461
KL Divergence                30.200075
KL Loss                      3.0200076
QF Loss                      419.12427
VF Loss                      124.63762
Policy Loss                  -685.0663
Q Predictions Mean           674.84155
Q Predictions Std            646.5492
Q Predictions Max            2002.5687
Q Predictions Min            31.501518
V Predictions Mean           681.33026
V Predictions Std            646.2774
V Predictions Max            1990.4631
V Predictions Min            46.71347
Log Pis Mean                 -1.341938
Log Pis Std                  3.5698185
Log Pis Max                  12.222639
Log Pis Min                  -6.309934
Policy mu Mean               -0.040434983
Policy mu Std                0.75269246
Policy mu Max                2.889136
Policy mu Min                -2.5509439
Policy log std Mean          -0.42825142
Policy log std Std           0.20375769
Policy log std Max           -0.14308858
Policy log std Min           -1.8292899
Z mean eval                  2.0582018
Z variance eval              0.010430889
total_rewards                [5008.13326421 4974.93899032 5062.57897545 4870.47741931 4796.37815565
 4859.92731145 4989.17966042 5047.78401663 4946.93882823 5034.46758714]
total_rewards_mean           4959.080420880951
total_rewards_std            84.9284521215626
total_rewards_max            5062.578975451279
total_rewards_min            4796.378155654111
Number of train steps total  120000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               140.1498629320413
(Previous) Eval Time (s)     17.633558608591557
Sample Time (s)              6.662011910695583
Epoch Time (s)               164.44543345132843
Total Train Time (s)         5018.166662522126
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:17:16.660337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #29 | Epoch Duration: 164.52508091926575
2020-01-12 09:17:16.660464 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0576825
Z variance train             0.010412558
KL Divergence                31.138704
KL Loss                      3.1138704
QF Loss                      285.7967
VF Loss                      116.991905
Policy Loss                  -746.8724
Q Predictions Mean           738.9391
Q Predictions Std            664.5203
Q Predictions Max            2037.9059
Q Predictions Min            30.50481
V Predictions Mean           740.34644
V Predictions Std            665.69196
V Predictions Max            2023.6799
V Predictions Min            31.49628
Log Pis Mean                 -1.5492251
Log Pis Std                  3.4208007
Log Pis Max                  13.254298
Log Pis Min                  -7.7265205
Policy mu Mean               -0.013829236
Policy mu Std                0.72250754
Policy mu Max                3.267513
Policy mu Min                -2.490012
Policy log std Mean          -0.4482905
Policy log std Std           0.22513644
Policy log std Max           -0.16336924
Policy log std Min           -2.0232937
Z mean eval                  2.0259438
Z variance eval              0.010483713
total_rewards                [5194.02909708 5278.40269842 4935.91400351 5203.3047555  5086.38994591
 5151.55745666 4928.47303166 5213.3157406  5184.3956227  5020.14055701]
total_rewards_mean           5119.592290905054
total_rewards_std            115.33950608277617
total_rewards_max            5278.402698422147
total_rewards_min            4928.473031656963
Number of train steps total  124000
Number of env steps total    374000
Number of rollouts total     0
Train Time (s)               141.5582011579536
(Previous) Eval Time (s)     17.912122840993106
Sample Time (s)              5.539829174987972
Epoch Time (s)               165.01015317393467
Total Train Time (s)         5183.252319649328
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:20:01.746949 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #30 | Epoch Duration: 165.08639454841614
2020-01-12 09:20:01.747072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.024499
Z variance train             0.010481054
KL Divergence                31.816204
KL Loss                      3.1816204
QF Loss                      320.4638
VF Loss                      120.12851
Policy Loss                  -730.2805
Q Predictions Mean           730.4114
Q Predictions Std            684.0302
Q Predictions Max            2035.8125
Q Predictions Min            28.300985
V Predictions Mean           731.5387
V Predictions Std            686.4791
V Predictions Max            2040.6293
V Predictions Min            28.085276
Log Pis Mean                 -1.7431116
Log Pis Std                  3.3617494
Log Pis Max                  10.267867
Log Pis Min                  -7.428671
Policy mu Mean               -0.093174584
Policy mu Std                0.71207017
Policy mu Max                2.730125
Policy mu Min                -2.4501557
Policy log std Mean          -0.44136313
Policy log std Std           0.21834816
Policy log std Max           -0.13053262
Policy log std Min           -1.9691508
Z mean eval                  2.0677016
Z variance eval              0.011395861
total_rewards                [4913.49948454 5029.09877209 4992.64858802 4943.18625227 5060.08056666
 4849.38693109 5159.94198972 5043.60289026 4833.75016385 4901.20610447]
total_rewards_mean           4972.64017429837
total_rewards_std            97.62232696584172
total_rewards_max            5159.94198972395
total_rewards_min            4833.750163852258
Number of train steps total  128000
Number of env steps total    386000
Number of rollouts total     0
Train Time (s)               141.90789236221462
(Previous) Eval Time (s)     20.776423908770084
Sample Time (s)              5.908073846716434
Epoch Time (s)               168.59239011770114
Total Train Time (s)         5351.927293284796
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:22:50.424460 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #31 | Epoch Duration: 168.67728209495544
2020-01-12 09:22:50.424633 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0681777
Z variance train             0.011424643
KL Divergence                31.909388
KL Loss                      3.1909387
QF Loss                      676.81323
VF Loss                      297.85492
Policy Loss                  -702.78284
Q Predictions Mean           699.1506
Q Predictions Std            674.1053
Q Predictions Max            2018.4272
Q Predictions Min            18.44637
V Predictions Mean           715.4896
V Predictions Std            679.4722
V Predictions Max            2048.6272
V Predictions Min            26.603224
Log Pis Mean                 -1.8288109
Log Pis Std                  2.8762844
Log Pis Max                  7.754303
Log Pis Min                  -6.397706
Policy mu Mean               -0.031804267
Policy mu Std                0.69080275
Policy mu Max                2.4755273
Policy mu Min                -2.460748
Policy log std Mean          -0.43325615
Policy log std Std           0.2059932
Policy log std Max           -0.17781869
Policy log std Min           -1.8117874
Z mean eval                  2.0115523
Z variance eval              0.009158669
total_rewards                [4930.71792118 4961.27760372 4962.53582958 4958.88330646 5123.64096342
 4917.26776985 4894.19879394 5066.61585105 5138.38355569 5131.77833401]
total_rewards_mean           5008.529992890032
total_rewards_std            91.07402678033239
total_rewards_max            5138.383555689717
total_rewards_min            4894.198793941758
Number of train steps total  132000
Number of env steps total    398000
Number of rollouts total     0
Train Time (s)               140.84066153736785
(Previous) Eval Time (s)     21.090258467011154
Sample Time (s)              6.336463165469468
Epoch Time (s)               168.26738316984847
Total Train Time (s)         5520.274471122306
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:25:38.771578 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #32 | Epoch Duration: 168.346825838089
2020-01-12 09:25:38.771712 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0108795
Z variance train             0.009148742
KL Divergence                31.219786
KL Loss                      3.1219785
QF Loss                      462.36652
VF Loss                      98.95071
Policy Loss                  -799.978
Q Predictions Mean           792.73425
Q Predictions Std            697.7275
Q Predictions Max            2116.9197
Q Predictions Min            7.562318
V Predictions Mean           805.38354
V Predictions Std            697.1497
V Predictions Max            2120.521
V Predictions Min            18.913448
Log Pis Mean                 -1.3409331
Log Pis Std                  3.4899313
Log Pis Max                  15.142234
Log Pis Min                  -10.815371
Policy mu Mean               -0.007524267
Policy mu Std                0.7541136
Policy mu Max                2.6081161
Policy mu Min                -2.9091694
Policy log std Mean          -0.44662738
Policy log std Std           0.23447126
Policy log std Max           -0.10689992
Policy log std Min           -1.9322999
Z mean eval                  2.0111644
Z variance eval              0.007921029
total_rewards                [5129.58879806 5111.6687505  5297.14298844 5097.01310495 5127.74535869
 5013.73793278 5257.27606019 5063.39930136 5181.40848919 5325.89018935]
total_rewards_mean           5160.487097349945
total_rewards_std            97.5905148372823
total_rewards_max            5325.8901893526845
total_rewards_min            5013.737932775146
Number of train steps total  136000
Number of env steps total    410000
Number of rollouts total     0
Train Time (s)               142.93487990368158
(Previous) Eval Time (s)     17.54302972694859
Sample Time (s)              6.32580513227731
Epoch Time (s)               166.80371476290748
Total Train Time (s)         5687.161943530664
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:28:25.666689 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #33 | Epoch Duration: 166.89479684829712
2020-01-12 09:28:25.666888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.013196
Z variance train             0.007927309
KL Divergence                32.476612
KL Loss                      3.2476614
QF Loss                      298.3022
VF Loss                      70.395615
Policy Loss                  -746.57043
Q Predictions Mean           743.2012
Q Predictions Std            706.8649
Q Predictions Max            2111.5063
Q Predictions Min            9.975159
V Predictions Mean           748.12537
V Predictions Std            704.9973
V Predictions Max            2103.6926
V Predictions Min            5.57406
Log Pis Mean                 -1.724053
Log Pis Std                  3.1172962
Log Pis Max                  10.207581
Log Pis Min                  -9.23498
Policy mu Mean               -0.11991951
Policy mu Std                0.6812127
Policy mu Max                3.2648926
Policy mu Min                -2.3841546
Policy log std Mean          -0.4455271
Policy log std Std           0.23644611
Policy log std Max           -0.14020789
Policy log std Min           -2.1365905
Z mean eval                  1.9923277
Z variance eval              0.0065028593
total_rewards                [5197.35521313 5141.54552838 5251.19244734 5284.64058169 5181.27458809
 5284.98839445 5165.15116807 5169.73454645 5271.48448344 5131.62165571]
total_rewards_mean           5207.8988606746825
total_rewards_std            56.63429281935582
total_rewards_max            5284.988394448434
total_rewards_min            5131.62165571312
Number of train steps total  140000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               141.8314101928845
(Previous) Eval Time (s)     21.229320212733
Sample Time (s)              6.686043226160109
Epoch Time (s)               169.74677363177761
Total Train Time (s)         5856.989601863548
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:31:15.490472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #34 | Epoch Duration: 169.82345485687256
2020-01-12 09:31:15.490662 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9908043
Z variance train             0.0065027988
KL Divergence                32.60604
KL Loss                      3.2606041
QF Loss                      463.14
VF Loss                      227.22041
Policy Loss                  -795.10925
Q Predictions Mean           785.98083
Q Predictions Std            677.6413
Q Predictions Max            2136.5193
Q Predictions Min            3.414191
V Predictions Mean           790.85913
V Predictions Std            679.9208
V Predictions Max            2105.9216
V Predictions Min            -4.4826446
Log Pis Mean                 -1.2362294
Log Pis Std                  3.76636
Log Pis Max                  18.776363
Log Pis Min                  -11.588324
Policy mu Mean               0.01176576
Policy mu Std                0.76745343
Policy mu Max                3.4863715
Policy mu Min                -2.9122043
Policy log std Mean          -0.46014056
Policy log std Std           0.2393165
Policy log std Max           -0.12928592
Policy log std Min           -2.080087
Z mean eval                  1.982322
Z variance eval              0.01019543
total_rewards                [5511.46937797 5275.52435592 5299.64951233 5623.86889705 5489.50535016
 5528.13720094 5434.59457079 5314.21975526 5166.55774969 5289.20242108]
total_rewards_mean           5393.272919119725
total_rewards_std            136.89826437036996
total_rewards_max            5623.86889705389
total_rewards_min            5166.557749693539
Number of train steps total  144000
Number of env steps total    434000
Number of rollouts total     0
Train Time (s)               142.30565339094028
(Previous) Eval Time (s)     17.496944373007864
Sample Time (s)              6.514322770293802
Epoch Time (s)               166.31692053424194
Total Train Time (s)         6023.396328133531
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:34:01.898952 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #35 | Epoch Duration: 166.4081506729126
2020-01-12 09:34:01.899142 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9842106
Z variance train             0.010114294
KL Divergence                31.774921
KL Loss                      3.1774921
QF Loss                      719.38043
VF Loss                      142.73395
Policy Loss                  -731.98566
Q Predictions Mean           728.1707
Q Predictions Std            687.2407
Q Predictions Max            2071.074
Q Predictions Min            -0.54025406
V Predictions Mean           730.228
V Predictions Std            691.8735
V Predictions Max            2086.4177
V Predictions Min            -3.9985905
Log Pis Mean                 -1.4094245
Log Pis Std                  3.4193897
Log Pis Max                  12.677217
Log Pis Min                  -7.1152325
Policy mu Mean               0.034444217
Policy mu Std                0.7468055
Policy mu Max                2.5352218
Policy mu Min                -2.57408
Policy log std Mean          -0.4505248
Policy log std Std           0.23987654
Policy log std Max           -0.13523254
Policy log std Min           -2.0475059
Z mean eval                  1.9508088
Z variance eval              0.016275797
total_rewards                [5003.12511508 5326.30028738 5190.58051303 5142.59032258 5331.63778743
 5310.00922322 5297.72064848 5135.7072647  5195.42553707 5284.08597899]
total_rewards_mean           5221.718267796825
total_rewards_std            101.7762467060514
total_rewards_max            5331.637787429987
total_rewards_min            5003.125115082092
Number of train steps total  148000
Number of env steps total    446000
Number of rollouts total     0
Train Time (s)               144.4348793583922
(Previous) Eval Time (s)     20.861664231866598
Sample Time (s)              6.419082653708756
Epoch Time (s)               171.71562624396756
Total Train Time (s)         6195.258109313436
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:36:53.772583 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #36 | Epoch Duration: 171.8732626438141
2020-01-12 09:36:53.772891 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9521799
Z variance train             0.0163229
KL Divergence                30.590855
KL Loss                      3.0590856
QF Loss                      715.11865
VF Loss                      172.6002
Policy Loss                  -858.7785
Q Predictions Mean           852.54987
Q Predictions Std            704.0104
Q Predictions Max            2119.3477
Q Predictions Min            172.0868
V Predictions Mean           851.788
V Predictions Std            707.78625
V Predictions Max            2117.8516
V Predictions Min            170.26138
Log Pis Mean                 -0.9219233
Log Pis Std                  3.811944
Log Pis Max                  19.309246
Log Pis Min                  -9.117815
Policy mu Mean               -0.01584625
Policy mu Std                0.82065904
Policy mu Max                2.7104678
Policy mu Min                -2.586577
Policy log std Mean          -0.45785967
Policy log std Std           0.22366466
Policy log std Max           -0.07210088
Policy log std Min           -1.7587082
Z mean eval                  1.9624538
Z variance eval              0.016997833
total_rewards                [5132.91055929 5157.18391045 5281.45662361 5146.77024401 5091.99859833
 5230.39312718 5209.76390769 5175.3328794  5100.81521801 5335.88686695]
total_rewards_mean           5186.251193492533
total_rewards_std            74.50316066494202
total_rewards_max            5335.886866950929
total_rewards_min            5091.998598326392
Number of train steps total  152000
Number of env steps total    458000
Number of rollouts total     0
Train Time (s)               145.45794845093042
(Previous) Eval Time (s)     20.677375125698745
Sample Time (s)              6.431504470761865
Epoch Time (s)               172.56682804739103
Total Train Time (s)         6367.9311778373085
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:39:46.434021 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #37 | Epoch Duration: 172.6609284877777
2020-01-12 09:39:46.434152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9644178
Z variance train             0.017000634
KL Divergence                30.903831
KL Loss                      3.0903833
QF Loss                      364.62387
VF Loss                      87.63764
Policy Loss                  -833.8527
Q Predictions Mean           825.0542
Q Predictions Std            742.15674
Q Predictions Max            2155.3752
Q Predictions Min            -25.079063
V Predictions Mean           836.38275
V Predictions Std            745.8499
V Predictions Max            2155.4973
V Predictions Min            -16.207958
Log Pis Mean                 -1.4076827
Log Pis Std                  3.2843692
Log Pis Max                  9.679754
Log Pis Min                  -6.10823
Policy mu Mean               0.041896883
Policy mu Std                0.7189112
Policy mu Max                2.3668315
Policy mu Min                -2.2783396
Policy log std Mean          -0.45866325
Policy log std Std           0.24457046
Policy log std Max           -0.16071695
Policy log std Min           -1.941442
Z mean eval                  1.9287876
Z variance eval              0.010005602
total_rewards                [5234.26838    5329.25251579 5315.78567077 5207.5551744  5415.67141014
 5449.64089351 5264.04659681 5284.43980118 5182.61279573 5300.13561691]
total_rewards_mean           5298.340885523703
total_rewards_std            80.64172329573218
total_rewards_max            5449.6408935102945
total_rewards_min            5182.612795726832
Number of train steps total  156000
Number of env steps total    470000
Number of rollouts total     0
Train Time (s)               144.1300858198665
(Previous) Eval Time (s)     19.676211544778198
Sample Time (s)              6.481772172264755
Epoch Time (s)               170.28806953690946
Total Train Time (s)         6538.415540090296
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:42:36.920236 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #38 | Epoch Duration: 170.48597359657288
2020-01-12 09:42:36.920432 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9272105
Z variance train             0.010000967
KL Divergence                32.510223
KL Loss                      3.2510223
QF Loss                      577.2046
VF Loss                      84.348495
Policy Loss                  -664.87524
Q Predictions Mean           656.20935
Q Predictions Std            689.24524
Q Predictions Max            2182.8716
Q Predictions Min            -25.503555
V Predictions Mean           665.0832
V Predictions Std            691.6892
V Predictions Max            2192.0193
V Predictions Min            -19.707468
Log Pis Mean                 -1.5502934
Log Pis Std                  3.6842868
Log Pis Max                  16.854641
Log Pis Min                  -5.7363153
Policy mu Mean               -0.032096673
Policy mu Std                0.7010603
Policy mu Max                2.8819785
Policy mu Min                -2.8021574
Policy log std Mean          -0.43353677
Policy log std Std           0.22576028
Policy log std Max           -0.111487776
Policy log std Min           -2.1224132
Z mean eval                  1.9261463
Z variance eval              0.010553861
total_rewards                [4841.72023421 4727.1767504  4673.99357773 4695.26410871 4732.95423643
 4804.11740735 4877.10070315 4711.59387007 4943.79758326 4801.65676445]
total_rewards_mean           4780.937523576407
total_rewards_std            83.19254079580932
total_rewards_max            4943.7975832642405
total_rewards_min            4673.993577734056
Number of train steps total  160000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               144.26923241792247
(Previous) Eval Time (s)     21.0937678120099
Sample Time (s)              6.575462173204869
Epoch Time (s)               171.93846240313724
Total Train Time (s)         6710.44034270104
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:45:28.946509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #39 | Epoch Duration: 172.02594590187073
2020-01-12 09:45:28.946658 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9253658
Z variance train             0.010538174
KL Divergence                31.91695
KL Loss                      3.191695
QF Loss                      289.47015
VF Loss                      93.636505
Policy Loss                  -705.2595
Q Predictions Mean           698.34973
Q Predictions Std            704.986
Q Predictions Max            2164.7893
Q Predictions Min            -40.51577
V Predictions Mean           702.0286
V Predictions Std            708.7143
V Predictions Max            2157.868
V Predictions Min            -30.491829
Log Pis Mean                 -1.5988269
Log Pis Std                  3.524259
Log Pis Max                  15.619225
Log Pis Min                  -7.467081
Policy mu Mean               0.009076622
Policy mu Std                0.71365994
Policy mu Max                2.5810375
Policy mu Min                -3.640359
Policy log std Mean          -0.4447304
Policy log std Std           0.23135073
Policy log std Max           -0.20116125
Policy log std Min           -2.151151
Z mean eval                  1.9241874
Z variance eval              0.007018107
total_rewards                [5255.78238791 5357.09015168 5286.09799596 5145.63399025 5446.89738573
 5469.86368091 5470.00097291 5484.02568532 5471.74067345 5090.33573978]
total_rewards_mean           5347.7468663903
total_rewards_std            138.95727308234007
total_rewards_max            5484.0256853181645
total_rewards_min            5090.335739783655
Number of train steps total  164000
Number of env steps total    494000
Number of rollouts total     0
Train Time (s)               143.19572606729344
(Previous) Eval Time (s)     20.853195880074054
Sample Time (s)              6.616421832703054
Epoch Time (s)               170.66534378007054
Total Train Time (s)         6881.185848126188
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:48:19.693430 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #40 | Epoch Duration: 170.74665665626526
2020-01-12 09:48:19.693619 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9250212
Z variance train             0.0070357444
KL Divergence                33.920822
KL Loss                      3.3920822
QF Loss                      243.66617
VF Loss                      69.93758
Policy Loss                  -766.4918
Q Predictions Mean           757.9278
Q Predictions Std            732.8205
Q Predictions Max            2186.0105
Q Predictions Min            -49.129402
V Predictions Mean           764.6832
V Predictions Std            730.8566
V Predictions Max            2169.438
V Predictions Min            -33.23138
Log Pis Mean                 -1.6020355
Log Pis Std                  3.108923
Log Pis Max                  8.506835
Log Pis Min                  -8.212087
Policy mu Mean               -0.054869715
Policy mu Std                0.71235174
Policy mu Max                2.9054751
Policy mu Min                -2.399456
Policy log std Mean          -0.45114264
Policy log std Std           0.22765432
Policy log std Max           -0.1610497
Policy log std Min           -2.0342834
Z mean eval                  1.9190514
Z variance eval              0.011739949
total_rewards                [5375.27445305 5470.55176071 5318.34127574 5630.99344036 5334.14956611
 5481.03371384 5555.55744295 5505.58239179 5567.26934222 5502.63762853]
total_rewards_mean           5474.139101529052
total_rewards_std            97.67854122860655
total_rewards_max            5630.993440358563
total_rewards_min            5318.341275739586
Number of train steps total  168000
Number of env steps total    506000
Number of rollouts total     0
Train Time (s)               143.62412471883
(Previous) Eval Time (s)     21.018029063940048
Sample Time (s)              6.4341979143209755
Epoch Time (s)               171.076351697091
Total Train Time (s)         7052.3416511416435
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:51:10.850680 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #41 | Epoch Duration: 171.1569230556488
2020-01-12 09:51:10.850870 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9198879
Z variance train             0.011732917
KL Divergence                34.13242
KL Loss                      3.413242
QF Loss                      609.5105
VF Loss                      74.978035
Policy Loss                  -804.8811
Q Predictions Mean           797.6124
Q Predictions Std            753.85614
Q Predictions Max            2188.6362
Q Predictions Min            -75.26409
V Predictions Mean           805.4087
V Predictions Std            756.02185
V Predictions Max            2211.2659
V Predictions Min            -47.226604
Log Pis Mean                 -1.4342676
Log Pis Std                  3.0170403
Log Pis Max                  7.873294
Log Pis Min                  -5.6499586
Policy mu Mean               -0.012094073
Policy mu Std                0.7186303
Policy mu Max                2.4601004
Policy mu Min                -2.3178265
Policy log std Mean          -0.4514916
Policy log std Std           0.2352799
Policy log std Max           -0.102035195
Policy log std Min           -2.2101946
Z mean eval                  1.9269985
Z variance eval              0.013267791
total_rewards                [5316.75040639 5394.59284535 5624.51197886 5448.12631754 5410.69106145
 5397.81146692 5397.91677631 5468.97522051 5419.58793861 5400.23368368]
total_rewards_mean           5427.919769562427
total_rewards_std            75.59835924673186
total_rewards_max            5624.511978855735
total_rewards_min            5316.750406388005
Number of train steps total  172000
Number of env steps total    518000
Number of rollouts total     0
Train Time (s)               143.49168620212004
(Previous) Eval Time (s)     17.771745512727648
Sample Time (s)              6.452022929675877
Epoch Time (s)               167.71545464452356
Total Train Time (s)         7220.141392479185
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:53:58.651610 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #42 | Epoch Duration: 167.80060124397278
2020-01-12 09:53:58.651782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9245384
Z variance train             0.013272281
KL Divergence                34.07424
KL Loss                      3.4074242
QF Loss                      357.13147
VF Loss                      52.87967
Policy Loss                  -819.3936
Q Predictions Mean           809.0873
Q Predictions Std            776.2733
Q Predictions Max            2288.3298
Q Predictions Min            -81.76934
V Predictions Mean           820.7569
V Predictions Std            779.14026
V Predictions Max            2284.8242
V Predictions Min            -53.971855
Log Pis Mean                 -1.3937776
Log Pis Std                  3.290599
Log Pis Max                  9.213146
Log Pis Min                  -6.105917
Policy mu Mean               -0.012945895
Policy mu Std                0.73307234
Policy mu Max                2.6098738
Policy mu Min                -2.747522
Policy log std Mean          -0.44627246
Policy log std Std           0.24057874
Policy log std Max           -0.107094675
Policy log std Min           -1.9801906
Z mean eval                  1.9023939
Z variance eval              0.015818728
total_rewards                [5469.7053899  5304.34691067 5318.87198343 5273.46485828 5475.76758404
 5335.37818025 5353.28994653 5586.96660554 5378.88940983 5557.66317237]
total_rewards_mean           5405.4344040848255
total_rewards_std            104.24217215954204
total_rewards_max            5586.966605542253
total_rewards_min            5273.464858280324
Number of train steps total  176000
Number of env steps total    530000
Number of rollouts total     0
Train Time (s)               143.06550880009308
(Previous) Eval Time (s)     17.937850577756763
Sample Time (s)              6.5041520041413605
Epoch Time (s)               167.5075113819912
Total Train Time (s)         7387.733203678392
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:56:46.243860 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #43 | Epoch Duration: 167.59194827079773
2020-01-12 09:56:46.244029 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9012167
Z variance train             0.015815016
KL Divergence                33.998493
KL Loss                      3.3998494
QF Loss                      239.00424
VF Loss                      67.562
Policy Loss                  -843.2859
Q Predictions Mean           835.68353
Q Predictions Std            768.2106
Q Predictions Max            2215.9426
Q Predictions Min            -88.108795
V Predictions Mean           846.5725
V Predictions Std            770.4154
V Predictions Max            2201.6748
V Predictions Min            -65.46102
Log Pis Mean                 -1.4238472
Log Pis Std                  3.4480162
Log Pis Max                  12.307868
Log Pis Min                  -7.2456417
Policy mu Mean               -0.060283113
Policy mu Std                0.7465031
Policy mu Max                2.421081
Policy mu Min                -2.3180935
Policy log std Mean          -0.45589724
Policy log std Std           0.21825029
Policy log std Max           -0.09982677
Policy log std Min           -2.124179
Z mean eval                  1.9076974
Z variance eval              0.04037873
total_rewards                [5442.26682282 5653.77333504 5710.47590112 5433.29131856 5687.16211155
 5542.57404424 5823.81447824 5477.79926265 5558.08626691 5659.14061679]
total_rewards_mean           5598.838415792896
total_rewards_std            122.03681071785272
total_rewards_max            5823.814478235809
total_rewards_min            5433.291318557084
Number of train steps total  180000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               142.94119915133342
(Previous) Eval Time (s)     17.483790965750813
Sample Time (s)              6.430965636391193
Epoch Time (s)               166.85595575347543
Total Train Time (s)         7554.683714353014
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:59:33.196329 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #44 | Epoch Duration: 166.95216512680054
2020-01-12 09:59:33.196519 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9086632
Z variance train             0.04029987
KL Divergence                33.183628
KL Loss                      3.318363
QF Loss                      304.98355
VF Loss                      73.066986
Policy Loss                  -791.1003
Q Predictions Mean           780.9748
Q Predictions Std            736.90955
Q Predictions Max            2218.1575
Q Predictions Min            -55.744564
V Predictions Mean           789.50476
V Predictions Std            740.0092
V Predictions Max            2206.0757
V Predictions Min            -64.38012
Log Pis Mean                 -1.5340321
Log Pis Std                  3.1847403
Log Pis Max                  8.749015
Log Pis Min                  -7.5470295
Policy mu Mean               0.054742172
Policy mu Std                0.72062105
Policy mu Max                2.8809147
Policy mu Min                -2.7458968
Policy log std Mean          -0.44299898
Policy log std Std           0.23286764
Policy log std Max           0.025168508
Policy log std Min           -2.0386028
Z mean eval                  1.8513556
Z variance eval              0.012730596
total_rewards                [5397.40525502 5370.16353743 5364.22663627 5264.2891714  5653.57532821
 5398.2987839  5505.47656431 5374.14392836 5670.40702041 5507.41517989]
total_rewards_mean           5450.540140520181
total_rewards_std            124.82235879247052
total_rewards_max            5670.407020414031
total_rewards_min            5264.28917139838
Number of train steps total  184000
Number of env steps total    554000
Number of rollouts total     0
Train Time (s)               144.12949279602617
(Previous) Eval Time (s)     17.7068201857619
Sample Time (s)              6.705497145652771
Epoch Time (s)               168.54181012744084
Total Train Time (s)         7723.308288410772
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:02:21.822865 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #45 | Epoch Duration: 168.62620306015015
2020-01-12 10:02:21.823058 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8514168
Z variance train             0.01271406
KL Divergence                33.495567
KL Loss                      3.3495567
QF Loss                      798.3193
VF Loss                      116.25695
Policy Loss                  -747.9724
Q Predictions Mean           744.17285
Q Predictions Std            755.35126
Q Predictions Max            2231.7295
Q Predictions Min            -56.000004
V Predictions Mean           747.9063
V Predictions Std            757.167
V Predictions Max            2235.5469
V Predictions Min            -54.767166
Log Pis Mean                 -1.1282357
Log Pis Std                  4.2470374
Log Pis Max                  23.090826
Log Pis Min                  -6.331657
Policy mu Mean               -0.06748571
Policy mu Std                0.8153058
Policy mu Max                4.0017395
Policy mu Min                -3.435657
Policy log std Mean          -0.43858957
Policy log std Std           0.21946585
Policy log std Max           -0.10813171
Policy log std Min           -2.1583917
Z mean eval                  1.8712082
Z variance eval              0.011885815
total_rewards                [5748.18982476 5783.06332014 5801.04602692 5645.08982198 5912.64965793
 5446.26334313 5708.11983901 5468.15816221 5646.84801799 5877.33752092]
total_rewards_mean           5703.6765534995375
total_rewards_std            148.3254860848242
total_rewards_max            5912.649657928322
total_rewards_min            5446.263343130335
Number of train steps total  188000
Number of env steps total    566000
Number of rollouts total     0
Train Time (s)               143.74878730112687
(Previous) Eval Time (s)     20.993784388992935
Sample Time (s)              6.59814507747069
Epoch Time (s)               171.3407167675905
Total Train Time (s)         7894.73615465872
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:05:13.254833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #46 | Epoch Duration: 171.43160009384155
2020-01-12 10:05:13.255145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #46 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8703245
Z variance train             0.01186792
KL Divergence                34.213387
KL Loss                      3.4213388
QF Loss                      263.79547
VF Loss                      90.35279
Policy Loss                  -792.53284
Q Predictions Mean           786.1685
Q Predictions Std            775.6831
Q Predictions Max            2308.4768
Q Predictions Min            -65.19418
V Predictions Mean           792.46094
V Predictions Std            777.14966
V Predictions Max            2282.9478
V Predictions Min            -66.33347
Log Pis Mean                 -1.6301293
Log Pis Std                  3.3078823
Log Pis Max                  11.368031
Log Pis Min                  -6.164665
Policy mu Mean               -0.054120336
Policy mu Std                0.69927406
Policy mu Max                2.808352
Policy mu Min                -2.4019203
Policy log std Mean          -0.45429122
Policy log std Std           0.2128615
Policy log std Max           -0.102273166
Policy log std Min           -1.7564662
Z mean eval                  1.8721428
Z variance eval              0.014268237
total_rewards                [5837.07552907 5850.41816961 5685.3987722  5558.38789608 5695.0855481
 5829.82082335 5717.63035447 5645.28799124 5734.21405516 5902.26022629]
total_rewards_mean           5745.557936558669
total_rewards_std            101.58193069532491
total_rewards_max            5902.260226291442
total_rewards_min            5558.387896084663
Number of train steps total  192000
Number of env steps total    578000
Number of rollouts total     0
Train Time (s)               143.50604869890958
(Previous) Eval Time (s)     17.73321666009724
Sample Time (s)              6.572123273741454
Epoch Time (s)               167.81138863274828
Total Train Time (s)         8062.632033065893
Epoch                        47
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:08:01.153273 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #47 | Epoch Duration: 167.8978705406189
2020-01-12 10:08:01.153607 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8735416
Z variance train             0.014314108
KL Divergence                34.210564
KL Loss                      3.4210565
QF Loss                      250.75179
VF Loss                      230.21744
Policy Loss                  -805.6316
Q Predictions Mean           799.13165
Q Predictions Std            794.46466
Q Predictions Max            2305.2632
Q Predictions Min            -59.250427
V Predictions Mean           798.6417
V Predictions Std            790.8266
V Predictions Max            2299.6558
V Predictions Min            -62.800117
Log Pis Mean                 -1.2670431
Log Pis Std                  3.7135718
Log Pis Max                  17.32623
Log Pis Min                  -6.441077
Policy mu Mean               -0.04691881
Policy mu Std                0.77236515
Policy mu Max                3.768476
Policy mu Min                -3.090287
Policy log std Mean          -0.46376157
Policy log std Std           0.24075274
Policy log std Max           -0.093961075
Policy log std Min           -2.1406426
Z mean eval                  1.9214566
Z variance eval              0.011791075
total_rewards                [5758.43177881 5669.22291618 5656.82555825 5533.6128064  5626.79835746
 5670.77350392 5878.66056699 5648.72597391 5743.69573581 5940.92112123]
total_rewards_mean           5712.7668318967935
total_rewards_std            115.32298504122477
total_rewards_max            5940.921121234132
total_rewards_min            5533.612806399934
Number of train steps total  196000
Number of env steps total    590000
Number of rollouts total     0
Train Time (s)               143.26335357129574
(Previous) Eval Time (s)     17.49813678022474
Sample Time (s)              6.509714362677187
Epoch Time (s)               167.27120471419767
Total Train Time (s)         8230.244601687416
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:10:48.769858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #48 | Epoch Duration: 167.6159737110138
2020-01-12 10:10:48.770176 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9220638
Z variance train             0.0117493365
KL Divergence                35.493843
KL Loss                      3.5493844
QF Loss                      172.55757
VF Loss                      130.18073
Policy Loss                  -838.7869
Q Predictions Mean           827.76196
Q Predictions Std            800.6093
Q Predictions Max            2316.8987
Q Predictions Min            -76.63891
V Predictions Mean           834.1653
V Predictions Std            798.9641
V Predictions Max            2306.9578
V Predictions Min            -60.37817
Log Pis Mean                 -1.3084625
Log Pis Std                  3.254869
Log Pis Max                  14.246044
Log Pis Min                  -8.17382
Policy mu Mean               -0.006135013
Policy mu Std                0.763452
Policy mu Max                3.1488557
Policy mu Min                -2.7901874
Policy log std Mean          -0.4522685
Policy log std Std           0.23155563
Policy log std Max           -0.16862334
Policy log std Min           -1.8720639
Z mean eval                  1.8891805
Z variance eval              0.026165362
total_rewards                [5804.44341711 5732.65804189 5751.82011639 5854.74367568 5720.83650314
 5904.0218234  5779.60885161 5630.85105581 5485.92094092 5787.32155007]
total_rewards_mean           5745.22259760217
total_rewards_std            111.7086290452769
total_rewards_max            5904.021823400131
total_rewards_min            5485.920940919257
Number of train steps total  200000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               143.59499228699133
(Previous) Eval Time (s)     20.5200759540312
Sample Time (s)              6.3855237369425595
Epoch Time (s)               170.5005919779651
Total Train Time (s)         8400.834318274632
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:13:39.354457 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #49 | Epoch Duration: 170.58405089378357
2020-01-12 10:13:39.354586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #49 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8877255
Z variance train             0.026143441
KL Divergence                34.261887
KL Loss                      3.4261887
QF Loss                      151.47
VF Loss                      74.689224
Policy Loss                  -777.18005
Q Predictions Mean           769.6283
Q Predictions Std            770.9103
Q Predictions Max            2333.2605
Q Predictions Min            -62.803467
V Predictions Mean           777.297
V Predictions Std            773.03485
V Predictions Max            2328.6194
V Predictions Min            -62.887608
Log Pis Mean                 -1.529425
Log Pis Std                  3.6031268
Log Pis Max                  17.604313
Log Pis Min                  -7.6806536
Policy mu Mean               -0.06453533
Policy mu Std                0.7351338
Policy mu Max                3.340883
Policy mu Min                -3.248255
Policy log std Mean          -0.4403194
Policy log std Std           0.219875
Policy log std Max           -0.12182957
Policy log std Min           -1.9094846
Z mean eval                  1.8983333
Z variance eval              0.03466819
total_rewards                [5956.75127262 1699.77521269 5811.72847505 5773.0327818  5821.3959483
 5721.56651624 5658.80711247 5837.42073997 6047.07290058 5953.67949323]
total_rewards_mean           5428.1230452949185
total_rewards_std            1247.6763245181592
total_rewards_max            6047.072900581278
total_rewards_min            1699.775212686662
Number of train steps total  204000
Number of env steps total    614000
Number of rollouts total     0
Train Time (s)               143.0922031570226
(Previous) Eval Time (s)     17.62692299997434
Sample Time (s)              6.368096839636564
Epoch Time (s)               167.0872229966335
Total Train Time (s)         8567.995984552428
Epoch                        50
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:16:26.516928 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #50 | Epoch Duration: 167.16224241256714
2020-01-12 10:16:26.517052 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8970093
Z variance train             0.03462486
KL Divergence                32.347282
KL Loss                      3.2347283
QF Loss                      238.3025
VF Loss                      70.43088
Policy Loss                  -772.3433
Q Predictions Mean           762.6304
Q Predictions Std            776.8947
Q Predictions Max            2348.6226
Q Predictions Min            -78.86066
V Predictions Mean           768.6371
V Predictions Std            777.508
V Predictions Max            2334.2148
V Predictions Min            -67.32561
Log Pis Mean                 -1.4217439
Log Pis Std                  3.4403946
Log Pis Max                  17.663092
Log Pis Min                  -6.4747696
Policy mu Mean               -0.006363314
Policy mu Std                0.7322028
Policy mu Max                2.9210782
Policy mu Min                -3.011281
Policy log std Mean          -0.4603014
Policy log std Std           0.23135853
Policy log std Max           -0.1317612
Policy log std Min           -2.0758135
Z mean eval                  1.8859174
Z variance eval              0.028622497
total_rewards                [5676.73303539 6136.70675763 5807.77601871 5843.73649974 5867.46245166
 5539.20326202 5775.14656404 5625.9146136  5841.53958546 5851.46430082]
total_rewards_mean           5796.5683089078075
total_rewards_std            154.36496215590952
total_rewards_max            6136.7067576262425
total_rewards_min            5539.203262022167
Number of train steps total  208000
Number of env steps total    626000
Number of rollouts total     0
Train Time (s)               140.98946531908587
(Previous) Eval Time (s)     20.95800048438832
Sample Time (s)              5.5577001688070595
Epoch Time (s)               167.50516597228125
Total Train Time (s)         8735.581801717635
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:19:14.104274 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #51 | Epoch Duration: 167.58712887763977
2020-01-12 10:19:14.104404 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8855245
Z variance train             0.02874494
KL Divergence                32.242107
KL Loss                      3.2242107
QF Loss                      415.83487
VF Loss                      130.15628
Policy Loss                  -863.2267
Q Predictions Mean           851.42523
Q Predictions Std            818.6352
Q Predictions Max            2347.273
Q Predictions Min            -71.14651
V Predictions Mean           862.005
V Predictions Std            818.00867
V Predictions Max            2336.8342
V Predictions Min            -59.318924
Log Pis Mean                 -1.0537436
Log Pis Std                  3.5502145
Log Pis Max                  16.264355
Log Pis Min                  -6.4583836
Policy mu Mean               -0.0024442847
Policy mu Std                0.7759726
Policy mu Max                2.6581337
Policy mu Min                -3.0068195
Policy log std Mean          -0.46276775
Policy log std Std           0.22981273
Policy log std Max           -0.11840966
Policy log std Min           -1.8850093
Z mean eval                  1.8791876
Z variance eval              0.05245585
total_rewards                [5647.46107092 5810.82622592 5733.83735299 5746.90792243 5470.40518885
 5541.54561808 5705.30807394 5811.23556752 5796.46995441 5680.22718485]
total_rewards_mean           5694.422415992133
total_rewards_std            108.62666732609759
total_rewards_max            5811.235567519679
total_rewards_min            5470.405188848102
Number of train steps total  212000
Number of env steps total    638000
Number of rollouts total     0
Train Time (s)               142.00966284796596
(Previous) Eval Time (s)     17.656149435788393
Sample Time (s)              6.600771842524409
Epoch Time (s)               166.26658412627876
Total Train Time (s)         8901.922805187758
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:22:00.445970 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #52 | Epoch Duration: 166.34147119522095
2020-01-12 10:22:00.446101 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8796126
Z variance train             0.05281351
KL Divergence                31.209103
KL Loss                      3.1209104
QF Loss                      385.22107
VF Loss                      154.79964
Policy Loss                  -882.1649
Q Predictions Mean           876.24396
Q Predictions Std            834.06836
Q Predictions Max            2412.9082
Q Predictions Min            -84.228714
V Predictions Mean           882.1519
V Predictions Std            831.72
V Predictions Max            2375.1313
V Predictions Min            -62.908863
Log Pis Mean                 -1.2079711
Log Pis Std                  3.4926126
Log Pis Max                  14.1277485
Log Pis Min                  -7.2336392
Policy mu Mean               -0.08577788
Policy mu Std                0.7572583
Policy mu Max                3.0300536
Policy mu Min                -2.4278972
Policy log std Mean          -0.45907047
Policy log std Std           0.22877806
Policy log std Max           -0.13666219
Policy log std Min           -2.0360932
Z mean eval                  1.8759577
Z variance eval              0.019643849
total_rewards                [6015.20083317 5955.70823263 6288.19307968 6084.16033687 6059.58445514
 6035.6238619  5759.36011688 6073.98305983 6069.37890615 6141.730862  ]
total_rewards_mean           6048.29237442458
total_rewards_std            127.32281349773167
total_rewards_max            6288.193079683072
total_rewards_min            5759.360116880512
Number of train steps total  216000
Number of env steps total    650000
Number of rollouts total     0
Train Time (s)               141.87324781576172
(Previous) Eval Time (s)     17.40392248891294
Sample Time (s)              5.383260604459792
Epoch Time (s)               164.66043090913445
Total Train Time (s)         9066.660925125703
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:24:45.188692 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #53 | Epoch Duration: 164.7424509525299
2020-01-12 10:24:45.188985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8752245
Z variance train             0.019695168
KL Divergence                32.45962
KL Loss                      3.2459621
QF Loss                      526.9427
VF Loss                      115.280945
Policy Loss                  -811.3098
Q Predictions Mean           811.2045
Q Predictions Std            791.34064
Q Predictions Max            2404.5454
Q Predictions Min            -61.525093
V Predictions Mean           804.0415
V Predictions Std            792.68384
V Predictions Max            2385.5576
V Predictions Min            -67.08904
Log Pis Mean                 -1.5077579
Log Pis Std                  3.3026364
Log Pis Max                  13.840845
Log Pis Min                  -7.509549
Policy mu Mean               -0.024167174
Policy mu Std                0.7159687
Policy mu Max                2.6582415
Policy mu Min                -2.9119568
Policy log std Mean          -0.4569099
Policy log std Std           0.249724
Policy log std Max           -0.0557594
Policy log std Min           -1.894979
Z mean eval                  1.8687963
Z variance eval              0.017156215
total_rewards                [6094.39871867 5967.25560032 6261.16660472 6233.36304866 6028.57398998
 6022.62935986 6103.81386295 6172.3787617  6170.77288427 5944.30641934]
total_rewards_mean           6099.865925047094
total_rewards_std            103.44228401755637
total_rewards_max            6261.166604715957
total_rewards_min            5944.306419342358
Number of train steps total  220000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               142.35266576800495
(Previous) Eval Time (s)     17.484444808214903
Sample Time (s)              5.55425452394411
Epoch Time (s)               165.39136510016397
Total Train Time (s)         9232.132719982881
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:27:30.659787 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #54 | Epoch Duration: 165.47057723999023
2020-01-12 10:27:30.659960 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8665617
Z variance train             0.017196361
KL Divergence                32.11814
KL Loss                      3.2118142
QF Loss                      869.615
VF Loss                      83.93859
Policy Loss                  -813.8923
Q Predictions Mean           803.3523
Q Predictions Std            800.8981
Q Predictions Max            2377.5645
Q Predictions Min            -71.04194
V Predictions Mean           811.28357
V Predictions Std            798.81366
V Predictions Max            2362.3835
V Predictions Min            -65.080826
Log Pis Mean                 -1.5664377
Log Pis Std                  3.0562074
Log Pis Max                  9.094181
Log Pis Min                  -6.759577
Policy mu Mean               0.015075472
Policy mu Std                0.71984273
Policy mu Max                2.4889178
Policy mu Min                -3.2864187
Policy log std Mean          -0.4525486
Policy log std Std           0.23027934
Policy log std Max           0.08763325
Policy log std Min           -2.2802095
Z mean eval                  1.9073509
Z variance eval              0.021411065
total_rewards                [5741.54867847 5813.77340642 5757.02317438 5874.51514773 6029.57331223
 5817.32682192 5908.44064017 5899.13547085 5813.33301009 5800.32795427]
total_rewards_mean           5845.499761652221
total_rewards_std            80.66765806150396
total_rewards_max            6029.573312234016
total_rewards_min            5741.5486784674285
Number of train steps total  224000
Number of env steps total    674000
Number of rollouts total     0
Train Time (s)               142.24116083234549
(Previous) Eval Time (s)     17.85305330483243
Sample Time (s)              5.736719515640289
Epoch Time (s)               165.8309336528182
Total Train Time (s)         9398.095145242289
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:30:16.627333 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #55 | Epoch Duration: 165.96720552444458
2020-01-12 10:30:16.627640 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9079523
Z variance train             0.021327242
KL Divergence                32.34118
KL Loss                      3.234118
QF Loss                      297.69354
VF Loss                      109.85297
Policy Loss                  -807.7722
Q Predictions Mean           798.99347
Q Predictions Std            800.4997
Q Predictions Max            2510.236
Q Predictions Min            -66.91797
V Predictions Mean           806.35175
V Predictions Std            800.03674
V Predictions Max            2516.539
V Predictions Min            -79.96045
Log Pis Mean                 -1.3187336
Log Pis Std                  3.8927338
Log Pis Max                  22.023584
Log Pis Min                  -7.100261
Policy mu Mean               -0.07080189
Policy mu Std                0.75371224
Policy mu Max                3.4942703
Policy mu Min                -3.4144812
Policy log std Mean          -0.44200215
Policy log std Std           0.22220433
Policy log std Max           -0.018855155
Policy log std Min           -2.0377605
Z mean eval                  1.9003198
Z variance eval              0.016185593
total_rewards                [5750.16359294 5929.24298895 6083.53535391 6139.56655124 5960.96412124
 6082.23952813 5974.01794056 6103.08198822 6121.9520657  6022.24441339]
total_rewards_mean           6016.700854428677
total_rewards_std            112.27101178876529
total_rewards_max            6139.566551243188
total_rewards_min            5750.16359293663
Number of train steps total  228000
Number of env steps total    686000
Number of rollouts total     0
Train Time (s)               143.50717155635357
(Previous) Eval Time (s)     18.054022955708206
Sample Time (s)              6.491305843926966
Epoch Time (s)               168.05250035598874
Total Train Time (s)         9566.24206357263
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:33:04.774475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #56 | Epoch Duration: 168.14661693572998
2020-01-12 10:33:04.774687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.899774
Z variance train             0.0162099
KL Divergence                34.23713
KL Loss                      3.423713
QF Loss                      760.7185
VF Loss                      149.54698
Policy Loss                  -861.9661
Q Predictions Mean           856.6144
Q Predictions Std            815.158
Q Predictions Max            2397.2427
Q Predictions Min            -80.41623
V Predictions Mean           870.09296
V Predictions Std            822.50336
V Predictions Max            2416.4675
V Predictions Min            -74.714424
Log Pis Mean                 -1.0770266
Log Pis Std                  3.4037735
Log Pis Max                  10.692542
Log Pis Min                  -7.0710588
Policy mu Mean               -0.023240903
Policy mu Std                0.77144516
Policy mu Max                2.6875458
Policy mu Min                -2.5628715
Policy log std Mean          -0.47222805
Policy log std Std           0.23849125
Policy log std Max           0.012934864
Policy log std Min           -2.3637486
Z mean eval                  1.8927075
Z variance eval              0.019894749
total_rewards                [6191.0840435  6433.2354981  6277.76043254 6195.72947268 6201.78595471
 6217.14165692 5986.72057399 6357.57680424 5997.79880047 6169.75077874]
total_rewards_mean           6202.858401589968
total_rewards_std            131.482865362053
total_rewards_max            6433.235498098495
total_rewards_min            5986.720573989353
Number of train steps total  232000
Number of env steps total    698000
Number of rollouts total     0
Train Time (s)               143.93344952864572
(Previous) Eval Time (s)     17.77554969023913
Sample Time (s)              6.518613598309457
Epoch Time (s)               168.2276128171943
Total Train Time (s)         9734.555853433907
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:35:53.088547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #57 | Epoch Duration: 168.31372570991516
2020-01-12 10:35:53.088678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8901827
Z variance train             0.019898092
KL Divergence                32.486
KL Loss                      3.2486
QF Loss                      201.25052
VF Loss                      170.5032
Policy Loss                  -729.086
Q Predictions Mean           722.7387
Q Predictions Std            750.1167
Q Predictions Max            2387.3716
Q Predictions Min            -77.74265
V Predictions Mean           729.80115
V Predictions Std            753.97125
V Predictions Max            2400.3093
V Predictions Min            -66.036446
Log Pis Mean                 -1.4717016
Log Pis Std                  3.694242
Log Pis Max                  19.116325
Log Pis Min                  -9.39739
Policy mu Mean               -0.07228136
Policy mu Std                0.73850834
Policy mu Max                2.7865067
Policy mu Min                -4.252967
Policy log std Mean          -0.44299603
Policy log std Std           0.227759
Policy log std Max           -0.08598387
Policy log std Min           -2.3459992
Z mean eval                  1.9252005
Z variance eval              0.017758148
total_rewards                [6232.47442118 6549.95927191 6500.69857661 6588.60745011 6357.09258942
 6555.11790968 6294.38454278 6280.46786495 6426.14816771 6524.62318688]
total_rewards_mean           6430.957398123196
total_rewards_std            124.19412411897807
total_rewards_max            6588.607450106943
total_rewards_min            6232.474421177899
Number of train steps total  236000
Number of env steps total    710000
Number of rollouts total     0
Train Time (s)               143.56845584418625
(Previous) Eval Time (s)     17.46554338792339
Sample Time (s)              6.655137183144689
Epoch Time (s)               167.68913641525432
Total Train Time (s)         9902.323139491957
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:38:40.857938 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #58 | Epoch Duration: 167.76915979385376
2020-01-12 10:38:40.858095 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9256147
Z variance train             0.017781407
KL Divergence                33.81601
KL Loss                      3.381601
QF Loss                      525.77045
VF Loss                      149.92085
Policy Loss                  -814.11053
Q Predictions Mean           808.9618
Q Predictions Std            809.64166
Q Predictions Max            2519.901
Q Predictions Min            -87.74165
V Predictions Mean           820.72473
V Predictions Std            811.73755
V Predictions Max            2493.5474
V Predictions Min            -75.8555
Log Pis Mean                 -1.1665244
Log Pis Std                  3.6893735
Log Pis Max                  16.430046
Log Pis Min                  -6.7211456
Policy mu Mean               -0.019803995
Policy mu Std                0.79165024
Policy mu Max                2.987426
Policy mu Min                -3.812008
Policy log std Mean          -0.44716606
Policy log std Std           0.22465664
Policy log std Max           -0.1455696
Policy log std Min           -2.0556123
Z mean eval                  1.8994443
Z variance eval              0.018577283
total_rewards                [6179.69659985 5839.93603208 6391.65903948 5682.45034428 5821.75260873
 1956.58622205 2033.34338564 5768.90171347 6056.36358283 4626.18300337]
total_rewards_mean           5035.68725317783
total_rewards_std            1583.4280347477397
total_rewards_max            6391.659039478091
total_rewards_min            1956.5862220484519
Number of train steps total  240000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               145.5277861300856
(Previous) Eval Time (s)     20.940628021024168
Sample Time (s)              5.603038269560784
Epoch Time (s)               172.07145242067054
Total Train Time (s)         10074.489447663072
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:41:33.028203 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #59 | Epoch Duration: 172.16996479034424
2020-01-12 10:41:33.028406 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8970039
Z variance train             0.018603487
KL Divergence                33.86045
KL Loss                      3.3860452
QF Loss                      277.7254
VF Loss                      156.77536
Policy Loss                  -762.06647
Q Predictions Mean           757.0532
Q Predictions Std            789.22504
Q Predictions Max            2477.9065
Q Predictions Min            -87.934555
V Predictions Mean           764.00836
V Predictions Std            793.2942
V Predictions Max            2478.8623
V Predictions Min            -81.49993
Log Pis Mean                 -1.3691115
Log Pis Std                  3.4341438
Log Pis Max                  15.413858
Log Pis Min                  -6.8653936
Policy mu Mean               0.022725277
Policy mu Std                0.7350813
Policy mu Max                2.6911309
Policy mu Min                -2.8846364
Policy log std Mean          -0.45042458
Policy log std Std           0.25385845
Policy log std Max           -0.12046051
Policy log std Min           -2.128117
Z mean eval                  1.9029392
Z variance eval              0.017013725
total_rewards                [6235.91544582 6504.20496221 6375.14782225 6369.74126573 6166.15508737
 6293.38570539 6328.76199036 6102.2269525  6278.81708252 6292.63418005]
total_rewards_mean           6294.699049421808
total_rewards_std            106.97623403139809
total_rewards_max            6504.204962212936
total_rewards_min            6102.226952496244
Number of train steps total  244000
Number of env steps total    734000
Number of rollouts total     0
Train Time (s)               143.45485528977588
(Previous) Eval Time (s)     20.97137754689902
Sample Time (s)              6.665078236721456
Epoch Time (s)               171.09131107339635
Total Train Time (s)         10245.667335619219
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:44:24.205399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #60 | Epoch Duration: 171.1768479347229
2020-01-12 10:44:24.205541 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9049244
Z variance train             0.01703859
KL Divergence                34.448112
KL Loss                      3.4448113
QF Loss                      219.80353
VF Loss                      65.774864
Policy Loss                  -732.9619
Q Predictions Mean           726.8058
Q Predictions Std            778.2118
Q Predictions Max            2483.9985
Q Predictions Min            -86.07766
V Predictions Mean           737.10645
V Predictions Std            781.17474
V Predictions Max            2484.1135
V Predictions Min            -75.22249
Log Pis Mean                 -1.8051128
Log Pis Std                  3.3693051
Log Pis Max                  11.850742
Log Pis Min                  -7.1885705
Policy mu Mean               -0.08657376
Policy mu Std                0.6796428
Policy mu Max                2.5687294
Policy mu Min                -2.6017447
Policy log std Mean          -0.4360343
Policy log std Std           0.22039998
Policy log std Max           -0.1517443
Policy log std Min           -1.8560152
Z mean eval                  1.8915558
Z variance eval              0.00734269
total_rewards                [6068.06574159 6378.23425657 6509.98468874 6065.62202989 6396.45389856
 6312.56601133 6358.0875473  6079.8965333  6382.86058413 6461.07551483]
total_rewards_mean           6301.2846806235775
total_rewards_std            159.0648778764951
total_rewards_max            6509.984688743908
total_rewards_min            6065.622029885062
Number of train steps total  248000
Number of env steps total    746000
Number of rollouts total     0
Train Time (s)               142.75785920303315
(Previous) Eval Time (s)     18.127722821664065
Sample Time (s)              6.582495357375592
Epoch Time (s)               167.4680773820728
Total Train Time (s)         10413.215161677916
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:47:11.758573 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #61 | Epoch Duration: 167.55288290977478
2020-01-12 10:47:11.758931 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8889208
Z variance train             0.0073339297
KL Divergence                35.53086
KL Loss                      3.553086
QF Loss                      297.96295
VF Loss                      41.249165
Policy Loss                  -705.5631
Q Predictions Mean           701.0416
Q Predictions Std            779.5128
Q Predictions Max            2433.4177
Q Predictions Min            -101.09969
V Predictions Mean           707.49475
V Predictions Std            783.0013
V Predictions Max            2422.8987
V Predictions Min            -79.826675
Log Pis Mean                 -1.7390406
Log Pis Std                  3.130801
Log Pis Max                  9.510326
Log Pis Min                  -6.8319407
Policy mu Mean               -0.051184982
Policy mu Std                0.6825109
Policy mu Max                2.7602153
Policy mu Min                -2.834474
Policy log std Mean          -0.42968836
Policy log std Std           0.23661794
Policy log std Max           -0.10862002
Policy log std Min           -2.1391056
Z mean eval                  1.9061356
Z variance eval              0.010682837
total_rewards                [6578.70640839 6296.01658627 6647.87899137 6412.69145483 6621.60786681
 6539.4973007  6904.93949966 6519.23629678 6655.26221568 6670.42525279]
total_rewards_mean           6584.626187329445
total_rewards_std            154.76584250645024
total_rewards_max            6904.9394996624
total_rewards_min            6296.016586272183
Number of train steps total  252000
Number of env steps total    758000
Number of rollouts total     0
Train Time (s)               144.06320699770004
(Previous) Eval Time (s)     21.253501236904413
Sample Time (s)              6.580273406114429
Epoch Time (s)               171.89698164071888
Total Train Time (s)         10585.197605942376
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:50:03.739242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #62 | Epoch Duration: 171.9801001548767
2020-01-12 10:50:03.739375 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9030536
Z variance train             0.010661701
KL Divergence                34.51133
KL Loss                      3.451133
QF Loss                      533.4357
VF Loss                      224.12732
Policy Loss                  -799.53485
Q Predictions Mean           795.2047
Q Predictions Std            836.0689
Q Predictions Max            2506.205
Q Predictions Min            -91.86117
V Predictions Mean           804.6668
V Predictions Std            837.33856
V Predictions Max            2508.2083
V Predictions Min            -87.94418
Log Pis Mean                 -1.0170063
Log Pis Std                  3.7692072
Log Pis Max                  15.681114
Log Pis Min                  -6.8727045
Policy mu Mean               -0.02965185
Policy mu Std                0.79105115
Policy mu Max                2.8841016
Policy mu Min                -3.410555
Policy log std Mean          -0.46799955
Policy log std Std           0.25324714
Policy log std Max           -0.16248855
Policy log std Min           -2.387453
Z mean eval                  1.8945932
Z variance eval              0.034098804
total_rewards                [6133.88904043 6035.04528481 5973.69116365 6196.54693396 6231.14843161
 6126.38545327 6229.95174404 6051.97928623 6301.1612887  6305.07116501]
total_rewards_mean           6158.486979171353
total_rewards_std            107.72425081504889
total_rewards_max            6305.071165012144
total_rewards_min            5973.691163654465
Number of train steps total  256000
Number of env steps total    770000
Number of rollouts total     0
Train Time (s)               143.02481592819095
(Previous) Eval Time (s)     21.04295474709943
Sample Time (s)              6.429969357326627
Epoch Time (s)               170.497740032617
Total Train Time (s)         10755.776366087608
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:52:54.318784 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #63 | Epoch Duration: 170.5793161392212
2020-01-12 10:52:54.318916 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8936714
Z variance train             0.03406387
KL Divergence                33.081333
KL Loss                      3.3081334
QF Loss                      395.1482
VF Loss                      165.02176
Policy Loss                  -799.7164
Q Predictions Mean           795.4488
Q Predictions Std            812.8137
Q Predictions Max            2613.428
Q Predictions Min            -78.51393
V Predictions Mean           806.78406
V Predictions Std            818.95404
V Predictions Max            2627.4404
V Predictions Min            -75.4325
Log Pis Mean                 -1.3049312
Log Pis Std                  3.3859644
Log Pis Max                  13.0040455
Log Pis Min                  -8.009828
Policy mu Mean               -0.088264674
Policy mu Std                0.7270105
Policy mu Max                2.7207222
Policy mu Min                -2.8013778
Policy log std Mean          -0.47342777
Policy log std Std           0.23787615
Policy log std Max           0.15596122
Policy log std Min           -2.1306317
Z mean eval                  1.8937544
Z variance eval              0.032910757
total_rewards                [6250.30204844 6413.6037487  6319.19397326 6223.21864185 6300.58138456
 5993.63460393 3371.53694921 6087.01571336 6279.91245524 6478.31883729]
total_rewards_mean           5971.73183558147
total_rewards_std            877.0039317627335
total_rewards_max            6478.318837287303
total_rewards_min            3371.536949209729
Number of train steps total  260000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               143.5806488879025
(Previous) Eval Time (s)     17.724546923767775
Sample Time (s)              6.459860369563103
Epoch Time (s)               167.76505618123338
Total Train Time (s)         10923.619017035235
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:55:42.162398 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #64 | Epoch Duration: 167.84338545799255
2020-01-12 10:55:42.162525 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8933146
Z variance train             0.03284865
KL Divergence                32.189735
KL Loss                      3.2189736
QF Loss                      363.97015
VF Loss                      155.22108
Policy Loss                  -696.5318
Q Predictions Mean           687.1306
Q Predictions Std            756.49896
Q Predictions Max            2562.2593
Q Predictions Min            -81.04364
V Predictions Mean           690.20874
V Predictions Std            759.4493
V Predictions Max            2555.3967
V Predictions Min            -85.60551
Log Pis Mean                 -1.6933634
Log Pis Std                  3.1749356
Log Pis Max                  12.735222
Log Pis Min                  -7.0048766
Policy mu Mean               -0.0028704193
Policy mu Std                0.7041377
Policy mu Max                3.1718159
Policy mu Min                -2.75017
Policy log std Mean          -0.4356241
Policy log std Std           0.21560813
Policy log std Max           -0.12779066
Policy log std Min           -1.9995737
Z mean eval                  1.9643263
Z variance eval              0.022422707
total_rewards                [5977.75288021 5776.0160587  6091.82940861 6288.05318071 5442.73526187
 6015.5980252  5741.71791203 6371.27116296 6278.92847887 6200.92333972]
total_rewards_mean           6018.482570889642
total_rewards_std            277.87865088368335
total_rewards_max            6371.271162955752
total_rewards_min            5442.735261869922
Number of train steps total  264000
Number of env steps total    794000
Number of rollouts total     0
Train Time (s)               141.49094415688887
(Previous) Eval Time (s)     17.660015925299376
Sample Time (s)              5.789603969082236
Epoch Time (s)               164.94056405127048
Total Train Time (s)         11088.639404475689
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:58:27.184284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #65 | Epoch Duration: 165.02164816856384
2020-01-12 10:58:27.184468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9642954
Z variance train             0.022471158
KL Divergence                34.296085
KL Loss                      3.4296086
QF Loss                      291.7028
VF Loss                      103.977196
Policy Loss                  -949.0619
Q Predictions Mean           940.9956
Q Predictions Std            887.71405
Q Predictions Max            2549.328
Q Predictions Min            -162.05264
V Predictions Mean           947.9253
V Predictions Std            887.99915
V Predictions Max            2527.7844
V Predictions Min            -93.95788
Log Pis Mean                 -0.87396747
Log Pis Std                  3.7186964
Log Pis Max                  16.326746
Log Pis Min                  -6.937147
Policy mu Mean               -0.0649516
Policy mu Std                0.822369
Policy mu Max                2.8577566
Policy mu Min                -3.2507486
Policy log std Mean          -0.46331108
Policy log std Std           0.25006807
Policy log std Max           -0.10547432
Policy log std Min           -2.1765544
Z mean eval                  1.9880623
Z variance eval              0.03057602
total_rewards                [6345.18806998 6759.26481283 6485.74336491 6195.50284021 6494.32211165
 6308.88445132 6364.44003704 6525.45511405 5964.05923242 6543.01058363]
total_rewards_mean           6398.587061803629
total_rewards_std            206.37954910614604
total_rewards_max            6759.2648128317505
total_rewards_min            5964.059232415425
Number of train steps total  268000
Number of env steps total    806000
Number of rollouts total     0
Train Time (s)               146.52034418284893
(Previous) Eval Time (s)     21.061013142578304
Sample Time (s)              6.558749390300363
Epoch Time (s)               174.1401067157276
Total Train Time (s)         11262.86058436893
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:01:21.408485 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #66 | Epoch Duration: 174.22382760047913
2020-01-12 11:01:21.408766 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9883578
Z variance train             0.03069983
KL Divergence                33.835472
KL Loss                      3.3835473
QF Loss                      196.62027
VF Loss                      93.62791
Policy Loss                  -756.3074
Q Predictions Mean           747.1897
Q Predictions Std            816.43384
Q Predictions Max            2587.6973
Q Predictions Min            -98.25599
V Predictions Mean           755.411
V Predictions Std            815.61005
V Predictions Max            2590.9146
V Predictions Min            -88.82018
Log Pis Mean                 -1.4048967
Log Pis Std                  3.482192
Log Pis Max                  14.167569
Log Pis Min                  -7.397729
Policy mu Mean               -0.068553604
Policy mu Std                0.76549387
Policy mu Max                2.773866
Policy mu Min                -2.9150543
Policy log std Mean          -0.45389572
Policy log std Std           0.20155948
Policy log std Max           -0.13707104
Policy log std Min           -1.894566
Z mean eval                  1.9476534
Z variance eval              0.014498072
total_rewards                [6386.06218552 6610.66714922 6554.25947498 6635.7848597  6277.62167439
 6534.4071712  6745.62575103 6625.77416542 6389.38013214 6480.643831  ]
total_rewards_mean           6524.022639459499
total_rewards_std            134.25286961555585
total_rewards_max            6745.625751030121
total_rewards_min            6277.621674385322
Number of train steps total  272000
Number of env steps total    818000
Number of rollouts total     0
Train Time (s)               141.35383306629956
(Previous) Eval Time (s)     17.545340763404965
Sample Time (s)              6.4322752663865685
Epoch Time (s)               165.3314490960911
Total Train Time (s)         11428.276671955828
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:04:06.825150 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #67 | Epoch Duration: 165.4162266254425
2020-01-12 11:04:06.825327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9495026
Z variance train             0.014513129
KL Divergence                33.638863
KL Loss                      3.3638864
QF Loss                      915.3757
VF Loss                      351.93448
Policy Loss                  -750.275
Q Predictions Mean           737.7329
Q Predictions Std            795.73987
Q Predictions Max            2546.1663
Q Predictions Min            -100.23332
V Predictions Mean           738.83435
V Predictions Std            796.2956
V Predictions Max            2540.413
V Predictions Min            -102.630936
Log Pis Mean                 -1.3221571
Log Pis Std                  3.4468234
Log Pis Max                  11.411898
Log Pis Min                  -6.660722
Policy mu Mean               0.0040029823
Policy mu Std                0.7463625
Policy mu Max                3.341102
Policy mu Min                -2.817051
Policy log std Mean          -0.46910104
Policy log std Std           0.22893475
Policy log std Max           -0.1513705
Policy log std Min           -2.0974493
Z mean eval                  1.9117606
Z variance eval              0.012644713
total_rewards                [6577.4481622  6872.44356186 6715.38265195 6774.1481082  6799.72618195
 6848.07878567 6576.24289906 6665.28158713 6660.97311759 6582.46248213]
total_rewards_mean           6707.218753773841
total_rewards_std            106.6307605052656
total_rewards_max            6872.443561857926
total_rewards_min            6576.242899055701
Number of train steps total  276000
Number of env steps total    830000
Number of rollouts total     0
Train Time (s)               141.31493050884455
(Previous) Eval Time (s)     20.594629519153386
Sample Time (s)              6.557933504227549
Epoch Time (s)               168.4674935322255
Total Train Time (s)         11596.825481682085
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:06:55.375746 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #68 | Epoch Duration: 168.5502486228943
2020-01-12 11:06:55.375969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9090292
Z variance train             0.01264553
KL Divergence                35.250046
KL Loss                      3.5250046
QF Loss                      323.01556
VF Loss                      178.41084
Policy Loss                  -806.95886
Q Predictions Mean           796.4945
Q Predictions Std            864.6997
Q Predictions Max            2598.8525
Q Predictions Min            -95.19227
V Predictions Mean           804.0812
V Predictions Std            868.6486
V Predictions Max            2600.4648
V Predictions Min            -92.77417
Log Pis Mean                 -1.2888842
Log Pis Std                  3.4355826
Log Pis Max                  9.4405
Log Pis Min                  -6.152956
Policy mu Mean               -0.041863292
Policy mu Std                0.75384337
Policy mu Max                2.6645062
Policy mu Min                -2.2961516
Policy log std Mean          -0.46271133
Policy log std Std           0.24614014
Policy log std Max           -0.15886796
Policy log std Min           -2.4293547
Z mean eval                  1.9282405
Z variance eval              0.016464395
total_rewards                [6637.55033879 6557.91798604 6797.8512828  6759.63766126 6682.06115259
 6810.53797496 6825.22869639 6733.06789363 6855.21062553 6619.97016631]
total_rewards_mean           6727.903377831164
total_rewards_std            94.46907897236079
total_rewards_max            6855.210625531985
total_rewards_min            6557.917986040426
Number of train steps total  280000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               142.8911835681647
(Previous) Eval Time (s)     21.060634987894446
Sample Time (s)              6.363416476175189
Epoch Time (s)               170.31523503223434
Total Train Time (s)         11767.224443089683
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:09:45.779470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #69 | Epoch Duration: 170.40337681770325
2020-01-12 11:09:45.779657 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9284779
Z variance train             0.016544286
KL Divergence                34.971523
KL Loss                      3.4971523
QF Loss                      218.70663
VF Loss                      90.274635
Policy Loss                  -730.20276
Q Predictions Mean           726.4252
Q Predictions Std            806.6503
Q Predictions Max            2633.4746
Q Predictions Min            -83.993904
V Predictions Mean           730.13525
V Predictions Std            810.7442
V Predictions Max            2631.3086
V Predictions Min            -90.43525
Log Pis Mean                 -1.1041367
Log Pis Std                  3.530715
Log Pis Max                  14.623306
Log Pis Min                  -5.6242113
Policy mu Mean               -0.027423477
Policy mu Std                0.77139163
Policy mu Max                3.3018475
Policy mu Min                -2.967915
Policy log std Mean          -0.44741473
Policy log std Std           0.22381204
Policy log std Max           -0.13951744
Policy log std Min           -1.9407089
Z mean eval                  1.9045881
Z variance eval              0.019563163
total_rewards                [6397.73721039 6334.65972206 6134.12455137 6244.53219982 6278.45179098
 6199.39234122 6240.07816942 6302.73183282 6057.80944138 5896.92813372]
total_rewards_mean           6208.64453931663
total_rewards_std            138.99442760472132
total_rewards_max            6397.737210388255
total_rewards_min            5896.928133724845
Number of train steps total  284000
Number of env steps total    854000
Number of rollouts total     0
Train Time (s)               145.16799584403634
(Previous) Eval Time (s)     17.54698609886691
Sample Time (s)              6.362792334519327
Epoch Time (s)               169.07777427742258
Total Train Time (s)         11936.384378995746
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:12:34.939036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #70 | Epoch Duration: 169.15923142433167
2020-01-12 11:12:34.939217 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #70 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9064925
Z variance train             0.019710252
KL Divergence                36.088448
KL Loss                      3.6088448
QF Loss                      657.52423
VF Loss                      247.75795
Policy Loss                  -954.9075
Q Predictions Mean           955.50476
Q Predictions Std            908.3305
Q Predictions Max            2633.0076
Q Predictions Min            -66.7108
V Predictions Mean           957.13446
V Predictions Std            911.1033
V Predictions Max            2625.5413
V Predictions Min            -92.77434
Log Pis Mean                 -0.80169666
Log Pis Std                  3.5094044
Log Pis Max                  9.956644
Log Pis Min                  -7.1128864
Policy mu Mean               -0.014122388
Policy mu Std                0.8351764
Policy mu Max                3.4713573
Policy mu Min                -2.980465
Policy log std Mean          -0.4906595
Policy log std Std           0.25094312
Policy log std Max           -0.10289964
Policy log std Min           -2.2119858
Z mean eval                  1.9259548
Z variance eval              0.023544218
total_rewards                [6207.18402351 6046.19454926 2299.39055116 6406.15013856 6298.8571819
 6767.19379656 6414.78696016 6645.77171238 6619.99180679 6463.21173607]
total_rewards_mean           6016.873245635494
total_rewards_std            1255.6913050618623
total_rewards_max            6767.193796562019
total_rewards_min            2299.3905511628113
Number of train steps total  288000
Number of env steps total    866000
Number of rollouts total     0
Train Time (s)               143.9915888281539
(Previous) Eval Time (s)     17.24979145405814
Sample Time (s)              6.408704467117786
Epoch Time (s)               167.65008474932984
Total Train Time (s)         12104.1184686739
Epoch                        71
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:15:22.674985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #71 | Epoch Duration: 167.73561334609985
2020-01-12 11:15:22.675226 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9274876
Z variance train             0.023443783
KL Divergence                35.6243
KL Loss                      3.56243
QF Loss                      603.8964
VF Loss                      110.7771
Policy Loss                  -898.12805
Q Predictions Mean           892.98694
Q Predictions Std            919.8184
Q Predictions Max            2740.545
Q Predictions Min            -112.776886
V Predictions Mean           903.4154
V Predictions Std            921.7069
V Predictions Max            2760.115
V Predictions Min            -94.450615
Log Pis Mean                 -0.5956864
Log Pis Std                  4.1839256
Log Pis Max                  15.474714
Log Pis Min                  -7.5330453
Policy mu Mean               -0.03236183
Policy mu Std                0.8391715
Policy mu Max                2.7498064
Policy mu Min                -3.6301155
Policy log std Mean          -0.4763801
Policy log std Std           0.24895069
Policy log std Max           0.17862576
Policy log std Min           -2.1130807
Z mean eval                  1.9065393
Z variance eval              0.020648029
total_rewards                [6800.66967287 6848.85127319 6688.03357635 6573.05473772 6421.46356637
 6926.23334063 6416.06024829 6636.83877914 6641.98357476 4944.70215119]
total_rewards_mean           6489.7890920508
total_rewards_std            538.9317912869752
total_rewards_max            6926.233340626881
total_rewards_min            4944.7021511893945
Number of train steps total  292000
Number of env steps total    878000
Number of rollouts total     0
Train Time (s)               142.37295288126916
(Previous) Eval Time (s)     20.63531113183126
Sample Time (s)              6.558693532366306
Epoch Time (s)               169.56695754546672
Total Train Time (s)         12273.768998747226
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:18:12.325227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #72 | Epoch Duration: 169.64983892440796
2020-01-12 11:18:12.325360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9069259
Z variance train             0.020696966
KL Divergence                35.30067
KL Loss                      3.5300672
QF Loss                      423.5443
VF Loss                      120.397644
Policy Loss                  -841.9248
Q Predictions Mean           837.20935
Q Predictions Std            875.8545
Q Predictions Max            2695.063
Q Predictions Min            -105.14013
V Predictions Mean           844.2478
V Predictions Std            881.29944
V Predictions Max            2689.672
V Predictions Min            -96.09946
Log Pis Mean                 -0.8446692
Log Pis Std                  3.6057746
Log Pis Max                  19.177437
Log Pis Min                  -6.6063986
Policy mu Mean               -0.08572644
Policy mu Std                0.79924846
Policy mu Max                3.4459207
Policy mu Min                -3.275269
Policy log std Mean          -0.48352802
Policy log std Std           0.24562743
Policy log std Max           -0.039794087
Policy log std Min           -2.0993092
Z mean eval                  1.9232066
Z variance eval              0.012680945
total_rewards                [6334.56660625 3353.65876259 6607.6835525  6594.60376544 6432.99780352
 6519.50576337 6524.39270468 6190.33679291 6663.14673595 6617.26892699]
total_rewards_mean           6183.816141421094
total_rewards_std            953.38237970731
total_rewards_max            6663.146735953936
total_rewards_min            3353.6587625865504
Number of train steps total  296000
Number of env steps total    890000
Number of rollouts total     0
Train Time (s)               142.93206780217588
(Previous) Eval Time (s)     20.723051264882088
Sample Time (s)              6.42490890994668
Epoch Time (s)               170.08002797700465
Total Train Time (s)         12443.935315628536
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:21:02.493345 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #73 | Epoch Duration: 170.16788530349731
2020-01-12 11:21:02.493482 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9219732
Z variance train             0.012649233
KL Divergence                36.754177
KL Loss                      3.6754177
QF Loss                      708.5473
VF Loss                      63.8428
Policy Loss                  -723.7065
Q Predictions Mean           716.6256
Q Predictions Std            813.18713
Q Predictions Max            2688.1958
Q Predictions Min            -118.86739
V Predictions Mean           718.99316
V Predictions Std            814.5323
V Predictions Max            2677.8003
V Predictions Min            -101.12744
Log Pis Mean                 -1.5221188
Log Pis Std                  3.2166948
Log Pis Max                  12.404056
Log Pis Min                  -6.1852627
Policy mu Mean               -0.0399356
Policy mu Std                0.7341676
Policy mu Max                3.1507752
Policy mu Min                -2.9435282
Policy log std Mean          -0.4478356
Policy log std Std           0.22285402
Policy log std Max           -0.15916756
Policy log std Min           -1.9836318
Z mean eval                  1.9176843
Z variance eval              0.039364442
total_rewards                [6365.15914054 6283.68921146 6131.74834958 6167.57811909 6552.78626449
 4372.49032422 6179.08144071 6602.51370961 6229.73777935 6191.17612243]
total_rewards_mean           6107.596046147545
total_rewards_std            598.5209117033972
total_rewards_max            6602.5137096075205
total_rewards_min            4372.490324218205
Number of train steps total  300000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               142.32089658873156
(Previous) Eval Time (s)     20.750394348055124
Sample Time (s)              6.607983416412026
Epoch Time (s)               169.6792743531987
Total Train Time (s)         12613.69556729123
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:23:52.254492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #74 | Epoch Duration: 169.7609167098999
2020-01-12 11:23:52.254641 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9142888
Z variance train             0.03954923
KL Divergence                33.758095
KL Loss                      3.3758094
QF Loss                      525.3814
VF Loss                      124.22824
Policy Loss                  -846.33026
Q Predictions Mean           831.631
Q Predictions Std            890.5416
Q Predictions Max            2727.1296
Q Predictions Min            -110.2047
V Predictions Mean           844.54724
V Predictions Std            889.8078
V Predictions Max            2704.8042
V Predictions Min            -97.693756
Log Pis Mean                 -0.8895787
Log Pis Std                  3.9307344
Log Pis Max                  17.172672
Log Pis Min                  -7.6534495
Policy mu Mean               -0.07315045
Policy mu Std                0.81108475
Policy mu Max                3.0775783
Policy mu Min                -3.1038806
Policy log std Mean          -0.4524858
Policy log std Std           0.2220385
Policy log std Max           -0.1042586
Policy log std Min           -2.0909927
Z mean eval                  1.9221071
Z variance eval              0.038345017
total_rewards                [6718.76190197 6772.4146805  6595.03178839 6515.63545106 6433.09545615
 6908.65216277 6557.4211703  1482.94969339 6317.05774773 6836.73879364]
total_rewards_mean           6113.775884589608
total_rewards_std            1553.4502252585623
total_rewards_max            6908.652162770284
total_rewards_min            1482.949693392347
Number of train steps total  304000
Number of env steps total    914000
Number of rollouts total     0
Train Time (s)               144.6765623362735
(Previous) Eval Time (s)     17.308902602177113
Sample Time (s)              6.515462671872228
Epoch Time (s)               168.50092761032283
Total Train Time (s)         12782.307247437537
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:26:40.868918 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #75 | Epoch Duration: 168.61415767669678
2020-01-12 11:26:40.869126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9220686
Z variance train             0.038225066
KL Divergence                33.276627
KL Loss                      3.3276627
QF Loss                      272.47702
VF Loss                      60.09032
Policy Loss                  -827.81665
Q Predictions Mean           821.15845
Q Predictions Std            844.0492
Q Predictions Max            2713.37
Q Predictions Min            -108.16551
V Predictions Mean           824.96594
V Predictions Std            845.4125
V Predictions Max            2690.336
V Predictions Min            -105.538506
Log Pis Mean                 -1.0661168
Log Pis Std                  3.3346736
Log Pis Max                  14.596866
Log Pis Min                  -6.564146
Policy mu Mean               0.010263724
Policy mu Std                0.7738751
Policy mu Max                2.7074406
Policy mu Min                -2.713632
Policy log std Mean          -0.4687407
Policy log std Std           0.23245813
Policy log std Max           -0.11971766
Policy log std Min           -2.0444312
Z mean eval                  1.935648
Z variance eval              0.021667432
total_rewards                [6476.14719352 6040.96465959 6385.53459449 6364.48569017 6451.07591961
 6335.63707979 6426.42537088 6426.62607753 6648.87476771 6605.10635166]
total_rewards_mean           6416.087770494148
total_rewards_std            156.76510137647313
total_rewards_max            6648.874767705496
total_rewards_min            6040.964659586793
Number of train steps total  308000
Number of env steps total    926000
Number of rollouts total     0
Train Time (s)               144.72288407105953
(Previous) Eval Time (s)     17.92733120592311
Sample Time (s)              6.342245437204838
Epoch Time (s)               168.99246071418747
Total Train Time (s)         12951.37879549805
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:29:29.941449 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #76 | Epoch Duration: 169.07216572761536
2020-01-12 11:29:29.941629 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9358187
Z variance train             0.021697322
KL Divergence                34.20354
KL Loss                      3.4203541
QF Loss                      385.87555
VF Loss                      93.6093
Policy Loss                  -879.66986
Q Predictions Mean           875.2638
Q Predictions Std            876.7594
Q Predictions Max            2710.769
Q Predictions Min            -93.82006
V Predictions Mean           882.414
V Predictions Std            878.2482
V Predictions Max            2700.2827
V Predictions Min            -105.51337
Log Pis Mean                 -1.0181878
Log Pis Std                  3.146918
Log Pis Max                  11.357937
Log Pis Min                  -6.000614
Policy mu Mean               0.034117606
Policy mu Std                0.77924865
Policy mu Max                2.657605
Policy mu Min                -2.4177413
Policy log std Mean          -0.48062968
Policy log std Std           0.2408191
Policy log std Max           -0.14605194
Policy log std Min           -2.060026
Z mean eval                  1.9189469
Z variance eval              0.013638318
total_rewards                [6163.72877212 6748.94202955 6535.39745781 6674.36148954 7025.42414481
 6494.51315068 6686.33099415 6709.07501976 6573.75666319 6665.36881776]
total_rewards_mean           6627.689853937109
total_rewards_std            207.5999821366779
total_rewards_max            7025.424144813877
total_rewards_min            6163.728772123472
Number of train steps total  312000
Number of env steps total    938000
Number of rollouts total     0
Train Time (s)               145.14685849659145
(Previous) Eval Time (s)     20.982759467791766
Sample Time (s)              6.589742365758866
Epoch Time (s)               172.71936033014208
Total Train Time (s)         13124.18441857677
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:32:22.747561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #77 | Epoch Duration: 172.805805683136
2020-01-12 11:32:22.747704 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9182926
Z variance train             0.013601027
KL Divergence                35.48971
KL Loss                      3.5489712
QF Loss                      309.7739
VF Loss                      103.51799
Policy Loss                  -761.9066
Q Predictions Mean           756.9069
Q Predictions Std            833.9687
Q Predictions Max            2720.9792
Q Predictions Min            -133.029
V Predictions Mean           758.75793
V Predictions Std            836.022
V Predictions Max            2699.8457
V Predictions Min            -128.14035
Log Pis Mean                 -1.2505851
Log Pis Std                  3.5732014
Log Pis Max                  18.01568
Log Pis Min                  -7.3036304
Policy mu Mean               -0.1042085
Policy mu Std                0.7657626
Policy mu Max                3.0361211
Policy mu Min                -2.945022
Policy log std Mean          -0.469956
Policy log std Std           0.22982384
Policy log std Max           -0.12308204
Policy log std Min           -2.2557588
Z mean eval                  1.94399
Z variance eval              0.02191857
total_rewards                [6784.77869933 2169.16833214 6730.45021197 7087.71559962 6775.75489183
 7106.07600229 6830.26298104 7039.087185   6825.09404071 6844.08188807]
total_rewards_mean           6419.246983199837
total_rewards_std            1422.5907445071173
total_rewards_max            7106.0760022853065
total_rewards_min            2169.168332136087
Number of train steps total  316000
Number of env steps total    950000
Number of rollouts total     0
Train Time (s)               144.8410155349411
(Previous) Eval Time (s)     18.20105986483395
Sample Time (s)              6.321663931012154
Epoch Time (s)               169.3637393307872
Total Train Time (s)         13293.63054038398
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:35:12.194590 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #78 | Epoch Duration: 169.44678473472595
2020-01-12 11:35:12.194738 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9430186
Z variance train             0.02191483
KL Divergence                33.534515
KL Loss                      3.3534515
QF Loss                      461.33008
VF Loss                      208.18115
Policy Loss                  -856.7875
Q Predictions Mean           848.7438
Q Predictions Std            890.2291
Q Predictions Max            2740.0264
Q Predictions Min            -132.73595
V Predictions Mean           868.24896
V Predictions Std            895.4994
V Predictions Max            2756.0156
V Predictions Min            -114.27151
Log Pis Mean                 -0.70113325
Log Pis Std                  3.6826344
Log Pis Max                  17.538399
Log Pis Min                  -7.46621
Policy mu Mean               -0.06077373
Policy mu Std                0.8319159
Policy mu Max                2.7827902
Policy mu Min                -3.3544865
Policy log std Mean          -0.47775874
Policy log std Std           0.2331503
Policy log std Max           -0.115655124
Policy log std Min           -2.1333344
Z mean eval                  1.9231899
Z variance eval              0.010022086
total_rewards                [6791.39886586 6895.59442615 6992.33227579 6781.41576121 6865.21895202
 6736.86717029 6945.50249449 6948.14761575 6630.03037554 6677.94892249]
total_rewards_mean           6826.44568595781
total_rewards_std            116.06020231325866
total_rewards_max            6992.332275786583
total_rewards_min            6630.030375537773
Number of train steps total  320000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               144.18312916485593
(Previous) Eval Time (s)     17.798429735004902
Sample Time (s)              5.395140776410699
Epoch Time (s)               167.37669967627153
Total Train Time (s)         13461.093271906022
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:37:59.662262 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #79 | Epoch Duration: 167.46737694740295
2020-01-12 11:37:59.662589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9211237
Z variance train             0.010034809
KL Divergence                35.451515
KL Loss                      3.5451515
QF Loss                      355.06934
VF Loss                      103.580345
Policy Loss                  -823.3496
Q Predictions Mean           811.9689
Q Predictions Std            843.40314
Q Predictions Max            2738.7295
Q Predictions Min            -121.927315
V Predictions Mean           822.4929
V Predictions Std            846.4049
V Predictions Max            2719.4226
V Predictions Min            -115.60786
Log Pis Mean                 -0.72505337
Log Pis Std                  3.8031275
Log Pis Max                  15.693098
Log Pis Min                  -5.7879877
Policy mu Mean               -0.0045198104
Policy mu Std                0.81326646
Policy mu Max                3.3265326
Policy mu Min                -3.3173363
Policy log std Mean          -0.46581006
Policy log std Std           0.2464985
Policy log std Max           -0.12999254
Policy log std Min           -2.1364317
Z mean eval                  1.9455141
Z variance eval              0.016692108
total_rewards                [6307.72662146 6177.27861646 6249.6712644  6195.71536975 6281.32905756
 6364.4853967  6228.47253397 6278.24448742 6040.67724012 6287.80328186]
total_rewards_mean           6241.140386969256
total_rewards_std            84.48518737274325
total_rewards_max            6364.485396696794
total_rewards_min            6040.677240124791
Number of train steps total  324000
Number of env steps total    974000
Number of rollouts total     0
Train Time (s)               143.84884004993364
(Previous) Eval Time (s)     20.464759598951787
Sample Time (s)              5.559265097603202
Epoch Time (s)               169.87286474648863
Total Train Time (s)         13631.051168244332
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:40:49.620492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #80 | Epoch Duration: 169.95763111114502
2020-01-12 11:40:49.620641 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9486698
Z variance train             0.016701987
KL Divergence                35.14409
KL Loss                      3.5144088
QF Loss                      253.83353
VF Loss                      190.0325
Policy Loss                  -826.6418
Q Predictions Mean           821.1393
Q Predictions Std            881.15356
Q Predictions Max            2721.5286
Q Predictions Min            -112.53979
V Predictions Mean           835.4753
V Predictions Std            882.69037
V Predictions Max            2732.1707
V Predictions Min            -123.31951
Log Pis Mean                 -1.0902462
Log Pis Std                  3.1302495
Log Pis Max                  10.575375
Log Pis Min                  -6.5758414
Policy mu Mean               0.02634734
Policy mu Std                0.7751295
Policy mu Max                3.1538591
Policy mu Min                -2.6675916
Policy log std Mean          -0.4725118
Policy log std Std           0.25235796
Policy log std Max           -0.12728155
Policy log std Min           -2.5123024
Z mean eval                  1.9192121
Z variance eval              0.017951565
total_rewards                [5807.87975832 6005.52447291 6360.43147995 6058.8051195  5955.13712917
 6075.44937861 6227.58640689 5981.45796038 6030.04323035 5920.05495236]
total_rewards_mean           6042.236988844628
total_rewards_std            148.19191634261696
total_rewards_max            6360.431479951385
total_rewards_min            5807.879758324435
Number of train steps total  328000
Number of env steps total    986000
Number of rollouts total     0
Train Time (s)               143.20830960012972
(Previous) Eval Time (s)     17.657349943183362
Sample Time (s)              6.617194666527212
Epoch Time (s)               167.4828542098403
Total Train Time (s)         13798.617211640812
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:43:37.190442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #81 | Epoch Duration: 167.56968069076538
2020-01-12 11:43:37.190646 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #81 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9189593
Z variance train             0.017912786
KL Divergence                34.725815
KL Loss                      3.4725816
QF Loss                      789.1039
VF Loss                      154.60805
Policy Loss                  -859.4405
Q Predictions Mean           851.6629
Q Predictions Std            890.95404
Q Predictions Max            2760.5967
Q Predictions Min            -115.70336
V Predictions Mean           865.77814
V Predictions Std            894.70355
V Predictions Max            2759.3745
V Predictions Min            -122.12347
Log Pis Mean                 -1.0074866
Log Pis Std                  3.3948438
Log Pis Max                  15.157591
Log Pis Min                  -7.0500264
Policy mu Mean               -0.054775495
Policy mu Std                0.7789646
Policy mu Max                2.6785607
Policy mu Min                -2.8804224
Policy log std Mean          -0.47855428
Policy log std Std           0.24742727
Policy log std Max           -0.1196104
Policy log std Min           -2.212659
Z mean eval                  1.9384058
Z variance eval              0.038305134
total_rewards                [6369.5886239  6051.82400702 6442.45906118 6010.99870121 6552.7907918
 6452.68356824 6190.55762437 6080.75837601 6028.01449084 6314.57071236]
total_rewards_mean           6249.424595692212
total_rewards_std            191.34260430743757
total_rewards_max            6552.790791803798
total_rewards_min            6010.998701206025
Number of train steps total  332000
Number of env steps total    998000
Number of rollouts total     0
Train Time (s)               142.6130550452508
(Previous) Eval Time (s)     17.538343803025782
Sample Time (s)              6.538192308973521
Epoch Time (s)               166.6895911572501
Total Train Time (s)         13965.399914619513
Epoch                        82
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:46:23.974486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #82 | Epoch Duration: 166.78368401527405
2020-01-12 11:46:23.974732 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.94098
Z variance train             0.03820688
KL Divergence                34.407875
KL Loss                      3.4407876
QF Loss                      254.24976
VF Loss                      48.29139
Policy Loss                  -851.0413
Q Predictions Mean           849.07874
Q Predictions Std            883.9519
Q Predictions Max            2773.583
Q Predictions Min            -106.49184
V Predictions Mean           849.94507
V Predictions Std            885.76495
V Predictions Max            2741.6157
V Predictions Min            -113.35897
Log Pis Mean                 -1.1637769
Log Pis Std                  3.4167147
Log Pis Max                  11.815897
Log Pis Min                  -7.1372414
Policy mu Mean               -0.028736515
Policy mu Std                0.8023472
Policy mu Max                2.5835238
Policy mu Min                -2.9365392
Policy log std Mean          -0.46769217
Policy log std Std           0.22383521
Policy log std Max           -0.11682156
Policy log std Min           -1.9243231
Z mean eval                  1.9712365
Z variance eval              0.026418012
total_rewards                [6690.53044493 6924.87712443 7148.06967873 6990.60276218 6894.89039207
 6816.19710798 6909.37127389 6960.7285762  6930.30762169 7296.81095698]
total_rewards_mean           6956.238593906298
total_rewards_std            158.6878377362714
total_rewards_max            7296.810956981488
total_rewards_min            6690.530444929169
Number of train steps total  336000
Number of env steps total    1010000
Number of rollouts total     0
Train Time (s)               143.27031986089423
(Previous) Eval Time (s)     17.746682967990637
Sample Time (s)              5.50136765325442
Epoch Time (s)               166.5183704821393
Total Train Time (s)         14132.090683217626
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:49:10.668094 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #83 | Epoch Duration: 166.69321298599243
2020-01-12 11:49:10.668265 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9672527
Z variance train             0.026458368
KL Divergence                34.10302
KL Loss                      3.410302
QF Loss                      231.01874
VF Loss                      54.513023
Policy Loss                  -812.5151
Q Predictions Mean           804.1588
Q Predictions Std            878.4718
Q Predictions Max            2738.9827
Q Predictions Min            -183.26633
V Predictions Mean           810.53455
V Predictions Std            878.19604
V Predictions Max            2723.628
V Predictions Min            -121.54699
Log Pis Mean                 -1.0447309
Log Pis Std                  3.418666
Log Pis Max                  12.548586
Log Pis Min                  -9.778387
Policy mu Mean               -0.07589989
Policy mu Std                0.7788128
Policy mu Max                3.7346258
Policy mu Min                -2.508574
Policy log std Mean          -0.4776822
Policy log std Std           0.23499379
Policy log std Max           -0.167907
Policy log std Min           -2.0649142
Z mean eval                  1.9605248
Z variance eval              0.04453638
total_rewards                [6904.48494448 7012.20663993 6921.92710338 6723.58486119 7097.62169707
 7184.79453668 7165.20523819 6827.01456413 6954.03183593 6816.4833586 ]
total_rewards_mean           6960.735477959572
total_rewards_std            145.95992093093705
total_rewards_max            7184.794536681355
total_rewards_min            6723.584861194478
Number of train steps total  340000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               145.0343587147072
(Previous) Eval Time (s)     21.011270728893578
Sample Time (s)              6.505604314152151
Epoch Time (s)               172.55123375775293
Total Train Time (s)         14304.726594283711
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:52:03.307271 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #84 | Epoch Duration: 172.63885116577148
2020-01-12 11:52:03.307532 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9616792
Z variance train             0.044243637
KL Divergence                33.639698
KL Loss                      3.3639698
QF Loss                      191.5141
VF Loss                      60.443348
Policy Loss                  -757.8577
Q Predictions Mean           750.0014
Q Predictions Std            819.1134
Q Predictions Max            2790.1428
Q Predictions Min            -156.7662
V Predictions Mean           756.552
V Predictions Std            821.15576
V Predictions Max            2795.5232
V Predictions Min            -127.847786
Log Pis Mean                 -1.1185857
Log Pis Std                  3.2382383
Log Pis Max                  9.454233
Log Pis Min                  -6.640612
Policy mu Mean               0.025142223
Policy mu Std                0.7646546
Policy mu Max                2.7468917
Policy mu Min                -2.8183126
Policy log std Mean          -0.4714192
Policy log std Std           0.23887856
Policy log std Max           -0.15221184
Policy log std Min           -2.2144492
Z mean eval                  1.9564724
Z variance eval              0.018473458
total_rewards                [6942.30077971 7047.7705823  6968.82483952 7071.70882836 6845.41130807
 7207.30030764 6856.18192482 6874.28339265 6773.45083073 7097.83206911]
total_rewards_mean           6968.506486291745
total_rewards_std            128.86500159864124
total_rewards_max            7207.3003076391715
total_rewards_min            6773.450830725401
Number of train steps total  344000
Number of env steps total    1034000
Number of rollouts total     0
Train Time (s)               145.20383495790884
(Previous) Eval Time (s)     17.260036647319794
Sample Time (s)              6.524156869854778
Epoch Time (s)               168.9880284750834
Total Train Time (s)         14473.80162749486
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:54:52.382773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #85 | Epoch Duration: 169.07504963874817
2020-01-12 11:54:52.382953 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9584984
Z variance train             0.018495385
KL Divergence                36.376415
KL Loss                      3.6376417
QF Loss                      771.8637
VF Loss                      121.42945
Policy Loss                  -758.9428
Q Predictions Mean           756.10095
Q Predictions Std            858.3358
Q Predictions Max            2790.0806
Q Predictions Min            -144.69232
V Predictions Mean           762.6328
V Predictions Std            859.2581
V Predictions Max            2779.6323
V Predictions Min            -132.52592
Log Pis Mean                 -0.89952475
Log Pis Std                  3.7501333
Log Pis Max                  16.842625
Log Pis Min                  -6.514022
Policy mu Mean               -0.060050827
Policy mu Std                0.779075
Policy mu Max                2.9006786
Policy mu Min                -3.7528172
Policy log std Mean          -0.47166553
Policy log std Std           0.23840795
Policy log std Max           -0.097542375
Policy log std Min           -2.3785365
Z mean eval                  1.917833
Z variance eval              0.011947613
total_rewards                [6723.38336053 6586.81425605 6683.31349468 6531.07100242 6748.38183354
 6824.20884668 6602.60554472 6762.81375439 6715.88557645 6685.54484295]
total_rewards_mean           6686.40225124014
total_rewards_std            84.8442351185703
total_rewards_max            6824.208846676684
total_rewards_min            6531.071002418416
Number of train steps total  348000
Number of env steps total    1046000
Number of rollouts total     0
Train Time (s)               144.9392209239304
(Previous) Eval Time (s)     20.80948308389634
Sample Time (s)              6.651611663401127
Epoch Time (s)               172.40031567122787
Total Train Time (s)         14646.309030967299
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:57:44.891635 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #86 | Epoch Duration: 172.50854420661926
2020-01-12 11:57:44.891813 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9193504
Z variance train             0.011947852
KL Divergence                37.54443
KL Loss                      3.754443
QF Loss                      302.48422
VF Loss                      124.549034
Policy Loss                  -758.5971
Q Predictions Mean           749.7369
Q Predictions Std            825.39325
Q Predictions Max            2844.6516
Q Predictions Min            -124.3326
V Predictions Mean           750.0429
V Predictions Std            822.6549
V Predictions Max            2825.7947
V Predictions Min            -135.47217
Log Pis Mean                 -1.2843583
Log Pis Std                  3.178608
Log Pis Max                  17.216084
Log Pis Min                  -9.446639
Policy mu Mean               0.036529597
Policy mu Std                0.75122565
Policy mu Max                3.1452076
Policy mu Min                -3.5980954
Policy log std Mean          -0.4869102
Policy log std Std           0.23340489
Policy log std Max           -0.14696631
Policy log std Min           -2.2146678
Z mean eval                  2.0778606
Z variance eval              0.023066204
total_rewards                [6294.18432362 6613.15722032 6650.41019992 6802.23951372 6505.46209215
 6570.41652318 6727.76468885 6616.44631544 6495.52210843 6415.72260294]
total_rewards_mean           6569.132558857034
total_rewards_std            141.02873619608417
total_rewards_max            6802.239513723461
total_rewards_min            6294.184323624649
Number of train steps total  352000
Number of env steps total    1058000
Number of rollouts total     0
Train Time (s)               144.1187355183065
(Previous) Eval Time (s)     20.705354772042483
Sample Time (s)              6.510303697548807
Epoch Time (s)               171.33439398789778
Total Train Time (s)         14817.737419188954
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:00:36.321513 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #87 | Epoch Duration: 171.4295744895935
2020-01-12 12:00:36.321651 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0807996
Z variance train             0.023039198
KL Divergence                35.8896
KL Loss                      3.58896
QF Loss                      208.56233
VF Loss                      139.0743
Policy Loss                  -805.8361
Q Predictions Mean           799.0617
Q Predictions Std            891.35333
Q Predictions Max            2843.275
Q Predictions Min            -144.12999
V Predictions Mean           802.68115
V Predictions Std            890.10406
V Predictions Max            2823.452
V Predictions Min            -143.1641
Log Pis Mean                 -1.184794
Log Pis Std                  3.180121
Log Pis Max                  12.356448
Log Pis Min                  -6.653386
Policy mu Mean               -0.09207025
Policy mu Std                0.7902631
Policy mu Max                3.784519
Policy mu Min                -2.3689399
Policy log std Mean          -0.4646425
Policy log std Std           0.2349661
Policy log std Max           0.15224183
Policy log std Min           -2.1052566
Z mean eval                  1.926891
Z variance eval              0.0233453
total_rewards                [6815.90570081 7289.6496237  7229.51027067 6995.31528024 6939.14556188
 7000.00685251 7141.58500059 7291.11815878 6593.81287209 6688.51545433]
total_rewards_mean           6998.45647756052
total_rewards_std            232.58776071583847
total_rewards_max            7291.118158781056
total_rewards_min            6593.812872091532
Number of train steps total  356000
Number of env steps total    1070000
Number of rollouts total     0
Train Time (s)               143.88833766197786
(Previous) Eval Time (s)     17.587287302594632
Sample Time (s)              6.576064620632678
Epoch Time (s)               168.05168958520517
Total Train Time (s)         14985.870213527232
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:03:24.456768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #88 | Epoch Duration: 168.13499903678894
2020-01-12 12:03:24.456973 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9271028
Z variance train             0.023267645
KL Divergence                35.154015
KL Loss                      3.5154016
QF Loss                      244.61386
VF Loss                      123.666275
Policy Loss                  -853.591
Q Predictions Mean           845.50305
Q Predictions Std            899.7223
Q Predictions Max            2820.118
Q Predictions Min            -136.60895
V Predictions Mean           854.8567
V Predictions Std            898.50446
V Predictions Max            2822.4182
V Predictions Min            -132.92235
Log Pis Mean                 -0.6983094
Log Pis Std                  3.6590133
Log Pis Max                  15.549471
Log Pis Min                  -7.363738
Policy mu Mean               0.044267733
Policy mu Std                0.83111835
Policy mu Max                3.83306
Policy mu Min                -2.9621847
Policy log std Mean          -0.4919586
Policy log std Std           0.24132477
Policy log std Max           -0.16028835
Policy log std Min           -2.203754
Z mean eval                  1.9272244
Z variance eval              0.015736718
total_rewards                [6798.99342897 6993.20036624 7270.62107761 6907.74184678 6765.08952119
 6489.69412808 7149.3802166  6972.35396072 6863.42144868 6931.90696816]
total_rewards_mean           6914.240296301823
total_rewards_std            202.6361452343653
total_rewards_max            7270.6210776110975
total_rewards_min            6489.694128076472
Number of train steps total  360000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               142.0992118776776
(Previous) Eval Time (s)     17.537145932670683
Sample Time (s)              5.57813604734838
Epoch Time (s)               165.21449385769665
Total Train Time (s)         15151.175662376918
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:06:09.767395 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #89 | Epoch Duration: 165.31020736694336
2020-01-12 12:06:09.767674 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9291741
Z variance train             0.015707111
KL Divergence                36.509743
KL Loss                      3.6509743
QF Loss                      1000.92725
VF Loss                      66.60585
Policy Loss                  -792.54034
Q Predictions Mean           788.59143
Q Predictions Std            872.82355
Q Predictions Max            2835.4275
Q Predictions Min            -155.32314
V Predictions Mean           792.95
V Predictions Std            875.2994
V Predictions Max            2789.1008
V Predictions Min            -145.24858
Log Pis Mean                 -0.95912737
Log Pis Std                  3.5319088
Log Pis Max                  13.981365
Log Pis Min                  -7.518078
Policy mu Mean               0.027622482
Policy mu Std                0.7943562
Policy mu Max                2.6899016
Policy mu Min                -2.610173
Policy log std Mean          -0.48913732
Policy log std Std           0.23090687
Policy log std Max           -0.09019421
Policy log std Min           -2.1225457
Z mean eval                  1.9263948
Z variance eval              0.03546231
total_rewards                [6962.21252432 6891.21945113 7071.40654509 6987.65388899 7120.20508048
 6950.76157563 7053.64443002 6752.48976576 6952.69758969 6842.34782823]
total_rewards_mean           6958.46386793362
total_rewards_std            104.57742089844858
total_rewards_max            7120.2050804776445
total_rewards_min            6752.4897657570555
Number of train steps total  364000
Number of env steps total    1094000
Number of rollouts total     0
Train Time (s)               144.20610792608932
(Previous) Eval Time (s)     17.521170976106077
Sample Time (s)              6.459666369948536
Epoch Time (s)               168.18694527214393
Total Train Time (s)         15319.446167192422
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:08:58.035822 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #90 | Epoch Duration: 168.26796460151672
2020-01-12 12:08:58.035964 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9271246
Z variance train             0.035411812
KL Divergence                34.936966
KL Loss                      3.4936967
QF Loss                      262.31976
VF Loss                      57.05413
Policy Loss                  -939.1956
Q Predictions Mean           938.13025
Q Predictions Std            945.0635
Q Predictions Max            2806.3594
Q Predictions Min            254.74431
V Predictions Mean           939.3331
V Predictions Std            945.3313
V Predictions Max            2786.2878
V Predictions Min            264.18433
Log Pis Mean                 -0.6832967
Log Pis Std                  3.5991898
Log Pis Max                  12.719261
Log Pis Min                  -7.2155433
Policy mu Mean               -0.021198655
Policy mu Std                0.84060055
Policy mu Max                2.7585504
Policy mu Min                -2.5623043
Policy log std Mean          -0.4961022
Policy log std Std           0.24633025
Policy log std Max           -0.10967898
Policy log std Min           -2.0952933
Z mean eval                  1.9254935
Z variance eval              0.031933405
total_rewards                [6983.59195109 7062.77059384 6930.22395019 6766.88011683 5308.97817283
 7146.32544945 6588.0054982  6606.30241647 6755.48852662 6565.82120332]
total_rewards_mean           6671.438787881707
total_rewards_std            493.75080248192126
total_rewards_max            7146.325449448679
total_rewards_min            5308.978172827709
Number of train steps total  368000
Number of env steps total    1106000
Number of rollouts total     0
Train Time (s)               143.75813356786966
(Previous) Eval Time (s)     20.968512722756714
Sample Time (s)              5.550566884689033
Epoch Time (s)               170.2772131753154
Total Train Time (s)         15489.800794639625
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:11:48.396333 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #91 | Epoch Duration: 170.3601999282837
2020-01-12 12:11:48.396599 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9250515
Z variance train             0.032038443
KL Divergence                34.908085
KL Loss                      3.4908085
QF Loss                      509.2765
VF Loss                      127.969284
Policy Loss                  -722.9397
Q Predictions Mean           712.375
Q Predictions Std            782.9121
Q Predictions Max            2825.6453
Q Predictions Min            -150.62369
V Predictions Mean           715.1199
V Predictions Std            780.5521
V Predictions Max            2791.151
V Predictions Min            -154.92726
Log Pis Mean                 -1.3459429
Log Pis Std                  3.0131645
Log Pis Max                  10.525032
Log Pis Min                  -7.659042
Policy mu Mean               -0.01008385
Policy mu Std                0.76773375
Policy mu Max                3.12268
Policy mu Min                -2.7024932
Policy log std Mean          -0.47551206
Policy log std Std           0.21089685
Policy log std Max           -0.10658145
Policy log std Min           -1.872183
Z mean eval                  1.9480652
Z variance eval              0.028568843
total_rewards                [6896.16222953 6933.43591348 7207.82974161 7108.12725061 7123.51070532
 7130.30406293 7060.38162886 7096.6089008  7156.52609358 6977.71199893]
total_rewards_mean           7069.0598525655105
total_rewards_std            96.23698279492831
total_rewards_max            7207.829741605403
total_rewards_min            6896.162229530173
Number of train steps total  372000
Number of env steps total    1118000
Number of rollouts total     0
Train Time (s)               144.4790194928646
(Previous) Eval Time (s)     20.898349762894213
Sample Time (s)              5.671871499624103
Epoch Time (s)               171.04924075538293
Total Train Time (s)         15660.93359193625
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:14:39.528145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #92 | Epoch Duration: 171.1313989162445
2020-01-12 12:14:39.528281 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9502541
Z variance train             0.028415492
KL Divergence                35.944492
KL Loss                      3.5944493
QF Loss                      451.23682
VF Loss                      175.29254
Policy Loss                  -829.1762
Q Predictions Mean           827.261
Q Predictions Std            898.9086
Q Predictions Max            2883.2905
Q Predictions Min            -146.39136
V Predictions Mean           825.4673
V Predictions Std            899.08154
V Predictions Max            2869.2632
V Predictions Min            -148.23943
Log Pis Mean                 -1.0268289
Log Pis Std                  3.411231
Log Pis Max                  12.243606
Log Pis Min                  -6.4797916
Policy mu Mean               -0.02386024
Policy mu Std                0.77204347
Policy mu Max                2.6899395
Policy mu Min                -2.8781614
Policy log std Mean          -0.49026632
Policy log std Std           0.23146656
Policy log std Max           -0.18375134
Policy log std Min           -2.2068822
Z mean eval                  1.9520752
Z variance eval              0.020687118
total_rewards                [6770.08694816 6852.6263622  6781.78102973 6721.45810336 6630.03339687
 6799.85093726 6984.73607002 6469.20997107 6962.23387439 6923.41478216]
total_rewards_mean           6789.543147521702
total_rewards_std            149.35219887864247
total_rewards_max            6984.736070018523
total_rewards_min            6469.209971071685
Number of train steps total  376000
Number of env steps total    1130000
Number of rollouts total     0
Train Time (s)               143.41464222688228
(Previous) Eval Time (s)     17.472814690787345
Sample Time (s)              6.470811376813799
Epoch Time (s)               167.35826829448342
Total Train Time (s)         15828.368514915928
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:17:26.965516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #93 | Epoch Duration: 167.4371199607849
2020-01-12 12:17:26.965702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.955849
Z variance train             0.020794028
KL Divergence                35.457333
KL Loss                      3.5457332
QF Loss                      971.7628
VF Loss                      47.19342
Policy Loss                  -829.6177
Q Predictions Mean           826.01184
Q Predictions Std            888.1491
Q Predictions Max            2963.528
Q Predictions Min            272.5681
V Predictions Mean           831.42413
V Predictions Std            887.75916
V Predictions Max            2943.7876
V Predictions Min            275.71057
Log Pis Mean                 -0.8349519
Log Pis Std                  3.562833
Log Pis Max                  11.356342
Log Pis Min                  -7.890978
Policy mu Mean               0.011857144
Policy mu Std                0.85243595
Policy mu Max                3.3515043
Policy mu Min                -3.0572422
Policy log std Mean          -0.46886578
Policy log std Std           0.21230197
Policy log std Max           0.17902192
Policy log std Min           -2.102565
Z mean eval                  1.9613756
Z variance eval              0.020575363
total_rewards                [6781.89910206 7135.13516177 7026.1236049  6985.12308895 6958.93112977
 6865.64811754 7001.42536767 6754.56096472 7080.09774399 6962.08331068]
total_rewards_mean           6955.102759205081
total_rewards_std            115.93464218903276
total_rewards_max            7135.135161774803
total_rewards_min            6754.560964716477
Number of train steps total  380000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               144.89263023482636
(Previous) Eval Time (s)     20.879871659446508
Sample Time (s)              6.523120848461986
Epoch Time (s)               172.29562274273485
Total Train Time (s)         16000.890623628162
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:20:19.490706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #94 | Epoch Duration: 172.52475881576538
2020-01-12 12:20:19.490990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #94 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9577183
Z variance train             0.020569151
KL Divergence                35.62691
KL Loss                      3.5626912
QF Loss                      328.0436
VF Loss                      105.83563
Policy Loss                  -762.04297
Q Predictions Mean           758.4116
Q Predictions Std            865.4914
Q Predictions Max            2912.8662
Q Predictions Min            -178.84142
V Predictions Mean           765.37305
V Predictions Std            866.19763
V Predictions Max            2908.577
V Predictions Min            -163.88391
Log Pis Mean                 -0.9066294
Log Pis Std                  3.525547
Log Pis Max                  17.648396
Log Pis Min                  -6.7583046
Policy mu Mean               0.011152982
Policy mu Std                0.80680907
Policy mu Max                2.91809
Policy mu Min                -2.8314044
Policy log std Mean          -0.4720684
Policy log std Std           0.23710132
Policy log std Max           -0.06470287
Policy log std Min           -2.0553463
Z mean eval                  1.9550068
Z variance eval              0.04327026
total_rewards                [6925.4990185  6891.67387614 6958.20214686 6803.17791482 6885.2944383
 6883.72798927 6757.10644823 6975.64832219 6919.30763631 6853.38276128]
total_rewards_mean           6885.302055189028
total_rewards_std            63.63132402670892
total_rewards_max            6975.648322189124
total_rewards_min            6757.106448232212
Number of train steps total  384000
Number of env steps total    1154000
Number of rollouts total     0
Train Time (s)               144.42324313195422
(Previous) Eval Time (s)     17.48837686376646
Sample Time (s)              6.4801661148667336
Epoch Time (s)               168.39178611058742
Total Train Time (s)         16169.366245115642
Epoch                        95
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:23:07.969791 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #95 | Epoch Duration: 168.4786114692688
2020-01-12 12:23:07.969997 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9518551
Z variance train             0.042925913
KL Divergence                34.443462
KL Loss                      3.4443462
QF Loss                      1031.6748
VF Loss                      90.52602
Policy Loss                  -821.28534
Q Predictions Mean           814.4607
Q Predictions Std            921.5163
Q Predictions Max            2898.069
Q Predictions Min            -160.11168
V Predictions Mean           823.7565
V Predictions Std            917.4904
V Predictions Max            2899.3906
V Predictions Min            -148.31297
Log Pis Mean                 -0.9597713
Log Pis Std                  3.2622561
Log Pis Max                  13.871848
Log Pis Min                  -6.8744698
Policy mu Mean               0.01018106
Policy mu Std                0.78635955
Policy mu Max                2.8477485
Policy mu Min                -3.26072
Policy log std Mean          -0.46347722
Policy log std Std           0.21617272
Policy log std Max           -0.0980041
Policy log std Min           -1.8197339
Z mean eval                  1.925991
Z variance eval              0.037870783
total_rewards                [6784.75083446 7108.81177622 7399.1155278  7183.25776872 7205.81909935
 7042.09442055 7076.81791695 7248.69563281 7119.30021553 7059.10557931]
total_rewards_mean           7122.776877169905
total_rewards_std            151.6301973662004
total_rewards_max            7399.115527797064
total_rewards_min            6784.750834458908
Number of train steps total  388000
Number of env steps total    1166000
Number of rollouts total     0
Train Time (s)               144.06890761805698
(Previous) Eval Time (s)     17.57093188771978
Sample Time (s)              6.366818407084793
Epoch Time (s)               168.00665791286156
Total Train Time (s)         16337.459316642024
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:25:56.063161 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #96 | Epoch Duration: 168.092933177948
2020-01-12 12:25:56.063488 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9246712
Z variance train             0.03768177
KL Divergence                33.886417
KL Loss                      3.3886418
QF Loss                      145.71849
VF Loss                      75.80509
Policy Loss                  -778.44586
Q Predictions Mean           773.874
Q Predictions Std            871.4688
Q Predictions Max            2842.3108
Q Predictions Min            -156.5935
V Predictions Mean           781.1615
V Predictions Std            866.9697
V Predictions Max            2833.1519
V Predictions Min            -156.84837
Log Pis Mean                 -0.8810864
Log Pis Std                  3.2318861
Log Pis Max                  10.44112
Log Pis Min                  -5.725468
Policy mu Mean               -0.11117516
Policy mu Std                0.80594635
Policy mu Max                2.6880643
Policy mu Min                -2.6677115
Policy log std Mean          -0.4733659
Policy log std Std           0.21655037
Policy log std Max           -0.12529892
Policy log std Min           -2.4063735
Z mean eval                  1.9261891
Z variance eval              0.015617192
total_rewards                [6910.92650716 7285.85988779 7070.93298224 7059.65686143 7061.45224823
 7394.64542133 7198.90833304 6887.95764664 7079.66250583 7115.98679961]
total_rewards_mean           7106.598919329257
total_rewards_std            146.98487998462107
total_rewards_max            7394.645421327544
total_rewards_min            6887.957646635956
Number of train steps total  392000
Number of env steps total    1178000
Number of rollouts total     0
Train Time (s)               143.565619263798
(Previous) Eval Time (s)     17.26439891103655
Sample Time (s)              6.321033394429833
Epoch Time (s)               167.15105156926438
Total Train Time (s)         16504.68865882093
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:28:43.293686 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #97 | Epoch Duration: 167.2299976348877
2020-01-12 12:28:43.293871 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9236796
Z variance train             0.015629128
KL Divergence                36.926384
KL Loss                      3.6926384
QF Loss                      140.98753
VF Loss                      70.67559
Policy Loss                  -772.65607
Q Predictions Mean           768.79614
Q Predictions Std            896.90076
Q Predictions Max            2890.0928
Q Predictions Min            -181.72795
V Predictions Mean           773.215
V Predictions Std            897.26587
V Predictions Max            2872.159
V Predictions Min            -165.36037
Log Pis Mean                 -0.8491062
Log Pis Std                  3.4017882
Log Pis Max                  16.401505
Log Pis Min                  -6.694831
Policy mu Mean               -0.07999235
Policy mu Std                0.79951745
Policy mu Max                3.4597378
Policy mu Min                -2.3984046
Policy log std Mean          -0.47717237
Policy log std Std           0.22853754
Policy log std Max           -0.14652878
Policy log std Min           -2.084047
Z mean eval                  1.955007
Z variance eval              0.01590431
total_rewards                [7173.46759039 7011.44339548 7295.25433609 7027.43267328 7365.85267069
 7230.93851412 7080.09379425 7203.13389546 7211.9468323  7115.84003063]
total_rewards_mean           7171.540373269328
total_rewards_std            108.20728990294137
total_rewards_max            7365.8526706925395
total_rewards_min            7011.443395475614
Number of train steps total  396000
Number of env steps total    1190000
Number of rollouts total     0
Train Time (s)               145.42305033281446
(Previous) Eval Time (s)     17.334379236679524
Sample Time (s)              6.631349541246891
Epoch Time (s)               169.38877911074087
Total Train Time (s)         16674.180383663625
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:31:32.795630 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #98 | Epoch Duration: 169.50161504745483
2020-01-12 12:31:32.795809 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9573311
Z variance train             0.015906803
KL Divergence                38.290527
KL Loss                      3.8290527
QF Loss                      222.62672
VF Loss                      127.45002
Policy Loss                  -823.197
Q Predictions Mean           818.0975
Q Predictions Std            913.699
Q Predictions Max            2958.4922
Q Predictions Min            -166.81929
V Predictions Mean           824.3971
V Predictions Std            913.9169
V Predictions Max            2955.7908
V Predictions Min            -187.14996
Log Pis Mean                 -0.71851224
Log Pis Std                  3.573749
Log Pis Max                  21.183805
Log Pis Min                  -5.614256
Policy mu Mean               -0.015614729
Policy mu Std                0.8101781
Policy mu Max                3.8962865
Policy mu Min                -2.9887483
Policy log std Mean          -0.47551736
Policy log std Std           0.22709781
Policy log std Max           -0.07680419
Policy log std Min           -2.0685337
Z mean eval                  1.9186201
Z variance eval              0.029956728
total_rewards                [7199.1334282  6986.66026459 7219.7231687  7054.786189   7101.66576537
 7397.95722234 7024.74711855 6969.33697813 7163.59485235 7207.62206831]
total_rewards_mean           7132.522705555524
total_rewards_std            124.74690844790118
total_rewards_max            7397.957222338196
total_rewards_min            6969.3369781315105
Number of train steps total  400000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               144.61361826816574
(Previous) Eval Time (s)     21.027083704713732
Sample Time (s)              6.556876257993281
Epoch Time (s)               172.19757823087275
Total Train Time (s)         16846.464620177634
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:34:25.076745 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #99 | Epoch Duration: 172.2808063030243
2020-01-12 12:34:25.076882 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9198582
Z variance train             0.030087644
KL Divergence                37.73826
KL Loss                      3.773826
QF Loss                      186.96909
VF Loss                      131.99274
Policy Loss                  -789.7919
Q Predictions Mean           787.02893
Q Predictions Std            913.64954
Q Predictions Max            2898.7463
Q Predictions Min            -202.56499
V Predictions Mean           792.09937
V Predictions Std            915.6611
V Predictions Max            2931.6113
V Predictions Min            -197.8871
Log Pis Mean                 -0.8441348
Log Pis Std                  3.5685039
Log Pis Max                  14.654056
Log Pis Min                  -8.287224
Policy mu Mean               -0.032866765
Policy mu Std                0.7899241
Policy mu Max                2.9057257
Policy mu Min                -2.3959796
Policy log std Mean          -0.47089636
Policy log std Std           0.24273388
Policy log std Max           -0.15467562
Policy log std Min           -2.1907928
Z mean eval                  1.9512832
Z variance eval              0.030735204
total_rewards                [6836.95180953 7186.2285294  7232.20174307 6919.99718401 7107.26881144
 7057.73115159 7045.45048829 7153.18812023 6935.67984264 7351.98645977]
total_rewards_mean           7082.668413997375
total_rewards_std            148.87800114147583
total_rewards_max            7351.986459765026
total_rewards_min            6836.951809529374
Number of train steps total  404000
Number of env steps total    1214000
Number of rollouts total     0
Train Time (s)               143.1254305159673
(Previous) Eval Time (s)     17.800623739603907
Sample Time (s)              6.571932315360755
Epoch Time (s)               167.49798657093197
Total Train Time (s)         17014.042863237206
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:37:12.658547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #100 | Epoch Duration: 167.58152103424072
2020-01-12 12:37:12.658900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9481484
Z variance train             0.030712593
KL Divergence                37.734062
KL Loss                      3.7734063
QF Loss                      211.76804
VF Loss                      112.42422
Policy Loss                  -809.84937
Q Predictions Mean           802.0088
Q Predictions Std            887.39594
Q Predictions Max            2985.6897
Q Predictions Min            -166.66971
V Predictions Mean           807.3661
V Predictions Std            890.58704
V Predictions Max            2965.6096
V Predictions Min            -190.80685
Log Pis Mean                 -0.87187636
Log Pis Std                  3.3722038
Log Pis Max                  13.284132
Log Pis Min                  -6.7265606
Policy mu Mean               0.0024157986
Policy mu Std                0.8291998
Policy mu Max                2.8632176
Policy mu Min                -2.5787098
Policy log std Mean          -0.49392834
Policy log std Std           0.22726126
Policy log std Max           -0.093110204
Policy log std Min           -2.0595007
Z mean eval                  1.9123154
Z variance eval              0.046586704
total_rewards                [6494.28234362 7286.10448183 6841.09749333 7078.7067167  7060.63968988
 6948.82282762 7006.3019518  6994.81328263 7154.83236328 7085.67850526]
total_rewards_mean           6995.127965596073
total_rewards_std            201.61603799319053
total_rewards_max            7286.104481830567
total_rewards_min            6494.2823436208755
Number of train steps total  408000
Number of env steps total    1226000
Number of rollouts total     0
Train Time (s)               143.60141613101587
(Previous) Eval Time (s)     17.73103729216382
Sample Time (s)              5.579986117780209
Epoch Time (s)               166.9124395409599
Total Train Time (s)         17181.03221380338
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:39:59.645739 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #101 | Epoch Duration: 166.98662400245667
2020-01-12 12:39:59.645866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #101 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9122131
Z variance train             0.046499323
KL Divergence                36.91224
KL Loss                      3.6912239
QF Loss                      204.64801
VF Loss                      425.9266
Policy Loss                  -830.5631
Q Predictions Mean           822.53845
Q Predictions Std            917.2486
Q Predictions Max            2953.9556
Q Predictions Min            280.40887
V Predictions Mean           834.4296
V Predictions Std            918.86285
V Predictions Max            2929.4495
V Predictions Min            291.0007
Log Pis Mean                 -0.5841043
Log Pis Std                  3.594026
Log Pis Max                  12.076417
Log Pis Min                  -7.8194447
Policy mu Mean               0.004250919
Policy mu Std                0.8290791
Policy mu Max                2.7618017
Policy mu Min                -3.0087683
Policy log std Mean          -0.5007985
Policy log std Std           0.2462666
Policy log std Max           -0.11922583
Policy log std Min           -2.0630345
Z mean eval                  1.9185776
Z variance eval              0.036846966
total_rewards                [6674.88464775 6050.55690009 6582.71613513 6281.26385174 6457.9208249
 6409.77093247 6790.2106098  6434.20594852 6581.91656938 6540.74954236]
total_rewards_mean           6480.419596214767
total_rewards_std            197.5528096253992
total_rewards_max            6790.210609800283
total_rewards_min            6050.556900093767
Number of train steps total  412000
Number of env steps total    1238000
Number of rollouts total     0
Train Time (s)               143.72307493630797
(Previous) Eval Time (s)     20.90759125724435
Sample Time (s)              5.638433326967061
Epoch Time (s)               170.26909952051938
Total Train Time (s)         17351.38688650867
Epoch                        102
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:42:50.001589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #102 | Epoch Duration: 170.35562944412231
2020-01-12 12:42:50.001722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9190061
Z variance train             0.036996357
KL Divergence                36.68301
KL Loss                      3.668301
QF Loss                      429.22845
VF Loss                      104.5327
Policy Loss                  -939.28455
Q Predictions Mean           934.9176
Q Predictions Std            1006.88794
Q Predictions Max            3030.2312
Q Predictions Min            -192.72853
V Predictions Mean           932.5804
V Predictions Std            1001.59344
V Predictions Max            2986.3684
V Predictions Min            -193.13354
Log Pis Mean                 -0.19239593
Log Pis Std                  3.7003336
Log Pis Max                  11.6999855
Log Pis Min                  -8.99497
Policy mu Mean               -0.06895702
Policy mu Std                0.870376
Policy mu Max                2.5754828
Policy mu Min                -2.6116986
Policy log std Mean          -0.5038132
Policy log std Std           0.22910304
Policy log std Max           -0.11108971
Policy log std Min           -2.2524993
Z mean eval                  1.9131848
Z variance eval              0.027703404
total_rewards                [6931.07392711 6911.31652707 6916.28483468 7033.84057386 7236.75355923
 7010.04167597 6992.58336973 7092.41402251 6858.28369889 6829.14155748]
total_rewards_mean           6981.173374653488
total_rewards_std            114.56400631425684
total_rewards_max            7236.753559230378
total_rewards_min            6829.141557477321
Number of train steps total  416000
Number of env steps total    1250000
Number of rollouts total     0
Train Time (s)               144.1944802897051
(Previous) Eval Time (s)     21.153590239118785
Sample Time (s)              6.52583810640499
Epoch Time (s)               171.87390863522887
Total Train Time (s)         17523.347225406673
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:45:41.964083 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #103 | Epoch Duration: 171.9622654914856
2020-01-12 12:45:41.964216 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9119923
Z variance train             0.02760329
KL Divergence                36.591766
KL Loss                      3.6591766
QF Loss                      355.2533
VF Loss                      113.76266
Policy Loss                  -781.56665
Q Predictions Mean           781.32465
Q Predictions Std            879.89734
Q Predictions Max            2971.0996
Q Predictions Min            -128.266
V Predictions Mean           782.276
V Predictions Std            881.92126
V Predictions Max            2991.2356
V Predictions Min            -193.10777
Log Pis Mean                 -0.85325295
Log Pis Std                  3.556944
Log Pis Max                  13.674867
Log Pis Min                  -7.6293197
Policy mu Mean               0.029721871
Policy mu Std                0.8053748
Policy mu Max                3.4148166
Policy mu Min                -2.5768363
Policy log std Mean          -0.49369538
Policy log std Std           0.23865134
Policy log std Max           -0.12624529
Policy log std Min           -2.253504
Z mean eval                  1.9161228
Z variance eval              0.026865054
total_rewards                [7080.11604718 7041.72792161 6991.95393567 7321.65221115 7051.88152365
 7375.47083907 7046.49432117 6881.59844924 7268.86431525 7133.40026517]
total_rewards_mean           7119.315982915413
total_rewards_std            148.07295165704585
total_rewards_max            7375.470839065252
total_rewards_min            6881.598449241846
Number of train steps total  420000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               144.76137865707278
(Previous) Eval Time (s)     21.319770948961377
Sample Time (s)              6.57034373190254
Epoch Time (s)               172.6514933379367
Total Train Time (s)         17696.07851255033
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:48:34.697399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #104 | Epoch Duration: 172.73307156562805
2020-01-12 12:48:34.697598 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9199657
Z variance train             0.026847642
KL Divergence                36.331535
KL Loss                      3.6331537
QF Loss                      177.95108
VF Loss                      128.5391
Policy Loss                  -786.4409
Q Predictions Mean           784.1812
Q Predictions Std            859.46
Q Predictions Max            2925.8354
Q Predictions Min            173.25728
V Predictions Mean           791.4624
V Predictions Std            859.21344
V Predictions Max            2927.9653
V Predictions Min            177.5191
Log Pis Mean                 -0.70992106
Log Pis Std                  3.55017
Log Pis Max                  12.903122
Log Pis Min                  -7.2793236
Policy mu Mean               0.020849323
Policy mu Std                0.8100438
Policy mu Max                2.7160182
Policy mu Min                -2.4194555
Policy log std Mean          -0.48243427
Policy log std Std           0.21911544
Policy log std Max           0.016684294
Policy log std Min           -1.8477298
Z mean eval                  1.9044956
Z variance eval              0.055526666
total_rewards                [7313.71779703 7495.45141191 7520.15145555 7445.75068871 7307.38067294
 7515.59825665 7384.09986366 7350.95264182 7497.84761127 7471.37889775]
total_rewards_mean           7430.232929729131
total_rewards_std            79.50700875653034
total_rewards_max            7520.151455553658
total_rewards_min            7307.380672944401
Number of train steps total  424000
Number of env steps total    1274000
Number of rollouts total     0
Train Time (s)               144.52712028520182
(Previous) Eval Time (s)     17.535538257099688
Sample Time (s)              5.701904498971999
Epoch Time (s)               167.7645630412735
Total Train Time (s)         17863.922279125545
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:51:22.543831 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #105 | Epoch Duration: 167.84603238105774
2020-01-12 12:51:22.544111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9023387
Z variance train             0.05563987
KL Divergence                35.090317
KL Loss                      3.5090318
QF Loss                      1831.6276
VF Loss                      178.37271
Policy Loss                  -817.60834
Q Predictions Mean           820.8696
Q Predictions Std            926.6495
Q Predictions Max            3012.8435
Q Predictions Min            -199.35379
V Predictions Mean           819.7685
V Predictions Std            920.3622
V Predictions Max            2977.6545
V Predictions Min            -250.17616
Log Pis Mean                 -0.36028093
Log Pis Std                  3.6196344
Log Pis Max                  14.3547535
Log Pis Min                  -7.2800493
Policy mu Mean               -0.0020337787
Policy mu Std                0.82577497
Policy mu Max                2.529899
Policy mu Min                -2.4691093
Policy log std Mean          -0.51568514
Policy log std Std           0.24168961
Policy log std Max           -0.07920104
Policy log std Min           -2.101961
Z mean eval                  1.9212914
Z variance eval              0.03641849
total_rewards                [7332.94438196 7423.87831011 7496.97089141 7566.78696447 7428.29160515
 7594.16045764 7295.23990967 7474.85704441 7493.19866737 7596.55574093]
total_rewards_mean           7470.288397312033
total_rewards_std            97.61167434436152
total_rewards_max            7596.555740926086
total_rewards_min            7295.239909671807
Number of train steps total  428000
Number of env steps total    1286000
Number of rollouts total     0
Train Time (s)               145.4948024759069
(Previous) Eval Time (s)     21.22278656810522
Sample Time (s)              6.706497674807906
Epoch Time (s)               173.42408671882004
Total Train Time (s)         18037.426344096195
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:54:16.048084 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #106 | Epoch Duration: 173.50380277633667
2020-01-12 12:54:16.048231 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9239724
Z variance train             0.03636636
KL Divergence                35.616932
KL Loss                      3.5616932
QF Loss                      1156.5464
VF Loss                      75.62479
Policy Loss                  -855.18085
Q Predictions Mean           848.7662
Q Predictions Std            939.9918
Q Predictions Max            2943.1384
Q Predictions Min            -227.2128
V Predictions Mean           850.2124
V Predictions Std            938.0852
V Predictions Max            2930.9998
V Predictions Min            -238.77425
Log Pis Mean                 -0.5033512
Log Pis Std                  3.2893548
Log Pis Max                  14.158642
Log Pis Min                  -6.04196
Policy mu Mean               -0.019183343
Policy mu Std                0.82449967
Policy mu Max                2.6877272
Policy mu Min                -2.4937038
Policy log std Mean          -0.5123274
Policy log std Std           0.24086493
Policy log std Max           -0.09537104
Policy log std Min           -2.3237872
Z mean eval                  1.90819
Z variance eval              0.03924941
total_rewards                [7079.91371451 7128.06021893 7284.29242871 7120.66729496 7280.37833744
 7242.91927915 7166.46462145 7303.89062327 7379.48486638 7054.06472779]
total_rewards_mean           7204.013611258201
total_rewards_std            103.23100055042836
total_rewards_max            7379.484866384539
total_rewards_min            7054.064727788141
Number of train steps total  432000
Number of env steps total    1298000
Number of rollouts total     0
Train Time (s)               145.1561213331297
(Previous) Eval Time (s)     17.87301849387586
Sample Time (s)              6.5740503994748
Epoch Time (s)               169.60319022648036
Total Train Time (s)         18207.126162834466
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:57:05.755293 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #107 | Epoch Duration: 169.70679092407227
2020-01-12 12:57:05.755782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9080664
Z variance train             0.03948683
KL Divergence                37.3465
KL Loss                      3.7346501
QF Loss                      1396.387
VF Loss                      39.721226
Policy Loss                  -938.37604
Q Predictions Mean           938.7648
Q Predictions Std            994.80786
Q Predictions Max            3171.219
Q Predictions Min            239.5251
V Predictions Mean           935.6797
V Predictions Std            992.1613
V Predictions Max            3157.042
V Predictions Min            236.0456
Log Pis Mean                 -0.23342033
Log Pis Std                  3.5909774
Log Pis Max                  13.300819
Log Pis Min                  -8.158692
Policy mu Mean               -0.03888278
Policy mu Std                0.8769801
Policy mu Max                2.449174
Policy mu Min                -2.502029
Policy log std Mean          -0.51083595
Policy log std Std           0.24604046
Policy log std Max           -0.13549732
Policy log std Min           -2.2447495
Z mean eval                  1.9063368
Z variance eval              0.061633624
total_rewards                [6851.39667541 7220.6755688  7322.37475953 7078.72550887 6902.9060456
 7105.45402231 7113.49357434 6819.26869596 7434.61915919 6911.04306633]
total_rewards_mean           7075.995707634696
total_rewards_std            196.48152644496312
total_rewards_max            7434.619159189323
total_rewards_min            6819.268695961751
Number of train steps total  436000
Number of env steps total    1310000
Number of rollouts total     0
Train Time (s)               142.51524862879887
(Previous) Eval Time (s)     17.76117130694911
Sample Time (s)              6.562565880361944
Epoch Time (s)               166.83898581610993
Total Train Time (s)         18374.05369709432
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:59:52.682858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #108 | Epoch Duration: 166.9267590045929
2020-01-12 12:59:52.683053 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9081059
Z variance train             0.062134463
KL Divergence                35.859013
KL Loss                      3.5859013
QF Loss                      171.74023
VF Loss                      122.72737
Policy Loss                  -851.08417
Q Predictions Mean           844.6479
Q Predictions Std            927.25684
Q Predictions Max            2995.3828
Q Predictions Min            177.99358
V Predictions Mean           845.505
V Predictions Std            925.7861
V Predictions Max            2983.0195
V Predictions Min            182.60228
Log Pis Mean                 -0.43036216
Log Pis Std                  3.7020714
Log Pis Max                  12.458061
Log Pis Min                  -7.847006
Policy mu Mean               -0.0036208492
Policy mu Std                0.85864455
Policy mu Max                3.3925426
Policy mu Min                -2.977624
Policy log std Mean          -0.49077502
Policy log std Std           0.22834393
Policy log std Max           -0.14068776
Policy log std Min           -2.0067024
Z mean eval                  1.9272276
Z variance eval              0.12757292
total_rewards                [7471.58946497 7087.35709427 6807.86512466 7140.07353814 7032.06243809
 7378.50430861 7507.8338408  7266.62277801 7258.38489962 7206.42088186]
total_rewards_mean           7215.671436904074
total_rewards_std            201.01526530273446
total_rewards_max            7507.83384080224
total_rewards_min            6807.865124664541
Number of train steps total  440000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               143.8547427719459
(Previous) Eval Time (s)     17.651402975898236
Sample Time (s)              6.479253159835935
Epoch Time (s)               167.98539890768006
Total Train Time (s)         18542.12601461634
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:02:40.756766 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #109 | Epoch Duration: 168.073561668396
2020-01-12 13:02:40.756940 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9280527
Z variance train             0.1268874
KL Divergence                37.429317
KL Loss                      3.7429318
QF Loss                      470.232
VF Loss                      92.32588
Policy Loss                  -760.1286
Q Predictions Mean           756.58325
Q Predictions Std            862.76056
Q Predictions Max            3043.059
Q Predictions Min            -303.75357
V Predictions Mean           753.98413
V Predictions Std            857.5785
V Predictions Max            3018.1267
V Predictions Min            -257.14316
Log Pis Mean                 -1.0864537
Log Pis Std                  3.5456898
Log Pis Max                  14.290344
Log Pis Min                  -7.863919
Policy mu Mean               0.002960734
Policy mu Std                0.81410563
Policy mu Max                2.5935562
Policy mu Min                -2.9445782
Policy log std Mean          -0.4749986
Policy log std Std           0.23077637
Policy log std Max           -0.10855514
Policy log std Min           -2.1209948
Z mean eval                  1.8875366
Z variance eval              0.044112746
total_rewards                [7543.11112517 7343.38792588 7567.90351152 7611.87158479 7499.49656459
 7603.1901754  7597.49106087 7496.92589915 7581.02284374 7567.32794193]
total_rewards_mean           7541.172863304377
total_rewards_std            76.03958066088532
total_rewards_max            7611.871584792599
total_rewards_min            7343.387925879508
Number of train steps total  444000
Number of env steps total    1334000
Number of rollouts total     0
Train Time (s)               145.14623410999775
(Previous) Eval Time (s)     21.108967198990285
Sample Time (s)              6.455439322628081
Epoch Time (s)               172.71064063161612
Total Train Time (s)         18714.917049956974
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:05:33.548428 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #110 | Epoch Duration: 172.7913601398468
2020-01-12 13:05:33.548575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8880463
Z variance train             0.044402517
KL Divergence                37.60445
KL Loss                      3.760445
QF Loss                      237.7527
VF Loss                      42.007004
Policy Loss                  -776.46564
Q Predictions Mean           775.03033
Q Predictions Std            867.4189
Q Predictions Max            3054.4944
Q Predictions Min            312.23987
V Predictions Mean           773.40015
V Predictions Std            867.1907
V Predictions Max            3011.364
V Predictions Min            309.64786
Log Pis Mean                 -1.0138376
Log Pis Std                  3.2418103
Log Pis Max                  11.1862545
Log Pis Min                  -6.3295317
Policy mu Mean               0.012316257
Policy mu Std                0.80221117
Policy mu Max                2.9116411
Policy mu Min                -2.8177445
Policy log std Mean          -0.48673233
Policy log std Std           0.21582386
Policy log std Max           -0.12275705
Policy log std Min           -1.8103812
Z mean eval                  1.9022865
Z variance eval              0.050370812
total_rewards                [7081.5059657  7543.53576731 7277.48006741 7360.66910782 7300.89242344
 7327.75994107 7306.46763724 7121.03569311 7213.4607395  7540.99165857]
total_rewards_mean           7307.379900116468
total_rewards_std            144.6029249580695
total_rewards_max            7543.535767311413
total_rewards_min            7081.505965704212
Number of train steps total  448000
Number of env steps total    1346000
Number of rollouts total     0
Train Time (s)               145.65298531530425
(Previous) Eval Time (s)     18.09470963384956
Sample Time (s)              6.466960986610502
Epoch Time (s)               170.2146559357643
Total Train Time (s)         18885.213521314785
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:08:23.845323 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #111 | Epoch Duration: 170.29664945602417
2020-01-12 13:08:23.845449 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #111 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9039986
Z variance train             0.049729537
KL Divergence                36.491695
KL Loss                      3.6491697
QF Loss                      1405.1643
VF Loss                      259.05408
Policy Loss                  -853.2169
Q Predictions Mean           852.65234
Q Predictions Std            924.5874
Q Predictions Max            3083.4578
Q Predictions Min            -282.27167
V Predictions Mean           866.15063
V Predictions Std            929.2659
V Predictions Max            3099.4607
V Predictions Min            -285.68552
Log Pis Mean                 -0.70494103
Log Pis Std                  3.2510262
Log Pis Max                  13.217918
Log Pis Min                  -7.246575
Policy mu Mean               -0.057437617
Policy mu Std                0.82263553
Policy mu Max                3.538799
Policy mu Min                -2.820245
Policy log std Mean          -0.4911076
Policy log std Std           0.24035822
Policy log std Max           -0.039743915
Policy log std Min           -2.3823073
Z mean eval                  1.9054581
Z variance eval              0.06622856
total_rewards                [7289.64648765 7532.49381457 7345.7478275  7529.78728686 7811.5301482
 7441.10943897 7480.99103629 7774.36640407 7638.49608968 7716.27872823]
total_rewards_mean           7556.044726200933
total_rewards_std            167.53817502530703
total_rewards_max            7811.530148195105
total_rewards_min            7289.646487646022
Number of train steps total  452000
Number of env steps total    1358000
Number of rollouts total     0
Train Time (s)               142.87984588369727
(Previous) Eval Time (s)     17.745346387848258
Sample Time (s)              5.649289525579661
Epoch Time (s)               166.2744817971252
Total Train Time (s)         19051.58230270911
Epoch                        112
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:11:10.217035 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #112 | Epoch Duration: 166.3714780807495
2020-01-12 13:11:10.217222 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9094651
Z variance train             0.066540025
KL Divergence                35.9141
KL Loss                      3.5914102
QF Loss                      196.49733
VF Loss                      51.570873
Policy Loss                  -872.6476
Q Predictions Mean           866.8109
Q Predictions Std            962.18097
Q Predictions Max            3109.0315
Q Predictions Min            324.93378
V Predictions Mean           872.9815
V Predictions Std            961.7692
V Predictions Max            3100.9292
V Predictions Min            324.6514
Log Pis Mean                 -0.53830713
Log Pis Std                  3.350883
Log Pis Max                  11.599407
Log Pis Min                  -8.683192
Policy mu Mean               0.050827205
Policy mu Std                0.8340545
Policy mu Max                2.6867223
Policy mu Min                -2.7862499
Policy log std Mean          -0.49042165
Policy log std Std           0.23613343
Policy log std Max           -0.13578013
Policy log std Min           -1.9563973
Z mean eval                  1.9007809
Z variance eval              0.038516693
total_rewards                [4591.38951419 6483.08747535 6385.76829397 6312.86570469 7034.20088381
 6490.47979072 6592.02162545 7136.36593443 6982.26341154 6307.41627828]
total_rewards_mean           6431.585891243546
total_rewards_std            679.1833723732648
total_rewards_max            7136.365934433517
total_rewards_min            4591.389514192275
Number of train steps total  456000
Number of env steps total    1370000
Number of rollouts total     0
Train Time (s)               145.5874309251085
(Previous) Eval Time (s)     18.49061840865761
Sample Time (s)              5.697768978308886
Epoch Time (s)               169.775818312075
Total Train Time (s)         19221.44087025663
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:14:00.078432 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #113 | Epoch Duration: 169.86106181144714
2020-01-12 13:14:00.078609 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9011631
Z variance train             0.03859276
KL Divergence                37.03447
KL Loss                      3.703447
QF Loss                      115.08835
VF Loss                      69.73685
Policy Loss                  -860.17303
Q Predictions Mean           857.6362
Q Predictions Std            951.5746
Q Predictions Max            3145.3337
Q Predictions Min            322.2025
V Predictions Mean           854.27527
V Predictions Std            948.4121
V Predictions Max            3117.2192
V Predictions Min            318.51343
Log Pis Mean                 -0.6824604
Log Pis Std                  3.2576005
Log Pis Max                  10.518961
Log Pis Min                  -6.5467157
Policy mu Mean               -0.06810882
Policy mu Std                0.8166818
Policy mu Max                2.3929021
Policy mu Min                -2.4685738
Policy log std Mean          -0.50172096
Policy log std Std           0.23528688
Policy log std Max           -0.14597297
Policy log std Min           -1.8952065
Z mean eval                  1.9165739
Z variance eval              0.03483177
total_rewards                [7387.95023028 7459.22926039 7579.88171534 7232.9194812  7475.48501255
 7705.07643705 7441.46705759 7774.34606089 7348.25686658 7522.10791506]
total_rewards_mean           7492.67200369349
total_rewards_std            153.70668018569066
total_rewards_max            7774.3460608938785
total_rewards_min            7232.919481199336
Number of train steps total  460000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               143.25593352224678
(Previous) Eval Time (s)     20.7247155290097
Sample Time (s)              6.684343710541725
Epoch Time (s)               170.6649927617982
Total Train Time (s)         19392.188857350964
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:16:50.827707 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #114 | Epoch Duration: 170.7489676475525
2020-01-12 13:16:50.827842 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9169391
Z variance train             0.03489836
KL Divergence                37.321022
KL Loss                      3.7321022
QF Loss                      563.5031
VF Loss                      160.4964
Policy Loss                  -918.4683
Q Predictions Mean           917.9453
Q Predictions Std            1006.29486
Q Predictions Max            3174.943
Q Predictions Min            -299.66113
V Predictions Mean           925.46716
V Predictions Std            1009.45135
V Predictions Max            3177.3132
V Predictions Min            -314.6009
Log Pis Mean                 -0.64203185
Log Pis Std                  3.3479748
Log Pis Max                  12.220511
Log Pis Min                  -8.43899
Policy mu Mean               -0.0069028228
Policy mu Std                0.82823354
Policy mu Max                2.8458598
Policy mu Min                -2.340374
Policy log std Mean          -0.5178518
Policy log std Std           0.2510042
Policy log std Max           -0.13519698
Policy log std Min           -2.045452
Z mean eval                  1.8629748
Z variance eval              0.03024486
total_rewards                [7137.35415643 7319.80341441 7098.84632851 6951.07999592 6974.04739117
 6954.5084906  6920.56350344 7176.1850445  7166.13685626 6848.58734057]
total_rewards_mean           7054.711252181047
total_rewards_std            139.28120157815005
total_rewards_max            7319.803414413312
total_rewards_min            6848.587340569953
Number of train steps total  464000
Number of env steps total    1394000
Number of rollouts total     0
Train Time (s)               143.29337359033525
(Previous) Eval Time (s)     17.866342968773097
Sample Time (s)              6.5710661839693785
Epoch Time (s)               167.73078274307773
Total Train Time (s)         19560.008664316032
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:19:38.648250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #115 | Epoch Duration: 167.8203136920929
2020-01-12 13:19:38.648383 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8643568
Z variance train             0.030050997
KL Divergence                37.71864
KL Loss                      3.771864
QF Loss                      1328.3547
VF Loss                      43.57567
Policy Loss                  -817.87854
Q Predictions Mean           814.14386
Q Predictions Std            903.1618
Q Predictions Max            3054.1433
Q Predictions Min            321.97647
V Predictions Mean           814.9961
V Predictions Std            902.37213
V Predictions Max            3042.5315
V Predictions Min            323.58896
Log Pis Mean                 -0.8339603
Log Pis Std                  3.1897955
Log Pis Max                  15.359024
Log Pis Min                  -7.761678
Policy mu Mean               -0.055720065
Policy mu Std                0.8074393
Policy mu Max                3.8086443
Policy mu Min                -3.295555
Policy log std Mean          -0.512848
Policy log std Std           0.2329146
Policy log std Max           -0.13149789
Policy log std Min           -1.798282
Z mean eval                  1.9113111
Z variance eval              0.027153749
total_rewards                [7541.83986259 7426.40661565 7606.1952651  7671.70428588 7627.94930612
 7522.72441121 7685.28793986 7927.10916377 7737.57390235 7645.39965526]
total_rewards_mean           7639.219040777648
total_rewards_std            128.5809645122482
total_rewards_max            7927.109163769693
total_rewards_min            7426.406615645668
Number of train steps total  468000
Number of env steps total    1406000
Number of rollouts total     0
Train Time (s)               142.12256727507338
(Previous) Eval Time (s)     17.5120849609375
Sample Time (s)              5.517080361023545
Epoch Time (s)               165.15173259703442
Total Train Time (s)         19725.24482318759
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:22:23.886237 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #116 | Epoch Duration: 165.2377495765686
2020-01-12 13:22:23.886400 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9126072
Z variance train             0.02712198
KL Divergence                39.05373
KL Loss                      3.905373
QF Loss                      127.00568
VF Loss                      83.04401
Policy Loss                  -790.92725
Q Predictions Mean           786.67664
Q Predictions Std            871.7051
Q Predictions Max            3136.247
Q Predictions Min            339.35434
V Predictions Mean           785.4231
V Predictions Std            868.9775
V Predictions Max            3123.198
V Predictions Min            337.20648
Log Pis Mean                 -0.9350321
Log Pis Std                  3.3906243
Log Pis Max                  15.53838
Log Pis Min                  -8.186732
Policy mu Mean               0.02482766
Policy mu Std                0.80265313
Policy mu Max                2.6167123
Policy mu Min                -3.2009027
Policy log std Mean          -0.5045402
Policy log std Std           0.24614045
Policy log std Max           -0.08879909
Policy log std Min           -2.183859
Z mean eval                  1.8970438
Z variance eval              0.052502535
total_rewards                [6770.02010606 6853.52541577 6830.70160612 6736.40662681 7035.73180251
 6552.36814977 6575.28448152 7124.27092476 6869.35050328 7054.21467063]
total_rewards_mean           6840.187428724127
total_rewards_std            182.9137719131161
total_rewards_max            7124.270924764412
total_rewards_min            6552.368149771533
Number of train steps total  472000
Number of env steps total    1418000
Number of rollouts total     0
Train Time (s)               143.2499834978953
(Previous) Eval Time (s)     21.006833757273853
Sample Time (s)              6.5547933634370565
Epoch Time (s)               170.8116106186062
Total Train Time (s)         19896.150430815294
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:25:14.793201 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #117 | Epoch Duration: 170.90667986869812
2020-01-12 13:25:14.793330 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8932397
Z variance train             0.052047856
KL Divergence                36.226376
KL Loss                      3.6226375
QF Loss                      414.04187
VF Loss                      160.24458
Policy Loss                  -951.13855
Q Predictions Mean           947.1282
Q Predictions Std            1011.3005
Q Predictions Max            3217.4246
Q Predictions Min            337.20016
V Predictions Mean           943.9464
V Predictions Std            1011.6994
V Predictions Max            3210.2717
V Predictions Min            337.15628
Log Pis Mean                 -0.22658238
Log Pis Std                  3.756109
Log Pis Max                  14.022488
Log Pis Min                  -6.1848235
Policy mu Mean               -0.017377093
Policy mu Std                0.87407607
Policy mu Max                2.7511168
Policy mu Min                -3.2514203
Policy log std Mean          -0.51549596
Policy log std Std           0.25036687
Policy log std Max           -0.11797637
Policy log std Min           -2.1203167
Z mean eval                  1.9187527
Z variance eval              0.059056066
total_rewards                [7485.80680699 7534.54266589 7780.52383127 7557.89506363 7913.54265272
 7519.79943614 7536.54924682 7841.24279322 7358.78559817 7603.69495628]
total_rewards_mean           7613.238305112495
total_rewards_std            165.86052853211416
total_rewards_max            7913.542652715864
total_rewards_min            7358.785598168658
Number of train steps total  476000
Number of env steps total    1430000
Number of rollouts total     0
Train Time (s)               146.01277970103547
(Previous) Eval Time (s)     17.829049854073673
Sample Time (s)              6.592224487569183
Epoch Time (s)               170.43405404267833
Total Train Time (s)         20066.659782813396
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:28:05.304522 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #118 | Epoch Duration: 170.51109743118286
2020-01-12 13:28:05.304642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9201494
Z variance train             0.059111483
KL Divergence                36.800495
KL Loss                      3.6800497
QF Loss                      552.80695
VF Loss                      134.59952
Policy Loss                  -880.40546
Q Predictions Mean           873.9572
Q Predictions Std            954.3509
Q Predictions Max            3245.014
Q Predictions Min            336.1944
V Predictions Mean           882.3362
V Predictions Std            954.6067
V Predictions Max            3235.073
V Predictions Min            348.3477
Log Pis Mean                 -0.5045211
Log Pis Std                  3.6810694
Log Pis Max                  17.057543
Log Pis Min                  -6.40963
Policy mu Mean               0.016252033
Policy mu Std                0.87295073
Policy mu Max                3.5429413
Policy mu Min                -3.6231174
Policy log std Mean          -0.47680545
Policy log std Std           0.23525366
Policy log std Max           0.10615286
Policy log std Min           -1.7438083
Z mean eval                  1.8499699
Z variance eval              0.041574962
total_rewards                [7166.02203731 6914.99813297 7484.81165074 7413.77446169 7244.08055029
 7277.55873161 7074.07979396 7234.95516712 7568.35890609 7165.87680776]
total_rewards_mean           7254.451623954461
total_rewards_std            184.78010153088542
total_rewards_max            7568.358906085889
total_rewards_min            6914.998132974983
Number of train steps total  480000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               143.69306420860812
(Previous) Eval Time (s)     19.218672181945294
Sample Time (s)              5.581175044644624
Epoch Time (s)               168.49291143519804
Total Train Time (s)         20235.22948155366
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:30:53.875921 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #119 | Epoch Duration: 168.5711760520935
2020-01-12 13:30:53.876085 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8507744
Z variance train             0.041518833
KL Divergence                36.75255
KL Loss                      3.6752548
QF Loss                      1290.2565
VF Loss                      70.82139
Policy Loss                  -866.0432
Q Predictions Mean           867.7007
Q Predictions Std            965.5447
Q Predictions Max            3177.8662
Q Predictions Min            330.15775
V Predictions Mean           868.81903
V Predictions Std            961.71216
V Predictions Max            3162.399
V Predictions Min            330.12518
Log Pis Mean                 -0.894922
Log Pis Std                  3.3007689
Log Pis Max                  13.019893
Log Pis Min                  -7.3243947
Policy mu Mean               0.034265686
Policy mu Std                0.8117967
Policy mu Max                3.182914
Policy mu Min                -2.5562327
Policy log std Mean          -0.4892534
Policy log std Std           0.22296138
Policy log std Max           -0.12204522
Policy log std Min           -1.8146917
Z mean eval                  1.8818638
Z variance eval              0.034975022
total_rewards                [6925.2472698  6858.91219428 7275.48051983 6775.40147855 6987.57238017
 7448.98691894 6921.66228328 6706.0192007  6943.06071979 6693.44193637]
total_rewards_mean           6953.578490169895
total_rewards_std            228.4301472721002
total_rewards_max            7448.986918937869
total_rewards_min            6693.44193637239
Number of train steps total  484000
Number of env steps total    1454000
Number of rollouts total     0
Train Time (s)               146.87898308085278
(Previous) Eval Time (s)     18.239474636036903
Sample Time (s)              5.785669642034918
Epoch Time (s)               170.9041273589246
Total Train Time (s)         20406.21143379761
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:33:44.863941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #120 | Epoch Duration: 170.98768711090088
2020-01-12 13:33:44.864266 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8801218
Z variance train             0.0349185
KL Divergence                37.942436
KL Loss                      3.7942436
QF Loss                      204.29294
VF Loss                      57.038223
Policy Loss                  -849.1939
Q Predictions Mean           845.59106
Q Predictions Std            965.028
Q Predictions Max            3183.6848
Q Predictions Min            333.11838
V Predictions Mean           851.19385
V Predictions Std            961.3914
V Predictions Max            3180.1636
V Predictions Min            346.7709
Log Pis Mean                 -0.604059
Log Pis Std                  3.5697298
Log Pis Max                  14.270751
Log Pis Min                  -8.27758
Policy mu Mean               0.019414816
Policy mu Std                0.8540691
Policy mu Max                2.6416867
Policy mu Min                -2.7371924
Policy log std Mean          -0.50075567
Policy log std Std           0.22682416
Policy log std Max           -0.06873512
Policy log std Min           -1.9365776
Z mean eval                  1.8481607
Z variance eval              0.03928976
total_rewards                [7738.27513516 7634.77287432 7616.52393936 7798.25266689 7611.83880956
 7906.00086824 7459.9396118  7570.34073781 7586.06429675 7191.06110608]
total_rewards_mean           7611.307004595483
total_rewards_std            184.47935887125516
total_rewards_max            7906.000868235701
total_rewards_min            7191.06110608216
Number of train steps total  488000
Number of env steps total    1466000
Number of rollouts total     0
Train Time (s)               145.37275499198586
(Previous) Eval Time (s)     17.57405790919438
Sample Time (s)              6.529192911926657
Epoch Time (s)               169.4760058131069
Total Train Time (s)         20575.76966544846
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:36:34.421792 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #121 | Epoch Duration: 169.55728888511658
2020-01-12 13:36:34.421968 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8494484
Z variance train             0.039281584
KL Divergence                37.28359
KL Loss                      3.728359
QF Loss                      134.6774
VF Loss                      40.87175
Policy Loss                  -881.18616
Q Predictions Mean           877.3775
Q Predictions Std            962.695
Q Predictions Max            3079.1685
Q Predictions Min            320.2457
V Predictions Mean           878.4719
V Predictions Std            961.2964
V Predictions Max            3070.5562
V Predictions Min            323.7233
Log Pis Mean                 -0.47622082
Log Pis Std                  3.5240083
Log Pis Max                  11.546876
Log Pis Min                  -6.755243
Policy mu Mean               0.081701614
Policy mu Std                0.8215505
Policy mu Max                2.4696395
Policy mu Min                -2.436808
Policy log std Mean          -0.5211946
Policy log std Std           0.24995562
Policy log std Max           -0.03588915
Policy log std Min           -2.1510968
Z mean eval                  1.8335276
Z variance eval              0.029113874
total_rewards                [6818.54030908 7301.84926138 6811.34581638 7043.46345132 7380.23103164
 7058.49506673 7224.01447336 7280.98989087 7051.34181705 7344.64222165]
total_rewards_mean           7131.491333945436
total_rewards_std            196.76628675222818
total_rewards_max            7380.231031644503
total_rewards_min            6811.345816376181
Number of train steps total  492000
Number of env steps total    1478000
Number of rollouts total     0
Train Time (s)               146.31620759889483
(Previous) Eval Time (s)     21.24554680706933
Sample Time (s)              6.6221495247446
Epoch Time (s)               174.18390393070877
Total Train Time (s)         20750.058508296497
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:39:28.711457 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #122 | Epoch Duration: 174.28935885429382
2020-01-12 13:39:28.711604 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8367221
Z variance train             0.029151142
KL Divergence                37.81427
KL Loss                      3.7814271
QF Loss                      165.36618
VF Loss                      110.80527
Policy Loss                  -836.0016
Q Predictions Mean           830.0836
Q Predictions Std            935.9544
Q Predictions Max            3156.3386
Q Predictions Min            342.55045
V Predictions Mean           830.6066
V Predictions Std            930.6443
V Predictions Max            3125.4104
V Predictions Min            347.80884
Log Pis Mean                 -0.70839316
Log Pis Std                  3.050689
Log Pis Max                  10.095632
Log Pis Min                  -7.283415
Policy mu Mean               -0.009277181
Policy mu Std                0.79680413
Policy mu Max                2.5817778
Policy mu Min                -2.573068
Policy log std Mean          -0.50226146
Policy log std Std           0.25192925
Policy log std Max           -0.07432011
Policy log std Min           -1.7558663
Z mean eval                  1.8661534
Z variance eval              0.03001014
total_rewards                [7511.9200587  7757.97548768 7564.54341975 7816.57207708 7501.55720857
 7598.05298486 7670.92197814 7388.76429501 7783.13872595 7746.39036047]
total_rewards_mean           7633.983659621799
total_rewards_std            135.51428998122637
total_rewards_max            7816.572077081103
total_rewards_min            7388.7642950086865
Number of train steps total  496000
Number of env steps total    1490000
Number of rollouts total     0
Train Time (s)               144.69395993603393
(Previous) Eval Time (s)     18.111950328107923
Sample Time (s)              6.529921711422503
Epoch Time (s)               169.33583197556436
Total Train Time (s)         20919.647980194073
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:42:18.301764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #123 | Epoch Duration: 169.5900604724884
2020-01-12 13:42:18.301900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8668585
Z variance train             0.030100679
KL Divergence                38.71598
KL Loss                      3.871598
QF Loss                      123.925125
VF Loss                      71.89647
Policy Loss                  -822.16125
Q Predictions Mean           817.5211
Q Predictions Std            927.0445
Q Predictions Max            3347.0083
Q Predictions Min            333.78275
V Predictions Mean           824.85846
V Predictions Std            930.52094
V Predictions Max            3355.614
V Predictions Min            349.46088
Log Pis Mean                 -0.7038152
Log Pis Std                  3.5019002
Log Pis Max                  13.319337
Log Pis Min                  -6.827503
Policy mu Mean               -0.030598769
Policy mu Std                0.8222927
Policy mu Max                2.509315
Policy mu Min                -2.5011435
Policy log std Mean          -0.48704568
Policy log std Std           0.23211601
Policy log std Max           -0.017534494
Policy log std Min           -2.2193139
Z mean eval                  1.8611753
Z variance eval              0.042956673
total_rewards                [7158.5776788  7441.98159803 7610.96184775 7603.48293559 7465.75990392
 7448.14934091 7425.04757104 7328.79609936 7547.71176119 7761.80167228]
total_rewards_mean           7479.227040884897
total_rewards_std            157.55871054396033
total_rewards_max            7761.8016722779485
total_rewards_min            7158.577678798395
Number of train steps total  500000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               144.9111647461541
(Previous) Eval Time (s)     20.907197867985815
Sample Time (s)              6.4997995514422655
Epoch Time (s)               172.31816216558218
Total Train Time (s)         21092.048303894233
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:45:10.703282 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #124 | Epoch Duration: 172.40126848220825
2020-01-12 13:45:10.703413 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8614782
Z variance train             0.043078624
KL Divergence                38.983948
KL Loss                      3.8983948
QF Loss                      132.79178
VF Loss                      27.679815
Policy Loss                  -837.3461
Q Predictions Mean           834.04736
Q Predictions Std            924.0828
Q Predictions Max            3197.9822
Q Predictions Min            343.19736
V Predictions Mean           838.538
V Predictions Std            923.52747
V Predictions Max            3189.5955
V Predictions Min            348.5128
Log Pis Mean                 -0.8053962
Log Pis Std                  3.5824857
Log Pis Max                  14.84872
Log Pis Min                  -7.847331
Policy mu Mean               -0.0021737823
Policy mu Std                0.79881424
Policy mu Max                2.5370014
Policy mu Min                -2.7086208
Policy log std Mean          -0.5094947
Policy log std Std           0.25337514
Policy log std Max           -0.1044265
Policy log std Min           -2.1129277
Z mean eval                  1.8212658
Z variance eval              0.117605925
total_rewards                [7274.54397431 7507.9341275  7550.00978697 6708.83347136 7222.65774553
 7564.12971838 7780.65193232 7428.45137594 7646.75578639 7645.93901233]
total_rewards_mean           7432.990693103985
total_rewards_std            290.2047326280812
total_rewards_max            7780.651932322306
total_rewards_min            6708.83347136245
Number of train steps total  504000
Number of env steps total    1514000
Number of rollouts total     0
Train Time (s)               144.13820491638035
(Previous) Eval Time (s)     20.630569559056312
Sample Time (s)              6.479814467951655
Epoch Time (s)               171.2485889433883
Total Train Time (s)         21263.37870433787
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:48:02.035144 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #125 | Epoch Duration: 171.3316352367401
2020-01-12 13:48:02.035279 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8215317
Z variance train             0.11672181
KL Divergence                36.655712
KL Loss                      3.6655712
QF Loss                      149.31471
VF Loss                      57.795654
Policy Loss                  -790.8566
Q Predictions Mean           788.6205
Q Predictions Std            888.573
Q Predictions Max            3107.344
Q Predictions Min            336.46533
V Predictions Mean           789.4405
V Predictions Std            887.24396
V Predictions Max            3087.2327
V Predictions Min            334.96527
Log Pis Mean                 -0.9328411
Log Pis Std                  3.084996
Log Pis Max                  15.2427635
Log Pis Min                  -5.618156
Policy mu Mean               0.011956084
Policy mu Std                0.81133354
Policy mu Max                2.6818419
Policy mu Min                -2.7882009
Policy log std Mean          -0.48226514
Policy log std Std           0.22172473
Policy log std Max           -0.11087811
Policy log std Min           -1.7793108
Z mean eval                  1.8387039
Z variance eval              0.040755693
total_rewards                [7486.71964412 7554.35233355 7611.01301615 7596.06526303 7757.60126009
 7930.31481413 7651.93507861 8088.65644543 7723.9233414  7720.25936113]
total_rewards_mean           7712.0840557641595
total_rewards_std            171.66021022549253
total_rewards_max            8088.656445433169
total_rewards_min            7486.719644120486
Number of train steps total  508000
Number of env steps total    1526000
Number of rollouts total     0
Train Time (s)               144.77675651712343
(Previous) Eval Time (s)     21.065692697651684
Sample Time (s)              6.5065997168421745
Epoch Time (s)               172.3490489316173
Total Train Time (s)         21435.882258300204
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:50:54.541644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #126 | Epoch Duration: 172.50624990463257
2020-01-12 13:50:54.541836 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8380674
Z variance train             0.040642887
KL Divergence                38.916622
KL Loss                      3.8916624
QF Loss                      194.88496
VF Loss                      87.83928
Policy Loss                  -974.5589
Q Predictions Mean           971.0128
Q Predictions Std            1050.6014
Q Predictions Max            3262.919
Q Predictions Min            339.52295
V Predictions Mean           968.8373
V Predictions Std            1046.3478
V Predictions Max            3262.0293
V Predictions Min            354.64798
Log Pis Mean                 -0.57238156
Log Pis Std                  3.2350988
Log Pis Max                  10.612283
Log Pis Min                  -6.500764
Policy mu Mean               0.012811299
Policy mu Std                0.84010345
Policy mu Max                2.5021422
Policy mu Min                -2.7318747
Policy log std Mean          -0.509458
Policy log std Std           0.24321648
Policy log std Max           0.03963986
Policy log std Min           -2.086578
Z mean eval                  1.8115892
Z variance eval              0.03108282
total_rewards                [7191.94307909 7615.67641713 7547.94582077 7373.66623268 7586.27329538
 7623.90373134 7477.22216229 7591.17425389 7499.34255099 7716.16888631]
total_rewards_mean           7522.331642987978
total_rewards_std            141.38893519462454
total_rewards_max            7716.168886305765
total_rewards_min            7191.943079089541
Number of train steps total  512000
Number of env steps total    1538000
Number of rollouts total     0
Train Time (s)               144.1370548917912
(Previous) Eval Time (s)     20.85098352096975
Sample Time (s)              6.478341998066753
Epoch Time (s)               171.4663804108277
Total Train Time (s)         21607.430835161358
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:53:46.092195 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #127 | Epoch Duration: 171.55021810531616
2020-01-12 13:53:46.092402 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8122171
Z variance train             0.03117317
KL Divergence                38.859158
KL Loss                      3.8859158
QF Loss                      233.37181
VF Loss                      95.50447
Policy Loss                  -797.2854
Q Predictions Mean           791.7494
Q Predictions Std            899.7598
Q Predictions Max            3268.2913
Q Predictions Min            366.93994
V Predictions Mean           800.39795
V Predictions Std            900.7093
V Predictions Max            3257.6628
V Predictions Min            381.7176
Log Pis Mean                 -0.7087847
Log Pis Std                  3.3647661
Log Pis Max                  13.444852
Log Pis Min                  -6.998047
Policy mu Mean               -0.064943895
Policy mu Std                0.81896716
Policy mu Max                2.3753378
Policy mu Min                -3.73557
Policy log std Mean          -0.48617145
Policy log std Std           0.24131653
Policy log std Max           -0.056463778
Policy log std Min           -2.247407
Z mean eval                  1.8235004
Z variance eval              0.023325099
total_rewards                [7751.78022267 7798.52808675 7968.35544488 7968.19231113 7764.52487425
 7683.84035325 7748.49370311 8035.14914481 7803.66776556 7430.69401936]
total_rewards_mean           7795.322592575672
total_rewards_std            163.65838452198463
total_rewards_max            8035.149144807296
total_rewards_min            7430.694019356463
Number of train steps total  516000
Number of env steps total    1550000
Number of rollouts total     0
Train Time (s)               143.20219663484022
(Previous) Eval Time (s)     20.714538524858654
Sample Time (s)              6.450128743890673
Epoch Time (s)               170.36686390358955
Total Train Time (s)         21777.875229611527
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:56:36.539576 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #128 | Epoch Duration: 170.4470546245575
2020-01-12 13:56:36.539771 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #128 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8205944
Z variance train             0.023453532
KL Divergence                40.743225
KL Loss                      4.0743227
QF Loss                      160.72658
VF Loss                      131.05241
Policy Loss                  -911.08704
Q Predictions Mean           911.241
Q Predictions Std            992.3962
Q Predictions Max            3220.5186
Q Predictions Min            365.47995
V Predictions Mean           920.5656
V Predictions Std            992.7454
V Predictions Max            3212.403
V Predictions Min            366.4041
Log Pis Mean                 -0.6439873
Log Pis Std                  3.2368991
Log Pis Max                  9.578053
Log Pis Min                  -11.37783
Policy mu Mean               -0.0017846028
Policy mu Std                0.8324258
Policy mu Max                2.6144614
Policy mu Min                -2.4692621
Policy log std Mean          -0.51133484
Policy log std Std           0.22946976
Policy log std Max           -0.13155514
Policy log std Min           -2.0583744
Z mean eval                  1.8370826
Z variance eval              0.030623298
total_rewards                [7640.97996849 7889.21971027 7649.08786514 7715.28459926 7597.4073414
 7639.83981536 7802.0107001  7850.27472552 7738.4543739  7647.586168  ]
total_rewards_mean           7717.01452674545
total_rewards_std            95.17211369646141
total_rewards_max            7889.219710271635
total_rewards_min            7597.407341404327
Number of train steps total  520000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               143.66975891590118
(Previous) Eval Time (s)     20.85225556930527
Sample Time (s)              6.5533627942204475
Epoch Time (s)               171.0753772794269
Total Train Time (s)         21949.042452285532
Epoch                        129
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:59:27.708551 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #129 | Epoch Duration: 171.1686396598816
2020-01-12 13:59:27.708696 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8380425
Z variance train             0.030589228
KL Divergence                39.637558
KL Loss                      3.9637558
QF Loss                      93.968155
VF Loss                      88.51391
Policy Loss                  -747.33936
Q Predictions Mean           747.517
Q Predictions Std            846.2245
Q Predictions Max            3216.586
Q Predictions Min            359.0986
V Predictions Mean           752.58655
V Predictions Std            848.822
V Predictions Max            3235.0527
V Predictions Min            362.4839
Log Pis Mean                 -0.9413626
Log Pis Std                  2.9979014
Log Pis Max                  10.618308
Log Pis Min                  -9.213745
Policy mu Mean               0.015732126
Policy mu Std                0.7790319
Policy mu Max                2.5679026
Policy mu Min                -2.3806226
Policy log std Mean          -0.4887898
Policy log std Std           0.23163384
Policy log std Max           -0.122729495
Policy log std Min           -2.1167278
Z mean eval                  1.8479391
Z variance eval              0.039434493
total_rewards                [7518.24289452 7722.2800696  7487.77548143 7429.12490418 7534.34898487
 7595.98867163 7541.69724786 7842.08173045 7541.76695474 7555.94746377]
total_rewards_mean           7576.925440305493
total_rewards_std            113.91468859699445
total_rewards_max            7842.081730447569
total_rewards_min            7429.124904177288
Number of train steps total  524000
Number of env steps total    1574000
Number of rollouts total     0
Train Time (s)               144.15348891029134
(Previous) Eval Time (s)     21.195497625041753
Sample Time (s)              6.63826256012544
Epoch Time (s)               171.98724909545854
Total Train Time (s)         22121.121800510213
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:02:19.791947 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #130 | Epoch Duration: 172.08315181732178
2020-01-12 14:02:19.792084 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8479557
Z variance train             0.03931167
KL Divergence                40.496727
KL Loss                      4.0496726
QF Loss                      272.22638
VF Loss                      47.3463
Policy Loss                  -856.77423
Q Predictions Mean           854.355
Q Predictions Std            953.03064
Q Predictions Max            3343.5535
Q Predictions Min            353.79312
V Predictions Mean           854.06635
V Predictions Std            949.42175
V Predictions Max            3334.4053
V Predictions Min            363.1797
Log Pis Mean                 -0.90828675
Log Pis Std                  2.9493513
Log Pis Max                  7.690044
Log Pis Min                  -9.09857
Policy mu Mean               0.02511003
Policy mu Std                0.79105455
Policy mu Max                2.5866976
Policy mu Min                -2.3657818
Policy log std Mean          -0.4940451
Policy log std Std           0.2441639
Policy log std Max           -0.022918224
Policy log std Min           -2.1897302
Z mean eval                  1.8197031
Z variance eval              0.030518552
total_rewards                [7397.96665046 7649.09541633 7915.0043156  7765.18771479 7627.25943077
 7827.56519487 7710.38332706 7969.31939292 7694.64637516 7800.79599882]
total_rewards_mean           7735.722381678136
total_rewards_std            153.59822334520595
total_rewards_max            7969.319392924116
total_rewards_min            7397.966650457985
Number of train steps total  528000
Number of env steps total    1586000
Number of rollouts total     0
Train Time (s)               145.58651711791754
(Previous) Eval Time (s)     20.872083269059658
Sample Time (s)              6.608593183103949
Epoch Time (s)               173.06719357008114
Total Train Time (s)         22294.277156444732
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:05:12.949026 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #131 | Epoch Duration: 173.15684413909912
2020-01-12 14:05:12.949170 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8235648
Z variance train             0.0304652
KL Divergence                41.281204
KL Loss                      4.1281204
QF Loss                      127.10039
VF Loss                      80.68078
Policy Loss                  -754.76166
Q Predictions Mean           750.10455
Q Predictions Std            864.94574
Q Predictions Max            3372.2593
Q Predictions Min            372.61035
V Predictions Mean           749.95746
V Predictions Std            858.0941
V Predictions Max            3339.909
V Predictions Min            378.69513
Log Pis Mean                 -0.81891453
Log Pis Std                  3.7001386
Log Pis Max                  17.78699
Log Pis Min                  -8.732503
Policy mu Mean               0.018080527
Policy mu Std                0.79340297
Policy mu Max                2.7478158
Policy mu Min                -3.406079
Policy log std Mean          -0.48622373
Policy log std Std           0.24465686
Policy log std Max           -0.05609697
Policy log std Min           -2.1441226
Z mean eval                  1.757605
Z variance eval              0.037237816
total_rewards                [7881.07257994 7989.81708583 7748.93395641 7991.94951057 8036.47424324
 7992.47590822 7937.53559505 7796.07200675 7974.62970543 7720.89631594]
total_rewards_mean           7906.985690737131
total_rewards_std            107.81822820191258
total_rewards_max            8036.474243237045
total_rewards_min            7720.896315935052
Number of train steps total  532000
Number of env steps total    1598000
Number of rollouts total     0
Train Time (s)               145.1648423038423
(Previous) Eval Time (s)     17.34565239585936
Sample Time (s)              6.628798060119152
Epoch Time (s)               169.13929275982082
Total Train Time (s)         22463.5015640771
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:08:02.190374 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #132 | Epoch Duration: 169.24107193946838
2020-01-12 14:08:02.190614 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #132 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7576202
Z variance train             0.03711044
KL Divergence                39.628704
KL Loss                      3.9628704
QF Loss                      133.92921
VF Loss                      35.76013
Policy Loss                  -974.7502
Q Predictions Mean           973.4297
Q Predictions Std            1038.7949
Q Predictions Max            3383.1897
Q Predictions Min            348.99744
V Predictions Mean           972.7655
V Predictions Std            1034.924
V Predictions Max            3357.0515
V Predictions Min            363.0363
Log Pis Mean                 -0.3085651
Log Pis Std                  3.3882356
Log Pis Max                  11.054456
Log Pis Min                  -7.7440033
Policy mu Mean               0.008387041
Policy mu Std                0.8577038
Policy mu Max                2.9050498
Policy mu Min                -2.5795345
Policy log std Mean          -0.49943212
Policy log std Std           0.24152018
Policy log std Max           -0.02792567
Policy log std Min           -1.9152899
Z mean eval                  1.7823569
Z variance eval              0.037143327
total_rewards                [7567.33352302 7811.53495751 7297.08661684 7600.50484106 7771.3780742
 7626.71215382 7756.75518457 7923.49619689 7722.24997083 7699.87773602]
total_rewards_mean           7677.692925476066
total_rewards_std            161.68969699172405
total_rewards_max            7923.496196892963
total_rewards_min            7297.0866168355315
Number of train steps total  536000
Number of env steps total    1610000
Number of rollouts total     0
Train Time (s)               144.92839886480942
(Previous) Eval Time (s)     20.740257733967155
Sample Time (s)              6.547158513683826
Epoch Time (s)               172.2158151124604
Total Train Time (s)         22635.814114558045
Epoch                        133
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:10:54.490164 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #133 | Epoch Duration: 172.29934668540955
2020-01-12 14:10:54.490313 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7825352
Z variance train             0.03731131
KL Divergence                40.43791
KL Loss                      4.043791
QF Loss                      1477.6377
VF Loss                      119.07679
Policy Loss                  -904.93884
Q Predictions Mean           901.77795
Q Predictions Std            947.6556
Q Predictions Max            3289.3762
Q Predictions Min            376.32318
V Predictions Mean           898.86743
V Predictions Std            945.36224
V Predictions Max            3270.4958
V Predictions Min            371.70676
Log Pis Mean                 -0.44075337
Log Pis Std                  3.5242155
Log Pis Max                  18.338017
Log Pis Min                  -7.886421
Policy mu Mean               0.04639278
Policy mu Std                0.8351306
Policy mu Max                2.9326546
Policy mu Min                -3.1506448
Policy log std Mean          -0.5185037
Policy log std Std           0.22951162
Policy log std Max           -0.12466842
Policy log std Min           -1.7184132
Z mean eval                  1.7542607
Z variance eval              0.020346548
total_rewards                [7944.3257592  7951.87777148 7855.64003529 7914.91240557 7987.81542741
 8093.280855   7807.75311511 7827.78479155 7732.1812168  8253.40491732]
total_rewards_mean           7936.897629471519
total_rewards_std            143.2074207863683
total_rewards_max            8253.404917315227
total_rewards_min            7732.1812168032575
Number of train steps total  540000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               145.91817820305005
(Previous) Eval Time (s)     17.87191461166367
Sample Time (s)              6.513427016790956
Epoch Time (s)               170.30351983150467
Total Train Time (s)         22806.203911382705
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:13:44.882971 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #134 | Epoch Duration: 170.3925404548645
2020-01-12 14:13:44.883176 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7522285
Z variance train             0.020341175
KL Divergence                41.112865
KL Loss                      4.1112866
QF Loss                      94.04376
VF Loss                      36.160748
Policy Loss                  -858.77277
Q Predictions Mean           854.3943
Q Predictions Std            947.5762
Q Predictions Max            3205.154
Q Predictions Min            326.87268
V Predictions Mean           857.1903
V Predictions Std            947.2093
V Predictions Max            3216.1804
V Predictions Min            342.64603
Log Pis Mean                 -0.730898
Log Pis Std                  3.1874325
Log Pis Max                  10.018614
Log Pis Min                  -6.873829
Policy mu Mean               0.0051218886
Policy mu Std                0.8281799
Policy mu Max                2.444793
Policy mu Min                -2.4050725
Policy log std Mean          -0.5197401
Policy log std Std           0.24925742
Policy log std Max           0.027904749
Policy log std Min           -1.8916998
Z mean eval                  1.7438694
Z variance eval              0.061626665
total_rewards                [7117.68505309 7603.99170577 7584.44224309 7338.99471001 7264.31043503
 7223.47613799 7249.63332826 7418.92431003 7387.40662598 6679.95566024]
total_rewards_mean           7286.882020950361
total_rewards_std            249.45163890752735
total_rewards_max            7603.991705768416
total_rewards_min            6679.9556602420735
Number of train steps total  544000
Number of env steps total    1634000
Number of rollouts total     0
Train Time (s)               145.06978103285655
(Previous) Eval Time (s)     21.062059884890914
Sample Time (s)              6.496819732710719
Epoch Time (s)               172.6286606504582
Total Train Time (s)         22978.912667525932
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:16:37.593020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #135 | Epoch Duration: 172.7096869945526
2020-01-12 14:16:37.593200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7433312
Z variance train             0.061525095
KL Divergence                39.24685
KL Loss                      3.924685
QF Loss                      114.83
VF Loss                      28.056816
Policy Loss                  -825.9537
Q Predictions Mean           822.30676
Q Predictions Std            914.09955
Q Predictions Max            3260.5317
Q Predictions Min            352.80777
V Predictions Mean           826.3916
V Predictions Std            914.51337
V Predictions Max            3261.9443
V Predictions Min            352.82248
Log Pis Mean                 -1.2569757
Log Pis Std                  3.0577667
Log Pis Max                  15.1072235
Log Pis Min                  -6.422102
Policy mu Mean               0.0202483
Policy mu Std                0.7696679
Policy mu Max                2.6683629
Policy mu Min                -2.4379058
Policy log std Mean          -0.48846373
Policy log std Std           0.23951235
Policy log std Max           -0.053191185
Policy log std Min           -1.9285353
Z mean eval                  1.728949
Z variance eval              0.027616441
total_rewards                [7612.87997847 7828.63250911 7691.70914418 7700.16060753 7952.91692192
 7657.40032278 7812.63787619 7754.90720842 7612.7274899  7685.72470905]
total_rewards_mean           7730.969676755973
total_rewards_std            101.94010270033357
total_rewards_max            7952.91692191959
total_rewards_min            7612.727489899622
Number of train steps total  548000
Number of env steps total    1646000
Number of rollouts total     0
Train Time (s)               144.42203078093007
(Previous) Eval Time (s)     20.776827164459974
Sample Time (s)              6.510994164273143
Epoch Time (s)               171.7098521096632
Total Train Time (s)         23150.85191868851
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:19:29.543911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #136 | Epoch Duration: 171.95056653022766
2020-01-12 14:19:29.544093 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7306238
Z variance train             0.027589971
KL Divergence                42.04811
KL Loss                      4.204811
QF Loss                      169.19385
VF Loss                      89.48551
Policy Loss                  -928.0183
Q Predictions Mean           925.94775
Q Predictions Std            996.8748
Q Predictions Max            3348.1921
Q Predictions Min            382.79813
V Predictions Mean           929.59546
V Predictions Std            998.4992
V Predictions Max            3351.2595
V Predictions Min            382.09912
Log Pis Mean                 -0.5398996
Log Pis Std                  3.2918835
Log Pis Max                  13.204885
Log Pis Min                  -7.302284
Policy mu Mean               -0.017130135
Policy mu Std                0.8295032
Policy mu Max                2.6592708
Policy mu Min                -2.7927608
Policy log std Mean          -0.5225695
Policy log std Std           0.2628406
Policy log std Max           -0.04151994
Policy log std Min           -2.1002548
Z mean eval                  1.6812592
Z variance eval              0.025864538
total_rewards                [7377.15145713 7470.03544018 7664.36614661 7508.59010866 7525.81416817
 7584.33098895 7635.74159948 7458.48776678 7437.95551676 7449.2646189 ]
total_rewards_mean           7511.173781162911
total_rewards_std            87.28221852058482
total_rewards_max            7664.366146605943
total_rewards_min            7377.151457132921
Number of train steps total  552000
Number of env steps total    1658000
Number of rollouts total     0
Train Time (s)               143.812108641956
(Previous) Eval Time (s)     17.4887810270302
Sample Time (s)              5.673709979280829
Epoch Time (s)               166.97459964826703
Total Train Time (s)         23317.917296231724
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:22:16.604091 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #137 | Epoch Duration: 167.05982613563538
2020-01-12 14:22:16.604378 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6811397
Z variance train             0.025929365
KL Divergence                41.697178
KL Loss                      4.169718
QF Loss                      1767.4293
VF Loss                      144.35196
Policy Loss                  -876.65405
Q Predictions Mean           879.4187
Q Predictions Std            960.37305
Q Predictions Max            3443.4258
Q Predictions Min            387.0552
V Predictions Mean           866.4966
V Predictions Std            954.21
V Predictions Max            3393.4272
V Predictions Min            382.9134
Log Pis Mean                 -0.8673366
Log Pis Std                  3.1024299
Log Pis Max                  12.520013
Log Pis Min                  -6.6202993
Policy mu Mean               0.0067869616
Policy mu Std                0.7825978
Policy mu Max                2.4569364
Policy mu Min                -2.6164176
Policy log std Mean          -0.50242925
Policy log std Std           0.24937904
Policy log std Max           -0.12986861
Policy log std Min           -1.8865056
Z mean eval                  1.7189758
Z variance eval              0.037884094
total_rewards                [7655.99150435 8070.7595127  2245.05594351 1965.09104499 3555.83140443
 8313.42508517 8020.45867633 7955.39379837 8035.1032499  7967.98008008]
total_rewards_mean           6378.509029982279
total_rewards_std            2514.439537110721
total_rewards_max            8313.425085166607
total_rewards_min            1965.091044985128
Number of train steps total  556000
Number of env steps total    1670000
Number of rollouts total     0
Train Time (s)               144.8537277309224
(Previous) Eval Time (s)     20.79012955306098
Sample Time (s)              6.458876014687121
Epoch Time (s)               172.1027332986705
Total Train Time (s)         23490.1010904368
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:25:08.787562 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #138 | Epoch Duration: 172.18297958374023
2020-01-12 14:25:08.787697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7218851
Z variance train             0.037715405
KL Divergence                42.475815
KL Loss                      4.2475815
QF Loss                      125.01979
VF Loss                      221.5585
Policy Loss                  -835.0908
Q Predictions Mean           831.423
Q Predictions Std            928.86206
Q Predictions Max            3451.9705
Q Predictions Min            380.3439
V Predictions Mean           821.80566
V Predictions Std            923.9096
V Predictions Max            3402.9802
V Predictions Min            385.3197
Log Pis Mean                 -0.7199174
Log Pis Std                  3.513939
Log Pis Max                  12.84791
Log Pis Min                  -7.2545214
Policy mu Mean               0.037523832
Policy mu Std                0.8159522
Policy mu Max                2.5374956
Policy mu Min                -2.8244612
Policy log std Mean          -0.49065864
Policy log std Std           0.23238008
Policy log std Max           -0.105009764
Policy log std Min           -1.9795783
Z mean eval                  1.705257
Z variance eval              0.017931748
total_rewards                [7729.36060135 7923.53621912 7807.07155965 7793.84426823 7942.65444242
 7870.73379172 7779.94549926 8228.05877882 7929.44083617 8183.05282024]
total_rewards_mean           7918.769881696554
total_rewards_std            158.66651430012783
total_rewards_max            8228.058778816141
total_rewards_min            7729.360601348091
Number of train steps total  560000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               144.2350407759659
(Previous) Eval Time (s)     20.72712330520153
Sample Time (s)              6.496301501523703
Epoch Time (s)               171.45846558269113
Total Train Time (s)         23661.656405152287
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:28:00.346687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #139 | Epoch Duration: 171.5588402748108
2020-01-12 14:28:00.346923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7078613
Z variance train             0.017957583
KL Divergence                44.437557
KL Loss                      4.4437556
QF Loss                      154.91199
VF Loss                      68.56824
Policy Loss                  -962.73395
Q Predictions Mean           960.1465
Q Predictions Std            1021.94604
Q Predictions Max            3434.551
Q Predictions Min            392.46188
V Predictions Mean           958.04315
V Predictions Std            1020.32684
V Predictions Max            3418.9783
V Predictions Min            385.89203
Log Pis Mean                 -0.27193367
Log Pis Std                  3.2791479
Log Pis Max                  12.361637
Log Pis Min                  -6.551708
Policy mu Mean               0.0127997175
Policy mu Std                0.8657557
Policy mu Max                2.821607
Policy mu Min                -3.3552132
Policy log std Mean          -0.50450176
Policy log std Std           0.23145266
Policy log std Max           -0.09376097
Policy log std Min           -1.8115304
Z mean eval                  1.6705122
Z variance eval              0.026523083
total_rewards                [7599.08982906 7823.06249443 7565.48927858 7825.88369551 7591.76505827
 7632.69361859 7555.71878536 7755.46039005 7562.97507837 7974.6254303 ]
total_rewards_mean           7688.676365852504
total_rewards_std            138.67864423690102
total_rewards_max            7974.6254303041005
total_rewards_min            7555.718785360357
Number of train steps total  564000
Number of env steps total    1694000
Number of rollouts total     0
Train Time (s)               144.3819398516789
(Previous) Eval Time (s)     17.3527836878784
Sample Time (s)              6.581952096428722
Epoch Time (s)               168.31667563598603
Total Train Time (s)         23830.049204952084
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:30:48.743985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #140 | Epoch Duration: 168.39689111709595
2020-01-12 14:30:48.744156 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #140 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6724755
Z variance train             0.026457597
KL Divergence                42.818604
KL Loss                      4.2818604
QF Loss                      212.34251
VF Loss                      135.14429
Policy Loss                  -939.9152
Q Predictions Mean           936.70435
Q Predictions Std            1014.29156
Q Predictions Max            3321.5918
Q Predictions Min            370.92145
V Predictions Mean           937.4798
V Predictions Std            1013.2774
V Predictions Max            3303.4026
V Predictions Min            374.76117
Log Pis Mean                 -0.6871144
Log Pis Std                  3.2557454
Log Pis Max                  13.116561
Log Pis Min                  -5.780411
Policy mu Mean               -0.07012439
Policy mu Std                0.83426267
Policy mu Max                3.516344
Policy mu Min                -2.5265033
Policy log std Mean          -0.51904243
Policy log std Std           0.26120734
Policy log std Max           -0.09599924
Policy log std Min           -2.169716
Z mean eval                  1.6975071
Z variance eval              0.042786114
total_rewards                [7822.48092932 7963.63732946 7960.46507618 8081.4886635  7926.4575578
 7718.57177261 7926.617254   7555.4719304  8040.40341715 8069.8527669 ]
total_rewards_mean           7906.54466973322
total_rewards_std            157.42048926383583
total_rewards_max            8081.488663503195
total_rewards_min            7555.471930399506
Number of train steps total  568000
Number of env steps total    1706000
Number of rollouts total     0
Train Time (s)               143.56427943194285
(Previous) Eval Time (s)     17.456223923247308
Sample Time (s)              5.601957100909203
Epoch Time (s)               166.62246045609936
Total Train Time (s)         23996.752792484593
Epoch                        141
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:33:35.449086 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #141 | Epoch Duration: 166.70479369163513
2020-01-12 14:33:35.449264 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7005589
Z variance train             0.04286251
KL Divergence                40.545593
KL Loss                      4.054559
QF Loss                      115.20897
VF Loss                      64.20511
Policy Loss                  -873.6405
Q Predictions Mean           871.32886
Q Predictions Std            969.471
Q Predictions Max            3401.6274
Q Predictions Min            395.1911
V Predictions Mean           871.6726
V Predictions Std            966.0788
V Predictions Max            3389.8289
V Predictions Min            397.75433
Log Pis Mean                 -0.8109594
Log Pis Std                  3.3118546
Log Pis Max                  12.546728
Log Pis Min                  -8.114454
Policy mu Mean               0.020435216
Policy mu Std                0.8312705
Policy mu Max                2.6438537
Policy mu Min                -2.7610672
Policy log std Mean          -0.48820606
Policy log std Std           0.23731178
Policy log std Max           -0.057269335
Policy log std Min           -1.8393135
Z mean eval                  1.6875916
Z variance eval              0.06020399
total_rewards                [7761.20754889 8237.20550767 8100.50827142 8114.43361214 8149.25941424
 8261.25916381 7898.71588142 7889.82849439 8199.70635419 8049.27487356]
total_rewards_mean           8066.139912174387
total_rewards_std            157.47443277164214
total_rewards_max            8261.259163808392
total_rewards_min            7761.207548891672
Number of train steps total  572000
Number of env steps total    1718000
Number of rollouts total     0
Train Time (s)               144.45822208793834
(Previous) Eval Time (s)     20.775319639593363
Sample Time (s)              6.494182187598199
Epoch Time (s)               171.7277239151299
Total Train Time (s)         24168.55801911885
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:36:27.254923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #142 | Epoch Duration: 171.8055284023285
2020-01-12 14:36:27.255064 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #142 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6896021
Z variance train             0.060075562
KL Divergence                40.33764
KL Loss                      4.033764
QF Loss                      189.56665
VF Loss                      130.34213
Policy Loss                  -902.52246
Q Predictions Mean           901.5034
Q Predictions Std            989.2753
Q Predictions Max            3351.882
Q Predictions Min            -37.8254
V Predictions Mean           895.41144
V Predictions Std            982.9141
V Predictions Max            3335.178
V Predictions Min            -214.0032
Log Pis Mean                 -0.8451228
Log Pis Std                  3.2761903
Log Pis Max                  12.555388
Log Pis Min                  -8.651445
Policy mu Mean               -0.036097694
Policy mu Std                0.810494
Policy mu Max                2.594103
Policy mu Min                -3.5895154
Policy log std Mean          -0.4847399
Policy log std Std           0.2377035
Policy log std Max           1.291451
Policy log std Min           -1.7998374
Z mean eval                  1.7047834
Z variance eval              0.030617535
total_rewards                [8066.2851058  8135.31650548 8126.91911162 8042.00357605 8213.3063808
 8138.23561531 8019.70712105 7888.50909691 7792.18019781 8210.1312531 ]
total_rewards_mean           8063.259396392452
total_rewards_std            128.5811121867668
total_rewards_max            8213.306380795511
total_rewards_min            7792.18019781153
Number of train steps total  576000
Number of env steps total    1730000
Number of rollouts total     0
Train Time (s)               145.63712676102296
(Previous) Eval Time (s)     21.089483039919287
Sample Time (s)              6.348131220322102
Epoch Time (s)               173.07474102126434
Total Train Time (s)         24341.711929821875
Epoch                        143
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:39:20.410298 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #143 | Epoch Duration: 173.15513491630554
2020-01-12 14:39:20.410439 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.704064
Z variance train             0.030686613
KL Divergence                42.12398
KL Loss                      4.212398
QF Loss                      113.489235
VF Loss                      45.46874
Policy Loss                  -1010.97015
Q Predictions Mean           1008.9187
Q Predictions Std            1047.8348
Q Predictions Max            3357.4624
Q Predictions Min            400.6333
V Predictions Mean           1009.1583
V Predictions Std            1048.1937
V Predictions Max            3351.5803
V Predictions Min            404.53513
Log Pis Mean                 -0.32177144
Log Pis Std                  3.538132
Log Pis Max                  16.532534
Log Pis Min                  -7.637881
Policy mu Mean               0.020259513
Policy mu Std                0.86021394
Policy mu Max                3.0817642
Policy mu Min                -3.2480564
Policy log std Mean          -0.5148467
Policy log std Std           0.25031292
Policy log std Max           -0.1017762
Policy log std Min           -2.1335037
Z mean eval                  1.6947591
Z variance eval              0.027009126
total_rewards                [8047.00475501 7568.39073529 8183.222503   8404.10145962 8132.54909948
 8200.20613759 8215.7009197  7886.8765491  8364.38421852 8050.43495691]
total_rewards_mean           8105.287133420633
total_rewards_std            229.5225003774886
total_rewards_max            8404.101459616077
total_rewards_min            7568.39073529063
Number of train steps total  580000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               144.97247170098126
(Previous) Eval Time (s)     17.71156317880377
Sample Time (s)              6.4146450138650835
Epoch Time (s)               169.09867989365011
Total Train Time (s)         24510.892487373203
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:42:09.594548 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #144 | Epoch Duration: 169.18398070335388
2020-01-12 14:42:09.594817 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #144 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.695317
Z variance train             0.0269678
KL Divergence                44.231728
KL Loss                      4.423173
QF Loss                      191.128
VF Loss                      48.93306
Policy Loss                  -1007.4997
Q Predictions Mean           1006.8425
Q Predictions Std            1065.3776
Q Predictions Max            3397.6692
Q Predictions Min            414.46292
V Predictions Mean           1003.80365
V Predictions Std            1061.5966
V Predictions Max            3369.1838
V Predictions Min            414.07217
Log Pis Mean                 -0.34204376
Log Pis Std                  3.390381
Log Pis Max                  11.930021
Log Pis Min                  -6.46827
Policy mu Mean               0.012326922
Policy mu Std                0.85887545
Policy mu Max                2.5322452
Policy mu Min                -2.492989
Policy log std Mean          -0.51445174
Policy log std Std           0.25449014
Policy log std Max           -0.062910855
Policy log std Min           -2.1959438
Z mean eval                  1.6749115
Z variance eval              0.035684813
total_rewards                [7794.33898786 7300.87560858 8461.92328295 8108.01400382 8127.2587326
 8413.23290417 8218.19622205 7924.93592859 7921.8125087  7480.93612209]
total_rewards_mean           7975.152430140026
total_rewards_std            355.7637574371275
total_rewards_max            8461.923282951328
total_rewards_min            7300.875608579461
Number of train steps total  584000
Number of env steps total    1754000
Number of rollouts total     0
Train Time (s)               144.5382714830339
(Previous) Eval Time (s)     20.85779401101172
Sample Time (s)              6.625020549166948
Epoch Time (s)               172.02108604321256
Total Train Time (s)         24682.995791705325
Epoch                        145
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:45:01.697795 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #145 | Epoch Duration: 172.10280060768127
2020-01-12 14:45:01.697924 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6735172
Z variance train             0.035613935
KL Divergence                42.52622
KL Loss                      4.252622
QF Loss                      255.3846
VF Loss                      54.65725
Policy Loss                  -946.40344
Q Predictions Mean           944.51465
Q Predictions Std            1009.6555
Q Predictions Max            3366.6094
Q Predictions Min            405.49487
V Predictions Mean           947.6812
V Predictions Std            1008.7205
V Predictions Max            3344.1775
V Predictions Min            407.7072
Log Pis Mean                 -0.67166626
Log Pis Std                  3.4005477
Log Pis Max                  19.14407
Log Pis Min                  -8.47286
Policy mu Mean               0.05054474
Policy mu Std                0.83535284
Policy mu Max                2.9949129
Policy mu Min                -2.993559
Policy log std Mean          -0.50306886
Policy log std Std           0.24255756
Policy log std Max           0.13695478
Policy log std Min           -2.1443942
Z mean eval                  1.6885169
Z variance eval              0.054299813
total_rewards                [8070.53551971 7833.99562536 8110.71489802 8028.12992089 8164.66064777
 8206.10809325 8162.95653143 8005.88883926 8306.53690481 8258.89763593]
total_rewards_mean           8114.842461644772
total_rewards_std            130.71722440527535
total_rewards_max            8306.536904810138
total_rewards_min            7833.99562536325
Number of train steps total  588000
Number of env steps total    1766000
Number of rollouts total     0
Train Time (s)               144.33919181581587
(Previous) Eval Time (s)     17.89652494667098
Sample Time (s)              6.5246032061986625
Epoch Time (s)               168.7603199686855
Total Train Time (s)         24851.830140058417
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:47:50.532898 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #146 | Epoch Duration: 168.83488082885742
2020-01-12 14:47:50.533016 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6845795
Z variance train             0.054148454
KL Divergence                41.15885
KL Loss                      4.1158853
QF Loss                      1865.0337
VF Loss                      160.36479
Policy Loss                  -873.4857
Q Predictions Mean           878.23566
Q Predictions Std            966.9287
Q Predictions Max            3396.9275
Q Predictions Min            410.0483
V Predictions Mean           882.6689
V Predictions Std            969.22736
V Predictions Max            3403.336
V Predictions Min            415.13788
Log Pis Mean                 -0.88807666
Log Pis Std                  3.4574506
Log Pis Max                  17.322197
Log Pis Min                  -6.8684244
Policy mu Mean               -0.057982665
Policy mu Std                0.81074435
Policy mu Max                2.4160388
Policy mu Min                -2.4674015
Policy log std Mean          -0.48417187
Policy log std Std           0.24627773
Policy log std Max           -0.07049495
Policy log std Min           -2.2624598
Z mean eval                  1.6995739
Z variance eval              0.034144156
total_rewards                [7859.22454082 8193.77730818 8013.94709021 7893.8453172  7969.60654873
 7947.76834788 8168.4819226  8004.80341609 7894.78993762 7613.99045009]
total_rewards_mean           7956.023487942997
total_rewards_std            155.44293010992695
total_rewards_max            8193.777308182089
total_rewards_min            7613.990450090866
Number of train steps total  592000
Number of env steps total    1778000
Number of rollouts total     0
Train Time (s)               142.9382596379146
(Previous) Eval Time (s)     20.754752404987812
Sample Time (s)              5.592764784581959
Epoch Time (s)               169.28577682748437
Total Train Time (s)         25021.19689891627
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:50:39.902128 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #147 | Epoch Duration: 169.3690047264099
2020-01-12 14:50:39.902318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #147 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6993278
Z variance train             0.03419941
KL Divergence                42.05922
KL Loss                      4.205922
QF Loss                      127.78282
VF Loss                      82.48812
Policy Loss                  -968.53265
Q Predictions Mean           967.4706
Q Predictions Std            1025.1672
Q Predictions Max            3507.7
Q Predictions Min            410.52313
V Predictions Mean           967.31824
V Predictions Std            1018.34875
V Predictions Max            3496.1433
V Predictions Min            416.84415
Log Pis Mean                 -0.7544557
Log Pis Std                  3.5216048
Log Pis Max                  13.356436
Log Pis Min                  -6.9355893
Policy mu Mean               -0.013523284
Policy mu Std                0.82396203
Policy mu Max                2.5335357
Policy mu Min                -2.59347
Policy log std Mean          -0.4910238
Policy log std Std           0.23108871
Policy log std Max           -0.083204165
Policy log std Min           -1.9751276
Z mean eval                  1.7093856
Z variance eval              0.06678541
total_rewards                [8372.47539888 8305.17977573 8115.75673478 8009.44016377 8122.9854833
 8193.21883932 8217.34464894 7989.21889769 8407.38607461 8120.50726524]
total_rewards_mean           8185.351328225724
total_rewards_std            134.94795300136974
total_rewards_max            8407.38607460596
total_rewards_min            7989.218897694061
Number of train steps total  596000
Number of env steps total    1790000
Number of rollouts total     0
Train Time (s)               143.79131935117766
(Previous) Eval Time (s)     20.44189016101882
Sample Time (s)              6.652902956586331
Epoch Time (s)               170.8861124687828
Total Train Time (s)         25192.165222160518
Epoch                        148
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:53:30.871925 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #148 | Epoch Duration: 170.96947979927063
2020-01-12 14:53:30.872070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7067196
Z variance train             0.06699556
KL Divergence                41.9236
KL Loss                      4.19236
QF Loss                      117.38296
VF Loss                      54.455948
Policy Loss                  -954.1566
Q Predictions Mean           952.3406
Q Predictions Std            1012.92316
Q Predictions Max            3471.4036
Q Predictions Min            403.38727
V Predictions Mean           958.19775
V Predictions Std            1011.96454
V Predictions Max            3453.7761
V Predictions Min            412.05
Log Pis Mean                 -0.9010433
Log Pis Std                  3.287745
Log Pis Max                  16.721191
Log Pis Min                  -9.495697
Policy mu Mean               0.031325307
Policy mu Std                0.8124128
Policy mu Max                2.7134693
Policy mu Min                -2.8730044
Policy log std Mean          -0.4850712
Policy log std Std           0.2469268
Policy log std Max           -0.08359355
Policy log std Min           -2.003707
Z mean eval                  1.715669
Z variance eval              0.090698436
total_rewards                [7748.58073103 6361.36515373 8195.59929725 7651.27935657 8296.16102852
 7694.80208715 8164.96740115 8046.92387212 7678.53043689 7984.44784922]
total_rewards_mean           7782.26572136293
total_rewards_std            524.211463341087
total_rewards_max            8296.161028523882
total_rewards_min            6361.365153725585
Number of train steps total  600000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               145.54839417291805
(Previous) Eval Time (s)     17.664936828892678
Sample Time (s)              6.532973472028971
Epoch Time (s)               169.7463044738397
Total Train Time (s)         25361.99229719583
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:56:20.703049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #149 | Epoch Duration: 169.83085560798645
2020-01-12 14:56:20.703257 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7178047
Z variance train             0.090257175
KL Divergence                40.92842
KL Loss                      4.092842
QF Loss                      175.07375
VF Loss                      136.16455
Policy Loss                  -986.78674
Q Predictions Mean           985.84875
Q Predictions Std            1042.5785
Q Predictions Max            3481.0479
Q Predictions Min            426.7741
V Predictions Mean           981.5595
V Predictions Std            1036.049
V Predictions Max            3461.1594
V Predictions Min            425.38358
Log Pis Mean                 -0.65893745
Log Pis Std                  3.4786277
Log Pis Max                  13.423782
Log Pis Min                  -7.2981043
Policy mu Mean               0.07259724
Policy mu Std                0.8542108
Policy mu Max                3.1013567
Policy mu Min                -2.3794746
Policy log std Mean          -0.501889
Policy log std Std           0.24229398
Policy log std Max           0.16486758
Policy log std Min           -2.094708
Z mean eval                  1.7175245
Z variance eval              0.083317116
total_rewards                [8167.88559685 8560.58897746 8351.27164624 8474.53364765 8248.41556732
 8340.90596232 8366.69041814 8209.67102664 8382.10477929 8013.19984604]
total_rewards_mean           8311.52674679435
total_rewards_std            149.3518186974628
total_rewards_max            8560.588977455489
total_rewards_min            8013.199846044453
Number of train steps total  604000
Number of env steps total    1814000
Number of rollouts total     0
Train Time (s)               142.83142576320097
(Previous) Eval Time (s)     17.749417902436107
Sample Time (s)              6.607822792604566
Epoch Time (s)               167.18866645824164
Total Train Time (s)         25529.259678859264
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:59:07.975577 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #150 | Epoch Duration: 167.272141456604
2020-01-12 14:59:07.975853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7179791
Z variance train             0.08380818
KL Divergence                40.16949
KL Loss                      4.016949
QF Loss                      1820.9321
VF Loss                      77.984406
Policy Loss                  -868.7331
Q Predictions Mean           868.7505
Q Predictions Std            920.84644
Q Predictions Max            3464.788
Q Predictions Min            414.7245
V Predictions Mean           875.4043
V Predictions Std            923.4088
V Predictions Max            3488.4612
V Predictions Min            421.67474
Log Pis Mean                 -0.89485383
Log Pis Std                  2.8976307
Log Pis Max                  12.021347
Log Pis Min                  -6.5136757
Policy mu Mean               -0.037747316
Policy mu Std                0.78664505
Policy mu Max                2.3581557
Policy mu Min                -2.7024503
Policy log std Mean          -0.49788514
Policy log std Std           0.24290256
Policy log std Max           0.011012733
Policy log std Min           -1.9909074
Z mean eval                  1.6884816
Z variance eval              0.07300848
total_rewards                [8115.59048734 8309.91026612 8316.04341789 5404.62943859 8199.53613459
 8583.06666864 8097.05125076 8220.6344292  8161.87534571 7937.79186665]
total_rewards_mean           7934.6129305484865
total_rewards_std            858.5124357528223
total_rewards_max            8583.066668639794
total_rewards_min            5404.629438591676
Number of train steps total  608000
Number of env steps total    1826000
Number of rollouts total     0
Train Time (s)               144.23151679104194
(Previous) Eval Time (s)     18.06207419699058
Sample Time (s)              6.582823527511209
Epoch Time (s)               168.87641451554373
Total Train Time (s)         25698.40862738993
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:01:57.142585 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #151 | Epoch Duration: 169.16652417182922
2020-01-12 15:01:57.142844 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.686836
Z variance train             0.0731434
KL Divergence                39.18359
KL Loss                      3.918359
QF Loss                      125.93544
VF Loss                      62.008263
Policy Loss                  -1010.30054
Q Predictions Mean           1006.9208
Q Predictions Std            1051.7389
Q Predictions Max            3697.2412
Q Predictions Min            427.8624
V Predictions Mean           1010.87366
V Predictions Std            1049.6222
V Predictions Max            3678.5056
V Predictions Min            438.3128
Log Pis Mean                 -0.7162546
Log Pis Std                  3.2384782
Log Pis Max                  12.120918
Log Pis Min                  -7.180093
Policy mu Mean               0.040409535
Policy mu Std                0.81921166
Policy mu Max                2.7138135
Policy mu Min                -2.8687184
Policy log std Mean          -0.48667845
Policy log std Std           0.24769405
Policy log std Max           -0.08386749
Policy log std Min           -2.1219926
Z mean eval                  1.6921375
Z variance eval              0.040080428
total_rewards                [8238.45074808 8551.36852417 8340.33021775 8493.60408402 8345.14772428
 8451.59515246 2590.3589485  8534.67624352 8563.24927174 8689.25094588]
total_rewards_mean           7879.803186040503
total_rewards_std            1767.5219843044065
total_rewards_max            8689.250945882563
total_rewards_min            2590.358948500473
Number of train steps total  612000
Number of env steps total    1838000
Number of rollouts total     0
Train Time (s)               142.83559004683048
(Previous) Eval Time (s)     17.5953217279166
Sample Time (s)              6.655787009745836
Epoch Time (s)               167.0866987844929
Total Train Time (s)         25865.605095817707
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:04:44.332549 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #152 | Epoch Duration: 167.18949699401855
2020-01-12 15:04:44.332879 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.693256
Z variance train             0.039960526
KL Divergence                41.038578
KL Loss                      4.103858
QF Loss                      136.55568
VF Loss                      66.44627
Policy Loss                  -942.7849
Q Predictions Mean           941.016
Q Predictions Std            1012.2404
Q Predictions Max            3522.7097
Q Predictions Min            412.33347
V Predictions Mean           942.74115
V Predictions Std            1011.7556
V Predictions Max            3520.0256
V Predictions Min            418.80405
Log Pis Mean                 -0.40801388
Log Pis Std                  3.3802607
Log Pis Max                  15.222777
Log Pis Min                  -7.1442385
Policy mu Mean               0.07008668
Policy mu Std                0.8282158
Policy mu Max                3.059695
Policy mu Min                -2.3629947
Policy log std Mean          -0.50592726
Policy log std Std           0.25840732
Policy log std Max           -0.048333526
Policy log std Min           -2.3577027
Z mean eval                  1.6963199
Z variance eval              0.04144279
total_rewards                [8253.8986913  8382.55545374 8290.22866372 8398.21415992 8497.28918823
 8213.24626783 8567.89602969 8591.49202666 8571.89852553 8200.77476557]
total_rewards_mean           8396.749377219861
total_rewards_std            145.61503610956134
total_rewards_max            8591.492026664331
total_rewards_min            8200.774765567403
Number of train steps total  616000
Number of env steps total    1850000
Number of rollouts total     0
Train Time (s)               144.7978356280364
(Previous) Eval Time (s)     18.97120857099071
Sample Time (s)              6.41348764160648
Epoch Time (s)               170.1825318406336
Total Train Time (s)         26035.876702698413
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:07:34.601915 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #153 | Epoch Duration: 170.26880526542664
2020-01-12 15:07:34.602085 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6955321
Z variance train             0.04150478
KL Divergence                41.28817
KL Loss                      4.128817
QF Loss                      143.51904
VF Loss                      67.00545
Policy Loss                  -971.3444
Q Predictions Mean           969.0608
Q Predictions Std            1012.7698
Q Predictions Max            3600.9263
Q Predictions Min            431.1245
V Predictions Mean           969.1841
V Predictions Std            1012.0774
V Predictions Max            3585.1094
V Predictions Min            431.19998
Log Pis Mean                 -0.63043904
Log Pis Std                  3.3967545
Log Pis Max                  11.379036
Log Pis Min                  -6.421377
Policy mu Mean               0.05623454
Policy mu Std                0.8380802
Policy mu Max                2.9975736
Policy mu Min                -3.0059075
Policy log std Mean          -0.5071673
Policy log std Std           0.2574827
Policy log std Max           -0.083399095
Policy log std Min           -2.121602
Z mean eval                  1.6824646
Z variance eval              0.03998089
total_rewards                [5943.84393829 7112.13828745 6304.53690215 6150.57977367 6837.87557596
 6697.69185472 6641.25379834 6296.21262397 5408.17388127 7632.39623994]
total_rewards_mean           6502.470287575382
total_rewards_std            594.4233814480615
total_rewards_max            7632.396239935801
total_rewards_min            5408.173881268125
Number of train steps total  620000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               144.73534564767033
(Previous) Eval Time (s)     17.482065471820533
Sample Time (s)              6.440991132054478
Epoch Time (s)               168.65840225154534
Total Train Time (s)         26204.624225288164
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:10:23.352315 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #154 | Epoch Duration: 168.75010299682617
2020-01-12 15:10:23.352477 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6773704
Z variance train             0.03989289
KL Divergence                41.444878
KL Loss                      4.144488
QF Loss                      300.15588
VF Loss                      176.63162
Policy Loss                  -932.2978
Q Predictions Mean           929.87787
Q Predictions Std            988.4613
Q Predictions Max            3419.7405
Q Predictions Min            422.8435
V Predictions Mean           939.0667
V Predictions Std            991.24963
V Predictions Max            3439.8638
V Predictions Min            427.20093
Log Pis Mean                 -0.58376443
Log Pis Std                  3.6474376
Log Pis Max                  12.717672
Log Pis Min                  -11.097915
Policy mu Mean               0.084276915
Policy mu Std                0.8590956
Policy mu Max                2.742898
Policy mu Min                -2.9587474
Policy log std Mean          -0.5016393
Policy log std Std           0.2567651
Policy log std Max           -0.09008881
Policy log std Min           -2.2405252
Z mean eval                  1.6808002
Z variance eval              0.039493173
total_rewards                [8080.76744991 8515.91389213 8238.1743592  7423.01857417 8185.88102562
 8361.52447008 7968.03710633 8352.09827542 8153.4835897  8246.0441083 ]
total_rewards_mean           8152.494285086135
total_rewards_std            283.57035849455036
total_rewards_max            8515.913892127788
total_rewards_min            7423.018574167669
Number of train steps total  624000
Number of env steps total    1874000
Number of rollouts total     0
Train Time (s)               143.76098084589466
(Previous) Eval Time (s)     17.13578405790031
Sample Time (s)              5.654736757278442
Epoch Time (s)               166.55150166107342
Total Train Time (s)         26371.25897920644
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:13:09.993242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #155 | Epoch Duration: 166.64058446884155
2020-01-12 15:13:09.993584 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6801609
Z variance train             0.03940464
KL Divergence                42.20976
KL Loss                      4.220976
QF Loss                      216.92978
VF Loss                      105.11313
Policy Loss                  -994.3619
Q Predictions Mean           992.47546
Q Predictions Std            1049.5995
Q Predictions Max            3547.9749
Q Predictions Min            414.82288
V Predictions Mean           993.93567
V Predictions Std            1046.69
V Predictions Max            3539.953
V Predictions Min            424.35324
Log Pis Mean                 -0.6395857
Log Pis Std                  3.3890698
Log Pis Max                  19.446762
Log Pis Min                  -7.691763
Policy mu Mean               -0.035720665
Policy mu Std                0.83088785
Policy mu Max                2.6309373
Policy mu Min                -3.7986195
Policy log std Mean          -0.5072802
Policy log std Std           0.2576026
Policy log std Max           -0.08554143
Policy log std Min           -2.346056
Z mean eval                  1.6838112
Z variance eval              0.03687975
total_rewards                [8087.8685862  8369.23098567 8194.29773205 8254.37643213 8150.03525646
 8431.08460093 8166.73737853 8314.90160849 7733.17214297 8265.90675663]
total_rewards_mean           8196.761148004818
total_rewards_std            183.4596112927521
total_rewards_max            8431.084600929693
total_rewards_min            7733.172142966617
Number of train steps total  628000
Number of env steps total    1886000
Number of rollouts total     0
Train Time (s)               146.90457370504737
(Previous) Eval Time (s)     20.62318090442568
Sample Time (s)              6.463837856426835
Epoch Time (s)               173.99159246589988
Total Train Time (s)         26545.33572577918
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:16:04.069814 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #156 | Epoch Duration: 174.0759961605072
2020-01-12 15:16:04.069958 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6855221
Z variance train             0.036920257
KL Divergence                40.59921
KL Loss                      4.059921
QF Loss                      156.14551
VF Loss                      134.67978
Policy Loss                  -873.7612
Q Predictions Mean           875.7315
Q Predictions Std            968.9583
Q Predictions Max            3495.8694
Q Predictions Min            430.46246
V Predictions Mean           881.9304
V Predictions Std            968.59985
V Predictions Max            3487.647
V Predictions Min            433.58414
Log Pis Mean                 -0.7079874
Log Pis Std                  3.3622265
Log Pis Max                  16.909262
Log Pis Min                  -9.469059
Policy mu Mean               0.0519211
Policy mu Std                0.8223465
Policy mu Max                3.328805
Policy mu Min                -2.7041535
Policy log std Mean          -0.48393586
Policy log std Std           0.25188404
Policy log std Max           0.0051498413
Policy log std Min           -2.156906
Z mean eval                  1.6692518
Z variance eval              0.0505194
total_rewards                [4134.42259465 7679.50688049 7833.52116349 7824.5074276  7976.00789373
 7753.73525323 8033.68162757 7666.49368759 7930.84792957 7647.68395113]
total_rewards_mean           7448.040840904667
total_rewards_std            1111.7472597465958
total_rewards_max            8033.681627570213
total_rewards_min            4134.4225946502265
Number of train steps total  632000
Number of env steps total    1898000
Number of rollouts total     0
Train Time (s)               145.36902018636465
(Previous) Eval Time (s)     17.324253030121326
Sample Time (s)              6.552715686149895
Epoch Time (s)               169.24598890263587
Total Train Time (s)         26714.66900205007
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:18:53.410110 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #157 | Epoch Duration: 169.3400011062622
2020-01-12 15:18:53.410387 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.670131
Z variance train             0.050728105
KL Divergence                40.101505
KL Loss                      4.0101504
QF Loss                      102.37797
VF Loss                      42.350967
Policy Loss                  -972.479
Q Predictions Mean           970.1383
Q Predictions Std            1026.8604
Q Predictions Max            3543.2964
Q Predictions Min            436.03403
V Predictions Mean           972.23627
V Predictions Std            1023.34766
V Predictions Max            3525.9258
V Predictions Min            442.33157
Log Pis Mean                 -0.75842786
Log Pis Std                  3.0300765
Log Pis Max                  10.531879
Log Pis Min                  -7.8359275
Policy mu Mean               0.05407253
Policy mu Std                0.8092073
Policy mu Max                2.8985863
Policy mu Min                -2.909739
Policy log std Mean          -0.482967
Policy log std Std           0.24299757
Policy log std Max           -0.023729205
Policy log std Min           -1.9544766
Z mean eval                  1.6684755
Z variance eval              0.059243787
total_rewards                [5940.00261673 8537.06576284 8520.15981503 8204.50175106 8164.09680543
 6609.34726375 8130.54345052 8338.11404128 8447.38003792 8473.04395161]
total_rewards_mean           7936.425549618754
total_rewards_std            855.5772270742784
total_rewards_max            8537.065762842689
total_rewards_min            5940.002616734299
Number of train steps total  636000
Number of env steps total    1910000
Number of rollouts total     0
Train Time (s)               145.28805463341996
(Previous) Eval Time (s)     21.349528718739748
Sample Time (s)              6.674951656721532
Epoch Time (s)               173.31253500888124
Total Train Time (s)         26888.064600161277
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:21:46.804754 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #158 | Epoch Duration: 173.394104719162
2020-01-12 15:21:46.805036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6666578
Z variance train             0.059202127
KL Divergence                39.49934
KL Loss                      3.949934
QF Loss                      125.46012
VF Loss                      35.91261
Policy Loss                  -984.80023
Q Predictions Mean           982.092
Q Predictions Std            996.62305
Q Predictions Max            3566.963
Q Predictions Min            420.77823
V Predictions Mean           982.0785
V Predictions Std            998.7925
V Predictions Max            3567.0232
V Predictions Min            413.30197
Log Pis Mean                 -0.5574315
Log Pis Std                  3.3183858
Log Pis Max                  11.515685
Log Pis Min                  -9.4117565
Policy mu Mean               0.008906503
Policy mu Std                0.8313205
Policy mu Max                2.9669752
Policy mu Min                -2.4077673
Policy log std Mean          -0.5148545
Policy log std Std           0.26446256
Policy log std Max           -0.14521945
Policy log std Min           -2.47193
Z mean eval                  1.6647692
Z variance eval              0.08769739
total_rewards                [8214.69070997 8519.70549844 8119.73163089 8351.10912689 8403.43391663
 8573.24854286 8454.08472371 8620.29238241 8455.73385285 8309.37525718]
total_rewards_mean           8402.140564183897
total_rewards_std            149.1186246627803
total_rewards_max            8620.292382409565
total_rewards_min            8119.731630891425
Number of train steps total  640000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               144.43296390166506
(Previous) Eval Time (s)     21.298181997146457
Sample Time (s)              6.552921161521226
Epoch Time (s)               172.28406706033275
Total Train Time (s)         27060.43429635046
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:24:39.175154 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #159 | Epoch Duration: 172.36994910240173
2020-01-12 15:24:39.175298 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6631695
Z variance train             0.0876924
KL Divergence                38.579678
KL Loss                      3.8579679
QF Loss                      195.24768
VF Loss                      85.20365
Policy Loss                  -987.6028
Q Predictions Mean           986.40546
Q Predictions Std            1046.7224
Q Predictions Max            3604.429
Q Predictions Min            427.89557
V Predictions Mean           987.4212
V Predictions Std            1040.8501
V Predictions Max            3574.9712
V Predictions Min            437.15805
Log Pis Mean                 -0.54161143
Log Pis Std                  3.2286925
Log Pis Max                  11.176964
Log Pis Min                  -6.3900795
Policy mu Mean               0.033344667
Policy mu Std                0.8332597
Policy mu Max                2.7732303
Policy mu Min                -2.5580568
Policy log std Mean          -0.48812118
Policy log std Std           0.25721726
Policy log std Max           -0.085149765
Policy log std Min           -2.10993
Z mean eval                  1.6858761
Z variance eval              0.11312804
total_rewards                [7778.41397073 7997.9124408  7872.32335618 7720.98820196 7903.96943954
 7952.47019068 7882.68079837 7581.91396263 6979.7540867  5462.1666011 ]
total_rewards_mean           7513.259304870393
total_rewards_std            738.6223227968701
total_rewards_max            7997.912440804156
total_rewards_min            5462.166601100374
Number of train steps total  644000
Number of env steps total    1934000
Number of rollouts total     0
Train Time (s)               145.56839477829635
(Previous) Eval Time (s)     21.465846753213555
Sample Time (s)              6.3990280805155635
Epoch Time (s)               173.43326961202547
Total Train Time (s)         27233.94944996247
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:27:32.692805 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #160 | Epoch Duration: 173.5173327922821
2020-01-12 15:27:32.693026 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6855644
Z variance train             0.11323136
KL Divergence                38.715633
KL Loss                      3.8715634
QF Loss                      145.97002
VF Loss                      57.43587
Policy Loss                  -1053.3379
Q Predictions Mean           1049.8362
Q Predictions Std            1089.5018
Q Predictions Max            3642.7822
Q Predictions Min            445.16068
V Predictions Mean           1053.5118
V Predictions Std            1087.329
V Predictions Max            3631.3323
V Predictions Min            446.63358
Log Pis Mean                 -0.31389982
Log Pis Std                  3.5349002
Log Pis Max                  15.372602
Log Pis Min                  -7.2831473
Policy mu Mean               0.07441337
Policy mu Std                0.8648342
Policy mu Max                3.1500065
Policy mu Min                -2.9904642
Policy log std Mean          -0.4997108
Policy log std Std           0.26974827
Policy log std Max           -0.049295485
Policy log std Min           -2.174433
Z mean eval                  1.706269
Z variance eval              0.061629813
total_rewards                [8069.84541031 8445.56400335 8387.10027589 8461.12580091 8287.55237038
 8305.26057917 8405.36678933 8175.68788902 8290.69610197 8186.85685544]
total_rewards_mean           8301.505607577363
total_rewards_std            121.37196527705841
total_rewards_max            8461.12580091366
total_rewards_min            8069.845410312459
Number of train steps total  648000
Number of env steps total    1946000
Number of rollouts total     0
Train Time (s)               144.08012962993234
(Previous) Eval Time (s)     18.6778327813372
Sample Time (s)              6.472726160660386
Epoch Time (s)               169.23068857192993
Total Train Time (s)         27403.291216287762
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:30:22.036610 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #161 | Epoch Duration: 169.34345602989197
2020-01-12 15:30:22.036783 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #161 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7067089
Z variance train             0.061644293
KL Divergence                39.990013
KL Loss                      3.9990013
QF Loss                      1927.54
VF Loss                      180.78108
Policy Loss                  -1056.0992
Q Predictions Mean           1053.0657
Q Predictions Std            1083.2035
Q Predictions Max            3586.295
Q Predictions Min            445.11728
V Predictions Mean           1062.9858
V Predictions Std            1083.0472
V Predictions Max            3611.5886
V Predictions Min            451.48813
Log Pis Mean                 -0.5531429
Log Pis Std                  3.2883127
Log Pis Max                  13.208656
Log Pis Min                  -7.936208
Policy mu Mean               0.043832522
Policy mu Std                0.84358853
Policy mu Max                3.0912414
Policy mu Min                -2.6023188
Policy log std Mean          -0.5062376
Policy log std Std           0.28084147
Policy log std Max           0.09842491
Policy log std Min           -2.3637557
Z mean eval                  1.6757586
Z variance eval              0.06733346
total_rewards                [7960.6738216  8227.36965026 8468.24236326 8700.9430975  8266.6804645
 8318.00530653 8484.96176387 8617.67743521 8503.63134857 8559.20573492]
total_rewards_mean           8410.739098620557
total_rewards_std            207.86157226089506
total_rewards_max            8700.943097501446
total_rewards_min            7960.67382159728
Number of train steps total  652000
Number of env steps total    1958000
Number of rollouts total     0
Train Time (s)               145.30942275980487
(Previous) Eval Time (s)     20.777943045832217
Sample Time (s)              6.592671235091984
Epoch Time (s)               172.68003704072908
Total Train Time (s)         27576.06158953719
Epoch                        162
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:33:14.812348 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #162 | Epoch Duration: 172.77539587020874
2020-01-12 15:33:14.812642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6757734
Z variance train             0.06743214
KL Divergence                39.702152
KL Loss                      3.9702153
QF Loss                      2026.3009
VF Loss                      85.45046
Policy Loss                  -960.99036
Q Predictions Mean           960.89606
Q Predictions Std            1032.7604
Q Predictions Max            3561.8257
Q Predictions Min            425.75882
V Predictions Mean           964.9397
V Predictions Std            1034.2883
V Predictions Max            3580.0413
V Predictions Min            436.6621
Log Pis Mean                 -0.4100744
Log Pis Std                  3.575611
Log Pis Max                  13.544498
Log Pis Min                  -5.9498224
Policy mu Mean               0.08590195
Policy mu Std                0.8717773
Policy mu Max                2.9629836
Policy mu Min                -2.8876421
Policy log std Mean          -0.5031908
Policy log std Std           0.26166865
Policy log std Max           -0.0982362
Policy log std Min           -2.3904204
Z mean eval                  1.6633358
Z variance eval              0.055999726
total_rewards                [8731.89896842 8725.92237956 8661.05932159 8683.15826959 8704.42176906
 8703.72434314 8365.46675214 8412.64892987 8213.6919596  8428.93031953]
total_rewards_mean           8563.09230124973
total_rewards_std            179.03720019231207
total_rewards_max            8731.898968420204
total_rewards_min            8213.691959603198
Number of train steps total  656000
Number of env steps total    1970000
Number of rollouts total     0
Train Time (s)               145.7679060101509
(Previous) Eval Time (s)     20.801635336130857
Sample Time (s)              6.622578330338001
Epoch Time (s)               173.19211967661977
Total Train Time (s)         27749.350282585714
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:36:08.101491 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #163 | Epoch Duration: 173.28865218162537
2020-01-12 15:36:08.101626 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #163 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.663591
Z variance train             0.05603979
KL Divergence                39.386177
KL Loss                      3.9386177
QF Loss                      246.87125
VF Loss                      66.25935
Policy Loss                  -986.45715
Q Predictions Mean           983.6944
Q Predictions Std            1018.4226
Q Predictions Max            3645.1917
Q Predictions Min            410.265
V Predictions Mean           982.8601
V Predictions Std            1013.9674
V Predictions Max            3638.7656
V Predictions Min            463.98865
Log Pis Mean                 -0.30612773
Log Pis Std                  3.875925
Log Pis Max                  16.222378
Log Pis Min                  -5.747678
Policy mu Mean               0.031479243
Policy mu Std                0.87018734
Policy mu Max                4.212607
Policy mu Min                -2.76833
Policy log std Mean          -0.48593482
Policy log std Std           0.25187275
Policy log std Max           -0.06016463
Policy log std Min           -2.197948
Z mean eval                  1.652396
Z variance eval              0.059991397
total_rewards                [8482.77786747 8698.36475853 8746.24731885 8687.32933596 8583.4225795
 8399.89611215 8609.75745802 8649.40435838 8762.64917968 8499.86422687]
total_rewards_mean           8611.971319542306
total_rewards_std            114.16327100965566
total_rewards_max            8762.649179675338
total_rewards_min            8399.896112151242
Number of train steps total  660000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               144.91382416989654
(Previous) Eval Time (s)     17.31726120505482
Sample Time (s)              6.554503338877112
Epoch Time (s)               168.78558871382847
Total Train Time (s)         27918.21486007562
Epoch                        164
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:38:56.968099 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #164 | Epoch Duration: 168.86636519432068
2020-01-12 15:38:56.968272 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6520624
Z variance train             0.060126733
KL Divergence                38.88307
KL Loss                      3.8883073
QF Loss                      177.16115
VF Loss                      100.05221
Policy Loss                  -936.2691
Q Predictions Mean           933.2539
Q Predictions Std            977.23883
Q Predictions Max            3624.445
Q Predictions Min            427.17838
V Predictions Mean           934.00745
V Predictions Std            973.2496
V Predictions Max            3598.4578
V Predictions Min            429.54123
Log Pis Mean                 -0.60585624
Log Pis Std                  3.5035627
Log Pis Max                  22.018147
Log Pis Min                  -7.7542787
Policy mu Mean               0.102687955
Policy mu Std                0.8617833
Policy mu Max                3.4867532
Policy mu Min                -2.5813835
Policy log std Mean          -0.4898169
Policy log std Std           0.2581751
Policy log std Max           -0.055503666
Policy log std Min           -2.1160653
Z mean eval                  1.6549307
Z variance eval              0.049500596
total_rewards                [8560.36756444 8804.43648673 8657.3518918  8243.41274752 8583.03812002
 8793.11679864 8420.86880505 8761.42629635 8703.32335427 8494.54362294]
total_rewards_mean           8602.188568776066
total_rewards_std            170.67097506409874
total_rewards_max            8804.436486732982
total_rewards_min            8243.41274752131
Number of train steps total  664000
Number of env steps total    1994000
Number of rollouts total     0
Train Time (s)               145.9682332049124
(Previous) Eval Time (s)     17.64883640082553
Sample Time (s)              6.589735724963248
Epoch Time (s)               170.20680533070117
Total Train Time (s)         28088.503470460884
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:41:47.259983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #165 | Epoch Duration: 170.29151725769043
2020-01-12 15:41:47.260255 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6567894
Z variance train             0.049710847
KL Divergence                38.783916
KL Loss                      3.8783917
QF Loss                      2300.9534
VF Loss                      74.5664
Policy Loss                  -1039.1998
Q Predictions Mean           1037.0245
Q Predictions Std            1075.2072
Q Predictions Max            3612.7527
Q Predictions Min            456.65234
V Predictions Mean           1041.5654
V Predictions Std            1079.2737
V Predictions Max            3619.7522
V Predictions Min            470.455
Log Pis Mean                 -0.606949
Log Pis Std                  3.495847
Log Pis Max                  14.524021
Log Pis Min                  -9.15163
Policy mu Mean               0.040339224
Policy mu Std                0.83455193
Policy mu Max                2.7011616
Policy mu Min                -2.6176834
Policy log std Mean          -0.5019823
Policy log std Std           0.2531119
Policy log std Max           -0.08505887
Policy log std Min           -2.01134
Z mean eval                  1.6605324
Z variance eval              0.08821193
total_rewards                [8706.8521606  8821.33295602 8683.74250931 9104.20513826 8935.74866726
 8832.43370236 8517.35477475 8908.95892219  537.5930163  8725.83854958]
total_rewards_mean           7977.406039662242
total_rewards_std            2484.6063883495144
total_rewards_max            9104.205138262496
total_rewards_min            537.5930162992486
Number of train steps total  668000
Number of env steps total    2006000
Number of rollouts total     0
Train Time (s)               146.48404628923163
(Previous) Eval Time (s)     17.58264566073194
Sample Time (s)              6.506538621149957
Epoch Time (s)               170.57323057111353
Total Train Time (s)         28259.162818637677
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:44:37.923338 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #166 | Epoch Duration: 170.6628942489624
2020-01-12 15:44:37.923517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6599884
Z variance train             0.08812831
KL Divergence                37.18761
KL Loss                      3.7187612
QF Loss                      125.12697
VF Loss                      129.45154
Policy Loss                  -1044.5137
Q Predictions Mean           1042.2798
Q Predictions Std            1071.4978
Q Predictions Max            3527.7073
Q Predictions Min            453.3944
V Predictions Mean           1046.7501
V Predictions Std            1072.6708
V Predictions Max            3550.8145
V Predictions Min            462.24417
Log Pis Mean                 -0.50661314
Log Pis Std                  3.7162547
Log Pis Max                  20.383276
Log Pis Min                  -7.911856
Policy mu Mean               0.017188562
Policy mu Std                0.870014
Policy mu Max                3.0606408
Policy mu Min                -3.49635
Policy log std Mean          -0.48185587
Policy log std Std           0.26425943
Policy log std Max           -0.07888186
Policy log std Min           -2.4321558
Z mean eval                  1.702982
Z variance eval              0.046680797
total_rewards                [8087.70545572 7971.05566275 8444.00460868 8295.40399072 8295.42607427
 8146.72682979 8244.65551981 8108.03837929 8256.18014317 8475.03219699]
total_rewards_mean           8232.42288611841
total_rewards_std            149.78232492859763
total_rewards_max            8475.0321969906
total_rewards_min            7971.055662750041
Number of train steps total  672000
Number of env steps total    2018000
Number of rollouts total     0
Train Time (s)               144.9417073582299
(Previous) Eval Time (s)     20.810718567110598
Sample Time (s)              6.608845453243703
Epoch Time (s)               172.3612713785842
Total Train Time (s)         28431.607398571447
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:47:30.366788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #167 | Epoch Duration: 172.4431381225586
2020-01-12 15:47:30.366933 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7016321
Z variance train             0.04675547
KL Divergence                39.42159
KL Loss                      3.942159
QF Loss                      140.04364
VF Loss                      80.33762
Policy Loss                  -1067.7583
Q Predictions Mean           1068.8872
Q Predictions Std            1101.6366
Q Predictions Max            3605.6501
Q Predictions Min            458.04523
V Predictions Mean           1069.8123
V Predictions Std            1103.8966
V Predictions Max            3614.9998
V Predictions Min            455.02527
Log Pis Mean                 -0.419085
Log Pis Std                  3.468799
Log Pis Max                  12.653125
Log Pis Min                  -6.702613
Policy mu Mean               0.060690235
Policy mu Std                0.8657343
Policy mu Max                2.8345518
Policy mu Min                -2.4403539
Policy log std Mean          -0.49641475
Policy log std Std           0.25748968
Policy log std Max           -0.07634348
Policy log std Min           -2.2391026
Z mean eval                  1.6878445
Z variance eval              0.051007003
total_rewards                [7900.46783036 8184.69743467 8310.31626619 8749.77395926 8276.80498693
 8310.9087901  8414.90839878 8491.06746268 8201.09901321 8251.19720909]
total_rewards_mean           8309.12413512604
total_rewards_std            209.05071653575988
total_rewards_max            8749.773959264885
total_rewards_min            7900.467830360265
Number of train steps total  676000
Number of env steps total    2030000
Number of rollouts total     0
Train Time (s)               146.2720042890869
(Previous) Eval Time (s)     20.62562488298863
Sample Time (s)              6.499655156861991
Epoch Time (s)               173.39728432893753
Total Train Time (s)         28605.098575496115
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:50:23.859825 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #168 | Epoch Duration: 173.49277544021606
2020-01-12 15:50:23.859999 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.687454
Z variance train             0.050934933
KL Divergence                39.88109
KL Loss                      3.9881089
QF Loss                      295.7052
VF Loss                      86.86297
Policy Loss                  -1072.0112
Q Predictions Mean           1070.7645
Q Predictions Std            1109.3578
Q Predictions Max            3642.529
Q Predictions Min            474.8323
V Predictions Mean           1078.8192
V Predictions Std            1110.3694
V Predictions Max            3636.7578
V Predictions Min            478.18896
Log Pis Mean                 -0.6712061
Log Pis Std                  3.4327505
Log Pis Max                  11.017113
Log Pis Min                  -6.7748785
Policy mu Mean               0.0124715455
Policy mu Std                0.82966834
Policy mu Max                2.6371453
Policy mu Min                -2.3315418
Policy log std Mean          -0.50378966
Policy log std Std           0.25258705
Policy log std Max           -0.14151967
Policy log std Min           -2.4408998
Z mean eval                  1.6869953
Z variance eval              0.053444393
total_rewards                [8222.75704986 8769.34860381 8667.29303842 8751.50126783 8714.62780148
 8685.13704641 8756.17191276 8591.48364041 8698.82390947 8863.25572692]
total_rewards_mean           8672.039999738172
total_rewards_std            164.46712489085743
total_rewards_max            8863.25572692445
total_rewards_min            8222.757049858508
Number of train steps total  680000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               145.8144045220688
(Previous) Eval Time (s)     18.04896749276668
Sample Time (s)              6.472155757714063
Epoch Time (s)               170.33552777254954
Total Train Time (s)         28775.51926541142
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:53:14.286049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #169 | Epoch Duration: 170.42587423324585
2020-01-12 15:53:14.286361 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.678326
Z variance train             0.0542598
KL Divergence                39.349335
KL Loss                      3.9349334
QF Loss                      115.38569
VF Loss                      100.75787
Policy Loss                  -923.0727
Q Predictions Mean           923.8257
Q Predictions Std            985.7428
Q Predictions Max            3852.1685
Q Predictions Min            488.97018
V Predictions Mean           931.28723
V Predictions Std            986.6508
V Predictions Max            3862.1404
V Predictions Min            494.59235
Log Pis Mean                 -0.77732897
Log Pis Std                  3.018531
Log Pis Max                  11.096724
Log Pis Min                  -7.9351444
Policy mu Mean               0.03150111
Policy mu Std                0.8071585
Policy mu Max                2.5668807
Policy mu Min                -2.4092195
Policy log std Mean          -0.48112497
Policy log std Std           0.23909311
Policy log std Max           -0.13827014
Policy log std Min           -2.3621607
Z mean eval                  1.6825974
Z variance eval              0.046334367
total_rewards                [8641.91015272 8888.73980555 8773.01330649 8796.47860474 8995.73795362
 8694.15572269 8695.28649672 8702.49986467 8888.052827   8958.91222216]
total_rewards_mean           8803.478695635657
total_rewards_std            116.82498358731809
total_rewards_max            8995.737953622373
total_rewards_min            8641.910152717783
Number of train steps total  684000
Number of env steps total    2054000
Number of rollouts total     0
Train Time (s)               145.4497742978856
(Previous) Eval Time (s)     20.640418864320964
Sample Time (s)              6.541411028243601
Epoch Time (s)               172.63160419045016
Total Train Time (s)         28948.235827020835
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:56:07.003728 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #170 | Epoch Duration: 172.71710586547852
2020-01-12 15:56:07.003941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6831436
Z variance train             0.046361286
KL Divergence                39.943245
KL Loss                      3.9943244
QF Loss                      115.007515
VF Loss                      46.87203
Policy Loss                  -942.1672
Q Predictions Mean           944.5106
Q Predictions Std            1002.2489
Q Predictions Max            3653.888
Q Predictions Min            453.87137
V Predictions Mean           941.97736
V Predictions Std            998.1779
V Predictions Max            3662.0325
V Predictions Min            453.36603
Log Pis Mean                 -0.61720127
Log Pis Std                  3.7740662
Log Pis Max                  17.2194
Log Pis Min                  -7.306044
Policy mu Mean               0.049936432
Policy mu Std                0.8299118
Policy mu Max                2.6820574
Policy mu Min                -2.7269726
Policy log std Mean          -0.4855143
Policy log std Std           0.24522267
Policy log std Max           -0.024852633
Policy log std Min           -2.467192
Z mean eval                  1.7050524
Z variance eval              0.09448192
total_rewards                [8653.16417191 8191.78583263 8793.55862292 8733.481518   8818.76590684
 8798.24848307 8717.48609557 8864.71789551 8843.92545433 8909.30582322]
total_rewards_mean           8732.44398040007
total_rewards_std            193.78923132276046
total_rewards_max            8909.305823221206
total_rewards_min            8191.7858326297865
Number of train steps total  688000
Number of env steps total    2066000
Number of rollouts total     0
Train Time (s)               145.12360028736293
(Previous) Eval Time (s)     17.576523912139237
Sample Time (s)              6.44432009011507
Epoch Time (s)               169.14444428961724
Total Train Time (s)         29117.466860174667
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:58:56.239897 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #171 | Epoch Duration: 169.2357897758484
2020-01-12 15:58:56.240164 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.706785
Z variance train             0.09420597
KL Divergence                39.010014
KL Loss                      3.9010015
QF Loss                      108.08577
VF Loss                      56.964302
Policy Loss                  -1012.15857
Q Predictions Mean           1013.34033
Q Predictions Std            1064.8325
Q Predictions Max            3734.7783
Q Predictions Min            470.01334
V Predictions Mean           1013.3255
V Predictions Std            1059.7817
V Predictions Max            3713.7957
V Predictions Min            472.16
Log Pis Mean                 -0.6319942
Log Pis Std                  3.0129151
Log Pis Max                  10.336362
Log Pis Min                  -7.9501543
Policy mu Mean               -0.003745328
Policy mu Std                0.8164501
Policy mu Max                2.4558353
Policy mu Min                -2.3234966
Policy log std Mean          -0.49421227
Policy log std Std           0.2609263
Policy log std Max           -0.06880888
Policy log std Min           -2.427072
Z mean eval                  1.6682355
Z variance eval              0.06003164
total_rewards                [8377.95027439 8412.9917206  8492.48902766 8474.81419142 8686.04625457
 8650.74650746 8485.18638406 8620.08692774 8541.25718181 8582.5044903 ]
total_rewards_mean           8532.407296002064
total_rewards_std            96.51018872477731
total_rewards_max            8686.04625456935
total_rewards_min            8377.950274388246
Number of train steps total  692000
Number of env steps total    2078000
Number of rollouts total     0
Train Time (s)               144.63459149608389
(Previous) Eval Time (s)     20.807526072021574
Sample Time (s)              6.478848413564265
Epoch Time (s)               171.92096598166972
Total Train Time (s)         29289.479592790827
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:01:48.252105 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #172 | Epoch Duration: 172.01175665855408
2020-01-12 16:01:48.252250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6671692
Z variance train             0.06010034
KL Divergence                39.07331
KL Loss                      3.9073312
QF Loss                      218.5209
VF Loss                      59.68052
Policy Loss                  -1067.602
Q Predictions Mean           1065.636
Q Predictions Std            1091.7543
Q Predictions Max            3639.1086
Q Predictions Min            477.81512
V Predictions Mean           1071.2861
V Predictions Std            1091.6047
V Predictions Max            3646.7468
V Predictions Min            476.20978
Log Pis Mean                 -0.6094056
Log Pis Std                  3.657351
Log Pis Max                  18.121746
Log Pis Min                  -10.36287
Policy mu Mean               0.031787086
Policy mu Std                0.8510661
Policy mu Max                2.7436037
Policy mu Min                -3.6127958
Policy log std Mean          -0.48602223
Policy log std Std           0.24332404
Policy log std Max           -0.049574703
Policy log std Min           -2.0343928
Z mean eval                  1.6780691
Z variance eval              0.062889606
total_rewards                [8493.76380846 8803.50052567 8707.00051943 8541.49716024 8620.10012156
 8641.5397058  8753.3827365  8334.10530247 8642.85443628 8528.10379821]
total_rewards_mean           8606.584811460943
total_rewards_std            130.57490989875575
total_rewards_max            8803.500525665982
total_rewards_min            8334.105302474423
Number of train steps total  696000
Number of env steps total    2090000
Number of rollouts total     0
Train Time (s)               147.4393158662133
(Previous) Eval Time (s)     17.911498561967164
Sample Time (s)              6.306300093885511
Epoch Time (s)               171.65711452206597
Total Train Time (s)         29461.219214608893
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:04:39.999537 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #173 | Epoch Duration: 171.74715304374695
2020-01-12 16:04:39.999763 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6771953
Z variance train             0.06303736
KL Divergence                40.09716
KL Loss                      4.009716
QF Loss                      171.9212
VF Loss                      260.6278
Policy Loss                  -1093.9211
Q Predictions Mean           1094.0339
Q Predictions Std            1115.9945
Q Predictions Max            3843.4707
Q Predictions Min            477.94824
V Predictions Mean           1103.3811
V Predictions Std            1119.4736
V Predictions Max            3821.106
V Predictions Min            490.99857
Log Pis Mean                 -0.63847864
Log Pis Std                  3.3520322
Log Pis Max                  13.690289
Log Pis Min                  -8.105515
Policy mu Mean               0.05621764
Policy mu Std                0.8360838
Policy mu Max                2.6801543
Policy mu Min                -2.920197
Policy log std Mean          -0.5023609
Policy log std Std           0.2499272
Policy log std Max           -0.061777055
Policy log std Min           -2.141471
Z mean eval                  1.6952012
Z variance eval              0.08217262
total_rewards                [8994.79626886 8887.80253752 9007.1559942  8952.93364084 8779.99238509
 9049.43228975 8970.81669913 8779.14907914 8766.53432564 8869.16749198]
total_rewards_mean           8905.778071215484
total_rewards_std            99.096490162204
total_rewards_max            9049.432289747085
total_rewards_min            8766.5343256448
Number of train steps total  700000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               145.814381333068
(Previous) Eval Time (s)     18.041688065044582
Sample Time (s)              6.3963568159379065
Epoch Time (s)               170.2524262140505
Total Train Time (s)         29631.557638970204
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:07:30.338697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #174 | Epoch Duration: 170.33875370025635
2020-01-12 16:07:30.338867 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.699496
Z variance train             0.08201949
KL Divergence                40.458797
KL Loss                      4.04588
QF Loss                      2202.725
VF Loss                      43.693214
Policy Loss                  -989.17926
Q Predictions Mean           987.53174
Q Predictions Std            1031.5293
Q Predictions Max            3803.191
Q Predictions Min            479.6905
V Predictions Mean           986.94324
V Predictions Std            1029.3966
V Predictions Max            3798.5305
V Predictions Min            483.41013
Log Pis Mean                 -0.68058753
Log Pis Std                  3.3727345
Log Pis Max                  13.08857
Log Pis Min                  -6.8905516
Policy mu Mean               0.038336482
Policy mu Std                0.83896935
Policy mu Max                2.6149118
Policy mu Min                -2.573729
Policy log std Mean          -0.49962616
Policy log std Std           0.24840404
Policy log std Max           -0.09239374
Policy log std Min           -2.1204078
Z mean eval                  1.6692533
Z variance eval              0.046211023
total_rewards                [8333.73656886 8750.26098998 9034.47775155 8948.32172134 8102.27504625
 8743.94914796 8607.45412672 8698.87804488 8531.88960273 8972.09332575]
total_rewards_mean           8672.333632601772
total_rewards_std            277.96193297027963
total_rewards_max            9034.477751549268
total_rewards_min            8102.275046247401
Number of train steps total  704000
Number of env steps total    2114000
Number of rollouts total     0
Train Time (s)               147.14764814032242
(Previous) Eval Time (s)     17.547311436850578
Sample Time (s)              6.3446714375168085
Epoch Time (s)               171.0396310146898
Total Train Time (s)         29802.680935938843
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:10:21.463682 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #175 | Epoch Duration: 171.12469339370728
2020-01-12 16:10:21.463817 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6701155
Z variance train             0.0460886
KL Divergence                41.09267
KL Loss                      4.109267
QF Loss                      124.47223
VF Loss                      73.095665
Policy Loss                  -956.966
Q Predictions Mean           951.4667
Q Predictions Std            982.78516
Q Predictions Max            3790.957
Q Predictions Min            478.27386
V Predictions Mean           954.1848
V Predictions Std            982.9141
V Predictions Max            3777.9802
V Predictions Min            486.54233
Log Pis Mean                 -0.86854744
Log Pis Std                  3.6279929
Log Pis Max                  18.509642
Log Pis Min                  -8.219343
Policy mu Mean               0.03843839
Policy mu Std                0.8116225
Policy mu Max                2.5132086
Policy mu Min                -3.596787
Policy log std Mean          -0.48347154
Policy log std Std           0.2693095
Policy log std Max           -0.040167928
Policy log std Min           -2.158823
Z mean eval                  1.6875372
Z variance eval              0.081984885
total_rewards                [8439.33403788 8701.4236542  8834.11082476 8797.29582384 8694.45912375
 8570.34329271 8749.04885477 8712.35527044 8668.13716022 8705.15952461]
total_rewards_mean           8687.166756718527
total_rewards_std            106.86248504119249
total_rewards_max            8834.110824755706
total_rewards_min            8439.334037879886
Number of train steps total  708000
Number of env steps total    2126000
Number of rollouts total     0
Train Time (s)               146.53834656393155
(Previous) Eval Time (s)     17.39765392197296
Sample Time (s)              6.364318030420691
Epoch Time (s)               170.3003185163252
Total Train Time (s)         29973.064368319232
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:13:11.851123 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #176 | Epoch Duration: 170.38719606399536
2020-01-12 16:13:11.851307 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6870663
Z variance train             0.0821037
KL Divergence                39.30276
KL Loss                      3.9302762
QF Loss                      134.93512
VF Loss                      38.91426
Policy Loss                  -976.9003
Q Predictions Mean           974.7768
Q Predictions Std            992.91876
Q Predictions Max            3697.3428
Q Predictions Min            494.9932
V Predictions Mean           979.1826
V Predictions Std            993.11835
V Predictions Max            3699.1135
V Predictions Min            488.99396
Log Pis Mean                 -0.59026265
Log Pis Std                  3.3876312
Log Pis Max                  10.000638
Log Pis Min                  -7.647888
Policy mu Mean               0.08149911
Policy mu Std                0.8220604
Policy mu Max                2.6009073
Policy mu Min                -2.5139763
Policy log std Mean          -0.49613747
Policy log std Std           0.2510641
Policy log std Max           -0.054849803
Policy log std Min           -2.2915
Z mean eval                  1.6964394
Z variance eval              0.067754745
total_rewards                [8487.54192292 8404.53119327 8051.99293928 8442.23132165 8560.56940351
 8356.34996091 8678.5822314  8547.65228727 7992.68358381 8418.15471798]
total_rewards_mean           8394.028956199334
total_rewards_std            205.80412014956647
total_rewards_max            8678.582231395738
total_rewards_min            7992.683583807222
Number of train steps total  712000
Number of env steps total    2138000
Number of rollouts total     0
Train Time (s)               146.09187183436006
(Previous) Eval Time (s)     20.882548933383077
Sample Time (s)              6.350449597928673
Epoch Time (s)               173.3248703656718
Total Train Time (s)         30146.475852184463
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:16:05.263603 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #177 | Epoch Duration: 173.4121596813202
2020-01-12 16:16:05.263731 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6978409
Z variance train             0.06774948
KL Divergence                40.42994
KL Loss                      4.042994
QF Loss                      138.07967
VF Loss                      29.455578
Policy Loss                  -1188.4291
Q Predictions Mean           1186.4222
Q Predictions Std            1179.2341
Q Predictions Max            3747.4812
Q Predictions Min            495.2209
V Predictions Mean           1187.3906
V Predictions Std            1177.5553
V Predictions Max            3750.9885
V Predictions Min            504.87775
Log Pis Mean                 -0.32210502
Log Pis Std                  3.705509
Log Pis Max                  13.144321
Log Pis Min                  -8.604168
Policy mu Mean               0.04275152
Policy mu Std                0.8962559
Policy mu Max                2.7351732
Policy mu Min                -2.4133248
Policy log std Mean          -0.50958824
Policy log std Std           0.24450162
Policy log std Max           -0.108245075
Policy log std Min           -2.1293695
Z mean eval                  1.6942619
Z variance eval              0.09794376
total_rewards                [8632.95683872 8676.85682769 8846.70275567 8936.89101883 8814.78527627
 8655.71828775 8790.97966925 8984.45267754 8870.11069264 8885.57510328]
total_rewards_mean           8809.502914764484
total_rewards_std            114.22061292773593
total_rewards_max            8984.452677544608
total_rewards_min            8632.956838724718
Number of train steps total  716000
Number of env steps total    2150000
Number of rollouts total     0
Train Time (s)               146.35559205524623
(Previous) Eval Time (s)     20.77053590072319
Sample Time (s)              6.486894185654819
Epoch Time (s)               173.61302214162424
Total Train Time (s)         30320.169105020817
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:18:58.962791 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #178 | Epoch Duration: 173.69892239570618
2020-01-12 16:18:58.963072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6923759
Z variance train             0.09796882
KL Divergence                39.548027
KL Loss                      3.9548028
QF Loss                      61.839207
VF Loss                      34.932076
Policy Loss                  -999.14734
Q Predictions Mean           999.6631
Q Predictions Std            1043.4205
Q Predictions Max            3716.914
Q Predictions Min            490.51797
V Predictions Mean           1002.34155
V Predictions Std            1042.5122
V Predictions Max            3712.7183
V Predictions Min            492.71558
Log Pis Mean                 -0.6330274
Log Pis Std                  3.2349293
Log Pis Max                  12.966345
Log Pis Min                  -6.320859
Policy mu Mean               -0.0055714077
Policy mu Std                0.8329428
Policy mu Max                2.5080755
Policy mu Min                -2.821793
Policy log std Mean          -0.4750462
Policy log std Std           0.22285497
Policy log std Max           -0.10340795
Policy log std Min           -2.2282233
Z mean eval                  1.665493
Z variance eval              0.0717429
total_rewards                [8381.87379153 8549.96148071 8853.64190725 8527.36108798 9025.33989149
 8840.53107773 8804.64839396 8704.600654   8791.36482238 8661.75903721]
total_rewards_mean           8714.108214422427
total_rewards_std            179.3077905254657
total_rewards_max            9025.33989148942
total_rewards_min            8381.873791527078
Number of train steps total  720000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               146.66667354479432
(Previous) Eval Time (s)     21.00497518805787
Sample Time (s)              6.549058952834457
Epoch Time (s)               174.22070768568665
Total Train Time (s)         30494.485300237313
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:21:53.280360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #179 | Epoch Duration: 174.31706285476685
2020-01-12 16:21:53.280609 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6676804
Z variance train             0.07192029
KL Divergence                38.664013
KL Loss                      3.8664014
QF Loss                      163.47878
VF Loss                      63.28457
Policy Loss                  -999.7759
Q Predictions Mean           993.6079
Q Predictions Std            1031.436
Q Predictions Max            3866.0
Q Predictions Min            505.05972
V Predictions Mean           996.6956
V Predictions Std            1030.2202
V Predictions Max            3841.573
V Predictions Min            512.34106
Log Pis Mean                 -0.37884724
Log Pis Std                  3.5527956
Log Pis Max                  12.49021
Log Pis Min                  -6.804724
Policy mu Mean               0.040824775
Policy mu Std                0.87437457
Policy mu Max                3.037385
Policy mu Min                -2.5841727
Policy log std Mean          -0.4913896
Policy log std Std           0.24801785
Policy log std Max           -0.12252971
Policy log std Min           -2.3237867
Z mean eval                  1.6852986
Z variance eval              0.08071253
total_rewards                [8307.95503807 8588.03873402 8505.76663806 2710.04149442 8287.56850041
 8635.45374516 8374.33722866 8378.77664905 8664.99503136 8263.15127305]
total_rewards_mean           7871.608433226717
total_rewards_std            1726.1751648219597
total_rewards_max            8664.99503136222
total_rewards_min            2710.041494419003
Number of train steps total  724000
Number of env steps total    2174000
Number of rollouts total     0
Train Time (s)               147.2059444868937
(Previous) Eval Time (s)     17.471482718829066
Sample Time (s)              6.327668683603406
Epoch Time (s)               171.00509588932618
Total Train Time (s)         30665.56648411695
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:24:44.361942 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #180 | Epoch Duration: 171.08116483688354
2020-01-12 16:24:44.362068 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6831768
Z variance train             0.080553666
KL Divergence                39.089607
KL Loss                      3.9089608
QF Loss                      223.28995
VF Loss                      185.13126
Policy Loss                  -1074.1578
Q Predictions Mean           1074.1628
Q Predictions Std            1092.0956
Q Predictions Max            3709.9834
Q Predictions Min            481.3003
V Predictions Mean           1076.3568
V Predictions Std            1086.2292
V Predictions Max            3728.8147
V Predictions Min            479.9881
Log Pis Mean                 -0.031360164
Log Pis Std                  3.6914644
Log Pis Max                  14.1808405
Log Pis Min                  -7.292016
Policy mu Mean               0.06914342
Policy mu Std                0.88528514
Policy mu Max                2.8421896
Policy mu Min                -3.7197642
Policy log std Mean          -0.505972
Policy log std Std           0.27387154
Policy log std Max           -0.040644944
Policy log std Min           -2.1336203
Z mean eval                  1.6642364
Z variance eval              0.07359573
total_rewards                [8071.77297664 8645.21069709 8616.77793377 8133.30952114 8909.45257923
 8494.54120956 8931.40190433 8867.6406523  8492.38885446 8651.72305269]
total_rewards_mean           8581.421938122372
total_rewards_std            282.54105589875655
total_rewards_max            8931.401904331064
total_rewards_min            8071.772976637262
Number of train steps total  728000
Number of env steps total    2186000
Number of rollouts total     0
Train Time (s)               146.1806647819467
(Previous) Eval Time (s)     17.724677585996687
Sample Time (s)              5.538220029789954
Epoch Time (s)               169.44356239773333
Total Train Time (s)         30835.091072749812
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:27:33.889254 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #181 | Epoch Duration: 169.52707433700562
2020-01-12 16:27:33.889432 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.666394
Z variance train             0.07386148
KL Divergence                38.181942
KL Loss                      3.8181942
QF Loss                      88.28792
VF Loss                      117.02282
Policy Loss                  -988.9998
Q Predictions Mean           989.24805
Q Predictions Std            1027.7803
Q Predictions Max            3847.2217
Q Predictions Min            500.704
V Predictions Mean           996.5965
V Predictions Std            1031.8088
V Predictions Max            3856.3242
V Predictions Min            501.0525
Log Pis Mean                 -0.35387734
Log Pis Std                  3.3473692
Log Pis Max                  10.734791
Log Pis Min                  -6.961877
Policy mu Mean               0.070555635
Policy mu Std                0.8689796
Policy mu Max                3.0094094
Policy mu Min                -2.5190241
Policy log std Mean          -0.4791762
Policy log std Std           0.23633948
Policy log std Max           -0.08435693
Policy log std Min           -1.9202514
Z mean eval                  1.6807957
Z variance eval              0.064743124
total_rewards                [8706.59883502 8771.12533754 8990.24525982 8800.47538849 8815.26327129
 8713.48342967 8809.10891983 8779.53177383 8965.91448974 8779.91740545]
total_rewards_mean           8813.166411068467
total_rewards_std            89.53680719700253
total_rewards_max            8990.245259819143
total_rewards_min            8706.598835023608
Number of train steps total  732000
Number of env steps total    2198000
Number of rollouts total     0
Train Time (s)               149.24344892520458
(Previous) Eval Time (s)     17.857403772883117
Sample Time (s)              6.533390552736819
Epoch Time (s)               173.6342432508245
Total Train Time (s)         31008.819211825263
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:30:27.620311 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #182 | Epoch Duration: 173.7307367324829
2020-01-12 16:30:27.620498 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6829824
Z variance train             0.06493826
KL Divergence                39.348465
KL Loss                      3.9348466
QF Loss                      123.732704
VF Loss                      142.9529
Policy Loss                  -1080.3712
Q Predictions Mean           1080.1722
Q Predictions Std            1101.5328
Q Predictions Max            3815.661
Q Predictions Min            478.71362
V Predictions Mean           1083.5515
V Predictions Std            1096.1123
V Predictions Max            3804.0725
V Predictions Min            498.78085
Log Pis Mean                 -0.40878057
Log Pis Std                  3.5061734
Log Pis Max                  11.946826
Log Pis Min                  -8.707611
Policy mu Mean               0.11593282
Policy mu Std                0.88142234
Policy mu Max                2.5572546
Policy mu Min                -3.1984022
Policy log std Mean          -0.499899
Policy log std Std           0.25807902
Policy log std Max           -0.076355815
Policy log std Min           -2.2470255
Z mean eval                  1.7054663
Z variance eval              0.06387605
total_rewards                [8609.04569985 8540.91817057 8834.56172915 8796.34900845 8505.38756551
 8575.07879459 8312.59609099 8686.11627069 8478.85044974 5108.41324401]
total_rewards_mean           8244.73170235509
total_rewards_std            1055.4825379121958
total_rewards_max            8834.561729151344
total_rewards_min            5108.413244013979
Number of train steps total  736000
Number of env steps total    2210000
Number of rollouts total     0
Train Time (s)               146.43098805705085
(Previous) Eval Time (s)     20.93689208989963
Sample Time (s)              6.604247314855456
Epoch Time (s)               173.97212746180594
Total Train Time (s)         31182.87598949764
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:33:21.678286 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #183 | Epoch Duration: 174.0576560497284
2020-01-12 16:33:21.678429 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7065881
Z variance train             0.06390907
KL Divergence                39.776844
KL Loss                      3.9776845
QF Loss                      4888.587
VF Loss                      48.15546
Policy Loss                  -1006.6428
Q Predictions Mean           1007.22797
Q Predictions Std            1046.6392
Q Predictions Max            3801.2883
Q Predictions Min            511.84335
V Predictions Mean           1009.0315
V Predictions Std            1041.226
V Predictions Max            3775.3562
V Predictions Min            513.9399
Log Pis Mean                 -0.68028575
Log Pis Std                  3.4260874
Log Pis Max                  10.661764
Log Pis Min                  -7.1725845
Policy mu Mean               0.007901371
Policy mu Std                0.82892424
Policy mu Max                2.9780633
Policy mu Min                -3.4027102
Policy log std Mean          -0.47880825
Policy log std Std           0.2370721
Policy log std Max           0.02617824
Policy log std Min           -1.8947015
Z mean eval                  1.6658407
Z variance eval              0.07405462
total_rewards                [8551.77222059 8900.15261778 8753.70547601 8826.49185518 8678.45074752
 8884.72119487 9010.04493606 8648.13219382 8866.12390708 8492.95586875]
total_rewards_mean           8761.255101766921
total_rewards_std            157.24629860340355
total_rewards_max            9010.044936057562
total_rewards_min            8492.955868752744
Number of train steps total  740000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               146.44592164317146
(Previous) Eval Time (s)     20.677749255672097
Sample Time (s)              6.5903394902125
Epoch Time (s)               173.71401038905606
Total Train Time (s)         31356.66955866618
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:36:15.473873 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #184 | Epoch Duration: 173.79534792900085
2020-01-12 16:36:15.474004 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6681888
Z variance train             0.074279994
KL Divergence                39.36576
KL Loss                      3.9365761
QF Loss                      115.72508
VF Loss                      156.89676
Policy Loss                  -1058.6951
Q Predictions Mean           1059.3735
Q Predictions Std            1089.0216
Q Predictions Max            3764.249
Q Predictions Min            477.86212
V Predictions Mean           1065.9973
V Predictions Std            1090.9125
V Predictions Max            3784.62
V Predictions Min            493.19843
Log Pis Mean                 -0.26908827
Log Pis Std                  3.6085756
Log Pis Max                  18.669975
Log Pis Min                  -7.5180674
Policy mu Mean               0.121090375
Policy mu Std                0.852294
Policy mu Max                2.666929
Policy mu Min                -3.775427
Policy log std Mean          -0.5035259
Policy log std Std           0.2531225
Policy log std Max           -0.025385618
Policy log std Min           -2.2420769
Z mean eval                  1.6881678
Z variance eval              0.0752055
total_rewards                [8960.7718307  8891.70750301 8975.32849256 9165.19634514 9073.00157654
 9133.3876182  9064.66258784 9015.89149942 9110.71160039 8898.28628901]
total_rewards_mean           9028.894534281313
total_rewards_std            91.08990236879298
total_rewards_max            9165.196345138613
total_rewards_min            8891.70750301241
Number of train steps total  744000
Number of env steps total    2234000
Number of rollouts total     0
Train Time (s)               146.0289580952376
(Previous) Eval Time (s)     20.61761238798499
Sample Time (s)              6.599296495318413
Epoch Time (s)               173.24586697854102
Total Train Time (s)         31529.99859035015
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:39:08.804063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #185 | Epoch Duration: 173.32996201515198
2020-01-12 16:39:08.804216 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6929147
Z variance train             0.07503499
KL Divergence                40.433067
KL Loss                      4.043307
QF Loss                      107.75513
VF Loss                      77.071236
Policy Loss                  -1160.8866
Q Predictions Mean           1159.7887
Q Predictions Std            1187.3699
Q Predictions Max            3895.4338
Q Predictions Min            508.6103
V Predictions Mean           1156.3226
V Predictions Std            1179.4282
V Predictions Max            3851.3083
V Predictions Min            510.72162
Log Pis Mean                 -0.12497142
Log Pis Std                  4.0862308
Log Pis Max                  14.847245
Log Pis Min                  -7.8579445
Policy mu Mean               0.034792468
Policy mu Std                0.89092773
Policy mu Max                2.8521965
Policy mu Min                -3.0593386
Policy log std Mean          -0.5130408
Policy log std Std           0.2736389
Policy log std Max           0.053883433
Policy log std Min           -2.652573
Z mean eval                  1.6832106
Z variance eval              0.044726856
total_rewards                [9127.28107347 9217.31309368 9381.53577756 9228.52926014 9224.72640406
 9374.82394744 8873.76168263 9323.7496019  9134.47222852 9045.91052268]
total_rewards_mean           9193.210359207356
total_rewards_std            148.27461606291993
total_rewards_max            9381.535777556284
total_rewards_min            8873.761682633372
Number of train steps total  748000
Number of env steps total    2246000
Number of rollouts total     0
Train Time (s)               146.69075849512592
(Previous) Eval Time (s)     17.503177902661264
Sample Time (s)              6.564194628037512
Epoch Time (s)               170.7581310258247
Total Train Time (s)         31700.83462200174
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:41:59.642702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #186 | Epoch Duration: 170.83836913108826
2020-01-12 16:41:59.642883 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6812952
Z variance train             0.044778105
KL Divergence                40.98622
KL Loss                      4.0986223
QF Loss                      120.175
VF Loss                      71.116554
Policy Loss                  -971.51263
Q Predictions Mean           965.75305
Q Predictions Std            1000.7689
Q Predictions Max            3814.5374
Q Predictions Min            490.57425
V Predictions Mean           968.2259
V Predictions Std            998.333
V Predictions Max            3797.3052
V Predictions Min            497.30133
Log Pis Mean                 -0.24333163
Log Pis Std                  3.7976022
Log Pis Max                  13.078165
Log Pis Min                  -8.25565
Policy mu Mean               0.07299315
Policy mu Std                0.8828938
Policy mu Max                2.7121458
Policy mu Min                -3.1922593
Policy log std Mean          -0.5220061
Policy log std Std           0.28319255
Policy log std Max           -0.08892533
Policy log std Min           -2.6927388
Z mean eval                  1.6982969
Z variance eval              0.073754236
total_rewards                [8729.11549421 8855.43115109 8534.85000619 8831.61565705 8747.45175516
 8842.92723104 8770.72902408 8771.01114152 8901.01092031 8798.67341147]
total_rewards_mean           8778.28157921226
total_rewards_std            95.49375458707605
total_rewards_max            8901.010920314637
total_rewards_min            8534.850006192728
Number of train steps total  752000
Number of env steps total    2258000
Number of rollouts total     0
Train Time (s)               146.2334445733577
(Previous) Eval Time (s)     20.514015895780176
Sample Time (s)              6.6737998547032475
Epoch Time (s)               173.42126032384112
Total Train Time (s)         31874.334378214553
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:44:53.143604 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #187 | Epoch Duration: 173.50058937072754
2020-01-12 16:44:53.143743 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.69918
Z variance train             0.07376666
KL Divergence                42.022305
KL Loss                      4.2022305
QF Loss                      203.33348
VF Loss                      58.304123
Policy Loss                  -1030.2057
Q Predictions Mean           1028.2969
Q Predictions Std            1052.1324
Q Predictions Max            3857.9048
Q Predictions Min            514.5825
V Predictions Mean           1027.4722
V Predictions Std            1046.4413
V Predictions Max            3834.3877
V Predictions Min            508.94064
Log Pis Mean                 -0.41910595
Log Pis Std                  3.8669984
Log Pis Max                  30.93509
Log Pis Min                  -6.8133607
Policy mu Mean               0.07851252
Policy mu Std                0.8694224
Policy mu Max                3.6326108
Policy mu Min                -5.131987
Policy log std Mean          -0.5172955
Policy log std Std           0.282295
Policy log std Max           0.24783498
Policy log std Min           -2.7574666
Z mean eval                  1.7012974
Z variance eval              0.06981384
total_rewards                [9055.8527424  9227.38238675 9326.92775445 9275.0929231  9042.88766155
 9357.5628536  9187.13099104 9025.91320589 9145.90520355 8998.66282145]
total_rewards_mean           9164.331854376103
total_rewards_std            124.0970315032281
total_rewards_max            9357.562853595204
total_rewards_min            8998.662821447433
Number of train steps total  756000
Number of env steps total    2270000
Number of rollouts total     0
Train Time (s)               146.06117654778063
(Previous) Eval Time (s)     17.705133387818933
Sample Time (s)              6.505432340782136
Epoch Time (s)               170.2717422763817
Total Train Time (s)         32044.684192322195
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:47:43.496358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #188 | Epoch Duration: 170.35249853134155
2020-01-12 16:47:43.496534 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7033889
Z variance train             0.06980344
KL Divergence                42.23034
KL Loss                      4.223034
QF Loss                      180.09535
VF Loss                      54.474594
Policy Loss                  -1079.5981
Q Predictions Mean           1071.3921
Q Predictions Std            1086.5505
Q Predictions Max            3827.7783
Q Predictions Min            499.3461
V Predictions Mean           1075.8838
V Predictions Std            1088.7896
V Predictions Max            3827.151
V Predictions Min            501.15488
Log Pis Mean                 -0.1831907
Log Pis Std                  3.8747375
Log Pis Max                  15.6215725
Log Pis Min                  -6.2285876
Policy mu Mean               0.019477552
Policy mu Std                0.9053817
Policy mu Max                3.1374824
Policy mu Min                -3.2183952
Policy log std Mean          -0.5156011
Policy log std Std           0.27503237
Policy log std Max           -0.07646938
Policy log std Min           -2.2903826
Z mean eval                  1.6967999
Z variance eval              0.07256846
total_rewards                [8055.87149681 8438.19148796 7923.94645699 8513.50889405 8402.25122365
 8342.48249914 8283.66198916 8091.45583201 8566.28655266 8177.85165204]
total_rewards_mean           8279.550808447138
total_rewards_std            200.83890490163424
total_rewards_max            8566.286552657562
total_rewards_min            7923.9464569894135
Number of train steps total  760000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               145.58566031977534
(Previous) Eval Time (s)     20.964581673964858
Sample Time (s)              6.614951249677688
Epoch Time (s)               173.1651932434179
Total Train Time (s)         32217.93081958685
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:50:36.743347 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #189 | Epoch Duration: 173.24668431282043
2020-01-12 16:50:36.743489 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.696228
Z variance train             0.072551355
KL Divergence                42.545883
KL Loss                      4.2545886
QF Loss                      4958.597
VF Loss                      58.29444
Policy Loss                  -1021.5836
Q Predictions Mean           1021.991
Q Predictions Std            1050.3866
Q Predictions Max            3894.7454
Q Predictions Min            499.67386
V Predictions Mean           1025.7759
V Predictions Std            1047.016
V Predictions Max            3896.5864
V Predictions Min            511.02496
Log Pis Mean                 -0.86824906
Log Pis Std                  3.1057398
Log Pis Max                  11.126255
Log Pis Min                  -7.6991215
Policy mu Mean               0.03502843
Policy mu Std                0.8167613
Policy mu Max                2.6623375
Policy mu Min                -2.4730887
Policy log std Mean          -0.4988329
Policy log std Std           0.24804287
Policy log std Max           -0.11597058
Policy log std Min           -2.2328906
Z mean eval                  1.7131548
Z variance eval              0.08508169
total_rewards                [8744.03473491 9010.82991797 9198.84992993 9036.29581483 9028.87370554
 9055.00217434 9186.43438188 9279.97704646 9036.0440885  9127.85564615]
total_rewards_mean           9070.419744051094
total_rewards_std            138.4033522907744
total_rewards_max            9279.977046456052
total_rewards_min            8744.034734910481
Number of train steps total  764000
Number of env steps total    2294000
Number of rollouts total     0
Train Time (s)               146.3015253241174
(Previous) Eval Time (s)     20.888772434089333
Sample Time (s)              6.453080204315484
Epoch Time (s)               173.6433779625222
Total Train Time (s)         32391.86983862752
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:53:30.684624 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #190 | Epoch Duration: 173.94103336334229
2020-01-12 16:53:30.684769 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7122301
Z variance train             0.085130155
KL Divergence                43.088146
KL Loss                      4.3088145
QF Loss                      111.17697
VF Loss                      73.83535
Policy Loss                  -1075.9713
Q Predictions Mean           1074.2484
Q Predictions Std            1101.0171
Q Predictions Max            3814.6982
Q Predictions Min            524.4989
V Predictions Mean           1079.4575
V Predictions Std            1099.6755
V Predictions Max            3809.6775
V Predictions Min            531.6801
Log Pis Mean                 -0.4649627
Log Pis Std                  3.5166104
Log Pis Max                  13.519795
Log Pis Min                  -7.2708373
Policy mu Mean               0.100054145
Policy mu Std                0.8456689
Policy mu Max                3.5056214
Policy mu Min                -2.8714228
Policy log std Mean          -0.49662375
Policy log std Std           0.26584595
Policy log std Max           -0.06025821
Policy log std Min           -2.2817042
Z mean eval                  1.7108405
Z variance eval              0.09768604
total_rewards                [9064.96492276 8843.84718069 9080.48177216 7849.36996687 8888.08364186
 8996.29248104 8447.2173203  8684.48798925 8790.55424429 8933.08400103]
total_rewards_mean           8757.838352024508
total_rewards_std            351.9387883956527
total_rewards_max            9080.481772161405
total_rewards_min            7849.369966873522
Number of train steps total  768000
Number of env steps total    2306000
Number of rollouts total     0
Train Time (s)               147.20914561674
(Previous) Eval Time (s)     20.798536719288677
Sample Time (s)              6.364354544319212
Epoch Time (s)               174.37203688034788
Total Train Time (s)         32566.33170265844
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:56:25.148654 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #191 | Epoch Duration: 174.46378540992737
2020-01-12 16:56:25.148788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.71293
Z variance train             0.09752443
KL Divergence                42.328804
KL Loss                      4.2328806
QF Loss                      109.03102
VF Loss                      39.30071
Policy Loss                  -1110.9706
Q Predictions Mean           1106.7029
Q Predictions Std            1111.5198
Q Predictions Max            3931.006
Q Predictions Min            515.82495
V Predictions Mean           1107.3689
V Predictions Std            1111.3822
V Predictions Max            3916.4011
V Predictions Min            520.30457
Log Pis Mean                 -0.6646637
Log Pis Std                  3.3591914
Log Pis Max                  11.680065
Log Pis Min                  -8.9846525
Policy mu Mean               0.059820037
Policy mu Std                0.846148
Policy mu Max                2.658929
Policy mu Min                -2.3936138
Policy log std Mean          -0.5142879
Policy log std Std           0.2466024
Policy log std Max           -0.031241536
Policy log std Min           -2.1553342
Z mean eval                  1.7075217
Z variance eval              0.09866415
total_rewards                [8667.54094963 2007.01678196 8769.71225676 8387.94578415 7955.34924932
 8181.82273449 8718.43459239 8195.27034475 8292.11266287 8110.82876064]
total_rewards_mean           7728.6034116968485
total_rewards_std            1924.962372848213
total_rewards_max            8769.712256763962
total_rewards_min            2007.016781955846
Number of train steps total  772000
Number of env steps total    2318000
Number of rollouts total     0
Train Time (s)               146.4284183094278
(Previous) Eval Time (s)     17.65025059087202
Sample Time (s)              6.390867673326284
Epoch Time (s)               170.4695365736261
Total Train Time (s)         32736.881064675283
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:59:15.700638 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #192 | Epoch Duration: 170.5517373085022
2020-01-12 16:59:15.700818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7113688
Z variance train             0.098663405
KL Divergence                42.053387
KL Loss                      4.205339
QF Loss                      2416.602
VF Loss                      126.08724
Policy Loss                  -1095.1356
Q Predictions Mean           1092.9553
Q Predictions Std            1130.604
Q Predictions Max            3909.1145
Q Predictions Min            508.8816
V Predictions Mean           1088.1948
V Predictions Std            1122.0159
V Predictions Max            3873.28
V Predictions Min            511.42462
Log Pis Mean                 -0.4339831
Log Pis Std                  3.5144646
Log Pis Max                  9.88088
Log Pis Min                  -7.5665216
Policy mu Mean               0.032218274
Policy mu Std                0.86186385
Policy mu Max                2.7161193
Policy mu Min                -2.4632177
Policy log std Mean          -0.5085588
Policy log std Std           0.2539084
Policy log std Max           -0.07049793
Policy log std Min           -2.5394394
Z mean eval                  1.6939878
Z variance eval              0.09998199
total_rewards                [8863.46816519 8971.66166663 9121.9370417  8719.17578061 8961.05348493
 8976.56614979 8960.71069964 9074.09421537 8864.30037384 9004.72990286]
total_rewards_mean           8951.76974805636
total_rewards_std            108.37419163692454
total_rewards_max            9121.937041702251
total_rewards_min            8719.175780609427
Number of train steps total  776000
Number of env steps total    2330000
Number of rollouts total     0
Train Time (s)               146.1112747597508
(Previous) Eval Time (s)     17.79670001938939
Sample Time (s)              6.5550921922549605
Epoch Time (s)               170.46306697139516
Total Train Time (s)         32907.42897571856
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:02:06.251603 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #193 | Epoch Duration: 170.55057764053345
2020-01-12 17:02:06.251878 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #193 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6941035
Z variance train             0.10006094
KL Divergence                41.76322
KL Loss                      4.1763225
QF Loss                      146.84152
VF Loss                      78.51757
Policy Loss                  -1092.3801
Q Predictions Mean           1089.6675
Q Predictions Std            1116.3761
Q Predictions Max            3844.5835
Q Predictions Min            509.43054
V Predictions Mean           1090.3726
V Predictions Std            1113.3141
V Predictions Max            3827.8677
V Predictions Min            510.29926
Log Pis Mean                 -0.6024409
Log Pis Std                  3.4898708
Log Pis Max                  14.074636
Log Pis Min                  -6.2672963
Policy mu Mean               0.04730612
Policy mu Std                0.83883363
Policy mu Max                3.1972768
Policy mu Min                -2.6674995
Policy log std Mean          -0.519337
Policy log std Std           0.27979717
Policy log std Max           -0.07951045
Policy log std Min           -2.7826838
Z mean eval                  1.687499
Z variance eval              0.09934179
total_rewards                [8948.24573182 9311.46456939 9349.55976587 9249.90585742 9321.7475005
 8986.36302182 9233.56369099 9122.57513271  940.2629385  9054.11324564]
total_rewards_mean           8351.780145463623
total_rewards_std            2474.2275092983887
total_rewards_max            9349.55976586637
total_rewards_min            940.2629384956426
Number of train steps total  780000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               146.29665383836254
(Previous) Eval Time (s)     20.944590090774
Sample Time (s)              6.55358438519761
Epoch Time (s)               173.79482831433415
Total Train Time (s)         33081.30736576766
Epoch                        194
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:05:00.131973 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #194 | Epoch Duration: 173.879900932312
2020-01-12 17:05:00.132162 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6905864
Z variance train             0.09944467
KL Divergence                42.120075
KL Loss                      4.2120075
QF Loss                      131.38678
VF Loss                      150.87064
Policy Loss                  -1126.9905
Q Predictions Mean           1123.0107
Q Predictions Std            1117.5967
Q Predictions Max            3954.2698
Q Predictions Min            522.7745
V Predictions Mean           1121.9597
V Predictions Std            1113.3804
V Predictions Max            3896.791
V Predictions Min            509.06122
Log Pis Mean                 -0.33159247
Log Pis Std                  3.605218
Log Pis Max                  12.687901
Log Pis Min                  -7.418553
Policy mu Mean               0.044152368
Policy mu Std                0.85397077
Policy mu Max                2.7186706
Policy mu Min                -3.1039262
Policy log std Mean          -0.5266972
Policy log std Std           0.26946068
Policy log std Max           -0.10856207
Policy log std Min           -2.5221846
Z mean eval                  1.6858763
Z variance eval              0.09752665
total_rewards                [8598.15088834 8791.00557521 8514.59404653 8650.23633292 8925.93605988
 8882.93467989 8755.42190292 8783.56037741 8841.11109079 8696.02344304]
total_rewards_mean           8743.897439692844
total_rewards_std            122.77274595711228
total_rewards_max            8925.936059875186
total_rewards_min            8514.594046525977
Number of train steps total  784000
Number of env steps total    2354000
Number of rollouts total     0
Train Time (s)               145.39813102781773
(Previous) Eval Time (s)     20.768622654955834
Sample Time (s)              6.4320673337206244
Epoch Time (s)               172.59882101649418
Total Train Time (s)         33254.1308147884
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:07:52.968422 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #195 | Epoch Duration: 172.8360824584961
2020-01-12 17:07:52.968644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6869322
Z variance train             0.09857558
KL Divergence                41.740486
KL Loss                      4.174049
QF Loss                      2655.0027
VF Loss                      236.94188
Policy Loss                  -994.03394
Q Predictions Mean           990.6623
Q Predictions Std            1011.4478
Q Predictions Max            3822.3179
Q Predictions Min            508.60336
V Predictions Mean           983.782
V Predictions Std            1001.33344
V Predictions Max            3789.1675
V Predictions Min            504.4289
Log Pis Mean                 -0.41232193
Log Pis Std                  3.2441995
Log Pis Max                  14.015472
Log Pis Min                  -5.7023067
Policy mu Mean               0.065329485
Policy mu Std                0.8528315
Policy mu Max                2.5796323
Policy mu Min                -2.3421009
Policy log std Mean          -0.51113415
Policy log std Std           0.25445306
Policy log std Max           -0.06577748
Policy log std Min           -2.3574493
Z mean eval                  1.6972668
Z variance eval              0.072154336
total_rewards                [9084.05034776 9289.10403729 9106.24619919 9036.86696754 8879.08527931
 8804.35633206 8997.89068029 9159.0003147  9311.77155369 8876.99261705]
total_rewards_mean           9054.536432886644
total_rewards_std            162.50092002550923
total_rewards_max            9311.771553689257
total_rewards_min            8804.35633205933
Number of train steps total  788000
Number of env steps total    2366000
Number of rollouts total     0
Train Time (s)               145.12612400529906
(Previous) Eval Time (s)     20.77337004803121
Sample Time (s)              6.528977301903069
Epoch Time (s)               172.42847135523334
Total Train Time (s)         33426.66569200717
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:10:45.501788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #196 | Epoch Duration: 172.5330033302307
2020-01-12 17:10:45.501984 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #196 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.697056
Z variance train             0.0721449
KL Divergence                42.3384
KL Loss                      4.2338405
QF Loss                      127.26834
VF Loss                      49.471657
Policy Loss                  -1068.5692
Q Predictions Mean           1069.5156
Q Predictions Std            1107.2277
Q Predictions Max            3961.0647
Q Predictions Min            508.89404
V Predictions Mean           1073.2957
V Predictions Std            1105.42
V Predictions Max            3974.995
V Predictions Min            529.3073
Log Pis Mean                 -0.36789978
Log Pis Std                  3.3500416
Log Pis Max                  10.806175
Log Pis Min                  -6.775489
Policy mu Mean               0.06737876
Policy mu Std                0.8642825
Policy mu Max                2.5811691
Policy mu Min                -2.7266467
Policy log std Mean          -0.504394
Policy log std Std           0.25166667
Policy log std Max           0.14978456
Policy log std Min           -2.1345081
Z mean eval                  1.7132845
Z variance eval              0.046563752
total_rewards                [9400.63277713 9239.78458436 9127.05388018 9475.27252825 9140.4557224
 9390.94268946 9268.3348912  9313.07617424 9484.31704902 9369.31508886]
total_rewards_mean           9320.918538510361
total_rewards_std            119.86817339661017
total_rewards_max            9484.317049021536
total_rewards_min            9127.053880182466
Number of train steps total  792000
Number of env steps total    2378000
Number of rollouts total     0
Train Time (s)               146.23433418991044
(Previous) Eval Time (s)     17.264515683054924
Sample Time (s)              6.498865949455649
Epoch Time (s)               169.99771582242101
Total Train Time (s)         33596.77547014784
Epoch                        197
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:13:35.605472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #197 | Epoch Duration: 170.10334062576294
2020-01-12 17:13:35.605644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7101166
Z variance train             0.046656154
KL Divergence                43.33781
KL Loss                      4.3337812
QF Loss                      155.17923
VF Loss                      67.90176
Policy Loss                  -1132.5665
Q Predictions Mean           1129.8606
Q Predictions Std            1136.9994
Q Predictions Max            3843.9482
Q Predictions Min            523.76807
V Predictions Mean           1134.732
V Predictions Std            1139.3578
V Predictions Max            3858.0635
V Predictions Min            518.5453
Log Pis Mean                 -0.20544933
Log Pis Std                  3.8032186
Log Pis Max                  16.528885
Log Pis Min                  -7.123689
Policy mu Mean               0.04097895
Policy mu Std                0.8869602
Policy mu Max                2.7028778
Policy mu Min                -3.1180735
Policy log std Mean          -0.50919896
Policy log std Std           0.25642294
Policy log std Max           -0.016150653
Policy log std Min           -2.4187155
Z mean eval                  1.7298286
Z variance eval              0.034972824
total_rewards                [8885.23527284 9062.23051812 8762.77357894 9080.35799275 8959.74715058
 9061.72889101 9076.00596579 9088.36798266 8815.36808447 8881.20348039]
total_rewards_mean           8967.30189175462
total_rewards_std            116.74922328420581
total_rewards_max            9088.36798265947
total_rewards_min            8762.773578941942
Number of train steps total  796000
Number of env steps total    2390000
Number of rollouts total     0
Train Time (s)               146.79004019405693
(Previous) Eval Time (s)     17.642449305858463
Sample Time (s)              5.566497159190476
Epoch Time (s)               169.99898665910587
Total Train Time (s)         33766.861504524015
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:16:25.700630 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #198 | Epoch Duration: 170.0948028564453
2020-01-12 17:16:25.700950 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #198 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.730148
Z variance train             0.03510184
KL Divergence                45.136093
KL Loss                      4.5136094
QF Loss                      2917.624
VF Loss                      51.886482
Policy Loss                  -1137.0054
Q Predictions Mean           1135.0513
Q Predictions Std            1146.0348
Q Predictions Max            3960.175
Q Predictions Min            509.89648
V Predictions Mean           1136.6287
V Predictions Std            1141.7587
V Predictions Max            3940.1152
V Predictions Min            514.72577
Log Pis Mean                 -0.1736877
Log Pis Std                  3.6384394
Log Pis Max                  12.312453
Log Pis Min                  -7.2218714
Policy mu Mean               0.09689351
Policy mu Std                0.89153004
Policy mu Max                2.5628476
Policy mu Min                -2.536098
Policy log std Mean          -0.51021296
Policy log std Std           0.26506257
Policy log std Max           0.101284266
Policy log std Min           -2.5537746
Z mean eval                  1.6934904
Z variance eval              0.06726597
total_rewards                [9035.13707719 9060.57770612 9034.11948595 8896.19638665 8929.130574
 8953.68668346 9145.33438515 9123.97715044 9074.90246392 9182.21775596]
total_rewards_mean           9043.527966883248
total_rewards_std            89.64946680287748
total_rewards_max            9182.217755956162
total_rewards_min            8896.196386653877
Number of train steps total  800000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               147.95308530004695
(Previous) Eval Time (s)     20.543671780265868
Sample Time (s)              6.628586707636714
Epoch Time (s)               175.12534378794953
Total Train Time (s)         33942.07764771301
Epoch                        199
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:19:20.915157 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #199 | Epoch Duration: 175.21397614479065
2020-01-12 17:19:20.915330 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6934481
Z variance train             0.06693025
KL Divergence                42.637115
KL Loss                      4.2637115
QF Loss                      90.05505
VF Loss                      40.932335
Policy Loss                  -1032.6726
Q Predictions Mean           1031.0654
Q Predictions Std            1054.4419
Q Predictions Max            3895.7703
Q Predictions Min            511.85114
V Predictions Mean           1030.1371
V Predictions Std            1050.9147
V Predictions Max            3871.3066
V Predictions Min            513.6952
Log Pis Mean                 -0.6363443
Log Pis Std                  3.189686
Log Pis Max                  10.824417
Log Pis Min                  -7.319549
Policy mu Mean               0.027788669
Policy mu Std                0.83063024
Policy mu Max                2.7241476
Policy mu Min                -2.7460096
Policy log std Mean          -0.5051399
Policy log std Std           0.2380272
Policy log std Max           -0.10197112
Policy log std Min           -2.2224302
Z mean eval                  1.7046881
Z variance eval              0.07738371
total_rewards                [8635.62865008 9180.35615152 8836.09541041 8560.40554791 8690.61258751
 9056.37352271 8733.50789677 8936.39478769 9041.83369063 9179.53014864]
total_rewards_mean           8885.073839388815
total_rewards_std            214.77102598417872
total_rewards_max            9180.356151517468
total_rewards_min            8560.405547914112
Number of train steps total  804000
Number of env steps total    2414000
Number of rollouts total     0
Train Time (s)               146.65308483038098
(Previous) Eval Time (s)     20.704933612141758
Sample Time (s)              6.581762968562543
Epoch Time (s)               173.93978141108528
Total Train Time (s)         34116.114224698395
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:22:14.952907 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #200 | Epoch Duration: 174.0374550819397
2020-01-12 17:22:14.953039 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #200 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7025543
Z variance train             0.077754855
KL Divergence                43.079063
KL Loss                      4.3079066
QF Loss                      262.73804
VF Loss                      115.987
Policy Loss                  -1062.7311
Q Predictions Mean           1060.2556
Q Predictions Std            1111.2787
Q Predictions Max            3966.4458
Q Predictions Min            505.7833
V Predictions Mean           1065.2811
V Predictions Std            1105.2432
V Predictions Max            3951.12
V Predictions Min            513.8231
Log Pis Mean                 -0.25854868
Log Pis Std                  3.3496912
Log Pis Max                  13.916698
Log Pis Min                  -6.3010397
Policy mu Mean               0.030226903
Policy mu Std                0.8847779
Policy mu Max                2.7222977
Policy mu Min                -2.9807284
Policy log std Mean          -0.5126122
Policy log std Std           0.25592157
Policy log std Max           0.027311087
Policy log std Min           -2.2823534
Z mean eval                  1.7027302
Z variance eval              0.08439375
total_rewards                [9256.29474799 8722.04319239 9008.89110593 9374.49495664 9181.3014047
 9123.07689693 9025.04572697 9247.19248194 9205.59880837 9356.76608279]
total_rewards_mean           9150.070540465571
total_rewards_std            183.67451625353428
total_rewards_max            9374.494956637676
total_rewards_min            8722.043192387528
Number of train steps total  808000
Number of env steps total    2426000
Number of rollouts total     0
Train Time (s)               146.6006886921823
(Previous) Eval Time (s)     20.985144505277276
Sample Time (s)              6.4868084019981325
Epoch Time (s)               174.0726415994577
Total Train Time (s)         34290.268560175784
Epoch                        201
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:25:09.109703 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #201 | Epoch Duration: 174.15656805038452
2020-01-12 17:25:09.109835 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7040704
Z variance train             0.08433118
KL Divergence                43.038284
KL Loss                      4.3038287
QF Loss                      128.56938
VF Loss                      49.131824
Policy Loss                  -969.7598
Q Predictions Mean           967.71985
Q Predictions Std            1004.434
Q Predictions Max            3947.7324
Q Predictions Min            533.07764
V Predictions Mean           967.35486
V Predictions Std            1002.2098
V Predictions Max            3940.7803
V Predictions Min            538.7566
Log Pis Mean                 -0.77706933
Log Pis Std                  3.1419814
Log Pis Max                  11.614351
Log Pis Min                  -6.813018
Policy mu Mean               0.11206687
Policy mu Std                0.8236692
Policy mu Max                2.656862
Policy mu Min                -2.6422122
Policy log std Mean          -0.4997275
Policy log std Std           0.25389695
Policy log std Max           -0.03843385
Policy log std Min           -2.3095987
Z mean eval                  1.7314816
Z variance eval              0.05944872
total_rewards                [8962.89871386 9295.11216908 9079.80439342 9319.55555777 9181.30589408
 9211.80810827 8952.34715282 9023.32113935 9223.57665005 9001.13942716]
total_rewards_mean           9125.08692058484
total_rewards_std            130.77530522034843
total_rewards_max            9319.555557773198
total_rewards_min            8952.347152816446
Number of train steps total  812000
Number of env steps total    2438000
Number of rollouts total     0
Train Time (s)               146.30680440366268
(Previous) Eval Time (s)     17.450661988928914
Sample Time (s)              6.613486037123948
Epoch Time (s)               170.37095242971554
Total Train Time (s)         34460.71851816634
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:27:59.561807 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #202 | Epoch Duration: 170.4518575668335
2020-01-12 17:27:59.561984 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7280226
Z variance train             0.059491236
KL Divergence                43.006504
KL Loss                      4.3006506
QF Loss                      218.16162
VF Loss                      49.431828
Policy Loss                  -1145.1229
Q Predictions Mean           1143.084
Q Predictions Std            1154.9609
Q Predictions Max            3938.4329
Q Predictions Min            536.3683
V Predictions Mean           1149.331
V Predictions Std            1150.6135
V Predictions Max            3932.0867
V Predictions Min            536.6733
Log Pis Mean                 -0.23706186
Log Pis Std                  3.62566
Log Pis Max                  13.337173
Log Pis Min                  -6.336797
Policy mu Mean               0.055251688
Policy mu Std                0.87684625
Policy mu Max                2.6041398
Policy mu Min                -3.2638223
Policy log std Mean          -0.5313512
Policy log std Std           0.26353863
Policy log std Max           -0.07100195
Policy log std Min           -2.4740162
Z mean eval                  1.6924375
Z variance eval              0.08173929
total_rewards                [9387.12025017 9582.17877241 9427.4809419  9147.32953664 9358.40084674
 9426.93718343 9466.81209778 9280.15773839 9455.61685981 9345.18268605]
total_rewards_mean           9387.72169133243
total_rewards_std            111.27681166472821
total_rewards_max            9582.178772406234
total_rewards_min            9147.329536635338
Number of train steps total  816000
Number of env steps total    2450000
Number of rollouts total     0
Train Time (s)               146.11444965470582
(Previous) Eval Time (s)     20.962142202071846
Sample Time (s)              6.429278474766761
Epoch Time (s)               173.50587033154443
Total Train Time (s)         34634.30784211354
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:30:53.154419 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #203 | Epoch Duration: 173.59225368499756
2020-01-12 17:30:53.154777 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6925848
Z variance train             0.08170718
KL Divergence                41.83606
KL Loss                      4.183606
QF Loss                      2798.2761
VF Loss                      37.48662
Policy Loss                  -891.8705
Q Predictions Mean           889.69214
Q Predictions Std            887.7412
Q Predictions Max            3937.3062
Q Predictions Min            508.95593
V Predictions Mean           891.961
V Predictions Std            886.7543
V Predictions Max            3937.7725
V Predictions Min            503.5324
Log Pis Mean                 -0.3690133
Log Pis Std                  3.2065904
Log Pis Max                  13.994274
Log Pis Min                  -6.6884956
Policy mu Mean               0.117606424
Policy mu Std                0.81976503
Policy mu Max                2.6123426
Policy mu Min                -2.8047683
Policy log std Mean          -0.524576
Policy log std Std           0.26558673
Policy log std Max           -0.0017889738
Policy log std Min           -2.8540447
Z mean eval                  1.6903225
Z variance eval              0.05551973
total_rewards                [8800.95313272 9230.35869249 8869.4653431  9051.99564197 8954.59150072
 9118.55430205 9139.07371282 8960.47036955 9059.11963547 9010.17206148]
total_rewards_mean           9019.47543923861
total_rewards_std            122.16973620274265
total_rewards_max            9230.358692494017
total_rewards_min            8800.953132716475
Number of train steps total  820000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               146.2352784909308
(Previous) Eval Time (s)     20.68618691712618
Sample Time (s)              5.461730735376477
Epoch Time (s)               172.38319614343345
Total Train Time (s)         34806.86846993631
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:33:45.719645 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #204 | Epoch Duration: 172.56465578079224
2020-01-12 17:33:45.719865 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6906471
Z variance train             0.055423014
KL Divergence                40.743412
KL Loss                      4.0743413
QF Loss                      65.984024
VF Loss                      41.57206
Policy Loss                  -987.5015
Q Predictions Mean           985.16815
Q Predictions Std            1008.15546
Q Predictions Max            3896.6208
Q Predictions Min            526.492
V Predictions Mean           989.71826
V Predictions Std            1005.7356
V Predictions Max            3897.4631
V Predictions Min            531.1801
Log Pis Mean                 -0.5705572
Log Pis Std                  3.1791873
Log Pis Max                  12.076463
Log Pis Min                  -6.6921935
Policy mu Mean               0.04897066
Policy mu Std                0.8237012
Policy mu Max                2.8734207
Policy mu Min                -2.9739344
Policy log std Mean          -0.51332456
Policy log std Std           0.2759577
Policy log std Max           -0.06010151
Policy log std Min           -3.0441368
Z mean eval                  1.694061
Z variance eval              0.17534448
total_rewards                [8522.28581664 8727.04272125 8744.22807007 8729.46642272 8766.65580571
 8536.74072661 8879.14772599 8606.89090823 8767.17556941 8533.12063167]
total_rewards_mean           8681.275439830473
total_rewards_std            116.55600312058928
total_rewards_max            8879.147725985078
total_rewards_min            8522.28581664432
Number of train steps total  824000
Number of env steps total    2474000
Number of rollouts total     0
Train Time (s)               145.50517260935158
(Previous) Eval Time (s)     20.992055953014642
Sample Time (s)              6.4334769560955465
Epoch Time (s)               172.93070551846176
Total Train Time (s)         34979.898139628116
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:36:38.749014 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #205 | Epoch Duration: 173.0289978981018
2020-01-12 17:36:38.749152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6941204
Z variance train             0.17628342
KL Divergence                36.657467
KL Loss                      3.6657467
QF Loss                      248.04498
VF Loss                      88.03432
Policy Loss                  -1129.4954
Q Predictions Mean           1127.0642
Q Predictions Std            1159.8922
Q Predictions Max            3984.654
Q Predictions Min            529.77014
V Predictions Mean           1126.9668
V Predictions Std            1161.3185
V Predictions Max            4002.2344
V Predictions Min            521.97003
Log Pis Mean                 0.1136894
Log Pis Std                  3.886417
Log Pis Max                  18.714848
Log Pis Min                  -7.621908
Policy mu Mean               -0.018717026
Policy mu Std                0.9463863
Policy mu Max                3.0051389
Policy mu Min                -3.1722193
Policy log std Mean          -0.4756864
Policy log std Std           0.24740605
Policy log std Max           0.0004773736
Policy log std Min           -2.314725
Z mean eval                  1.735349
Z variance eval              0.13897789
total_rewards                [8911.13167997 9168.65687446 9114.3796691  8820.8405071  9021.18266949
 9313.01805684 8943.9738834  9090.06263041 9033.5042699  9062.63102755]
total_rewards_mean           9047.938126821191
total_rewards_std            131.63103981255654
total_rewards_max            9313.018056838313
total_rewards_min            8820.840507096595
Number of train steps total  828000
Number of env steps total    2486000
Number of rollouts total     0
Train Time (s)               146.93720084009692
(Previous) Eval Time (s)     19.570022805128247
Sample Time (s)              6.476296167355031
Epoch Time (s)               172.9835198125802
Total Train Time (s)         35153.00406690873
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:39:31.866612 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #206 | Epoch Duration: 173.11733961105347
2020-01-12 17:39:31.866828 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7378677
Z variance train             0.13888685
KL Divergence                38.66286
KL Loss                      3.866286
QF Loss                      140.82191
VF Loss                      61.11139
Policy Loss                  -1081.3616
Q Predictions Mean           1080.7632
Q Predictions Std            1091.1627
Q Predictions Max            4080.2942
Q Predictions Min            542.2383
V Predictions Mean           1080.7961
V Predictions Std            1087.1604
V Predictions Max            4050.0957
V Predictions Min            548.38025
Log Pis Mean                 -0.15279005
Log Pis Std                  3.5692475
Log Pis Max                  15.352744
Log Pis Min                  -10.105234
Policy mu Mean               0.006608682
Policy mu Std                0.9063831
Policy mu Max                2.5421734
Policy mu Min                -3.4760025
Policy log std Mean          -0.49777377
Policy log std Std           0.24644548
Policy log std Max           -0.021213114
Policy log std Min           -2.464424
Z mean eval                  1.7130544
Z variance eval              0.18530285
total_rewards                [8880.91843699 8741.02966101 8657.50834887 8670.24581531 8858.28912114
 8723.54448849 8954.19656741 8704.649761   8796.88256958 8773.91148641]
total_rewards_mean           8776.117625620971
total_rewards_std            91.79503288819103
total_rewards_max            8954.19656741343
total_rewards_min            8657.508348874024
Number of train steps total  832000
Number of env steps total    2498000
Number of rollouts total     0
Train Time (s)               143.655111821834
(Previous) Eval Time (s)     21.95609152689576
Sample Time (s)              6.91140774730593
Epoch Time (s)               172.5226110960357
Total Train Time (s)         35325.61553229997
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:42:24.472613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #207 | Epoch Duration: 172.60564851760864
2020-01-12 17:42:24.472745 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7113113
Z variance train             0.1855948
KL Divergence                37.94906
KL Loss                      3.794906
QF Loss                      234.90213
VF Loss                      29.879597
Policy Loss                  -1166.9312
Q Predictions Mean           1164.167
Q Predictions Std            1187.9684
Q Predictions Max            4133.4634
Q Predictions Min            522.7659
V Predictions Mean           1167.4124
V Predictions Std            1188.6041
V Predictions Max            4139.5127
V Predictions Min            533.93787
Log Pis Mean                 -0.3580705
Log Pis Std                  3.3955433
Log Pis Max                  12.93464
Log Pis Min                  -5.9884186
Policy mu Mean               0.02292051
Policy mu Std                0.8771618
Policy mu Max                2.8516917
Policy mu Min                -2.748975
Policy log std Mean          -0.5326974
Policy log std Std           0.2819091
Policy log std Max           -0.0036711395
Policy log std Min           -2.811674
Z mean eval                  1.7142677
Z variance eval              0.12710182
total_rewards                [9064.49360866 9084.86728605 9062.13478498 9135.35405517 9364.88434989
 9213.11309527 9145.08137325 8970.06269472 8951.31974702 9118.00178156]
total_rewards_mean           9110.931277657304
total_rewards_std            112.81961916722486
total_rewards_max            9364.88434989149
total_rewards_min            8951.319747024985
Number of train steps total  836000
Number of env steps total    2510000
Number of rollouts total     0
Train Time (s)               144.3762525380589
(Previous) Eval Time (s)     20.815607185009867
Sample Time (s)              6.896891946904361
Epoch Time (s)               172.08875166997313
Total Train Time (s)         35497.7839936642
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:45:16.652090 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #208 | Epoch Duration: 172.17924904823303
2020-01-12 17:45:16.652224 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.712814
Z variance train             0.12687448
KL Divergence                38.77152
KL Loss                      3.877152
QF Loss                      2749.7139
VF Loss                      191.15712
Policy Loss                  -1258.1925
Q Predictions Mean           1257.766
Q Predictions Std            1267.8527
Q Predictions Max            4044.3735
Q Predictions Min            502.2954
V Predictions Mean           1268.1592
V Predictions Std            1272.1788
V Predictions Max            4039.4033
V Predictions Min            507.65613
Log Pis Mean                 0.22878888
Log Pis Std                  3.8011475
Log Pis Max                  14.200465
Log Pis Min                  -5.9273806
Policy mu Mean               0.025564425
Policy mu Std                0.9287778
Policy mu Max                2.9686956
Policy mu Min                -3.2209122
Policy log std Mean          -0.5344067
Policy log std Std           0.26013207
Policy log std Max           0.24928093
Policy log std Min           -2.3762124
Z mean eval                  1.7091122
Z variance eval              0.07407548
total_rewards                [9232.34369818 9508.05845685 9397.01060684 9285.29081517 9258.66877188
 9305.32651157 9258.16365039 9274.1542535  9234.30268099 9300.95193063]
total_rewards_mean           9305.427137599567
total_rewards_std            81.03736494843014
total_rewards_max            9508.058456851146
total_rewards_min            9232.343698178307
Number of train steps total  840000
Number of env steps total    2522000
Number of rollouts total     0
Train Time (s)               143.91588306613266
(Previous) Eval Time (s)     21.111531027127057
Sample Time (s)              6.59813128085807
Epoch Time (s)               171.6255453741178
Total Train Time (s)         35669.50284263771
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:48:08.365283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #209 | Epoch Duration: 171.71294379234314
2020-01-12 17:48:08.365472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7082949
Z variance train             0.074122146
KL Divergence                40.026768
KL Loss                      4.002677
QF Loss                      222.36508
VF Loss                      56.87302
Policy Loss                  -1327.4528
Q Predictions Mean           1321.2494
Q Predictions Std            1299.1411
Q Predictions Max            4117.9688
Q Predictions Min            507.92996
V Predictions Mean           1329.4716
V Predictions Std            1304.4058
V Predictions Max            4104.146
V Predictions Min            525.1413
Log Pis Mean                 0.28042114
Log Pis Std                  3.8466322
Log Pis Max                  12.965671
Log Pis Min                  -6.301421
Policy mu Mean               0.05829531
Policy mu Std                0.94377303
Policy mu Max                2.7349207
Policy mu Min                -2.735943
Policy log std Mean          -0.543623
Policy log std Std           0.28455487
Policy log std Max           -0.07125291
Policy log std Min           -2.5396104
Z mean eval                  1.7066746
Z variance eval              0.089258716
total_rewards                [8553.54979952 9172.39667209 9105.98260973 9221.72387024 9149.98970937
 9216.49968053 8931.03345228 9181.8790011  6384.38570599 9275.86589511]
total_rewards_mean           8819.3306395954
total_rewards_std            835.9284366400548
total_rewards_max            9275.865895107858
total_rewards_min            6384.385705986135
Number of train steps total  844000
Number of env steps total    2534000
Number of rollouts total     0
Train Time (s)               146.73322032624856
(Previous) Eval Time (s)     21.078335050027817
Sample Time (s)              6.955166131723672
Epoch Time (s)               174.76672150800005
Total Train Time (s)         35844.34945812123
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:51:03.219392 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #210 | Epoch Duration: 174.8537561893463
2020-01-12 17:51:03.219650 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #210 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7074264
Z variance train             0.08898366
KL Divergence                40.92733
KL Loss                      4.092733
QF Loss                      2491.755
VF Loss                      110.99331
Policy Loss                  -1177.7621
Q Predictions Mean           1178.3198
Q Predictions Std            1211.4381
Q Predictions Max            4103.5386
Q Predictions Min            542.0405
V Predictions Mean           1186.2219
V Predictions Std            1211.5927
V Predictions Max            4108.407
V Predictions Min            550.6748
Log Pis Mean                 -0.07719603
Log Pis Std                  3.733366
Log Pis Max                  13.53549
Log Pis Min                  -5.7263837
Policy mu Mean               0.038000587
Policy mu Std                0.8846872
Policy mu Max                2.6210961
Policy mu Min                -3.0157094
Policy log std Mean          -0.51465064
Policy log std Std           0.2735969
Policy log std Max           -0.04598683
Policy log std Min           -2.4612968
Z mean eval                  1.7068379
Z variance eval              0.12312776
total_rewards                [8894.56475638 6886.04382312 9000.5356847  9434.36435095 8900.3604714
 9006.67538998 9334.43005959 9099.6112185  8797.17300654 8849.34654117]
total_rewards_mean           8820.31053023305
total_rewards_std            673.890988162474
total_rewards_max            9434.364350952283
total_rewards_min            6886.043823123855
Number of train steps total  848000
Number of env steps total    2546000
Number of rollouts total     0
Train Time (s)               145.24092021817341
(Previous) Eval Time (s)     20.682845467701554
Sample Time (s)              5.637660083826631
Epoch Time (s)               171.5614257697016
Total Train Time (s)         36016.002434975
Epoch                        211
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:53:54.871604 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #211 | Epoch Duration: 171.6517791748047
2020-01-12 17:53:54.871736 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7070545
Z variance train             0.12288682
KL Divergence                40.02068
KL Loss                      4.002068
QF Loss                      120.987816
VF Loss                      79.65114
Policy Loss                  -1173.1714
Q Predictions Mean           1165.3821
Q Predictions Std            1176.556
Q Predictions Max            4043.4602
Q Predictions Min            540.2183
V Predictions Mean           1172.3157
V Predictions Std            1175.8816
V Predictions Max            4009.4634
V Predictions Min            549.72455
Log Pis Mean                 -0.17129433
Log Pis Std                  3.7941308
Log Pis Max                  17.011341
Log Pis Min                  -6.879841
Policy mu Mean               0.028044812
Policy mu Std                0.9055751
Policy mu Max                2.6297326
Policy mu Min                -3.126706
Policy log std Mean          -0.5433321
Policy log std Std           0.30177808
Policy log std Max           -0.047489226
Policy log std Min           -2.7552564
Z mean eval                  1.7146492
Z variance eval              0.13211767
total_rewards                [8551.15927249 8415.28481405 8732.34627108 8643.96811575 8274.45933953
 8531.59150431 8380.38709562 8478.87014943 8168.72043922 8640.78691337]
total_rewards_mean           8481.75739148475
total_rewards_std            166.5428013437008
total_rewards_max            8732.346271083727
total_rewards_min            8168.720439217954
Number of train steps total  852000
Number of env steps total    2558000
Number of rollouts total     0
Train Time (s)               145.87384576303884
(Previous) Eval Time (s)     21.23324052011594
Sample Time (s)              6.437002129852772
Epoch Time (s)               173.54408841300756
Total Train Time (s)         36189.64059030777
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:56:48.512446 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #212 | Epoch Duration: 173.64060735702515
2020-01-12 17:56:48.512581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7150263
Z variance train             0.13211247
KL Divergence                39.828327
KL Loss                      3.9828327
QF Loss                      307.25977
VF Loss                      66.07424
Policy Loss                  -1168.8378
Q Predictions Mean           1167.8677
Q Predictions Std            1181.1508
Q Predictions Max            4096.4756
Q Predictions Min            517.50977
V Predictions Mean           1169.2595
V Predictions Std            1182.7305
V Predictions Max            4113.2373
V Predictions Min            534.58997
Log Pis Mean                 -0.23663333
Log Pis Std                  3.7575884
Log Pis Max                  11.7329235
Log Pis Min                  -6.7338905
Policy mu Mean               0.078871004
Policy mu Std                0.87999105
Policy mu Max                2.7403817
Policy mu Min                -2.4625795
Policy log std Mean          -0.5067051
Policy log std Std           0.29411194
Policy log std Max           -0.08375268
Policy log std Min           -2.782281
Z mean eval                  1.7337275
Z variance eval              0.10577212
total_rewards                [8916.59303144 9238.50155427 9571.39541518 9264.87420882 9192.14958397
 9426.19027467 9597.29501517 9240.11104867 9433.77334602 9187.53577301]
total_rewards_mean           9306.841925122211
total_rewards_std            193.71999282871909
total_rewards_max            9597.295015172485
total_rewards_min            8916.593031439448
Number of train steps total  856000
Number of env steps total    2570000
Number of rollouts total     0
Train Time (s)               146.41540854191408
(Previous) Eval Time (s)     21.058708952274173
Sample Time (s)              6.57752860058099
Epoch Time (s)               174.05164609476924
Total Train Time (s)         36363.778908691835
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:59:42.652401 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #213 | Epoch Duration: 174.13972449302673
2020-01-12 17:59:42.652539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7348278
Z variance train             0.10549116
KL Divergence                40.596256
KL Loss                      4.0596256
QF Loss                      198.89307
VF Loss                      40.78517
Policy Loss                  -1215.588
Q Predictions Mean           1212.1553
Q Predictions Std            1233.6992
Q Predictions Max            4108.7866
Q Predictions Min            545.6882
V Predictions Mean           1212.9707
V Predictions Std            1228.0247
V Predictions Max            4095.9084
V Predictions Min            557.4882
Log Pis Mean                 -0.09313153
Log Pis Std                  3.4710288
Log Pis Max                  12.637717
Log Pis Min                  -6.3797736
Policy mu Mean               0.04520963
Policy mu Std                0.8905494
Policy mu Max                3.1741407
Policy mu Min                -3.1147223
Policy log std Mean          -0.55406576
Policy log std Std           0.29840013
Policy log std Max           -0.0071983337
Policy log std Min           -2.7259367
Z mean eval                  1.7440834
Z variance eval              0.08302575
total_rewards                [8835.95622926 9009.54854272 9158.50252556 8993.98975441 9146.51888748
 9102.74506122 8974.82661368 9026.06162089 9195.34471502 9087.04941907]
total_rewards_mean           9053.05433693032
total_rewards_std            101.5320042541595
total_rewards_max            9195.344715015613
total_rewards_min            8835.956229255318
Number of train steps total  860000
Number of env steps total    2582000
Number of rollouts total     0
Train Time (s)               144.70381261780858
(Previous) Eval Time (s)     17.53740318212658
Sample Time (s)              6.401593696791679
Epoch Time (s)               168.64280949672684
Total Train Time (s)         36532.50011877203
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:02:31.376324 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #214 | Epoch Duration: 168.7236704826355
2020-01-12 18:02:31.376504 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7405058
Z variance train             0.08323489
KL Divergence                41.356907
KL Loss                      4.1356907
QF Loss                      153.21512
VF Loss                      140.55891
Policy Loss                  -1111.5717
Q Predictions Mean           1109.4501
Q Predictions Std            1120.4004
Q Predictions Max            4071.3918
Q Predictions Min            544.2443
V Predictions Mean           1119.488
V Predictions Std            1122.305
V Predictions Max            4074.3552
V Predictions Min            549.02386
Log Pis Mean                 -0.24720432
Log Pis Std                  3.732569
Log Pis Max                  18.396563
Log Pis Min                  -6.6269283
Policy mu Mean               0.05669087
Policy mu Std                0.8855157
Policy mu Max                3.0319145
Policy mu Min                -3.100356
Policy log std Mean          -0.5090282
Policy log std Std           0.26792294
Policy log std Max           0.094299436
Policy log std Min           -2.3758526
Z mean eval                  1.7308394
Z variance eval              0.091580875
total_rewards                [9320.91184197 2306.67961979 9562.71235828 9268.84243093 9329.81950442
 9317.22616764 9555.80835372 9562.94373746 9396.69951908 9399.72290879]
total_rewards_mean           8702.136644208244
total_rewards_std            2134.4228405562753
total_rewards_max            9562.9437374616
total_rewards_min            2306.679619786884
Number of train steps total  864000
Number of env steps total    2594000
Number of rollouts total     0
Train Time (s)               145.283290815074
(Previous) Eval Time (s)     17.57725627301261
Sample Time (s)              6.358042251318693
Epoch Time (s)               169.2185893394053
Total Train Time (s)         36701.800054891966
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:05:20.679280 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #215 | Epoch Duration: 169.3025827407837
2020-01-12 18:05:20.679546 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7320902
Z variance train             0.0917941
KL Divergence                41.661938
KL Loss                      4.166194
QF Loss                      2823.598
VF Loss                      62.986244
Policy Loss                  -1113.7609
Q Predictions Mean           1111.5627
Q Predictions Std            1156.464
Q Predictions Max            4132.8486
Q Predictions Min            554.82104
V Predictions Mean           1108.206
V Predictions Std            1154.1094
V Predictions Max            4103.759
V Predictions Min            548.26825
Log Pis Mean                 -0.47848547
Log Pis Std                  3.5919642
Log Pis Max                  15.486395
Log Pis Min                  -14.318243
Policy mu Mean               0.048854876
Policy mu Std                0.8603003
Policy mu Max                2.5131588
Policy mu Min                -3.0673249
Policy log std Mean          -0.51427984
Policy log std Std           0.24143334
Policy log std Max           -0.054030776
Policy log std Min           -2.2676907
Z mean eval                  1.7344316
Z variance eval              0.056700993
total_rewards                [8668.95076803 8914.08250795 8895.26767973 9005.45436789 8854.61857508
 8949.29154215 8882.9589069  8764.82608151 8984.49647435 8954.31646033]
total_rewards_mean           8887.426336392335
total_rewards_std            98.12520675774869
total_rewards_max            9005.454367894064
total_rewards_min            8668.950768029092
Number of train steps total  868000
Number of env steps total    2606000
Number of rollouts total     0
Train Time (s)               146.5494204950519
(Previous) Eval Time (s)     18.015554320067167
Sample Time (s)              6.43099557608366
Epoch Time (s)               170.99597039120272
Total Train Time (s)         36872.90420361003
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:08:11.788456 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #216 | Epoch Duration: 171.10870504379272
2020-01-12 18:08:11.788754 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #216 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7344086
Z variance train             0.05665636
KL Divergence                42.19182
KL Loss                      4.219182
QF Loss                      133.87013
VF Loss                      42.56513
Policy Loss                  -1124.4424
Q Predictions Mean           1123.1086
Q Predictions Std            1147.007
Q Predictions Max            4140.9395
Q Predictions Min            519.14075
V Predictions Mean           1123.8475
V Predictions Std            1145.4094
V Predictions Max            4131.249
V Predictions Min            539.28845
Log Pis Mean                 -0.54363096
Log Pis Std                  3.2404122
Log Pis Max                  13.445564
Log Pis Min                  -6.8485513
Policy mu Mean               0.0694134
Policy mu Std                0.8622231
Policy mu Max                3.4180315
Policy mu Min                -2.6643555
Policy log std Mean          -0.5281289
Policy log std Std           0.2767771
Policy log std Max           -0.0069844723
Policy log std Min           -2.5401232
Z mean eval                  1.7413776
Z variance eval              0.047825627
total_rewards                [8646.80651683 8717.64366056 8869.58023822 8797.03192554 8759.3615188
 8798.38624986 8808.21618762 8721.00784428 8685.8200649  8792.29331896]
total_rewards_mean           8759.614752557707
total_rewards_std            63.126186403097414
total_rewards_max            8869.580238222145
total_rewards_min            8646.806516831384
Number of train steps total  872000
Number of env steps total    2618000
Number of rollouts total     0
Train Time (s)               147.90211744373664
(Previous) Eval Time (s)     17.89165558340028
Sample Time (s)              5.546857584733516
Epoch Time (s)               171.34063061187044
Total Train Time (s)         37044.32610475365
Epoch                        217
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:11:03.210284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #217 | Epoch Duration: 171.42124843597412
2020-01-12 18:11:03.210531 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #217 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7388332
Z variance train             0.047776576
KL Divergence                44.256176
KL Loss                      4.4256177
QF Loss                      112.94303
VF Loss                      51.68519
Policy Loss                  -1123.3486
Q Predictions Mean           1116.9231
Q Predictions Std            1124.514
Q Predictions Max            4135.0024
Q Predictions Min            544.9842
V Predictions Mean           1121.873
V Predictions Std            1126.1941
V Predictions Max            4132.7183
V Predictions Min            552.2422
Log Pis Mean                 -0.4307107
Log Pis Std                  3.3801324
Log Pis Max                  12.81058
Log Pis Min                  -6.9925246
Policy mu Mean               0.032443017
Policy mu Std                0.8582877
Policy mu Max                2.8030849
Policy mu Min                -2.7362616
Policy log std Mean          -0.53426725
Policy log std Std           0.28124565
Policy log std Max           -0.08821416
Policy log std Min           -2.596902
Z mean eval                  1.7331879
Z variance eval              0.108204916
total_rewards                [9200.4955946  9424.80574845 9545.93730405 9250.47652441 9524.7845507
 9494.16262625 9310.17511646 9521.27006028 9232.42721353 9479.03598904]
total_rewards_mean           9398.357072776811
total_rewards_std            128.67997323850554
total_rewards_max            9545.937304049627
total_rewards_min            9200.49559460044
Number of train steps total  876000
Number of env steps total    2630000
Number of rollouts total     0
Train Time (s)               147.73535219440237
(Previous) Eval Time (s)     17.86169846728444
Sample Time (s)              5.670122170355171
Epoch Time (s)               171.26717283204198
Total Train Time (s)         37215.87718870584
Epoch                        218
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:13:54.774038 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #218 | Epoch Duration: 171.56331539154053
2020-01-12 18:13:54.774260 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7368336
Z variance train             0.10780551
KL Divergence                42.722286
KL Loss                      4.2722287
QF Loss                      129.6864
VF Loss                      34.506783
Policy Loss                  -1157.266
Q Predictions Mean           1157.8423
Q Predictions Std            1169.1244
Q Predictions Max            4143.842
Q Predictions Min            555.6381
V Predictions Mean           1155.6472
V Predictions Std            1167.3868
V Predictions Max            4136.0806
V Predictions Min            556.227
Log Pis Mean                 -0.13102593
Log Pis Std                  3.599447
Log Pis Max                  13.926161
Log Pis Min                  -7.1640854
Policy mu Mean               0.08641704
Policy mu Std                0.8779761
Policy mu Max                2.8490057
Policy mu Min                -2.7902083
Policy log std Mean          -0.5205469
Policy log std Std           0.27353662
Policy log std Max           -0.066838145
Policy log std Min           -2.5102797
Z mean eval                  1.7473152
Z variance eval              0.09340286
total_rewards                [9102.44138012 9342.58838559 9319.38115992 9441.57692619 9357.78238133
 9463.29032523 9271.46674768 9462.7461194  9320.88561769 9127.82493478]
total_rewards_mean           9320.998397793466
total_rewards_std            120.09868819147518
total_rewards_max            9463.290325232436
total_rewards_min            9102.441380119068
Number of train steps total  880000
Number of env steps total    2642000
Number of rollouts total     0
Train Time (s)               147.67492049420252
(Previous) Eval Time (s)     21.013349410146475
Sample Time (s)              6.477473234757781
Epoch Time (s)               175.16574313910678
Total Train Time (s)         37391.136818909086
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:16:50.025487 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #219 | Epoch Duration: 175.25107955932617
2020-01-12 18:16:50.025632 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #219 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7456518
Z variance train             0.093389526
KL Divergence                42.469055
KL Loss                      4.246906
QF Loss                      995.8814
VF Loss                      54.68829
Policy Loss                  -1096.7024
Q Predictions Mean           1095.2302
Q Predictions Std            1123.4882
Q Predictions Max            4176.9004
Q Predictions Min            558.17584
V Predictions Mean           1096.7048
V Predictions Std            1124.7234
V Predictions Max            4190.842
V Predictions Min            555.93744
Log Pis Mean                 -0.19406271
Log Pis Std                  3.7757962
Log Pis Max                  14.645822
Log Pis Min                  -6.7036743
Policy mu Mean               -0.002334457
Policy mu Std                0.8808056
Policy mu Max                2.8049762
Policy mu Min                -3.2355862
Policy log std Mean          -0.51563966
Policy log std Std           0.27644503
Policy log std Max           0.047933698
Policy log std Min           -2.6880848
Z mean eval                  1.7373024
Z variance eval              0.062100053
total_rewards                [8809.26623912 9453.60707178 9066.05352854 9030.58209656 8994.4538219
 9190.03717804 9134.52650181 9367.97689305 9234.17423791 9114.4527067 ]
total_rewards_mean           9139.51302754126
total_rewards_std            176.17732153889614
total_rewards_max            9453.60707178083
total_rewards_min            8809.266239120792
Number of train steps total  884000
Number of env steps total    2654000
Number of rollouts total     0
Train Time (s)               146.5731981229037
(Previous) Eval Time (s)     20.892029155045748
Sample Time (s)              6.519253885373473
Epoch Time (s)               173.98448116332293
Total Train Time (s)         37565.207145153545
Epoch                        220
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:19:44.096377 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #220 | Epoch Duration: 174.07064819335938
2020-01-12 18:19:44.096509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7348568
Z variance train             0.0620976
KL Divergence                43.858837
KL Loss                      4.385884
QF Loss                      707.4806
VF Loss                      100.89576
Policy Loss                  -1258.1005
Q Predictions Mean           1257.1205
Q Predictions Std            1278.9785
Q Predictions Max            4120.485
Q Predictions Min            558.5902
V Predictions Mean           1263.0017
V Predictions Std            1275.6284
V Predictions Max            4119.1895
V Predictions Min            569.12885
Log Pis Mean                 -0.041989423
Log Pis Std                  3.9353745
Log Pis Max                  14.601633
Log Pis Min                  -7.766538
Policy mu Mean               0.045465697
Policy mu Std                0.9088295
Policy mu Max                3.1055262
Policy mu Min                -2.7380679
Policy log std Mean          -0.52947336
Policy log std Std           0.28855664
Policy log std Max           0.1442141
Policy log std Min           -2.5155253
Z mean eval                  1.7403877
Z variance eval              0.047440834
total_rewards                [9286.43463098 9381.21734733 2029.96967168 9257.85473855 9612.25750513
 9549.75305771  872.48441073 9374.88014815 9278.49699619 9473.5511263 ]
total_rewards_mean           7811.6899632762115
total_rewards_std            3192.6528088123155
total_rewards_max            9612.257505127687
total_rewards_min            872.4844107347177
Number of train steps total  888000
Number of env steps total    2666000
Number of rollouts total     0
Train Time (s)               145.6638389849104
(Previous) Eval Time (s)     20.999510334804654
Sample Time (s)              6.590334984008223
Epoch Time (s)               173.25368430372328
Total Train Time (s)         37738.54252606537
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:22:37.435818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #221 | Epoch Duration: 173.33921432495117
2020-01-12 18:22:37.435958 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7409805
Z variance train             0.04738955
KL Divergence                44.12509
KL Loss                      4.4125094
QF Loss                      2853.586
VF Loss                      35.14002
Policy Loss                  -1144.3342
Q Predictions Mean           1142.5901
Q Predictions Std            1148.481
Q Predictions Max            4134.9663
Q Predictions Min            560.5719
V Predictions Mean           1147.1244
V Predictions Std            1148.4631
V Predictions Max            4123.899
V Predictions Min            564.4657
Log Pis Mean                 -0.050237328
Log Pis Std                  3.4449527
Log Pis Max                  14.599347
Log Pis Min                  -4.893965
Policy mu Mean               0.08853513
Policy mu Std                0.8889648
Policy mu Max                3.0229454
Policy mu Min                -3.0891948
Policy log std Mean          -0.5340837
Policy log std Std           0.28502297
Policy log std Max           0.02693218
Policy log std Min           -2.4930644
Z mean eval                  1.7346628
Z variance eval              0.06294651
total_rewards                [9011.58172406 9142.80656285 9277.89389209 8958.07022517 9041.77773304
 8903.77149503 9167.88586858 9081.22019237 9112.13567648 9302.34354202]
total_rewards_mean           9099.94869117068
total_rewards_std            122.22408900996489
total_rewards_max            9302.34354202078
total_rewards_min            8903.771495032874
Number of train steps total  892000
Number of env steps total    2678000
Number of rollouts total     0
Train Time (s)               146.19566773297265
(Previous) Eval Time (s)     19.112906740047038
Sample Time (s)              6.541603402700275
Epoch Time (s)               171.85017787571996
Total Train Time (s)         37910.491256489884
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:25:29.385648 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #222 | Epoch Duration: 171.94957041740417
2020-01-12 18:25:29.385862 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.734588
Z variance train             0.06307542
KL Divergence                43.322453
KL Loss                      4.3322453
QF Loss                      454.2215
VF Loss                      67.70894
Policy Loss                  -1243.0261
Q Predictions Mean           1237.0781
Q Predictions Std            1237.4043
Q Predictions Max            4152.567
Q Predictions Min            547.9941
V Predictions Mean           1243.6855
V Predictions Std            1238.2136
V Predictions Max            4183.9165
V Predictions Min            553.2627
Log Pis Mean                 0.12458263
Log Pis Std                  3.7505465
Log Pis Max                  15.854021
Log Pis Min                  -5.886406
Policy mu Mean               -0.045920044
Policy mu Std                0.90747976
Policy mu Max                3.0666893
Policy mu Min                -3.2222378
Policy log std Mean          -0.54185194
Policy log std Std           0.30201715
Policy log std Max           0.015821755
Policy log std Min           -2.7274556
Z mean eval                  1.7352676
Z variance eval              0.057144053
total_rewards                [9352.52880642 9532.33267849 9158.16015439 9553.24912026 9301.28781379
 9454.17920284 9404.65200372 9430.22953327 9354.09449553 9802.42348034]
total_rewards_mean           9434.313728905428
total_rewards_std            163.59396575140144
total_rewards_max            9802.423480341635
total_rewards_min            9158.160154394103
Number of train steps total  896000
Number of env steps total    2690000
Number of rollouts total     0
Train Time (s)               146.20417060982436
(Previous) Eval Time (s)     17.482033308129758
Sample Time (s)              6.623651725240052
Epoch Time (s)               170.30985564319417
Total Train Time (s)         38080.88241394982
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:28:19.783135 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #223 | Epoch Duration: 170.39707827568054
2020-01-12 18:28:19.783450 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7347504
Z variance train             0.05713568
KL Divergence                44.00722
KL Loss                      4.400722
QF Loss                      178.30365
VF Loss                      52.678497
Policy Loss                  -1315.291
Q Predictions Mean           1315.101
Q Predictions Std            1305.0913
Q Predictions Max            4148.9346
Q Predictions Min            540.81903
V Predictions Mean           1319.1067
V Predictions Std            1301.4744
V Predictions Max            4154.439
V Predictions Min            554.98944
Log Pis Mean                 0.033200577
Log Pis Std                  3.5297515
Log Pis Max                  12.622372
Log Pis Min                  -7.220719
Policy mu Mean               0.02448482
Policy mu Std                0.905386
Policy mu Max                2.9434915
Policy mu Min                -3.154326
Policy log std Mean          -0.52323157
Policy log std Std           0.26793393
Policy log std Max           0.06387758
Policy log std Min           -2.5005622
Z mean eval                  1.732228
Z variance eval              0.07489728
total_rewards                [9167.61554037 9533.55880279 9290.33207363 9593.72116368 9605.48768787
 9498.27269107 9691.98735833 9475.53959216 9690.20336244 9751.05080709]
total_rewards_mean           9529.776907944299
total_rewards_std            174.14798180800537
total_rewards_max            9751.050807089063
total_rewards_min            9167.615540370152
Number of train steps total  900000
Number of env steps total    2702000
Number of rollouts total     0
Train Time (s)               147.3471515593119
(Previous) Eval Time (s)     17.273735930677503
Sample Time (s)              6.456083071418107
Epoch Time (s)               171.0769705614075
Total Train Time (s)         38252.03774689231
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:31:10.938358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #224 | Epoch Duration: 171.15468049049377
2020-01-12 18:31:10.938479 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7317854
Z variance train             0.07505366
KL Divergence                43.43254
KL Loss                      4.343254
QF Loss                      94.86341
VF Loss                      67.61196
Policy Loss                  -1180.0935
Q Predictions Mean           1178.055
Q Predictions Std            1186.9836
Q Predictions Max            4136.199
Q Predictions Min            561.72784
V Predictions Mean           1181.8562
V Predictions Std            1186.8021
V Predictions Max            4154.106
V Predictions Min            560.41284
Log Pis Mean                 -0.31564635
Log Pis Std                  3.7436576
Log Pis Max                  15.6778145
Log Pis Min                  -6.7635264
Policy mu Mean               -0.062924005
Policy mu Std                0.87938917
Policy mu Max                2.5894885
Policy mu Min                -3.1219425
Policy log std Mean          -0.54010886
Policy log std Std           0.27498668
Policy log std Max           0.02078098
Policy log std Min           -2.4431295
Z mean eval                  1.7287709
Z variance eval              0.12516762
total_rewards                [9446.92507837 9641.32046158 9522.16916285 9396.11798105 9411.92366726
 9291.44842741 9577.15828963 9394.52242494 9639.57441913 9396.07645585]
total_rewards_mean           9471.723636805464
total_rewards_std            111.66336887279942
total_rewards_max            9641.320461578503
total_rewards_min            9291.448427406607
Number of train steps total  904000
Number of env steps total    2714000
Number of rollouts total     0
Train Time (s)               145.65713091334328
(Previous) Eval Time (s)     18.61435656901449
Sample Time (s)              5.470973840914667
Epoch Time (s)               169.74246132327244
Total Train Time (s)         38421.99140059156
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:34:00.898090 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #225 | Epoch Duration: 169.95948004722595
2020-01-12 18:34:00.898360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7279022
Z variance train             0.1254052
KL Divergence                42.500145
KL Loss                      4.250015
QF Loss                      190.71034
VF Loss                      56.2739
Policy Loss                  -1224.2383
Q Predictions Mean           1221.4641
Q Predictions Std            1227.067
Q Predictions Max            4148.8193
Q Predictions Min            565.1195
V Predictions Mean           1226.3818
V Predictions Std            1226.3177
V Predictions Max            4156.393
V Predictions Min            562.9021
Log Pis Mean                 0.030081153
Log Pis Std                  3.8749244
Log Pis Max                  17.484325
Log Pis Min                  -6.5489945
Policy mu Mean               0.032415796
Policy mu Std                0.907481
Policy mu Max                3.1310263
Policy mu Min                -3.5178688
Policy log std Mean          -0.5342701
Policy log std Std           0.2635269
Policy log std Max           0.009602547
Policy log std Min           -2.5536835
Z mean eval                  1.7263105
Z variance eval              0.17240453
total_rewards                [8151.57351941 9196.42199524 9300.35903866 9389.53975655 9396.32073677
 8983.56155851 1285.37440942 9106.0420717  9178.15244705 9467.85530694]
total_rewards_mean           8345.520084024101
total_rewards_std            2380.1593731998737
total_rewards_max            9467.85530693801
total_rewards_min            1285.3744094154495
Number of train steps total  908000
Number of env steps total    2726000
Number of rollouts total     0
Train Time (s)               147.9310075440444
(Previous) Eval Time (s)     20.89479874400422
Sample Time (s)              6.4804739584214985
Epoch Time (s)               175.30628024647012
Total Train Time (s)         38597.3795314203
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:36:56.286639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #226 | Epoch Duration: 175.38808798789978
2020-01-12 18:36:56.286775 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.728002
Z variance train             0.17203687
KL Divergence                40.608387
KL Loss                      4.0608387
QF Loss                      173.9826
VF Loss                      43.22136
Policy Loss                  -1060.3564
Q Predictions Mean           1057.0684
Q Predictions Std            1061.9441
Q Predictions Max            4199.1987
Q Predictions Min            565.7418
V Predictions Mean           1060.812
V Predictions Std            1062.9591
V Predictions Max            4179.9346
V Predictions Min            560.80505
Log Pis Mean                 -0.66325784
Log Pis Std                  3.5938666
Log Pis Max                  14.732559
Log Pis Min                  -7.1234794
Policy mu Mean               0.07207286
Policy mu Std                0.829344
Policy mu Max                3.1592574
Policy mu Min                -2.8284945
Policy log std Mean          -0.5081424
Policy log std Std           0.2660056
Policy log std Max           0.053049266
Policy log std Min           -2.4508228
Z mean eval                  1.742232
Z variance eval              0.12382053
total_rewards                [9003.98699302 9463.0752053  9071.99383043 9204.77081659 9395.75616289
 9404.42019817 9351.96949829 9051.24177459 9246.56554275 9289.30164453]
total_rewards_mean           9248.308166657034
total_rewards_std            153.68024508198442
total_rewards_max            9463.075205302306
total_rewards_min            9003.986993020868
Number of train steps total  912000
Number of env steps total    2738000
Number of rollouts total     0
Train Time (s)               148.06949076615274
(Previous) Eval Time (s)     20.544507113751024
Sample Time (s)              6.418978095520288
Epoch Time (s)               175.03297597542405
Total Train Time (s)         38772.50317056617
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:39:51.413158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #227 | Epoch Duration: 175.12628364562988
2020-01-12 18:39:51.413297 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7428453
Z variance train             0.12372893
KL Divergence                39.701035
KL Loss                      3.9701035
QF Loss                      168.67313
VF Loss                      74.73437
Policy Loss                  -1046.229
Q Predictions Mean           1045.1187
Q Predictions Std            1067.871
Q Predictions Max            4221.2437
Q Predictions Min            581.0396
V Predictions Mean           1043.3152
V Predictions Std            1068.0007
V Predictions Max            4196.2373
V Predictions Min            577.33746
Log Pis Mean                 -0.67825913
Log Pis Std                  3.2403164
Log Pis Max                  15.539333
Log Pis Min                  -7.391143
Policy mu Mean               0.04459518
Policy mu Std                0.821991
Policy mu Max                2.755582
Policy mu Min                -2.716633
Policy log std Mean          -0.52300924
Policy log std Std           0.26348233
Policy log std Max           -0.043105185
Policy log std Min           -2.5566974
Z mean eval                  1.7345755
Z variance eval              0.08687471
total_rewards                [9270.258524   9634.61108181 9421.9881397  9667.83166078 9602.55240328
 9449.21851497 9422.16615531 9693.15065019 9415.54805213 9753.26946549]
total_rewards_mean           9533.05946476427
total_rewards_std            148.9845337882129
total_rewards_max            9753.269465489813
total_rewards_min            9270.2585239982
Number of train steps total  916000
Number of env steps total    2750000
Number of rollouts total     0
Train Time (s)               147.97868695715442
(Previous) Eval Time (s)     21.202125573996454
Sample Time (s)              6.532635123934597
Epoch Time (s)               175.71344765508547
Total Train Time (s)         38948.29604360927
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:42:47.209275 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #228 | Epoch Duration: 175.7958824634552
2020-01-12 18:42:47.209410 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7329403
Z variance train             0.08697151
KL Divergence                41.474995
KL Loss                      4.1474996
QF Loss                      98.18147
VF Loss                      46.926987
Policy Loss                  -1216.5331
Q Predictions Mean           1216.9927
Q Predictions Std            1239.4768
Q Predictions Max            4182.011
Q Predictions Min            553.54315
V Predictions Mean           1218.147
V Predictions Std            1237.1798
V Predictions Max            4185.131
V Predictions Min            563.8026
Log Pis Mean                 -0.23346005
Log Pis Std                  3.5403967
Log Pis Max                  15.606242
Log Pis Min                  -7.4487367
Policy mu Mean               0.024799736
Policy mu Std                0.8846811
Policy mu Max                2.5019279
Policy mu Min                -2.3767595
Policy log std Mean          -0.5260937
Policy log std Std           0.27044204
Policy log std Max           0.1608805
Policy log std Min           -2.5790057
Z mean eval                  1.7503252
Z variance eval              0.10696536
total_rewards                [9207.90544216 9487.74680912 9511.26679107 9505.94987673 9729.46959204
 9648.86387838 9680.23009002 9409.92156539 9623.70436964 9555.96651572]
total_rewards_mean           9536.102493027973
total_rewards_std            143.68249462942052
total_rewards_max            9729.469592043322
total_rewards_min            9207.90544216405
Number of train steps total  920000
Number of env steps total    2762000
Number of rollouts total     0
Train Time (s)               145.2490284726955
(Previous) Eval Time (s)     20.835194481071085
Sample Time (s)              6.273639798630029
Epoch Time (s)               172.3578627523966
Total Train Time (s)         39120.73272788152
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:45:39.649641 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #229 | Epoch Duration: 172.44012689590454
2020-01-12 18:45:39.649812 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7517197
Z variance train             0.10741804
KL Divergence                42.40929
KL Loss                      4.240929
QF Loss                      6025.464
VF Loss                      107.76045
Policy Loss                  -1270.0327
Q Predictions Mean           1270.5259
Q Predictions Std            1297.525
Q Predictions Max            4294.4517
Q Predictions Min            581.3585
V Predictions Mean           1267.9736
V Predictions Std            1291.3539
V Predictions Max            4277.3037
V Predictions Min            577.047
Log Pis Mean                 -0.01717591
Log Pis Std                  4.178217
Log Pis Max                  23.108671
Log Pis Min                  -6.8245525
Policy mu Mean               0.07322227
Policy mu Std                0.91099846
Policy mu Max                2.8523219
Policy mu Min                -3.4056435
Policy log std Mean          -0.5416176
Policy log std Std           0.2909687
Policy log std Max           0.25326994
Policy log std Min           -2.4957438
Z mean eval                  1.7426989
Z variance eval              0.107905686
total_rewards                [9293.2566713  9679.55460087 9786.63545593 9484.16954614 9523.87561276
 9396.57965246 9361.11713293 9509.43898198 9845.60312941 9632.71466286]
total_rewards_mean           9551.294544664514
total_rewards_std            172.8525112667496
total_rewards_max            9845.603129407218
total_rewards_min            9293.256671300447
Number of train steps total  924000
Number of env steps total    2774000
Number of rollouts total     0
Train Time (s)               147.00769191095605
(Previous) Eval Time (s)     20.69810054684058
Sample Time (s)              5.529124544002116
Epoch Time (s)               173.23491700179875
Total Train Time (s)         39294.20506564481
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:48:33.131074 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #230 | Epoch Duration: 173.48111820220947
2020-01-12 18:48:33.131305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7423942
Z variance train             0.1080873
KL Divergence                42.356632
KL Loss                      4.2356634
QF Loss                      94.617165
VF Loss                      37.713036
Policy Loss                  -1225.9305
Q Predictions Mean           1225.6372
Q Predictions Std            1224.393
Q Predictions Max            4208.8174
Q Predictions Min            570.45276
V Predictions Mean           1224.7067
V Predictions Std            1224.5012
V Predictions Max            4201.8345
V Predictions Min            568.3288
Log Pis Mean                 -0.26418442
Log Pis Std                  3.2905486
Log Pis Max                  12.295668
Log Pis Min                  -8.650687
Policy mu Mean               0.084849976
Policy mu Std                0.87890416
Policy mu Max                2.9874017
Policy mu Min                -2.532746
Policy log std Mean          -0.52380365
Policy log std Std           0.27189288
Policy log std Max           0.11979866
Policy log std Min           -2.7888055
Z mean eval                  1.7498701
Z variance eval              0.09255205
total_rewards                [9008.2601144  9303.59784349 9013.16786825 1644.05372538 9135.02064473
 9246.88013125 9264.8818557  8986.02193975 9276.12080242 9003.47475397]
total_rewards_mean           8388.147967934301
total_rewards_std            2251.3223382101737
total_rewards_max            9303.597843487916
total_rewards_min            1644.053725382966
Number of train steps total  928000
Number of env steps total    2786000
Number of rollouts total     0
Train Time (s)               146.1963987420313
(Previous) Eval Time (s)     20.745109593030065
Sample Time (s)              6.474832345265895
Epoch Time (s)               173.41634068032727
Total Train Time (s)         39467.71258625435
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:51:26.632772 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #231 | Epoch Duration: 173.50130987167358
2020-01-12 18:51:26.632908 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7487938
Z variance train             0.0926595
KL Divergence                43.00201
KL Loss                      4.300201
QF Loss                      350.2469
VF Loss                      43.850082
Policy Loss                  -1195.9232
Q Predictions Mean           1194.956
Q Predictions Std            1238.4318
Q Predictions Max            4179.4575
Q Predictions Min            562.7443
V Predictions Mean           1197.873
V Predictions Std            1233.6091
V Predictions Max            4170.4736
V Predictions Min            566.7016
Log Pis Mean                 -0.14405349
Log Pis Std                  3.66165
Log Pis Max                  17.244137
Log Pis Min                  -8.479563
Policy mu Mean               0.032286804
Policy mu Std                0.897355
Policy mu Max                3.7077136
Policy mu Min                -4.3373084
Policy log std Mean          -0.5245798
Policy log std Std           0.2713786
Policy log std Max           0.07187992
Policy log std Min           -2.5840917
Z mean eval                  1.7665517
Z variance eval              0.1031481
total_rewards                [9214.54697287 9458.2385275  9314.44763444 9549.95816129 9537.05153606
 9565.16667197 9558.05281282 9501.69448585 9494.47787359 9446.06045156]
total_rewards_mean           9463.96951279312
total_rewards_std            109.13453625333202
total_rewards_max            9565.166671966519
total_rewards_min            9214.546972865517
Number of train steps total  932000
Number of env steps total    2798000
Number of rollouts total     0
Train Time (s)               148.198510334827
(Previous) Eval Time (s)     21.23102974984795
Sample Time (s)              6.339035422541201
Epoch Time (s)               175.76857550721616
Total Train Time (s)         39643.57230284158
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:54:22.494578 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #232 | Epoch Duration: 175.86157298088074
2020-01-12 18:54:22.494719 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #232 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7655274
Z variance train             0.10298546
KL Divergence                43.541187
KL Loss                      4.354119
QF Loss                      173.24835
VF Loss                      120.766685
Policy Loss                  -1132.9915
Q Predictions Mean           1129.9528
Q Predictions Std            1144.9039
Q Predictions Max            4266.0005
Q Predictions Min            567.93256
V Predictions Mean           1133.9313
V Predictions Std            1145.6917
V Predictions Max            4224.6763
V Predictions Min            574.4705
Log Pis Mean                 -0.08891168
Log Pis Std                  3.328378
Log Pis Max                  12.422525
Log Pis Min                  -10.282532
Policy mu Mean               0.061582685
Policy mu Std                0.9073549
Policy mu Max                2.9748201
Policy mu Min                -3.1489732
Policy log std Mean          -0.5313754
Policy log std Std           0.28692243
Policy log std Max           0.047224402
Policy log std Min           -2.6113405
Z mean eval                  1.7548879
Z variance eval              0.08302106
total_rewards                [9172.80931983 9720.20065287 9683.54129359 9440.97692733 9382.5788131
 9540.74638425 9387.23987381 9644.40710222 9531.5643767  9281.55169434]
total_rewards_mean           9478.561643804269
total_rewards_std            169.07081339697888
total_rewards_max            9720.200652870479
total_rewards_min            9172.809319826792
Number of train steps total  936000
Number of env steps total    2810000
Number of rollouts total     0
Train Time (s)               148.6798719149083
(Previous) Eval Time (s)     20.74681560182944
Sample Time (s)              6.6336586670950055
Epoch Time (s)               176.06034618383273
Total Train Time (s)         39819.89907279983
Epoch                        233
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:57:18.822276 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #233 | Epoch Duration: 176.32745790481567
2020-01-12 18:57:18.822411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #233 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.752677
Z variance train             0.08309738
KL Divergence                43.716423
KL Loss                      4.3716426
QF Loss                      99.53604
VF Loss                      49.029163
Policy Loss                  -1178.7112
Q Predictions Mean           1173.8575
Q Predictions Std            1170.5176
Q Predictions Max            4285.006
Q Predictions Min            561.45465
V Predictions Mean           1179.4847
V Predictions Std            1173.0594
V Predictions Max            4309.1733
V Predictions Min            560.47656
Log Pis Mean                 -0.12801524
Log Pis Std                  4.0513916
Log Pis Max                  19.523445
Log Pis Min                  -6.470353
Policy mu Mean               0.107124746
Policy mu Std                0.892818
Policy mu Max                3.1027708
Policy mu Min                -3.1790104
Policy log std Mean          -0.5179596
Policy log std Std           0.28534266
Policy log std Max           -0.026420712
Policy log std Min           -2.593227
Z mean eval                  1.7594588
Z variance eval              0.08703445
total_rewards                [ 9539.02149287 10050.98960938  9553.66870993  9898.88562137
  9555.78183174  9579.65578771  9723.40205507  9691.234594
  9678.09191168  9725.06813334]
total_rewards_mean           9699.579974709948
total_rewards_std            157.19059511682528
total_rewards_max            10050.989609379543
total_rewards_min            9539.021492872032
Number of train steps total  940000
Number of env steps total    2822000
Number of rollouts total     0
Train Time (s)               147.90465028211474
(Previous) Eval Time (s)     20.81265427498147
Sample Time (s)              6.415562524925917
Epoch Time (s)               175.13286708202213
Total Train Time (s)         39995.11731131049
Epoch                        234
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:00:14.042858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #234 | Epoch Duration: 175.22034907341003
2020-01-12 19:00:14.042993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7623447
Z variance train             0.08708357
KL Divergence                43.99018
KL Loss                      4.3990183
QF Loss                      114.339584
VF Loss                      130.00156
Policy Loss                  -1159.3489
Q Predictions Mean           1157.7021
Q Predictions Std            1176.1127
Q Predictions Max            4245.1665
Q Predictions Min            552.63416
V Predictions Mean           1152.67
V Predictions Std            1166.9955
V Predictions Max            4202.7295
V Predictions Min            546.29596
Log Pis Mean                 -0.6427915
Log Pis Std                  3.1261394
Log Pis Max                  12.506096
Log Pis Min                  -6.222555
Policy mu Mean               0.09209762
Policy mu Std                0.82864094
Policy mu Max                2.7166004
Policy mu Min                -2.9933534
Policy log std Mean          -0.52754605
Policy log std Std           0.26871333
Policy log std Max           -0.07734382
Policy log std Min           -2.8941498
Z mean eval                  1.7440736
Z variance eval              0.13200095
total_rewards                [9197.5816714  9223.79259047 9442.62525237 9209.46944807 9363.44985902
 9365.63529339 9379.52090326 9333.29152972 9263.85595581 9257.35298605]
total_rewards_mean           9303.657548956366
total_rewards_std            79.74458363306351
total_rewards_max            9442.62525237448
total_rewards_min            9197.581671402873
Number of train steps total  944000
Number of env steps total    2834000
Number of rollouts total     0
Train Time (s)               146.26748043624684
(Previous) Eval Time (s)     20.765130613930523
Sample Time (s)              6.399905517697334
Epoch Time (s)               173.4325165678747
Total Train Time (s)         40168.6305154711
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:03:07.558337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #235 | Epoch Duration: 173.5152485370636
2020-01-12 19:03:07.558471 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7443731
Z variance train             0.13182107
KL Divergence                42.1919
KL Loss                      4.21919
QF Loss                      173.69598
VF Loss                      82.743324
Policy Loss                  -1338.9216
Q Predictions Mean           1334.9371
Q Predictions Std            1316.5126
Q Predictions Max            4224.2007
Q Predictions Min            577.79395
V Predictions Mean           1336.5875
V Predictions Std            1318.5104
V Predictions Max            4227.4814
V Predictions Min            579.1403
Log Pis Mean                 0.33510742
Log Pis Std                  3.978442
Log Pis Max                  17.412214
Log Pis Min                  -6.6421447
Policy mu Mean               0.051074352
Policy mu Std                0.94190073
Policy mu Max                3.1814303
Policy mu Min                -3.3937378
Policy log std Mean          -0.5386979
Policy log std Std           0.28472272
Policy log std Max           0.036548615
Policy log std Min           -2.9593387
Z mean eval                  1.7415183
Z variance eval              0.14029428
total_rewards                [9307.38261075 9444.2589238  9742.81776089 9235.56989138 9736.74401577
 9533.11919059 9518.2645387  9630.22741579 9696.67235001 9456.26254725]
total_rewards_mean           9530.13192449389
total_rewards_std            165.84429620926548
total_rewards_max            9742.817760892094
total_rewards_min            9235.569891377156
Number of train steps total  948000
Number of env steps total    2846000
Number of rollouts total     0
Train Time (s)               147.1857724711299
(Previous) Eval Time (s)     20.94881410524249
Sample Time (s)              6.424197501968592
Epoch Time (s)               174.55878407834098
Total Train Time (s)         40343.272571347654
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:06:02.201454 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #236 | Epoch Duration: 174.64288997650146
2020-01-12 19:06:02.201586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7409378
Z variance train             0.13979453
KL Divergence                42.04451
KL Loss                      4.204451
QF Loss                      179.87332
VF Loss                      62.000004
Policy Loss                  -1258.4338
Q Predictions Mean           1254.8398
Q Predictions Std            1235.7494
Q Predictions Max            4200.8193
Q Predictions Min            577.191
V Predictions Mean           1259.7344
V Predictions Std            1238.4583
V Predictions Max            4220.7427
V Predictions Min            579.4726
Log Pis Mean                 -0.064141296
Log Pis Std                  4.358242
Log Pis Max                  26.584398
Log Pis Min                  -5.892085
Policy mu Mean               -0.012388381
Policy mu Std                0.9302486
Policy mu Max                3.2856598
Policy mu Min                -4.382543
Policy log std Mean          -0.52080554
Policy log std Std           0.29007852
Policy log std Max           0.12649095
Policy log std Min           -3.0279634
Z mean eval                  1.7555393
Z variance eval              0.13308448
total_rewards                [8527.57484698 4164.5601825  8065.3162996  2073.39731536 8776.91508098
 7663.0807435  8745.04739764 8902.09271567 8075.17012076 8140.8812634 ]
total_rewards_mean           7313.4035966408355
total_rewards_std            2179.7970043241266
total_rewards_max            8902.092715673678
total_rewards_min            2073.397315361418
Number of train steps total  952000
Number of env steps total    2858000
Number of rollouts total     0
Train Time (s)               146.25779404724017
(Previous) Eval Time (s)     20.880973808001727
Sample Time (s)              6.53899160772562
Epoch Time (s)               173.67775946296751
Total Train Time (s)         40517.02848346345
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:08:55.960502 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #237 | Epoch Duration: 173.75880217552185
2020-01-12 19:08:55.960687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7550852
Z variance train             0.1328868
KL Divergence                40.875683
KL Loss                      4.0875683
QF Loss                      114.63052
VF Loss                      91.18154
Policy Loss                  -1148.7448
Q Predictions Mean           1149.1184
Q Predictions Std            1168.0715
Q Predictions Max            4311.929
Q Predictions Min            581.18854
V Predictions Mean           1154.7177
V Predictions Std            1172.4915
V Predictions Max            4324.1245
V Predictions Min            584.9489
Log Pis Mean                 -0.28310633
Log Pis Std                  3.4506326
Log Pis Max                  21.639008
Log Pis Min                  -6.637509
Policy mu Mean               0.03856479
Policy mu Std                0.8903793
Policy mu Max                2.7534466
Policy mu Min                -3.1301932
Policy log std Mean          -0.5144677
Policy log std Std           0.2734825
Policy log std Max           0.14652205
Policy log std Min           -2.4577131
Z mean eval                  1.7403314
Z variance eval              0.11732908
total_rewards                [6218.30140692 7400.5442076  8038.56561523 2968.33348393 3171.31999737
 5455.91808553 1614.54268978 2636.30375564 2847.84012573 7683.9041207 ]
total_rewards_mean           4803.557348843454
total_rewards_std            2294.710655628425
total_rewards_max            8038.565615233906
total_rewards_min            1614.5426897805185
Number of train steps total  956000
Number of env steps total    2870000
Number of rollouts total     0
Train Time (s)               146.9847324108705
(Previous) Eval Time (s)     17.378817431163043
Sample Time (s)              6.570080150850117
Epoch Time (s)               170.93362999288365
Total Train Time (s)         40688.04016756918
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:11:46.977190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #238 | Epoch Duration: 171.01626467704773
2020-01-12 19:11:46.977562 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7397734
Z variance train             0.117521666
KL Divergence                41.023403
KL Loss                      4.10234
QF Loss                      132.9189
VF Loss                      122.29071
Policy Loss                  -1251.8754
Q Predictions Mean           1245.7798
Q Predictions Std            1241.8401
Q Predictions Max            4221.3394
Q Predictions Min            564.8528
V Predictions Mean           1245.6187
V Predictions Std            1233.9236
V Predictions Max            4216.3706
V Predictions Min            573.5452
Log Pis Mean                 0.12590367
Log Pis Std                  3.9320297
Log Pis Max                  23.240826
Log Pis Min                  -6.7249384
Policy mu Mean               0.047979075
Policy mu Std                0.947397
Policy mu Max                5.4012117
Policy mu Min                -3.4870517
Policy log std Mean          -0.51210856
Policy log std Std           0.26960713
Policy log std Max           -0.040112257
Policy log std Min           -2.7522287
Z mean eval                  1.769359
Z variance eval              0.20383437
total_rewards                [9595.26468561 9463.80449176 9427.5703037  9688.35994229 9604.57532457
 9467.38053348 9613.95361562 9641.13476819 9748.06900711 9477.86637852]
total_rewards_mean           9572.797905086165
total_rewards_std            102.4930538907365
total_rewards_max            9748.0690071096
total_rewards_min            9427.570303696835
Number of train steps total  960000
Number of env steps total    2882000
Number of rollouts total     0
Train Time (s)               146.19603704707697
(Previous) Eval Time (s)     17.364326817449182
Sample Time (s)              6.656008009798825
Epoch Time (s)               170.21637187432498
Total Train Time (s)         40858.33538107155
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:14:37.273561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #239 | Epoch Duration: 170.29577136039734
2020-01-12 19:14:37.273706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7697443
Z variance train             0.20442705
KL Divergence                41.321583
KL Loss                      4.1321583
QF Loss                      161.51642
VF Loss                      95.096565
Policy Loss                  -1230.995
Q Predictions Mean           1227.3522
Q Predictions Std            1252.1006
Q Predictions Max            4370.191
Q Predictions Min            583.1786
V Predictions Mean           1228.5244
V Predictions Std            1243.479
V Predictions Max            4365.515
V Predictions Min            587.69617
Log Pis Mean                 -0.2040827
Log Pis Std                  3.8038342
Log Pis Max                  18.976147
Log Pis Min                  -5.813304
Policy mu Mean               0.036249157
Policy mu Std                0.8824146
Policy mu Max                3.4418783
Policy mu Min                -3.2778163
Policy log std Mean          -0.51396054
Policy log std Std           0.29290837
Policy log std Max           -0.027433693
Policy log std Min           -2.7066567
Z mean eval                  1.753783
Z variance eval              0.14757663
total_rewards                [9489.60749546 9717.59752625 9604.09264267 9611.74751001 9450.56241673
 9487.35941706 9851.47894701 9643.59456292 9522.55935442 9600.38984621]
total_rewards_mean           9597.898971872366
total_rewards_std            115.01527648717123
total_rewards_max            9851.478947010726
total_rewards_min            9450.562416729397
Number of train steps total  964000
Number of env steps total    2894000
Number of rollouts total     0
Train Time (s)               145.28915762668476
(Previous) Eval Time (s)     20.005855911877006
Sample Time (s)              12.263744393829256
Epoch Time (s)               177.55875793239102
Total Train Time (s)         41035.97555930726
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:17:34.915721 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #240 | Epoch Duration: 177.64188957214355
2020-01-12 19:17:34.915923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7535717
Z variance train             0.1478019
KL Divergence                41.283367
KL Loss                      4.128337
QF Loss                      85.24814
VF Loss                      59.295425
Policy Loss                  -1270.4902
Q Predictions Mean           1268.8276
Q Predictions Std            1285.6353
Q Predictions Max            4247.918
Q Predictions Min            553.3007
V Predictions Mean           1270.0411
V Predictions Std            1281.6582
V Predictions Max            4228.981
V Predictions Min            560.83905
Log Pis Mean                 -0.27866906
Log Pis Std                  3.2091324
Log Pis Max                  10.760291
Log Pis Min                  -8.796211
Policy mu Mean               0.01185518
Policy mu Std                0.88623947
Policy mu Max                2.5212872
Policy mu Min                -2.309916
Policy log std Mean          -0.5322993
Policy log std Std           0.27702394
Policy log std Max           0.03683579
Policy log std Min           -2.7036183
Z mean eval                  1.7555279
Z variance eval              0.11521077
total_rewards                [9368.46827921 9614.31496543 9957.35103509 9622.20331845 9722.32130851
 9518.36011407 9895.83114822 9686.60492376 9922.53296118 9735.81724786]
total_rewards_mean           9704.380530176826
total_rewards_std            176.68320384945196
total_rewards_max            9957.351035086973
total_rewards_min            9368.468279207476
Number of train steps total  968000
Number of env steps total    2906000
Number of rollouts total     0
Train Time (s)               147.4575348799117
(Previous) Eval Time (s)     21.027356008067727
Sample Time (s)              6.273262531496584
Epoch Time (s)               174.758153419476
Total Train Time (s)         41210.81481294893
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:20:29.762653 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #241 | Epoch Duration: 174.84649562835693
2020-01-12 19:20:29.762950 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7553165
Z variance train             0.11537477
KL Divergence                41.670174
KL Loss                      4.1670175
QF Loss                      95.99848
VF Loss                      42.348133
Policy Loss                  -1139.9138
Q Predictions Mean           1136.996
Q Predictions Std            1154.4907
Q Predictions Max            4280.847
Q Predictions Min            577.4439
V Predictions Mean           1141.137
V Predictions Std            1151.7992
V Predictions Max            4265.4053
V Predictions Min            581.39465
Log Pis Mean                 -0.10442451
Log Pis Std                  3.786532
Log Pis Max                  15.370172
Log Pis Min                  -8.657416
Policy mu Mean               0.077679984
Policy mu Std                0.8768772
Policy mu Max                2.5687475
Policy mu Min                -3.121379
Policy log std Mean          -0.5185261
Policy log std Std           0.29285476
Policy log std Max           -0.027443111
Policy log std Min           -2.7237647
Z mean eval                  1.7434313
Z variance eval              0.090328015
total_rewards                [9541.31272588 9622.82065607 9512.86409943 9709.71468569 9633.22243041
 9771.81552948 9720.80388474 9668.58886183 9818.02926137 9645.18831803]
total_rewards_mean           9664.436045294771
total_rewards_std            90.31941987685117
total_rewards_max            9818.029261374239
total_rewards_min            9512.864099432445
Number of train steps total  972000
Number of env steps total    2918000
Number of rollouts total     0
Train Time (s)               147.83431280078366
(Previous) Eval Time (s)     20.820023346226662
Sample Time (s)              6.342322268057615
Epoch Time (s)               174.99665841506794
Total Train Time (s)         41385.96210625628
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:23:24.908200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #242 | Epoch Duration: 175.14505815505981
2020-01-12 19:23:24.908448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.743277
Z variance train             0.090263925
KL Divergence                41.020523
KL Loss                      4.102052
QF Loss                      235.07556
VF Loss                      62.001694
Policy Loss                  -1051.2185
Q Predictions Mean           1048.563
Q Predictions Std            1068.6287
Q Predictions Max            4343.218
Q Predictions Min            581.14996
V Predictions Mean           1053.446
V Predictions Std            1070.2213
V Predictions Max            4356.4375
V Predictions Min            590.197
Log Pis Mean                 -0.29338676
Log Pis Std                  3.1654117
Log Pis Max                  14.731068
Log Pis Min                  -7.6059847
Policy mu Mean               0.0745933
Policy mu Std                0.8578729
Policy mu Max                2.7099662
Policy mu Min                -2.5289176
Policy log std Mean          -0.5217146
Policy log std Std           0.2903483
Policy log std Max           0.06759566
Policy log std Min           -2.4162245
Z mean eval                  1.7405046
Z variance eval              0.10184844
total_rewards                [9449.82976642 9617.67911817 9533.49903967 9400.18933113 9161.35954457
 1329.40227026 9256.75277929 9328.33718015 9582.00776033 9203.58912218]
total_rewards_mean           8586.264591217221
total_rewards_std            2423.5282635955355
total_rewards_max            9617.679118167634
total_rewards_min            1329.4022702603393
Number of train steps total  976000
Number of env steps total    2930000
Number of rollouts total     0
Train Time (s)               147.0014761062339
(Previous) Eval Time (s)     20.64854386402294
Sample Time (s)              6.428846076596528
Epoch Time (s)               174.07886604685336
Total Train Time (s)         41560.12688823696
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:26:19.073468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #243 | Epoch Duration: 174.16484022140503
2020-01-12 19:26:19.073601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7400625
Z variance train             0.10216812
KL Divergence                41.26239
KL Loss                      4.1262393
QF Loss                      86.1644
VF Loss                      94.77193
Policy Loss                  -1053.2701
Q Predictions Mean           1050.8701
Q Predictions Std            1047.8953
Q Predictions Max            4321.281
Q Predictions Min            573.4082
V Predictions Mean           1058.206
V Predictions Std            1051.2747
V Predictions Max            4307.122
V Predictions Min            582.78674
Log Pis Mean                 -0.38569644
Log Pis Std                  3.4732554
Log Pis Max                  13.311855
Log Pis Min                  -6.989979
Policy mu Mean               0.06256003
Policy mu Std                0.864404
Policy mu Max                3.1574893
Policy mu Min                -3.1732137
Policy log std Mean          -0.5021481
Policy log std Std           0.2733402
Policy log std Max           -0.008643925
Policy log std Min           -2.51032
Z mean eval                  1.746245
Z variance eval              0.12272687
total_rewards                [8675.39151923 8557.95395327 8576.71654798 8662.24498571 8814.13968461
 8540.32764168 8577.13554502 8420.73578825 8776.7660787  8510.22845774]
total_rewards_mean           8611.164020218954
total_rewards_std            114.89219611982645
total_rewards_max            8814.13968461366
total_rewards_min            8420.73578824751
Number of train steps total  980000
Number of env steps total    2942000
Number of rollouts total     0
Train Time (s)               145.63153187185526
(Previous) Eval Time (s)     20.76222208607942
Sample Time (s)              6.432944263797253
Epoch Time (s)               172.82669822173193
Total Train Time (s)         41733.038160453085
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:29:11.986403 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #244 | Epoch Duration: 172.9127061367035
2020-01-12 19:29:11.986535 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #244 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7465522
Z variance train             0.12290241
KL Divergence                41.473034
KL Loss                      4.1473036
QF Loss                      63.876736
VF Loss                      28.068262
Policy Loss                  -1125.5853
Q Predictions Mean           1123.0966
Q Predictions Std            1142.3922
Q Predictions Max            4383.3125
Q Predictions Min            586.70917
V Predictions Mean           1124.6482
V Predictions Std            1137.6709
V Predictions Max            4364.7256
V Predictions Min            592.40564
Log Pis Mean                 -0.41343692
Log Pis Std                  3.7192342
Log Pis Max                  16.857246
Log Pis Min                  -6.8796806
Policy mu Mean               0.06790906
Policy mu Std                0.84742105
Policy mu Max                3.071768
Policy mu Min                -2.9213562
Policy log std Mean          -0.52660465
Policy log std Std           0.28679767
Policy log std Max           0.044259965
Policy log std Min           -2.7207499
Z mean eval                  1.7536799
Z variance eval              0.09292577
total_rewards                [ 9401.82031761  9743.06000706  9641.73144054  9684.43789165
  9792.63591848  9688.89156939  9631.79731749  9494.9398502
  8511.23113671 10004.45109694]
total_rewards_mean           9559.499654606238
total_rewards_std            381.8726467276882
total_rewards_max            10004.451096936282
total_rewards_min            8511.231136713779
Number of train steps total  984000
Number of env steps total    2954000
Number of rollouts total     0
Train Time (s)               147.13269118079916
(Previous) Eval Time (s)     20.84032960794866
Sample Time (s)              6.546165274921805
Epoch Time (s)               174.51918606366962
Total Train Time (s)         41907.63729048194
Epoch                        245
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:32:06.588874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #245 | Epoch Duration: 174.60221147537231
2020-01-12 19:32:06.589124 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.757605
Z variance train             0.09310536
KL Divergence                41.985695
KL Loss                      4.19857
QF Loss                      168.50597
VF Loss                      180.81978
Policy Loss                  -1298.4866
Q Predictions Mean           1295.0479
Q Predictions Std            1276.7852
Q Predictions Max            4271.6494
Q Predictions Min            563.2525
V Predictions Mean           1291.0063
V Predictions Std            1266.802
V Predictions Max            4246.6514
V Predictions Min            588.1915
Log Pis Mean                 0.053647757
Log Pis Std                  3.7410457
Log Pis Max                  22.350365
Log Pis Min                  -7.799821
Policy mu Mean               0.027179683
Policy mu Std                0.9035577
Policy mu Max                3.401928
Policy mu Min                -4.3787894
Policy log std Mean          -0.53548014
Policy log std Std           0.28902376
Policy log std Max           0.18270916
Policy log std Min           -2.343298
Z mean eval                  1.741952
Z variance eval              0.1255991
total_rewards                [9349.87380785 9647.21075538 9652.24171928 9986.90827054 9778.96219524
 9694.90596303 8262.72522524 9959.44548285 9839.52627217 9696.98482609]
total_rewards_mean           9586.878451767969
total_rewards_std            473.3725597484358
total_rewards_max            9986.90827054001
total_rewards_min            8262.725225241616
Number of train steps total  988000
Number of env steps total    2966000
Number of rollouts total     0
Train Time (s)               148.28509284881875
(Previous) Eval Time (s)     20.013280373997986
Sample Time (s)              6.608933925628662
Epoch Time (s)               174.9073071484454
Total Train Time (s)         42082.63267545588
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:35:01.589070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #246 | Epoch Duration: 174.99973845481873
2020-01-12 19:35:01.589337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.742396
Z variance train             0.12574041
KL Divergence                42.18763
KL Loss                      4.218763
QF Loss                      249.04099
VF Loss                      122.4818
Policy Loss                  -1134.4979
Q Predictions Mean           1132.6044
Q Predictions Std            1142.4135
Q Predictions Max            4294.5356
Q Predictions Min            594.22003
V Predictions Mean           1132.384
V Predictions Std            1137.6532
V Predictions Max            4297.891
V Predictions Min            600.22125
Log Pis Mean                 -0.24487051
Log Pis Std                  3.3126407
Log Pis Max                  10.053282
Log Pis Min                  -6.6233916
Policy mu Mean               0.10837755
Policy mu Std                0.84246606
Policy mu Max                2.6497948
Policy mu Min                -2.4111938
Policy log std Mean          -0.5315239
Policy log std Std           0.2939661
Policy log std Max           -0.025124907
Policy log std Min           -2.565117
Z mean eval                  1.7761278
Z variance eval              0.21891162
total_rewards                [9327.07459755 6943.99354212 9795.29654445 9457.85499822 9508.01460198
 9582.14422624 9831.87033275 9840.46733598 9746.66037073 9640.24391505]
total_rewards_mean           9367.362046506332
total_rewards_std            823.9840846390379
total_rewards_max            9840.467335978165
total_rewards_min            6943.993542118503
Number of train steps total  992000
Number of env steps total    2978000
Number of rollouts total     0
Train Time (s)               144.99456060910597
(Previous) Eval Time (s)     20.642044589389116
Sample Time (s)              6.4396892176009715
Epoch Time (s)               172.07629441609606
Total Train Time (s)         42254.856095574796
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:37:53.838012 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #247 | Epoch Duration: 172.24846172332764
2020-01-12 19:37:53.838247 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7808367
Z variance train             0.21946359
KL Divergence                41.646427
KL Loss                      4.164643
QF Loss                      3137.4502
VF Loss                      71.614
Policy Loss                  -1249.729
Q Predictions Mean           1247.2704
Q Predictions Std            1268.4957
Q Predictions Max            4341.874
Q Predictions Min            553.904
V Predictions Mean           1249.7037
V Predictions Std            1263.8331
V Predictions Max            4333.7554
V Predictions Min            582.7824
Log Pis Mean                 0.13475206
Log Pis Std                  3.945512
Log Pis Max                  13.038726
Log Pis Min                  -6.367713
Policy mu Mean               0.057308603
Policy mu Std                0.9101018
Policy mu Max                3.0814364
Policy mu Min                -3.2372906
Policy log std Mean          -0.5317345
Policy log std Std           0.31471327
Policy log std Max           -0.0015593469
Policy log std Min           -2.7365646
Z mean eval                  1.7895944
Z variance eval              0.20777074
total_rewards                [9285.11854296 9741.3798338  9641.53032895 9551.89385633 9602.09142616
 9423.22838334 8901.55215058 9752.73051394 9654.35256234 9649.21632879]
total_rewards_mean           9520.30939271924
total_rewards_std            246.4663596926194
total_rewards_max            9752.73051394028
total_rewards_min            8901.552150584128
Number of train steps total  996000
Number of env steps total    2990000
Number of rollouts total     0
Train Time (s)               147.26645398605615
(Previous) Eval Time (s)     20.95986649999395
Sample Time (s)              6.370590458158404
Epoch Time (s)               174.5969109442085
Total Train Time (s)         42429.557815935
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:40:48.521030 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #248 | Epoch Duration: 174.68256545066833
2020-01-12 19:40:48.521355 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7857702
Z variance train             0.20802024
KL Divergence                41.312172
KL Loss                      4.1312175
QF Loss                      3491.8516
VF Loss                      86.253624
Policy Loss                  -1291.3575
Q Predictions Mean           1290.3569
Q Predictions Std            1306.7186
Q Predictions Max            4359.3237
Q Predictions Min            575.464
V Predictions Mean           1295.1721
V Predictions Std            1309.8551
V Predictions Max            4366.727
V Predictions Min            578.3418
Log Pis Mean                 -0.4919771
Log Pis Std                  3.702838
Log Pis Max                  11.06343
Log Pis Min                  -8.361116
Policy mu Mean               0.0042738332
Policy mu Std                0.88259333
Policy mu Max                2.7075617
Policy mu Min                -3.3106897
Policy log std Mean          -0.52201027
Policy log std Std           0.28866777
Policy log std Max           -0.020443559
Policy log std Min           -2.7537513
Z mean eval                  1.7741749
Z variance eval              0.19469921
total_rewards                [8953.59386701 9078.20746522 9082.6129015  9184.80300371 9140.97529638
 9161.61964361 9225.32541587 9043.93005791 9106.4554853  9179.93103352]
total_rewards_mean           9115.745417002716
total_rewards_std            75.94817080568373
total_rewards_max            9225.325415871645
total_rewards_min            8953.593867008452
Number of train steps total  1000000
Number of env steps total    3002000
Number of rollouts total     0
Train Time (s)               144.73458814807236
(Previous) Eval Time (s)     20.888639369048178
Sample Time (s)              5.518612444866449
Epoch Time (s)               171.141839961987
Total Train Time (s)         42600.78605386708
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:43:39.751512 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #249 | Epoch Duration: 171.22993779182434
2020-01-12 19:43:39.751645 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7708296
Z variance train             0.19426517
KL Divergence                41.50176
KL Loss                      4.150176
QF Loss                      312.63577
VF Loss                      79.54883
Policy Loss                  -1214.9336
Q Predictions Mean           1212.8563
Q Predictions Std            1199.0344
Q Predictions Max            4320.982
Q Predictions Min            566.72766
V Predictions Mean           1216.3716
V Predictions Std            1199.1665
V Predictions Max            4318.967
V Predictions Min            584.54297
Log Pis Mean                 -0.09262577
Log Pis Std                  3.9762115
Log Pis Max                  14.427551
Log Pis Min                  -6.418995
Policy mu Mean               0.010030989
Policy mu Std                0.9012278
Policy mu Max                3.8242
Policy mu Min                -3.318738
Policy log std Mean          -0.51690495
Policy log std Std           0.3031114
Policy log std Max           -0.0356839
Policy log std Min           -2.5228927
Z mean eval                  1.779094
Z variance eval              0.16788673
total_rewards                [9293.24347319 9320.62791688 8982.58661267 9102.22969245 9626.58224729
 9579.82159245 9651.96357395 9203.52862491 9475.62391751 5204.51161802]
total_rewards_mean           8944.07192693135
total_rewards_std            1264.7330786139976
total_rewards_max            9651.963573947622
total_rewards_min            5204.511618020752
Number of train steps total  1004000
Number of env steps total    3014000
Number of rollouts total     0
Train Time (s)               147.85446588508785
(Previous) Eval Time (s)     20.90647173067555
Sample Time (s)              6.4679902866482735
Epoch Time (s)               175.22892790241167
Total Train Time (s)         42776.143607934006
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:46:35.132242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #250 | Epoch Duration: 175.38044667243958
2020-01-12 19:46:35.132575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.781633
Z variance train             0.16794653
KL Divergence                42.087605
KL Loss                      4.2087607
QF Loss                      162.08014
VF Loss                      90.7452
Policy Loss                  -1182.178
Q Predictions Mean           1179.3741
Q Predictions Std            1190.5563
Q Predictions Max            4399.238
Q Predictions Min            568.9331
V Predictions Mean           1177.9407
V Predictions Std            1183.6565
V Predictions Max            4365.2056
V Predictions Min            569.1673
Log Pis Mean                 0.036378667
Log Pis Std                  3.9523475
Log Pis Max                  16.46635
Log Pis Min                  -7.4223256
Policy mu Mean               0.1192106
Policy mu Std                0.8995898
Policy mu Max                3.3675923
Policy mu Min                -2.8045778
Policy log std Mean          -0.53068477
Policy log std Std           0.29475403
Policy log std Max           0.07542354
Policy log std Min           -2.8296185
Z mean eval                  1.7824188
Z variance eval              0.08480109
total_rewards                [9561.63311355 9911.994618   9585.5584945  9769.39539689 9518.80373113
 9730.77940212 9621.22299616 9466.27733852 9639.09516555 9737.44180413]
total_rewards_mean           9654.220206055687
total_rewards_std            126.79299787697703
total_rewards_max            9911.994617998691
total_rewards_min            9466.277338519903
Number of train steps total  1008000
Number of env steps total    3026000
Number of rollouts total     0
Train Time (s)               146.4372411747463
(Previous) Eval Time (s)     20.998735588043928
Sample Time (s)              6.387659186962992
Epoch Time (s)               173.82363594975322
Total Train Time (s)         42950.06826605741
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:49:29.037606 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #251 | Epoch Duration: 173.90480995178223
2020-01-12 19:49:29.037741 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.779948
Z variance train             0.08494794
KL Divergence                42.98838
KL Loss                      4.298838
QF Loss                      115.548996
VF Loss                      40.357155
Policy Loss                  -1172.4442
Q Predictions Mean           1169.6829
Q Predictions Std            1194.9348
Q Predictions Max            4375.903
Q Predictions Min            580.5599
V Predictions Mean           1173.3706
V Predictions Std            1197.6575
V Predictions Max            4377.232
V Predictions Min            584.6308
Log Pis Mean                 -0.47764584
Log Pis Std                  3.542006
Log Pis Max                  12.724888
Log Pis Min                  -6.3510075
Policy mu Mean               0.060035665
Policy mu Std                0.85212046
Policy mu Max                2.9897208
Policy mu Min                -3.0786083
Policy log std Mean          -0.53258693
Policy log std Std           0.2844259
Policy log std Max           -0.03864561
Policy log std Min           -2.686901
Z mean eval                  1.7742409
Z variance eval              0.069273874
total_rewards                [7918.3108124  8404.26100453 1993.11720653 8637.12196374 8686.91210689
 1241.89127459 9086.00930346 9261.13435885 8897.57452191 8543.00803974]
total_rewards_mean           7266.934059262074
total_rewards_std            2851.2990768885734
total_rewards_max            9261.134358845975
total_rewards_min            1241.8912745857501
Number of train steps total  1012000
Number of env steps total    3038000
Number of rollouts total     0
Train Time (s)               145.87022060807794
(Previous) Eval Time (s)     20.873014727141708
Sample Time (s)              6.406892157159746
Epoch Time (s)               173.1501274923794
Total Train Time (s)         43123.30724194879
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:52:22.278305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #252 | Epoch Duration: 173.24047088623047
2020-01-12 19:52:22.278442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7725197
Z variance train             0.06935481
KL Divergence                42.754585
KL Loss                      4.275459
QF Loss                      116.50628
VF Loss                      61.664944
Policy Loss                  -1372.1632
Q Predictions Mean           1370.2963
Q Predictions Std            1348.9945
Q Predictions Max            4335.462
Q Predictions Min            584.12866
V Predictions Mean           1374.6292
V Predictions Std            1346.0734
V Predictions Max            4324.6953
V Predictions Min            581.8322
Log Pis Mean                 0.16490975
Log Pis Std                  4.2498426
Log Pis Max                  24.896267
Log Pis Min                  -7.650147
Policy mu Mean               0.07763508
Policy mu Std                0.9504339
Policy mu Max                4.084854
Policy mu Min                -4.3351984
Policy log std Mean          -0.5551511
Policy log std Std           0.29576644
Policy log std Max           -0.078214645
Policy log std Min           -2.6446655
Z mean eval                  1.7733316
Z variance eval              0.1054492
total_rewards                [9297.31855359 9524.66210388 9736.58595865 9376.52987659 9495.91938876
 9495.36825022 9577.36126132 9375.93736886 9560.2794408  9671.36630047]
total_rewards_mean           9511.132850312875
total_rewards_std            128.8723389020426
total_rewards_max            9736.58595864641
total_rewards_min            9297.318553588626
Number of train steps total  1016000
Number of env steps total    3050000
Number of rollouts total     0
Train Time (s)               147.20895784022287
(Previous) Eval Time (s)     20.903329230844975
Sample Time (s)              6.391632665414363
Epoch Time (s)               174.5039197364822
Total Train Time (s)         43297.8927455768
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:55:16.865866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #253 | Epoch Duration: 174.58732438087463
2020-01-12 19:55:16.865999 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.772883
Z variance train             0.10536511
KL Divergence                42.610783
KL Loss                      4.2610784
QF Loss                      314.62955
VF Loss                      47.436485
Policy Loss                  -1174.5073
Q Predictions Mean           1174.7141
Q Predictions Std            1197.613
Q Predictions Max            4362.861
Q Predictions Min            596.42957
V Predictions Mean           1174.3839
V Predictions Std            1198.0925
V Predictions Max            4344.783
V Predictions Min            596.0866
Log Pis Mean                 -0.22037485
Log Pis Std                  3.5147452
Log Pis Max                  14.948996
Log Pis Min                  -5.9011946
Policy mu Mean               0.037654866
Policy mu Std                0.8659603
Policy mu Max                2.5179725
Policy mu Min                -2.5017154
Policy log std Mean          -0.52178925
Policy log std Std           0.2663274
Policy log std Max           0.020970047
Policy log std Min           -2.5639024
Z mean eval                  1.7574002
Z variance eval              0.083392896
total_rewards                [9436.59517697 7645.52392509 9888.78148295 9283.85671157 9772.65494797
 9625.66442201 9476.33448268 9675.11230832 9727.43305852 8940.84725862]
total_rewards_mean           9347.280377469391
total_rewards_std            623.9769262334604
total_rewards_max            9888.781482949382
total_rewards_min            7645.523925085676
Number of train steps total  1020000
Number of env steps total    3062000
Number of rollouts total     0
Train Time (s)               146.61939822230488
(Previous) Eval Time (s)     20.885880242101848
Sample Time (s)              6.405118784401566
Epoch Time (s)               173.9103972488083
Total Train Time (s)         43471.880744062364
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:58:10.857068 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #254 | Epoch Duration: 173.99095678329468
2020-01-12 19:58:10.857262 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7567291
Z variance train             0.083589815
KL Divergence                42.660053
KL Loss                      4.2660055
QF Loss                      110.299545
VF Loss                      58.03016
Policy Loss                  -1345.028
Q Predictions Mean           1344.6294
Q Predictions Std            1344.6343
Q Predictions Max            4363.851
Q Predictions Min            570.07184
V Predictions Mean           1344.8416
V Predictions Std            1338.7618
V Predictions Max            4375.342
V Predictions Min            573.71094
Log Pis Mean                 0.19450305
Log Pis Std                  4.052311
Log Pis Max                  16.350153
Log Pis Min                  -6.6292815
Policy mu Mean               0.031369675
Policy mu Std                0.92569155
Policy mu Max                2.7624369
Policy mu Min                -3.1202905
Policy log std Mean          -0.54127717
Policy log std Std           0.287054
Policy log std Max           0.060705245
Policy log std Min           -2.9605079
Z mean eval                  1.7736576
Z variance eval              0.124440074
total_rewards                [9543.0524522  9568.09634856 9348.12763431 9788.60165247 9472.89849871
 9547.89491777 9827.39908861 9432.49402028 9562.72839157 9663.41812542]
total_rewards_mean           9575.471112989708
total_rewards_std            141.8815831949464
total_rewards_max            9827.39908861006
total_rewards_min            9348.127634314687
Number of train steps total  1024000
Number of env steps total    3074000
Number of rollouts total     0
Train Time (s)               146.66588221257553
(Previous) Eval Time (s)     21.13049812288955
Sample Time (s)              6.607282637152821
Epoch Time (s)               174.4036629726179
Total Train Time (s)         43646.37151093315
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:01:05.350325 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #255 | Epoch Duration: 174.4929323196411
2020-01-12 20:01:05.350468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7696536
Z variance train             0.12433443
KL Divergence                42.53275
KL Loss                      4.253275
QF Loss                      137.61432
VF Loss                      200.22217
Policy Loss                  -1205.2664
Q Predictions Mean           1207.1848
Q Predictions Std            1244.0605
Q Predictions Max            4375.4473
Q Predictions Min            596.6173
V Predictions Mean           1213.2854
V Predictions Std            1244.6924
V Predictions Max            4366.8154
V Predictions Min            603.7684
Log Pis Mean                 -0.05770106
Log Pis Std                  3.5814118
Log Pis Max                  13.804436
Log Pis Min                  -6.3363624
Policy mu Mean               0.07291773
Policy mu Std                0.8686205
Policy mu Max                2.6653752
Policy mu Min                -2.5074222
Policy log std Mean          -0.5305609
Policy log std Std           0.27696538
Policy log std Max           0.04726708
Policy log std Min           -2.407583
Z mean eval                  1.7659814
Z variance eval              0.14784692
total_rewards                [9482.0832671  9526.10796027 9586.63965771 9076.85540055 9432.76884432
 9425.94774397 9457.84490658 9236.0533262  9300.11439827 5282.76617061]
total_rewards_mean           8980.71816755669
total_rewards_std            1240.8661608371513
total_rewards_max            9586.639657705757
total_rewards_min            5282.766170613876
Number of train steps total  1028000
Number of env steps total    3086000
Number of rollouts total     0
Train Time (s)               144.8586970884353
(Previous) Eval Time (s)     20.92569271288812
Sample Time (s)              6.48561123246327
Epoch Time (s)               172.27000103378668
Total Train Time (s)         43818.71970782569
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:03:57.699361 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #256 | Epoch Duration: 172.34879088401794
2020-01-12 20:03:57.699493 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7671797
Z variance train             0.14730713
KL Divergence                41.99893
KL Loss                      4.1998935
QF Loss                      3088.1333
VF Loss                      79.66611
Policy Loss                  -1119.6488
Q Predictions Mean           1117.0925
Q Predictions Std            1146.0569
Q Predictions Max            4369.577
Q Predictions Min            533.8716
V Predictions Mean           1116.3622
V Predictions Std            1140.1249
V Predictions Max            4337.3555
V Predictions Min            562.38873
Log Pis Mean                 -0.24003728
Log Pis Std                  3.6565027
Log Pis Max                  15.823721
Log Pis Min                  -6.151873
Policy mu Mean               0.047149498
Policy mu Std                0.8578993
Policy mu Max                2.84176
Policy mu Min                -2.6344876
Policy log std Mean          -0.51927334
Policy log std Std           0.28049564
Policy log std Max           0.22885507
Policy log std Min           -2.368062
Z mean eval                  1.7467384
Z variance eval              0.07817599
total_rewards                [9360.25716485 9156.6142327  9418.1786055  9062.56081975 9038.25587707
 9232.31632545 9223.43472996 9450.11777444 9547.63202213 9116.12260379]
total_rewards_mean           9260.549015562578
total_rewards_std            166.0094326399013
total_rewards_max            9547.632022130394
total_rewards_min            9038.255877073909
Number of train steps total  1032000
Number of env steps total    3098000
Number of rollouts total     0
Train Time (s)               148.3286285973154
(Previous) Eval Time (s)     17.352066116873175
Sample Time (s)              6.619578615296632
Epoch Time (s)               172.3002733294852
Total Train Time (s)         43991.103924071416
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:06:50.087909 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #257 | Epoch Duration: 172.3882999420166
2020-01-12 20:06:50.088097 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7466068
Z variance train             0.078112744
KL Divergence                43.106705
KL Loss                      4.3106704
QF Loss                      113.54188
VF Loss                      40.66529
Policy Loss                  -1205.5977
Q Predictions Mean           1206.2733
Q Predictions Std            1198.4668
Q Predictions Max            4369.998
Q Predictions Min            589.5702
V Predictions Mean           1204.4309
V Predictions Std            1195.4578
V Predictions Max            4353.837
V Predictions Min            590.47095
Log Pis Mean                 -0.5620737
Log Pis Std                  3.5955713
Log Pis Max                  14.956507
Log Pis Min                  -7.457562
Policy mu Mean               0.058630973
Policy mu Std                0.86694425
Policy mu Max                3.1030345
Policy mu Min                -3.631264
Policy log std Mean          -0.5288134
Policy log std Std           0.26747486
Policy log std Max           0.02033484
Policy log std Min           -2.7380586
Z mean eval                  1.7535006
Z variance eval              0.101828896
total_rewards                [9014.4994191  8955.6178815  9112.27310852 9230.61919304 9226.20428257
 9150.81280974 9030.58887528 9155.16566097 9182.65525363 9303.63480021]
total_rewards_mean           9136.207128455524
total_rewards_std            103.4062988981088
total_rewards_max            9303.634800207385
total_rewards_min            8955.617881498874
Number of train steps total  1036000
Number of env steps total    3110000
Number of rollouts total     0
Train Time (s)               146.43617687094957
(Previous) Eval Time (s)     20.645288208965212
Sample Time (s)              6.701856094412506
Epoch Time (s)               173.78332117432728
Total Train Time (s)         44164.97197356913
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:09:43.956227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #258 | Epoch Duration: 173.8679940700531
2020-01-12 20:09:43.956369 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #258 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.757515
Z variance train             0.102180645
KL Divergence                42.70831
KL Loss                      4.270831
QF Loss                      118.2476
VF Loss                      114.67954
Policy Loss                  -1116.6198
Q Predictions Mean           1114.4193
Q Predictions Std            1153.6993
Q Predictions Max            4426.0
Q Predictions Min            592.1076
V Predictions Mean           1110.6354
V Predictions Std            1145.0475
V Predictions Max            4377.2983
V Predictions Min            599.01117
Log Pis Mean                 -0.254673
Log Pis Std                  3.5463016
Log Pis Max                  12.619457
Log Pis Min                  -6.426708
Policy mu Mean               0.10736949
Policy mu Std                0.85020524
Policy mu Max                2.7074182
Policy mu Min                -2.3784518
Policy log std Mean          -0.5272296
Policy log std Std           0.27173275
Policy log std Max           -0.010414362
Policy log std Min           -2.3654675
Z mean eval                  1.7456992
Z variance eval              0.11958937
total_rewards                [ 9582.03346982  9992.80349231  9806.89539839  9841.1413341
  9952.94112694  9750.0695819   9844.52247665 10217.08594831
  9650.18901719  9727.11601141]
total_rewards_mean           9836.479785701767
total_rewards_std            173.98200587888314
total_rewards_max            10217.085948311493
total_rewards_min            9582.033469821065
Number of train steps total  1040000
Number of env steps total    3122000
Number of rollouts total     0
Train Time (s)               144.62589588807896
(Previous) Eval Time (s)     20.62823871569708
Sample Time (s)              6.520058323163539
Epoch Time (s)               171.77419292693958
Total Train Time (s)         44336.82399552921
Epoch                        259
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:12:35.810516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #259 | Epoch Duration: 171.85404872894287
2020-01-12 20:12:35.810658 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7392038
Z variance train             0.11992015
KL Divergence                42.237
KL Loss                      4.2237
QF Loss                      173.88284
VF Loss                      218.82959
Policy Loss                  -1194.1675
Q Predictions Mean           1191.1134
Q Predictions Std            1205.2891
Q Predictions Max            4360.028
Q Predictions Min            601.7235
V Predictions Mean           1202.6624
V Predictions Std            1212.2273
V Predictions Max            4361.2905
V Predictions Min            601.97485
Log Pis Mean                 -0.076390214
Log Pis Std                  3.6655471
Log Pis Max                  12.557689
Log Pis Min                  -7.4810295
Policy mu Mean               0.08533436
Policy mu Std                0.8968728
Policy mu Max                2.8948433
Policy mu Min                -3.3117871
Policy log std Mean          -0.53730637
Policy log std Std           0.29991594
Policy log std Max           0.20123446
Policy log std Min           -2.766329
Z mean eval                  1.7346836
Z variance eval              0.09075831
total_rewards                [8582.13087516 9500.02280516 9639.52496233 9386.68534673 9185.10237711
 9644.74223414 9198.08859355 9127.5286929  9467.13042529 9617.0004374 ]
total_rewards_mean           9334.795674976314
total_rewards_std            310.9070885407209
total_rewards_max            9644.74223414028
total_rewards_min            8582.130875159151
Number of train steps total  1044000
Number of env steps total    3134000
Number of rollouts total     0
Train Time (s)               147.3854846721515
(Previous) Eval Time (s)     17.361706456169486
Sample Time (s)              7.163505083415657
Epoch Time (s)               171.91069621173665
Total Train Time (s)         44508.81322113611
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:15:27.812279 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #260 | Epoch Duration: 172.0015058517456
2020-01-12 20:15:27.812466 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7356094
Z variance train             0.090810955
KL Divergence                41.900925
KL Loss                      4.1900926
QF Loss                      128.53183
VF Loss                      121.72565
Policy Loss                  -1248.1598
Q Predictions Mean           1248.9766
Q Predictions Std            1258.8635
Q Predictions Max            4340.17
Q Predictions Min            593.4023
V Predictions Mean           1239.8278
V Predictions Std            1251.0731
V Predictions Max            4293.5386
V Predictions Min            592.1569
Log Pis Mean                 -0.38945076
Log Pis Std                  3.8229377
Log Pis Max                  11.162537
Log Pis Min                  -10.818248
Policy mu Mean               0.0821761
Policy mu Std                0.86427796
Policy mu Max                2.6682222
Policy mu Min                -2.6191435
Policy log std Mean          -0.51123875
Policy log std Std           0.27295086
Policy log std Max           0.022065043
Policy log std Min           -2.7542558
Z mean eval                  1.7592528
Z variance eval              0.115919426
total_rewards                [8733.29606113 9129.99931395 8882.51067484 9690.71167706 9382.29636179
 9319.7893472  9174.00853016 8779.24326081 9368.36617903 9185.75061213]
total_rewards_mean           9164.597201809138
total_rewards_std            283.8344516791523
total_rewards_max            9690.711677056248
total_rewards_min            8733.296061128049
Number of train steps total  1048000
Number of env steps total    3146000
Number of rollouts total     0
Train Time (s)               146.63168477499858
(Previous) Eval Time (s)     20.716114414855838
Sample Time (s)              6.353921830654144
Epoch Time (s)               173.70172102050856
Total Train Time (s)         44682.61376539664
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:18:21.614518 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #261 | Epoch Duration: 173.80190205574036
2020-01-12 20:18:21.614765 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7592831
Z variance train             0.11545143
KL Divergence                40.196453
KL Loss                      4.019645
QF Loss                      94.97003
VF Loss                      149.12033
Policy Loss                  -1268.4645
Q Predictions Mean           1265.7703
Q Predictions Std            1264.2429
Q Predictions Max            4391.273
Q Predictions Min            603.3117
V Predictions Mean           1272.4617
V Predictions Std            1271.0067
V Predictions Max            4393.1777
V Predictions Min            600.84204
Log Pis Mean                 -0.3984337
Log Pis Std                  3.463973
Log Pis Max                  10.35025
Log Pis Min                  -7.520997
Policy mu Mean               0.0481486
Policy mu Std                0.90044373
Policy mu Max                2.6502335
Policy mu Min                -2.714939
Policy log std Mean          -0.5165883
Policy log std Std           0.2921982
Policy log std Max           0.043790698
Policy log std Min           -2.896711
Z mean eval                  1.745047
Z variance eval              0.08715452
total_rewards                [9280.48230629 9383.77209041 9353.4571532  8884.89910416 8916.26078091
 9359.3328798  9383.23904886 9219.88198348 9455.93200074 9036.15902022]
total_rewards_mean           9227.3416368059
total_rewards_std            196.93232675694512
total_rewards_max            9455.93200073663
total_rewards_min            8884.899104160253
Number of train steps total  1052000
Number of env steps total    3158000
Number of rollouts total     0
Train Time (s)               146.6336931148544
(Previous) Eval Time (s)     20.84137403825298
Sample Time (s)              6.371843389701098
Epoch Time (s)               173.84691054280847
Total Train Time (s)         44856.765758476686
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:21:15.765526 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #262 | Epoch Duration: 174.15058064460754
2020-01-12 20:21:15.765764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #262 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7452042
Z variance train             0.0868842
KL Divergence                41.589752
KL Loss                      4.158975
QF Loss                      180.93974
VF Loss                      126.100494
Policy Loss                  -1238.6925
Q Predictions Mean           1235.9426
Q Predictions Std            1263.0867
Q Predictions Max            4398.207
Q Predictions Min            602.05054
V Predictions Mean           1234.561
V Predictions Std            1256.9209
V Predictions Max            4383.42
V Predictions Min            603.8504
Log Pis Mean                 0.017342582
Log Pis Std                  3.693031
Log Pis Max                  16.862032
Log Pis Min                  -8.191497
Policy mu Mean               -0.00019532256
Policy mu Std                0.8909035
Policy mu Max                2.7036388
Policy mu Min                -2.4853492
Policy log std Mean          -0.524471
Policy log std Std           0.29293114
Policy log std Max           0.0033568144
Policy log std Min           -2.9662037
Z mean eval                  1.7660414
Z variance eval              0.092907295
total_rewards                [9246.33412308 9880.27072724 9510.18602029 9725.82068277 9821.2008116
 9919.45869741 9718.74481617 9807.52747678 9934.84722089 9840.51884968]
total_rewards_mean           9740.490942591063
total_rewards_std            202.05820955649847
total_rewards_max            9934.847220892663
total_rewards_min            9246.334123076897
Number of train steps total  1056000
Number of env steps total    3170000
Number of rollouts total     0
Train Time (s)               145.5090962871909
(Previous) Eval Time (s)     20.74479079199955
Sample Time (s)              6.479285418521613
Epoch Time (s)               172.73317249771208
Total Train Time (s)         45029.58179012034
Epoch                        263
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:24:08.580833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #263 | Epoch Duration: 172.81490421295166
2020-01-12 20:24:08.580970 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7674544
Z variance train             0.09268341
KL Divergence                42.820137
KL Loss                      4.282014
QF Loss                      142.76653
VF Loss                      50.05094
Policy Loss                  -1257.801
Q Predictions Mean           1251.8201
Q Predictions Std            1260.7694
Q Predictions Max            4382.842
Q Predictions Min            579.8911
V Predictions Mean           1256.5542
V Predictions Std            1258.1921
V Predictions Max            4379.6216
V Predictions Min            582.98804
Log Pis Mean                 -0.054270566
Log Pis Std                  3.787392
Log Pis Max                  13.063032
Log Pis Min                  -10.751216
Policy mu Mean               0.07265356
Policy mu Std                0.88973165
Policy mu Max                2.4966269
Policy mu Min                -2.8431544
Policy log std Mean          -0.54232186
Policy log std Std           0.3004154
Policy log std Max           -0.016217709
Policy log std Min           -2.8722336
Z mean eval                  1.7454135
Z variance eval              0.09278419
total_rewards                [9609.03153428 9702.18040305 9696.43015969 9879.92615209 9975.52721157
 9807.92252283 9884.29342294 9895.78264647 9853.73068436 9609.89229134]
total_rewards_mean           9791.471702862966
total_rewards_std            121.90381608184126
total_rewards_max            9975.527211566443
total_rewards_min            9609.031534284286
Number of train steps total  1060000
Number of env steps total    3182000
Number of rollouts total     0
Train Time (s)               147.2457104199566
(Previous) Eval Time (s)     20.704821993596852
Sample Time (s)              6.552130613476038
Epoch Time (s)               174.50266302702948
Total Train Time (s)         45204.166069444735
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:27:03.168274 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #264 | Epoch Duration: 174.58720660209656
2020-01-12 20:27:03.168411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7463608
Z variance train             0.092796125
KL Divergence                43.294846
KL Loss                      4.3294845
QF Loss                      143.43774
VF Loss                      62.886543
Policy Loss                  -1269.644
Q Predictions Mean           1268.9779
Q Predictions Std            1298.0004
Q Predictions Max            4372.104
Q Predictions Min            590.20905
V Predictions Mean           1270.8508
V Predictions Std            1291.8638
V Predictions Max            4331.3604
V Predictions Min            600.31635
Log Pis Mean                 0.019742236
Log Pis Std                  4.2634945
Log Pis Max                  24.542145
Log Pis Min                  -6.686059
Policy mu Mean               0.06087004
Policy mu Std                0.9288629
Policy mu Max                2.9903731
Policy mu Min                -3.6272037
Policy log std Mean          -0.52189523
Policy log std Std           0.2775352
Policy log std Max           0.039422452
Policy log std Min           -2.6491127
Z mean eval                  1.7472773
Z variance eval              0.05981777
total_rewards                [9459.28721303 9735.37377131 9738.73380732 9765.99337355 9759.78076077
 9602.01404775 9704.2133714  9543.49027655 9790.50147059 9757.21633363]
total_rewards_mean           9685.660442589618
total_rewards_std            105.89873033555946
total_rewards_max            9790.501470589665
total_rewards_min            9459.287213026506
Number of train steps total  1064000
Number of env steps total    3194000
Number of rollouts total     0
Train Time (s)               144.91787139233202
(Previous) Eval Time (s)     17.46636558091268
Sample Time (s)              6.586990963667631
Epoch Time (s)               168.97122793691233
Total Train Time (s)         45373.21807850432
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:29:52.224693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #265 | Epoch Duration: 169.0561661720276
2020-01-12 20:29:52.224878 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7451235
Z variance train             0.059518296
KL Divergence                44.472107
KL Loss                      4.447211
QF Loss                      120.551575
VF Loss                      55.106342
Policy Loss                  -1218.0856
Q Predictions Mean           1219.495
Q Predictions Std            1254.5999
Q Predictions Max            4359.777
Q Predictions Min            564.6509
V Predictions Mean           1221.447
V Predictions Std            1255.6483
V Predictions Max            4348.4106
V Predictions Min            555.7788
Log Pis Mean                 -0.2760762
Log Pis Std                  3.6505923
Log Pis Max                  12.610852
Log Pis Min                  -8.276613
Policy mu Mean               0.09583279
Policy mu Std                0.856386
Policy mu Max                2.6970887
Policy mu Min                -2.9787123
Policy log std Mean          -0.5191657
Policy log std Std           0.2841953
Policy log std Max           0.057383537
Policy log std Min           -2.9506981
Z mean eval                  1.7385772
Z variance eval              0.035187196
total_rewards                [9660.143292   9644.99637509 9689.20299252 9679.1998455  9780.75601008
 9926.06666626 9694.02714043 9675.89592774 9911.27479518 9903.64086707]
total_rewards_mean           9756.520391187005
total_rewards_std            108.429066881898
total_rewards_max            9926.066666255521
total_rewards_min            9644.996375090208
Number of train steps total  1068000
Number of env steps total    3206000
Number of rollouts total     0
Train Time (s)               145.79407923389226
(Previous) Eval Time (s)     21.038610205985606
Sample Time (s)              6.791314459405839
Epoch Time (s)               173.6240038992837
Total Train Time (s)         45546.93370489543
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:32:45.940665 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #266 | Epoch Duration: 173.71564984321594
2020-01-12 20:32:45.940807 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #266 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7365135
Z variance train             0.035247542
KL Divergence                45.664352
KL Loss                      4.5664353
QF Loss                      93.18532
VF Loss                      30.372679
Policy Loss                  -1159.3887
Q Predictions Mean           1155.7102
Q Predictions Std            1149.6685
Q Predictions Max            4335.1514
Q Predictions Min            607.82104
V Predictions Mean           1160.4246
V Predictions Std            1148.7865
V Predictions Max            4327.755
V Predictions Min            613.9379
Log Pis Mean                 0.015656546
Log Pis Std                  3.2932482
Log Pis Max                  14.532477
Log Pis Min                  -8.064541
Policy mu Mean               0.12966149
Policy mu Std                0.8757177
Policy mu Max                2.6650927
Policy mu Min                -2.182673
Policy log std Mean          -0.55498165
Policy log std Std           0.30463317
Policy log std Max           0.03918588
Policy log std Min           -2.670804
Z mean eval                  1.7481508
Z variance eval              0.08875714
total_rewards                [8235.15190744 5134.02705917 8943.61360524 8889.50625222 8921.0080086
 9002.74468688 9032.81428565 9189.96434883 8608.06135219 9174.89871434]
total_rewards_mean           8513.179022056202
total_rewards_std            1157.7476838752534
total_rewards_max            9189.964348828462
total_rewards_min            5134.027059169511
Number of train steps total  1072000
Number of env steps total    3218000
Number of rollouts total     0
Train Time (s)               145.32139267586172
(Previous) Eval Time (s)     21.02859862195328
Sample Time (s)              6.4026372381486
Epoch Time (s)               172.7526285359636
Total Train Time (s)         45719.7720606979
Epoch                        267
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:35:38.781981 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #267 | Epoch Duration: 172.84107661247253
2020-01-12 20:35:38.782114 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7478126
Z variance train             0.088783465
KL Divergence                42.81504
KL Loss                      4.281504
QF Loss                      3348.2485
VF Loss                      61.408363
Policy Loss                  -1160.5621
Q Predictions Mean           1160.4563
Q Predictions Std            1190.4075
Q Predictions Max            4379.071
Q Predictions Min            571.579
V Predictions Mean           1155.3696
V Predictions Std            1188.8616
V Predictions Max            4355.9033
V Predictions Min            593.9074
Log Pis Mean                 -0.26281565
Log Pis Std                  3.521033
Log Pis Max                  11.419003
Log Pis Min                  -7.0363874
Policy mu Mean               0.05872916
Policy mu Std                0.860494
Policy mu Max                3.3131218
Policy mu Min                -2.4647305
Policy log std Mean          -0.5362471
Policy log std Std           0.27901968
Policy log std Max           -0.07379049
Policy log std Min           -2.3348083
Z mean eval                  1.7501844
Z variance eval              0.104217276
total_rewards                [9658.85056241 8384.69687762 9658.45727889 9857.11345035 9822.15418681
 9992.98466659 9448.23603542 9723.75927926 9678.1243849  4806.46622039]
total_rewards_mean           9103.08429426427
total_rewards_std            1493.5496332065795
total_rewards_max            9992.98466658966
total_rewards_min            4806.4662203896605
Number of train steps total  1076000
Number of env steps total    3230000
Number of rollouts total     0
Train Time (s)               146.45349782239646
(Previous) Eval Time (s)     17.568248297087848
Sample Time (s)              6.399309926666319
Epoch Time (s)               170.42105604615062
Total Train Time (s)         45890.27335677389
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:38:29.284538 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #268 | Epoch Duration: 170.50232911109924
2020-01-12 20:38:29.284662 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7536707
Z variance train             0.104101166
KL Divergence                43.182846
KL Loss                      4.3182845
QF Loss                      173.51886
VF Loss                      121.20978
Policy Loss                  -1255.8507
Q Predictions Mean           1252.2139
Q Predictions Std            1268.9392
Q Predictions Max            4420.8623
Q Predictions Min            601.2195
V Predictions Mean           1249.9639
V Predictions Std            1260.8335
V Predictions Max            4384.191
V Predictions Min            600.04224
Log Pis Mean                 -0.22825804
Log Pis Std                  3.6361682
Log Pis Max                  15.240686
Log Pis Min                  -6.6483135
Policy mu Mean               0.019539187
Policy mu Std                0.8696629
Policy mu Max                3.1137211
Policy mu Min                -2.821637
Policy log std Mean          -0.5409538
Policy log std Std           0.29847503
Policy log std Max           0.10710096
Policy log std Min           -2.8368092
Z mean eval                  1.7342281
Z variance eval              0.12573054
total_rewards                [9540.67324403 9656.16208556 9788.00592088 9933.9485191  9717.08214636
 9770.28226797 9683.38190284 9562.14080572 9775.18004461 9727.91676694]
total_rewards_mean           9715.477370402125
total_rewards_std            108.78066931246433
total_rewards_max            9933.948519101346
total_rewards_min            9540.67324403384
Number of train steps total  1080000
Number of env steps total    3242000
Number of rollouts total     0
Train Time (s)               148.75103180482984
(Previous) Eval Time (s)     17.32146666571498
Sample Time (s)              5.594295365270227
Epoch Time (s)               171.66679383581504
Total Train Time (s)         46062.01820778148
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:41:21.032517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #269 | Epoch Duration: 171.74774074554443
2020-01-12 20:41:21.032701 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.734925
Z variance train             0.12511994
KL Divergence                40.980484
KL Loss                      4.0980487
QF Loss                      3307.3552
VF Loss                      55.60722
Policy Loss                  -1208.0804
Q Predictions Mean           1206.3738
Q Predictions Std            1205.2891
Q Predictions Max            4292.719
Q Predictions Min            577.8253
V Predictions Mean           1208.6997
V Predictions Std            1200.2239
V Predictions Max            4295.9604
V Predictions Min            586.86945
Log Pis Mean                 -0.5608056
Log Pis Std                  3.4237473
Log Pis Max                  10.542607
Log Pis Min                  -6.4412975
Policy mu Mean               0.068316646
Policy mu Std                0.82910055
Policy mu Max                2.6098995
Policy mu Min                -2.9539247
Policy log std Mean          -0.5160478
Policy log std Std           0.2799233
Policy log std Max           0.114674926
Policy log std Min           -2.5811617
Z mean eval                  1.7548397
Z variance eval              0.08945949
total_rewards                [9482.031321   9487.31077299 9736.73351149 9708.85297019 9490.92930187
 9512.8964819  9600.81628189 9768.73201264 9599.84273855 9618.40251606]
total_rewards_mean           9600.654790858329
total_rewards_std            102.68859804006739
total_rewards_max            9768.732012641207
total_rewards_min            9482.031321004146
Number of train steps total  1084000
Number of env steps total    3254000
Number of rollouts total     0
Train Time (s)               146.60268000885844
(Previous) Eval Time (s)     17.56419771630317
Sample Time (s)              6.462789782322943
Epoch Time (s)               170.62966750748456
Total Train Time (s)         46232.73623618344
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:44:11.754794 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #270 | Epoch Duration: 170.72193717956543
2020-01-12 20:44:11.755028 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7555453
Z variance train             0.08920672
KL Divergence                42.32183
KL Loss                      4.232183
QF Loss                      92.76051
VF Loss                      49.591805
Policy Loss                  -1277.0006
Q Predictions Mean           1276.3308
Q Predictions Std            1281.9404
Q Predictions Max            4400.368
Q Predictions Min            590.3804
V Predictions Mean           1275.7125
V Predictions Std            1275.9762
V Predictions Max            4385.7754
V Predictions Min            593.8369
Log Pis Mean                 -0.11393137
Log Pis Std                  3.4208694
Log Pis Max                  11.889294
Log Pis Min                  -6.542387
Policy mu Mean               0.055158526
Policy mu Std                0.8782008
Policy mu Max                2.682156
Policy mu Min                -2.535752
Policy log std Mean          -0.5436446
Policy log std Std           0.2832663
Policy log std Max           -0.020268738
Policy log std Min           -2.3069928
Z mean eval                  1.7443607
Z variance eval              0.08621048
total_rewards                [9031.98208478 5678.63847641 9170.99171008 9327.15738919 2732.51589279
 8459.21521694 9504.43467068 3694.13234766 9017.40115312 2438.14279284]
total_rewards_mean           6905.461173449983
total_rewards_std            2798.867097438392
total_rewards_max            9504.434670682898
total_rewards_min            2438.1427928446724
Number of train steps total  1088000
Number of env steps total    3266000
Number of rollouts total     0
Train Time (s)               147.19228057935834
(Previous) Eval Time (s)     17.32895897794515
Sample Time (s)              6.598547065164894
Epoch Time (s)               171.11978662246838
Total Train Time (s)         46403.93567018304
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:47:02.956403 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #271 | Epoch Duration: 171.20120930671692
2020-01-12 20:47:02.956581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7444131
Z variance train             0.085782126
KL Divergence                42.383575
KL Loss                      4.2383575
QF Loss                      180.43394
VF Loss                      81.07958
Policy Loss                  -1219.5262
Q Predictions Mean           1214.7198
Q Predictions Std            1239.7426
Q Predictions Max            4440.586
Q Predictions Min            586.17816
V Predictions Mean           1222.5881
V Predictions Std            1242.797
V Predictions Max            4459.6006
V Predictions Min            597.1973
Log Pis Mean                 -0.437898
Log Pis Std                  3.2550666
Log Pis Max                  11.165357
Log Pis Min                  -6.9576464
Policy mu Mean               0.05111481
Policy mu Std                0.8577328
Policy mu Max                3.459533
Policy mu Min                -2.8054976
Policy log std Mean          -0.52078146
Policy log std Std           0.28934747
Policy log std Max           0.11424762
Policy log std Min           -2.6555288
Z mean eval                  1.7374609
Z variance eval              0.071178116
total_rewards                [8346.9289355  8825.10455415 9442.28414192 8671.70726048 9373.76835071
 9450.36538038 9066.13371641 9307.82733755 9187.76668575 8940.24567317]
total_rewards_mean           9061.213203601312
total_rewards_std            346.9151274033055
total_rewards_max            9450.365380378673
total_rewards_min            8346.928935497464
Number of train steps total  1092000
Number of env steps total    3278000
Number of rollouts total     0
Train Time (s)               147.28848968073726
(Previous) Eval Time (s)     20.461997426114976
Sample Time (s)              6.637129923328757
Epoch Time (s)               174.387617030181
Total Train Time (s)         46578.40435325494
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:49:57.425969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #272 | Epoch Duration: 174.4692575931549
2020-01-12 20:49:57.426112 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7378273
Z variance train             0.07116778
KL Divergence                41.750343
KL Loss                      4.1750345
QF Loss                      3389.3552
VF Loss                      105.16761
Policy Loss                  -1311.3065
Q Predictions Mean           1312.6985
Q Predictions Std            1323.4949
Q Predictions Max            4330.1636
Q Predictions Min            512.96606
V Predictions Mean           1310.274
V Predictions Std            1316.8094
V Predictions Max            4315.374
V Predictions Min            549.35547
Log Pis Mean                 -0.07276502
Log Pis Std                  3.8851311
Log Pis Max                  12.640143
Log Pis Min                  -6.412588
Policy mu Mean               0.034809023
Policy mu Std                0.8857936
Policy mu Max                2.7590334
Policy mu Min                -2.4972398
Policy log std Mean          -0.5288662
Policy log std Std           0.29222944
Policy log std Max           0.05652827
Policy log std Min           -2.9337573
Z mean eval                  1.7335932
Z variance eval              0.09292992
total_rewards                [9295.81588268 9663.92786682 1853.74511099 9629.3875523  9574.30691754
 9688.14170932 9530.02228108 9299.00275534 9720.62159426 9630.18966046]
total_rewards_mean           8788.516133079927
total_rewards_std            2315.950535370803
total_rewards_max            9720.62159426111
total_rewards_min            1853.745110990957
Number of train steps total  1096000
Number of env steps total    3290000
Number of rollouts total     0
Train Time (s)               146.4547862401232
(Previous) Eval Time (s)     17.443616937845945
Sample Time (s)              6.422807740047574
Epoch Time (s)               170.32121091801673
Total Train Time (s)         46748.80904034758
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:52:47.837128 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #273 | Epoch Duration: 170.4108967781067
2020-01-12 20:52:47.837342 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7349608
Z variance train             0.0930696
KL Divergence                40.347538
KL Loss                      4.034754
QF Loss                      3335.855
VF Loss                      70.39378
Policy Loss                  -1384.7418
Q Predictions Mean           1385.7225
Q Predictions Std            1366.226
Q Predictions Max            4327.263
Q Predictions Min            585.34436
V Predictions Mean           1387.7263
V Predictions Std            1367.7933
V Predictions Max            4311.309
V Predictions Min            574.4044
Log Pis Mean                 -0.0141959265
Log Pis Std                  3.8340762
Log Pis Max                  13.839698
Log Pis Min                  -7.0351276
Policy mu Mean               0.027492968
Policy mu Std                0.88298273
Policy mu Max                2.4742856
Policy mu Min                -3.0555267
Policy log std Mean          -0.54370934
Policy log std Std           0.29239687
Policy log std Max           0.045506477
Policy log std Min           -2.806665
Z mean eval                  1.7576834
Z variance eval              0.071939364
total_rewards                [9185.53642366 9457.71836456 9543.66976431 6782.42140256 9379.53242635
 9741.23716456 9466.97250379 9609.91658317 9396.80923962 9585.30247177]
total_rewards_mean           9214.911634436756
total_rewards_std            823.3387467309844
total_rewards_max            9741.237164562492
total_rewards_min            6782.421402556816
Number of train steps total  1100000
Number of env steps total    3302000
Number of rollouts total     0
Train Time (s)               145.70883277710527
(Previous) Eval Time (s)     20.83021711418405
Sample Time (s)              6.5475135035812855
Epoch Time (s)               173.0865633948706
Total Train Time (s)         46921.98192926776
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:55:41.010111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #274 | Epoch Duration: 173.1726200580597
2020-01-12 20:55:41.010240 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7586253
Z variance train             0.07215244
KL Divergence                41.39457
KL Loss                      4.139457
QF Loss                      210.7392
VF Loss                      120.94069
Policy Loss                  -1248.6448
Q Predictions Mean           1245.3901
Q Predictions Std            1267.8595
Q Predictions Max            4345.2363
Q Predictions Min            596.62494
V Predictions Mean           1239.5889
V Predictions Std            1262.9565
V Predictions Max            4302.739
V Predictions Min            593.71545
Log Pis Mean                 -0.1491435
Log Pis Std                  3.8912091
Log Pis Max                  13.694525
Log Pis Min                  -8.179174
Policy mu Mean               0.047808483
Policy mu Std                0.90989345
Policy mu Max                3.115144
Policy mu Min                -2.7271748
Policy log std Mean          -0.53578913
Policy log std Std           0.29092962
Policy log std Max           0.2172997
Policy log std Min           -2.8345075
Z mean eval                  1.7425239
Z variance eval              0.06898398
total_rewards                [9460.55912926 9741.40318782 9724.40992924 9629.06322863 9996.45626637
 9908.08297124 9246.67077599 9527.22045183 9870.94551327 9686.4530979 ]
total_rewards_mean           9679.126455155085
total_rewards_std            213.60427463751532
total_rewards_max            9996.456266368465
total_rewards_min            9246.670775989794
Number of train steps total  1104000
Number of env steps total    3314000
Number of rollouts total     0
Train Time (s)               147.76809813501313
(Previous) Eval Time (s)     21.285306555684656
Sample Time (s)              6.407560394145548
Epoch Time (s)               175.46096508484334
Total Train Time (s)         47097.522965267766
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:58:36.553663 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #275 | Epoch Duration: 175.54332661628723
2020-01-12 20:58:36.553801 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7432768
Z variance train             0.069136225
KL Divergence                42.574093
KL Loss                      4.2574096
QF Loss                      144.89163
VF Loss                      99.689316
Policy Loss                  -1250.899
Q Predictions Mean           1247.3203
Q Predictions Std            1266.6183
Q Predictions Max            4349.0796
Q Predictions Min            574.6034
V Predictions Mean           1244.5433
V Predictions Std            1262.4752
V Predictions Max            4330.9907
V Predictions Min            573.58636
Log Pis Mean                 -0.31666213
Log Pis Std                  3.853306
Log Pis Max                  17.190506
Log Pis Min                  -6.8929353
Policy mu Mean               0.062362194
Policy mu Std                0.8660175
Policy mu Max                3.1714425
Policy mu Min                -3.5257285
Policy log std Mean          -0.5154569
Policy log std Std           0.27587366
Policy log std Max           0.11025846
Policy log std Min           -2.5508661
Z mean eval                  1.7648163
Z variance eval              0.078547604
total_rewards                [9069.72196686 7224.20710826 9450.95950634 9375.41940055 9446.15247182
 9367.92043175 9284.56373064 9437.73788319 9460.88036039 9360.32015523]
total_rewards_mean           9147.788301503802
total_rewards_std            650.6490369876992
total_rewards_max            9460.880360392268
total_rewards_min            7224.20710825721
Number of train steps total  1108000
Number of env steps total    3326000
Number of rollouts total     0
Train Time (s)               146.99340754002333
(Previous) Eval Time (s)     19.884230616968125
Sample Time (s)              6.556339040398598
Epoch Time (s)               173.43397719739005
Total Train Time (s)         47271.04510283237
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:01:30.082129 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #276 | Epoch Duration: 173.5282051563263
2020-01-12 21:01:30.082303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.764679
Z variance train             0.07856524
KL Divergence                43.226593
KL Loss                      4.3226595
QF Loss                      102.647484
VF Loss                      49.501194
Policy Loss                  -991.0964
Q Predictions Mean           987.2644
Q Predictions Std            974.0554
Q Predictions Max            4403.011
Q Predictions Min            581.80426
V Predictions Mean           988.02167
V Predictions Std            971.1892
V Predictions Max            4385.987
V Predictions Min            573.72174
Log Pis Mean                 -0.75669634
Log Pis Std                  3.3660727
Log Pis Max                  18.61289
Log Pis Min                  -8.731966
Policy mu Mean               0.06812299
Policy mu Std                0.80612123
Policy mu Max                3.753063
Policy mu Min                -4.0298357
Policy log std Mean          -0.49651837
Policy log std Std           0.26400617
Policy log std Max           -0.055824563
Policy log std Min           -2.8486624
Z mean eval                  1.740016
Z variance eval              0.09686902
total_rewards                [9337.48182007 9459.64236705 9597.34835195 9444.67462635 9667.13708007
 9612.79216978 9484.06077501 9840.65399692 9689.94141777 9632.05697035]
total_rewards_mean           9576.578957530524
total_rewards_std            138.71120927563527
total_rewards_max            9840.653996919851
total_rewards_min            9337.481820071558
Number of train steps total  1112000
Number of env steps total    3338000
Number of rollouts total     0
Train Time (s)               147.48841155134141
(Previous) Eval Time (s)     20.857713548932225
Sample Time (s)              6.50327519653365
Epoch Time (s)               174.8494002968073
Total Train Time (s)         47445.99035245087
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:04:25.030036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #277 | Epoch Duration: 174.94760537147522
2020-01-12 21:04:25.030172 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7434896
Z variance train             0.09696863
KL Divergence                41.819405
KL Loss                      4.1819406
QF Loss                      3259.271
VF Loss                      123.110275
Policy Loss                  -1240.5762
Q Predictions Mean           1237.8848
Q Predictions Std            1264.3225
Q Predictions Max            4427.5376
Q Predictions Min            591.54236
V Predictions Mean           1237.1461
V Predictions Std            1266.8448
V Predictions Max            4457.8115
V Predictions Min            583.13
Log Pis Mean                 -0.49892074
Log Pis Std                  3.5097435
Log Pis Max                  17.804604
Log Pis Min                  -7.1039195
Policy mu Mean               0.0116665
Policy mu Std                0.82776767
Policy mu Max                2.7733347
Policy mu Min                -3.5363154
Policy log std Mean          -0.5052878
Policy log std Std           0.27190188
Policy log std Max           -0.023944348
Policy log std Min           -2.4260182
Z mean eval                  1.7616742
Z variance eval              0.093697146
total_rewards                [9501.08920455 9591.35804991 9725.86415631 9681.82342503 9707.37959607
 9652.53565263 9608.08521344 9607.17007972 9534.95824684 9611.74894159]
total_rewards_mean           9622.20125661053
total_rewards_std            68.001139687494
total_rewards_max            9725.864156314981
total_rewards_min            9501.089204552223
Number of train steps total  1116000
Number of env steps total    3350000
Number of rollouts total     0
Train Time (s)               145.7023400021717
(Previous) Eval Time (s)     17.358841136097908
Sample Time (s)              6.540822580456734
Epoch Time (s)               169.60200371872634
Total Train Time (s)         47615.67494026944
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:07:14.722530 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #278 | Epoch Duration: 169.6922447681427
2020-01-12 21:07:14.722748 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7637131
Z variance train             0.09373473
KL Divergence                43.673252
KL Loss                      4.3673253
QF Loss                      85.556015
VF Loss                      39.27642
Policy Loss                  -1147.2986
Q Predictions Mean           1143.6907
Q Predictions Std            1155.2415
Q Predictions Max            4362.751
Q Predictions Min            587.3572
V Predictions Mean           1146.2986
V Predictions Std            1153.4796
V Predictions Max            4364.107
V Predictions Min            592.6431
Log Pis Mean                 -0.7190977
Log Pis Std                  3.5888562
Log Pis Max                  23.169933
Log Pis Min                  -6.155051
Policy mu Mean               0.014476043
Policy mu Std                0.8332003
Policy mu Max                4.140258
Policy mu Min                -3.460829
Policy log std Mean          -0.49355236
Policy log std Std           0.2804568
Policy log std Max           0.40330547
Policy log std Min           -2.2532296
Z mean eval                  1.7730224
Z variance eval              0.11972387
total_rewards                [9705.95421544 9645.42182052 9832.42020263 9896.81045353 9948.52727022
 9786.97817433 9906.6341873  9823.97398633 9769.11802533 9812.83329363]
total_rewards_mean           9812.86716292633
total_rewards_std            87.63596718530383
total_rewards_max            9948.527270215978
total_rewards_min            9645.421820524636
Number of train steps total  1120000
Number of env steps total    3362000
Number of rollouts total     0
Train Time (s)               145.88070540875196
(Previous) Eval Time (s)     20.724658160004765
Sample Time (s)              5.653849940747023
Epoch Time (s)               172.25921350950375
Total Train Time (s)         47788.01965285046
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:10:07.064601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #279 | Epoch Duration: 172.3417193889618
2020-01-12 21:10:07.064747 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7749875
Z variance train             0.11954923
KL Divergence                42.854637
KL Loss                      4.285464
QF Loss                      88.41647
VF Loss                      51.865326
Policy Loss                  -1262.2653
Q Predictions Mean           1259.6322
Q Predictions Std            1220.8245
Q Predictions Max            4431.6577
Q Predictions Min            602.4041
V Predictions Mean           1261.9612
V Predictions Std            1216.4175
V Predictions Max            4425.497
V Predictions Min            608.3096
Log Pis Mean                 -0.15354186
Log Pis Std                  4.1109533
Log Pis Max                  16.408554
Log Pis Min                  -8.559284
Policy mu Mean               0.058541086
Policy mu Std                0.87691885
Policy mu Max                2.9466443
Policy mu Min                -3.296139
Policy log std Mean          -0.52103764
Policy log std Std           0.28373384
Policy log std Max           0.039352298
Policy log std Min           -2.7925138
Z mean eval                  1.8014818
Z variance eval              0.07060844
total_rewards                [6513.99871498 6193.8134067  5686.04132414 4793.67195519 6438.65418359
 2073.49520946 7130.25785176 6611.32506525 7623.1469935  6357.64446678]
total_rewards_mean           5942.204917134713
total_rewards_std            1478.030014525223
total_rewards_max            7623.146993500513
total_rewards_min            2073.495209456037
Number of train steps total  1124000
Number of env steps total    3374000
Number of rollouts total     0
Train Time (s)               145.72794235078618
(Previous) Eval Time (s)     20.987641382031143
Sample Time (s)              8.109821412712336
Epoch Time (s)               174.82540514552966
Total Train Time (s)         47962.93135652132
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:13:01.978755 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #280 | Epoch Duration: 174.91390919685364
2020-01-12 21:13:01.978934 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8023672
Z variance train             0.07044431
KL Divergence                44.032
KL Loss                      4.4032
QF Loss                      3550.4016
VF Loss                      52.10685
Policy Loss                  -1318.946
Q Predictions Mean           1317.3202
Q Predictions Std            1302.7037
Q Predictions Max            4339.474
Q Predictions Min            589.56995
V Predictions Mean           1319.641
V Predictions Std            1299.5764
V Predictions Max            4334.733
V Predictions Min            602.37213
Log Pis Mean                 -0.37042367
Log Pis Std                  3.7248483
Log Pis Max                  17.331356
Log Pis Min                  -7.924635
Policy mu Mean               0.073993154
Policy mu Std                0.85528684
Policy mu Max                2.738887
Policy mu Min                -2.775319
Policy log std Mean          -0.52084285
Policy log std Std           0.29186237
Policy log std Max           0.122879624
Policy log std Min           -2.7148266
Z mean eval                  1.7584461
Z variance eval              0.07197299
total_rewards                [9654.13997413 9597.46862019 9888.61269431 9674.33487321 9591.61994637
 9774.55938802 9730.97431618 9801.56598737 9443.76450099 9621.27783347]
total_rewards_mean           9677.831813422075
total_rewards_std            120.1537327422073
total_rewards_max            9888.612694305448
total_rewards_min            9443.7645009913
Number of train steps total  1128000
Number of env steps total    3386000
Number of rollouts total     0
Train Time (s)               145.62832851102576
(Previous) Eval Time (s)     20.688161376863718
Sample Time (s)              6.406944481655955
Epoch Time (s)               172.72343436954543
Total Train Time (s)         48135.73978115199
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:15:54.789206 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #281 | Epoch Duration: 172.81012892723083
2020-01-12 21:15:54.789342 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7626944
Z variance train             0.0721272
KL Divergence                44.05497
KL Loss                      4.405497
QF Loss                      247.41498
VF Loss                      60.52787
Policy Loss                  -1328.0951
Q Predictions Mean           1325.3875
Q Predictions Std            1328.5789
Q Predictions Max            4449.159
Q Predictions Min            609.0485
V Predictions Mean           1325.9556
V Predictions Std            1325.0255
V Predictions Max            4451.638
V Predictions Min            615.00256
Log Pis Mean                 -0.055399675
Log Pis Std                  4.1445045
Log Pis Max                  16.589645
Log Pis Min                  -8.800672
Policy mu Mean               0.070227385
Policy mu Std                0.8859241
Policy mu Max                2.898926
Policy mu Min                -2.7161813
Policy log std Mean          -0.522006
Policy log std Std           0.27372086
Policy log std Max           -0.00424999
Policy log std Min           -2.5997868
Z mean eval                  1.7666109
Z variance eval              0.054257948
total_rewards                [8918.09642975 8928.5050782  8511.20000228 8834.3183625  8609.80192502
 8899.7851917  8719.71955833 8924.78093199 9159.5352537  8644.97001007]
total_rewards_mean           8815.071274354039
total_rewards_std            182.8167378462688
total_rewards_max            9159.535253697355
total_rewards_min            8511.200002278913
Number of train steps total  1132000
Number of env steps total    3398000
Number of rollouts total     0
Train Time (s)               147.3115260968916
(Previous) Eval Time (s)     20.93802823824808
Sample Time (s)              6.588734094519168
Epoch Time (s)               174.83828842965886
Total Train Time (s)         48310.65869535785
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:18:49.711083 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #282 | Epoch Duration: 174.92163515090942
2020-01-12 21:18:49.711249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7642615
Z variance train             0.054446053
KL Divergence                44.91707
KL Loss                      4.491707
QF Loss                      4088.074
VF Loss                      151.99626
Policy Loss                  -1346.1993
Q Predictions Mean           1345.9451
Q Predictions Std            1306.4268
Q Predictions Max            4420.859
Q Predictions Min            600.61816
V Predictions Mean           1351.687
V Predictions Std            1308.657
V Predictions Max            4405.1826
V Predictions Min            593.60815
Log Pis Mean                 0.119096756
Log Pis Std                  3.9447012
Log Pis Max                  15.071226
Log Pis Min                  -8.321809
Policy mu Mean               0.014877605
Policy mu Std                0.9146304
Policy mu Max                2.8977776
Policy mu Min                -2.7641842
Policy log std Mean          -0.52999157
Policy log std Std           0.29831666
Policy log std Max           0.23874247
Policy log std Min           -3.0155551
Z mean eval                  1.7678697
Z variance eval              0.06463901
total_rewards                [9475.96979313 9525.60448614 9901.90048161 9438.9898158  9589.21370132
 9525.85808696 9434.13544797 9657.89637641 9492.82555276 9717.1570933 ]
total_rewards_mean           9575.955083538893
total_rewards_std            139.24558844531285
total_rewards_max            9901.900481609688
total_rewards_min            9434.13544796952
Number of train steps total  1136000
Number of env steps total    3410000
Number of rollouts total     0
Train Time (s)               146.2355166929774
(Previous) Eval Time (s)     20.765631312970072
Sample Time (s)              5.563776773400605
Epoch Time (s)               172.56492477934808
Total Train Time (s)         48483.3029702208
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:21:42.357039 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #283 | Epoch Duration: 172.6456708908081
2020-01-12 21:21:42.357178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7714062
Z variance train             0.064855866
KL Divergence                44.592495
KL Loss                      4.4592495
QF Loss                      3598.9727
VF Loss                      96.67319
Policy Loss                  -1129.9913
Q Predictions Mean           1129.1694
Q Predictions Std            1115.6249
Q Predictions Max            4436.5986
Q Predictions Min            616.14453
V Predictions Mean           1125.8691
V Predictions Std            1109.8324
V Predictions Max            4412.624
V Predictions Min            603.9428
Log Pis Mean                 -0.5145312
Log Pis Std                  3.722901
Log Pis Max                  14.725639
Log Pis Min                  -7.173586
Policy mu Mean               0.05870053
Policy mu Std                0.8501726
Policy mu Max                3.0648584
Policy mu Min                -3.2112489
Policy log std Mean          -0.51183486
Policy log std Std           0.26213416
Policy log std Max           0.3311466
Policy log std Min           -2.7444596
Z mean eval                  1.7715778
Z variance eval              0.04864805
total_rewards                [9677.34949292 9866.20869133 9645.45035518 9786.88092109 9850.11077002
 9890.12219275 9676.35476697 9645.75229583 9558.11991468 9753.35003798]
total_rewards_mean           9734.969943874605
total_rewards_std            105.63671240066257
total_rewards_max            9890.122192751733
total_rewards_min            9558.119914677594
Number of train steps total  1140000
Number of env steps total    3422000
Number of rollouts total     0
Train Time (s)               147.28355960501358
(Previous) Eval Time (s)     20.831867817789316
Sample Time (s)              6.565144828520715
Epoch Time (s)               174.6805722513236
Total Train Time (s)         48658.06526054256
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:24:37.121258 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #284 | Epoch Duration: 174.76397323608398
2020-01-12 21:24:37.121390 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #284 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.77222
Z variance train             0.04864514
KL Divergence                45.65871
KL Loss                      4.5658712
QF Loss                      160.55875
VF Loss                      43.305023
Policy Loss                  -1109.3389
Q Predictions Mean           1107.4421
Q Predictions Std            1093.0526
Q Predictions Max            4326.0356
Q Predictions Min            606.48004
V Predictions Mean           1110.5592
V Predictions Std            1090.9778
V Predictions Max            4330.8545
V Predictions Min            611.93774
Log Pis Mean                 -0.30848944
Log Pis Std                  3.483263
Log Pis Max                  14.445216
Log Pis Min                  -6.25606
Policy mu Mean               0.032727662
Policy mu Std                0.8557903
Policy mu Max                2.699662
Policy mu Min                -2.9699984
Policy log std Mean          -0.50108755
Policy log std Std           0.2863527
Policy log std Max           0.40628546
Policy log std Min           -2.467825
Z mean eval                  1.765186
Z variance eval              0.048910514
total_rewards                [ 9976.36875733 10033.68669601 10025.64139399  9873.41960684
  6199.61143162  9983.23698398  9779.32648179  9612.06744385
  9324.76183595  9802.72775488]
total_rewards_mean           9461.084838622957
total_rewards_std            1106.8587737619903
total_rewards_max            10033.686696011615
total_rewards_min            6199.611431621401
Number of train steps total  1144000
Number of env steps total    3434000
Number of rollouts total     0
Train Time (s)               145.21202384121716
(Previous) Eval Time (s)     17.33502593776211
Sample Time (s)              6.528730419464409
Epoch Time (s)               169.07578019844368
Total Train Time (s)         48827.24020955432
Epoch                        285
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:27:26.303886 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #285 | Epoch Duration: 169.1823799610138
2020-01-12 21:27:26.304078 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7622572
Z variance train             0.048784588
KL Divergence                45.844143
KL Loss                      4.5844145
QF Loss                      112.27789
VF Loss                      223.67195
Policy Loss                  -1208.9602
Q Predictions Mean           1205.3232
Q Predictions Std            1186.396
Q Predictions Max            4348.881
Q Predictions Min            596.5533
V Predictions Mean           1198.977
V Predictions Std            1177.9926
V Predictions Max            4321.607
V Predictions Min            597.61865
Log Pis Mean                 -0.24998365
Log Pis Std                  3.778379
Log Pis Max                  18.347244
Log Pis Min                  -7.0559664
Policy mu Mean               0.046843484
Policy mu Std                0.87995225
Policy mu Max                3.374902
Policy mu Min                -2.6832795
Policy log std Mean          -0.52085525
Policy log std Std           0.28213495
Policy log std Max           0.10611987
Policy log std Min           -2.6348512
Z mean eval                  1.7837347
Z variance eval              0.04696402
total_rewards                [9559.91831182 9750.7852991  9708.60742148 9675.90519765 9786.23321677
 9603.21163466 9780.73639334 9833.3813574  9967.05721939 9949.6834471 ]
total_rewards_mean           9761.55194987138
total_rewards_std            126.39016459935154
total_rewards_max            9967.057219386854
total_rewards_min            9559.91831182262
Number of train steps total  1148000
Number of env steps total    3446000
Number of rollouts total     0
Train Time (s)               146.74777188804
(Previous) Eval Time (s)     17.25803456408903
Sample Time (s)              6.728774580638856
Epoch Time (s)               170.7345810327679
Total Train Time (s)         48998.062092122156
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:30:17.129713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #286 | Epoch Duration: 170.82545948028564
2020-01-12 21:30:17.129966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7828429
Z variance train             0.04706251
KL Divergence                47.168083
KL Loss                      4.7168083
QF Loss                      81.71923
VF Loss                      128.98077
Policy Loss                  -1289.9343
Q Predictions Mean           1288.4451
Q Predictions Std            1294.9152
Q Predictions Max            4432.225
Q Predictions Min            611.50275
V Predictions Mean           1292.9072
V Predictions Std            1296.7457
V Predictions Max            4414.4053
V Predictions Min            614.8895
Log Pis Mean                 -0.19826289
Log Pis Std                  3.9690928
Log Pis Max                  17.394192
Log Pis Min                  -6.6879907
Policy mu Mean               0.025852038
Policy mu Std                0.9019686
Policy mu Max                4.157739
Policy mu Min                -3.3095105
Policy log std Mean          -0.50180846
Policy log std Std           0.2830132
Policy log std Max           0.11397582
Policy log std Min           -2.6340885
Z mean eval                  1.7834523
Z variance eval              0.080649205
total_rewards                [10038.43382557  9834.84920853  9718.31687299  9445.30319938
  9636.91758422  9862.21348337  9740.05315127  9821.09091973
  9690.69839463  9895.70993014]
total_rewards_mean           9768.358656982131
total_rewards_std            153.67089487656648
total_rewards_max            10038.433825567823
total_rewards_min            9445.303199381227
Number of train steps total  1152000
Number of env steps total    3458000
Number of rollouts total     0
Train Time (s)               145.94240709301084
(Previous) Eval Time (s)     20.752828030847013
Sample Time (s)              6.5417518159374595
Epoch Time (s)               173.23698693979532
Total Train Time (s)         49171.381984169595
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:33:10.452389 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #287 | Epoch Duration: 173.32223844528198
2020-01-12 21:33:10.452584 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7859339
Z variance train             0.08038323
KL Divergence                46.030704
KL Loss                      4.6030707
QF Loss                      223.4495
VF Loss                      87.21871
Policy Loss                  -1275.6323
Q Predictions Mean           1273.5724
Q Predictions Std            1267.5414
Q Predictions Max            4402.998
Q Predictions Min            589.1068
V Predictions Mean           1277.4221
V Predictions Std            1266.1124
V Predictions Max            4413.3193
V Predictions Min            605.16956
Log Pis Mean                 -0.016786769
Log Pis Std                  4.2181835
Log Pis Max                  18.101841
Log Pis Min                  -7.477542
Policy mu Mean               0.07887435
Policy mu Std                0.8975007
Policy mu Max                3.2666254
Policy mu Min                -3.862086
Policy log std Mean          -0.52366203
Policy log std Std           0.30712003
Policy log std Max           0.24035239
Policy log std Min           -2.680142
Z mean eval                  1.7888119
Z variance eval              0.051549245
total_rewards                [9113.10130568 9768.55830449 3424.9632535  9965.59130853 9845.86637841
 9959.21691486 9944.5505399  9892.12633573 9555.14061522 9780.76193749]
total_rewards_mean           9124.98768937937
total_rewards_std            1915.778648345489
total_rewards_max            9965.591308526822
total_rewards_min            3424.9632535023907
Number of train steps total  1156000
Number of env steps total    3470000
Number of rollouts total     0
Train Time (s)               146.60124074714258
(Previous) Eval Time (s)     20.741818635258824
Sample Time (s)              6.524375143460929
Epoch Time (s)               173.86743452586234
Total Train Time (s)         49345.35535021592
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:36:04.425710 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #288 | Epoch Duration: 173.97299003601074
2020-01-12 21:36:04.425842 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7889764
Z variance train             0.051645886
KL Divergence                44.99638
KL Loss                      4.499638
QF Loss                      172.45413
VF Loss                      51.29037
Policy Loss                  -1360.8175
Q Predictions Mean           1359.7686
Q Predictions Std            1313.137
Q Predictions Max            4403.669
Q Predictions Min            601.1051
V Predictions Mean           1361.5461
V Predictions Std            1308.9231
V Predictions Max            4394.091
V Predictions Min            614.53076
Log Pis Mean                 -0.07416597
Log Pis Std                  3.712958
Log Pis Max                  12.903284
Log Pis Min                  -7.147926
Policy mu Mean               -0.03956072
Policy mu Std                0.88219905
Policy mu Max                2.7929633
Policy mu Min                -2.8367774
Policy log std Mean          -0.52693516
Policy log std Std           0.29014197
Policy log std Max           -9.119511e-05
Policy log std Min           -2.562913
Z mean eval                  1.8058903
Z variance eval              0.049370836
total_rewards                [9629.14162397 9793.22729356 9739.793613   9710.58672933 9205.28387522
 9361.64200311 9607.8951544  9653.84108193 9194.61140406 4621.83717445]
total_rewards_mean           9051.785995302915
total_rewards_std            1490.8585892528051
total_rewards_max            9793.227293557875
total_rewards_min            4621.837174452128
Number of train steps total  1160000
Number of env steps total    3482000
Number of rollouts total     0
Train Time (s)               146.81170956976712
(Previous) Eval Time (s)     20.86482169525698
Sample Time (s)              6.461506320163608
Epoch Time (s)               174.1380375851877
Total Train Time (s)         49519.57362927217
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:38:58.646044 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #289 | Epoch Duration: 174.2201051712036
2020-01-12 21:38:58.646174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8089777
Z variance train             0.048916142
KL Divergence                44.82688
KL Loss                      4.4826884
QF Loss                      131.16002
VF Loss                      112.154854
Policy Loss                  -1315.4913
Q Predictions Mean           1311.9846
Q Predictions Std            1297.9377
Q Predictions Max            4377.295
Q Predictions Min            599.44147
V Predictions Mean           1309.0381
V Predictions Std            1294.9409
V Predictions Max            4367.3135
V Predictions Min            602.0426
Log Pis Mean                 -0.24224955
Log Pis Std                  3.664795
Log Pis Max                  14.304645
Log Pis Min                  -6.1282697
Policy mu Mean               0.07317506
Policy mu Std                0.89600873
Policy mu Max                3.405333
Policy mu Min                -3.5420778
Policy log std Mean          -0.5114183
Policy log std Std           0.2852239
Policy log std Max           0.4066491
Policy log std Min           -2.4759617
Z mean eval                  1.7758442
Z variance eval              0.0701207
total_rewards                [9409.47094207 9457.98498487 9761.30274891 9364.4955835  9189.94982685
 9620.08599778 9564.04062573 9881.39781033 9683.68436247 9212.94416772]
total_rewards_mean           9514.535705024306
total_rewards_std            216.96698416149184
total_rewards_max            9881.397810329128
total_rewards_min            9189.949826850107
Number of train steps total  1164000
Number of env steps total    3494000
Number of rollouts total     0
Train Time (s)               145.8233518130146
(Previous) Eval Time (s)     20.80260653188452
Sample Time (s)              6.556597809307277
Epoch Time (s)               173.1825561542064
Total Train Time (s)         49692.83144956082
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:41:51.905988 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #290 | Epoch Duration: 173.25971865653992
2020-01-12 21:41:51.906117 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #290 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7741699
Z variance train             0.07043089
KL Divergence                45.463696
KL Loss                      4.5463696
QF Loss                      3643.0894
VF Loss                      49.178093
Policy Loss                  -1248.7518
Q Predictions Mean           1246.2487
Q Predictions Std            1227.3931
Q Predictions Max            4412.7046
Q Predictions Min            600.29584
V Predictions Mean           1250.2203
V Predictions Std            1224.3274
V Predictions Max            4416.487
V Predictions Min            616.2984
Log Pis Mean                 -0.37017053
Log Pis Std                  3.7967205
Log Pis Max                  15.96657
Log Pis Min                  -6.444874
Policy mu Mean               0.017505998
Policy mu Std                0.8597905
Policy mu Max                2.8887997
Policy mu Min                -3.0238023
Policy log std Mean          -0.49700746
Policy log std Std           0.279869
Policy log std Max           0.013768375
Policy log std Min           -2.4290588
Z mean eval                  1.7743847
Z variance eval              0.10184449
total_rewards                [9694.66507765 9771.46626768 9531.12292654 9677.21968224 9484.6379054
 9712.27725225 9542.31994499 9869.49695908 9641.45188215 9866.97738403]
total_rewards_mean           9679.163528200792
total_rewards_std            126.9904809578937
total_rewards_max            9869.496959077384
total_rewards_min            9484.637905398744
Number of train steps total  1168000
Number of env steps total    3506000
Number of rollouts total     0
Train Time (s)               146.10416641365737
(Previous) Eval Time (s)     21.216266134288162
Sample Time (s)              6.597804294433445
Epoch Time (s)               173.91823684237897
Total Train Time (s)         49866.83250547387
Epoch                        291
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:44:45.909126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #291 | Epoch Duration: 174.00291347503662
2020-01-12 21:44:45.909269 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #291 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7722896
Z variance train             0.101696454
KL Divergence                44.69092
KL Loss                      4.4690924
QF Loss                      3220.54
VF Loss                      65.32998
Policy Loss                  -1183.2407
Q Predictions Mean           1181.7894
Q Predictions Std            1179.8167
Q Predictions Max            4316.385
Q Predictions Min            599.09845
V Predictions Mean           1189.264
V Predictions Std            1182.0874
V Predictions Max            4339.2583
V Predictions Min            609.9986
Log Pis Mean                 -0.6406333
Log Pis Std                  3.5307643
Log Pis Max                  13.195324
Log Pis Min                  -8.9440365
Policy mu Mean               0.024223946
Policy mu Std                0.839058
Policy mu Max                2.7931514
Policy mu Min                -2.7439356
Policy log std Mean          -0.49955297
Policy log std Std           0.2681348
Policy log std Max           0.007417619
Policy log std Min           -2.5651085
Z mean eval                  1.7606472
Z variance eval              0.07049555
total_rewards                [ 9554.58440381  9665.94559024  9790.56374431  9886.40581116
  9730.99293983  9792.32737444 10087.52878071  9816.38340068
  9931.31944268  9877.94154911]
total_rewards_mean           9813.399303698334
total_rewards_std            139.65698462704322
total_rewards_max            10087.528780712108
total_rewards_min            9554.584403813999
Number of train steps total  1172000
Number of env steps total    3518000
Number of rollouts total     0
Train Time (s)               148.37834131438285
(Previous) Eval Time (s)     19.66342899063602
Sample Time (s)              6.466103165410459
Epoch Time (s)               174.50787347042933
Total Train Time (s)         50041.42384757474
Epoch                        292
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:47:40.505499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #292 | Epoch Duration: 174.59609937667847
2020-01-12 21:47:40.505694 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7573166
Z variance train             0.07048865
KL Divergence                45.945652
KL Loss                      4.5945654
QF Loss                      212.19734
VF Loss                      85.1691
Policy Loss                  -1316.2229
Q Predictions Mean           1313.4551
Q Predictions Std            1317.6665
Q Predictions Max            4366.346
Q Predictions Min            606.2456
V Predictions Mean           1321.6592
V Predictions Std            1321.1127
V Predictions Max            4387.2334
V Predictions Min            607.0357
Log Pis Mean                 -0.28230304
Log Pis Std                  3.7044344
Log Pis Max                  13.419886
Log Pis Min                  -6.5579886
Policy mu Mean               0.08874122
Policy mu Std                0.8476482
Policy mu Max                2.7775476
Policy mu Min                -2.4866803
Policy log std Mean          -0.51742643
Policy log std Std           0.30340925
Policy log std Max           0.1490221
Policy log std Min           -2.6783462
Z mean eval                  1.7835901
Z variance eval              0.13394883
total_rewards                [ 9786.35484164  9785.96812964  9777.39709259  9816.59265174
  9969.45230246 10150.46247233 10334.6011771   9936.16617803
  9761.73991914 10092.1154927 ]
total_rewards_mean           9941.085025737515
total_rewards_std            185.68586783888816
total_rewards_max            10334.601177101635
total_rewards_min            9761.739919144442
Number of train steps total  1176000
Number of env steps total    3530000
Number of rollouts total     0
Train Time (s)               146.2617495143786
(Previous) Eval Time (s)     20.898657848127186
Sample Time (s)              6.493871899787337
Epoch Time (s)               173.65427926229313
Total Train Time (s)         50215.16054207785
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:50:34.243481 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #293 | Epoch Duration: 173.73765325546265
2020-01-12 21:50:34.243617 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7843113
Z variance train             0.13446955
KL Divergence                44.747395
KL Loss                      4.4747396
QF Loss                      83.30455
VF Loss                      36.7655
Policy Loss                  -1234.2246
Q Predictions Mean           1230.7877
Q Predictions Std            1210.2255
Q Predictions Max            4471.8696
Q Predictions Min            623.23755
V Predictions Mean           1235.4695
V Predictions Std            1211.5885
V Predictions Max            4484.7383
V Predictions Min            630.5162
Log Pis Mean                 -0.6223146
Log Pis Std                  3.4817421
Log Pis Max                  12.162188
Log Pis Min                  -8.301773
Policy mu Mean               0.03249288
Policy mu Std                0.83581555
Policy mu Max                2.498312
Policy mu Min                -2.7058034
Policy log std Mean          -0.5012674
Policy log std Std           0.2842324
Policy log std Max           0.22878253
Policy log std Min           -2.6395016
Z mean eval                  1.7871363
Z variance eval              0.065643474
total_rewards                [9711.39282932 9714.65557264 9891.68954528 9494.70129223 9741.4650806
 9718.0149579  9765.81474027 9697.64697162 9928.85709072 9754.50471153]
total_rewards_mean           9741.874279211408
total_rewards_std            111.09896979963305
total_rewards_max            9928.857090715148
total_rewards_min            9494.701292228763
Number of train steps total  1180000
Number of env steps total    3542000
Number of rollouts total     0
Train Time (s)               147.8722472260706
(Previous) Eval Time (s)     20.883575363084674
Sample Time (s)              6.362222519237548
Epoch Time (s)               175.11804510839283
Total Train Time (s)         50390.36641819356
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:53:29.451227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #294 | Epoch Duration: 175.20751094818115
2020-01-12 21:53:29.451362 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #294 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.788945
Z variance train             0.065576024
KL Divergence                45.146732
KL Loss                      4.514673
QF Loss                      108.29137
VF Loss                      51.06169
Policy Loss                  -1107.1108
Q Predictions Mean           1106.1996
Q Predictions Std            1113.5134
Q Predictions Max            4398.0854
Q Predictions Min            614.6111
V Predictions Mean           1103.0935
V Predictions Std            1110.1309
V Predictions Max            4382.3247
V Predictions Min            615.15515
Log Pis Mean                 -0.8189488
Log Pis Std                  3.685084
Log Pis Max                  14.407267
Log Pis Min                  -8.967124
Policy mu Mean               0.08752885
Policy mu Std                0.82651645
Policy mu Max                3.8015578
Policy mu Min                -3.3320742
Policy log std Mean          -0.4918108
Policy log std Std           0.28174993
Policy log std Max           0.022119045
Policy log std Min           -2.4166465
Z mean eval                  1.7972469
Z variance eval              0.06322133
total_rewards                [9221.39165948 9437.65608062 9399.93686065 9377.85099416 9462.402452
 9432.97173694 9132.94382333 9099.79385166 9114.69673406 9401.45719687]
total_rewards_mean           9308.11013897778
total_rewards_std            140.4265103178095
total_rewards_max            9462.402451998738
total_rewards_min            9099.793851658735
Number of train steps total  1184000
Number of env steps total    3554000
Number of rollouts total     0
Train Time (s)               146.6431085160002
(Previous) Eval Time (s)     20.5017858450301
Sample Time (s)              6.431200892664492
Epoch Time (s)               173.5760952536948
Total Train Time (s)         50564.11758754775
Epoch                        295
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:56:23.204506 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #295 | Epoch Duration: 173.75304746627808
2020-01-12 21:56:23.204642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8022372
Z variance train             0.06285991
KL Divergence                44.913536
KL Loss                      4.4913535
QF Loss                      147.71423
VF Loss                      57.36821
Policy Loss                  -1329.5085
Q Predictions Mean           1326.4216
Q Predictions Std            1307.8597
Q Predictions Max            4489.7817
Q Predictions Min            621.85944
V Predictions Mean           1326.5116
V Predictions Std            1308.5009
V Predictions Max            4485.5186
V Predictions Min            606.2001
Log Pis Mean                 -0.24486737
Log Pis Std                  4.2440224
Log Pis Max                  21.710302
Log Pis Min                  -7.3248873
Policy mu Mean               0.06422213
Policy mu Std                0.90940714
Policy mu Max                3.7979743
Policy mu Min                -3.21097
Policy log std Mean          -0.49762344
Policy log std Std           0.28703263
Policy log std Max           0.23438823
Policy log std Min           -2.8057988
Z mean eval                  1.8225048
Z variance eval              0.08786689
total_rewards                [9070.95118039 8594.54958323 8290.01829468 7777.7018734  7861.37185387
 8513.73749539 8087.50512516 7832.12661752 8168.11673373 7686.31779673]
total_rewards_mean           8188.2396554111165
total_rewards_std            415.3616959571746
total_rewards_max            9070.951180386957
total_rewards_min            7686.317796730912
Number of train steps total  1188000
Number of env steps total    3566000
Number of rollouts total     0
Train Time (s)               146.73075282294303
(Previous) Eval Time (s)     20.711064288858324
Sample Time (s)              6.4352643811143935
Epoch Time (s)               173.87708149291575
Total Train Time (s)         50738.07854477409
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:59:17.167475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #296 | Epoch Duration: 173.96273517608643
2020-01-12 21:59:17.167610 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8256531
Z variance train             0.08727001
KL Divergence                44.771996
KL Loss                      4.4771996
QF Loss                      245.21277
VF Loss                      41.50163
Policy Loss                  -1157.0105
Q Predictions Mean           1155.0613
Q Predictions Std            1143.9895
Q Predictions Max            4397.577
Q Predictions Min            620.24414
V Predictions Mean           1154.8293
V Predictions Std            1141.114
V Predictions Max            4369.067
V Predictions Min            624.5424
Log Pis Mean                 -0.87420774
Log Pis Std                  3.2204695
Log Pis Max                  12.514687
Log Pis Min                  -5.734761
Policy mu Mean               0.061504263
Policy mu Std                0.8073748
Policy mu Max                2.9221423
Policy mu Min                -2.8248937
Policy log std Mean          -0.48920342
Policy log std Std           0.26607257
Policy log std Max           0.17148864
Policy log std Min           -2.3700798
Z mean eval                  1.776922
Z variance eval              0.06602446
total_rewards                [9600.82018182 9947.89001377 9599.93637229 9881.22717991 9854.74122976
 4146.41931455 9903.87656295 9837.98179263 9811.69236048 9933.41037082]
total_rewards_mean           9251.799537898942
total_rewards_std            1705.8449244836427
total_rewards_max            9947.890013767907
total_rewards_min            4146.419314554901
Number of train steps total  1192000
Number of env steps total    3578000
Number of rollouts total     0
Train Time (s)               146.6342815309763
(Previous) Eval Time (s)     20.826059431303293
Sample Time (s)              6.3957953420467675
Epoch Time (s)               173.85613630432636
Total Train Time (s)         50912.01461682981
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:02:11.105282 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #297 | Epoch Duration: 173.93757677078247
2020-01-12 22:02:11.105412 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #297 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7753452
Z variance train             0.065744184
KL Divergence                44.130074
KL Loss                      4.4130073
QF Loss                      307.713
VF Loss                      34.060604
Policy Loss                  -1162.9637
Q Predictions Mean           1161.2026
Q Predictions Std            1129.9381
Q Predictions Max            4482.8896
Q Predictions Min            620.6795
V Predictions Mean           1165.2446
V Predictions Std            1128.4967
V Predictions Max            4477.49
V Predictions Min            627.9984
Log Pis Mean                 -0.37792534
Log Pis Std                  3.6560495
Log Pis Max                  20.710644
Log Pis Min                  -6.492455
Policy mu Mean               0.10623851
Policy mu Std                0.853081
Policy mu Max                3.331889
Policy mu Min                -2.9735067
Policy log std Mean          -0.49464807
Policy log std Std           0.26936847
Policy log std Max           0.41083807
Policy log std Min           -2.5652418
Z mean eval                  1.7654731
Z variance eval              0.044286896
total_rewards                [ 9384.25880016  9753.5399584   9847.49533552 10007.83528499
 10024.44678988  9809.22567345  9945.52184422  9803.53835929
  9840.68375081  9993.82449937]
total_rewards_mean           9841.03702960959
total_rewards_std            177.3369451359737
total_rewards_max            10024.446789877977
total_rewards_min            9384.258800163625
Number of train steps total  1196000
Number of env steps total    3590000
Number of rollouts total     0
Train Time (s)               147.7659698203206
(Previous) Eval Time (s)     17.441839011851698
Sample Time (s)              6.526860641781241
Epoch Time (s)               171.73466947395355
Total Train Time (s)         51083.82687009359
Epoch                        298
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:05:02.920889 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #298 | Epoch Duration: 171.81536436080933
2020-01-12 22:05:02.921065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7662363
Z variance train             0.04419474
KL Divergence                45.45102
KL Loss                      4.545102
QF Loss                      131.35718
VF Loss                      96.74388
Policy Loss                  -1403.6234
Q Predictions Mean           1397.6633
Q Predictions Std            1336.9595
Q Predictions Max            4412.6494
Q Predictions Min            619.3424
V Predictions Mean           1398.6206
V Predictions Std            1337.1694
V Predictions Max            4419.769
V Predictions Min            624.2218
Log Pis Mean                 -0.14102449
Log Pis Std                  3.6180964
Log Pis Max                  13.570574
Log Pis Min                  -7.01133
Policy mu Mean               0.06840125
Policy mu Std                0.86914355
Policy mu Max                2.9084024
Policy mu Min                -2.4072957
Policy log std Mean          -0.53438693
Policy log std Std           0.31011233
Policy log std Max           -0.05377698
Policy log std Min           -2.9317627
Z mean eval                  1.7752209
Z variance eval              0.074220166
total_rewards                [9456.19410912 9197.45600563 9598.99930434 6147.55755811 9555.02273058
 9367.18184026 9748.29580897 9017.31043123 9500.89703187 9656.47116388]
total_rewards_mean           9124.538598398864
total_rewards_std            1013.5187514260117
total_rewards_max            9748.295808968158
total_rewards_min            6147.557558106802
Number of train steps total  1200000
Number of env steps total    3602000
Number of rollouts total     0
Train Time (s)               145.35767476214096
(Previous) Eval Time (s)     20.77295720623806
Sample Time (s)              6.585640623234212
Epoch Time (s)               172.71627259161323
Total Train Time (s)         51256.62433876749
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:07:55.720166 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #299 | Epoch Duration: 172.798969745636
2020-01-12 22:07:55.720308 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7747421
Z variance train             0.07423786
KL Divergence                45.09706
KL Loss                      4.509706
QF Loss                      3782.5654
VF Loss                      37.434273
Policy Loss                  -1223.245
Q Predictions Mean           1221.0337
Q Predictions Std            1199.2335
Q Predictions Max            4395.873
Q Predictions Min            627.30524
V Predictions Mean           1224.8499
V Predictions Std            1197.0975
V Predictions Max            4389.018
V Predictions Min            621.3709
Log Pis Mean                 -0.43736666
Log Pis Std                  3.8200774
Log Pis Max                  16.496737
Log Pis Min                  -9.028261
Policy mu Mean               0.08393634
Policy mu Std                0.8633996
Policy mu Max                3.2865548
Policy mu Min                -2.7072902
Policy log std Mean          -0.48977718
Policy log std Std           0.2749999
Policy log std Max           0.23198771
Policy log std Min           -2.5429761
Z mean eval                  1.7961047
Z variance eval              0.07271739
total_rewards                [9231.6628517  9760.06165774 9729.40477773 9752.67934466 9766.16304675
 9397.42942754 9620.16833119 9690.16395916 9669.11655925 9570.04129935]
total_rewards_mean           9618.689125506615
total_rewards_std            167.5445171626156
total_rewards_max            9766.163046746362
total_rewards_min            9231.662851698567
Number of train steps total  1204000
Number of env steps total    3614000
Number of rollouts total     0
Train Time (s)               146.76977785630152
(Previous) Eval Time (s)     20.73562667891383
Sample Time (s)              8.129041645675898
Epoch Time (s)               175.63444618089125
Total Train Time (s)         51432.343228037935
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:10:51.441893 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #300 | Epoch Duration: 175.72148418426514
2020-01-12 22:10:51.442030 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #300 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7955515
Z variance train             0.07270336
KL Divergence                43.782867
KL Loss                      4.378287
QF Loss                      332.877
VF Loss                      148.72339
Policy Loss                  -1280.014
Q Predictions Mean           1278.2876
Q Predictions Std            1267.7418
Q Predictions Max            4482.2227
Q Predictions Min            640.1394
V Predictions Mean           1280.8284
V Predictions Std            1271.0627
V Predictions Max            4521.483
V Predictions Min            634.00073
Log Pis Mean                 -0.25972697
Log Pis Std                  3.56801
Log Pis Max                  14.651103
Log Pis Min                  -6.765519
Policy mu Mean               -0.021065215
Policy mu Std                0.8717477
Policy mu Max                3.1865072
Policy mu Min                -2.6083379
Policy log std Mean          -0.5109462
Policy log std Std           0.2921282
Policy log std Max           0.12725812
Policy log std Min           -2.390552
Z mean eval                  1.7961328
Z variance eval              0.069618575
total_rewards                [ 9802.0151278   9699.44526854  9847.73951123 10020.70913508
  9838.01395219  9831.83875143  9984.58770199  9722.35988993
  9974.62458473  9733.63245409]
total_rewards_mean           9845.496637701484
total_rewards_std            108.56575306784231
total_rewards_max            10020.709135082709
total_rewards_min            9699.445268539595
Number of train steps total  1208000
Number of env steps total    3626000
Number of rollouts total     0
Train Time (s)               147.13537891115993
(Previous) Eval Time (s)     20.9792550932616
Sample Time (s)              6.3891238565556705
Epoch Time (s)               174.5037578609772
Total Train Time (s)         51606.979694562964
Epoch                        301
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:13:46.087242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #301 | Epoch Duration: 174.6450638771057
2020-01-12 22:13:46.087574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #301 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7977053
Z variance train             0.06952851
KL Divergence                44.68281
KL Loss                      4.4682813
QF Loss                      96.74396
VF Loss                      74.89988
Policy Loss                  -1304.4158
Q Predictions Mean           1300.3242
Q Predictions Std            1271.2744
Q Predictions Max            4392.5957
Q Predictions Min            621.89844
V Predictions Mean           1299.4531
V Predictions Std            1267.7158
V Predictions Max            4386.294
V Predictions Min            623.01434
Log Pis Mean                 -0.03864701
Log Pis Std                  3.8446121
Log Pis Max                  17.71598
Log Pis Min                  -6.0567646
Policy mu Mean               0.01314159
Policy mu Std                0.9226242
Policy mu Max                2.8907664
Policy mu Min                -3.2848103
Policy log std Mean          -0.4882224
Policy log std Std           0.2770315
Policy log std Max           0.26449448
Policy log std Min           -2.7558799
Z mean eval                  1.7999731
Z variance eval              0.07085535
total_rewards                [ 9545.90370966 10054.27444372  9735.02181911  9842.6018181
  9762.99802044  9774.73040487  9816.34222279  9701.40066011
 10117.18525593  9936.78480857]
total_rewards_mean           9828.724316330126
total_rewards_std            160.7233027116543
total_rewards_max            10117.18525592806
total_rewards_min            9545.903709655604
Number of train steps total  1212000
Number of env steps total    3638000
Number of rollouts total     0
Train Time (s)               148.6941445628181
(Previous) Eval Time (s)     20.83903538901359
Sample Time (s)              6.476941705681384
Epoch Time (s)               176.01012165751308
Total Train Time (s)         51783.152066549286
Epoch                        302
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:16:42.265884 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #302 | Epoch Duration: 176.17805218696594
2020-01-12 22:16:42.266148 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7997215
Z variance train             0.07057479
KL Divergence                44.20946
KL Loss                      4.420946
QF Loss                      202.38177
VF Loss                      72.1368
Policy Loss                  -1174.714
Q Predictions Mean           1166.4226
Q Predictions Std            1120.7981
Q Predictions Max            4449.744
Q Predictions Min            626.19763
V Predictions Mean           1171.1782
V Predictions Std            1122.1384
V Predictions Max            4445.9766
V Predictions Min            627.487
Log Pis Mean                 -0.5434498
Log Pis Std                  4.022326
Log Pis Max                  18.898846
Log Pis Min                  -6.964944
Policy mu Mean               -0.0013154013
Policy mu Std                0.8760498
Policy mu Max                3.4486058
Policy mu Min                -3.5043552
Policy log std Mean          -0.48827
Policy log std Std           0.2763987
Policy log std Max           0.11077744
Policy log std Min           -2.9110389
Z mean eval                  1.7733183
Z variance eval              0.05421058
total_rewards                [ 9589.92368579 10085.72682977 10010.06086752  9926.49256446
  9813.28564654 10132.43847789  9844.61800543  9923.97897051
  9935.02809259  9916.08133771]
total_rewards_mean           9917.763447822004
total_rewards_std            143.86673827494698
total_rewards_max            10132.438477890926
total_rewards_min            9589.923685790814
Number of train steps total  1216000
Number of env steps total    3650000
Number of rollouts total     0
Train Time (s)               146.55261725513265
(Previous) Eval Time (s)     20.812600024975836
Sample Time (s)              6.391945228911936
Epoch Time (s)               173.75716250902042
Total Train Time (s)         51956.99492629757
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:19:36.109118 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #303 | Epoch Duration: 173.84278774261475
2020-01-12 22:19:36.109250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7736838
Z variance train             0.05427807
KL Divergence                44.290207
KL Loss                      4.429021
QF Loss                      148.28806
VF Loss                      40.375397
Policy Loss                  -1291.0541
Q Predictions Mean           1289.9509
Q Predictions Std            1265.8804
Q Predictions Max            4539.987
Q Predictions Min            625.1691
V Predictions Mean           1291.0734
V Predictions Std            1265.9443
V Predictions Max            4540.906
V Predictions Min            620.0627
Log Pis Mean                 -0.3320163
Log Pis Std                  3.5391076
Log Pis Max                  12.459843
Log Pis Min                  -5.988287
Policy mu Mean               0.00015985407
Policy mu Std                0.86376137
Policy mu Max                2.874387
Policy mu Min                -2.7309039
Policy log std Mean          -0.4864192
Policy log std Std           0.27105284
Policy log std Max           0.18617451
Policy log std Min           -2.270648
Z mean eval                  1.765756
Z variance eval              0.08573645
total_rewards                [9526.98556361 9281.7873082  9793.15958492 9674.86047983 9387.54424556
 9665.21957479 9579.99852525 9464.85367618 9657.97899156 8952.43231187]
total_rewards_mean           9498.482026176764
total_rewards_std            231.7773186228015
total_rewards_max            9793.159584920659
total_rewards_min            8952.432311868688
Number of train steps total  1220000
Number of env steps total    3662000
Number of rollouts total     0
Train Time (s)               148.6317911730148
(Previous) Eval Time (s)     17.584219795186073
Sample Time (s)              6.461607371922582
Epoch Time (s)               172.67761834012344
Total Train Time (s)         52129.75681212917
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:22:28.874214 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #304 | Epoch Duration: 172.76485109329224
2020-01-12 22:22:28.874391 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7672135
Z variance train             0.085728295
KL Divergence                42.719284
KL Loss                      4.2719283
QF Loss                      160.20615
VF Loss                      227.56012
Policy Loss                  -1288.1722
Q Predictions Mean           1284.4457
Q Predictions Std            1278.941
Q Predictions Max            4516.4644
Q Predictions Min            624.93274
V Predictions Mean           1277.1361
V Predictions Std            1268.9524
V Predictions Max            4475.447
V Predictions Min            619.6817
Log Pis Mean                 -0.40369207
Log Pis Std                  4.228481
Log Pis Max                  20.997288
Log Pis Min                  -9.429037
Policy mu Mean               0.0030029186
Policy mu Std                0.88400215
Policy mu Max                3.2972324
Policy mu Min                -3.2785535
Policy log std Mean          -0.49148598
Policy log std Std           0.2947284
Policy log std Max           0.037620485
Policy log std Min           -2.578416
Z mean eval                  1.7990776
Z variance eval              0.06866924
total_rewards                [9325.963591   9639.38866346 6745.52607816 9762.14836396 9771.25947909
 9706.86257459 9754.64025295 9406.77695136 9572.01764549 9561.93045086]
total_rewards_mean           9324.651405093642
total_rewards_std            871.609021958248
total_rewards_max            9771.259479094118
total_rewards_min            6745.52607816466
Number of train steps total  1224000
Number of env steps total    3674000
Number of rollouts total     0
Train Time (s)               146.85900598904118
(Previous) Eval Time (s)     18.307155821938068
Sample Time (s)              6.697442340198904
Epoch Time (s)               171.86360415117815
Total Train Time (s)         52301.79360276507
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:25:20.917739 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #305 | Epoch Duration: 172.04320073127747
2020-01-12 22:25:20.917941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7985992
Z variance train             0.06862789
KL Divergence                44.439327
KL Loss                      4.443933
QF Loss                      149.81592
VF Loss                      61.45254
Policy Loss                  -1275.624
Q Predictions Mean           1274.5049
Q Predictions Std            1242.9208
Q Predictions Max            4466.6357
Q Predictions Min            627.2416
V Predictions Mean           1276.2631
V Predictions Std            1242.7554
V Predictions Max            4467.7573
V Predictions Min            631.0571
Log Pis Mean                 -0.53933144
Log Pis Std                  3.6731443
Log Pis Max                  12.492868
Log Pis Min                  -7.893554
Policy mu Mean               0.016283752
Policy mu Std                0.8467416
Policy mu Max                2.8555837
Policy mu Min                -2.816742
Policy log std Mean          -0.49351645
Policy log std Std           0.28944808
Policy log std Max           0.09078914
Policy log std Min           -2.6196077
Z mean eval                  1.7916797
Z variance eval              0.082396366
total_rewards                [8962.23615838 9242.78010083 3491.92814336 9329.1191469  9318.22380099
 8938.8725333  9250.1670199  9105.814003   9324.23574955 9408.35786359]
total_rewards_mean           8637.173451979668
total_rewards_std            1721.6788404980134
total_rewards_max            9408.357863591304
total_rewards_min            3491.9281433610345
Number of train steps total  1228000
Number of env steps total    3686000
Number of rollouts total     0
Train Time (s)               146.0020103752613
(Previous) Eval Time (s)     20.445565198082477
Sample Time (s)              6.563765593338758
Epoch Time (s)               173.01134116668254
Total Train Time (s)         52474.89129066048
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:28:14.023278 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #306 | Epoch Duration: 173.10515308380127
2020-01-12 22:28:14.023587 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7935026
Z variance train             0.08210872
KL Divergence                45.301624
KL Loss                      4.5301623
QF Loss                      126.600945
VF Loss                      109.258865
Policy Loss                  -1360.3292
Q Predictions Mean           1359.252
Q Predictions Std            1331.8873
Q Predictions Max            4483.1133
Q Predictions Min            632.4388
V Predictions Mean           1355.7297
V Predictions Std            1321.9446
V Predictions Max            4447.3325
V Predictions Min            631.5299
Log Pis Mean                 -0.22178736
Log Pis Std                  4.007602
Log Pis Max                  13.244955
Log Pis Min                  -7.4860396
Policy mu Mean               0.044446904
Policy mu Std                0.87862676
Policy mu Max                2.9192147
Policy mu Min                -2.5026824
Policy log std Mean          -0.50762725
Policy log std Std           0.29433048
Policy log std Max           0.2171309
Policy log std Min           -2.6851153
Z mean eval                  1.8043737
Z variance eval              0.09714695
total_rewards                [9555.79185273 9395.63616525 9424.58607337 9617.6100549  9474.72424989
 9710.55395606 9302.84174249 9396.79067392 9348.02786456 9344.90489961]
total_rewards_mean           9457.146753277662
total_rewards_std            125.22192866942453
total_rewards_max            9710.553956058711
total_rewards_min            9302.841742487195
Number of train steps total  1232000
Number of env steps total    3698000
Number of rollouts total     0
Train Time (s)               144.75072347419336
(Previous) Eval Time (s)     21.07744924305007
Sample Time (s)              6.600636965595186
Epoch Time (s)               172.42880968283862
Total Train Time (s)         52647.415347011294
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:31:06.550259 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #307 | Epoch Duration: 172.52644515037537
2020-01-12 22:31:06.550482 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #307 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8041741
Z variance train             0.09759934
KL Divergence                44.115425
KL Loss                      4.4115424
QF Loss                      137.72667
VF Loss                      230.26747
Policy Loss                  -1259.7378
Q Predictions Mean           1259.7448
Q Predictions Std            1228.326
Q Predictions Max            4476.597
Q Predictions Min            619.0707
V Predictions Mean           1268.7869
V Predictions Std            1233.8253
V Predictions Max            4503.5537
V Predictions Min            627.6394
Log Pis Mean                 -0.3053261
Log Pis Std                  4.115492
Log Pis Max                  23.373491
Log Pis Min                  -7.684518
Policy mu Mean               0.077526174
Policy mu Std                0.90920836
Policy mu Max                3.1731331
Policy mu Min                -4.452347
Policy log std Mean          -0.4875659
Policy log std Std           0.26642326
Policy log std Max           -0.029409587
Policy log std Min           -2.582425
Z mean eval                  1.7777439
Z variance eval              0.07455977
total_rewards                [ 9773.70786804  9611.25395373  9964.7744772   9886.11167285
  9817.17194562  9686.74196867  9882.3952756   9603.61940974
 10065.42856989  9967.31649711]
total_rewards_mean           9825.852163844049
total_rewards_std            148.70190380076596
total_rewards_max            10065.428569892583
total_rewards_min            9603.619409737952
Number of train steps total  1236000
Number of env steps total    3710000
Number of rollouts total     0
Train Time (s)               145.16040387609974
(Previous) Eval Time (s)     17.534940616227686
Sample Time (s)              6.563863026443869
Epoch Time (s)               169.2592075187713
Total Train Time (s)         52816.75679601403
Epoch                        308
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:33:55.897369 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #308 | Epoch Duration: 169.34673309326172
2020-01-12 22:33:55.897535 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #308 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7768011
Z variance train             0.074453175
KL Divergence                44.801502
KL Loss                      4.48015
QF Loss                      290.2929
VF Loss                      61.198494
Policy Loss                  -1148.8304
Q Predictions Mean           1142.4834
Q Predictions Std            1108.9772
Q Predictions Max            4462.8354
Q Predictions Min            617.6345
V Predictions Mean           1153.1287
V Predictions Std            1110.8193
V Predictions Max            4466.1387
V Predictions Min            627.57837
Log Pis Mean                 -0.4166856
Log Pis Std                  3.6811256
Log Pis Max                  14.333782
Log Pis Min                  -7.595539
Policy mu Mean               0.04888575
Policy mu Std                0.832394
Policy mu Max                2.7515152
Policy mu Min                -3.2707703
Policy log std Mean          -0.51266605
Policy log std Std           0.29559457
Policy log std Max           0.050203264
Policy log std Min           -2.5651765
Z mean eval                  1.776811
Z variance eval              0.08908029
total_rewards                [ 9425.96184676  9835.67890575 10091.90724705  9767.092064
  9807.49120338  9977.75562138  9614.5010228   9787.30537355
  9680.1883365   9832.19003332]
total_rewards_mean           9782.007165449737
total_rewards_std            174.88513735424436
total_rewards_max            10091.907247052937
total_rewards_min            9425.961846757484
Number of train steps total  1240000
Number of env steps total    3722000
Number of rollouts total     0
Train Time (s)               147.19403685769066
(Previous) Eval Time (s)     20.675275477115065
Sample Time (s)              6.410454101394862
Epoch Time (s)               174.2797664362006
Total Train Time (s)         52991.12078478327
Epoch                        309
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:36:50.264561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #309 | Epoch Duration: 174.3669068813324
2020-01-12 22:36:50.264693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #309 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7767203
Z variance train             0.08894973
KL Divergence                43.74858
KL Loss                      4.3748584
QF Loss                      322.93994
VF Loss                      30.20936
Policy Loss                  -1160.7787
Q Predictions Mean           1156.9486
Q Predictions Std            1165.4595
Q Predictions Max            4451.756
Q Predictions Min            613.729
V Predictions Mean           1158.9637
V Predictions Std            1166.575
V Predictions Max            4444.6987
V Predictions Min            619.3392
Log Pis Mean                 -0.79207695
Log Pis Std                  3.5484397
Log Pis Max                  15.273776
Log Pis Min                  -7.2679873
Policy mu Mean               0.04810205
Policy mu Std                0.8409586
Policy mu Max                2.934445
Policy mu Min                -3.3897822
Policy log std Mean          -0.50179464
Policy log std Std           0.27869108
Policy log std Max           0.09431815
Policy log std Min           -2.494413
Z mean eval                  1.80108
Z variance eval              0.07824404
total_rewards                [10011.95211126  9943.93387989 10097.50991435 10029.56487999
  9979.15105968  9992.76087659  9742.30399858  9720.52169664
  9694.31935735  2978.36951377]
total_rewards_mean           9219.038728809957
total_rewards_std            2084.6198989802697
total_rewards_max            10097.509914351767
total_rewards_min            2978.3695137661334
Number of train steps total  1244000
Number of env steps total    3734000
Number of rollouts total     0
Train Time (s)               145.65282604005188
(Previous) Eval Time (s)     20.65744609804824
Sample Time (s)              6.576770623214543
Epoch Time (s)               172.88704276131466
Total Train Time (s)         53164.091541513335
Epoch                        310
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:39:43.237107 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #310 | Epoch Duration: 172.97231674194336
2020-01-12 22:39:43.237243 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8007901
Z variance train             0.07823266
KL Divergence                44.869946
KL Loss                      4.4869947
QF Loss                      82.2359
VF Loss                      42.612663
Policy Loss                  -1144.7765
Q Predictions Mean           1145.5264
Q Predictions Std            1139.6516
Q Predictions Max            4436.485
Q Predictions Min            609.04565
V Predictions Mean           1146.7864
V Predictions Std            1134.7092
V Predictions Max            4423.4824
V Predictions Min            623.0147
Log Pis Mean                 -0.43932512
Log Pis Std                  3.4313643
Log Pis Max                  12.650631
Log Pis Min                  -8.274021
Policy mu Mean               0.021535635
Policy mu Std                0.845201
Policy mu Max                2.4625788
Policy mu Min                -2.5442915
Policy log std Mean          -0.504466
Policy log std Std           0.2530017
Policy log std Max           0.26568323
Policy log std Min           -2.425052
Z mean eval                  1.7963327
Z variance eval              0.08562441
total_rewards                [ 9371.58872134  9877.19368266  9796.50796289  9871.70083544
  9549.70862587  9839.08544931 10162.2133726   9905.19537302
  9945.56424738  9591.30051594]
total_rewards_mean           9791.005878646127
total_rewards_std            215.6436442676122
total_rewards_max            10162.213372598844
total_rewards_min            9371.588721342006
Number of train steps total  1248000
Number of env steps total    3746000
Number of rollouts total     0
Train Time (s)               144.85634472128004
(Previous) Eval Time (s)     20.859417208936065
Sample Time (s)              6.444515200331807
Epoch Time (s)               172.1602771305479
Total Train Time (s)         53336.332650802564
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:42:35.480498 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #311 | Epoch Duration: 172.24315810203552
2020-01-12 22:42:35.480637 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #311 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7962716
Z variance train             0.08567779
KL Divergence                44.773045
KL Loss                      4.4773045
QF Loss                      270.1863
VF Loss                      33.942
Policy Loss                  -1123.3965
Q Predictions Mean           1118.6387
Q Predictions Std            1114.3601
Q Predictions Max            4618.031
Q Predictions Min            626.9934
V Predictions Mean           1124.553
V Predictions Std            1119.2251
V Predictions Max            4632.068
V Predictions Min            639.48
Log Pis Mean                 -0.7689757
Log Pis Std                  3.5272124
Log Pis Max                  18.776539
Log Pis Min                  -7.0568686
Policy mu Mean               0.060161244
Policy mu Std                0.8401822
Policy mu Max                4.3152504
Policy mu Min                -3.3407934
Policy log std Mean          -0.49474764
Policy log std Std           0.274777
Policy log std Max           0.21635121
Policy log std Min           -2.8879366
Z mean eval                  1.7841647
Z variance eval              0.093428455
total_rewards                [9202.71395987 9557.58793418 8985.58758087 9307.58643076 9382.3437324
 8143.77627286 9306.26527999 9073.49810118 9341.28350261 8967.03476419]
total_rewards_mean           9126.767755891191
total_rewards_std            371.7769591979031
total_rewards_max            9557.587934179573
total_rewards_min            8143.776272856632
Number of train steps total  1252000
Number of env steps total    3758000
Number of rollouts total     0
Train Time (s)               147.1140506430529
(Previous) Eval Time (s)     17.55216360092163
Sample Time (s)              6.460114154964685
Epoch Time (s)               171.12632839893922
Total Train Time (s)         53507.53807624988
Epoch                        312
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:45:26.689614 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #312 | Epoch Duration: 171.20886301994324
2020-01-12 22:45:26.689782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7855997
Z variance train             0.093419604
KL Divergence                44.21741
KL Loss                      4.421741
QF Loss                      116.75348
VF Loss                      143.56061
Policy Loss                  -1299.3881
Q Predictions Mean           1297.6934
Q Predictions Std            1300.0734
Q Predictions Max            4489.277
Q Predictions Min            636.1987
V Predictions Mean           1293.2192
V Predictions Std            1288.1655
V Predictions Max            4446.8374
V Predictions Min            635.7293
Log Pis Mean                 -0.6721461
Log Pis Std                  3.6448812
Log Pis Max                  15.823763
Log Pis Min                  -11.856018
Policy mu Mean               -0.024462253
Policy mu Std                0.85921603
Policy mu Max                3.2763436
Policy mu Min                -3.1205933
Policy log std Mean          -0.4841137
Policy log std Std           0.2656746
Policy log std Max           0.30590367
Policy log std Min           -2.514464
Z mean eval                  1.8006792
Z variance eval              0.092416614
total_rewards                [9595.48847177 9812.53663929 9635.07906561 9552.98700666 9786.02892557
 9549.46843    9664.55489219 9599.50034457 9584.84508508 9819.4144142 ]
total_rewards_mean           9659.99032749554
total_rewards_std            101.16555069122911
total_rewards_max            9819.41441420254
total_rewards_min            9549.468429997436
Number of train steps total  1256000
Number of env steps total    3770000
Number of rollouts total     0
Train Time (s)               146.49051501322538
(Previous) Eval Time (s)     20.790774310939014
Sample Time (s)              6.514025928452611
Epoch Time (s)               173.795315252617
Total Train Time (s)         53681.432074513286
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:48:20.585292 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #313 | Epoch Duration: 173.8953833580017
2020-01-12 22:48:20.585440 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #313 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.799708
Z variance train             0.09247057
KL Divergence                44.444786
KL Loss                      4.4444785
QF Loss                      202.6352
VF Loss                      63.65096
Policy Loss                  -1426.0076
Q Predictions Mean           1426.8375
Q Predictions Std            1367.022
Q Predictions Max            4487.449
Q Predictions Min            631.5592
V Predictions Mean           1427.9951
V Predictions Std            1366.9971
V Predictions Max            4473.785
V Predictions Min            623.2108
Log Pis Mean                 -0.053217262
Log Pis Std                  4.021117
Log Pis Max                  13.648204
Log Pis Min                  -8.327703
Policy mu Mean               0.023064354
Policy mu Std                0.8970868
Policy mu Max                2.4380906
Policy mu Min                -2.751778
Policy log std Mean          -0.5148533
Policy log std Std           0.31370705
Policy log std Max           0.009624362
Policy log std Min           -2.8126454
Z mean eval                  1.7752241
Z variance eval              0.068423524
total_rewards                [ 9282.87524261  9920.04625788  9765.68718994  9934.40145568
 10091.94764953  9742.32679589  9993.826551    9885.11271757
 10029.76252079  9738.6155431 ]
total_rewards_mean           9838.460192398943
total_rewards_std            218.22231269309887
total_rewards_max            10091.947649526808
total_rewards_min            9282.875242614244
Number of train steps total  1260000
Number of env steps total    3782000
Number of rollouts total     0
Train Time (s)               145.7166095469147
(Previous) Eval Time (s)     17.284411718137562
Sample Time (s)              6.648063201922923
Epoch Time (s)               169.64908446697518
Total Train Time (s)         53851.16395285772
Epoch                        314
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:51:10.322240 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #314 | Epoch Duration: 169.73668003082275
2020-01-12 22:51:10.322419 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7749426
Z variance train             0.06850171
KL Divergence                44.03917
KL Loss                      4.403917
QF Loss                      68.12311
VF Loss                      27.99068
Policy Loss                  -1170.3198
Q Predictions Mean           1170.6338
Q Predictions Std            1165.3677
Q Predictions Max            4478.541
Q Predictions Min            639.9777
V Predictions Mean           1169.7449
V Predictions Std            1162.5529
V Predictions Max            4429.2773
V Predictions Min            643.8294
Log Pis Mean                 -0.48028436
Log Pis Std                  3.6581159
Log Pis Max                  12.617698
Log Pis Min                  -6.233508
Policy mu Mean               0.034611553
Policy mu Std                0.83962697
Policy mu Max                2.4909465
Policy mu Min                -3.3860748
Policy log std Mean          -0.4972725
Policy log std Std           0.26124924
Policy log std Max           0.027370632
Policy log std Min           -2.662407
Z mean eval                  1.7949635
Z variance eval              0.08724328
total_rewards                [9335.60425739 9680.77576791 9490.36091915 9499.225024   9612.46711993
 9638.29412838 9409.16427803 9725.75469371 9510.86079607 9254.70256503]
total_rewards_mean           9515.720954959335
total_rewards_std            144.43236627959647
total_rewards_max            9725.754693710238
total_rewards_min            9254.702565025953
Number of train steps total  1264000
Number of env steps total    3794000
Number of rollouts total     0
Train Time (s)               145.1270740358159
(Previous) Eval Time (s)     20.919906778261065
Sample Time (s)              5.716656708158553
Epoch Time (s)               171.7636375222355
Total Train Time (s)         54023.00660692435
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:54:02.167779 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #315 | Epoch Duration: 171.84522557258606
2020-01-12 22:54:02.167919 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #315 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7947447
Z variance train             0.08734233
KL Divergence                44.14329
KL Loss                      4.414329
QF Loss                      86.03195
VF Loss                      59.7796
Policy Loss                  -1238.3792
Q Predictions Mean           1237.2092
Q Predictions Std            1211.3815
Q Predictions Max            4437.7544
Q Predictions Min            640.6839
V Predictions Mean           1234.8733
V Predictions Std            1208.2854
V Predictions Max            4414.7266
V Predictions Min            637.2332
Log Pis Mean                 -0.6166153
Log Pis Std                  3.1903954
Log Pis Max                  14.598618
Log Pis Min                  -7.440077
Policy mu Mean               -0.024926012
Policy mu Std                0.82863426
Policy mu Max                2.2870686
Policy mu Min                -2.44068
Policy log std Mean          -0.5010974
Policy log std Std           0.27332196
Policy log std Max           0.0016109943
Policy log std Min           -2.628548
Z mean eval                  1.7905957
Z variance eval              0.086955115
total_rewards                [ 9792.54153828 10003.92943057  6632.4814116   9808.34272664
  9901.01542641  9919.68597167 10123.69386013  9715.67304113
  9787.7896183  10146.98086906]
total_rewards_mean           9583.213389378898
total_rewards_std            993.0702150906137
total_rewards_max            10146.98086906192
total_rewards_min            6632.481411597136
Number of train steps total  1268000
Number of env steps total    3806000
Number of rollouts total     0
Train Time (s)               145.14495570305735
(Previous) Eval Time (s)     20.871004222426564
Sample Time (s)              6.404998062644154
Epoch Time (s)               172.42095798812807
Total Train Time (s)         54195.51261004293
Epoch                        316
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:56:54.676754 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #316 | Epoch Duration: 172.50873684883118
2020-01-12 22:56:54.676892 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #316 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7953287
Z variance train             0.08687654
KL Divergence                42.795906
KL Loss                      4.2795906
QF Loss                      111.549576
VF Loss                      129.90356
Policy Loss                  -1228.9694
Q Predictions Mean           1229.7441
Q Predictions Std            1210.5975
Q Predictions Max            4412.45
Q Predictions Min            397.1112
V Predictions Mean           1236.1638
V Predictions Std            1207.8668
V Predictions Max            4431.8853
V Predictions Min            420.666
Log Pis Mean                 -0.58089465
Log Pis Std                  3.7102644
Log Pis Max                  17.666498
Log Pis Min                  -6.52494
Policy mu Mean               0.04804148
Policy mu Std                0.84052885
Policy mu Max                2.7786055
Policy mu Min                -3.0895662
Policy log std Mean          -0.49979028
Policy log std Std           0.30293205
Policy log std Max           0.13399714
Policy log std Min           -2.7357616
Z mean eval                  1.7866462
Z variance eval              0.08098515
total_rewards                [ 9679.8280732   9984.20153326 10154.36403974  9664.09656082
  9679.46115331 10169.06354437  9724.1910651   9886.92768345
  9946.15768536 10127.31384342]
total_rewards_mean           9901.560518204406
total_rewards_std            195.3988426007276
total_rewards_max            10169.063544371005
total_rewards_min            9664.096560823726
Number of train steps total  1272000
Number of env steps total    3818000
Number of rollouts total     0
Train Time (s)               147.50106215197593
(Previous) Eval Time (s)     21.048378004692495
Sample Time (s)              6.4849837962538
Epoch Time (s)               175.03442395292222
Total Train Time (s)         54370.63554027304
Epoch                        317
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:59:49.803693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #317 | Epoch Duration: 175.1267008781433
2020-01-12 22:59:49.803853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7888424
Z variance train             0.08096676
KL Divergence                43.924664
KL Loss                      4.3924665
QF Loss                      100.5616
VF Loss                      66.96734
Policy Loss                  -1303.5632
Q Predictions Mean           1302.7944
Q Predictions Std            1272.3824
Q Predictions Max            4485.6377
Q Predictions Min            637.55023
V Predictions Mean           1299.0492
V Predictions Std            1266.7603
V Predictions Max            4483.229
V Predictions Min            637.519
Log Pis Mean                 -0.22578041
Log Pis Std                  3.7003188
Log Pis Max                  15.616499
Log Pis Min                  -6.8604527
Policy mu Mean               -0.026461527
Policy mu Std                0.8778995
Policy mu Max                2.752522
Policy mu Min                -2.5294917
Policy log std Mean          -0.5049451
Policy log std Std           0.27467513
Policy log std Max           0.033811867
Policy log std Min           -2.72507
Z mean eval                  1.8149059
Z variance eval              0.07224999
total_rewards                [9468.0434454  9634.42008977 9432.54877685 9560.13970554 9695.20447001
 9461.60074088 9496.40337415 9562.52945348 9444.99957729 9464.19452372]
total_rewards_mean           9522.008415710177
total_rewards_std            83.79854717986417
total_rewards_max            9695.204470013055
total_rewards_min            9432.548776851441
Number of train steps total  1276000
Number of env steps total    3830000
Number of rollouts total     0
Train Time (s)               147.04323120880872
(Previous) Eval Time (s)     20.58857871964574
Sample Time (s)              6.4745201715268195
Epoch Time (s)               174.10633009998128
Total Train Time (s)         54544.82632547151
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:02:43.999959 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #318 | Epoch Duration: 174.1959934234619
2020-01-12 23:02:44.000158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8142198
Z variance train             0.07217006
KL Divergence                45.56876
KL Loss                      4.556876
QF Loss                      130.74384
VF Loss                      45.9796
Policy Loss                  -1171.2893
Q Predictions Mean           1168.4698
Q Predictions Std            1142.2971
Q Predictions Max            4515.466
Q Predictions Min            631.99524
V Predictions Mean           1173.1011
V Predictions Std            1139.6653
V Predictions Max            4487.333
V Predictions Min            650.7112
Log Pis Mean                 -0.8331382
Log Pis Std                  3.4860277
Log Pis Max                  18.116556
Log Pis Min                  -10.735769
Policy mu Mean               0.00092520687
Policy mu Std                0.8391631
Policy mu Max                3.3855193
Policy mu Min                -2.88572
Policy log std Mean          -0.49852487
Policy log std Std           0.2731121
Policy log std Max           0.0077904463
Policy log std Min           -2.586977
Z mean eval                  1.8191893
Z variance eval              0.061810352
total_rewards                [9401.33962409 9873.19163202 9609.56025157 9674.01141173 9583.6622926
 9539.0607231  9870.08431981 9624.66075486 9753.39679708 9628.77076237]
total_rewards_mean           9655.773856922451
total_rewards_std            138.00507671496285
total_rewards_max            9873.19163201501
total_rewards_min            9401.339624085032
Number of train steps total  1280000
Number of env steps total    3842000
Number of rollouts total     0
Train Time (s)               146.27230041194707
(Previous) Eval Time (s)     20.824665712192655
Sample Time (s)              6.44978565024212
Epoch Time (s)               173.54675177438185
Total Train Time (s)         54718.458419310395
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:05:37.633829 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #319 | Epoch Duration: 173.6335334777832
2020-01-12 23:05:37.633956 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #319 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8184685
Z variance train             0.06187564
KL Divergence                46.237034
KL Loss                      4.6237035
QF Loss                      133.29282
VF Loss                      46.932415
Policy Loss                  -1355.2161
Q Predictions Mean           1350.6199
Q Predictions Std            1327.2208
Q Predictions Max            4524.739
Q Predictions Min            652.7664
V Predictions Mean           1355.2233
V Predictions Std            1325.4136
V Predictions Max            4517.929
V Predictions Min            650.91406
Log Pis Mean                 -0.1624864
Log Pis Std                  3.9193969
Log Pis Max                  15.417389
Log Pis Min                  -6.569827
Policy mu Mean               0.013450739
Policy mu Std                0.892372
Policy mu Max                3.3218932
Policy mu Min                -3.0201838
Policy log std Mean          -0.510017
Policy log std Std           0.29690346
Policy log std Max           0.020125628
Policy log std Min           -2.7273316
Z mean eval                  1.7931359
Z variance eval              0.06180688
total_rewards                [ 9886.73211423  9772.62332223  2618.94262588 10038.78099806
 10310.4763645   9983.69036037 10110.51527547  6453.70948912
 10301.02820458  9958.26526597]
total_rewards_mean           8943.476402041368
total_rewards_std            2369.8318911249385
total_rewards_max            10310.476364503573
total_rewards_min            2618.9426258784806
Number of train steps total  1284000
Number of env steps total    3854000
Number of rollouts total     0
Train Time (s)               146.6990394545719
(Previous) Eval Time (s)     20.929202146828175
Sample Time (s)              9.112991851754487
Epoch Time (s)               176.74123345315456
Total Train Time (s)         54895.27982244687
Epoch                        320
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:08:34.459470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #320 | Epoch Duration: 176.82540345191956
2020-01-12 23:08:34.459668 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7915913
Z variance train             0.06177526
KL Divergence                46.325565
KL Loss                      4.6325564
QF Loss                      128.34099
VF Loss                      50.620792
Policy Loss                  -1388.82
Q Predictions Mean           1386.7906
Q Predictions Std            1350.8788
Q Predictions Max            4482.2075
Q Predictions Min            648.28625
V Predictions Mean           1391.5123
V Predictions Std            1351.5094
V Predictions Max            4479.8633
V Predictions Min            639.86523
Log Pis Mean                 -0.17547199
Log Pis Std                  3.85754
Log Pis Max                  19.854832
Log Pis Min                  -7.4209986
Policy mu Mean               0.035516363
Policy mu Std                0.8911105
Policy mu Max                3.8539643
Policy mu Min                -3.1948836
Policy log std Mean          -0.5160196
Policy log std Std           0.29072127
Policy log std Max           0.091507375
Policy log std Min           -2.7668412
Z mean eval                  1.8179731
Z variance eval              0.03804742
total_rewards                [9945.8806471  9874.97436651 9465.54198735 9763.76761406 9819.5391115
 9812.33818263 9703.61615315 9785.79274391 9802.25489227 9614.38479763]
total_rewards_mean           9758.809049612424
total_rewards_std            129.4581440029693
total_rewards_max            9945.880647102043
total_rewards_min            9465.541987351919
Number of train steps total  1288000
Number of env steps total    3866000
Number of rollouts total     0
Train Time (s)               146.68735046684742
(Previous) Eval Time (s)     20.63172680605203
Sample Time (s)              6.613966029603034
Epoch Time (s)               173.93304330250248
Total Train Time (s)         55069.29437848274
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:11:28.476901 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #321 | Epoch Duration: 174.01710486412048
2020-01-12 23:11:28.477043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #321 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8166513
Z variance train             0.038317334
KL Divergence                46.796886
KL Loss                      4.679689
QF Loss                      162.21094
VF Loss                      57.69388
Policy Loss                  -1267.4938
Q Predictions Mean           1264.154
Q Predictions Std            1229.0376
Q Predictions Max            4502.2944
Q Predictions Min            627.0964
V Predictions Mean           1269.1566
V Predictions Std            1232.9266
V Predictions Max            4494.0605
V Predictions Min            634.14105
Log Pis Mean                 -0.46615365
Log Pis Std                  3.753073
Log Pis Max                  18.552597
Log Pis Min                  -7.2546434
Policy mu Mean               0.035747185
Policy mu Std                0.8575909
Policy mu Max                3.3654106
Policy mu Min                -3.264254
Policy log std Mean          -0.4954169
Policy log std Std           0.28197476
Policy log std Max           0.123829424
Policy log std Min           -2.4824643
Z mean eval                  1.8378938
Z variance eval              0.035229467
total_rewards                [10324.57758033  9747.52261899 10119.68082762  9944.67272504
  9906.82975509  9918.00824619  9890.95708219 10080.13762785
  9993.69216219  9859.33627466]
total_rewards_mean           9978.541490015134
total_rewards_std            153.43310494035367
total_rewards_max            10324.57758033226
total_rewards_min            9747.522618988236
Number of train steps total  1292000
Number of env steps total    3878000
Number of rollouts total     0
Train Time (s)               146.63254825398326
(Previous) Eval Time (s)     20.88586122682318
Sample Time (s)              6.348956322297454
Epoch Time (s)               173.8673658031039
Total Train Time (s)         55243.24179429794
Epoch                        322
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:14:22.426554 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #322 | Epoch Duration: 173.94941449165344
2020-01-12 23:14:22.426706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #322 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8354524
Z variance train             0.035291873
KL Divergence                46.701706
KL Loss                      4.670171
QF Loss                      3749.7876
VF Loss                      121.99382
Policy Loss                  -1243.1213
Q Predictions Mean           1243.5635
Q Predictions Std            1204.2931
Q Predictions Max            4582.2383
Q Predictions Min            651.9841
V Predictions Mean           1250.9438
V Predictions Std            1209.0864
V Predictions Max            4561.851
V Predictions Min            660.2693
Log Pis Mean                 -0.64009196
Log Pis Std                  3.8796325
Log Pis Max                  18.694765
Log Pis Min                  -7.5491266
Policy mu Mean               0.004742379
Policy mu Std                0.8411301
Policy mu Max                2.8816638
Policy mu Min                -2.8058934
Policy log std Mean          -0.49778786
Policy log std Std           0.24876657
Policy log std Max           -0.08993882
Policy log std Min           -2.8222978
Z mean eval                  1.8086367
Z variance eval              0.062253065
total_rewards                [ 9364.36959992  9673.79740586  9690.45054656 10092.37258081
 10087.32805781  9950.09617363  9561.96115514  9586.88468048
  9896.14996053  9609.19845112]
total_rewards_mean           9751.260861186918
total_rewards_std            230.70450009913333
total_rewards_max            10092.372580810903
total_rewards_min            9364.369599920608
Number of train steps total  1296000
Number of env steps total    3890000
Number of rollouts total     0
Train Time (s)               147.6890561892651
(Previous) Eval Time (s)     20.829177561216056
Sample Time (s)              6.518782259896398
Epoch Time (s)               175.03701601037756
Total Train Time (s)         55418.384355042595
Epoch                        323
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:17:17.571668 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #323 | Epoch Duration: 175.14485335350037
2020-01-12 23:17:17.571819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8083346
Z variance train             0.062205404
KL Divergence                45.60729
KL Loss                      4.560729
QF Loss                      219.96854
VF Loss                      90.42331
Policy Loss                  -1169.7908
Q Predictions Mean           1165.4143
Q Predictions Std            1136.1155
Q Predictions Max            4488.367
Q Predictions Min            624.08887
V Predictions Mean           1172.4409
V Predictions Std            1137.0585
V Predictions Max            4499.5356
V Predictions Min            644.8678
Log Pis Mean                 -0.62989783
Log Pis Std                  3.765229
Log Pis Max                  15.310375
Log Pis Min                  -9.1012745
Policy mu Mean               0.027270874
Policy mu Std                0.83733624
Policy mu Max                2.8599894
Policy mu Min                -2.9920173
Policy log std Mean          -0.48343506
Policy log std Std           0.27185768
Policy log std Max           0.05000502
Policy log std Min           -2.7499425
Z mean eval                  1.8248799
Z variance eval              0.0763
total_rewards                [ 9892.4092187   9971.35117857  9853.27197143  9828.57580705
  9900.41909857  9911.41938252 10035.90893349  9865.60999454
  9741.51747475  9533.69501514]
total_rewards_mean           9853.417807475016
total_rewards_std            130.31311115648865
total_rewards_max            10035.908933488208
total_rewards_min            9533.695015139674
Number of train steps total  1300000
Number of env steps total    3902000
Number of rollouts total     0
Train Time (s)               146.7134806108661
(Previous) Eval Time (s)     20.559383395127952
Sample Time (s)              6.516948052216321
Epoch Time (s)               173.78981205821037
Total Train Time (s)         55592.26152543817
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:20:11.456507 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #324 | Epoch Duration: 173.88453364372253
2020-01-12 23:20:11.456836 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.824578
Z variance train             0.07611875
KL Divergence                44.313255
KL Loss                      4.4313254
QF Loss                      4079.2651
VF Loss                      40.483707
Policy Loss                  -1346.5663
Q Predictions Mean           1344.0398
Q Predictions Std            1286.3104
Q Predictions Max            4565.155
Q Predictions Min            655.9565
V Predictions Mean           1348.6931
V Predictions Std            1291.4928
V Predictions Max            4569.228
V Predictions Min            655.8736
Log Pis Mean                 -0.3258282
Log Pis Std                  3.8476388
Log Pis Max                  16.461363
Log Pis Min                  -6.07214
Policy mu Mean               -0.015268292
Policy mu Std                0.8731474
Policy mu Max                2.870411
Policy mu Min                -2.8070865
Policy log std Mean          -0.4968016
Policy log std Std           0.2829678
Policy log std Max           0.009041667
Policy log std Min           -2.5800118
Z mean eval                  1.8339853
Z variance eval              0.048369553
total_rewards                [7655.44047983 5752.84510276 8559.55563506 7890.42663897 3040.70451243
 7870.0596186  7569.77741771 7917.78743226 8532.0049641  8137.33023499]
total_rewards_mean           7292.593203670394
total_rewards_std            1599.8289582962095
total_rewards_max            8559.55563505779
total_rewards_min            3040.7045124277797
Number of train steps total  1304000
Number of env steps total    3914000
Number of rollouts total     0
Train Time (s)               146.01165640726686
(Previous) Eval Time (s)     20.78400301700458
Sample Time (s)              6.601574673783034
Epoch Time (s)               173.39723409805447
Total Train Time (s)         55766.02625609469
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:23:05.224548 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #325 | Epoch Duration: 173.7674684524536
2020-01-12 23:23:05.224745 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #325 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.83335
Z variance train             0.048315912
KL Divergence                46.083607
KL Loss                      4.608361
QF Loss                      272.6649
VF Loss                      57.4078
Policy Loss                  -1392.077
Q Predictions Mean           1388.9653
Q Predictions Std            1345.9608
Q Predictions Max            4531.745
Q Predictions Min            637.5959
V Predictions Mean           1388.9434
V Predictions Std            1342.5558
V Predictions Max            4516.3325
V Predictions Min            640.2321
Log Pis Mean                 -0.2535825
Log Pis Std                  3.7412157
Log Pis Max                  14.947681
Log Pis Min                  -5.9983234
Policy mu Mean               0.07919838
Policy mu Std                0.87431127
Policy mu Max                3.9232395
Policy mu Min                -2.6082172
Policy log std Mean          -0.50824887
Policy log std Std           0.28710547
Policy log std Max           0.22171384
Policy log std Min           -2.534364
Z mean eval                  1.8194473
Z variance eval              0.07984494
total_rewards                [10063.14229088  9940.3528517  10046.05435381  9908.10160264
  9960.34000501 10107.06768307 10185.11390055 10397.75163036
 10187.67057373 10104.26286518]
total_rewards_mean           10089.985775691639
total_rewards_std            137.38178946202942
total_rewards_max            10397.751630356837
total_rewards_min            9908.101602641507
Number of train steps total  1308000
Number of env steps total    3926000
Number of rollouts total     0
Train Time (s)               146.93553664395586
(Previous) Eval Time (s)     20.508644022978842
Sample Time (s)              6.509763809386641
Epoch Time (s)               173.95394447632134
Total Train Time (s)         55940.234440295026
Epoch                        326
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:25:59.438673 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #326 | Epoch Duration: 174.21376419067383
2020-01-12 23:25:59.438873 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8189042
Z variance train             0.07992017
KL Divergence                45.821995
KL Loss                      4.5821996
QF Loss                      146.47086
VF Loss                      42.22112
Policy Loss                  -1228.2992
Q Predictions Mean           1226.2246
Q Predictions Std            1174.9176
Q Predictions Max            4474.378
Q Predictions Min            661.18445
V Predictions Mean           1230.5381
V Predictions Std            1176.1594
V Predictions Max            4475.9336
V Predictions Min            668.0647
Log Pis Mean                 -0.56933665
Log Pis Std                  3.4682748
Log Pis Max                  13.844731
Log Pis Min                  -7.5461383
Policy mu Mean               0.0020708367
Policy mu Std                0.8483383
Policy mu Max                2.5388198
Policy mu Min                -2.4788399
Policy log std Mean          -0.5099029
Policy log std Std           0.27827972
Policy log std Max           0.07713896
Policy log std Min           -2.617006
Z mean eval                  1.8621187
Z variance eval              0.10776566
total_rewards                [9241.51869715 3750.86294603 9006.04338385 8891.87885532 8894.85209663
 9009.60803255 9293.76660356 9310.69979682 8829.51996668 8875.65679257]
total_rewards_mean           8510.440717116897
total_rewards_std            1595.7857354363714
total_rewards_max            9310.699796821307
total_rewards_min            3750.862946033172
Number of train steps total  1312000
Number of env steps total    3938000
Number of rollouts total     0
Train Time (s)               146.30824392288923
(Previous) Eval Time (s)     18.241675504948944
Sample Time (s)              6.395097536034882
Epoch Time (s)               170.94501696387306
Total Train Time (s)         56111.26459609019
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:28:50.474419 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #327 | Epoch Duration: 171.0354037284851
2020-01-12 23:28:50.474589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #327 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8620383
Z variance train             0.10790123
KL Divergence                45.431343
KL Loss                      4.543134
QF Loss                      3862.7185
VF Loss                      117.93612
Policy Loss                  -1409.451
Q Predictions Mean           1407.2874
Q Predictions Std            1346.8794
Q Predictions Max            4481.8667
Q Predictions Min            654.284
V Predictions Mean           1402.6877
V Predictions Std            1339.959
V Predictions Max            4457.3203
V Predictions Min            659.0607
Log Pis Mean                 -0.29728281
Log Pis Std                  3.7960358
Log Pis Max                  13.533589
Log Pis Min                  -8.252262
Policy mu Mean               -0.026726743
Policy mu Std                0.88632685
Policy mu Max                2.708605
Policy mu Min                -3.2168474
Policy log std Mean          -0.5095651
Policy log std Std           0.27818924
Policy log std Max           -0.0018121004
Policy log std Min           -2.2883432
Z mean eval                  1.8313675
Z variance eval              0.07746356
total_rewards                [ 9838.81789946  9850.49985032  9562.76617602  9785.03172767
  9922.33499537  9945.62468608  9931.15896608  9958.00504511
 10205.32443795  9784.17587104]
total_rewards_mean           9878.373965510118
total_rewards_std            155.5683733692212
total_rewards_max            10205.324437951118
total_rewards_min            9562.766176021874
Number of train steps total  1316000
Number of env steps total    3950000
Number of rollouts total     0
Train Time (s)               147.5890951338224
(Previous) Eval Time (s)     20.83732996881008
Sample Time (s)              6.566782809328288
Epoch Time (s)               174.99320791196078
Total Train Time (s)         56286.33895621169
Epoch                        328
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:31:45.552509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #328 | Epoch Duration: 175.07779264450073
2020-01-12 23:31:45.552643 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #328 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8293676
Z variance train             0.077918395
KL Divergence                46.89896
KL Loss                      4.689896
QF Loss                      138.33032
VF Loss                      128.92958
Policy Loss                  -1319.5686
Q Predictions Mean           1314.9475
Q Predictions Std            1260.4956
Q Predictions Max            4476.746
Q Predictions Min            639.8118
V Predictions Mean           1325.3961
V Predictions Std            1262.5817
V Predictions Max            4491.972
V Predictions Min            631.5764
Log Pis Mean                 0.08046979
Log Pis Std                  3.886015
Log Pis Max                  15.821927
Log Pis Min                  -7.590043
Policy mu Mean               0.09035381
Policy mu Std                0.8972683
Policy mu Max                4.14953
Policy mu Min                -3.5200028
Policy log std Mean          -0.54867506
Policy log std Std           0.31237826
Policy log std Max           -0.03648019
Policy log std Min           -2.7964916
Z mean eval                  1.8025023
Z variance eval              0.110143624
total_rewards                [ 9909.14046996 10338.47805041 10087.04965074 10208.8109192
  9973.00429657 10130.07544009 10150.05962816  9641.31886906
 10140.02985021  9621.06639731]
total_rewards_mean           10019.903357169329
total_rewards_std            224.06662362382178
total_rewards_max            10338.478050408634
total_rewards_min            9621.066397310584
Number of train steps total  1320000
Number of env steps total    3962000
Number of rollouts total     0
Train Time (s)               146.94836933119223
(Previous) Eval Time (s)     17.24934294912964
Sample Time (s)              6.405183338560164
Epoch Time (s)               170.60289561888203
Total Train Time (s)         56457.02025509672
Epoch                        329
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:34:36.237303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #329 | Epoch Duration: 170.68454885482788
2020-01-12 23:34:36.237476 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8021635
Z variance train             0.110085115
KL Divergence                46.6348
KL Loss                      4.6634803
QF Loss                      3838.9453
VF Loss                      60.507942
Policy Loss                  -1221.7848
Q Predictions Mean           1216.9954
Q Predictions Std            1161.827
Q Predictions Max            4548.9717
Q Predictions Min            519.55835
V Predictions Mean           1218.295
V Predictions Std            1161.3622
V Predictions Max            4540.39
V Predictions Min            526.74536
Log Pis Mean                 -0.5185359
Log Pis Std                  3.8059914
Log Pis Max                  12.619298
Log Pis Min                  -6.8114953
Policy mu Mean               0.07273104
Policy mu Std                0.83797127
Policy mu Max                3.2814226
Policy mu Min                -2.7174768
Policy log std Mean          -0.5144411
Policy log std Std           0.30123442
Policy log std Max           0.038885415
Policy log std Min           -2.8665273
Z mean eval                  1.8286982
Z variance eval              0.07674527
total_rewards                [9049.59526166 9527.78907598 9320.7703519  9524.09966737 9393.69055367
 9638.03030938 9565.3394443  9260.89437662 9318.62315743 9506.10269979]
total_rewards_mean           9410.493489810211
total_rewards_std            167.61747429416508
total_rewards_max            9638.030309378453
total_rewards_min            9049.595261660394
Number of train steps total  1324000
Number of env steps total    3974000
Number of rollouts total     0
Train Time (s)               146.55700511205941
(Previous) Eval Time (s)     20.7774381400086
Sample Time (s)              6.404016450513154
Epoch Time (s)               173.73845970258117
Total Train Time (s)         56630.84298846731
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:37:30.064240 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #330 | Epoch Duration: 173.82656383514404
2020-01-12 23:37:30.064531 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #330 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8327217
Z variance train             0.07668658
KL Divergence                47.327793
KL Loss                      4.7327795
QF Loss                      131.69771
VF Loss                      118.96875
Policy Loss                  -1238.0488
Q Predictions Mean           1235.5544
Q Predictions Std            1173.2623
Q Predictions Max            4517.8545
Q Predictions Min            652.6937
V Predictions Mean           1232.993
V Predictions Std            1166.9231
V Predictions Max            4506.5273
V Predictions Min            642.2624
Log Pis Mean                 -0.6541594
Log Pis Std                  3.5114238
Log Pis Max                  14.2097435
Log Pis Min                  -8.389521
Policy mu Mean               -0.008253339
Policy mu Std                0.8160523
Policy mu Max                2.4989476
Policy mu Min                -2.8821933
Policy log std Mean          -0.50788605
Policy log std Std           0.2767612
Policy log std Max           0.00046658516
Policy log std Min           -2.44751
Z mean eval                  1.8329633
Z variance eval              0.07045446
total_rewards                [ 9399.23851361 10194.91122584 10156.42956264  9849.88943468
  9927.27515143  9871.94254234  9801.21662823 10060.54163895
  9786.2688524  10018.52121967]
total_rewards_mean           9906.623476979918
total_rewards_std            216.7044445528123
total_rewards_max            10194.91122584031
total_rewards_min            9399.23851361444
Number of train steps total  1328000
Number of env steps total    3986000
Number of rollouts total     0
Train Time (s)               146.25544716976583
(Previous) Eval Time (s)     20.822639302816242
Sample Time (s)              6.446203996427357
Epoch Time (s)               173.52429046900943
Total Train Time (s)         56804.452338489704
Epoch                        331
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:40:23.674884 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #331 | Epoch Duration: 173.61017775535583
2020-01-12 23:40:23.675067 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #331 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8351854
Z variance train             0.07059305
KL Divergence                46.512833
KL Loss                      4.6512833
QF Loss                      241.54883
VF Loss                      36.29786
Policy Loss                  -1485.35
Q Predictions Mean           1481.7775
Q Predictions Std            1384.3191
Q Predictions Max            4472.8604
Q Predictions Min            656.1197
V Predictions Mean           1484.6603
V Predictions Std            1380.6879
V Predictions Max            4462.073
V Predictions Min            653.49884
Log Pis Mean                 -0.13280942
Log Pis Std                  3.8704088
Log Pis Max                  14.194908
Log Pis Min                  -5.9922967
Policy mu Mean               0.06215481
Policy mu Std                0.91108334
Policy mu Max                3.771106
Policy mu Min                -3.0158763
Policy log std Mean          -0.5221524
Policy log std Std           0.30045345
Policy log std Max           -0.09355542
Policy log std Min           -2.6785421
Z mean eval                  1.8152514
Z variance eval              0.074680954
total_rewards                [ 9963.77490107  9777.47015837  9964.98752385 10008.18482827
  9874.83367309  9843.0457182  10226.85463583  9677.31024158
 10123.99944561  9720.46463652]
total_rewards_mean           9918.092576239893
total_rewards_std            165.66388753727935
total_rewards_max            10226.854635834668
total_rewards_min            9677.310241581643
Number of train steps total  1332000
Number of env steps total    3998000
Number of rollouts total     0
Train Time (s)               147.5805674381554
(Previous) Eval Time (s)     20.908862388692796
Sample Time (s)              6.411856855265796
Epoch Time (s)               174.901286682114
Total Train Time (s)         56979.43693455914
Epoch                        332
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:43:18.662911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #332 | Epoch Duration: 174.98767066001892
2020-01-12 23:43:18.663145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8155787
Z variance train             0.074708626
KL Divergence                45.998295
KL Loss                      4.5998297
QF Loss                      4199.7236
VF Loss                      67.31695
Policy Loss                  -1139.9938
Q Predictions Mean           1137.4448
Q Predictions Std            1102.211
Q Predictions Max            4524.96
Q Predictions Min            663.6632
V Predictions Mean           1134.7856
V Predictions Std            1098.5431
V Predictions Max            4503.7886
V Predictions Min            659.7857
Log Pis Mean                 -0.95836425
Log Pis Std                  3.4024549
Log Pis Max                  12.790806
Log Pis Min                  -7.2361484
Policy mu Mean               0.05909562
Policy mu Std                0.8093788
Policy mu Max                2.4893606
Policy mu Min                -2.5540988
Policy log std Mean          -0.49387464
Policy log std Std           0.2612322
Policy log std Max           0.051922023
Policy log std Min           -2.625378
Z mean eval                  1.8061682
Z variance eval              0.09122591
total_rewards                [8656.18276164 9305.82778496 8930.2450811  9255.37823156 9185.96769367
 8978.52340445 9263.97839126 9063.84823882 9305.93179412 8970.64600582]
total_rewards_mean           9091.652938739786
total_rewards_std            200.27092675845572
total_rewards_max            9305.931794122962
total_rewards_min            8656.182761637829
Number of train steps total  1336000
Number of env steps total    4010000
Number of rollouts total     0
Train Time (s)               146.27871873276308
(Previous) Eval Time (s)     21.430413161870092
Sample Time (s)              6.606893048156053
Epoch Time (s)               174.31602494278923
Total Train Time (s)         57153.83585699415
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:46:13.063789 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #333 | Epoch Duration: 174.4005160331726
2020-01-12 23:46:13.063923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8060621
Z variance train             0.090751484
KL Divergence                43.99221
KL Loss                      4.399221
QF Loss                      189.6778
VF Loss                      225.8501
Policy Loss                  -1379.4615
Q Predictions Mean           1381.2661
Q Predictions Std            1322.3804
Q Predictions Max            4603.777
Q Predictions Min            679.93726
V Predictions Mean           1390.5798
V Predictions Std            1322.4695
V Predictions Max            4624.897
V Predictions Min            678.6757
Log Pis Mean                 -0.04936929
Log Pis Std                  4.065462
Log Pis Max                  14.215408
Log Pis Min                  -7.295275
Policy mu Mean               -0.023982817
Policy mu Std                0.89597714
Policy mu Max                2.9063976
Policy mu Min                -2.9195757
Policy log std Mean          -0.49305758
Policy log std Std           0.30590767
Policy log std Max           -0.013739824
Policy log std Min           -2.6469064
Z mean eval                  1.8217099
Z variance eval              0.0866249
total_rewards                [9580.36897603 9594.23251819 9605.31125362 9773.97632217 9496.26255874
 9665.75294844 9629.98851816 9721.04508397 9869.70411517 9507.01992551]
total_rewards_mean           9644.366222000903
total_rewards_std            110.9291345903558
total_rewards_max            9869.704115172895
total_rewards_min            9496.26255873641
Number of train steps total  1340000
Number of env steps total    4022000
Number of rollouts total     0
Train Time (s)               145.47550945496187
(Previous) Eval Time (s)     17.272665590047836
Sample Time (s)              6.3704776600934565
Epoch Time (s)               169.11865270510316
Total Train Time (s)         57323.03227137448
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:49:02.263382 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #334 | Epoch Duration: 169.19934558868408
2020-01-12 23:49:02.263566 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #334 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8212506
Z variance train             0.08680912
KL Divergence                44.48769
KL Loss                      4.448769
QF Loss                      2997.9644
VF Loss                      93.59709
Policy Loss                  -1387.5334
Q Predictions Mean           1386.2847
Q Predictions Std            1320.0217
Q Predictions Max            4632.7114
Q Predictions Min            662.24976
V Predictions Mean           1389.9861
V Predictions Std            1316.5831
V Predictions Max            4630.9185
V Predictions Min            665.3816
Log Pis Mean                 -0.08654553
Log Pis Std                  4.1824265
Log Pis Max                  19.767733
Log Pis Min                  -9.237613
Policy mu Mean               -0.016641228
Policy mu Std                0.90480673
Policy mu Max                3.6595688
Policy mu Min                -3.7621388
Policy log std Mean          -0.5036669
Policy log std Std           0.30933473
Policy log std Max           0.10315621
Policy log std Min           -2.5682952
Z mean eval                  1.8208838
Z variance eval              0.09730226
total_rewards                [10076.68707859  9842.32336811 10144.07154159  9807.73536395
 10094.99276842  9938.99162073 10109.12612744  9698.63475731
 10026.61918312  9779.66698719]
total_rewards_mean           9951.884879643836
total_rewards_std            151.67230023900407
total_rewards_max            10144.071541586107
total_rewards_min            9698.634757309357
Number of train steps total  1344000
Number of env steps total    4034000
Number of rollouts total     0
Train Time (s)               150.32923045614734
(Previous) Eval Time (s)     20.636019038967788
Sample Time (s)              6.561267789918929
Epoch Time (s)               177.52651728503406
Total Train Time (s)         57500.636335468385
Epoch                        335
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:51:59.869575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #335 | Epoch Duration: 177.605877161026
2020-01-12 23:51:59.869716 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #335 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8201965
Z variance train             0.09715905
KL Divergence                45.08085
KL Loss                      4.508085
QF Loss                      3876.1233
VF Loss                      54.064537
Policy Loss                  -1275.8412
Q Predictions Mean           1273.0046
Q Predictions Std            1224.116
Q Predictions Max            4494.3647
Q Predictions Min            640.3293
V Predictions Mean           1276.7845
V Predictions Std            1222.8495
V Predictions Max            4481.308
V Predictions Min            635.97455
Log Pis Mean                 -0.3021875
Log Pis Std                  3.926213
Log Pis Max                  13.239311
Log Pis Min                  -6.6824846
Policy mu Mean               -0.0022186302
Policy mu Std                0.8739285
Policy mu Max                2.9330559
Policy mu Min                -2.74411
Policy log std Mean          -0.50017446
Policy log std Std           0.29791358
Policy log std Max           0.046095908
Policy log std Min           -2.6930082
Z mean eval                  1.8246889
Z variance eval              0.07085391
total_rewards                [ 9730.15613255  9812.13415365  9857.57735841 10323.45587015
 10065.36047988 10176.73462023 10126.22136555  9812.27137845
  9922.87451305 10046.41530766]
total_rewards_mean           9987.320117959995
total_rewards_std            180.60817036202104
total_rewards_max            10323.455870148886
total_rewards_min            9730.156132553591
Number of train steps total  1348000
Number of env steps total    4046000
Number of rollouts total     0
Train Time (s)               145.4739891490899
(Previous) Eval Time (s)     20.769424594007432
Sample Time (s)              6.486803446430713
Epoch Time (s)               172.73021718952805
Total Train Time (s)         57673.643714384176
Epoch                        336
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:54:52.884071 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #336 | Epoch Duration: 173.014244556427
2020-01-12 23:54:52.884253 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #336 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.824501
Z variance train             0.07071011
KL Divergence                45.61443
KL Loss                      4.561443
QF Loss                      85.25052
VF Loss                      48.875824
Policy Loss                  -1370.4395
Q Predictions Mean           1368.4302
Q Predictions Std            1328.7148
Q Predictions Max            4577.7383
Q Predictions Min            669.1449
V Predictions Mean           1371.7151
V Predictions Std            1328.5729
V Predictions Max            4549.5093
V Predictions Min            672.7522
Log Pis Mean                 -0.400388
Log Pis Std                  3.6268806
Log Pis Max                  12.760285
Log Pis Min                  -6.7662034
Policy mu Mean               -0.0032765232
Policy mu Std                0.8468688
Policy mu Max                3.3513446
Policy mu Min                -2.7041373
Policy log std Mean          -0.5001902
Policy log std Std           0.27603158
Policy log std Max           0.05202961
Policy log std Min           -2.622629
Z mean eval                  1.8296293
Z variance eval              0.094293915
total_rewards                [ 9631.65818954  9928.71277106  9845.66783413 10031.04288806
 10065.93011192  9775.85204384 10113.9492131   9946.52752081
 10057.86276787  9785.65739573]
total_rewards_mean           9918.286073606843
total_rewards_std            147.81462918669575
total_rewards_max            10113.949213101807
total_rewards_min            9631.658189540587
Number of train steps total  1352000
Number of env steps total    4058000
Number of rollouts total     0
Train Time (s)               148.26231301994994
(Previous) Eval Time (s)     20.64838545070961
Sample Time (s)              6.387514457572252
Epoch Time (s)               175.2982129282318
Total Train Time (s)         57849.02417322993
Epoch                        337
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:57:48.268345 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #337 | Epoch Duration: 175.38394713401794
2020-01-12 23:57:48.268534 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #337 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8250828
Z variance train             0.094017506
KL Divergence                44.817734
KL Loss                      4.4817734
QF Loss                      4183.844
VF Loss                      72.870056
Policy Loss                  -1231.5205
Q Predictions Mean           1232.4106
Q Predictions Std            1214.4067
Q Predictions Max            4522.7876
Q Predictions Min            658.5801
V Predictions Mean           1236.3867
V Predictions Std            1213.8818
V Predictions Max            4519.9517
V Predictions Min            654.58514
Log Pis Mean                 -0.69964486
Log Pis Std                  3.683207
Log Pis Max                  14.469589
Log Pis Min                  -7.6673164
Policy mu Mean               0.039348017
Policy mu Std                0.8262759
Policy mu Max                2.5949953
Policy mu Min                -2.9042504
Policy log std Mean          -0.48851028
Policy log std Std           0.2957867
Policy log std Max           0.16578472
Policy log std Min           -2.82328
Z mean eval                  1.8247025
Z variance eval              0.062182963
total_rewards                [ 9539.86456534  9697.00914038  9626.64320358  9529.56695084
 10016.31351664  9869.92514756  9563.22733402  9802.43377464
  9701.08057946  9410.98855929]
total_rewards_mean           9675.705277176205
total_rewards_std            171.9987291747585
total_rewards_max            10016.313516643248
total_rewards_min            9410.98855929051
Number of train steps total  1356000
Number of env steps total    4070000
Number of rollouts total     0
Train Time (s)               147.1937460140325
(Previous) Eval Time (s)     20.916537881828845
Sample Time (s)              6.33578815497458
Epoch Time (s)               174.44607205083594
Total Train Time (s)         58023.614666817244
Epoch                        338
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:00:42.861713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #338 | Epoch Duration: 174.59305262565613
2020-01-13 00:00:42.861861 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8255999
Z variance train             0.0622875
KL Divergence                45.940117
KL Loss                      4.594012
QF Loss                      1009.62006
VF Loss                      67.70579
Policy Loss                  -1332.5548
Q Predictions Mean           1329.6956
Q Predictions Std            1272.8235
Q Predictions Max            4699.8286
Q Predictions Min            647.429
V Predictions Mean           1332.437
V Predictions Std            1270.4755
V Predictions Max            4676.386
V Predictions Min            672.6284
Log Pis Mean                 -0.11108866
Log Pis Std                  3.7952259
Log Pis Max                  20.280216
Log Pis Min                  -5.350403
Policy mu Mean               0.021614274
Policy mu Std                0.88503253
Policy mu Max                5.219601
Policy mu Min                -2.9790115
Policy log std Mean          -0.5124027
Policy log std Std           0.2880978
Policy log std Max           0.037814856
Policy log std Min           -2.7916653
Z mean eval                  1.8409512
Z variance eval              0.06553675
total_rewards                [9624.70690371 9884.88730146 9916.69437527 9872.98334827 9952.02085798
 9862.52642801 9925.1325537  9872.14114155 9627.83233539 9877.86008259]
total_rewards_mean           9841.678532792164
total_rewards_std            110.94726761029656
total_rewards_max            9952.020857981466
total_rewards_min            9624.70690370725
Number of train steps total  1360000
Number of env steps total    4082000
Number of rollouts total     0
Train Time (s)               147.41266050515696
(Previous) Eval Time (s)     17.556980613153428
Sample Time (s)              6.339962052181363
Epoch Time (s)               171.30960317049176
Total Train Time (s)         58194.998364359606
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:03:34.248746 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #339 | Epoch Duration: 171.3867838382721
2020-01-13 00:03:34.248865 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8405278
Z variance train             0.065351084
KL Divergence                46.034184
KL Loss                      4.6034184
QF Loss                      138.38667
VF Loss                      70.109726
Policy Loss                  -1401.8776
Q Predictions Mean           1400.2915
Q Predictions Std            1347.1049
Q Predictions Max            4559.214
Q Predictions Min            650.71814
V Predictions Mean           1396.9766
V Predictions Std            1342.2205
V Predictions Max            4536.4253
V Predictions Min            655.40533
Log Pis Mean                 -0.23670647
Log Pis Std                  4.1280675
Log Pis Max                  15.618782
Log Pis Min                  -8.191832
Policy mu Mean               0.065535516
Policy mu Std                0.8892071
Policy mu Max                2.897707
Policy mu Min                -3.1344872
Policy log std Mean          -0.5033185
Policy log std Std           0.30009052
Policy log std Max           0.14634961
Policy log std Min           -2.7476664
Z mean eval                  1.8498852
Z variance eval              0.07301996
total_rewards                [8023.06173584 8156.78576302 8288.87301534 8330.54136651 8104.12629644
 8371.20349841 8174.80098978 8153.93947439 8255.33552314 8419.98045885]
total_rewards_mean           8227.864812170876
total_rewards_std            119.60852506659585
total_rewards_max            8419.980458845694
total_rewards_min            8023.061735839242
Number of train steps total  1364000
Number of env steps total    4094000
Number of rollouts total     0
Train Time (s)               146.22127603320405
(Previous) Eval Time (s)     20.8803131300956
Sample Time (s)              8.344155779574066
Epoch Time (s)               175.44574494287372
Total Train Time (s)         58370.52180456743
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:06:29.774582 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #340 | Epoch Duration: 175.52561902999878
2020-01-13 00:06:29.774756 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.852677
Z variance train             0.07317206
KL Divergence                46.112698
KL Loss                      4.61127
QF Loss                      221.73683
VF Loss                      47.9816
Policy Loss                  -1299.4442
Q Predictions Mean           1295.6025
Q Predictions Std            1249.2568
Q Predictions Max            4577.008
Q Predictions Min            661.2148
V Predictions Mean           1297.1434
V Predictions Std            1245.9032
V Predictions Max            4561.2017
V Predictions Min            674.25726
Log Pis Mean                 -0.38822836
Log Pis Std                  3.896987
Log Pis Max                  15.256684
Log Pis Min                  -7.558311
Policy mu Mean               -0.011467062
Policy mu Std                0.86836106
Policy mu Max                2.660948
Policy mu Min                -2.9300728
Policy log std Mean          -0.50153524
Policy log std Std           0.29677328
Policy log std Max           -0.05904159
Policy log std Min           -2.5435028
Z mean eval                  1.8404335
Z variance eval              0.11922457
total_rewards                [ 9949.17734456  9749.32314102  9965.42005497  9922.84195161
 10090.88565048 10042.02506564  9715.36662084  9884.44602747
  9915.32501267  9990.74855602]
total_rewards_mean           9922.555942527808
total_rewards_std            111.4655902011986
total_rewards_max            10090.885650483751
total_rewards_min            9715.366620836106
Number of train steps total  1368000
Number of env steps total    4106000
Number of rollouts total     0
Train Time (s)               148.3010449227877
(Previous) Eval Time (s)     20.393329040147364
Sample Time (s)              6.4877264546230435
Epoch Time (s)               175.1821004175581
Total Train Time (s)         58545.78569179773
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:09:25.045006 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #341 | Epoch Duration: 175.2701325416565
2020-01-13 00:09:25.045171 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8391638
Z variance train             0.1193429
KL Divergence                45.02854
KL Loss                      4.5028543
QF Loss                      4055.372
VF Loss                      72.47125
Policy Loss                  -1606.7693
Q Predictions Mean           1604.4607
Q Predictions Std            1460.5403
Q Predictions Max            4598.351
Q Predictions Min            657.5799
V Predictions Mean           1609.1652
V Predictions Std            1458.1654
V Predictions Max            4597.1987
V Predictions Min            663.2641
Log Pis Mean                 -0.00095997006
Log Pis Std                  4.153386
Log Pis Max                  16.298584
Log Pis Min                  -7.849018
Policy mu Mean               -0.056151617
Policy mu Std                0.9105393
Policy mu Max                2.6859853
Policy mu Min                -2.9017134
Policy log std Mean          -0.53383493
Policy log std Std           0.31036174
Policy log std Max           0.19569308
Policy log std Min           -2.6190486
Z mean eval                  1.8432564
Z variance eval              0.069820076
total_rewards                [ 9739.77145273  9634.20961977 10036.87528429  9630.93634981
  9791.43967253  9562.07171998  9804.04636005  9821.64637661
  9862.06044876  9856.17183853]
total_rewards_mean           9773.92291230462
total_rewards_std            131.59827514617575
total_rewards_max            10036.875284287935
total_rewards_min            9562.071719977088
Number of train steps total  1372000
Number of env steps total    4118000
Number of rollouts total     0
Train Time (s)               146.87822971399873
(Previous) Eval Time (s)     18.241755773779005
Sample Time (s)              6.427176746539772
Epoch Time (s)               171.5471622343175
Total Train Time (s)         58717.42795168236
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:12:16.691863 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #342 | Epoch Duration: 171.6465549468994
2020-01-13 00:12:16.692070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #342 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8436859
Z variance train             0.06977452
KL Divergence                47.05431
KL Loss                      4.705431
QF Loss                      216.69626
VF Loss                      33.445423
Policy Loss                  -1271.9297
Q Predictions Mean           1268.6332
Q Predictions Std            1242.551
Q Predictions Max            4512.7534
Q Predictions Min            650.5856
V Predictions Mean           1271.3823
V Predictions Std            1240.1438
V Predictions Max            4501.913
V Predictions Min            659.3523
Log Pis Mean                 -0.7987901
Log Pis Std                  3.4466445
Log Pis Max                  11.477796
Log Pis Min                  -6.851809
Policy mu Mean               -0.008658107
Policy mu Std                0.8267645
Policy mu Max                2.8384542
Policy mu Min                -2.871006
Policy log std Mean          -0.48863062
Policy log std Std           0.28352392
Policy log std Max           0.005528748
Policy log std Min           -2.7160075
Z mean eval                  1.8291639
Z variance eval              0.10008357
total_rewards                [ 9918.42413959 10198.88004905 10074.01287068  9736.97627757
 10131.57418062  9895.28044424  9968.31054893 10008.13868258
  9970.85469948  9993.90350788]
total_rewards_mean           9989.635540061408
total_rewards_std            122.48595176056602
total_rewards_max            10198.880049045581
total_rewards_min            9736.976277569733
Number of train steps total  1376000
Number of env steps total    4130000
Number of rollouts total     0
Train Time (s)               146.69321072567254
(Previous) Eval Time (s)     20.772946750279516
Sample Time (s)              6.493485406041145
Epoch Time (s)               173.9596428819932
Total Train Time (s)         58891.47322723316
Epoch                        343
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:15:10.739983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #343 | Epoch Duration: 174.047771692276
2020-01-13 00:15:10.740114 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8286438
Z variance train             0.10022275
KL Divergence                46.168427
KL Loss                      4.6168427
QF Loss                      189.30765
VF Loss                      56.32193
Policy Loss                  -1362.183
Q Predictions Mean           1360.7943
Q Predictions Std            1323.7476
Q Predictions Max            4488.953
Q Predictions Min            674.7807
V Predictions Mean           1364.8024
V Predictions Std            1321.1168
V Predictions Max            4502.7417
V Predictions Min            660.0426
Log Pis Mean                 -0.15203883
Log Pis Std                  3.9195986
Log Pis Max                  16.629911
Log Pis Min                  -7.454934
Policy mu Mean               0.02080444
Policy mu Std                0.90160733
Policy mu Max                3.1080942
Policy mu Min                -3.4374814
Policy log std Mean          -0.5110834
Policy log std Std           0.30277073
Policy log std Max           -0.042701185
Policy log std Min           -2.8012547
Z mean eval                  1.833217
Z variance eval              0.093521655
total_rewards                [9256.60445543 9246.75927937 9640.34548032 9391.84179435 9391.94449892
 9265.15321437 9375.99236938 9342.3712048  9525.39571121 9264.99054682]
total_rewards_mean           9370.139855497135
total_rewards_std            122.08966069483756
total_rewards_max            9640.345480315169
total_rewards_min            9246.759279371354
Number of train steps total  1380000
Number of env steps total    4142000
Number of rollouts total     0
Train Time (s)               146.74374176608399
(Previous) Eval Time (s)     17.42936285911128
Sample Time (s)              6.314222876448184
Epoch Time (s)               170.48732750164345
Total Train Time (s)         59062.28018979821
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:18:01.569327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #344 | Epoch Duration: 170.82907724380493
2020-01-13 00:18:01.569579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8334459
Z variance train             0.09328767
KL Divergence                46.81523
KL Loss                      4.6815233
QF Loss                      121.86545
VF Loss                      60.815144
Policy Loss                  -1323.2635
Q Predictions Mean           1318.1304
Q Predictions Std            1193.3145
Q Predictions Max            4491.0635
Q Predictions Min            678.69885
V Predictions Mean           1325.1672
V Predictions Std            1191.5223
V Predictions Max            4475.6978
V Predictions Min            678.47534
Log Pis Mean                 -0.36271286
Log Pis Std                  3.7822237
Log Pis Max                  19.356867
Log Pis Min                  -6.2234683
Policy mu Mean               -0.03377303
Policy mu Std                0.8807373
Policy mu Max                3.0925176
Policy mu Min                -4.3731294
Policy log std Mean          -0.5054669
Policy log std Std           0.2856803
Policy log std Max           0.48508108
Policy log std Min           -2.4486349
Z mean eval                  1.8328295
Z variance eval              0.0922366
total_rewards                [9736.86242955 9878.57574357 9904.59337075 9699.81917271 9730.37970448
 9722.66113182 9864.93294729 9855.3821113  9746.37018483 9875.98186864]
total_rewards_mean           9801.555866492736
total_rewards_std            76.0745804122873
total_rewards_max            9904.593370746583
total_rewards_min            9699.81917270711
Number of train steps total  1384000
Number of env steps total    4154000
Number of rollouts total     0
Train Time (s)               146.60409619892016
(Previous) Eval Time (s)     20.888385785743594
Sample Time (s)              6.488904841244221
Epoch Time (s)               173.98138682590798
Total Train Time (s)         59236.375948396046
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:20:55.649698 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #345 | Epoch Duration: 174.07993912696838
2020-01-13 00:20:55.649839 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8321819
Z variance train             0.092349485
KL Divergence                46.684517
KL Loss                      4.668452
QF Loss                      169.61911
VF Loss                      57.880905
Policy Loss                  -1352.8619
Q Predictions Mean           1348.4375
Q Predictions Std            1304.598
Q Predictions Max            4542.7603
Q Predictions Min            681.9153
V Predictions Mean           1353.8079
V Predictions Std            1300.7972
V Predictions Max            4522.7026
V Predictions Min            679.6164
Log Pis Mean                 -0.39963818
Log Pis Std                  4.2549896
Log Pis Max                  19.321692
Log Pis Min                  -8.390442
Policy mu Mean               0.015077568
Policy mu Std                0.8698117
Policy mu Max                3.1122491
Policy mu Min                -3.1848516
Policy log std Mean          -0.48184335
Policy log std Std           0.2779943
Policy log std Max           0.078504264
Policy log std Min           -2.5302434
Z mean eval                  1.8561354
Z variance eval              0.082350455
total_rewards                [10048.48832518 10088.67384354 10421.99805828  9844.36663651
 10063.9817483  10402.79759365 10108.34191363 10403.22093857
  9862.44634161 10388.49198999]
total_rewards_mean           10163.28073892526
total_rewards_std            213.6408136376865
total_rewards_max            10421.998058275145
total_rewards_min            9844.366636511548
Number of train steps total  1388000
Number of env steps total    4166000
Number of rollouts total     0
Train Time (s)               147.08229421125725
(Previous) Eval Time (s)     20.716909378767014
Sample Time (s)              6.587531710974872
Epoch Time (s)               174.38673530099913
Total Train Time (s)         59410.84829856083
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:23:50.125172 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #346 | Epoch Duration: 174.4752335548401
2020-01-13 00:23:50.125306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #346 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8578688
Z variance train             0.08221245
KL Divergence                47.59751
KL Loss                      4.7597513
QF Loss                      221.94824
VF Loss                      143.76259
Policy Loss                  -1492.6504
Q Predictions Mean           1485.0426
Q Predictions Std            1366.2386
Q Predictions Max            4558.7456
Q Predictions Min            668.2183
V Predictions Mean           1487.175
V Predictions Std            1357.773
V Predictions Max            4521.3438
V Predictions Min            700.5715
Log Pis Mean                 0.17247921
Log Pis Std                  4.612528
Log Pis Max                  18.49457
Log Pis Min                  -7.9665833
Policy mu Mean               0.08923557
Policy mu Std                0.93457013
Policy mu Max                3.3448257
Policy mu Min                -3.331242
Policy log std Mean          -0.5322592
Policy log std Std           0.32736325
Policy log std Max           0.054721594
Policy log std Min           -2.793089
Z mean eval                  1.8566797
Z variance eval              0.13749304
total_rewards                [ 9789.68933703  9669.31464109 10171.33931157 10157.0955964
  9833.07937579  9939.17239313  9860.84328966  9798.09725865
  9935.32733124 10105.55670162]
total_rewards_mean           9925.951523618442
total_rewards_std            161.1844812601454
total_rewards_max            10171.3393115735
total_rewards_min            9669.314641091987
Number of train steps total  1392000
Number of env steps total    4178000
Number of rollouts total     0
Train Time (s)               146.39732149569318
(Previous) Eval Time (s)     17.516058631706983
Sample Time (s)              6.571978659834713
Epoch Time (s)               170.48535878723487
Total Train Time (s)         59581.41064221552
Epoch                        347
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:26:40.689612 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #347 | Epoch Duration: 170.56421089172363
2020-01-13 00:26:40.689729 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #347 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8562987
Z variance train             0.13777256
KL Divergence                47.027695
KL Loss                      4.7027698
QF Loss                      139.17206
VF Loss                      61.147087
Policy Loss                  -1377.6332
Q Predictions Mean           1372.8462
Q Predictions Std            1276.6189
Q Predictions Max            4536.1426
Q Predictions Min            676.6622
V Predictions Mean           1378.5878
V Predictions Std            1278.0819
V Predictions Max            4529.1567
V Predictions Min            678.01465
Log Pis Mean                 -0.21583363
Log Pis Std                  3.905712
Log Pis Max                  16.519909
Log Pis Min                  -7.9273834
Policy mu Mean               0.0069204415
Policy mu Std                0.90333414
Policy mu Max                3.944686
Policy mu Min                -2.9716158
Policy log std Mean          -0.50323313
Policy log std Std           0.30059195
Policy log std Max           0.16491002
Policy log std Min           -2.562983
Z mean eval                  1.8476801
Z variance eval              0.08796762
total_rewards                [ 9893.6326677  10314.17808352 10074.3805561   9897.14385363
  9928.25860642 10027.88660459 10043.41771597  9896.35844381
 10101.21600856  9848.60103678]
total_rewards_mean           10002.507357708011
total_rewards_std            133.33729787174616
total_rewards_max            10314.178083517045
total_rewards_min            9848.601036783615
Number of train steps total  1396000
Number of env steps total    4190000
Number of rollouts total     0
Train Time (s)               144.3998355390504
(Previous) Eval Time (s)     20.72651378484443
Sample Time (s)              5.65494659403339
Epoch Time (s)               170.78129591792822
Total Train Time (s)         59752.27984481864
Epoch                        348
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:29:31.561868 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #348 | Epoch Duration: 170.87204551696777
2020-01-13 00:29:31.562000 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #348 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.847317
Z variance train             0.0878471
KL Divergence                48.395638
KL Loss                      4.839564
QF Loss                      364.64505
VF Loss                      36.31974
Policy Loss                  -1256.8934
Q Predictions Mean           1255.617
Q Predictions Std            1194.6049
Q Predictions Max            4570.4443
Q Predictions Min            688.3916
V Predictions Mean           1257.1515
V Predictions Std            1188.8682
V Predictions Max            4552.7935
V Predictions Min            692.2869
Log Pis Mean                 -0.7506112
Log Pis Std                  3.6249874
Log Pis Max                  14.195293
Log Pis Min                  -10.3397455
Policy mu Mean               0.0717719
Policy mu Std                0.83563757
Policy mu Max                3.0358732
Policy mu Min                -3.126992
Policy log std Mean          -0.48148933
Policy log std Std           0.2722331
Policy log std Max           0.01765585
Policy log std Min           -2.6362927
Z mean eval                  1.8624494
Z variance eval              0.06141011
total_rewards                [ 9881.43255477 10171.29720186  9772.88319347 10010.63195647
 10057.95672567  9826.93811936 10179.25716946  9851.81571753
 10115.16513393  9874.61113506]
total_rewards_mean           9974.198890757221
total_rewards_std            143.11728296888913
total_rewards_max            10179.25716946413
total_rewards_min            9772.883193465861
Number of train steps total  1400000
Number of env steps total    4202000
Number of rollouts total     0
Train Time (s)               145.86519985971972
(Previous) Eval Time (s)     20.902857689652592
Sample Time (s)              6.479375948663801
Epoch Time (s)               173.24743349803612
Total Train Time (s)         59925.61039251974
Epoch                        349
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:32:24.893986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #349 | Epoch Duration: 173.33189129829407
2020-01-13 00:32:24.894119 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #349 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8612331
Z variance train             0.0613809
KL Divergence                48.939754
KL Loss                      4.8939757
QF Loss                      201.48355
VF Loss                      169.38062
Policy Loss                  -1380.9829
Q Predictions Mean           1379.2739
Q Predictions Std            1312.5623
Q Predictions Max            4607.2163
Q Predictions Min            681.7146
V Predictions Mean           1389.8884
V Predictions Std            1315.8057
V Predictions Max            4635.7124
V Predictions Min            695.2076
Log Pis Mean                 -0.12871502
Log Pis Std                  3.897133
Log Pis Max                  14.942531
Log Pis Min                  -7.6354218
Policy mu Mean               0.07304492
Policy mu Std                0.91413623
Policy mu Max                3.0418255
Policy mu Min                -2.800838
Policy log std Mean          -0.51091576
Policy log std Std           0.2985345
Policy log std Max           0.04423046
Policy log std Min           -2.7122142
Z mean eval                  1.849289
Z variance eval              0.07283457
total_rewards                [ 9575.07457336  9911.81803409  9764.07129512 10263.62059012
 10031.05259721 10091.10105023  9978.61951248 10189.22572734
 10232.19481941 10036.07713881]
total_rewards_mean           10007.285533816232
total_rewards_std            203.39818509340697
total_rewards_max            10263.620590121665
total_rewards_min            9575.074573362768
Number of train steps total  1404000
Number of env steps total    4214000
Number of rollouts total     0
Train Time (s)               146.51579332724214
(Previous) Eval Time (s)     20.802566334605217
Sample Time (s)              6.556663405150175
Epoch Time (s)               173.87502306699753
Total Train Time (s)         60099.566186717246
Epoch                        350
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:35:18.853347 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #350 | Epoch Duration: 173.9591302871704
2020-01-13 00:35:18.853479 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #350 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8497334
Z variance train             0.072962254
KL Divergence                49.548218
KL Loss                      4.954822
QF Loss                      175.31404
VF Loss                      74.50957
Policy Loss                  -1515.1267
Q Predictions Mean           1512.0448
Q Predictions Std            1375.5514
Q Predictions Max            4550.8916
Q Predictions Min            685.2018
V Predictions Mean           1518.4492
V Predictions Std            1375.366
V Predictions Max            4551.167
V Predictions Min            687.09033
Log Pis Mean                 0.45178097
Log Pis Std                  4.450904
Log Pis Max                  18.46
Log Pis Min                  -6.643337
Policy mu Mean               0.02468059
Policy mu Std                0.9767721
Policy mu Max                3.108381
Policy mu Min                -3.3104708
Policy log std Mean          -0.5204467
Policy log std Std           0.30388638
Policy log std Max           -0.044879615
Policy log std Min           -2.8399036
Z mean eval                  1.8619545
Z variance eval              0.07303933
total_rewards                [ 9979.10349783 10264.60921311  9662.38602866 10071.94888796
 10076.36003757 10059.36458107  9989.6812923  10184.77317964
 10163.29496566 10095.15153305]
total_rewards_mean           10054.66732168357
total_rewards_std            154.61275739747015
total_rewards_max            10264.6092131054
total_rewards_min            9662.386028659937
Number of train steps total  1408000
Number of env steps total    4226000
Number of rollouts total     0
Train Time (s)               149.47894290694967
(Previous) Eval Time (s)     20.69077391922474
Sample Time (s)              6.454261219128966
Epoch Time (s)               176.62397804530337
Total Train Time (s)         60276.27410187572
Epoch                        351
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:38:15.564746 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #351 | Epoch Duration: 176.71116828918457
2020-01-13 00:38:15.564888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #351 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8631217
Z variance train             0.073069274
KL Divergence                49.00699
KL Loss                      4.900699
QF Loss                      142.3876
VF Loss                      73.71319
Policy Loss                  -1366.8645
Q Predictions Mean           1363.7317
Q Predictions Std            1278.6663
Q Predictions Max            4601.0967
Q Predictions Min            687.04645
V Predictions Mean           1365.3843
V Predictions Std            1273.3303
V Predictions Max            4593.2095
V Predictions Min            692.2533
Log Pis Mean                 -0.08354321
Log Pis Std                  4.1205335
Log Pis Max                  17.510796
Log Pis Min                  -8.025678
Policy mu Mean               0.083417766
Policy mu Std                0.9105896
Policy mu Max                3.5714743
Policy mu Min                -3.2962334
Policy log std Mean          -0.52076554
Policy log std Std           0.30777198
Policy log std Max           0.013059527
Policy log std Min           -2.819493
Z mean eval                  1.8504517
Z variance eval              0.07553662
total_rewards                [ 9692.10201096  9969.87007202  9715.89969848  9815.3044551
  9739.58471661  9613.31581595 10017.35727552  9919.87746519
  9818.65449238  9796.29686839]
total_rewards_mean           9809.826287058997
total_rewards_std            121.37414530727435
total_rewards_max            10017.35727552313
total_rewards_min            9613.31581595248
Number of train steps total  1412000
Number of env steps total    4238000
Number of rollouts total     0
Train Time (s)               146.28346044383943
(Previous) Eval Time (s)     20.740760545246303
Sample Time (s)              6.457725353073329
Epoch Time (s)               173.48194634215906
Total Train Time (s)         60449.85863009794
Epoch                        352
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:41:09.159346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #352 | Epoch Duration: 173.5943579673767
2020-01-13 00:41:09.159484 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #352 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8483646
Z variance train             0.07544076
KL Divergence                47.94437
KL Loss                      4.794437
QF Loss                      122.53633
VF Loss                      91.2699
Policy Loss                  -1531.867
Q Predictions Mean           1531.8639
Q Predictions Std            1408.1052
Q Predictions Max            4578.7666
Q Predictions Min            682.3524
V Predictions Mean           1526.6578
V Predictions Std            1399.3855
V Predictions Max            4558.5127
V Predictions Min            678.58826
Log Pis Mean                 0.080535874
Log Pis Std                  3.8680766
Log Pis Max                  14.609116
Log Pis Min                  -7.5763226
Policy mu Mean               0.016443362
Policy mu Std                0.9041299
Policy mu Max                2.6854074
Policy mu Min                -2.6100526
Policy log std Mean          -0.52228695
Policy log std Std           0.3077607
Policy log std Max           -0.018633366
Policy log std Min           -2.866218
Z mean eval                  1.8480438
Z variance eval              0.10293715
total_rewards                [ 9749.29482221 10152.89426882 10029.66766913  9801.08822929
  9926.55501404 10303.59222372 10051.18159903 10277.44994168
  9759.82820295 10214.72483577]
total_rewards_mean           10026.627680664235
total_rewards_std            200.13374294095095
total_rewards_max            10303.592223724412
total_rewards_min            9749.294822207728
Number of train steps total  1416000
Number of env steps total    4250000
Number of rollouts total     0
Train Time (s)               147.1821274808608
(Previous) Eval Time (s)     20.9338300623931
Sample Time (s)              6.5439105136319995
Epoch Time (s)               174.6598680568859
Total Train Time (s)         60624.602142375894
Epoch                        353
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:44:03.903043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #353 | Epoch Duration: 174.74346256256104
2020-01-13 00:44:03.903178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #353 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.848726
Z variance train             0.10251161
KL Divergence                47.63917
KL Loss                      4.7639174
QF Loss                      178.12326
VF Loss                      95.31075
Policy Loss                  -1442.6187
Q Predictions Mean           1439.0608
Q Predictions Std            1351.3805
Q Predictions Max            4561.414
Q Predictions Min            665.60114
V Predictions Mean           1438.8865
V Predictions Std            1350.205
V Predictions Max            4562.9106
V Predictions Min            689.83905
Log Pis Mean                 0.27439058
Log Pis Std                  4.2074466
Log Pis Max                  18.740677
Log Pis Min                  -8.208524
Policy mu Mean               0.11083261
Policy mu Std                0.9305595
Policy mu Max                3.0914378
Policy mu Min                -3.489496
Policy log std Mean          -0.5177876
Policy log std Std           0.29663217
Policy log std Max           0.11405349
Policy log std Min           -2.904211
Z mean eval                  1.881594
Z variance eval              0.06506904
total_rewards                [ 9775.58560389  9946.42181755 10018.1874166   9569.40172085
  9851.79930825 10098.20192068  9980.370648    9840.53365642
 10021.8291443   9954.22374534]
total_rewards_mean           9905.655498187816
total_rewards_std            144.90104147726095
total_rewards_max            10098.20192068184
total_rewards_min            9569.401720847662
Number of train steps total  1420000
Number of env steps total    4262000
Number of rollouts total     0
Train Time (s)               146.25058292178437
(Previous) Eval Time (s)     20.748722524847835
Sample Time (s)              6.500010514631867
Epoch Time (s)               173.49931596126407
Total Train Time (s)         60798.182764337864
Epoch                        354
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:46:57.485258 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #354 | Epoch Duration: 173.58198308944702
2020-01-13 00:46:57.485392 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #354 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.881538
Z variance train             0.06492968
KL Divergence                49.040997
KL Loss                      4.9041
QF Loss                      124.8899
VF Loss                      173.06395
Policy Loss                  -1229.473
Q Predictions Mean           1225.2249
Q Predictions Std            1172.5316
Q Predictions Max            4591.919
Q Predictions Min            655.1089
V Predictions Mean           1228.7463
V Predictions Std            1170.1934
V Predictions Max            4561.577
V Predictions Min            697.51636
Log Pis Mean                 -0.36916476
Log Pis Std                  3.876764
Log Pis Max                  18.25143
Log Pis Min                  -6.772699
Policy mu Mean               0.058277216
Policy mu Std                0.86661
Policy mu Max                3.0480905
Policy mu Min                -4.089854
Policy log std Mean          -0.52049613
Policy log std Std           0.29545557
Policy log std Max           -0.06434187
Policy log std Min           -2.8631225
Z mean eval                  1.8537203
Z variance eval              0.06058227
total_rewards                [ 9892.78693415  9750.10655888 10007.58970216 10324.3781215
 10204.16504838 10063.0023127  10169.78499054  9883.53248682
 10218.18426989 10045.08894906]
total_rewards_mean           10055.861937407806
total_rewards_std            169.0255170560671
total_rewards_max            10324.378121500093
total_rewards_min            9750.10655887887
Number of train steps total  1424000
Number of env steps total    4274000
Number of rollouts total     0
Train Time (s)               147.11119894869626
(Previous) Eval Time (s)     19.31167462375015
Sample Time (s)              6.345767810475081
Epoch Time (s)               172.7686413829215
Total Train Time (s)         60971.03306262847
Epoch                        355
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:49:50.341769 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #355 | Epoch Duration: 172.85626339912415
2020-01-13 00:49:50.341960 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #355 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8537728
Z variance train             0.06055795
KL Divergence                48.08824
KL Loss                      4.808824
QF Loss                      167.72624
VF Loss                      103.606026
Policy Loss                  -1349.9442
Q Predictions Mean           1347.8163
Q Predictions Std            1270.4658
Q Predictions Max            4644.329
Q Predictions Min            701.39075
V Predictions Mean           1347.0519
V Predictions Std            1269.458
V Predictions Max            4650.618
V Predictions Min            703.61804
Log Pis Mean                 -0.5167564
Log Pis Std                  3.748653
Log Pis Max                  18.7029
Log Pis Min                  -7.2248955
Policy mu Mean               0.03163379
Policy mu Std                0.8548907
Policy mu Max                3.020635
Policy mu Min                -2.6186583
Policy log std Mean          -0.50243783
Policy log std Std           0.2804168
Policy log std Max           0.075195074
Policy log std Min           -2.5525265
Z mean eval                  1.8609943
Z variance eval              0.07598624
total_rewards                [ 9635.35765255  9945.89512493 10219.18388148 10097.3103237
 10359.51130764  9982.73988636 10064.82170716  1493.34001155
  9988.05244381  9989.74257633]
total_rewards_mean           9177.595491550785
total_rewards_std            2567.6286873372906
total_rewards_max            10359.511307635656
total_rewards_min            1493.3400115500292
Number of train steps total  1428000
Number of env steps total    4286000
Number of rollouts total     0
Train Time (s)               144.66256770538166
(Previous) Eval Time (s)     20.904944290407002
Sample Time (s)              6.385996394790709
Epoch Time (s)               171.95350839057937
Total Train Time (s)         61143.07343854988
Epoch                        356
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:52:42.386135 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #356 | Epoch Duration: 172.04404473304749
2020-01-13 00:52:42.386267 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #356 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8611896
Z variance train             0.07605184
KL Divergence                47.679867
KL Loss                      4.767987
QF Loss                      102.41341
VF Loss                      44.615925
Policy Loss                  -1351.1964
Q Predictions Mean           1346.0148
Q Predictions Std            1272.4662
Q Predictions Max            4552.6587
Q Predictions Min            692.18475
V Predictions Mean           1348.2103
V Predictions Std            1270.2443
V Predictions Max            4552.68
V Predictions Min            693.6235
Log Pis Mean                 -0.16995054
Log Pis Std                  4.2517753
Log Pis Max                  20.572536
Log Pis Min                  -7.159783
Policy mu Mean               0.07527397
Policy mu Std                0.8977369
Policy mu Max                3.5874307
Policy mu Min                -3.1016245
Policy log std Mean          -0.51815176
Policy log std Std           0.30474165
Policy log std Max           0.27702963
Policy log std Min           -2.7268133
Z mean eval                  1.8264391
Z variance eval              0.08286072
total_rewards                [ 9563.60775766  9571.12015623  9977.07050095  9869.33029534
  9726.23734422  9838.94996982  9853.38106536  9772.00856347
  9580.40896966 10013.41900545]
total_rewards_mean           9776.553362817434
total_rewards_std            155.977389391517
total_rewards_max            10013.419005450085
total_rewards_min            9563.607757663869
Number of train steps total  1432000
Number of env steps total    4298000
Number of rollouts total     0
Train Time (s)               145.15819940716028
(Previous) Eval Time (s)     17.74588004918769
Sample Time (s)              6.478155167773366
Epoch Time (s)               169.38223462412134
Total Train Time (s)         61312.53783490928
Epoch                        357
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:55:31.854200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #357 | Epoch Duration: 169.4678177833557
2020-01-13 00:55:31.854380 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #357 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8244965
Z variance train             0.08283038
KL Divergence                45.287586
KL Loss                      4.5287585
QF Loss                      565.8202
VF Loss                      198.26428
Policy Loss                  -1375.8119
Q Predictions Mean           1373.8086
Q Predictions Std            1288.2517
Q Predictions Max            4712.8315
Q Predictions Min            713.46686
V Predictions Mean           1373.4158
V Predictions Std            1286.5881
V Predictions Max            4707.641
V Predictions Min            706.75323
Log Pis Mean                 -0.2391325
Log Pis Std                  4.014742
Log Pis Max                  17.647861
Log Pis Min                  -6.113115
Policy mu Mean               0.14753209
Policy mu Std                0.90652937
Policy mu Max                3.3243134
Policy mu Min                -2.7243736
Policy log std Mean          -0.50081897
Policy log std Std           0.3179667
Policy log std Max           0.020028293
Policy log std Min           -3.0257497
Z mean eval                  1.8421446
Z variance eval              0.0826164
total_rewards                [ 9669.86430105  9734.03042479  9992.33192812  9928.24122598
  9791.60967291  9957.0152517   9869.64994211  9860.45286806
 10022.95394319 10001.3248589 ]
total_rewards_mean           9882.747441680021
total_rewards_std            113.89613105986167
total_rewards_max            10022.953943187596
total_rewards_min            9669.864301047337
Number of train steps total  1436000
Number of env steps total    4310000
Number of rollouts total     0
Train Time (s)               146.02048127399758
(Previous) Eval Time (s)     20.861144644673914
Sample Time (s)              6.463406052440405
Epoch Time (s)               173.3450319711119
Total Train Time (s)         61486.077863588
Epoch                        358
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:58:25.414847 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #358 | Epoch Duration: 173.56033635139465
2020-01-13 00:58:25.415109 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #358 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8453735
Z variance train             0.082847096
KL Divergence                45.6274
KL Loss                      4.56274
QF Loss                      144.40259
VF Loss                      33.046715
Policy Loss                  -1242.2997
Q Predictions Mean           1239.3613
Q Predictions Std            1147.5435
Q Predictions Max            4612.604
Q Predictions Min            692.2751
V Predictions Mean           1243.0227
V Predictions Std            1149.7834
V Predictions Max            4602.748
V Predictions Min            700.3417
Log Pis Mean                 -0.4797287
Log Pis Std                  3.483205
Log Pis Max                  17.585466
Log Pis Min                  -7.358797
Policy mu Mean               0.010662545
Policy mu Std                0.84263384
Policy mu Max                3.5719917
Policy mu Min                -3.1559563
Policy log std Mean          -0.4629661
Policy log std Std           0.27142653
Policy log std Max           0.30314738
Policy log std Min           -2.6692352
Z mean eval                  1.8548696
Z variance eval              0.0680264
total_rewards                [ 9701.18640983  9850.2866486   9818.77297475  9761.97032535
  9817.44027499  9539.35563946  9882.56401639  9933.75798989
 10071.13100509  9777.0935673 ]
total_rewards_mean           9815.355885164772
total_rewards_std            133.68541819667448
total_rewards_max            10071.131005088248
total_rewards_min            9539.355639464899
Number of train steps total  1440000
Number of env steps total    4322000
Number of rollouts total     0
Train Time (s)               148.36556641198695
(Previous) Eval Time (s)     20.98266609897837
Sample Time (s)              6.348034780006856
Epoch Time (s)               175.69626729097217
Total Train Time (s)         61661.88767816126
Epoch                        359
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:01:21.209103 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #359 | Epoch Duration: 175.79378366470337
2020-01-13 01:01:21.209237 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8570051
Z variance train             0.06794588
KL Divergence                46.47085
KL Loss                      4.647085
QF Loss                      271.49536
VF Loss                      38.072727
Policy Loss                  -1279.5435
Q Predictions Mean           1278.6025
Q Predictions Std            1184.7512
Q Predictions Max            4488.761
Q Predictions Min            687.24774
V Predictions Mean           1279.2676
V Predictions Std            1183.8655
V Predictions Max            4477.689
V Predictions Min            694.147
Log Pis Mean                 -0.57549506
Log Pis Std                  3.497228
Log Pis Max                  12.042032
Log Pis Min                  -9.439621
Policy mu Mean               0.053488106
Policy mu Std                0.8236874
Policy mu Max                2.7926624
Policy mu Min                -2.3891802
Policy log std Mean          -0.49153543
Policy log std Std           0.29494715
Policy log std Max           0.15815002
Policy log std Min           -2.7477162
Z mean eval                  1.8577036
Z variance eval              0.077561885
total_rewards                [9909.57666816 9834.86818363 9949.27741223 9879.30276137 9597.68890918
 9641.7788345  9821.77746795 9907.42684598 9687.71375456 9810.16437416]
total_rewards_mean           9803.957521171833
total_rewards_std            115.03430179874155
total_rewards_max            9949.277412226642
total_rewards_min            9597.688909179962
Number of train steps total  1444000
Number of env steps total    4334000
Number of rollouts total     0
Train Time (s)               145.26331496797502
(Previous) Eval Time (s)     20.701958978082985
Sample Time (s)              8.133673972915858
Epoch Time (s)               174.09894791897386
Total Train Time (s)         61836.07495500101
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:04:15.398303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #360 | Epoch Duration: 174.18896770477295
2020-01-13 01:04:15.398437 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #360 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8587701
Z variance train             0.0776149
KL Divergence                47.738262
KL Loss                      4.773826
QF Loss                      8217.021
VF Loss                      88.303185
Policy Loss                  -1339.2173
Q Predictions Mean           1337.9532
Q Predictions Std            1272.3597
Q Predictions Max            4601.986
Q Predictions Min            681.8224
V Predictions Mean           1333.7246
V Predictions Std            1268.4474
V Predictions Max            4592.4478
V Predictions Min            690.299
Log Pis Mean                 -0.5095546
Log Pis Std                  3.242269
Log Pis Max                  13.790972
Log Pis Min                  -6.340557
Policy mu Mean               0.021975951
Policy mu Std                0.8417512
Policy mu Max                2.8337297
Policy mu Min                -2.7334628
Policy log std Mean          -0.49032807
Policy log std Std           0.27623418
Policy log std Max           -0.006203145
Policy log std Min           -2.6114874
Z mean eval                  1.8440173
Z variance eval              0.07079522
total_rewards                [10095.58359704  9892.28554026 10096.86166888  9783.58384837
 10153.03301476  9916.31845991  9908.50525524  9852.9577162
  9844.40684351 10094.41179203]
total_rewards_mean           9963.794773619033
total_rewards_std            125.45350548942909
total_rewards_max            10153.033014763696
total_rewards_min            9783.583848368264
Number of train steps total  1448000
Number of env steps total    4346000
Number of rollouts total     0
Train Time (s)               148.2155560622923
(Previous) Eval Time (s)     20.930695451330394
Sample Time (s)              6.528435806278139
Epoch Time (s)               175.67468731990084
Total Train Time (s)         62011.83573226398
Epoch                        361
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:07:11.162423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #361 | Epoch Duration: 175.7638909816742
2020-01-13 01:07:11.162556 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #361 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.845287
Z variance train             0.0708726
KL Divergence                47.243793
KL Loss                      4.7243795
QF Loss                      4779.64
VF Loss                      69.33417
Policy Loss                  -1353.4777
Q Predictions Mean           1349.2417
Q Predictions Std            1250.9185
Q Predictions Max            4650.763
Q Predictions Min            707.69324
V Predictions Mean           1352.9016
V Predictions Std            1248.5706
V Predictions Max            4632.3057
V Predictions Min            707.77527
Log Pis Mean                 -0.19530661
Log Pis Std                  3.6174672
Log Pis Max                  14.914707
Log Pis Min                  -8.072503
Policy mu Mean               0.013597135
Policy mu Std                0.8715546
Policy mu Max                3.0605924
Policy mu Min                -3.0696988
Policy log std Mean          -0.51542026
Policy log std Std           0.31585848
Policy log std Max           -0.02049321
Policy log std Min           -2.6551943
Z mean eval                  1.8383939
Z variance eval              0.10216625
total_rewards                [ 9747.25100703  9477.15740065 10080.50213657 10002.80695326
  9595.31095892  9947.56212868  9993.724023    9759.21599835
  9863.02002541 10096.05924423]
total_rewards_mean           9856.260987608945
total_rewards_std            197.3970716057565
total_rewards_max            10096.059244227885
total_rewards_min            9477.157400653656
Number of train steps total  1452000
Number of env steps total    4358000
Number of rollouts total     0
Train Time (s)               145.76617284491658
(Previous) Eval Time (s)     20.75638945400715
Sample Time (s)              6.541879638563842
Epoch Time (s)               173.06444193748757
Total Train Time (s)         62184.97846966004
Epoch                        362
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:10:04.308707 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #362 | Epoch Duration: 173.14603900909424
2020-01-13 01:10:04.308899 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8384529
Z variance train             0.1024044
KL Divergence                45.58058
KL Loss                      4.5580583
QF Loss                      133.00044
VF Loss                      42.49553
Policy Loss                  -1277.5936
Q Predictions Mean           1277.7207
Q Predictions Std            1247.397
Q Predictions Max            4627.6733
Q Predictions Min            653.8135
V Predictions Mean           1280.8682
V Predictions Std            1242.5782
V Predictions Max            4620.4062
V Predictions Min            668.04974
Log Pis Mean                 -0.5225414
Log Pis Std                  3.6151755
Log Pis Max                  15.953471
Log Pis Min                  -7.02795
Policy mu Mean               0.05737573
Policy mu Std                0.83457536
Policy mu Max                2.5235531
Policy mu Min                -2.6683047
Policy log std Mean          -0.4840764
Policy log std Std           0.27171406
Policy log std Max           0.03287661
Policy log std Min           -2.657131
Z mean eval                  1.8566902
Z variance eval              0.08506473
total_rewards                [8565.79282715 8302.88343846 9576.6493326  9109.76396899 3827.33942707
 8875.78086326 8969.05545795 9237.03507038 9378.76822853 8523.63027381]
total_rewards_mean           8436.669888820754
total_rewards_std            1582.5629934469673
total_rewards_max            9576.649332601366
total_rewards_min            3827.339427074365
Number of train steps total  1456000
Number of env steps total    4370000
Number of rollouts total     0
Train Time (s)               146.9422320551239
(Previous) Eval Time (s)     20.92936616158113
Sample Time (s)              6.510731665417552
Epoch Time (s)               174.38232988212258
Total Train Time (s)         62359.44496897096
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:12:58.779834 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #363 | Epoch Duration: 174.470805644989
2020-01-13 01:12:58.779978 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8551229
Z variance train             0.085217856
KL Divergence                46.51379
KL Loss                      4.651379
QF Loss                      342.4103
VF Loss                      83.01464
Policy Loss                  -1222.1837
Q Predictions Mean           1220.5872
Q Predictions Std            1195.9498
Q Predictions Max            4631.477
Q Predictions Min            680.1671
V Predictions Mean           1224.0249
V Predictions Std            1195.1599
V Predictions Max            4642.9175
V Predictions Min            684.22656
Log Pis Mean                 -0.61169064
Log Pis Std                  3.6577814
Log Pis Max                  17.333158
Log Pis Min                  -7.150735
Policy mu Mean               0.101583205
Policy mu Std                0.83461004
Policy mu Max                3.2144675
Policy mu Min                -3.449287
Policy log std Mean          -0.4916632
Policy log std Std           0.2684664
Policy log std Max           -0.07861376
Policy log std Min           -2.6627352
Z mean eval                  1.859567
Z variance eval              0.05522721
total_rewards                [9943.27879746 9670.63923683 9434.23258038 9687.51489152 9405.72400417
 9669.77246602 9489.11061962 9162.34213496 9512.58697135 9830.29684905]
total_rewards_mean           9580.549855136498
total_rewards_std            214.78238852540355
total_rewards_max            9943.278797462268
total_rewards_min            9162.34213496021
Number of train steps total  1460000
Number of env steps total    4382000
Number of rollouts total     0
Train Time (s)               145.78922959789634
(Previous) Eval Time (s)     17.723533776123077
Sample Time (s)              6.45414467016235
Epoch Time (s)               169.96690804418176
Total Train Time (s)         62529.49612938007
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:15:48.835190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #364 | Epoch Duration: 170.05509638786316
2020-01-13 01:15:48.835367 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #364 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8588616
Z variance train             0.05528129
KL Divergence                48.011845
KL Loss                      4.8011847
QF Loss                      74.914795
VF Loss                      40.457592
Policy Loss                  -1324.7317
Q Predictions Mean           1323.5712
Q Predictions Std            1271.4158
Q Predictions Max            4671.691
Q Predictions Min            682.2637
V Predictions Mean           1323.008
V Predictions Std            1268.6141
V Predictions Max            4662.07
V Predictions Min            686.58325
Log Pis Mean                 -0.7338573
Log Pis Std                  3.607448
Log Pis Max                  13.718275
Log Pis Min                  -6.3713765
Policy mu Mean               0.06573415
Policy mu Std                0.7943346
Policy mu Max                2.5968304
Policy mu Min                -2.9405835
Policy log std Mean          -0.4861773
Policy log std Std           0.30225545
Policy log std Max           0.055418193
Policy log std Min           -2.6381109
Z mean eval                  1.8443062
Z variance eval              0.08299732
total_rewards                [ 9930.12872019 10239.78987481 10144.94801141  9965.56291844
  9792.03097339  9969.65365723 10062.30892762 10152.05947373
  9679.74134765 10268.05087242]
total_rewards_mean           10020.427477688234
total_rewards_std            180.5540298975575
total_rewards_max            10268.05087242068
total_rewards_min            9679.741347654981
Number of train steps total  1464000
Number of env steps total    4394000
Number of rollouts total     0
Train Time (s)               145.89375209994614
(Previous) Eval Time (s)     20.67879368085414
Sample Time (s)              6.563134719617665
Epoch Time (s)               173.13568050041795
Total Train Time (s)         62702.712294443976
Epoch                        365
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:18:42.053651 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #365 | Epoch Duration: 173.2181534767151
2020-01-13 01:18:42.053797 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #365 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8471782
Z variance train             0.0830139
KL Divergence                45.155277
KL Loss                      4.5155277
QF Loss                      160.79004
VF Loss                      298.30127
Policy Loss                  -1340.8502
Q Predictions Mean           1338.4514
Q Predictions Std            1262.0308
Q Predictions Max            4639.7285
Q Predictions Min            684.7921
V Predictions Mean           1340.4144
V Predictions Std            1255.2847
V Predictions Max            4623.1646
V Predictions Min            686.80914
Log Pis Mean                 -0.55714285
Log Pis Std                  3.9847658
Log Pis Max                  16.713001
Log Pis Min                  -7.876581
Policy mu Mean               0.058192234
Policy mu Std                0.8638374
Policy mu Max                3.255702
Policy mu Min                -3.4209325
Policy log std Mean          -0.47455287
Policy log std Std           0.2927251
Policy log std Max           0.06737888
Policy log std Min           -2.9541752
Z mean eval                  1.8577582
Z variance eval              0.06824687
total_rewards                [ 9771.84841364  9999.29257337  9893.23563407  9651.81948039
  9967.93187405 10219.06262493  9688.88594541 10057.35887486
 10051.29446174 10041.67127106]
total_rewards_mean           9934.240115353618
total_rewards_std            171.72790601951488
total_rewards_max            10219.062624934408
total_rewards_min            9651.819480393657
Number of train steps total  1468000
Number of env steps total    4406000
Number of rollouts total     0
Train Time (s)               145.9803829290904
(Previous) Eval Time (s)     20.722102309111506
Sample Time (s)              6.420011936221272
Epoch Time (s)               173.1224971744232
Total Train Time (s)         62875.92160390457
Epoch                        366
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:21:35.265212 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #366 | Epoch Duration: 173.21131491661072
2020-01-13 01:21:35.265347 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8582951
Z variance train             0.06823022
KL Divergence                46.25193
KL Loss                      4.625193
QF Loss                      175.5272
VF Loss                      67.889244
Policy Loss                  -1338.0399
Q Predictions Mean           1333.0883
Q Predictions Std            1257.9575
Q Predictions Max            4650.99
Q Predictions Min            687.28876
V Predictions Mean           1341.875
V Predictions Std            1262.0939
V Predictions Max            4639.9214
V Predictions Min            697.07153
Log Pis Mean                 -0.4382679
Log Pis Std                  3.9304254
Log Pis Max                  15.590043
Log Pis Min                  -7.5465384
Policy mu Mean               0.04437824
Policy mu Std                0.88996184
Policy mu Max                3.4268847
Policy mu Min                -2.6872616
Policy log std Mean          -0.48115337
Policy log std Std           0.28200895
Policy log std Max           -0.037985682
Policy log std Min           -2.8382342
Z mean eval                  1.8727022
Z variance eval              0.08660668
total_rewards                [ 9608.18074917 10091.81295236  9559.31662289 10017.17175172
  9497.90592955  9681.165552    9796.67286717  9960.37888116
  9417.4091444   9394.09950056]
total_rewards_mean           9702.41139509777
total_rewards_std            239.5938252220751
total_rewards_max            10091.812952355658
total_rewards_min            9394.099500563332
Number of train steps total  1472000
Number of env steps total    4418000
Number of rollouts total     0
Train Time (s)               145.94146282412112
(Previous) Eval Time (s)     20.794119416736066
Sample Time (s)              6.479675690177828
Epoch Time (s)               173.215257931035
Total Train Time (s)         63049.21640000399
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:24:28.563087 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #367 | Epoch Duration: 173.29764342308044
2020-01-13 01:24:28.563222 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8661268
Z variance train             0.08657605
KL Divergence                46.37815
KL Loss                      4.637815
QF Loss                      456.0761
VF Loss                      257.0418
Policy Loss                  -1237.6528
Q Predictions Mean           1237.3054
Q Predictions Std            1191.8408
Q Predictions Max            4593.918
Q Predictions Min            688.1935
V Predictions Mean           1248.4353
V Predictions Std            1196.6211
V Predictions Max            4622.269
V Predictions Min            691.36316
Log Pis Mean                 -0.59966975
Log Pis Std                  3.5812612
Log Pis Max                  12.187182
Log Pis Min                  -6.73626
Policy mu Mean               0.14193697
Policy mu Std                0.82664454
Policy mu Max                2.723677
Policy mu Min                -2.5621188
Policy log std Mean          -0.47991106
Policy log std Std           0.27289647
Policy log std Max           0.089524806
Policy log std Min           -2.7199678
Z mean eval                  1.8745295
Z variance eval              0.06753503
total_rewards                [9668.54571457 9624.70882031 9744.41060742 9701.50706788 9351.1273502
 9722.06458535 9719.97601224 9662.11569554 9431.84647722 9759.89445358]
total_rewards_mean           9638.619678429579
total_rewards_std            130.56958259908316
total_rewards_max            9759.89445358119
total_rewards_min            9351.127350200124
Number of train steps total  1476000
Number of env steps total    4430000
Number of rollouts total     0
Train Time (s)               146.59506458230317
(Previous) Eval Time (s)     20.712419072631747
Sample Time (s)              6.599893202073872
Epoch Time (s)               173.90737685700879
Total Train Time (s)         63223.208734185435
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:27:22.561034 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #368 | Epoch Duration: 173.99771571159363
2020-01-13 01:27:22.561174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8746071
Z variance train             0.067481205
KL Divergence                48.04349
KL Loss                      4.8043494
QF Loss                      90.842575
VF Loss                      28.949436
Policy Loss                  -1336.3514
Q Predictions Mean           1331.6907
Q Predictions Std            1275.9974
Q Predictions Max            4610.5044
Q Predictions Min            695.4032
V Predictions Mean           1335.9102
V Predictions Std            1272.3864
V Predictions Max            4601.1685
V Predictions Min            704.2146
Log Pis Mean                 -0.6051181
Log Pis Std                  3.6131175
Log Pis Max                  12.57281
Log Pis Min                  -7.0333786
Policy mu Mean               0.015791018
Policy mu Std                0.82429963
Policy mu Max                2.682476
Policy mu Min                -2.714042
Policy log std Mean          -0.5013218
Policy log std Std           0.29751766
Policy log std Max           -0.10248256
Policy log std Min           -2.640863
Z mean eval                  1.856795
Z variance eval              0.07131281
total_rewards                [9411.26545504 9895.06028922 9484.65731087 9659.20155837 9828.95663506
 5093.93967665 9600.89659503 9930.14684252 9727.34973159 9622.25828911]
total_rewards_mean           9225.37323834521
total_rewards_std            1386.3170583669153
total_rewards_max            9930.146842517439
total_rewards_min            5093.939676650215
Number of train steps total  1480000
Number of env steps total    4442000
Number of rollouts total     0
Train Time (s)               147.3023287258111
(Previous) Eval Time (s)     17.24756547017023
Sample Time (s)              6.497730576898903
Epoch Time (s)               171.04762477288023
Total Train Time (s)         63394.33408117015
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:30:13.690867 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #369 | Epoch Duration: 171.12958002090454
2020-01-13 01:30:13.691052 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #369 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8598144
Z variance train             0.07161415
KL Divergence                49.136944
KL Loss                      4.9136944
QF Loss                      98.16275
VF Loss                      92.626656
Policy Loss                  -1349.4565
Q Predictions Mean           1349.793
Q Predictions Std            1296.2275
Q Predictions Max            4578.64
Q Predictions Min            690.5608
V Predictions Mean           1352.8489
V Predictions Std            1299.2585
V Predictions Max            4563.395
V Predictions Min            688.2837
Log Pis Mean                 -0.9120597
Log Pis Std                  3.541335
Log Pis Max                  11.619145
Log Pis Min                  -6.994156
Policy mu Mean               0.04050609
Policy mu Std                0.84388053
Policy mu Max                3.0287564
Policy mu Min                -2.5214
Policy log std Mean          -0.4578903
Policy log std Std           0.2654365
Policy log std Max           0.14870101
Policy log std Min           -2.6645093
Z mean eval                  1.854358
Z variance eval              0.06874547
total_rewards                [ 9425.68511575 10257.69891977  9961.69950342 10111.46737541
 10202.35788256 10011.80773666 10110.55359934 10055.75321787
  2884.66001391  9899.44992654]
total_rewards_mean           9292.113329123937
total_rewards_std            2146.94422203026
total_rewards_max            10257.698919772032
total_rewards_min            2884.660013912916
Number of train steps total  1484000
Number of env steps total    4454000
Number of rollouts total     0
Train Time (s)               147.83454036479816
(Previous) Eval Time (s)     20.411029533017427
Sample Time (s)              6.528864238411188
Epoch Time (s)               174.77443413622677
Total Train Time (s)         63569.193658747245
Epoch                        370
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:33:08.553021 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #370 | Epoch Duration: 174.861829996109
2020-01-13 01:33:08.553174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8541634
Z variance train             0.06893162
KL Divergence                46.917095
KL Loss                      4.6917095
QF Loss                      4683.848
VF Loss                      58.310852
Policy Loss                  -1551.3397
Q Predictions Mean           1547.6241
Q Predictions Std            1417.0452
Q Predictions Max            4532.076
Q Predictions Min            670.7988
V Predictions Mean           1548.2786
V Predictions Std            1411.2917
V Predictions Max            4523.0396
V Predictions Min            683.11926
Log Pis Mean                 -0.3023495
Log Pis Std                  4.0676756
Log Pis Max                  15.839283
Log Pis Min                  -8.670622
Policy mu Mean               0.05018246
Policy mu Std                0.8867885
Policy mu Max                2.9913054
Policy mu Min                -3.1964545
Policy log std Mean          -0.51132244
Policy log std Std           0.2960332
Policy log std Max           0.20096171
Policy log std Min           -2.6050892
Z mean eval                  1.8763683
Z variance eval              0.07306431
total_rewards                [8244.61842996 5073.83805833 8764.74729385 8767.07577321 1629.51881748
 8892.32131145 8259.2769084  8428.3062154  8750.48970293 8349.66927419]
total_rewards_mean           7515.98617851958
total_rewards_std            2230.8799542155757
total_rewards_max            8892.321311451113
total_rewards_min            1629.518817480986
Number of train steps total  1488000
Number of env steps total    4466000
Number of rollouts total     0
Train Time (s)               147.39492608513683
(Previous) Eval Time (s)     20.9735300228931
Sample Time (s)              6.406075118109584
Epoch Time (s)               174.77453122613952
Total Train Time (s)         63744.33805178199
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:36:03.700751 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #371 | Epoch Duration: 175.14745569229126
2020-01-13 01:36:03.700971 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8720888
Z variance train             0.073074535
KL Divergence                47.69825
KL Loss                      4.769825
QF Loss                      331.6851
VF Loss                      108.66548
Policy Loss                  -1352.3418
Q Predictions Mean           1351.0457
Q Predictions Std            1301.351
Q Predictions Max            4626.189
Q Predictions Min            671.53815
V Predictions Mean           1353.5793
V Predictions Std            1295.0857
V Predictions Max            4585.764
V Predictions Min            700.2465
Log Pis Mean                 -0.36471152
Log Pis Std                  3.7204103
Log Pis Max                  21.732737
Log Pis Min                  -8.568241
Policy mu Mean               0.08448354
Policy mu Std                0.88928103
Policy mu Max                3.6636395
Policy mu Min                -3.0022204
Policy log std Mean          -0.5035999
Policy log std Std           0.26188946
Policy log std Max           0.05197537
Policy log std Min           -2.683847
Z mean eval                  1.9058424
Z variance eval              0.06104355
total_rewards                [9753.58612202 9333.77489575 9486.86455093 9367.65327141 9486.12817034
 9397.77186115 9452.98021453 9394.73211707 9688.05736486 9852.59965197]
total_rewards_mean           9521.414822002083
total_rewards_std            169.90181035573443
total_rewards_max            9852.599651970617
total_rewards_min            9333.774895745524
Number of train steps total  1492000
Number of env steps total    4478000
Number of rollouts total     0
Train Time (s)               146.59874951420352
(Previous) Eval Time (s)     20.981097446754575
Sample Time (s)              6.522314988542348
Epoch Time (s)               174.10216194950044
Total Train Time (s)         63918.51693839207
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:38:57.882557 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #372 | Epoch Duration: 174.1814386844635
2020-01-13 01:38:57.882708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9049795
Z variance train             0.0607522
KL Divergence                48.642387
KL Loss                      4.8642387
QF Loss                      91.0038
VF Loss                      214.60056
Policy Loss                  -1233.3805
Q Predictions Mean           1231.8986
Q Predictions Std            1141.8549
Q Predictions Max            4566.988
Q Predictions Min            705.5357
V Predictions Mean           1232.3484
V Predictions Std            1140.3953
V Predictions Max            4551.835
V Predictions Min            710.21094
Log Pis Mean                 -0.39557493
Log Pis Std                  3.5991518
Log Pis Max                  14.736191
Log Pis Min                  -8.40066
Policy mu Mean               0.0778608
Policy mu Std                0.85922694
Policy mu Max                2.7416258
Policy mu Min                -2.3560505
Policy log std Mean          -0.46265492
Policy log std Std           0.26083586
Policy log std Max           0.16277283
Policy log std Min           -2.577678
Z mean eval                  1.8623168
Z variance eval              0.058080144
total_rewards                [9443.40970657 9766.75244381 9655.70725521 9918.20865009 9550.06125299
 9741.52534271 9651.22224449 9589.77093432 9759.91473567 9705.1500342 ]
total_rewards_mean           9678.172260006422
total_rewards_std            125.48259800309691
total_rewards_max            9918.208650092116
total_rewards_min            9443.409706570092
Number of train steps total  1496000
Number of env steps total    4490000
Number of rollouts total     0
Train Time (s)               146.01743032922968
(Previous) Eval Time (s)     20.649838144890964
Sample Time (s)              6.465938136447221
Epoch Time (s)               173.13320661056787
Total Train Time (s)         64091.74090041593
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:41:51.108636 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #373 | Epoch Duration: 173.22582721710205
2020-01-13 01:41:51.108773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #373 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8645595
Z variance train             0.058060437
KL Divergence                49.232185
KL Loss                      4.9232187
QF Loss                      113.167465
VF Loss                      126.327354
Policy Loss                  -1428.1129
Q Predictions Mean           1425.0156
Q Predictions Std            1345.8099
Q Predictions Max            4581.4663
Q Predictions Min            681.4493
V Predictions Mean           1434.5802
V Predictions Std            1349.5704
V Predictions Max            4597.5034
V Predictions Min            688.4541
Log Pis Mean                 -0.57074857
Log Pis Std                  3.6628945
Log Pis Max                  11.933704
Log Pis Min                  -7.974207
Policy mu Mean               -0.008136186
Policy mu Std                0.872685
Policy mu Max                3.2477179
Policy mu Min                -3.2476995
Policy log std Mean          -0.47760853
Policy log std Std           0.28437066
Policy log std Max           0.074451864
Policy log std Min           -2.5244699
Z mean eval                  1.8720691
Z variance eval              0.05864207
total_rewards                [ 9228.82554547 10100.39399054  9878.93817079  9795.15052845
  9610.96302845 10101.76195003  9746.20920291  9963.08387714
 10144.30837407  9845.33522547]
total_rewards_mean           9841.496989333416
total_rewards_std            261.2278984076381
total_rewards_max            10144.308374074217
total_rewards_min            9228.82554547207
Number of train steps total  1500000
Number of env steps total    4502000
Number of rollouts total     0
Train Time (s)               145.9852113253437
(Previous) Eval Time (s)     18.915250062942505
Sample Time (s)              6.517569481860846
Epoch Time (s)               171.41803087014705
Total Train Time (s)         64263.241047421936
Epoch                        374
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:44:42.614874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #374 | Epoch Duration: 171.50599217414856
2020-01-13 01:44:42.615054 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #374 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8733565
Z variance train             0.058594126
KL Divergence                48.069878
KL Loss                      4.806988
QF Loss                      487.33093
VF Loss                      70.43212
Policy Loss                  -1362.6978
Q Predictions Mean           1359.4316
Q Predictions Std            1282.5581
Q Predictions Max            4546.3716
Q Predictions Min            684.4458
V Predictions Mean           1365.4731
V Predictions Std            1282.1063
V Predictions Max            4537.2036
V Predictions Min            681.5605
Log Pis Mean                 -0.046076875
Log Pis Std                  4.1570277
Log Pis Max                  19.397678
Log Pis Min                  -6.298489
Policy mu Mean               0.045988362
Policy mu Std                0.87617815
Policy mu Max                3.0377815
Policy mu Min                -2.3313034
Policy log std Mean          -0.52103645
Policy log std Std           0.31902114
Policy log std Max           0.011676669
Policy log std Min           -2.7963984
Z mean eval                  1.8519018
Z variance eval              0.051588416
total_rewards                [ 9759.25579558  9952.82258957  9855.29699376  9822.78864855
  9746.84980753 10261.80299203  9739.36913308  9764.17843707
  9824.38198439 10047.8364642 ]
total_rewards_mean           9877.458284576824
total_rewards_std            158.6372221626767
total_rewards_max            10261.802992032495
total_rewards_min            9739.369133079592
Number of train steps total  1504000
Number of env steps total    4514000
Number of rollouts total     0
Train Time (s)               147.46908017387614
(Previous) Eval Time (s)     20.74203820992261
Sample Time (s)              6.422376410569996
Epoch Time (s)               174.63349479436874
Total Train Time (s)         64437.95572407404
Epoch                        375
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:47:37.333249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #375 | Epoch Duration: 174.71807503700256
2020-01-13 01:47:37.333382 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8527569
Z variance train             0.05146869
KL Divergence                48.920998
KL Loss                      4.8921
QF Loss                      4283.911
VF Loss                      61.36199
Policy Loss                  -1177.6538
Q Predictions Mean           1177.2274
Q Predictions Std            1134.8536
Q Predictions Max            4563.5015
Q Predictions Min            692.9888
V Predictions Mean           1181.5487
V Predictions Std            1133.6555
V Predictions Max            4566.878
V Predictions Min            691.4291
Log Pis Mean                 -0.818128
Log Pis Std                  3.5149739
Log Pis Max                  13.045515
Log Pis Min                  -7.363297
Policy mu Mean               0.06544609
Policy mu Std                0.7996116
Policy mu Max                2.5946445
Policy mu Min                -2.6598012
Policy log std Mean          -0.4785782
Policy log std Std           0.29886204
Policy log std Max           0.06389916
Policy log std Min           -2.9975765
Z mean eval                  1.8877121
Z variance eval              0.05429084
total_rewards                [9775.4859337  9663.36033872 9821.13861025 9899.8259116  9635.38882195
 9725.60534284 9584.71623649 9605.6960997  9839.84463366 9796.58132513]
total_rewards_mean           9734.76432540506
total_rewards_std            102.69286692628799
total_rewards_max            9899.825911599646
total_rewards_min            9584.71623649335
Number of train steps total  1508000
Number of env steps total    4526000
Number of rollouts total     0
Train Time (s)               146.5798662211746
(Previous) Eval Time (s)     20.766570428851992
Sample Time (s)              6.353318152949214
Epoch Time (s)               173.6997548029758
Total Train Time (s)         64611.73657546425
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:50:31.118058 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #376 | Epoch Duration: 173.7845802307129
2020-01-13 01:50:31.118191 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8891817
Z variance train             0.05412261
KL Divergence                49.278618
KL Loss                      4.9278617
QF Loss                      188.60461
VF Loss                      221.97289
Policy Loss                  -1403.4576
Q Predictions Mean           1401.602
Q Predictions Std            1351.9827
Q Predictions Max            4605.5884
Q Predictions Min            690.7526
V Predictions Mean           1396.1794
V Predictions Std            1344.0605
V Predictions Max            4598.462
V Predictions Min            691.0826
Log Pis Mean                 -0.5086727
Log Pis Std                  3.7280076
Log Pis Max                  12.025011
Log Pis Min                  -7.0365314
Policy mu Mean               0.04438859
Policy mu Std                0.86374885
Policy mu Max                2.689698
Policy mu Min                -2.6745632
Policy log std Mean          -0.4914128
Policy log std Std           0.3011539
Policy log std Max           0.004956007
Policy log std Min           -2.700985
Z mean eval                  1.8784506
Z variance eval              0.07369449
total_rewards                [9830.23066763 9873.88504108 9982.62502551 9911.54331345 9564.99325842
 9867.2771766  9535.86820532 9491.88751294 9524.77640956 9785.01468792]
total_rewards_mean           9736.81012984239
total_rewards_std            176.82278908869893
total_rewards_max            9982.625025512074
total_rewards_min            9491.887512936335
Number of train steps total  1512000
Number of env steps total    4538000
Number of rollouts total     0
Train Time (s)               145.9759434047155
(Previous) Eval Time (s)     18.780366893857718
Sample Time (s)              6.5756055768579245
Epoch Time (s)               171.33191587543115
Total Train Time (s)         64783.15810635267
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:53:22.543880 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #377 | Epoch Duration: 171.42557621002197
2020-01-13 01:53:22.544076 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #377 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8783257
Z variance train             0.073640004
KL Divergence                49.98961
KL Loss                      4.998961
QF Loss                      107.15909
VF Loss                      88.775986
Policy Loss                  -1311.6166
Q Predictions Mean           1309.2953
Q Predictions Std            1250.8107
Q Predictions Max            4567.1045
Q Predictions Min            692.26373
V Predictions Mean           1316.243
V Predictions Std            1253.2958
V Predictions Max            4585.7837
V Predictions Min            695.0303
Log Pis Mean                 -0.34927756
Log Pis Std                  4.07571
Log Pis Max                  22.59872
Log Pis Min                  -9.336418
Policy mu Mean               0.12467283
Policy mu Std                0.8696991
Policy mu Max                3.4552784
Policy mu Min                -3.4474747
Policy log std Mean          -0.483747
Policy log std Std           0.27180234
Policy log std Max           -0.03493753
Policy log std Min           -2.430083
Z mean eval                  1.8636315
Z variance eval              0.08437241
total_rewards                [ 9884.23214215  9845.31090512  9964.26847708  9871.09781088
  9861.1540425  10172.89529209 10259.5531585  10098.89612856
 10035.48255359 10018.33527748]
total_rewards_mean           10001.122578794502
total_rewards_std            135.32379300436355
total_rewards_max            10259.553158503899
total_rewards_min            9845.310905116237
Number of train steps total  1516000
Number of env steps total    4550000
Number of rollouts total     0
Train Time (s)               145.6304522929713
(Previous) Eval Time (s)     17.486366973724216
Sample Time (s)              6.606286349706352
Epoch Time (s)               169.72310561640188
Total Train Time (s)         64952.974975013174
Epoch                        378
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:56:12.368848 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #378 | Epoch Duration: 169.82459378242493
2020-01-13 01:56:12.369155 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8648698
Z variance train             0.08427806
KL Divergence                48.81436
KL Loss                      4.8814363
QF Loss                      4143.829
VF Loss                      94.36327
Policy Loss                  -1357.0913
Q Predictions Mean           1350.7317
Q Predictions Std            1319.9967
Q Predictions Max            4572.3647
Q Predictions Min            693.63544
V Predictions Mean           1352.4526
V Predictions Std            1313.982
V Predictions Max            4542.9175
V Predictions Min            692.5985
Log Pis Mean                 -0.73985416
Log Pis Std                  3.5772917
Log Pis Max                  11.939463
Log Pis Min                  -9.071801
Policy mu Mean               0.059381362
Policy mu Std                0.8483426
Policy mu Max                3.4313107
Policy mu Min                -2.8575697
Policy log std Mean          -0.49625146
Policy log std Std           0.30080262
Policy log std Max           -0.010328352
Policy log std Min           -2.6150818
Z mean eval                  1.8911839
Z variance eval              0.09610556
total_rewards                [9154.9978098  9418.12507202 9168.1876093  9092.92055287 9346.22424731
 9272.68744628 9106.27343312 9297.29535943 9016.0494305  9345.53341038]
total_rewards_mean           9221.829437101394
total_rewards_std            125.3995112947056
total_rewards_max            9418.125072015091
total_rewards_min            9016.049430504596
Number of train steps total  1520000
Number of env steps total    4562000
Number of rollouts total     0
Train Time (s)               147.9935928718187
(Previous) Eval Time (s)     20.703739661723375
Sample Time (s)              6.0328971622511744
Epoch Time (s)               174.73022969579324
Total Train Time (s)         65127.78539409116
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:59:07.180121 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #379 | Epoch Duration: 174.8107578754425
2020-01-13 01:59:07.180254 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8903253
Z variance train             0.09679222
KL Divergence                49.513382
KL Loss                      4.9513383
QF Loss                      4212.922
VF Loss                      69.50273
Policy Loss                  -1275.4385
Q Predictions Mean           1272.2983
Q Predictions Std            1247.8866
Q Predictions Max            4517.77
Q Predictions Min            678.69867
V Predictions Mean           1279.5656
V Predictions Std            1250.463
V Predictions Max            4527.057
V Predictions Min            685.593
Log Pis Mean                 -0.7475784
Log Pis Std                  3.6823223
Log Pis Max                  14.32426
Log Pis Min                  -6.23864
Policy mu Mean               0.052413326
Policy mu Std                0.82359385
Policy mu Max                3.0384197
Policy mu Min                -2.6233156
Policy log std Mean          -0.4741056
Policy log std Std           0.27518812
Policy log std Max           0.07576728
Policy log std Min           -2.806288
Z mean eval                  1.9115146
Z variance eval              0.122425176
total_rewards                [9316.61175347 9894.82550863 9226.9385677  9357.06360616 9799.66013854
 9193.49394249 9111.40337268 9907.42773971 9859.50943572 9285.73826778]
total_rewards_mean           9495.267233289673
total_rewards_std            309.869292920655
total_rewards_max            9907.42773970602
total_rewards_min            9111.403372679206
Number of train steps total  1524000
Number of env steps total    4574000
Number of rollouts total     0
Train Time (s)               145.38703901832923
(Previous) Eval Time (s)     20.757535024080426
Sample Time (s)              9.667046279180795
Epoch Time (s)               175.81162032159045
Total Train Time (s)         65303.676605890505
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:02:03.074185 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #380 | Epoch Duration: 175.89383721351624
2020-01-13 02:02:03.074317 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #380 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9097958
Z variance train             0.122848235
KL Divergence                49.871918
KL Loss                      4.9871917
QF Loss                      104.273285
VF Loss                      55.488876
Policy Loss                  -1429.0654
Q Predictions Mean           1430.2382
Q Predictions Std            1393.8066
Q Predictions Max            4643.3467
Q Predictions Min            682.2826
V Predictions Mean           1431.7933
V Predictions Std            1389.4744
V Predictions Max            4631.1353
V Predictions Min            693.72534
Log Pis Mean                 -0.0950571
Log Pis Std                  3.9896061
Log Pis Max                  13.884285
Log Pis Min                  -6.259799
Policy mu Mean               0.044379156
Policy mu Std                0.87781304
Policy mu Max                2.80202
Policy mu Min                -2.74337
Policy log std Mean          -0.49447322
Policy log std Std           0.27528292
Policy log std Max           -0.06160289
Policy log std Min           -2.5288646
Z mean eval                  1.8902848
Z variance eval              0.09111163
total_rewards                [ 9956.37725297 10116.04604728 10160.72979594 10528.38805598
 10544.77191348 10371.61645099 10325.29314689 10319.00681739
 10080.69152425 10178.79194004]
total_rewards_mean           10258.171294519712
total_rewards_std            182.97741560931294
total_rewards_max            10544.771913479039
total_rewards_min            9956.377252967484
Number of train steps total  1528000
Number of env steps total    4586000
Number of rollouts total     0
Train Time (s)               147.17296544322744
(Previous) Eval Time (s)     20.69597431831062
Sample Time (s)              6.41876144008711
Epoch Time (s)               174.28770120162517
Total Train Time (s)         65478.06792785274
Epoch                        381
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:04:57.469283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #381 | Epoch Duration: 174.39487051963806
2020-01-13 02:04:57.469420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.889546
Z variance train             0.091347516
KL Divergence                49.574787
KL Loss                      4.957479
QF Loss                      143.38548
VF Loss                      140.23366
Policy Loss                  -1319.5021
Q Predictions Mean           1317.7166
Q Predictions Std            1276.6633
Q Predictions Max            4522.3877
Q Predictions Min            671.98706
V Predictions Mean           1328.0442
V Predictions Std            1279.332
V Predictions Max            4541.4224
V Predictions Min            699.8771
Log Pis Mean                 -0.6203114
Log Pis Std                  3.6145096
Log Pis Max                  16.266825
Log Pis Min                  -10.058009
Policy mu Mean               0.048218112
Policy mu Std                0.86379737
Policy mu Max                3.2186873
Policy mu Min                -4.3629103
Policy log std Mean          -0.48435125
Policy log std Std           0.26703313
Policy log std Max           0.0036036372
Policy log std Min           -2.324059
Z mean eval                  1.8951944
Z variance eval              0.11654963
total_rewards                [ 9919.54446449 10495.40435337 10272.70183772 10387.30945939
  7385.04395634 10272.72657506 10218.21167305 10192.46056748
 10284.64298126 10377.27125576]
total_rewards_mean           9980.531712391978
total_rewards_std            877.0901242423059
total_rewards_max            10495.404353371452
total_rewards_min            7385.043956343066
Number of train steps total  1532000
Number of env steps total    4598000
Number of rollouts total     0
Train Time (s)               147.43155474821106
(Previous) Eval Time (s)     20.827033730689436
Sample Time (s)              6.389928185380995
Epoch Time (s)               174.6485166642815
Total Train Time (s)         65652.85013167001
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:07:52.254520 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #382 | Epoch Duration: 174.78500413894653
2020-01-13 02:07:52.254667 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #382 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8971351
Z variance train             0.11596942
KL Divergence                49.559055
KL Loss                      4.9559054
QF Loss                      343.6308
VF Loss                      200.1422
Policy Loss                  -1370.5541
Q Predictions Mean           1365.8002
Q Predictions Std            1309.8289
Q Predictions Max            4621.5337
Q Predictions Min            683.55853
V Predictions Mean           1362.8613
V Predictions Std            1299.6565
V Predictions Max            4591.5747
V Predictions Min            676.0936
Log Pis Mean                 -0.295713
Log Pis Std                  3.5996482
Log Pis Max                  14.090097
Log Pis Min                  -7.3290095
Policy mu Mean               0.041946918
Policy mu Std                0.8942907
Policy mu Max                3.5028
Policy mu Min                -3.1218584
Policy log std Mean          -0.50378555
Policy log std Std           0.30407238
Policy log std Max           0.15377104
Policy log std Min           -2.7430675
Z mean eval                  1.8952847
Z variance eval              0.1369302
total_rewards                [ 9822.86032444  9932.39801591 10290.69103599  9778.02415338
  7441.35133644 10011.59007516  9407.77094011  9765.73052146
  9891.14364361 10007.46422236]
total_rewards_mean           9634.902426886349
total_rewards_std            761.6495815746009
total_rewards_max            10290.69103599409
total_rewards_min            7441.351336443568
Number of train steps total  1536000
Number of env steps total    4610000
Number of rollouts total     0
Train Time (s)               146.3406353201717
(Previous) Eval Time (s)     19.111975512001663
Sample Time (s)              6.442974720615894
Epoch Time (s)               171.89558555278927
Total Train Time (s)         65824.8221931993
Epoch                        383
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:10:44.228649 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #383 | Epoch Duration: 171.97388458251953
2020-01-13 02:10:44.228781 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.895698
Z variance train             0.1367574
KL Divergence                49.288246
KL Loss                      4.928825
QF Loss                      110.54071
VF Loss                      50.77611
Policy Loss                  -1273.8097
Q Predictions Mean           1273.229
Q Predictions Std            1227.7203
Q Predictions Max            4566.8896
Q Predictions Min            678.5529
V Predictions Mean           1271.5636
V Predictions Std            1218.4852
V Predictions Max            4548.713
V Predictions Min            687.5646
Log Pis Mean                 -0.8547034
Log Pis Std                  3.3356996
Log Pis Max                  12.310268
Log Pis Min                  -5.935505
Policy mu Mean               0.025870046
Policy mu Std                0.80943096
Policy mu Max                2.633931
Policy mu Min                -2.4321449
Policy log std Mean          -0.47138834
Policy log std Std           0.24050955
Policy log std Max           0.016303658
Policy log std Min           -2.7038317
Z mean eval                  1.9035523
Z variance eval              0.09112503
total_rewards                [9805.06780356 9605.65035664 9781.15323929 9684.56101401 9854.68923379
 9489.76015025 9895.99722315 9526.28098342 9655.7417608  9729.63897842]
total_rewards_mean           9702.85407433318
total_rewards_std            128.9355940540727
total_rewards_max            9895.997223153629
total_rewards_min            9489.760150246919
Number of train steps total  1540000
Number of env steps total    4622000
Number of rollouts total     0
Train Time (s)               147.62035322422162
(Previous) Eval Time (s)     20.74056278122589
Sample Time (s)              5.581156665459275
Epoch Time (s)               173.94207267090678
Total Train Time (s)         65998.84810821246
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:13:38.258190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #384 | Epoch Duration: 174.029314994812
2020-01-13 02:13:38.258328 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #384 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9047047
Z variance train             0.0906706
KL Divergence                48.64567
KL Loss                      4.8645673
QF Loss                      4550.5454
VF Loss                      145.57423
Policy Loss                  -1371.8453
Q Predictions Mean           1370.268
Q Predictions Std            1302.8373
Q Predictions Max            4700.114
Q Predictions Min            680.45264
V Predictions Mean           1364.4208
V Predictions Std            1293.964
V Predictions Max            4681.375
V Predictions Min            690.16986
Log Pis Mean                 -0.48252323
Log Pis Std                  3.6925607
Log Pis Max                  18.175653
Log Pis Min                  -8.225813
Policy mu Mean               0.017248712
Policy mu Std                0.8820387
Policy mu Max                2.9999309
Policy mu Min                -3.338814
Policy log std Mean          -0.4764212
Policy log std Std           0.26501012
Policy log std Max           0.097031355
Policy log std Min           -2.645468
Z mean eval                  1.8827059
Z variance eval              0.07058672
total_rewards                [ 9824.21743551  9870.06093209  9911.2823155   9850.01310712
 10057.93047434  9704.71018786  9868.13497198 10103.40336055
  9931.84338291  9621.03999895]
total_rewards_mean           9874.263616682345
total_rewards_std            136.7270443148174
total_rewards_max            10103.403360551709
total_rewards_min            9621.039998954497
Number of train steps total  1544000
Number of env steps total    4634000
Number of rollouts total     0
Train Time (s)               147.22266611177474
(Previous) Eval Time (s)     20.63532943185419
Sample Time (s)              6.489180014934391
Epoch Time (s)               174.34717555856332
Total Train Time (s)         66173.29110403499
Epoch                        385
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:16:32.704470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #385 | Epoch Duration: 174.44603204727173
2020-01-13 02:16:32.704644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #385 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8815473
Z variance train             0.07050952
KL Divergence                48.015472
KL Loss                      4.8015475
QF Loss                      88.58998
VF Loss                      77.5449
Policy Loss                  -1362.3651
Q Predictions Mean           1361.3921
Q Predictions Std            1292.3824
Q Predictions Max            4635.543
Q Predictions Min            696.75696
V Predictions Mean           1362.4426
V Predictions Std            1291.0468
V Predictions Max            4608.857
V Predictions Min            698.6242
Log Pis Mean                 -0.43609193
Log Pis Std                  3.8358235
Log Pis Max                  14.5136
Log Pis Min                  -7.046588
Policy mu Mean               0.05321659
Policy mu Std                0.87740266
Policy mu Max                2.8220086
Policy mu Min                -3.2565691
Policy log std Mean          -0.4621273
Policy log std Std           0.2684683
Policy log std Max           -0.07856831
Policy log std Min           -2.3541474
Z mean eval                  1.8741112
Z variance eval              0.08466537
total_rewards                [ 9580.65716835 10139.2922156   9975.23592676  9777.62018511
 10006.0011701   9798.5117571  10192.45956504  9296.84161637
 10094.25175073 10208.75121912]
total_rewards_mean           9906.962257427058
total_rewards_std            279.8790711116719
total_rewards_max            10208.75121912379
total_rewards_min            9296.841616368101
Number of train steps total  1548000
Number of env steps total    4646000
Number of rollouts total     0
Train Time (s)               147.02580833202228
(Previous) Eval Time (s)     21.01948000723496
Sample Time (s)              5.618510524742305
Epoch Time (s)               173.66379886399955
Total Train Time (s)         66347.03587124357
Epoch                        386
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:19:26.451574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #386 | Epoch Duration: 173.7467999458313
2020-01-13 02:19:26.451706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #386 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8752114
Z variance train             0.08471556
KL Divergence                47.04331
KL Loss                      4.704331
QF Loss                      322.9041
VF Loss                      65.78241
Policy Loss                  -1476.9084
Q Predictions Mean           1474.9913
Q Predictions Std            1412.7407
Q Predictions Max            4573.7354
Q Predictions Min            682.5473
V Predictions Mean           1478.4866
V Predictions Std            1409.7052
V Predictions Max            4562.1724
V Predictions Min            688.25574
Log Pis Mean                 -0.42684162
Log Pis Std                  3.9500926
Log Pis Max                  13.37689
Log Pis Min                  -8.024233
Policy mu Mean               0.037790466
Policy mu Std                0.9085021
Policy mu Max                3.2215068
Policy mu Min                -2.8796232
Policy log std Mean          -0.48016873
Policy log std Std           0.2891063
Policy log std Max           -0.025840938
Policy log std Min           -2.6700325
Z mean eval                  1.901823
Z variance eval              0.06951566
total_rewards                [ 9922.22070781  9737.82762957  9994.93782965  9634.72936663
  9933.59420461  8702.61407952 10099.63696185 10009.02367408
 10233.96095396  9764.34312096]
total_rewards_mean           9803.288852865753
total_rewards_std            403.63105393480583
total_rewards_max            10233.960953964099
total_rewards_min            8702.614079521925
Number of train steps total  1552000
Number of env steps total    4658000
Number of rollouts total     0
Train Time (s)               146.18365166382864
(Previous) Eval Time (s)     20.734043068718165
Sample Time (s)              6.482313010841608
Epoch Time (s)               173.40000774338841
Total Train Time (s)         66520.51829900686
Epoch                        387
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:22:19.939808 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #387 | Epoch Duration: 173.48800611495972
2020-01-13 02:22:19.939941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8999485
Z variance train             0.07017151
KL Divergence                48.295616
KL Loss                      4.8295617
QF Loss                      237.2309
VF Loss                      146.28653
Policy Loss                  -1299.7925
Q Predictions Mean           1295.333
Q Predictions Std            1239.0123
Q Predictions Max            4390.5034
Q Predictions Min            627.6116
V Predictions Mean           1291.0153
V Predictions Std            1231.6228
V Predictions Max            4357.549
V Predictions Min            653.1528
Log Pis Mean                 -0.2823229
Log Pis Std                  3.7880468
Log Pis Max                  19.842842
Log Pis Min                  -6.8442607
Policy mu Mean               0.122609295
Policy mu Std                0.8723011
Policy mu Max                3.0502315
Policy mu Min                -2.763727
Policy log std Mean          -0.5074384
Policy log std Std           0.28026125
Policy log std Max           -0.04724419
Policy log std Min           -2.578574
Z mean eval                  1.8992189
Z variance eval              0.08997854
total_rewards                [ 9992.8572176  10030.7224103  10115.92501704  9867.56256009
  9990.41605376 10382.59232251 10111.34667459 10098.00960827
 10279.62443036 10288.17370271]
total_rewards_mean           10115.722999723936
total_rewards_std            150.917743081549
total_rewards_max            10382.592322512995
total_rewards_min            9867.562560090386
Number of train steps total  1556000
Number of env steps total    4670000
Number of rollouts total     0
Train Time (s)               144.4777842978947
(Previous) Eval Time (s)     20.957605473231524
Sample Time (s)              6.340437537524849
Epoch Time (s)               171.77582730865106
Total Train Time (s)         66692.38316213572
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:25:11.805306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #388 | Epoch Duration: 171.86526727676392
2020-01-13 02:25:11.805444 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #388 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8987204
Z variance train             0.09011395
KL Divergence                48.425285
KL Loss                      4.842529
QF Loss                      221.11778
VF Loss                      36.644543
Policy Loss                  -1308.4253
Q Predictions Mean           1304.102
Q Predictions Std            1227.1985
Q Predictions Max            4589.328
Q Predictions Min            693.4028
V Predictions Mean           1306.868
V Predictions Std            1229.1643
V Predictions Max            4589.693
V Predictions Min            704.7774
Log Pis Mean                 -0.6968523
Log Pis Std                  3.6748917
Log Pis Max                  12.22304
Log Pis Min                  -7.2281013
Policy mu Mean               0.03057913
Policy mu Std                0.8518098
Policy mu Max                3.2549334
Policy mu Min                -2.8614638
Policy log std Mean          -0.4864631
Policy log std Std           0.26927108
Policy log std Max           -0.055342674
Policy log std Min           -2.3364913
Z mean eval                  1.9072285
Z variance eval              0.06950181
total_rewards                [10024.09484984 10063.98781432 10431.60488367 10109.20115255
 10307.88131007  9874.76004892 10055.8497286  10105.320112
 10230.16519795 10149.68165789]
total_rewards_mean           10135.254675582577
total_rewards_std            148.32817618368313
total_rewards_max            10431.604883669619
total_rewards_min            9874.760048918153
Number of train steps total  1560000
Number of env steps total    4682000
Number of rollouts total     0
Train Time (s)               145.51547252899036
(Previous) Eval Time (s)     20.923224737867713
Sample Time (s)              6.484979311469942
Epoch Time (s)               172.923676578328
Total Train Time (s)         66865.39026572695
Epoch                        389
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:28:04.814475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #389 | Epoch Duration: 173.00893354415894
2020-01-13 02:28:04.814606 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #389 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.903992
Z variance train             0.069136776
KL Divergence                49.289806
KL Loss                      4.928981
QF Loss                      329.67566
VF Loss                      98.13901
Policy Loss                  -1399.5602
Q Predictions Mean           1399.2511
Q Predictions Std            1331.4027
Q Predictions Max            4617.217
Q Predictions Min            677.0626
V Predictions Mean           1403.6993
V Predictions Std            1328.7468
V Predictions Max            4622.042
V Predictions Min            689.49115
Log Pis Mean                 -0.3122967
Log Pis Std                  3.9972737
Log Pis Max                  15.4096
Log Pis Min                  -6.6008863
Policy mu Mean               0.08555964
Policy mu Std                0.87432253
Policy mu Max                3.1559243
Policy mu Min                -3.170525
Policy log std Mean          -0.49958527
Policy log std Std           0.2865004
Policy log std Max           -0.0063121915
Policy log std Min           -2.7243795
Z mean eval                  1.8877227
Z variance eval              0.082491145
total_rewards                [10089.10846199 10131.84432662  9931.74355496 10299.35234109
 10105.13363692  9958.21696179 10209.37449088  9931.84899394
 10110.61231432 10219.82148397]
total_rewards_mean           10098.70565664817
total_rewards_std            120.00152256082555
total_rewards_max            10299.352341088186
total_rewards_min            9931.74355495897
Number of train steps total  1564000
Number of env steps total    4694000
Number of rollouts total     0
Train Time (s)               145.38560410775244
(Previous) Eval Time (s)     20.563520544208586
Sample Time (s)              6.488403321243823
Epoch Time (s)               172.43752797320485
Total Train Time (s)         67037.9182320172
Epoch                        390
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:30:57.344583 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #390 | Epoch Duration: 172.52986979484558
2020-01-13 02:30:57.344722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #390 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8861424
Z variance train             0.082233384
KL Divergence                48.42465
KL Loss                      4.842465
QF Loss                      1424.9521
VF Loss                      138.24815
Policy Loss                  -1476.3822
Q Predictions Mean           1477.5317
Q Predictions Std            1390.1486
Q Predictions Max            4616.67
Q Predictions Min            693.7515
V Predictions Mean           1481.3752
V Predictions Std            1391.9945
V Predictions Max            4647.0493
V Predictions Min            704.3722
Log Pis Mean                 0.09456141
Log Pis Std                  3.7611911
Log Pis Max                  13.056921
Log Pis Min                  -5.5130253
Policy mu Mean               0.107567914
Policy mu Std                0.91286236
Policy mu Max                2.8072503
Policy mu Min                -2.7117753
Policy log std Mean          -0.49535012
Policy log std Std           0.2669025
Policy log std Max           -0.0704487
Policy log std Min           -2.616741
Z mean eval                  1.8760185
Z variance eval              0.07646864
total_rewards                [ 9738.64287302  9889.6417485  10188.9473026   9990.60838944
 10022.88971496  9993.4117046  10063.37543344 10094.59637313
  9933.13147753  9959.65499271]
total_rewards_mean           9987.49000099314
total_rewards_std            115.90606508074741
total_rewards_max            10188.947302600725
total_rewards_min            9738.642873020823
Number of train steps total  1568000
Number of env steps total    4706000
Number of rollouts total     0
Train Time (s)               146.27276569698006
(Previous) Eval Time (s)     17.514762572944164
Sample Time (s)              6.617209106683731
Epoch Time (s)               170.40473737660795
Total Train Time (s)         67208.41193868872
Epoch                        391
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:33:47.842122 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #391 | Epoch Duration: 170.49728417396545
2020-01-13 02:33:47.842294 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #391 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8754389
Z variance train             0.07624092
KL Divergence                47.886322
KL Loss                      4.7886324
QF Loss                      238.96756
VF Loss                      74.49184
Policy Loss                  -1351.1353
Q Predictions Mean           1344.7388
Q Predictions Std            1265.9229
Q Predictions Max            4548.9253
Q Predictions Min            682.1016
V Predictions Mean           1350.9624
V Predictions Std            1262.4153
V Predictions Max            4524.3574
V Predictions Min            680.04584
Log Pis Mean                 -0.4002482
Log Pis Std                  3.606474
Log Pis Max                  12.189025
Log Pis Min                  -6.291816
Policy mu Mean               0.0829666
Policy mu Std                0.8625842
Policy mu Max                2.9970357
Policy mu Min                -2.7836628
Policy log std Mean          -0.49225548
Policy log std Std           0.30370212
Policy log std Max           -0.0041605234
Policy log std Min           -2.967675
Z mean eval                  1.9052607
Z variance eval              0.087996885
total_rewards                [ 9788.06876266 10051.89731148 10046.49940822 10142.60843961
  9811.15173522  9919.09869266 10010.73800214  9686.71036158
  9861.88494645  9904.82131444]
total_rewards_mean           9922.347897446916
total_rewards_std            133.57327317692543
total_rewards_max            10142.608439607238
total_rewards_min            9686.710361584199
Number of train steps total  1572000
Number of env steps total    4718000
Number of rollouts total     0
Train Time (s)               146.96382901910692
(Previous) Eval Time (s)     20.756376903038472
Sample Time (s)              6.572071221657097
Epoch Time (s)               174.2922771438025
Total Train Time (s)         67382.7918473729
Epoch                        392
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:36:42.228563 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #392 | Epoch Duration: 174.38606929779053
2020-01-13 02:36:42.228838 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #392 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9043131
Z variance train             0.08790706
KL Divergence                47.985104
KL Loss                      4.7985106
QF Loss                      198.24417
VF Loss                      40.434155
Policy Loss                  -1253.43
Q Predictions Mean           1249.044
Q Predictions Std            1178.2765
Q Predictions Max            4556.0835
Q Predictions Min            685.5494
V Predictions Mean           1254.4713
V Predictions Std            1177.8674
V Predictions Max            4535.9893
V Predictions Min            681.8884
Log Pis Mean                 -0.66509604
Log Pis Std                  3.5987546
Log Pis Max                  15.00477
Log Pis Min                  -6.4677014
Policy mu Mean               0.08104371
Policy mu Std                0.8223866
Policy mu Max                2.966594
Policy mu Min                -2.8613195
Policy log std Mean          -0.4762024
Policy log std Std           0.2738823
Policy log std Max           -0.011745423
Policy log std Min           -2.281291
Z mean eval                  1.8933156
Z variance eval              0.10633089
total_rewards                [ 9903.48893391 10199.33546354 10449.80951319 10209.93621709
 10245.68160853 10240.0583153  10091.96982588 10150.62829146
 10290.92624293 10332.41774029]
total_rewards_mean           10211.425215211919
total_rewards_std            138.82327668273743
total_rewards_max            10449.809513192737
total_rewards_min            9903.488933913202
Number of train steps total  1576000
Number of env steps total    4730000
Number of rollouts total     0
Train Time (s)               146.08845992106944
(Previous) Eval Time (s)     20.626837758813053
Sample Time (s)              5.633285072632134
Epoch Time (s)               172.34858275251463
Total Train Time (s)         67555.24207505444
Epoch                        393
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:39:34.682531 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #393 | Epoch Duration: 172.4535174369812
2020-01-13 02:39:34.682724 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #393 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.896175
Z variance train             0.10630341
KL Divergence                47.268238
KL Loss                      4.726824
QF Loss                      629.7744
VF Loss                      51.266205
Policy Loss                  -1340.2639
Q Predictions Mean           1337.0735
Q Predictions Std            1255.7408
Q Predictions Max            4570.6777
Q Predictions Min            668.98236
V Predictions Mean           1342.1182
V Predictions Std            1255.4723
V Predictions Max            4562.848
V Predictions Min            676.3086
Log Pis Mean                 -0.23062836
Log Pis Std                  3.5601318
Log Pis Max                  10.929634
Log Pis Min                  -7.9260406
Policy mu Mean               0.12932657
Policy mu Std                0.87808925
Policy mu Max                2.8067694
Policy mu Min                -2.4082968
Policy log std Mean          -0.50943774
Policy log std Std           0.29851186
Policy log std Max           -0.01970157
Policy log std Min           -2.817096
Z mean eval                  1.8851728
Z variance eval              0.07160795
total_rewards                [10054.39630099 10095.16536547 10265.74692683 10267.75460518
 10284.89928894 10256.94947546  9881.63941073 10309.45293056
 10211.17637704 10404.72210955]
total_rewards_mean           10203.190279076083
total_rewards_std            143.81338541151737
total_rewards_max            10404.72210954645
total_rewards_min            9881.639410733544
Number of train steps total  1580000
Number of env steps total    4742000
Number of rollouts total     0
Train Time (s)               147.57199665205553
(Previous) Eval Time (s)     20.550741785671562
Sample Time (s)              5.755672336090356
Epoch Time (s)               173.87841077381745
Total Train Time (s)         67729.20655962871
Epoch                        394
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:42:28.654895 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #394 | Epoch Duration: 173.97203826904297
2020-01-13 02:42:28.655043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #394 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8825204
Z variance train             0.07156132
KL Divergence                47.863907
KL Loss                      4.786391
QF Loss                      4322.563
VF Loss                      137.18787
Policy Loss                  -1342.9341
Q Predictions Mean           1340.9174
Q Predictions Std            1287.8755
Q Predictions Max            4544.294
Q Predictions Min            672.5672
V Predictions Mean           1340.375
V Predictions Std            1278.9353
V Predictions Max            4525.5913
V Predictions Min            680.2921
Log Pis Mean                 -0.6889212
Log Pis Std                  3.5366714
Log Pis Max                  11.350292
Log Pis Min                  -7.4817615
Policy mu Mean               0.0056784055
Policy mu Std                0.8474052
Policy mu Max                2.4648013
Policy mu Min                -2.412916
Policy log std Mean          -0.4945508
Policy log std Std           0.2651586
Policy log std Max           -0.026863873
Policy log std Min           -2.5784612
Z mean eval                  1.8672445
Z variance eval              0.03916168
total_rewards                [ 9884.7571182  10161.71159031 10091.74229165 10376.86198327
 10358.30245117 10475.35964844 10446.78126866 10298.65646177
 10413.37770135 10174.47619047]
total_rewards_mean           10268.202670531142
total_rewards_std            177.4897543644053
total_rewards_max            10475.359648442049
total_rewards_min            9884.757118203936
Number of train steps total  1584000
Number of env steps total    4754000
Number of rollouts total     0
Train Time (s)               147.3232988701202
(Previous) Eval Time (s)     19.657551805954427
Sample Time (s)              6.355615169741213
Epoch Time (s)               173.33646584581584
Total Train Time (s)         67902.6222065757
Epoch                        395
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:45:22.073231 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #395 | Epoch Duration: 173.4180281162262
2020-01-13 02:45:22.073441 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #395 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.867061
Z variance train             0.039123215
KL Divergence                49.350285
KL Loss                      4.9350286
QF Loss                      146.10896
VF Loss                      44.79104
Policy Loss                  -1325.3201
Q Predictions Mean           1322.6266
Q Predictions Std            1268.0208
Q Predictions Max            4630.8257
Q Predictions Min            700.7541
V Predictions Mean           1324.1895
V Predictions Std            1264.7229
V Predictions Max            4624.9614
V Predictions Min            700.9733
Log Pis Mean                 -0.3264502
Log Pis Std                  4.063251
Log Pis Max                  22.486332
Log Pis Min                  -6.8523273
Policy mu Mean               0.033119325
Policy mu Std                0.89072263
Policy mu Max                3.27666
Policy mu Min                -3.0869071
Policy log std Mean          -0.4890343
Policy log std Std           0.26420406
Policy log std Max           0.29679108
Policy log std Min           -2.7463543
Z mean eval                  1.8766603
Z variance eval              0.0410124
total_rewards                [10162.02317076 10183.25542795 10424.68273847 10359.3737206
 10080.95985627 10208.11717868 10384.93439864 10433.71066426
 10414.64633713 10251.2773055 ]
total_rewards_mean           10290.298079826014
total_rewards_std            121.58444256599867
total_rewards_max            10433.710664262491
total_rewards_min            10080.959856265967
Number of train steps total  1588000
Number of env steps total    4766000
Number of rollouts total     0
Train Time (s)               144.67909861914814
(Previous) Eval Time (s)     20.825641923118383
Sample Time (s)              5.394221387337893
Epoch Time (s)               170.8989619296044
Total Train Time (s)         68073.60068234382
Epoch                        396
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:48:13.053722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #396 | Epoch Duration: 170.98016047477722
2020-01-13 02:48:13.053856 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #396 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8772275
Z variance train             0.041085124
KL Divergence                48.85475
KL Loss                      4.885475
QF Loss                      147.3132
VF Loss                      117.58589
Policy Loss                  -1357.0221
Q Predictions Mean           1354.6329
Q Predictions Std            1268.3251
Q Predictions Max            4611.677
Q Predictions Min            664.9964
V Predictions Mean           1359.9358
V Predictions Std            1265.9365
V Predictions Max            4578.183
V Predictions Min            676.8047
Log Pis Mean                 -0.1168339
Log Pis Std                  4.183656
Log Pis Max                  16.460957
Log Pis Min                  -11.871697
Policy mu Mean               0.06628954
Policy mu Std                0.89998406
Policy mu Max                3.685719
Policy mu Min                -2.757251
Policy log std Mean          -0.5114947
Policy log std Std           0.28447354
Policy log std Max           0.18368179
Policy log std Min           -2.7951095
Z mean eval                  1.8909365
Z variance eval              0.05186034
total_rewards                [10023.98830982 10596.89281975 10473.77646032  9987.74993344
 10277.17060274  9937.68708112 10069.68785204 10083.9259122
 10310.52935858 10424.69955197]
total_rewards_mean           10218.610788196322
total_rewards_std            217.47838948455043
total_rewards_max            10596.892819752682
total_rewards_min            9937.68708111611
Number of train steps total  1592000
Number of env steps total    4778000
Number of rollouts total     0
Train Time (s)               147.92868971591815
(Previous) Eval Time (s)     20.861705656629056
Sample Time (s)              6.400278631132096
Epoch Time (s)               175.1906740036793
Total Train Time (s)         68248.87812365964
Epoch                        397
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:51:08.333739 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #397 | Epoch Duration: 175.2797863483429
2020-01-13 02:51:08.333879 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #397 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8907467
Z variance train             0.051840723
KL Divergence                49.261124
KL Loss                      4.9261127
QF Loss                      4376.8154
VF Loss                      46.741604
Policy Loss                  -1356.5066
Q Predictions Mean           1356.567
Q Predictions Std            1305.5358
Q Predictions Max            4617.6553
Q Predictions Min            681.7818
V Predictions Mean           1353.1069
V Predictions Std            1301.7406
V Predictions Max            4588.977
V Predictions Min            680.7207
Log Pis Mean                 -0.04543773
Log Pis Std                  3.9766803
Log Pis Max                  17.971598
Log Pis Min                  -7.990786
Policy mu Mean               0.06239305
Policy mu Std                0.9122026
Policy mu Max                2.8414156
Policy mu Min                -2.833856
Policy log std Mean          -0.49133205
Policy log std Std           0.28893113
Policy log std Max           -0.055936456
Policy log std Min           -2.9678657
Z mean eval                  1.9103525
Z variance eval              0.079182066
total_rewards                [ 9835.0883486  10242.98875589 10299.72696914 10424.02645012
 10234.71972628 10163.13316062 10502.45548794 10308.4341195
 10134.5280055  10325.00608797]
total_rewards_mean           10247.01071115569
total_rewards_std            172.84582822229805
total_rewards_max            10502.455487940464
total_rewards_min            9835.08834860254
Number of train steps total  1596000
Number of env steps total    4790000
Number of rollouts total     0
Train Time (s)               147.34677468892187
(Previous) Eval Time (s)     20.978184663690627
Sample Time (s)              6.457738631870598
Epoch Time (s)               174.7826979844831
Total Train Time (s)         68423.73816756858
Epoch                        398
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:54:03.196241 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #398 | Epoch Duration: 174.86226391792297
2020-01-13 02:54:03.196374 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #398 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9073935
Z variance train             0.079215325
KL Divergence                48.960293
KL Loss                      4.8960295
QF Loss                      183.23956
VF Loss                      34.27533
Policy Loss                  -1261.4558
Q Predictions Mean           1262.0872
Q Predictions Std            1206.3676
Q Predictions Max            4674.51
Q Predictions Min            671.10754
V Predictions Mean           1264.2981
V Predictions Std            1203.9199
V Predictions Max            4654.2974
V Predictions Min            684.9982
Log Pis Mean                 -0.7786428
Log Pis Std                  3.5198557
Log Pis Max                  11.9752
Log Pis Min                  -7.0705013
Policy mu Mean               0.036928397
Policy mu Std                0.8224587
Policy mu Max                2.5638378
Policy mu Min                -2.84967
Policy log std Mean          -0.46785152
Policy log std Std           0.27113998
Policy log std Max           0.02387768
Policy log std Min           -2.4173791
Z mean eval                  1.9394159
Z variance eval              0.07506261
total_rewards                [10136.97303095 10479.08104253 10388.31105129 10260.4150996
 10305.3330965   9985.18368427 10315.61136304  9919.82697182
 10116.45980959 10180.12083983]
total_rewards_mean           10208.731598941926
total_rewards_std            166.33863752927164
total_rewards_max            10479.081042526643
total_rewards_min            9919.82697181788
Number of train steps total  1600000
Number of env steps total    4802000
Number of rollouts total     0
Train Time (s)               145.57254185900092
(Previous) Eval Time (s)     17.791263420134783
Sample Time (s)              6.505859424825758
Epoch Time (s)               169.86966470396146
Total Train Time (s)         68593.68638642877
Epoch                        399
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:56:53.148063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #399 | Epoch Duration: 169.95157957077026
2020-01-13 02:56:53.148225 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9404914
Z variance train             0.075068824
KL Divergence                49.514652
KL Loss                      4.951465
QF Loss                      298.41324
VF Loss                      95.846375
Policy Loss                  -1362.9908
Q Predictions Mean           1362.7937
Q Predictions Std            1325.5211
Q Predictions Max            4625.2534
Q Predictions Min            689.18164
V Predictions Mean           1368.6948
V Predictions Std            1323.6149
V Predictions Max            4643.391
V Predictions Min            699.0817
Log Pis Mean                 -0.5438384
Log Pis Std                  3.662629
Log Pis Max                  16.383741
Log Pis Min                  -8.572298
Policy mu Mean               0.032556053
Policy mu Std                0.87408143
Policy mu Max                2.653739
Policy mu Min                -2.9973626
Policy log std Mean          -0.47978005
Policy log std Std           0.29913327
Policy log std Max           0.010383248
Policy log std Min           -2.6812658
Z mean eval                  1.8975118
Z variance eval              0.08046272
total_rewards                [10455.7329956  10491.3390127  10625.92697884 10501.68698817
 10494.55973583 10505.56412011 10403.99038304 10378.10642102
 10472.99106497 10446.55331257]
total_rewards_mean           10477.645101285198
total_rewards_std            63.73389472241659
total_rewards_max            10625.926978844653
total_rewards_min            10378.106421021039
Number of train steps total  1604000
Number of env steps total    4814000
Number of rollouts total     0
Train Time (s)               147.54965612711385
(Previous) Eval Time (s)     20.726361530832946
Sample Time (s)              7.856264054309577
Epoch Time (s)               176.13228171225637
Total Train Time (s)         68769.90114028193
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:59:49.372402 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #400 | Epoch Duration: 176.22403979301453
2020-01-13 02:59:49.372601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #400 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8959926
Z variance train             0.08060728
KL Divergence                49.043262
KL Loss                      4.9043264
QF Loss                      268.07703
VF Loss                      54.187744
Policy Loss                  -1392.2711
Q Predictions Mean           1386.0889
Q Predictions Std            1364.6765
Q Predictions Max            4764.547
Q Predictions Min            707.3445
V Predictions Mean           1392.8737
V Predictions Std            1365.1265
V Predictions Max            4758.2
V Predictions Min            711.6903
Log Pis Mean                 -0.34766886
Log Pis Std                  3.823209
Log Pis Max                  16.607677
Log Pis Min                  -8.138903
Policy mu Mean               0.0417417
Policy mu Std                0.85917664
Policy mu Max                2.822535
Policy mu Min                -2.4961216
Policy log std Mean          -0.5044164
Policy log std Std           0.28639013
Policy log std Max           0.0030941367
Policy log std Min           -2.7194276
Z mean eval                  1.8907025
Z variance eval              0.07908176
total_rewards                [10181.13560882 10634.45164651 10583.8271003  10628.47556263
 10380.98344822 10429.38348584 10494.38948414 10508.51010645
 10451.60816255 10658.85153375]
total_rewards_mean           10495.161613920476
total_rewards_std            137.79757237536944
total_rewards_max            10658.851533746281
total_rewards_min            10181.135608824967
Number of train steps total  1608000
Number of env steps total    4826000
Number of rollouts total     0
Train Time (s)               146.24460635427386
(Previous) Eval Time (s)     20.84005969297141
Sample Time (s)              5.436967414338142
Epoch Time (s)               172.5216334615834
Total Train Time (s)         68942.50756613119
Epoch                        401
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:02:41.981393 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #401 | Epoch Duration: 172.60865473747253
2020-01-13 03:02:41.981527 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #401 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8914257
Z variance train             0.07958003
KL Divergence                49.156322
KL Loss                      4.9156322
QF Loss                      144.6893
VF Loss                      71.054504
Policy Loss                  -1442.1516
Q Predictions Mean           1439.4854
Q Predictions Std            1354.0951
Q Predictions Max            4672.2397
Q Predictions Min            654.2663
V Predictions Mean           1445.7979
V Predictions Std            1356.6324
V Predictions Max            4662.3774
V Predictions Min            636.99146
Log Pis Mean                 0.0688279
Log Pis Std                  3.8911655
Log Pis Max                  15.387388
Log Pis Min                  -5.5450206
Policy mu Mean               0.1214571
Policy mu Std                0.9058417
Policy mu Max                2.89713
Policy mu Min                -2.6584604
Policy log std Mean          -0.50110143
Policy log std Std           0.29672113
Policy log std Max           -0.029788017
Policy log std Min           -3.006113
Z mean eval                  1.9087007
Z variance eval              0.04927544
total_rewards                [10020.70742393 10454.5346494   9973.21762765 10294.8074457
 10469.3633284  10253.60824097 10293.83901451 10424.46012263
 10239.88335794 10065.7624949 ]
total_rewards_mean           10249.018370604685
total_rewards_std            169.57398051487638
total_rewards_max            10469.363328402946
total_rewards_min            9973.217627652788
Number of train steps total  1612000
Number of env steps total    4838000
Number of rollouts total     0
Train Time (s)               147.01670192694291
(Previous) Eval Time (s)     17.268064606003463
Sample Time (s)              6.365338065195829
Epoch Time (s)               170.6501045981422
Total Train Time (s)         69113.23715629894
Epoch                        402
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:05:32.715181 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #402 | Epoch Duration: 170.73354125022888
2020-01-13 03:05:32.715357 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9093287
Z variance train             0.04923575
KL Divergence                50.174175
KL Loss                      5.0174174
QF Loss                      130.29462
VF Loss                      37.90901
Policy Loss                  -1413.2888
Q Predictions Mean           1412.3329
Q Predictions Std            1371.0259
Q Predictions Max            4663.105
Q Predictions Min            698.7093
V Predictions Mean           1416.2777
V Predictions Std            1368.8014
V Predictions Max            4666.217
V Predictions Min            705.22375
Log Pis Mean                 0.020787477
Log Pis Std                  3.697312
Log Pis Max                  11.540907
Log Pis Min                  -7.9941416
Policy mu Mean               0.016952919
Policy mu Std                0.92344886
Policy mu Max                2.7234552
Policy mu Min                -2.5282722
Policy log std Mean          -0.50719875
Policy log std Std           0.27393925
Policy log std Max           -0.06504363
Policy log std Min           -2.7799015
Z mean eval                  1.9020351
Z variance eval              0.08188798
total_rewards                [10007.84151399 10614.85266385 10094.26223764 10242.07418013
 10403.6013173  10487.15937296 10377.75813903 10472.34304095
 10439.91042286 10056.50760039]
total_rewards_mean           10319.63104890899
total_rewards_std            196.64491308272758
total_rewards_max            10614.852663852991
total_rewards_min            10007.841513985688
Number of train steps total  1616000
Number of env steps total    4850000
Number of rollouts total     0
Train Time (s)               147.07247551577166
(Previous) Eval Time (s)     20.87780385883525
Sample Time (s)              6.531084469053894
Epoch Time (s)               174.4813638436608
Total Train Time (s)         69288.06970913243
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:08:27.581230 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #403 | Epoch Duration: 174.86558175086975
2020-01-13 03:08:27.581730 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #403 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9019037
Z variance train             0.0818142
KL Divergence                50.639668
KL Loss                      5.0639668
QF Loss                      88.938576
VF Loss                      66.23644
Policy Loss                  -1551.7
Q Predictions Mean           1547.9917
Q Predictions Std            1460.049
Q Predictions Max            4646.807
Q Predictions Min            704.4257
V Predictions Mean           1546.9537
V Predictions Std            1455.52
V Predictions Max            4628.9937
V Predictions Min            708.3448
Log Pis Mean                 0.123206556
Log Pis Std                  4.027325
Log Pis Max                  13.753431
Log Pis Min                  -7.54463
Policy mu Mean               0.116163135
Policy mu Std                0.93766564
Policy mu Max                2.8512459
Policy mu Min                -2.7034023
Policy log std Mean          -0.51527065
Policy log std Std           0.29420364
Policy log std Max           -0.07583785
Policy log std Min           -2.6284375
Z mean eval                  1.9048783
Z variance eval              0.045196317
total_rewards                [ 9853.45148005 10458.6067557  10681.29294056 10422.30578566
  9992.68060252 10487.70317458 10473.59654123 10334.78775473
 10483.45138259 10573.59633811]
total_rewards_mean           10376.147275571167
total_rewards_std            244.22400095114963
total_rewards_max            10681.292940562615
total_rewards_min            9853.451480046451
Number of train steps total  1620000
Number of env steps total    4862000
Number of rollouts total     0
Train Time (s)               147.56863400200382
(Previous) Eval Time (s)     18.257526158355176
Sample Time (s)              5.612033978104591
Epoch Time (s)               171.4381941384636
Total Train Time (s)         69459.62204274116
Epoch                        404
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:11:19.112996 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #404 | Epoch Duration: 171.53094005584717
2020-01-13 03:11:19.113278 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #404 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9035791
Z variance train             0.045097522
KL Divergence                51.89647
KL Loss                      5.189647
QF Loss                      62.448708
VF Loss                      56.872597
Policy Loss                  -1257.701
Q Predictions Mean           1254.8469
Q Predictions Std            1191.9884
Q Predictions Max            4626.693
Q Predictions Min            691.5789
V Predictions Mean           1257.6493
V Predictions Std            1193.6772
V Predictions Max            4629.8423
V Predictions Min            693.3224
Log Pis Mean                 -0.4249233
Log Pis Std                  3.9518464
Log Pis Max                  15.262182
Log Pis Min                  -7.9909487
Policy mu Mean               0.119920574
Policy mu Std                0.8579678
Policy mu Max                2.7288961
Policy mu Min                -2.9017231
Policy log std Mean          -0.47444698
Policy log std Std           0.28718987
Policy log std Max           -0.03533888
Policy log std Min           -2.5285473
Z mean eval                  1.9271549
Z variance eval              0.04545523
total_rewards                [ 9040.36581613 10410.81695893 10068.99932588 10149.08265198
 10351.85605264 10059.15801608 10149.79738909 10524.50109978
 10437.13109981 10131.39816965]
total_rewards_mean           10132.310657996222
total_rewards_std            396.835718402072
total_rewards_max            10524.501099779998
total_rewards_min            9040.365816128613
Number of train steps total  1624000
Number of env steps total    4874000
Number of rollouts total     0
Train Time (s)               145.59316671732813
(Previous) Eval Time (s)     20.78404233790934
Sample Time (s)              6.371390086598694
Epoch Time (s)               172.74859914183617
Total Train Time (s)         69632.66144053452
Epoch                        405
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:14:12.156340 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #405 | Epoch Duration: 173.04278588294983
2020-01-13 03:14:12.156680 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #405 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9306023
Z variance train             0.045355685
KL Divergence                50.717556
KL Loss                      5.071756
QF Loss                      143.01958
VF Loss                      45.46712
Policy Loss                  -1531.0287
Q Predictions Mean           1530.2045
Q Predictions Std            1459.9777
Q Predictions Max            4650.2153
Q Predictions Min            692.61646
V Predictions Mean           1527.9799
V Predictions Std            1455.456
V Predictions Max            4634.5786
V Predictions Min            695.5101
Log Pis Mean                 -0.2509101
Log Pis Std                  3.544971
Log Pis Max                  13.789306
Log Pis Min                  -5.608187
Policy mu Mean               0.06766143
Policy mu Std                0.8921502
Policy mu Max                2.7028346
Policy mu Min                -2.6613083
Policy log std Mean          -0.50934815
Policy log std Std           0.292061
Policy log std Max           0.22581631
Policy log std Min           -2.540585
Z mean eval                  1.9113026
Z variance eval              0.08933032
total_rewards                [ 9761.91476524 10010.41458741 10270.51801116 10328.67489336
 10347.02692754 10356.99700205 10338.74287618 10512.5149663
 10399.43254536 10310.53518988]
total_rewards_mean           10263.677176447924
total_rewards_std            205.91625140606521
total_rewards_max            10512.514966299592
total_rewards_min            9761.914765244146
Number of train steps total  1628000
Number of env steps total    4886000
Number of rollouts total     0
Train Time (s)               146.05503563396633
(Previous) Eval Time (s)     17.530388582963496
Sample Time (s)              6.448921694420278
Epoch Time (s)               170.0343459113501
Total Train Time (s)         69802.78374348581
Epoch                        406
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:17:02.282554 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #406 | Epoch Duration: 170.12565636634827
2020-01-13 03:17:02.282780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9119383
Z variance train             0.089284636
KL Divergence                49.54314
KL Loss                      4.954314
QF Loss                      157.936
VF Loss                      52.6373
Policy Loss                  -1454.8331
Q Predictions Mean           1450.8176
Q Predictions Std            1381.1001
Q Predictions Max            4662.2383
Q Predictions Min            680.4296
V Predictions Mean           1456.5164
V Predictions Std            1381.1368
V Predictions Max            4666.107
V Predictions Min            702.14764
Log Pis Mean                 -0.13694774
Log Pis Std                  4.0394444
Log Pis Max                  19.566591
Log Pis Min                  -7.128259
Policy mu Mean               0.1017443
Policy mu Std                0.88972336
Policy mu Max                4.0167212
Policy mu Min                -3.9662228
Policy log std Mean          -0.4972858
Policy log std Std           0.28805614
Policy log std Max           0.0031924248
Policy log std Min           -2.7353864
Z mean eval                  1.9184656
Z variance eval              0.047562502
total_rewards                [9021.55353495 6900.03137473 9729.35908047 9466.39622991 9685.21852307
 9504.84158563 9458.07763539 9735.17372541 9643.30610432 9683.70311934]
total_rewards_mean           9282.76609132259
total_rewards_std            819.5275435459471
total_rewards_max            9735.173725410787
total_rewards_min            6900.031374726737
Number of train steps total  1632000
Number of env steps total    4898000
Number of rollouts total     0
Train Time (s)               145.95770594710484
(Previous) Eval Time (s)     20.674642940983176
Sample Time (s)              6.458085722755641
Epoch Time (s)               173.09043461084366
Total Train Time (s)         69975.98031010525
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:19:55.481938 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #407 | Epoch Duration: 173.19901204109192
2020-01-13 03:19:55.482072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9198542
Z variance train             0.047561683
KL Divergence                51.408974
KL Loss                      5.1408973
QF Loss                      96.77911
VF Loss                      187.27856
Policy Loss                  -1518.1522
Q Predictions Mean           1517.7821
Q Predictions Std            1472.9191
Q Predictions Max            4738.781
Q Predictions Min            693.8588
V Predictions Mean           1525.6038
V Predictions Std            1474.5701
V Predictions Max            4770.2017
V Predictions Min            694.8026
Log Pis Mean                 -0.6332035
Log Pis Std                  3.698829
Log Pis Max                  14.706481
Log Pis Min                  -8.317611
Policy mu Mean               0.06600802
Policy mu Std                0.86539733
Policy mu Max                3.2599237
Policy mu Min                -3.059905
Policy log std Mean          -0.50233513
Policy log std Std           0.29137227
Policy log std Max           -0.05104947
Policy log std Min           -2.734068
Z mean eval                  1.9040403
Z variance eval              0.03472104
total_rewards                [10152.06355342 10122.14515676 10233.30280918 10111.63739746
 10521.9490896  10700.99210519 10579.2912821  10337.13915585
 10645.89598697 10548.57732447]
total_rewards_mean           10395.299386100949
total_rewards_std            217.60067023640474
total_rewards_max            10700.992105191368
total_rewards_min            10111.637397455697
Number of train steps total  1636000
Number of env steps total    4910000
Number of rollouts total     0
Train Time (s)               144.6892712879926
(Previous) Eval Time (s)     20.71940801013261
Sample Time (s)              6.486786783207208
Epoch Time (s)               171.89546608133242
Total Train Time (s)         70147.95798850898
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:22:47.462829 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #408 | Epoch Duration: 171.9806604385376
2020-01-13 03:22:47.462966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #408 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9032748
Z variance train             0.034642346
KL Divergence                51.761208
KL Loss                      5.1761208
QF Loss                      104.74103
VF Loss                      95.21057
Policy Loss                  -1260.4647
Q Predictions Mean           1259.0157
Q Predictions Std            1239.2526
Q Predictions Max            4615.688
Q Predictions Min            687.251
V Predictions Mean           1264.0597
V Predictions Std            1241.2789
V Predictions Max            4634.2075
V Predictions Min            688.8315
Log Pis Mean                 -0.40070802
Log Pis Std                  3.6125154
Log Pis Max                  13.137016
Log Pis Min                  -6.237115
Policy mu Mean               0.10500238
Policy mu Std                0.852738
Policy mu Max                3.1923788
Policy mu Min                -2.959377
Policy log std Mean          -0.47051883
Policy log std Std           0.27973184
Policy log std Max           -0.061506122
Policy log std Min           -2.6840854
Z mean eval                  1.8972183
Z variance eval              0.060329385
total_rewards                [10195.38218519 10174.75402601 10508.35572272 10060.4427909
 10131.16641144 10338.56199815  2537.62374708 10559.44402788
 10329.98891393  9897.65084255]
total_rewards_mean           9473.337066583337
total_rewards_std            2319.661342378474
total_rewards_max            10559.444027883215
total_rewards_min            2537.6237470791493
Number of train steps total  1640000
Number of env steps total    4922000
Number of rollouts total     0
Train Time (s)               149.62660721875727
(Previous) Eval Time (s)     20.683767335955054
Sample Time (s)              6.628593503963202
Epoch Time (s)               176.93896805867553
Total Train Time (s)         70324.97663286468
Epoch                        409
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:25:44.484660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #409 | Epoch Duration: 177.02158951759338
2020-01-13 03:25:44.484827 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #409 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.898361
Z variance train             0.06061256
KL Divergence                50.95791
KL Loss                      5.095791
QF Loss                      580.7645
VF Loss                      47.348183
Policy Loss                  -1438.6224
Q Predictions Mean           1437.777
Q Predictions Std            1358.7539
Q Predictions Max            4689.0454
Q Predictions Min            693.52045
V Predictions Mean           1438.1655
V Predictions Std            1355.6604
V Predictions Max            4654.231
V Predictions Min            688.8895
Log Pis Mean                 0.0021902397
Log Pis Std                  3.784885
Log Pis Max                  15.419238
Log Pis Min                  -7.8187304
Policy mu Mean               0.04670159
Policy mu Std                0.90317976
Policy mu Max                3.212234
Policy mu Min                -2.8004475
Policy log std Mean          -0.5012701
Policy log std Std           0.28457695
Policy log std Max           0.04518783
Policy log std Min           -2.761546
Z mean eval                  1.9216158
Z variance eval              0.06236539
total_rewards                [10022.64123292 10038.89546783 10047.19971788 10186.22987949
 10238.73484746 10241.2308908  10461.76211658 10444.33594291
 10288.71633908  4367.73002242]
total_rewards_mean           9633.747645737843
total_rewards_std            1761.5105611830609
total_rewards_max            10461.762116584921
total_rewards_min            4367.730022415902
Number of train steps total  1644000
Number of env steps total    4934000
Number of rollouts total     0
Train Time (s)               146.64515613717958
(Previous) Eval Time (s)     20.76957193063572
Sample Time (s)              5.4242078815586865
Epoch Time (s)               172.838935949374
Total Train Time (s)         70497.90971040679
Epoch                        410
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:28:37.419859 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #410 | Epoch Duration: 172.9349136352539
2020-01-13 03:28:37.419993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #410 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9217046
Z variance train             0.062167536
KL Divergence                50.92323
KL Loss                      5.092323
QF Loss                      175.8577
VF Loss                      58.330154
Policy Loss                  -1362.3218
Q Predictions Mean           1361.1067
Q Predictions Std            1339.69
Q Predictions Max            4733.2837
Q Predictions Min            695.8612
V Predictions Mean           1362.2195
V Predictions Std            1333.0293
V Predictions Max            4724.6846
V Predictions Min            700.52045
Log Pis Mean                 -0.3443896
Log Pis Std                  3.6539109
Log Pis Max                  10.355797
Log Pis Min                  -8.437069
Policy mu Mean               0.09024197
Policy mu Std                0.8729348
Policy mu Max                2.748036
Policy mu Min                -2.7594228
Policy log std Mean          -0.48251942
Policy log std Std           0.28990763
Policy log std Max           -0.06692338
Policy log std Min           -2.789962
Z mean eval                  1.8893859
Z variance eval              0.059290547
total_rewards                [10137.45131425 10207.89222409 10451.94323063 10088.34109845
 10351.68973896 10551.80174229 10329.90292221 10122.36233376
 10376.69305231 10847.73137168]
total_rewards_mean           10346.580902862454
total_rewards_std            220.34316417667227
total_rewards_max            10847.731371677062
total_rewards_min            10088.34109844847
Number of train steps total  1648000
Number of env steps total    4946000
Number of rollouts total     0
Train Time (s)               146.55383007135242
(Previous) Eval Time (s)     17.470764236990362
Sample Time (s)              6.364544781856239
Epoch Time (s)               170.38913909019902
Total Train Time (s)         70668.39760744246
Epoch                        411
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:31:27.914958 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #411 | Epoch Duration: 170.4948501586914
2020-01-13 03:31:27.915147 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #411 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8896393
Z variance train             0.05889716
KL Divergence                49.90686
KL Loss                      4.990686
QF Loss                      69.42998
VF Loss                      34.356316
Policy Loss                  -1242.4695
Q Predictions Mean           1242.7384
Q Predictions Std            1214.2166
Q Predictions Max            4677.659
Q Predictions Min            675.4875
V Predictions Mean           1243.9016
V Predictions Std            1213.8802
V Predictions Max            4675.113
V Predictions Min            686.46515
Log Pis Mean                 -0.457246
Log Pis Std                  3.6575263
Log Pis Max                  12.163237
Log Pis Min                  -7.83512
Policy mu Mean               0.09167
Policy mu Std                0.84581834
Policy mu Max                2.6422222
Policy mu Min                -2.52305
Policy log std Mean          -0.47864732
Policy log std Std           0.2753019
Policy log std Max           -0.06319037
Policy log std Min           -2.9306457
Z mean eval                  1.9081268
Z variance eval              0.055146944
total_rewards                [ 9848.33846484 10292.50883623 10028.20097492 10089.21525888
  9517.09762357 10369.75066999 10026.41766858 10370.56570939
 10027.27065446  9888.68974276]
total_rewards_mean           10045.805560361478
total_rewards_std            248.4746601945126
total_rewards_max            10370.565709386727
total_rewards_min            9517.097623573798
Number of train steps total  1652000
Number of env steps total    4958000
Number of rollouts total     0
Train Time (s)               147.36103295581415
(Previous) Eval Time (s)     20.875341047067195
Sample Time (s)              6.434187808539718
Epoch Time (s)               174.67056181142107
Total Train Time (s)         70843.17032394651
Epoch                        412
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:34:22.693947 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #412 | Epoch Duration: 174.77866458892822
2020-01-13 03:34:22.694092 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #412 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9079773
Z variance train             0.05508669
KL Divergence                50.664608
KL Loss                      5.066461
QF Loss                      136.69135
VF Loss                      113.4421
Policy Loss                  -1325.5526
Q Predictions Mean           1324.5194
Q Predictions Std            1288.1747
Q Predictions Max            4674.022
Q Predictions Min            659.9891
V Predictions Mean           1331.2811
V Predictions Std            1290.5143
V Predictions Max            4694.6235
V Predictions Min            676.55066
Log Pis Mean                 -0.6195383
Log Pis Std                  3.7897599
Log Pis Max                  14.223317
Log Pis Min                  -12.076387
Policy mu Mean               0.03737031
Policy mu Std                0.87058735
Policy mu Max                3.2809937
Policy mu Min                -3.1132305
Policy log std Mean          -0.48413816
Policy log std Std           0.27450758
Policy log std Max           0.08145416
Policy log std Min           -2.9153934
Z mean eval                  1.8864071
Z variance eval              0.051914968
total_rewards                [10580.00491185 10118.82530119 10666.94815985 10183.22600935
 10531.34490025 10748.34644654 10324.94926125 10384.12463992
 10712.05620115 10317.45854227]
total_rewards_mean           10456.728437362563
total_rewards_std            211.23580225983247
total_rewards_max            10748.346446542624
total_rewards_min            10118.825301186498
Number of train steps total  1656000
Number of env steps total    4970000
Number of rollouts total     0
Train Time (s)               148.456434473861
(Previous) Eval Time (s)     20.48492588987574
Sample Time (s)              6.3358022519387305
Epoch Time (s)               175.27716261567548
Total Train Time (s)         71018.52901811246
Epoch                        413
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:37:18.056480 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #413 | Epoch Duration: 175.36228942871094
2020-01-13 03:37:18.056617 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8858938
Z variance train             0.051822376
KL Divergence                50.775673
KL Loss                      5.0775676
QF Loss                      4485.117
VF Loss                      64.52556
Policy Loss                  -1490.6953
Q Predictions Mean           1491.9856
Q Predictions Std            1442.7046
Q Predictions Max            4629.524
Q Predictions Min            670.9963
V Predictions Mean           1494.7422
V Predictions Std            1436.3093
V Predictions Max            4623.161
V Predictions Min            689.27954
Log Pis Mean                 -0.32219306
Log Pis Std                  3.6351945
Log Pis Max                  14.979469
Log Pis Min                  -8.619598
Policy mu Mean               0.065692045
Policy mu Std                0.8824567
Policy mu Max                3.0950818
Policy mu Min                -2.8651373
Policy log std Mean          -0.4962966
Policy log std Std           0.28560624
Policy log std Max           0.051529706
Policy log std Min           -2.706001
Z mean eval                  1.9047245
Z variance eval              0.049020458
total_rewards                [10072.19847103 10370.01947789 10360.97302424 10315.86294732
 10229.49907985 10288.96337508 10559.46132728 10265.31797594
 10351.71114117 10360.88567238]
total_rewards_mean           10317.489249217893
total_rewards_std            117.34700059451615
total_rewards_max            10559.461327275943
total_rewards_min            10072.19847102722
Number of train steps total  1660000
Number of env steps total    4982000
Number of rollouts total     0
Train Time (s)               146.4452155227773
(Previous) Eval Time (s)     17.613607332110405
Sample Time (s)              6.5380096337758005
Epoch Time (s)               170.5968324886635
Total Train Time (s)         71189.20772393327
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:40:08.742268 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #414 | Epoch Duration: 170.68549585342407
2020-01-13 03:40:08.742588 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #414 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9030335
Z variance train             0.049007714
KL Divergence                51.117786
KL Loss                      5.1117787
QF Loss                      4479.4785
VF Loss                      88.2288
Policy Loss                  -1353.4705
Q Predictions Mean           1351.0798
Q Predictions Std            1318.5839
Q Predictions Max            4616.165
Q Predictions Min            683.39874
V Predictions Mean           1355.4924
V Predictions Std            1323.6558
V Predictions Max            4643.148
V Predictions Min            679.95953
Log Pis Mean                 -0.33871046
Log Pis Std                  3.7094655
Log Pis Max                  13.109023
Log Pis Min                  -7.0882816
Policy mu Mean               0.028483475
Policy mu Std                0.8574167
Policy mu Max                3.1066918
Policy mu Min                -2.6727235
Policy log std Mean          -0.49156967
Policy log std Std           0.31515914
Policy log std Max           0.040480673
Policy log std Min           -2.799239
Z mean eval                  1.9117801
Z variance eval              0.047973588
total_rewards                [10077.03456934 10158.32913838 10236.51563998  9917.54576903
 10272.09990461 10564.78818909 10304.47774205 10251.84277101
 10334.63319189 10392.38527851]
total_rewards_mean           10250.965219388254
total_rewards_std            167.0348732766465
total_rewards_max            10564.788189088142
total_rewards_min            9917.545769028582
Number of train steps total  1664000
Number of env steps total    4994000
Number of rollouts total     0
Train Time (s)               145.84422278031707
(Previous) Eval Time (s)     20.85423147585243
Sample Time (s)              6.639511271379888
Epoch Time (s)               173.3379655275494
Total Train Time (s)         71362.6301852935
Epoch                        415
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:43:02.164233 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #415 | Epoch Duration: 173.42139196395874
2020-01-13 03:43:02.164369 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9090321
Z variance train             0.048072636
KL Divergence                49.95606
KL Loss                      4.995606
QF Loss                      318.5901
VF Loss                      28.482796
Policy Loss                  -1249.6987
Q Predictions Mean           1249.278
Q Predictions Std            1200.3038
Q Predictions Max            4674.6636
Q Predictions Min            678.27954
V Predictions Mean           1251.0793
V Predictions Std            1199.079
V Predictions Max            4694.9233
V Predictions Min            681.37836
Log Pis Mean                 -0.37968627
Log Pis Std                  3.4127333
Log Pis Max                  17.227453
Log Pis Min                  -6.808982
Policy mu Mean               0.07913401
Policy mu Std                0.85954875
Policy mu Max                2.8972535
Policy mu Min                -3.759299
Policy log std Mean          -0.47546014
Policy log std Std           0.2672964
Policy log std Max           0.061985493
Policy log std Min           -2.9416418
Z mean eval                  1.9202328
Z variance eval              0.09039552
total_rewards                [ 9993.91765485 10566.68320112 10196.55062133 10384.13437764
 10134.2606386  10565.42222314 10461.37687632 10085.54778094
 10337.67582365 10389.53666379]
total_rewards_mean           10311.510586137098
total_rewards_std            189.9075533160327
total_rewards_max            10566.683201115393
total_rewards_min            9993.91765484697
Number of train steps total  1668000
Number of env steps total    5006000
Number of rollouts total     0
Train Time (s)               145.22856312105432
(Previous) Eval Time (s)     17.817012610845268
Sample Time (s)              6.609399145934731
Epoch Time (s)               169.65497487783432
Total Train Time (s)         71532.36522533651
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:45:51.903394 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #416 | Epoch Duration: 169.73891472816467
2020-01-13 03:45:51.903576 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #416 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9192501
Z variance train             0.09033766
KL Divergence                49.96923
KL Loss                      4.996923
QF Loss                      217.94226
VF Loss                      67.3744
Policy Loss                  -1413.004
Q Predictions Mean           1409.77
Q Predictions Std            1384.7948
Q Predictions Max            4738.61
Q Predictions Min            670.6586
V Predictions Mean           1416.2336
V Predictions Std            1379.1298
V Predictions Max            4704.6855
V Predictions Min            683.3442
Log Pis Mean                 -0.4071174
Log Pis Std                  3.849716
Log Pis Max                  19.150265
Log Pis Min                  -6.771483
Policy mu Mean               0.05351563
Policy mu Std                0.8955893
Policy mu Max                2.9305935
Policy mu Min                -2.8508265
Policy log std Mean          -0.49699935
Policy log std Std           0.29463968
Policy log std Max           -0.08809477
Policy log std Min           -2.9315991
Z mean eval                  1.8951561
Z variance eval              0.052683067
total_rewards                [ 9727.27015001 10176.86886251 10121.20768424  9867.93726966
 10190.17784999 10019.09770919 10055.09683776 10108.17784449
 10195.10561784 10183.04586313]
total_rewards_mean           10064.398568882605
total_rewards_std            148.04280162705882
total_rewards_max            10195.105617840225
total_rewards_min            9727.2701500129
Number of train steps total  1672000
Number of env steps total    5018000
Number of rollouts total     0
Train Time (s)               145.67443236894906
(Previous) Eval Time (s)     20.715956420172006
Sample Time (s)              6.584896146319807
Epoch Time (s)               172.97528493544087
Total Train Time (s)         71705.42732709227
Epoch                        417
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:48:44.968321 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #417 | Epoch Duration: 173.06461453437805
2020-01-13 03:48:44.968467 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #417 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8953774
Z variance train             0.052962057
KL Divergence                49.511055
KL Loss                      4.9511056
QF Loss                      147.67294
VF Loss                      52.705566
Policy Loss                  -1439.3813
Q Predictions Mean           1438.3054
Q Predictions Std            1395.9504
Q Predictions Max            4737.3696
Q Predictions Min            680.9345
V Predictions Mean           1436.2761
V Predictions Std            1387.0684
V Predictions Max            4721.2246
V Predictions Min            682.11176
Log Pis Mean                 -0.29648617
Log Pis Std                  3.687315
Log Pis Max                  13.249498
Log Pis Min                  -8.209368
Policy mu Mean               0.10772133
Policy mu Std                0.8801426
Policy mu Max                2.6569192
Policy mu Min                -2.8670819
Policy log std Mean          -0.49844554
Policy log std Std           0.30773842
Policy log std Max           -0.034392744
Policy log std Min           -3.170532
Z mean eval                  1.895586
Z variance eval              0.088887885
total_rewards                [10088.34513316 10077.87525678 10521.53872767 10389.75032566
 10083.67515606 10197.44777532 10502.97726864 10217.50387416
 10444.2439429  10459.48073907]
total_rewards_mean           10298.283819942477
total_rewards_std            174.01191359615746
total_rewards_max            10521.538727670284
total_rewards_min            10077.875256780952
Number of train steps total  1676000
Number of env steps total    5030000
Number of rollouts total     0
Train Time (s)               145.51977327885106
(Previous) Eval Time (s)     20.817774121183902
Sample Time (s)              6.534645848441869
Epoch Time (s)               172.87219324847683
Total Train Time (s)         71878.37664187187
Epoch                        418
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:51:37.920300 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #418 | Epoch Duration: 172.95173263549805
2020-01-13 03:51:37.920431 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #418 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8945484
Z variance train             0.088657215
KL Divergence                48.90981
KL Loss                      4.890981
QF Loss                      110.48957
VF Loss                      58.332558
Policy Loss                  -1344.0865
Q Predictions Mean           1341.951
Q Predictions Std            1320.4264
Q Predictions Max            4679.668
Q Predictions Min            695.7211
V Predictions Mean           1342.4121
V Predictions Std            1314.1053
V Predictions Max            4659.051
V Predictions Min            697.92316
Log Pis Mean                 -0.21328449
Log Pis Std                  3.8451986
Log Pis Max                  20.92426
Log Pis Min                  -9.538202
Policy mu Mean               0.08821279
Policy mu Std                0.8951096
Policy mu Max                3.0155115
Policy mu Min                -3.3716512
Policy log std Mean          -0.48944154
Policy log std Std           0.28181142
Policy log std Max           -0.0489676
Policy log std Min           -2.5961473
Z mean eval                  1.9051679
Z variance eval              0.05230831
total_rewards                [10416.77257356 10656.82271874 10457.33151102 10798.62037093
 10824.28035009 10887.39538031 10300.35000963 10763.71902259
 10827.9754278  10887.51777466]
total_rewards_mean           10682.078513932396
total_rewards_std            203.31446523542408
total_rewards_max            10887.517774659673
total_rewards_min            10300.3500096262
Number of train steps total  1680000
Number of env steps total    5042000
Number of rollouts total     0
Train Time (s)               146.3434685477987
(Previous) Eval Time (s)     20.63211562903598
Sample Time (s)              6.596232309937477
Epoch Time (s)               173.57181648677215
Total Train Time (s)         72052.0823740419
Epoch                        419
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:54:31.648677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #419 | Epoch Duration: 173.72810888290405
2020-01-13 03:54:31.648967 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #419 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9046484
Z variance train             0.05262629
KL Divergence                49.78643
KL Loss                      4.978643
QF Loss                      120.057945
VF Loss                      71.24375
Policy Loss                  -1300.93
Q Predictions Mean           1299.4507
Q Predictions Std            1281.3684
Q Predictions Max            4729.4883
Q Predictions Min            688.50275
V Predictions Mean           1302.5768
V Predictions Std            1278.6549
V Predictions Max            4696.3623
V Predictions Min            688.43896
Log Pis Mean                 -0.56312174
Log Pis Std                  3.4269521
Log Pis Max                  11.639732
Log Pis Min                  -6.4594936
Policy mu Mean               -0.01335979
Policy mu Std                0.86223793
Policy mu Max                2.7800672
Policy mu Min                -2.7978168
Policy log std Mean          -0.4914458
Policy log std Std           0.27327588
Policy log std Max           -0.065935045
Policy log std Min           -3.060028
Z mean eval                  1.9179713
Z variance eval              0.054015595
total_rewards                [10254.34737091 10511.01109638 10620.1810199  10533.99846966
 10650.14811662 10500.47665591 10726.56947747 10432.80855638
 10542.22862795 10795.45072685]
total_rewards_mean           10556.722011803544
total_rewards_std            145.38206802569715
total_rewards_max            10795.450726851666
total_rewards_min            10254.347370908674
Number of train steps total  1684000
Number of env steps total    5054000
Number of rollouts total     0
Train Time (s)               146.03571323072538
(Previous) Eval Time (s)     20.81830655504018
Sample Time (s)              8.621596432756633
Epoch Time (s)               175.4756162185222
Total Train Time (s)         72227.6696280567
Epoch                        420
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:57:27.223142 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #420 | Epoch Duration: 175.57396984100342
2020-01-13 03:57:27.223279 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9196889
Z variance train             0.05403748
KL Divergence                50.20552
KL Loss                      5.020552
QF Loss                      106.13934
VF Loss                      79.413086
Policy Loss                  -1275.3733
Q Predictions Mean           1271.3417
Q Predictions Std            1239.26
Q Predictions Max            4706.5996
Q Predictions Min            688.83923
V Predictions Mean           1270.0295
V Predictions Std            1234.7999
V Predictions Max            4698.298
V Predictions Min            685.8922
Log Pis Mean                 -0.540437
Log Pis Std                  3.5205674
Log Pis Max                  12.268975
Log Pis Min                  -6.8160996
Policy mu Mean               0.066494934
Policy mu Std                0.8388445
Policy mu Max                3.4995947
Policy mu Min                -2.7597845
Policy log std Mean          -0.48797974
Policy log std Std           0.29075852
Policy log std Max           -0.008509815
Policy log std Min           -2.7096539
Z mean eval                  1.9067341
Z variance eval              0.04999695
total_rewards                [10333.45146788 10611.68770626 10887.40679357 10793.68170566
 10623.99611504 10718.42673641 10846.21095839 10612.01032177
 10341.50779513 10583.14073054]
total_rewards_mean           10635.152033065577
total_rewards_std            179.27927390153852
total_rewards_max            10887.406793573924
total_rewards_min            10333.451467876517
Number of train steps total  1688000
Number of env steps total    5066000
Number of rollouts total     0
Train Time (s)               147.33268348500133
(Previous) Eval Time (s)     20.714878904633224
Sample Time (s)              6.3484950377605855
Epoch Time (s)               174.39605742739514
Total Train Time (s)         72402.14744600747
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:00:21.704058 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #421 | Epoch Duration: 174.48068380355835
2020-01-13 04:00:21.704192 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #421 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9034961
Z variance train             0.049895417
KL Divergence                50.50301
KL Loss                      5.050301
QF Loss                      107.02425
VF Loss                      95.32562
Policy Loss                  -1361.4302
Q Predictions Mean           1359.0994
Q Predictions Std            1310.4183
Q Predictions Max            4746.247
Q Predictions Min            664.00146
V Predictions Mean           1362.4174
V Predictions Std            1311.7568
V Predictions Max            4756.7393
V Predictions Min            651.03265
Log Pis Mean                 -0.13518824
Log Pis Std                  3.959503
Log Pis Max                  17.24668
Log Pis Min                  -8.73677
Policy mu Mean               0.049543116
Policy mu Std                0.9002575
Policy mu Max                3.225898
Policy mu Min                -3.286909
Policy log std Mean          -0.4933783
Policy log std Std           0.27321997
Policy log std Max           -0.043605924
Policy log std Min           -2.8751194
Z mean eval                  1.8832439
Z variance eval              0.08442445
total_rewards                [10032.52220915 10406.20459433 10648.18329795 10845.52407724
 10506.48368447 10312.50778881 10656.80287969 10678.32437418
 10810.86886657 10878.07362057]
total_rewards_mean           10577.549539296473
total_rewards_std            252.92294044922812
total_rewards_max            10878.073620570245
total_rewards_min            10032.522209152547
Number of train steps total  1692000
Number of env steps total    5078000
Number of rollouts total     0
Train Time (s)               146.9567560260184
(Previous) Eval Time (s)     20.609389916993678
Sample Time (s)              6.396866306196898
Epoch Time (s)               173.963012249209
Total Train Time (s)         72576.19756108476
Epoch                        422
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:03:15.757486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #422 | Epoch Duration: 174.05319356918335
2020-01-13 04:03:15.757621 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #422 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8823969
Z variance train             0.084244385
KL Divergence                49.655647
KL Loss                      4.9655647
QF Loss                      156.62694
VF Loss                      118.66877
Policy Loss                  -1404.0399
Q Predictions Mean           1400.989
Q Predictions Std            1371.9249
Q Predictions Max            4703.492
Q Predictions Min            665.93884
V Predictions Mean           1400.9017
V Predictions Std            1362.0557
V Predictions Max            4686.586
V Predictions Min            675.0156
Log Pis Mean                 -0.6697594
Log Pis Std                  3.7378368
Log Pis Max                  14.782316
Log Pis Min                  -6.591645
Policy mu Mean               0.01472953
Policy mu Std                0.86166537
Policy mu Max                3.5941627
Policy mu Min                -2.6805322
Policy log std Mean          -0.49515995
Policy log std Std           0.29295358
Policy log std Max           0.0014413297
Policy log std Min           -2.9152918
Z mean eval                  1.8961376
Z variance eval              0.11275921
total_rewards                [ 9809.26084644 10281.70338736 10397.46283387 10173.8047025
 10145.81597742 10202.16503894 10150.49236571 10174.65949614
 10302.74507946 10063.77433644]
total_rewards_mean           10170.188406427493
total_rewards_std            150.09687150024817
total_rewards_max            10397.462833867252
total_rewards_min            9809.260846436482
Number of train steps total  1696000
Number of env steps total    5090000
Number of rollouts total     0
Train Time (s)               147.9545729327947
(Previous) Eval Time (s)     21.001318227965385
Sample Time (s)              6.574464097153395
Epoch Time (s)               175.53035525791347
Total Train Time (s)         72751.81169264344
Epoch                        423
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:06:11.375543 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #423 | Epoch Duration: 175.61781120300293
2020-01-13 04:06:11.375723 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #423 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.894201
Z variance train             0.112690076
KL Divergence                49.22386
KL Loss                      4.922386
QF Loss                      327.42172
VF Loss                      73.52609
Policy Loss                  -1551.0044
Q Predictions Mean           1543.9172
Q Predictions Std            1468.678
Q Predictions Max            4798.392
Q Predictions Min            691.71246
V Predictions Mean           1551.2965
V Predictions Std            1465.6459
V Predictions Max            4791.703
V Predictions Min            702.4459
Log Pis Mean                 -0.07596585
Log Pis Std                  4.229339
Log Pis Max                  23.620754
Log Pis Min                  -8.451209
Policy mu Mean               0.031022834
Policy mu Std                0.92968464
Policy mu Max                3.2298107
Policy mu Min                -3.572475
Policy log std Mean          -0.52026385
Policy log std Std           0.29819816
Policy log std Max           -0.049028724
Policy log std Min           -2.729099
Z mean eval                  1.9062674
Z variance eval              0.107914865
total_rewards                [10342.09043922 10620.17305676 10544.79981012 10565.63469913
 10627.95122393 10722.13909673 10739.58433593 10285.65310691
 10383.67995529 10773.05959156]
total_rewards_mean           10560.476531559934
total_rewards_std            163.17850744769967
total_rewards_max            10773.059591562493
total_rewards_min            10285.653106913234
Number of train steps total  1700000
Number of env steps total    5102000
Number of rollouts total     0
Train Time (s)               145.97968639899045
(Previous) Eval Time (s)     21.007165275048465
Sample Time (s)              6.403328616637737
Epoch Time (s)               173.39018029067665
Total Train Time (s)         72925.28572511999
Epoch                        424
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:09:04.852073 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #424 | Epoch Duration: 173.4762237071991
2020-01-13 04:09:04.852206 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9078194
Z variance train             0.108356334
KL Divergence                49.100407
KL Loss                      4.910041
QF Loss                      171.79646
VF Loss                      68.39865
Policy Loss                  -1514.0137
Q Predictions Mean           1512.9221
Q Predictions Std            1467.0681
Q Predictions Max            4695.462
Q Predictions Min            695.8809
V Predictions Mean           1509.7793
V Predictions Std            1459.8679
V Predictions Max            4678.2925
V Predictions Min            697.9403
Log Pis Mean                 -0.33023864
Log Pis Std                  4.071907
Log Pis Max                  15.026672
Log Pis Min                  -7.3767443
Policy mu Mean               0.073474
Policy mu Std                0.8790862
Policy mu Max                2.777174
Policy mu Min                -2.7942383
Policy log std Mean          -0.50430393
Policy log std Std           0.2945523
Policy log std Max           -0.051397145
Policy log std Min           -2.7429802
Z mean eval                  1.8830004
Z variance eval              0.07587813
total_rewards                [9780.32830344 9533.79953125 9794.37508154 9435.71211414 5882.20342252
 8812.7479142  9089.89911379 9788.63869989 9645.69092619 9749.88054792]
total_rewards_mean           9151.327565488007
total_rewards_std            1133.6101621210091
total_rewards_max            9794.375081542148
total_rewards_min            5882.20342252042
Number of train steps total  1704000
Number of env steps total    5114000
Number of rollouts total     0
Train Time (s)               145.18037056317553
(Previous) Eval Time (s)     20.70946630835533
Sample Time (s)              6.477448559831828
Epoch Time (s)               172.3672854313627
Total Train Time (s)         73097.72871010425
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:11:57.297420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #425 | Epoch Duration: 172.4451162815094
2020-01-13 04:11:57.297552 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8817803
Z variance train             0.07568092
KL Divergence                48.78075
KL Loss                      4.878075
QF Loss                      92.53147
VF Loss                      57.096195
Policy Loss                  -1452.8613
Q Predictions Mean           1449.2374
Q Predictions Std            1384.9773
Q Predictions Max            4741.1743
Q Predictions Min            663.6585
V Predictions Mean           1455.1782
V Predictions Std            1382.9597
V Predictions Max            4691.38
V Predictions Min            679.9805
Log Pis Mean                 -0.0023521483
Log Pis Std                  3.9969285
Log Pis Max                  13.569023
Log Pis Min                  -7.1639566
Policy mu Mean               0.08742782
Policy mu Std                0.9242485
Policy mu Max                3.2683961
Policy mu Min                -2.5247812
Policy log std Mean          -0.50161725
Policy log std Std           0.31714454
Policy log std Max           -0.0070199966
Policy log std Min           -2.8351846
Z mean eval                  1.8815165
Z variance eval              0.05259949
total_rewards                [10743.0611087  11044.86549384 10936.61725261 10889.41037995
 10719.67192232 10757.91020471 11069.61288059 10649.83768015
 10655.7289245  10802.4977244 ]
total_rewards_mean           10826.921357176443
total_rewards_std            143.83893871685893
total_rewards_max            11069.61288058858
total_rewards_min            10649.83768014959
Number of train steps total  1708000
Number of env steps total    5126000
Number of rollouts total     0
Train Time (s)               146.02187874075025
(Previous) Eval Time (s)     20.964037926401943
Sample Time (s)              6.386199675966054
Epoch Time (s)               173.37211634311825
Total Train Time (s)         73271.19776715711
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:14:50.769246 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #426 | Epoch Duration: 173.47160005569458
2020-01-13 04:14:50.769384 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #426 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8810203
Z variance train             0.05242799
KL Divergence                50.42947
KL Loss                      5.0429473
QF Loss                      12615.893
VF Loss                      78.05677
Policy Loss                  -1382.4568
Q Predictions Mean           1379.1156
Q Predictions Std            1281.0632
Q Predictions Max            4711.8535
Q Predictions Min            675.17883
V Predictions Mean           1385.1665
V Predictions Std            1278.4944
V Predictions Max            4703.565
V Predictions Min            692.48114
Log Pis Mean                 -0.0261468
Log Pis Std                  4.12001
Log Pis Max                  14.686729
Log Pis Min                  -7.691976
Policy mu Mean               0.06707336
Policy mu Std                0.9057575
Policy mu Max                2.9326742
Policy mu Min                -3.0936062
Policy log std Mean          -0.5051878
Policy log std Std           0.2848545
Policy log std Max           -0.08872169
Policy log std Min           -2.587383
Z mean eval                  1.882745
Z variance eval              0.084159344
total_rewards                [ 9899.00211365 10727.31462526 10428.35441824 10260.84465061
 10528.27344507 10556.55665729 10210.91577309 10375.40738054
 10009.64821855 10047.56173905]
total_rewards_mean           10304.387902135357
total_rewards_std            253.1391206950038
total_rewards_max            10727.314625262055
total_rewards_min            9899.002113652292
Number of train steps total  1712000
Number of env steps total    5138000
Number of rollouts total     0
Train Time (s)               147.19543016003445
(Previous) Eval Time (s)     20.69324969733134
Sample Time (s)              6.390401181764901
Epoch Time (s)               174.2790810391307
Total Train Time (s)         73445.56434388366
Epoch                        427
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:17:45.138911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #427 | Epoch Duration: 174.3694293498993
2020-01-13 04:17:45.139049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8813183
Z variance train             0.0848428
KL Divergence                50.271935
KL Loss                      5.0271935
QF Loss                      106.22778
VF Loss                      81.139114
Policy Loss                  -1438.2771
Q Predictions Mean           1436.7894
Q Predictions Std            1376.5328
Q Predictions Max            4728.0273
Q Predictions Min            694.3598
V Predictions Mean           1436.936
V Predictions Std            1380.125
V Predictions Max            4729.0063
V Predictions Min            693.0442
Log Pis Mean                 -0.36538562
Log Pis Std                  3.8452222
Log Pis Max                  14.96969
Log Pis Min                  -8.22176
Policy mu Mean               0.035875197
Policy mu Std                0.8541421
Policy mu Max                2.7181063
Policy mu Min                -2.8269384
Policy log std Mean          -0.48820877
Policy log std Std           0.29766077
Policy log std Max           0.07099354
Policy log std Min           -3.0396955
Z mean eval                  1.897753
Z variance eval              0.07532557
total_rewards                [10353.99949639 10814.12189332 10590.37630034 10602.00137884
 10570.45143868 10389.29006195 10817.77317937 10686.25663023
 10846.390428   10727.52924142]
total_rewards_mean           10639.819004853196
total_rewards_std            163.61987422745588
total_rewards_max            10846.390427995426
total_rewards_min            10353.999496387021
Number of train steps total  1716000
Number of env steps total    5150000
Number of rollouts total     0
Train Time (s)               145.45114495698363
(Previous) Eval Time (s)     17.679213162045926
Sample Time (s)              6.564122166018933
Epoch Time (s)               169.69448028504848
Total Train Time (s)         73615.35480933543
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:20:34.954350 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #428 | Epoch Duration: 169.8151569366455
2020-01-13 04:20:34.954678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #428 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8977578
Z variance train             0.075260974
KL Divergence                49.89399
KL Loss                      4.989399
QF Loss                      174.16055
VF Loss                      57.602997
Policy Loss                  -1244.3351
Q Predictions Mean           1241.0162
Q Predictions Std            1207.2877
Q Predictions Max            4721.5874
Q Predictions Min            687.12933
V Predictions Mean           1247.1249
V Predictions Std            1203.3602
V Predictions Max            4739.6123
V Predictions Min            702.47943
Log Pis Mean                 -0.32065892
Log Pis Std                  4.015864
Log Pis Max                  18.795448
Log Pis Min                  -6.8898687
Policy mu Mean               0.07331815
Policy mu Std                0.8871283
Policy mu Max                3.6560488
Policy mu Min                -2.7155125
Policy log std Mean          -0.48769593
Policy log std Std           0.27985093
Policy log std Max           0.06385577
Policy log std Min           -2.6231873
Z mean eval                  1.8989786
Z variance eval              0.05113002
total_rewards                [ 9942.5749371  10248.22241107 10190.68763715 10030.49886403
 10031.63452162 10191.29757543 10030.00001437  9828.6675321
 10311.56389378 10144.09349107]
total_rewards_mean           10094.924087771762
total_rewards_std            140.63550380268313
total_rewards_max            10311.563893775574
total_rewards_min            9828.667532098843
Number of train steps total  1720000
Number of env steps total    5162000
Number of rollouts total     0
Train Time (s)               148.3274369230494
(Previous) Eval Time (s)     20.919686214998364
Sample Time (s)              6.638114570174366
Epoch Time (s)               175.88523770822212
Total Train Time (s)         73791.33675222797
Epoch                        429
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:23:30.925713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #429 | Epoch Duration: 175.97081971168518
2020-01-13 04:23:30.925857 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.900494
Z variance train             0.051228743
KL Divergence                51.5524
KL Loss                      5.15524
QF Loss                      195.35889
VF Loss                      65.525826
Policy Loss                  -1446.9036
Q Predictions Mean           1443.7968
Q Predictions Std            1376.5957
Q Predictions Max            4755.944
Q Predictions Min            659.9003
V Predictions Mean           1450.9425
V Predictions Std            1376.2563
V Predictions Max            4760.945
V Predictions Min            681.48535
Log Pis Mean                 0.10315192
Log Pis Std                  4.2405386
Log Pis Max                  21.33192
Log Pis Min                  -6.7418203
Policy mu Mean               0.04858015
Policy mu Std                0.94248825
Policy mu Max                3.803758
Policy mu Min                -3.4389307
Policy log std Mean          -0.5024056
Policy log std Std           0.31422895
Policy log std Max           -0.020439506
Policy log std Min           -3.0640583
Z mean eval                  1.886885
Z variance eval              0.08246843
total_rewards                [10248.67103213 10821.63781382 10657.64355585 10557.51483471
 10384.94256488 10771.72299969 10350.34606744 10563.00864207
 10540.81924728 10931.02376796]
total_rewards_mean           10582.733052583873
total_rewards_std            206.6917246342968
total_rewards_max            10931.023767961393
total_rewards_min            10248.671032129674
Number of train steps total  1724000
Number of env steps total    5174000
Number of rollouts total     0
Train Time (s)               147.18829761072993
(Previous) Eval Time (s)     20.831570502836257
Sample Time (s)              6.512115796096623
Epoch Time (s)               174.5319839096628
Total Train Time (s)         73965.95450416859
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:26:25.546757 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #430 | Epoch Duration: 174.62080264091492
2020-01-13 04:26:25.546893 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #430 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8860216
Z variance train             0.082351334
KL Divergence                50.82055
KL Loss                      5.082055
QF Loss                      237.53929
VF Loss                      73.34516
Policy Loss                  -1353.3473
Q Predictions Mean           1350.1384
Q Predictions Std            1312.2878
Q Predictions Max            4756.881
Q Predictions Min            676.89197
V Predictions Mean           1354.6863
V Predictions Std            1313.1101
V Predictions Max            4775.644
V Predictions Min            678.5368
Log Pis Mean                 -0.19093198
Log Pis Std                  3.8410575
Log Pis Max                  16.573545
Log Pis Min                  -6.9224186
Policy mu Mean               0.09888067
Policy mu Std                0.86865866
Policy mu Max                3.4176552
Policy mu Min                -2.7237153
Policy log std Mean          -0.48908213
Policy log std Std           0.29003766
Policy log std Max           -0.054974318
Policy log std Min           -3.0262687
Z mean eval                  1.9241663
Z variance eval              0.106581315
total_rewards                [10435.10563475 10380.55953228 10428.51767829 10678.80818903
 10675.21848584 10617.5896902  10760.78710401 10388.84265396
 10871.87189208  5205.19939801]
total_rewards_mean           10044.250025845158
total_rewards_std            1621.0051155546655
total_rewards_max            10871.871892080017
total_rewards_min            5205.199398005823
Number of train steps total  1728000
Number of env steps total    5186000
Number of rollouts total     0
Train Time (s)               147.2366073615849
(Previous) Eval Time (s)     20.78831843007356
Sample Time (s)              6.382857249584049
Epoch Time (s)               174.4077830412425
Total Train Time (s)         74140.43988292804
Epoch                        431
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:29:20.037383 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #431 | Epoch Duration: 174.49039363861084
2020-01-13 04:29:20.037516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #431 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9280317
Z variance train             0.1061942
KL Divergence                49.39197
KL Loss                      4.939197
QF Loss                      130.10303
VF Loss                      60.506226
Policy Loss                  -1283.7834
Q Predictions Mean           1280.5907
Q Predictions Std            1260.852
Q Predictions Max            4807.0063
Q Predictions Min            696.17566
V Predictions Mean           1285.4177
V Predictions Std            1262.0133
V Predictions Max            4821.53
V Predictions Min            698.3948
Log Pis Mean                 -0.41143608
Log Pis Std                  4.047982
Log Pis Max                  17.165508
Log Pis Min                  -8.583809
Policy mu Mean               0.061752196
Policy mu Std                0.8843565
Policy mu Max                3.4753914
Policy mu Min                -3.192459
Policy log std Mean          -0.4903345
Policy log std Std           0.2812607
Policy log std Max           0.13885558
Policy log std Min           -2.9134183
Z mean eval                  1.8951963
Z variance eval              0.0868473
total_rewards                [10164.83774372 10558.32087417 10490.74836458 10404.9884343
 10470.25692796 10415.32479048 10532.21734534 10710.60369618
 10496.19744396 10599.22134983]
total_rewards_mean           10484.271697053126
total_rewards_std            136.2643786765058
total_rewards_max            10710.60369618493
total_rewards_min            10164.837743721117
Number of train steps total  1732000
Number of env steps total    5198000
Number of rollouts total     0
Train Time (s)               146.2763920542784
(Previous) Eval Time (s)     17.562435451895
Sample Time (s)              6.324753407854587
Epoch Time (s)               170.163580914028
Total Train Time (s)         74310.69605106348
Epoch                        432
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:32:10.297962 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #432 | Epoch Duration: 170.26034140586853
2020-01-13 04:32:10.298131 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #432 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8937212
Z variance train             0.08669703
KL Divergence                48.528835
KL Loss                      4.852884
QF Loss                      4459.1426
VF Loss                      58.41676
Policy Loss                  -1200.8743
Q Predictions Mean           1197.833
Q Predictions Std            1164.2252
Q Predictions Max            4870.623
Q Predictions Min            686.65094
V Predictions Mean           1200.3389
V Predictions Std            1161.6222
V Predictions Max            4848.613
V Predictions Min            691.6614
Log Pis Mean                 -0.4050876
Log Pis Std                  3.5907907
Log Pis Max                  21.558306
Log Pis Min                  -6.410951
Policy mu Mean               0.07818698
Policy mu Std                0.8494072
Policy mu Max                3.8779628
Policy mu Min                -3.2926114
Policy log std Mean          -0.46784726
Policy log std Std           0.28342587
Policy log std Max           -0.016708732
Policy log std Min           -3.0891795
Z mean eval                  1.8889297
Z variance eval              0.06489781
total_rewards                [10467.69113388 10802.85584091 10463.66676284 10684.30310003
 10577.6253947  10331.88986526 10343.82983424 10697.5382136
 10500.77258309 10793.99532206]
total_rewards_mean           10566.416805060619
total_rewards_std            163.72915810926537
total_rewards_max            10802.855840913791
total_rewards_min            10331.889865263336
Number of train steps total  1736000
Number of env steps total    5210000
Number of rollouts total     0
Train Time (s)               146.5844216630794
(Previous) Eval Time (s)     20.562145273201168
Sample Time (s)              6.312064338475466
Epoch Time (s)               173.45863127475604
Total Train Time (s)         74484.23353413166
Epoch                        433
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:35:03.840182 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #433 | Epoch Duration: 173.54191780090332
2020-01-13 04:35:03.840358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #433 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8878514
Z variance train             0.065038815
KL Divergence                48.724487
KL Loss                      4.872449
QF Loss                      4297.9946
VF Loss                      84.02727
Policy Loss                  -1369.9265
Q Predictions Mean           1369.0579
Q Predictions Std            1323.8356
Q Predictions Max            4775.8833
Q Predictions Min            676.7667
V Predictions Mean           1375.0271
V Predictions Std            1323.0685
V Predictions Max            4776.9893
V Predictions Min            676.2895
Log Pis Mean                 -0.33028796
Log Pis Std                  3.4939146
Log Pis Max                  16.93302
Log Pis Min                  -6.3316565
Policy mu Mean               0.048905477
Policy mu Std                0.8839806
Policy mu Max                3.184321
Policy mu Min                -2.6295125
Policy log std Mean          -0.49362978
Policy log std Std           0.2693448
Policy log std Max           -0.06294137
Policy log std Min           -2.8175974
Z mean eval                  1.8742397
Z variance eval              0.05191944
total_rewards                [10693.20436706 10719.23510677 10598.2336079  10772.3395106
 10400.73613767 10419.20388286 10487.38298972 10838.02673681
 10613.65001154 10761.67984085]
total_rewards_mean           10630.369219177855
total_rewards_std            145.4113241961455
total_rewards_max            10838.026736812184
total_rewards_min            10400.73613766929
Number of train steps total  1740000
Number of env steps total    5222000
Number of rollouts total     0
Train Time (s)               146.41853273799643
(Previous) Eval Time (s)     20.786485355813056
Sample Time (s)              6.325193568132818
Epoch Time (s)               173.5302116619423
Total Train Time (s)         74657.85079065152
Epoch                        434
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:37:57.459826 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #434 | Epoch Duration: 173.61934566497803
2020-01-13 04:37:57.459966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #434 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8738976
Z variance train             0.051647115
KL Divergence                48.31939
KL Loss                      4.831939
QF Loss                      191.65158
VF Loss                      70.80016
Policy Loss                  -1350.5415
Q Predictions Mean           1346.8376
Q Predictions Std            1313.7162
Q Predictions Max            4785.46
Q Predictions Min            675.0755
V Predictions Mean           1352.2319
V Predictions Std            1310.5593
V Predictions Max            4792.4004
V Predictions Min            681.351
Log Pis Mean                 -0.006816961
Log Pis Std                  4.184349
Log Pis Max                  17.582193
Log Pis Min                  -5.790014
Policy mu Mean               0.11709329
Policy mu Std                0.9169178
Policy mu Max                3.040636
Policy mu Min                -3.3898966
Policy log std Mean          -0.4933103
Policy log std Std           0.30044016
Policy log std Max           -0.010066092
Policy log std Min           -3.2357724
Z mean eval                  1.8918314
Z variance eval              0.08637954
total_rewards                [10621.74544821 10557.75178572 10786.63753525 10969.70960457
 11214.0793925  10623.30274041 10647.02921958 10418.47293142
 10419.07588078 10604.55888857]
total_rewards_mean           10686.236342700307
total_rewards_std            233.44466836461703
total_rewards_max            11214.079392495849
total_rewards_min            10418.472931420536
Number of train steps total  1744000
Number of env steps total    5234000
Number of rollouts total     0
Train Time (s)               148.96664359094575
(Previous) Eval Time (s)     20.64462794503197
Sample Time (s)              6.375989323016256
Epoch Time (s)               175.98726085899398
Total Train Time (s)         74833.92304163845
Epoch                        435
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:40:53.540986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #435 | Epoch Duration: 176.08088660240173
2020-01-13 04:40:53.541259 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.892342
Z variance train             0.08637828
KL Divergence                47.022778
KL Loss                      4.7022777
QF Loss                      496.3579
VF Loss                      58.515633
Policy Loss                  -1334.6271
Q Predictions Mean           1328.6095
Q Predictions Std            1315.3157
Q Predictions Max            4664.184
Q Predictions Min            652.9601
V Predictions Mean           1330.2986
V Predictions Std            1312.8026
V Predictions Max            4659.47
V Predictions Min            647.09094
Log Pis Mean                 -0.38539892
Log Pis Std                  3.5663652
Log Pis Max                  12.998675
Log Pis Min                  -7.275393
Policy mu Mean               0.086793415
Policy mu Std                0.85351676
Policy mu Max                3.2867332
Policy mu Min                -2.860735
Policy log std Mean          -0.5008945
Policy log std Std           0.28980342
Policy log std Max           0.060969293
Policy log std Min           -2.932266
Z mean eval                  1.9022696
Z variance eval              0.064708285
total_rewards                [10309.34900388 10860.17168144 10621.76515654 10617.93614702
 10659.37078674 10504.44135972 10573.97515621 10763.39808053
 10550.91970565 10730.04970782]
total_rewards_mean           10619.137678555287
total_rewards_std            144.44881323123596
total_rewards_max            10860.171681443737
total_rewards_min            10309.349003877876
Number of train steps total  1748000
Number of env steps total    5246000
Number of rollouts total     0
Train Time (s)               145.40669959411025
(Previous) Eval Time (s)     20.76350947888568
Sample Time (s)              6.641254153102636
Epoch Time (s)               172.81146322609857
Total Train Time (s)         75006.8224198604
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:43:46.442490 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #436 | Epoch Duration: 172.90104031562805
2020-01-13 04:43:46.442639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9033388
Z variance train             0.06450491
KL Divergence                48.147057
KL Loss                      4.814706
QF Loss                      3870.54
VF Loss                      76.30322
Policy Loss                  -1331.9419
Q Predictions Mean           1329.8254
Q Predictions Std            1342.3696
Q Predictions Max            4744.6377
Q Predictions Min            655.34265
V Predictions Mean           1334.2776
V Predictions Std            1342.9243
V Predictions Max            4735.1196
V Predictions Min            672.9894
Log Pis Mean                 -0.24181113
Log Pis Std                  3.944247
Log Pis Max                  20.157825
Log Pis Min                  -6.7531786
Policy mu Mean               0.11774423
Policy mu Std                0.88931006
Policy mu Max                3.6538706
Policy mu Min                -2.617689
Policy log std Mean          -0.50355166
Policy log std Std           0.28469872
Policy log std Max           -0.08490078
Policy log std Min           -3.0811844
Z mean eval                  1.8996906
Z variance eval              0.067385815
total_rewards                [10079.69902094 10759.930695   10502.30997988 10876.47850755
 10622.90385638 10592.25382656 10929.98497135 10515.42788543
 10482.4738373  10822.41681558]
total_rewards_mean           10618.387939596385
total_rewards_std            236.38998084635406
total_rewards_max            10929.984971345204
total_rewards_min            10079.69902093693
Number of train steps total  1752000
Number of env steps total    5258000
Number of rollouts total     0
Train Time (s)               149.061324252747
(Previous) Eval Time (s)     20.915003903210163
Sample Time (s)              6.511465047951788
Epoch Time (s)               176.48779320390895
Total Train Time (s)         75183.404877414
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:46:43.026990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #437 | Epoch Duration: 176.5842502117157
2020-01-13 04:46:43.027123 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #437 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8989229
Z variance train             0.06747687
KL Divergence                48.550888
KL Loss                      4.8550887
QF Loss                      123.74895
VF Loss                      101.10213
Policy Loss                  -1285.7838
Q Predictions Mean           1283.9177
Q Predictions Std            1306.2596
Q Predictions Max            4858.434
Q Predictions Min            681.3532
V Predictions Mean           1292.3
V Predictions Std            1306.0327
V Predictions Max            4861.191
V Predictions Min            687.7664
Log Pis Mean                 -0.47562033
Log Pis Std                  4.046032
Log Pis Max                  14.194849
Log Pis Min                  -7.817528
Policy mu Mean               0.031137249
Policy mu Std                0.8884835
Policy mu Max                3.3620358
Policy mu Min                -2.9690905
Policy log std Mean          -0.4630272
Policy log std Std           0.2623892
Policy log std Max           0.0016680956
Policy log std Min           -2.753735
Z mean eval                  1.905318
Z variance eval              0.08134098
total_rewards                [10786.30556562 10680.37062064 10880.47166279 10533.5718247
 10923.92870649 10570.06670466 10443.91587996 10884.41479802
 10546.40489628 10620.20482344]
total_rewards_mean           10686.965548260981
total_rewards_std            162.16556343828782
total_rewards_max            10923.928706494398
total_rewards_min            10443.915879964276
Number of train steps total  1756000
Number of env steps total    5270000
Number of rollouts total     0
Train Time (s)               147.59594786912203
(Previous) Eval Time (s)     20.43109474517405
Sample Time (s)              6.4354451284743845
Epoch Time (s)               174.46248774277046
Total Train Time (s)         75358.04490848258
Epoch                        438
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:49:37.673911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #438 | Epoch Duration: 174.64667510986328
2020-01-13 04:49:37.674099 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #438 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9083488
Z variance train             0.081280716
KL Divergence                48.426056
KL Loss                      4.8426056
QF Loss                      72.46973
VF Loss                      36.948334
Policy Loss                  -1282.8861
Q Predictions Mean           1282.9004
Q Predictions Std            1301.1752
Q Predictions Max            4811.3643
Q Predictions Min            685.94336
V Predictions Mean           1283.9363
V Predictions Std            1295.4712
V Predictions Max            4778.2075
V Predictions Min            692.682
Log Pis Mean                 -0.6052912
Log Pis Std                  3.619214
Log Pis Max                  13.373043
Log Pis Min                  -8.147602
Policy mu Mean               0.064528584
Policy mu Std                0.8250993
Policy mu Max                2.7022896
Policy mu Min                -2.6291642
Policy log std Mean          -0.45895162
Policy log std Std           0.25049204
Policy log std Max           -0.025914252
Policy log std Min           -2.837773
Z mean eval                  1.9105585
Z variance eval              0.043925
total_rewards                [10833.68614578 10482.66998607 10902.07557484 10830.14884825
 10889.07091943 11047.54123837 10987.33387407 11160.84979895
 11093.97231891 11058.77508747]
total_rewards_mean           10928.612379215967
total_rewards_std            183.20784662889136
total_rewards_max            11160.849798954565
total_rewards_min            10482.66998606699
Number of train steps total  1760000
Number of env steps total    5282000
Number of rollouts total     0
Train Time (s)               146.88190671615303
(Previous) Eval Time (s)     17.41251872293651
Sample Time (s)              6.520229780115187
Epoch Time (s)               170.81465521920472
Total Train Time (s)         75528.94158150302
Epoch                        439
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:52:28.572821 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #439 | Epoch Duration: 170.89857649803162
2020-01-13 04:52:28.572998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9111761
Z variance train             0.04381271
KL Divergence                50.921337
KL Loss                      5.092134
QF Loss                      154.80547
VF Loss                      51.667023
Policy Loss                  -1271.0724
Q Predictions Mean           1264.302
Q Predictions Std            1260.3855
Q Predictions Max            4887.1167
Q Predictions Min            701.1659
V Predictions Mean           1269.2085
V Predictions Std            1260.1168
V Predictions Max            4883.755
V Predictions Min            697.8492
Log Pis Mean                 -0.36198288
Log Pis Std                  4.0197854
Log Pis Max                  21.104958
Log Pis Min                  -6.8494473
Policy mu Mean               0.056986142
Policy mu Std                0.8832137
Policy mu Max                3.7293394
Policy mu Min                -2.537609
Policy log std Mean          -0.48903608
Policy log std Std           0.30122378
Policy log std Max           0.011072338
Policy log std Min           -2.546293
Z mean eval                  1.9137408
Z variance eval              0.03418284
total_rewards                [10416.81348523 10855.37606623 10699.12427737 10856.73129808
 10539.56236767 10783.14183274 10744.75988081 10861.66035602
 10969.3356756  10771.47706672]
total_rewards_mean           10749.798230646466
total_rewards_std            155.73828884183746
total_rewards_max            10969.335675598577
total_rewards_min            10416.813485227065
Number of train steps total  1764000
Number of env steps total    5294000
Number of rollouts total     0
Train Time (s)               147.89311720291153
(Previous) Eval Time (s)     20.657317908946425
Sample Time (s)              7.583876258227974
Epoch Time (s)               176.13431137008592
Total Train Time (s)         75705.16471066
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:55:24.798219 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #440 | Epoch Duration: 176.22509241104126
2020-01-13 04:55:24.798363 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #440 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.914182
Z variance train             0.034205116
KL Divergence                51.3877
KL Loss                      5.13877
QF Loss                      68.580185
VF Loss                      94.7126
Policy Loss                  -1319.5542
Q Predictions Mean           1316.1873
Q Predictions Std            1290.5023
Q Predictions Max            4810.6567
Q Predictions Min            676.2456
V Predictions Mean           1320.4882
V Predictions Std            1292.2347
V Predictions Max            4806.079
V Predictions Min            669.5284
Log Pis Mean                 -0.51541317
Log Pis Std                  3.7319255
Log Pis Max                  13.601404
Log Pis Min                  -9.351805
Policy mu Mean               0.09104705
Policy mu Std                0.84399176
Policy mu Max                3.1805816
Policy mu Min                -2.7973566
Policy log std Mean          -0.47984418
Policy log std Std           0.2735839
Policy log std Max           0.059610724
Policy log std Min           -2.9412837
Z mean eval                  1.887716
Z variance eval              0.05588659
total_rewards                [10342.86627061 10430.4240902  10638.69767868 10758.73327809
 10660.23308307 10503.58784914 10810.30532365 10379.822672
 10827.80792398 10916.21522971]
total_rewards_mean           10626.869339913386
total_rewards_std            192.83830723978514
total_rewards_max            10916.215229712769
total_rewards_min            10342.866270605793
Number of train steps total  1768000
Number of env steps total    5306000
Number of rollouts total     0
Train Time (s)               145.27159711020067
(Previous) Eval Time (s)     17.868515198118985
Sample Time (s)              6.4437551479786634
Epoch Time (s)               169.58386745629832
Total Train Time (s)         75874.83484175615
Epoch                        441
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:58:14.474969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #441 | Epoch Duration: 169.67648267745972
2020-01-13 04:58:14.475140 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8874075
Z variance train             0.0560924
KL Divergence                51.149185
KL Loss                      5.1149187
QF Loss                      92.6946
VF Loss                      90.6104
Policy Loss                  -1315.8386
Q Predictions Mean           1311.0427
Q Predictions Std            1268.7136
Q Predictions Max            4865.192
Q Predictions Min            671.3598
V Predictions Mean           1317.3728
V Predictions Std            1273.886
V Predictions Max            4875.0093
V Predictions Min            666.8563
Log Pis Mean                 -0.03970565
Log Pis Std                  4.261072
Log Pis Max                  18.72725
Log Pis Min                  -7.9607477
Policy mu Mean               0.06203735
Policy mu Std                0.9135028
Policy mu Max                3.7028172
Policy mu Min                -2.9338515
Policy log std Mean          -0.4888809
Policy log std Std           0.31071526
Policy log std Max           0.10440463
Policy log std Min           -2.738863
Z mean eval                  1.9056883
Z variance eval              0.03648042
total_rewards                [10311.67333826 10575.39908324 10274.32860759 10723.99733276
 10306.93000572 10651.71135817 10622.12361924 10510.01457503
 10308.94976477 10698.45852214]
total_rewards_mean           10498.358620692143
total_rewards_std            171.29512567881525
total_rewards_max            10723.997332757232
total_rewards_min            10274.328607589936
Number of train steps total  1772000
Number of env steps total    5318000
Number of rollouts total     0
Train Time (s)               146.37976440275088
(Previous) Eval Time (s)     20.992337252013385
Sample Time (s)              6.5587994256056845
Epoch Time (s)               173.93090108036995
Total Train Time (s)         76048.91744983243
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:01:08.566744 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #442 | Epoch Duration: 174.0914385318756
2020-01-13 05:01:08.567020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #442 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9019239
Z variance train             0.03643264
KL Divergence                52.11959
KL Loss                      5.2119594
QF Loss                      4348.2593
VF Loss                      51.147655
Policy Loss                  -1398.3738
Q Predictions Mean           1396.4763
Q Predictions Std            1393.856
Q Predictions Max            4870.7188
Q Predictions Min            704.8461
V Predictions Mean           1400.9666
V Predictions Std            1392.2279
V Predictions Max            4871.3145
V Predictions Min            708.0085
Log Pis Mean                 -0.25744826
Log Pis Std                  4.0351005
Log Pis Max                  16.345615
Log Pis Min                  -7.3717084
Policy mu Mean               0.048291445
Policy mu Std                0.88867754
Policy mu Max                3.288211
Policy mu Min                -2.9023492
Policy log std Mean          -0.4726895
Policy log std Std           0.28585932
Policy log std Max           -0.046676874
Policy log std Min           -3.1511214
Z mean eval                  1.8922046
Z variance eval              0.048251662
total_rewards                [10255.78457046 10540.29595992  9907.5878142   5474.54669538
  8122.7939517  10467.22767796 10404.52186518 10149.79181661
 10524.9808118  10290.68826136]
total_rewards_mean           9613.82194245751
total_rewards_std            1537.6170677552605
total_rewards_max            10540.295959919315
total_rewards_min            5474.546695378802
Number of train steps total  1776000
Number of env steps total    5330000
Number of rollouts total     0
Train Time (s)               146.48040924593806
(Previous) Eval Time (s)     20.81905736681074
Sample Time (s)              6.541000257711858
Epoch Time (s)               173.84046687046066
Total Train Time (s)         76223.01585422223
Epoch                        443
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:04:02.666870 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #443 | Epoch Duration: 174.0996744632721
2020-01-13 05:04:02.667053 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8910172
Z variance train             0.04828289
KL Divergence                51.187668
KL Loss                      5.118767
QF Loss                      198.99167
VF Loss                      80.00702
Policy Loss                  -1322.6162
Q Predictions Mean           1315.8457
Q Predictions Std            1285.898
Q Predictions Max            4768.604
Q Predictions Min            674.7879
V Predictions Mean           1324.9028
V Predictions Std            1282.2942
V Predictions Max            4757.753
V Predictions Min            679.8705
Log Pis Mean                 -0.2474423
Log Pis Std                  3.8860393
Log Pis Max                  18.17808
Log Pis Min                  -7.9646797
Policy mu Mean               0.06136781
Policy mu Std                0.9117294
Policy mu Max                3.1090693
Policy mu Min                -2.938628
Policy log std Mean          -0.49722457
Policy log std Std           0.3093273
Policy log std Max           0.18074647
Policy log std Min           -3.1005142
Z mean eval                  1.910737
Z variance eval              0.057356376
total_rewards                [10644.50502128 10574.54376932 11016.68877209 11030.89277994
 10817.19451744 10820.70963282 10763.29960598 10852.14329232
 10803.07841388 11075.21620227]
total_rewards_mean           10839.827200733565
total_rewards_std            154.90528001103868
total_rewards_max            11075.216202268039
total_rewards_min            10574.543769322048
Number of train steps total  1780000
Number of env steps total    5342000
Number of rollouts total     0
Train Time (s)               145.56446985993534
(Previous) Eval Time (s)     17.66420510970056
Sample Time (s)              6.595969972200692
Epoch Time (s)               169.8246449418366
Total Train Time (s)         76392.92377431085
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:06:52.576375 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #444 | Epoch Duration: 169.90912413597107
2020-01-13 05:06:52.576648 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.912013
Z variance train             0.057532698
KL Divergence                51.164913
KL Loss                      5.1164913
QF Loss                      134.97841
VF Loss                      27.306276
Policy Loss                  -1281.639
Q Predictions Mean           1277.6819
Q Predictions Std            1235.7252
Q Predictions Max            4750.379
Q Predictions Min            697.92163
V Predictions Mean           1279.7217
V Predictions Std            1239.3375
V Predictions Max            4753.5483
V Predictions Min            698.29736
Log Pis Mean                 -0.51191944
Log Pis Std                  3.7083616
Log Pis Max                  18.764584
Log Pis Min                  -6.5357814
Policy mu Mean               0.04001121
Policy mu Std                0.8515303
Policy mu Max                3.2724206
Policy mu Min                -3.1162517
Policy log std Mean          -0.49299923
Policy log std Std           0.27243245
Policy log std Max           0.022485375
Policy log std Min           -2.6446636
Z mean eval                  1.8955872
Z variance eval              0.054313023
total_rewards                [10459.36428551 10785.55120664 10719.42158838 10531.90261113
 10924.67497149 10498.97849752 10542.37383825 10294.68265075
 10693.47784164 10495.29502888]
total_rewards_mean           10594.572252018124
total_rewards_std            174.54847388005467
total_rewards_max            10924.674971485105
total_rewards_min            10294.68265075018
Number of train steps total  1784000
Number of env steps total    5354000
Number of rollouts total     0
Train Time (s)               147.59928074618801
(Previous) Eval Time (s)     20.730800893623382
Sample Time (s)              6.6078863511793315
Epoch Time (s)               174.93796799099073
Total Train Time (s)         76567.97256495524
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:09:47.632492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #445 | Epoch Duration: 175.05564141273499
2020-01-13 05:09:47.632768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8980078
Z variance train             0.05428972
KL Divergence                51.275143
KL Loss                      5.1275144
QF Loss                      175.93661
VF Loss                      100.27701
Policy Loss                  -1362.6761
Q Predictions Mean           1358.5466
Q Predictions Std            1330.2316
Q Predictions Max            4865.887
Q Predictions Min            688.1488
V Predictions Mean           1357.9152
V Predictions Std            1321.862
V Predictions Max            4837.6313
V Predictions Min            685.6066
Log Pis Mean                 0.00753811
Log Pis Std                  4.1276298
Log Pis Max                  25.271465
Log Pis Min                  -6.018547
Policy mu Mean               0.06628395
Policy mu Std                0.90696996
Policy mu Max                3.3074
Policy mu Min                -3.2903125
Policy log std Mean          -0.48785368
Policy log std Std           0.30070966
Policy log std Max           0.024104297
Policy log std Min           -2.8990614
Z mean eval                  1.8815918
Z variance eval              0.064834476
total_rewards                [10608.94736119  9974.27285855 10871.57131704 10842.80761947
 10930.16765344 10909.86930368 10651.84961494 10591.16593103
 10979.2526439  11079.93300478]
total_rewards_mean           10743.98373080193
total_rewards_std            299.828655875769
total_rewards_max            11079.933004779734
total_rewards_min            9974.27285855108
Number of train steps total  1788000
Number of env steps total    5366000
Number of rollouts total     0
Train Time (s)               146.93666121084243
(Previous) Eval Time (s)     20.51930050039664
Sample Time (s)              6.365057336166501
Epoch Time (s)               173.82101904740557
Total Train Time (s)         76741.88534819335
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:12:41.549082 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #446 | Epoch Duration: 173.9160599708557
2020-01-13 05:12:41.549353 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8830054
Z variance train             0.06504502
KL Divergence                50.771446
KL Loss                      5.0771446
QF Loss                      144.78186
VF Loss                      34.18989
Policy Loss                  -1286.0836
Q Predictions Mean           1283.5444
Q Predictions Std            1261.1454
Q Predictions Max            4851.6113
Q Predictions Min            682.4289
V Predictions Mean           1284.0747
V Predictions Std            1262.5505
V Predictions Max            4877.705
V Predictions Min            684.0425
Log Pis Mean                 -0.6893713
Log Pis Std                  3.9249666
Log Pis Max                  21.303701
Log Pis Min                  -7.318077
Policy mu Mean               0.032436416
Policy mu Std                0.8562693
Policy mu Max                3.369184
Policy mu Min                -3.496525
Policy log std Mean          -0.49797186
Policy log std Std           0.27690062
Policy log std Max           -0.06941146
Policy log std Min           -2.9823616
Z mean eval                  1.8981116
Z variance eval              0.14356716
total_rewards                [10415.24480199 10531.73197384 10661.93732599 10443.93321698
 10736.18612382 10474.81501017 10767.4266886  10709.80203214
 10194.3089911  10380.8591541 ]
total_rewards_mean           10531.624531872914
total_rewards_std            175.25697208575423
total_rewards_max            10767.42668859883
total_rewards_min            10194.308991096243
Number of train steps total  1792000
Number of env steps total    5378000
Number of rollouts total     0
Train Time (s)               146.16488880105317
(Previous) Eval Time (s)     20.63489160174504
Sample Time (s)              5.462374303024262
Epoch Time (s)               172.26215470582247
Total Train Time (s)         76914.2359900428
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:15:33.902833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #447 | Epoch Duration: 172.3533263206482
2020-01-13 05:15:33.902969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #447 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8982611
Z variance train             0.14389266
KL Divergence                50.12352
KL Loss                      5.012352
QF Loss                      8737.493
VF Loss                      46.80094
Policy Loss                  -1320.727
Q Predictions Mean           1318.852
Q Predictions Std            1309.6154
Q Predictions Max            4768.844
Q Predictions Min            644.6998
V Predictions Mean           1323.3721
V Predictions Std            1311.0338
V Predictions Max            4774.263
V Predictions Min            649.8079
Log Pis Mean                 -0.4441889
Log Pis Std                  3.7995276
Log Pis Max                  15.66493
Log Pis Min                  -7.6932
Policy mu Mean               0.039350316
Policy mu Std                0.84439826
Policy mu Max                2.5861745
Policy mu Min                -2.9854774
Policy log std Mean          -0.49059796
Policy log std Std           0.28611732
Policy log std Max           0.05222091
Policy log std Min           -2.9233792
Z mean eval                  1.9184468
Z variance eval              0.10065961
total_rewards                [10648.66897765 11042.97375689  8291.51855557 11119.85390359
 10711.9183323  10633.88145575 10649.73290553 10826.93188866
 10848.18284901 10917.59688857]
total_rewards_mean           10569.125951351683
total_rewards_std            775.790218455531
total_rewards_max            11119.853903587875
total_rewards_min            8291.518555574845
Number of train steps total  1796000
Number of env steps total    5390000
Number of rollouts total     0
Train Time (s)               146.48958264896646
(Previous) Eval Time (s)     20.81534635089338
Sample Time (s)              6.334420608356595
Epoch Time (s)               173.63934960821643
Total Train Time (s)         77087.95536437398
Epoch                        448
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:18:27.627249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #448 | Epoch Duration: 173.72416019439697
2020-01-13 05:18:27.627456 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9158598
Z variance train             0.100943014
KL Divergence                49.03042
KL Loss                      4.903042
QF Loss                      8349.672
VF Loss                      88.23596
Policy Loss                  -1393.0292
Q Predictions Mean           1395.1072
Q Predictions Std            1399.8668
Q Predictions Max            4911.713
Q Predictions Min            680.71265
V Predictions Mean           1396.0779
V Predictions Std            1401.0039
V Predictions Max            4901.075
V Predictions Min            685.6511
Log Pis Mean                 -0.3000125
Log Pis Std                  3.9829884
Log Pis Max                  21.834137
Log Pis Min                  -6.225214
Policy mu Mean               0.013732982
Policy mu Std                0.8941395
Policy mu Max                3.3193917
Policy mu Min                -3.3831735
Policy log std Mean          -0.50687784
Policy log std Std           0.28820494
Policy log std Max           0.18306679
Policy log std Min           -3.062467
Z mean eval                  1.8972889
Z variance eval              0.082726315
total_rewards                [10715.60118651 11041.01081421 10935.4271895  10923.55339117
 11002.69891993 10738.31470287 11057.99250846 10270.16417564
 10953.23368181 10950.41927973]
total_rewards_mean           10858.841584983673
total_rewards_std            224.15989814164064
total_rewards_max            11057.99250845567
total_rewards_min            10270.164175640937
Number of train steps total  1800000
Number of env steps total    5402000
Number of rollouts total     0
Train Time (s)               146.13015120103955
(Previous) Eval Time (s)     18.852964421734214
Sample Time (s)              6.491886574309319
Epoch Time (s)               171.47500219708309
Total Train Time (s)         77259.53402850451
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:21:19.213508 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #449 | Epoch Duration: 171.58589339256287
2020-01-13 05:21:19.213684 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #449 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8978183
Z variance train             0.082758754
KL Divergence                48.727913
KL Loss                      4.8727913
QF Loss                      4241.573
VF Loss                      80.904274
Policy Loss                  -1426.2838
Q Predictions Mean           1425.1796
Q Predictions Std            1404.8323
Q Predictions Max            4825.5977
Q Predictions Min            687.8501
V Predictions Mean           1433.4036
V Predictions Std            1406.3484
V Predictions Max            4826.961
V Predictions Min            701.7157
Log Pis Mean                 -0.43500116
Log Pis Std                  3.7521777
Log Pis Max                  10.644165
Log Pis Min                  -6.7002707
Policy mu Mean               0.10187882
Policy mu Std                0.85305965
Policy mu Max                2.7893357
Policy mu Min                -2.6546197
Policy log std Mean          -0.5227662
Policy log std Std           0.30821192
Policy log std Max           0.01823324
Policy log std Min           -3.068052
Z mean eval                  1.8917307
Z variance eval              0.12818784
total_rewards                [10749.24143854  4303.0296123  10724.73676068  3437.7230329
 10584.58479335 11056.611835   10767.77905433  6521.74270363
 10708.73608734 11083.0278908 ]
total_rewards_mean           8993.72132088726
total_rewards_std            2868.81110560702
total_rewards_max            11083.027890799212
total_rewards_min            3437.7230329042573
Number of train steps total  1804000
Number of env steps total    5414000
Number of rollouts total     0
Train Time (s)               146.49587798304856
(Previous) Eval Time (s)     18.981058911420405
Sample Time (s)              6.496600104030222
Epoch Time (s)               171.97353699849918
Total Train Time (s)         77431.59048984153
Epoch                        450
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:24:11.277843 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #450 | Epoch Duration: 172.06400656700134
2020-01-13 05:24:11.278072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #450 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.89077
Z variance train             0.12800337
KL Divergence                48.6845
KL Loss                      4.86845
QF Loss                      109.3065
VF Loss                      113.22561
Policy Loss                  -1336.994
Q Predictions Mean           1336.8479
Q Predictions Std            1311.5807
Q Predictions Max            4827.2334
Q Predictions Min            687.435
V Predictions Mean           1345.2522
V Predictions Std            1311.9183
V Predictions Max            4836.5845
V Predictions Min            674.9966
Log Pis Mean                 -0.23987766
Log Pis Std                  4.0880795
Log Pis Max                  13.666697
Log Pis Min                  -7.990329
Policy mu Mean               0.05307922
Policy mu Std                0.9010162
Policy mu Max                3.1495557
Policy mu Min                -2.6854901
Policy log std Mean          -0.49094367
Policy log std Std           0.27096292
Policy log std Max           0.023384154
Policy log std Min           -2.71782
Z mean eval                  1.8944464
Z variance eval              0.14666024
total_rewards                [10920.6367918   7656.8306622  10649.35440036 11177.20275182
 10985.95136605 10907.25496397 10950.22431196 11048.87804517
 10770.0541391  10928.83351824]
total_rewards_mean           10599.522095066448
total_rewards_std            990.2127460181099
total_rewards_max            11177.202751823472
total_rewards_min            7656.830662196094
Number of train steps total  1808000
Number of env steps total    5426000
Number of rollouts total     0
Train Time (s)               147.23455089796335
(Previous) Eval Time (s)     20.69714109832421
Sample Time (s)              6.514999872073531
Epoch Time (s)               174.44669186836109
Total Train Time (s)         77606.11908712797
Epoch                        451
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:27:05.809539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #451 | Epoch Duration: 174.53130793571472
2020-01-13 05:27:05.809674 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #451 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8943882
Z variance train             0.14622995
KL Divergence                48.014416
KL Loss                      4.8014417
QF Loss                      4222.1074
VF Loss                      50.046844
Policy Loss                  -1453.191
Q Predictions Mean           1452.0205
Q Predictions Std            1435.664
Q Predictions Max            4857.5693
Q Predictions Min            680.723
V Predictions Mean           1454.7223
V Predictions Std            1432.1332
V Predictions Max            4836.9873
V Predictions Min            683.7331
Log Pis Mean                 0.13178068
Log Pis Std                  4.3225107
Log Pis Max                  18.835323
Log Pis Min                  -9.06859
Policy mu Mean               0.03512877
Policy mu Std                0.94179773
Policy mu Max                3.1803744
Policy mu Min                -2.7786782
Policy log std Mean          -0.5080428
Policy log std Std           0.29039884
Policy log std Max           0.0040914416
Policy log std Min           -3.0901425
Z mean eval                  1.8963821
Z variance eval              0.11797075
total_rewards                [10347.73731484 10671.38040502 10690.19835391 10901.89040432
 10255.77891918 11011.76485768  2495.77854759  9993.30750538
 10726.20607542 10134.18659405]
total_rewards_mean           9722.822897738904
total_rewards_std            2429.8361710689887
total_rewards_max            11011.764857682589
total_rewards_min            2495.7785475912815
Number of train steps total  1812000
Number of env steps total    5438000
Number of rollouts total     0
Train Time (s)               145.68957131821662
(Previous) Eval Time (s)     20.556891046930104
Sample Time (s)              6.450925251469016
Epoch Time (s)               172.69738761661574
Total Train Time (s)         77778.90839222632
Epoch                        452
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:29:58.606539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #452 | Epoch Duration: 172.7967348098755
2020-01-13 05:29:58.606819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #452 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8955473
Z variance train             0.117573895
KL Divergence                48.19087
KL Loss                      4.819087
QF Loss                      311.1854
VF Loss                      70.43654
Policy Loss                  -1280.6964
Q Predictions Mean           1278.8259
Q Predictions Std            1267.1512
Q Predictions Max            4870.552
Q Predictions Min            676.8642
V Predictions Mean           1286.2631
V Predictions Std            1264.8483
V Predictions Max            4885.5635
V Predictions Min            682.19525
Log Pis Mean                 -0.012343243
Log Pis Std                  3.9236643
Log Pis Max                  13.995291
Log Pis Min                  -5.708015
Policy mu Mean               0.017927554
Policy mu Std                0.9158984
Policy mu Max                3.713221
Policy mu Min                -3.0017295
Policy log std Mean          -0.49508798
Policy log std Std           0.2762162
Policy log std Max           -0.0020994544
Policy log std Min           -2.5531352
Z mean eval                  1.8964208
Z variance eval              0.14979401
total_rewards                [10693.36122858 10834.68894599 10681.14720698 10778.60976148
 10666.34310902 10766.30020047 10942.38518892 10775.53395541
 10853.29216118 10689.80466816]
total_rewards_mean           10768.146642617043
total_rewards_std            84.77461380103364
total_rewards_max            10942.385188918402
total_rewards_min            10666.343109016023
Number of train steps total  1816000
Number of env steps total    5450000
Number of rollouts total     0
Train Time (s)               145.38865894498304
(Previous) Eval Time (s)     20.66732067707926
Sample Time (s)              6.550375580321997
Epoch Time (s)               172.6063552023843
Total Train Time (s)         77951.59479331179
Epoch                        453
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:32:51.294993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #453 | Epoch Duration: 172.68799352645874
2020-01-13 05:32:51.295134 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8918955
Z variance train             0.15021011
KL Divergence                46.90715
KL Loss                      4.6907153
QF Loss                      161.27039
VF Loss                      86.84529
Policy Loss                  -1338.571
Q Predictions Mean           1333.7098
Q Predictions Std            1312.5156
Q Predictions Max            4909.813
Q Predictions Min            680.4733
V Predictions Mean           1343.8818
V Predictions Std            1314.1578
V Predictions Max            4943.104
V Predictions Min            678.55084
Log Pis Mean                 -0.18238865
Log Pis Std                  3.6568203
Log Pis Max                  16.152554
Log Pis Min                  -6.3587513
Policy mu Mean               0.09187934
Policy mu Std                0.87300795
Policy mu Max                3.483766
Policy mu Min                -3.2025573
Policy log std Mean          -0.51262087
Policy log std Std           0.29463425
Policy log std Max           -0.079093575
Policy log std Min           -2.8090026
Z mean eval                  1.8811651
Z variance eval              0.1372255
total_rewards                [10363.49093845 10677.6515986  10988.45790726 10833.34468372
 10475.5264934  11115.6078236  10765.93082573 10437.32058648
 10431.69238942 10677.31608509]
total_rewards_mean           10676.633933174657
total_rewards_std            240.46536920384807
total_rewards_max            11115.607823599774
total_rewards_min            10363.49093844964
Number of train steps total  1820000
Number of env steps total    5462000
Number of rollouts total     0
Train Time (s)               146.54011026583612
(Previous) Eval Time (s)     20.660541265737265
Sample Time (s)              6.566249906085432
Epoch Time (s)               173.76690143765882
Total Train Time (s)         78125.43942013616
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:35:45.141708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #454 | Epoch Duration: 173.84647822380066
2020-01-13 05:35:45.141842 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #454 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8790417
Z variance train             0.1369888
KL Divergence                46.78776
KL Loss                      4.6787763
QF Loss                      98.96087
VF Loss                      50.109
Policy Loss                  -1332.4108
Q Predictions Mean           1332.7222
Q Predictions Std            1371.244
Q Predictions Max            4861.3716
Q Predictions Min            680.93646
V Predictions Mean           1334.9214
V Predictions Std            1370.3728
V Predictions Max            4852.997
V Predictions Min            682.72473
Log Pis Mean                 -0.4637345
Log Pis Std                  3.5903194
Log Pis Max                  13.402579
Log Pis Min                  -6.307931
Policy mu Mean               0.08214142
Policy mu Std                0.8590985
Policy mu Max                2.806993
Policy mu Min                -2.341168
Policy log std Mean          -0.4803585
Policy log std Std           0.29724845
Policy log std Max           0.07613391
Policy log std Min           -2.9432585
Z mean eval                  1.87703
Z variance eval              0.15928957
total_rewards                [10959.91572464 10976.37502352  7227.5303118  11011.56082108
 10805.81121522 11209.76997883 10901.65473577  4326.86288276
  2460.2643896  10972.84964354]
total_rewards_mean           9085.259472676971
total_rewards_std            3084.177007919418
total_rewards_max            11209.769978833805
total_rewards_min            2460.264389601882
Number of train steps total  1824000
Number of env steps total    5474000
Number of rollouts total     0
Train Time (s)               146.1452081790194
(Previous) Eval Time (s)     20.601239568088204
Sample Time (s)              6.431381857488304
Epoch Time (s)               173.1778296045959
Total Train Time (s)         78298.70160811488
Epoch                        455
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:38:38.408406 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #455 | Epoch Duration: 173.2664520740509
2020-01-13 05:38:38.408591 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8777726
Z variance train             0.15933585
KL Divergence                47.263508
KL Loss                      4.726351
QF Loss                      125.079315
VF Loss                      40.09571
Policy Loss                  -1261.7798
Q Predictions Mean           1260.7919
Q Predictions Std            1261.1749
Q Predictions Max            4971.253
Q Predictions Min            683.11725
V Predictions Mean           1261.7075
V Predictions Std            1256.1936
V Predictions Max            4958.583
V Predictions Min            689.77014
Log Pis Mean                 -0.52714264
Log Pis Std                  3.7150524
Log Pis Max                  16.401615
Log Pis Min                  -6.846851
Policy mu Mean               0.031161392
Policy mu Std                0.8463659
Policy mu Max                2.8162966
Policy mu Min                -2.8058
Policy log std Mean          -0.4699054
Policy log std Std           0.26088306
Policy log std Max           0.17681256
Policy log std Min           -3.2440238
Z mean eval                  1.9102137
Z variance eval              0.15005085
total_rewards                [10584.85034936 11195.06561429 11336.89161477 11169.19238675
 10758.25482179 10737.23234443 10976.17289572 10982.49500014
 11072.28472195 10717.64831306]
total_rewards_mean           10953.00880622636
total_rewards_std            233.1843500936559
total_rewards_max            11336.891614771814
total_rewards_min            10584.850349356162
Number of train steps total  1828000
Number of env steps total    5486000
Number of rollouts total     0
Train Time (s)               146.28025486227125
(Previous) Eval Time (s)     17.553029103204608
Sample Time (s)              5.7747227172367275
Epoch Time (s)               169.60800668271258
Total Train Time (s)         78468.39501549723
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:41:28.106412 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #456 | Epoch Duration: 169.69767141342163
2020-01-13 05:41:28.106613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.909819
Z variance train             0.15012941
KL Divergence                48.25519
KL Loss                      4.825519
QF Loss                      244.11487
VF Loss                      93.050125
Policy Loss                  -1598.3359
Q Predictions Mean           1596.7449
Q Predictions Std            1561.0327
Q Predictions Max            4961.64
Q Predictions Min            707.5679
V Predictions Mean           1595.84
V Predictions Std            1558.231
V Predictions Max            4950.899
V Predictions Min            705.87177
Log Pis Mean                 0.20288816
Log Pis Std                  4.0837383
Log Pis Max                  14.077455
Log Pis Min                  -7.8017006
Policy mu Mean               0.105428346
Policy mu Std                0.9247552
Policy mu Max                3.438371
Policy mu Min                -2.7180946
Policy log std Mean          -0.5253412
Policy log std Std           0.33297235
Policy log std Max           0.011527926
Policy log std Min           -2.9251113
Z mean eval                  1.8834327
Z variance eval              0.08861502
total_rewards                [10361.69436735 10272.90539492  4647.75341183 10521.38748608
 10442.7852674  10600.45001418 10572.46800704 10576.15796406
 10590.46418712 10516.0419514 ]
total_rewards_mean           9910.210805136705
total_rewards_std            1757.1081784891603
total_rewards_max            10600.450014178412
total_rewards_min            4647.753411825078
Number of train steps total  1832000
Number of env steps total    5498000
Number of rollouts total     0
Train Time (s)               145.38320007221773
(Previous) Eval Time (s)     20.823622571770102
Sample Time (s)              6.38406097702682
Epoch Time (s)               172.59088362101465
Total Train Time (s)         78641.07281193044
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:44:20.789516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #457 | Epoch Duration: 172.6827392578125
2020-01-13 05:44:20.789705 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #457 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8832384
Z variance train             0.088624954
KL Divergence                48.310436
KL Loss                      4.8310437
QF Loss                      131.0792
VF Loss                      58.17727
Policy Loss                  -1505.8469
Q Predictions Mean           1502.4905
Q Predictions Std            1491.0674
Q Predictions Max            4960.8926
Q Predictions Min            686.80975
V Predictions Mean           1510.8397
V Predictions Std            1489.2134
V Predictions Max            4945.905
V Predictions Min            696.7612
Log Pis Mean                 -0.08536706
Log Pis Std                  3.7779837
Log Pis Max                  23.878967
Log Pis Min                  -6.218171
Policy mu Mean               0.07701835
Policy mu Std                0.9120711
Policy mu Max                3.441033
Policy mu Min                -2.924437
Policy log std Mean          -0.52007365
Policy log std Std           0.29019082
Policy log std Max           -0.053328693
Policy log std Min           -2.938697
Z mean eval                  1.8892654
Z variance eval              0.061988372
total_rewards                [ 9970.07490403 10564.59030287  8980.36106314 10530.92290263
 10040.49268718 10424.25685543  2541.72238901  8455.86149775
 10896.81119249 10342.41868945]
total_rewards_mean           9274.75124839736
total_rewards_std            2355.732708568687
total_rewards_max            10896.81119248925
total_rewards_min            2541.722389011683
Number of train steps total  1836000
Number of env steps total    5510000
Number of rollouts total     0
Train Time (s)               147.29853372601792
(Previous) Eval Time (s)     21.004796106833965
Sample Time (s)              6.472396778874099
Epoch Time (s)               174.775726611726
Total Train Time (s)         78815.9547014148
Epoch                        458
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:47:15.675147 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #458 | Epoch Duration: 174.8853099346161
2020-01-13 05:47:15.675288 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8876864
Z variance train             0.06198298
KL Divergence                49.57578
KL Loss                      4.957578
QF Loss                      190.00531
VF Loss                      27.493376
Policy Loss                  -1362.2667
Q Predictions Mean           1361.4912
Q Predictions Std            1367.6449
Q Predictions Max            4930.997
Q Predictions Min            686.28827
V Predictions Mean           1364.1172
V Predictions Std            1363.9231
V Predictions Max            4923.9775
V Predictions Min            690.0906
Log Pis Mean                 -0.068887964
Log Pis Std                  4.197683
Log Pis Max                  24.448935
Log Pis Min                  -7.1302576
Policy mu Mean               0.08237127
Policy mu Std                0.91370416
Policy mu Max                3.6378846
Policy mu Min                -4.0116067
Policy log std Mean          -0.50880325
Policy log std Std           0.29413784
Policy log std Max           0.017705888
Policy log std Min           -2.9697964
Z mean eval                  1.904365
Z variance eval              0.054545116
total_rewards                [10672.74211336 10716.52945824 10877.63837607 10843.29637805
 11283.18000984 10846.98328148 10751.82693402 10828.42843197
 10773.78505584 10881.07912332]
total_rewards_mean           10847.54891621803
total_rewards_std            159.5353937912421
total_rewards_max            11283.180009836538
total_rewards_min            10672.742113357011
Number of train steps total  1840000
Number of env steps total    5522000
Number of rollouts total     0
Train Time (s)               146.54742319323123
(Previous) Eval Time (s)     20.73665491119027
Sample Time (s)              6.575991722755134
Epoch Time (s)               173.86006982717663
Total Train Time (s)         78989.91084654769
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:50:09.638567 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #459 | Epoch Duration: 173.96316480636597
2020-01-13 05:50:09.638781 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #459 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9026988
Z variance train             0.05444293
KL Divergence                51.012215
KL Loss                      5.1012216
QF Loss                      90.80066
VF Loss                      63.72102
Policy Loss                  -1429.9531
Q Predictions Mean           1429.1816
Q Predictions Std            1452.7177
Q Predictions Max            4995.831
Q Predictions Min            704.8311
V Predictions Mean           1434.6053
V Predictions Std            1452.2661
V Predictions Max            4994.632
V Predictions Min            713.534
Log Pis Mean                 -0.23260084
Log Pis Std                  3.6518412
Log Pis Max                  15.43363
Log Pis Min                  -7.658534
Policy mu Mean               0.03326461
Policy mu Std                0.9052829
Policy mu Max                3.139291
Policy mu Min                -2.7270865
Policy log std Mean          -0.49945745
Policy log std Std           0.28360137
Policy log std Max           0.040359944
Policy log std Min           -2.7884793
Z mean eval                  1.8909731
Z variance eval              0.07918452
total_rewards                [10589.33270108 10970.54728556 11125.99401537 11002.35714765
 10922.56758013 10934.84307904 10758.05343323 10930.17687738
 11022.30606691 10669.09531265]
total_rewards_mean           10892.527349900036
total_rewards_std            159.22987219599264
total_rewards_max            11125.994015365113
total_rewards_min            10589.332701080077
Number of train steps total  1844000
Number of env steps total    5534000
Number of rollouts total     0
Train Time (s)               146.4363874271512
(Previous) Eval Time (s)     20.760548822116107
Sample Time (s)              12.687214400619268
Epoch Time (s)               179.88415064988658
Total Train Time (s)         79169.88309581764
Epoch                        460
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:53:09.616429 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #460 | Epoch Duration: 179.97750234603882
2020-01-13 05:53:09.616620 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8904483
Z variance train             0.0793394
KL Divergence                50.73609
KL Loss                      5.0736094
QF Loss                      192.78552
VF Loss                      69.25722
Policy Loss                  -1437.6821
Q Predictions Mean           1436.305
Q Predictions Std            1414.0869
Q Predictions Max            4972.3613
Q Predictions Min            698.5021
V Predictions Mean           1437.1917
V Predictions Std            1412.1343
V Predictions Max            4971.539
V Predictions Min            696.3659
Log Pis Mean                 -0.06304833
Log Pis Std                  4.39167
Log Pis Max                  16.87181
Log Pis Min                  -6.5205264
Policy mu Mean               0.037630454
Policy mu Std                0.917547
Policy mu Max                2.5744562
Policy mu Min                -2.8532643
Policy log std Mean          -0.51636344
Policy log std Std           0.29636282
Policy log std Max           0.0014389753
Policy log std Min           -3.166156
Z mean eval                  1.9063431
Z variance eval              0.03828411
total_rewards                [10250.90083104 10752.99785637 10763.17763427 10217.82142663
 11005.52652676 10763.51021614 10439.14459066 10081.26004834
 11068.42760135 10401.92277121]
total_rewards_mean           10574.468950278038
total_rewards_std            325.00147572040515
total_rewards_max            11068.427601347676
total_rewards_min            10081.26004834004
Number of train steps total  1848000
Number of env steps total    5546000
Number of rollouts total     0
Train Time (s)               147.34830001695082
(Previous) Eval Time (s)     20.778069878928363
Sample Time (s)              6.4701144327409565
Epoch Time (s)               174.59648432862014
Total Train Time (s)         79344.56088691996
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:56:04.298126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #461 | Epoch Duration: 174.68137860298157
2020-01-13 05:56:04.298263 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #461 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9046692
Z variance train             0.038234077
KL Divergence                52.27316
KL Loss                      5.227316
QF Loss                      102.883415
VF Loss                      90.60936
Policy Loss                  -1412.1487
Q Predictions Mean           1409.0074
Q Predictions Std            1419.3037
Q Predictions Max            4935.3154
Q Predictions Min            699.7846
V Predictions Mean           1418.489
V Predictions Std            1420.2362
V Predictions Max            4949.3755
V Predictions Min            702.2342
Log Pis Mean                 -0.011594322
Log Pis Std                  3.9127812
Log Pis Max                  12.062646
Log Pis Min                  -7.459061
Policy mu Mean               0.08613498
Policy mu Std                0.8917188
Policy mu Max                3.3490036
Policy mu Min                -2.8154528
Policy log std Mean          -0.5309709
Policy log std Std           0.3258561
Policy log std Max           -0.04775229
Policy log std Min           -2.9782064
Z mean eval                  1.9299333
Z variance eval              0.0711736
total_rewards                [10277.81813232 10770.39362387 10424.22071918 11014.47688519
 10903.88412963 10976.83027241 11011.49018371 11025.66633353
 10793.86799797 10926.74147333]
total_rewards_mean           10812.5389751125
total_rewards_std            247.58914267075536
total_rewards_max            11025.666333525218
total_rewards_min            10277.818132315668
Number of train steps total  1852000
Number of env steps total    5558000
Number of rollouts total     0
Train Time (s)               146.7788669941947
(Previous) Eval Time (s)     21.09874525759369
Sample Time (s)              6.3334707682952285
Epoch Time (s)               174.2110830200836
Total Train Time (s)         79518.85822705505
Epoch                        462
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:58:58.599196 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #462 | Epoch Duration: 174.3008270263672
2020-01-13 05:58:58.599371 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.92852
Z variance train             0.07164474
KL Divergence                50.76503
KL Loss                      5.0765033
QF Loss                      196.98402
VF Loss                      38.523994
Policy Loss                  -1413.8032
Q Predictions Mean           1409.1824
Q Predictions Std            1403.0155
Q Predictions Max            5023.701
Q Predictions Min            705.69073
V Predictions Mean           1414.9557
V Predictions Std            1401.9265
V Predictions Max            4997.3545
V Predictions Min            703.36035
Log Pis Mean                 -0.047372043
Log Pis Std                  3.9818876
Log Pis Max                  14.611339
Log Pis Min                  -6.646678
Policy mu Mean               0.11129713
Policy mu Std                0.9098279
Policy mu Max                3.3784711
Policy mu Min                -3.1366887
Policy log std Mean          -0.52653104
Policy log std Std           0.304095
Policy log std Max           0.099654555
Policy log std Min           -2.9586663
Z mean eval                  1.89444
Z variance eval              0.07753505
total_rewards                [10765.10772074 10900.91519094 10905.71146958 10786.34732199
 11079.10948368 10994.36516567 10483.29904952 10681.79227691
 10590.75606355 11057.82096984]
total_rewards_mean           10824.522471240834
total_rewards_std            188.93287118533115
total_rewards_max            11079.109483678714
total_rewards_min            10483.299049518335
Number of train steps total  1856000
Number of env steps total    5570000
Number of rollouts total     0
Train Time (s)               146.1811050591059
(Previous) Eval Time (s)     17.54022894660011
Sample Time (s)              6.330197154544294
Epoch Time (s)               170.0515311602503
Total Train Time (s)         79688.99335803138
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:48.738463 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #463 | Epoch Duration: 170.13894724845886
2020-01-13 06:01:48.738654 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #463 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8944263
Z variance train             0.077645466
KL Divergence                50.9314
KL Loss                      5.09314
QF Loss                      128.68387
VF Loss                      66.94386
Policy Loss                  -1500.0724
Q Predictions Mean           1497.6648
Q Predictions Std            1476.9108
Q Predictions Max            5004.3877
Q Predictions Min            699.3096
V Predictions Mean           1498.8702
V Predictions Std            1479.0613
V Predictions Max            5011.249
V Predictions Min            705.8989
Log Pis Mean                 0.0020401292
Log Pis Std                  4.1038446
Log Pis Max                  18.014107
Log Pis Min                  -6.342431
Policy mu Mean               0.05722438
Policy mu Std                0.92467296
Policy mu Max                3.012131
Policy mu Min                -3.4542592
Policy log std Mean          -0.50007653
Policy log std Std           0.29269984
Policy log std Max           0.078152835
Policy log std Min           -3.0819004
Z mean eval                  1.9042677
Z variance eval              0.09391199
total_rewards                [10390.72708279 10998.21463703 10790.1073516  11066.650545
 11095.99620452 10706.13787624 10540.07481073 11162.29214019
 10908.31023819 10815.2207367 ]
total_rewards_mean           10847.373162299255
total_rewards_std            237.22455699808486
total_rewards_max            11162.292140194902
total_rewards_min            10390.727082789832
Number of train steps total  1860000
Number of env steps total    5582000
Number of rollouts total     0
Train Time (s)               145.9456521049142
(Previous) Eval Time (s)     17.842334665823728
Sample Time (s)              6.429427412804216
Epoch Time (s)               170.21741418354213
Total Train Time (s)         79859.2956757322
Epoch                        464
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:04:39.045579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #464 | Epoch Duration: 170.30671525001526
2020-01-13 06:04:39.045854 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.905381
Z variance train             0.09386529
KL Divergence                50.81174
KL Loss                      5.0811744
QF Loss                      389.43597
VF Loss                      40.895363
Policy Loss                  -1342.6548
Q Predictions Mean           1339.1733
Q Predictions Std            1358.9259
Q Predictions Max            5083.173
Q Predictions Min            706.1784
V Predictions Mean           1343.1437
V Predictions Std            1356.8284
V Predictions Max            5015.5596
V Predictions Min            705.5775
Log Pis Mean                 -0.2406742
Log Pis Std                  3.9735436
Log Pis Max                  14.178722
Log Pis Min                  -7.3380065
Policy mu Mean               0.04113962
Policy mu Std                0.89572865
Policy mu Max                3.0843453
Policy mu Min                -2.7086544
Policy log std Mean          -0.49481153
Policy log std Std           0.30400616
Policy log std Max           0.059927344
Policy log std Min           -2.9820342
Z mean eval                  1.9018055
Z variance eval              0.0797833
total_rewards                [10783.43088075 11172.3539105  11145.08654901 11092.97331845
 11304.85342611 11116.89665706 11081.22177312 10946.65690658
 11214.25443114 10934.44786158]
total_rewards_mean           11079.217571430057
total_rewards_std            144.84229641133106
total_rewards_max            11304.853426114809
total_rewards_min            10783.43088074607
Number of train steps total  1864000
Number of env steps total    5594000
Number of rollouts total     0
Train Time (s)               146.326757799834
(Previous) Eval Time (s)     20.641468650195748
Sample Time (s)              6.393634412437677
Epoch Time (s)               173.36186086246744
Total Train Time (s)         80032.73647603998
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:07:32.488784 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #465 | Epoch Duration: 173.44274973869324
2020-01-13 06:07:32.488942 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #465 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9040706
Z variance train             0.07986385
KL Divergence                51.02527
KL Loss                      5.102527
QF Loss                      4555.6787
VF Loss                      118.02367
Policy Loss                  -1394.4857
Q Predictions Mean           1393.466
Q Predictions Std            1402.2827
Q Predictions Max            4990.5825
Q Predictions Min            696.2401
V Predictions Mean           1385.7753
V Predictions Std            1395.0312
V Predictions Max            4956.1665
V Predictions Min            699.82465
Log Pis Mean                 0.004979305
Log Pis Std                  3.9779332
Log Pis Max                  15.382381
Log Pis Min                  -6.991977
Policy mu Mean               0.056325775
Policy mu Std                0.9048963
Policy mu Max                2.560525
Policy mu Min                -2.861113
Policy log std Mean          -0.49192753
Policy log std Std           0.28335822
Policy log std Max           -0.01944092
Policy log std Min           -2.5022297
Z mean eval                  1.8977209
Z variance eval              0.075611606
total_rewards                [10588.32410513  3708.90409784  7319.27874311 10850.09408993
 10925.22311342 10798.31019821 11121.09821596 10869.2661335
 10452.67715619 11058.87451186]
total_rewards_mean           9769.205036516278
total_rewards_std            2283.2483398111017
total_rewards_max            11121.09821595887
total_rewards_min            3708.9040978408943
Number of train steps total  1868000
Number of env steps total    5606000
Number of rollouts total     0
Train Time (s)               146.5892332638614
(Previous) Eval Time (s)     20.991606883239
Sample Time (s)              6.4883266421966255
Epoch Time (s)               174.06916678929701
Total Train Time (s)         80206.88354482502
Epoch                        466
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:10:26.639775 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #466 | Epoch Duration: 174.15070343017578
2020-01-13 06:10:26.639957 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.898155
Z variance train             0.0754288
KL Divergence                49.319313
KL Loss                      4.9319315
QF Loss                      4203.176
VF Loss                      38.808083
Policy Loss                  -1505.8032
Q Predictions Mean           1504.226
Q Predictions Std            1521.9896
Q Predictions Max            4962.046
Q Predictions Min            698.65405
V Predictions Mean           1507.3025
V Predictions Std            1517.7719
V Predictions Max            4964.413
V Predictions Min            702.2797
Log Pis Mean                 -0.12744129
Log Pis Std                  3.7905934
Log Pis Max                  15.0334015
Log Pis Min                  -5.69446
Policy mu Mean               0.015414494
Policy mu Std                0.90964663
Policy mu Max                3.1454458
Policy mu Min                -3.4323356
Policy log std Mean          -0.5091925
Policy log std Std           0.28931844
Policy log std Max           0.019714475
Policy log std Min           -2.9405572
Z mean eval                  1.9342234
Z variance eval              0.08097483
total_rewards                [10667.91815875 10638.13026121 10047.28458706 10707.90051441
 10493.90405366 10832.23528165 10852.73554474 10397.82078123
 10765.02878424 10796.6626781 ]
total_rewards_mean           10619.96206450454
total_rewards_std            235.59940113859724
total_rewards_max            10852.735544742767
total_rewards_min            10047.284587057467
Number of train steps total  1872000
Number of env steps total    5618000
Number of rollouts total     0
Train Time (s)               149.84639490395784
(Previous) Eval Time (s)     20.69963901815936
Sample Time (s)              6.640363079961389
Epoch Time (s)               177.1863970020786
Total Train Time (s)         80384.15296738967
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:23.911478 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #467 | Epoch Duration: 177.27139401435852
2020-01-13 06:13:23.911624 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9357811
Z variance train             0.08104898
KL Divergence                50.63583
KL Loss                      5.063583
QF Loss                      141.08417
VF Loss                      46.78643
Policy Loss                  -1495.7389
Q Predictions Mean           1496.3269
Q Predictions Std            1510.9442
Q Predictions Max            5037.032
Q Predictions Min            673.054
V Predictions Mean           1493.124
V Predictions Std            1503.1544
V Predictions Max            5030.722
V Predictions Min            672.57007
Log Pis Mean                 0.040970713
Log Pis Std                  4.2209225
Log Pis Max                  22.272442
Log Pis Min                  -6.1763253
Policy mu Mean               -0.02211746
Policy mu Std                0.91754436
Policy mu Max                2.9467084
Policy mu Min                -3.1610296
Policy log std Mean          -0.4973286
Policy log std Std           0.28753284
Policy log std Max           -0.03518641
Policy log std Min           -2.794537
Z mean eval                  1.9118057
Z variance eval              0.07757226
total_rewards                [10171.51242949  9790.56138324 10390.21727852 10048.27983279
 10157.9454873   9984.36007376 10100.91636142 10418.20995358
 10055.05189563 10298.63412991]
total_rewards_mean           10141.568882564135
total_rewards_std            181.64584926376168
total_rewards_max            10418.209953578276
total_rewards_min            9790.561383244809
Number of train steps total  1876000
Number of env steps total    5630000
Number of rollouts total     0
Train Time (s)               146.93145877402276
(Previous) Eval Time (s)     20.987081818748266
Sample Time (s)              6.49509046273306
Epoch Time (s)               174.41363105550408
Total Train Time (s)         80558.64949877327
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:16:18.411527 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #468 | Epoch Duration: 174.49975180625916
2020-01-13 06:16:18.411752 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9121056
Z variance train             0.0775271
KL Divergence                49.499893
KL Loss                      4.9499893
QF Loss                      274.08038
VF Loss                      67.05533
Policy Loss                  -1524.1951
Q Predictions Mean           1519.2361
Q Predictions Std            1506.1125
Q Predictions Max            4860.576
Q Predictions Min            666.31165
V Predictions Mean           1522.4116
V Predictions Std            1508.1493
V Predictions Max            4830.562
V Predictions Min            678.25806
Log Pis Mean                 0.006069474
Log Pis Std                  3.7658951
Log Pis Max                  12.234846
Log Pis Min                  -5.89418
Policy mu Mean               0.03915518
Policy mu Std                0.9213236
Policy mu Max                2.8926644
Policy mu Min                -2.5968542
Policy log std Mean          -0.5091467
Policy log std Std           0.28292263
Policy log std Max           -0.028164208
Policy log std Min           -2.566405
Z mean eval                  1.8997482
Z variance eval              0.08620671
total_rewards                [11006.12068723 11111.92129857 11197.96943568 11255.42026759
 11201.24081931 10789.72501419 10888.87593947 11024.19426701
 11458.95964428 11211.86826934]
total_rewards_mean           11114.629564267827
total_rewards_std            184.05851119528714
total_rewards_max            11458.959644284796
total_rewards_min            10789.725014193067
Number of train steps total  1880000
Number of env steps total    5642000
Number of rollouts total     0
Train Time (s)               144.87706909375265
(Previous) Eval Time (s)     17.964134177193046
Sample Time (s)              6.313470317050815
Epoch Time (s)               169.1546735879965
Total Train Time (s)         80727.88962696819
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:19:07.658095 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #469 | Epoch Duration: 169.2462077140808
2020-01-13 06:19:07.658257 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8988708
Z variance train             0.086034335
KL Divergence                50.20752
KL Loss                      5.020752
QF Loss                      223.31522
VF Loss                      41.562107
Policy Loss                  -1391.9946
Q Predictions Mean           1388.3274
Q Predictions Std            1414.7264
Q Predictions Max            4942.7397
Q Predictions Min            701.855
V Predictions Mean           1390.396
V Predictions Std            1413.6566
V Predictions Max            4937.7344
V Predictions Min            703.9648
Log Pis Mean                 -0.08373403
Log Pis Std                  4.1959066
Log Pis Max                  19.834631
Log Pis Min                  -6.7451854
Policy mu Mean               0.04713446
Policy mu Std                0.8990403
Policy mu Max                3.1198704
Policy mu Min                -3.0776954
Policy log std Mean          -0.49410978
Policy log std Std           0.29663876
Policy log std Max           0.64274585
Policy log std Min           -2.930779
Z mean eval                  1.9465272
Z variance eval              0.10792641
total_rewards                [ 5017.78220965 10711.72362615 10108.2033531  10347.55055763
  6728.36609718  9922.25025175 10197.98157443 10646.74164294
 10655.37924646 10551.56319309]
total_rewards_mean           9488.754175237696
total_rewards_std            1864.0995102043987
total_rewards_max            10711.72362614961
total_rewards_min            5017.782209654667
Number of train steps total  1884000
Number of env steps total    5654000
Number of rollouts total     0
Train Time (s)               146.2207966791466
(Previous) Eval Time (s)     17.625145617872477
Sample Time (s)              6.338951169047505
Epoch Time (s)               170.18489346606657
Total Train Time (s)         80898.15451486176
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:21:57.929433 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #470 | Epoch Duration: 170.27103447914124
2020-01-13 06:21:57.929613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.945735
Z variance train             0.1078009
KL Divergence                50.19498
KL Loss                      5.0194983
QF Loss                      267.9864
VF Loss                      67.60443
Policy Loss                  -1310.7927
Q Predictions Mean           1311.1578
Q Predictions Std            1320.8882
Q Predictions Max            4935.015
Q Predictions Min            695.60614
V Predictions Mean           1317.6694
V Predictions Std            1320.8018
V Predictions Max            4914.177
V Predictions Min            699.9674
Log Pis Mean                 -0.6834066
Log Pis Std                  3.477547
Log Pis Max                  13.217736
Log Pis Min                  -7.7725377
Policy mu Mean               0.040283155
Policy mu Std                0.85421723
Policy mu Max                2.6063464
Policy mu Min                -2.763673
Policy log std Mean          -0.47042522
Policy log std Std           0.252242
Policy log std Max           0.014385104
Policy log std Min           -2.3408854
Z mean eval                  1.9020954
Z variance eval              0.059701808
total_rewards                [10932.4924989  11194.75862418 10774.66990052 11075.70778261
 10831.34821667 11120.80021836 10850.26428785 11005.52711471
 11029.52279879 11048.32780845]
total_rewards_mean           10986.341925103174
total_rewards_std            128.77216250600154
total_rewards_max            11194.758624176602
total_rewards_min            10774.66990051865
Number of train steps total  1888000
Number of env steps total    5666000
Number of rollouts total     0
Train Time (s)               146.51118022203445
(Previous) Eval Time (s)     20.782484869938344
Sample Time (s)              6.357478577177972
Epoch Time (s)               173.65114366915077
Total Train Time (s)         81071.88931461051
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:24:51.667366 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #471 | Epoch Duration: 173.73761916160583
2020-01-13 06:24:51.667517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #471 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9046685
Z variance train             0.059680752
KL Divergence                51.81332
KL Loss                      5.181332
QF Loss                      116.75201
VF Loss                      39.919456
Policy Loss                  -1364.4567
Q Predictions Mean           1360.9136
Q Predictions Std            1342.9758
Q Predictions Max            4939.248
Q Predictions Min            707.8516
V Predictions Mean           1363.0518
V Predictions Std            1342.2438
V Predictions Max            4937.4062
V Predictions Min            707.3256
Log Pis Mean                 -0.19136432
Log Pis Std                  3.9745934
Log Pis Max                  14.153146
Log Pis Min                  -6.765851
Policy mu Mean               0.046342343
Policy mu Std                0.88999355
Policy mu Max                3.4279509
Policy mu Min                -2.8243797
Policy log std Mean          -0.49910673
Policy log std Std           0.2805549
Policy log std Max           0.14655697
Policy log std Min           -2.82943
Z mean eval                  1.9043581
Z variance eval              0.03876396
total_rewards                [10625.13310875 11105.46812051 11120.05618114 11318.09650179
 10852.4076245  11043.6999986  11080.41829681 11298.50345706
 10352.49901757 11152.43731305]
total_rewards_mean           10994.871961978457
total_rewards_std            287.8791215277325
total_rewards_max            11318.096501785252
total_rewards_min            10352.499017570846
Number of train steps total  1892000
Number of env steps total    5678000
Number of rollouts total     0
Train Time (s)               147.6002483149059
(Previous) Eval Time (s)     20.76616905629635
Sample Time (s)              6.238984188530594
Epoch Time (s)               174.60540155973285
Total Train Time (s)         81246.58268728014
Epoch                        472
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:27:46.368494 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #472 | Epoch Duration: 174.7008557319641
2020-01-13 06:27:46.368700 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #472 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9053196
Z variance train             0.038859166
KL Divergence                53.41358
KL Loss                      5.341358
QF Loss                      2220.936
VF Loss                      108.33225
Policy Loss                  -1385.425
Q Predictions Mean           1380.7351
Q Predictions Std            1377.1395
Q Predictions Max            4969.3765
Q Predictions Min            330.04764
V Predictions Mean           1383.7319
V Predictions Std            1371.914
V Predictions Max            4956.5024
V Predictions Min            716.1331
Log Pis Mean                 -0.14858802
Log Pis Std                  4.1000395
Log Pis Max                  17.236443
Log Pis Min                  -8.057421
Policy mu Mean               0.060691725
Policy mu Std                0.90613234
Policy mu Max                3.169164
Policy mu Min                -3.2978404
Policy log std Mean          -0.51401854
Policy log std Std           0.29928002
Policy log std Max           -0.03928125
Policy log std Min           -2.773388
Z mean eval                  1.9210787
Z variance eval              0.05522249
total_rewards                [10444.05159977 10643.74112695 10848.71538242 10848.52244899
 10665.88272425 10893.5200308  10629.41340416 10807.24057546
 11036.56322511 10837.42343009]
total_rewards_mean           10765.507394797762
total_rewards_std            160.3728912438485
total_rewards_max            11036.563225106196
total_rewards_min            10444.051599769062
Number of train steps total  1896000
Number of env steps total    5690000
Number of rollouts total     0
Train Time (s)               146.02566036675125
(Previous) Eval Time (s)     20.71144007332623
Sample Time (s)              6.475900081451982
Epoch Time (s)               173.21300052152947
Total Train Time (s)         81419.88288313244
Epoch                        473
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:30:39.676841 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #473 | Epoch Duration: 173.30797410011292
2020-01-13 06:30:39.677048 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9229391
Z variance train             0.055282645
KL Divergence                52.649258
KL Loss                      5.264926
QF Loss                      178.03833
VF Loss                      84.07631
Policy Loss                  -1480.5052
Q Predictions Mean           1477.4048
Q Predictions Std            1467.6039
Q Predictions Max            5042.1836
Q Predictions Min            693.48785
V Predictions Mean           1480.7505
V Predictions Std            1466.2935
V Predictions Max            5015.8794
V Predictions Min            698.43567
Log Pis Mean                 0.1612994
Log Pis Std                  3.9319742
Log Pis Max                  16.746246
Log Pis Min                  -8.320455
Policy mu Mean               0.08616351
Policy mu Std                0.9175488
Policy mu Max                2.7740273
Policy mu Min                -3.1177535
Policy log std Mean          -0.5140763
Policy log std Std           0.30302346
Policy log std Max           0.038535744
Policy log std Min           -2.9753125
Z mean eval                  1.9100962
Z variance eval              0.061217755
total_rewards                [10473.40643426 11044.23091241 10805.43157174 11224.31751825
 11243.85701465 10784.23967781 10959.91990865 11537.44813732
 11165.74959366 11257.63597223]
total_rewards_mean           11049.623674098995
total_rewards_std            288.6402926289083
total_rewards_max            11537.448137324405
total_rewards_min            10473.406434264098
Number of train steps total  1900000
Number of env steps total    5702000
Number of rollouts total     0
Train Time (s)               146.13698118831962
(Previous) Eval Time (s)     17.55434784805402
Sample Time (s)              6.4445712878368795
Epoch Time (s)               170.13590032421052
Total Train Time (s)         81590.11779532162
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:33:29.907299 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #474 | Epoch Duration: 170.23010802268982
2020-01-13 06:33:29.907426 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.909878
Z variance train             0.06114787
KL Divergence                52.260525
KL Loss                      5.2260528
QF Loss                      4340.2476
VF Loss                      119.18564
Policy Loss                  -1608.1349
Q Predictions Mean           1603.5507
Q Predictions Std            1547.21
Q Predictions Max            5004.372
Q Predictions Min            703.65985
V Predictions Mean           1612.917
V Predictions Std            1546.969
V Predictions Max            5006.9062
V Predictions Min            712.1132
Log Pis Mean                 0.0739446
Log Pis Std                  3.845382
Log Pis Max                  13.2386265
Log Pis Min                  -7.819598
Policy mu Mean               0.036541257
Policy mu Std                0.92676437
Policy mu Max                3.1383789
Policy mu Min                -3.2900372
Policy log std Mean          -0.54351825
Policy log std Std           0.32046193
Policy log std Max           0.069793105
Policy log std Min           -3.0453513
Z mean eval                  1.9412501
Z variance eval              0.09927571
total_rewards                [10442.39026894 10883.29390644 10730.87242304 10838.01104536
 10683.57411856 11013.49603436 10830.88652971 10746.74844186
 10724.79483234 10611.21236709]
total_rewards_mean           10750.52799676799
total_rewards_std            148.591083625154
total_rewards_max            11013.49603436174
total_rewards_min            10442.390268939647
Number of train steps total  1904000
Number of env steps total    5714000
Number of rollouts total     0
Train Time (s)               144.97644892381504
(Previous) Eval Time (s)     18.946407571900636
Sample Time (s)              5.3985868049785495
Epoch Time (s)               169.32144330069423
Total Train Time (s)         81759.52181272721
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:36:19.320484 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #475 | Epoch Duration: 169.41292357444763
2020-01-13 06:36:19.320770 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9420536
Z variance train             0.0994717
KL Divergence                50.961502
KL Loss                      5.0961504
QF Loss                      364.52533
VF Loss                      177.13486
Policy Loss                  -1449.3782
Q Predictions Mean           1445.5295
Q Predictions Std            1443.6648
Q Predictions Max            4996.174
Q Predictions Min            699.0154
V Predictions Mean           1444.7388
V Predictions Std            1439.056
V Predictions Max            4977.1646
V Predictions Min            706.4408
Log Pis Mean                 0.030737206
Log Pis Std                  4.1159625
Log Pis Max                  19.502075
Log Pis Min                  -5.8206654
Policy mu Mean               0.054369193
Policy mu Std                0.93027186
Policy mu Max                3.3039904
Policy mu Min                -3.1314957
Policy log std Mean          -0.52987784
Policy log std Std           0.30634946
Policy log std Max           0.018318892
Policy log std Min           -2.9480867
Z mean eval                  1.9219061
Z variance eval              0.0644934
total_rewards                [10704.27067813 10831.99600311 11053.14782413 10969.32581858
 11131.54954544 10531.12824112 10803.93091052 10722.60587716
 10599.55473556  3779.8109137 ]
total_rewards_mean           10112.732054743869
total_rewards_std            2118.750248442419
total_rewards_max            11131.549545435022
total_rewards_min            3779.810913701394
Number of train steps total  1908000
Number of env steps total    5726000
Number of rollouts total     0
Train Time (s)               145.99292594008148
(Previous) Eval Time (s)     18.571296812966466
Sample Time (s)              6.496478038374335
Epoch Time (s)               171.06070079142228
Total Train Time (s)         81930.66845519375
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:39:10.475043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #476 | Epoch Duration: 171.1540687084198
2020-01-13 06:39:10.475220 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9215797
Z variance train             0.0644102
KL Divergence                51.76545
KL Loss                      5.176545
QF Loss                      148.6279
VF Loss                      65.55623
Policy Loss                  -1375.8143
Q Predictions Mean           1374.1105
Q Predictions Std            1374.2666
Q Predictions Max            4992.796
Q Predictions Min            709.285
V Predictions Mean           1377.5881
V Predictions Std            1373.4618
V Predictions Max            5006.9175
V Predictions Min            710.4366
Log Pis Mean                 -0.14660412
Log Pis Std                  3.8423984
Log Pis Max                  14.845793
Log Pis Min                  -7.796835
Policy mu Mean               0.056566115
Policy mu Std                0.9087318
Policy mu Max                3.3689997
Policy mu Min                -2.7435658
Policy log std Mean          -0.51040274
Policy log std Std           0.2835738
Policy log std Max           -6.812811e-05
Policy log std Min           -2.7377353
Z mean eval                  1.9382589
Z variance eval              0.07342229
total_rewards                [10494.38520104 11079.80951688 10270.20112471 11016.52913955
 11055.99616407 10727.59088454 10757.74693469  7848.54919204
 10722.86923251 11243.80190985]
total_rewards_mean           10521.747929988725
total_rewards_std            933.3572168686921
total_rewards_max            11243.80190985262
total_rewards_min            7848.54919203871
Number of train steps total  1912000
Number of env steps total    5738000
Number of rollouts total     0
Train Time (s)               146.44279421307147
(Previous) Eval Time (s)     17.49807812506333
Sample Time (s)              6.540099622681737
Epoch Time (s)               170.48097196081653
Total Train Time (s)         82101.25821323413
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:42:01.067995 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #477 | Epoch Duration: 170.5926399230957
2020-01-13 06:42:01.068163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #477 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9385636
Z variance train             0.07307295
KL Divergence                52.064342
KL Loss                      5.2064342
QF Loss                      311.86453
VF Loss                      119.08108
Policy Loss                  -1469.3341
Q Predictions Mean           1470.8298
Q Predictions Std            1479.9359
Q Predictions Max            5045.476
Q Predictions Min            708.6676
V Predictions Mean           1471.0474
V Predictions Std            1481.2026
V Predictions Max            5049.3164
V Predictions Min            711.97815
Log Pis Mean                 -0.36409104
Log Pis Std                  3.341307
Log Pis Max                  10.855498
Log Pis Min                  -7.0987706
Policy mu Mean               0.04609257
Policy mu Std                0.88407004
Policy mu Max                2.8240075
Policy mu Min                -2.295888
Policy log std Mean          -0.506406
Policy log std Std           0.2969356
Policy log std Max           0.015345156
Policy log std Min           -2.9158983
Z mean eval                  1.9299568
Z variance eval              0.10658576
total_rewards                [11073.44185022 11135.9225355  10931.74546114 11045.66647093
 11062.53188798 10763.27223995 10909.33135842 11023.6810065
 11378.18290707  3903.74672839]
total_rewards_mean           10322.752244610003
total_rewards_std            2145.053197381442
total_rewards_max            11378.182907066455
total_rewards_min            3903.7467283864407
Number of train steps total  1916000
Number of env steps total    5750000
Number of rollouts total     0
Train Time (s)               145.77133054286242
(Previous) Eval Time (s)     20.994496474973857
Sample Time (s)              5.496454646345228
Epoch Time (s)               172.2622816641815
Total Train Time (s)         82273.60583481751
Epoch                        478
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:44:53.417442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #478 | Epoch Duration: 172.34915041923523
2020-01-13 06:44:53.417579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #478 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9299237
Z variance train             0.106579706
KL Divergence                51.326534
KL Loss                      5.1326537
QF Loss                      4624.7905
VF Loss                      46.80402
Policy Loss                  -1471.5432
Q Predictions Mean           1471.9856
Q Predictions Std            1447.4788
Q Predictions Max            5030.6875
Q Predictions Min            698.8049
V Predictions Mean           1472.9326
V Predictions Std            1445.4672
V Predictions Max            5013.8296
V Predictions Min            690.9491
Log Pis Mean                 -0.4342942
Log Pis Std                  3.955201
Log Pis Max                  30.82098
Log Pis Min                  -8.323935
Policy mu Mean               -0.0025851277
Policy mu Std                0.88631725
Policy mu Max                4.9911547
Policy mu Min                -4.8986325
Policy log std Mean          -0.50897795
Policy log std Std           0.27937806
Policy log std Max           -0.03760436
Policy log std Min           -2.9815927
Z mean eval                  1.9169581
Z variance eval              0.07589391
total_rewards                [10912.57657116 11098.49832939 10449.07518703 11146.63708802
 10542.8707315  10969.94798221 10960.04839066 11075.96666963
 11132.51566476 10861.13327287]
total_rewards_mean           10914.926988722236
total_rewards_std            228.9263891838117
total_rewards_max            11146.637088020572
total_rewards_min            10449.075187027302
Number of train steps total  1920000
Number of env steps total    5762000
Number of rollouts total     0
Train Time (s)               145.67179154977202
(Previous) Eval Time (s)     20.833420569542795
Sample Time (s)              6.588676243554801
Epoch Time (s)               173.09388836286962
Total Train Time (s)         82446.8092748574
Epoch                        479
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:47:46.623639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #479 | Epoch Duration: 173.20596313476562
2020-01-13 06:47:46.623769 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #479 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9170904
Z variance train             0.075952135
KL Divergence                52.2453
KL Loss                      5.22453
QF Loss                      4823.877
VF Loss                      108.94285
Policy Loss                  -1390.6871
Q Predictions Mean           1390.1254
Q Predictions Std            1394.6223
Q Predictions Max            5087.4395
Q Predictions Min            703.66235
V Predictions Mean           1398.7285
V Predictions Std            1395.322
V Predictions Max            5087.968
V Predictions Min            712.6094
Log Pis Mean                 -0.20261204
Log Pis Std                  3.9276202
Log Pis Max                  17.113379
Log Pis Min                  -8.458815
Policy mu Mean               0.07365552
Policy mu Std                0.9090248
Policy mu Max                2.842454
Policy mu Min                -3.1087933
Policy log std Mean          -0.5027702
Policy log std Std           0.3024813
Policy log std Max           -0.0046758354
Policy log std Min           -2.944003
Z mean eval                  1.9371055
Z variance eval              0.04834003
total_rewards                [10462.87170378 10786.48675718 10735.66551991 10671.50497685
 10618.52214277 10398.26452177 10851.91329962 10725.44082392
 10733.68830939 10676.8276809 ]
total_rewards_mean           10666.118573608652
total_rewards_std            133.18932309875538
total_rewards_max            10851.91329961959
total_rewards_min            10398.264521770541
Number of train steps total  1924000
Number of env steps total    5774000
Number of rollouts total     0
Train Time (s)               145.20507576689124
(Previous) Eval Time (s)     20.543459633830935
Sample Time (s)              9.357812229543924
Epoch Time (s)               175.1063476302661
Total Train Time (s)         82622.09535995545
Epoch                        480
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:50:41.916645 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #480 | Epoch Duration: 175.29275393486023
2020-01-13 06:50:41.916884 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #480 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.937013
Z variance train             0.04834043
KL Divergence                54.550858
KL Loss                      5.4550858
QF Loss                      128.84842
VF Loss                      132.71507
Policy Loss                  -1442.434
Q Predictions Mean           1439.1498
Q Predictions Std            1427.5397
Q Predictions Max            5070.1616
Q Predictions Min            716.1996
V Predictions Mean           1435.3552
V Predictions Std            1424.9089
V Predictions Max            5042.5693
V Predictions Min            712.80804
Log Pis Mean                 -0.08497582
Log Pis Std                  3.9510744
Log Pis Max                  14.801898
Log Pis Min                  -8.917055
Policy mu Mean               0.03795256
Policy mu Std                0.9198515
Policy mu Max                3.2024722
Policy mu Min                -4.7321105
Policy log std Mean          -0.50886893
Policy log std Std           0.3076216
Policy log std Max           0.19354713
Policy log std Min           -2.882358
Z mean eval                  1.9692732
Z variance eval              0.03745597
total_rewards                [10581.52575357 10986.0354508  11138.20857527 10903.19513956
 10797.53569024 10780.07510739 10937.72946363 10969.75662728
 10814.28627298 10691.7802423 ]
total_rewards_mean           10860.012832301272
total_rewards_std            152.13956339301632
total_rewards_max            11138.208575270059
total_rewards_min            10581.525753570622
Number of train steps total  1928000
Number of env steps total    5786000
Number of rollouts total     0
Train Time (s)               146.53895801771432
(Previous) Eval Time (s)     20.80060675693676
Sample Time (s)              6.466960404999554
Epoch Time (s)               173.80652517965063
Total Train Time (s)         82795.98320999835
Epoch                        481
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:53:35.807397 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #481 | Epoch Duration: 173.89035058021545
2020-01-13 06:53:35.807532 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #481 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9693766
Z variance train             0.037395053
KL Divergence                53.976505
KL Loss                      5.3976507
QF Loss                      84.94588
VF Loss                      82.693245
Policy Loss                  -1416.0228
Q Predictions Mean           1412.0756
Q Predictions Std            1421.6146
Q Predictions Max            5019.7905
Q Predictions Min            699.7934
V Predictions Mean           1415.9609
V Predictions Std            1421.7878
V Predictions Max            5030.835
V Predictions Min            701.8262
Log Pis Mean                 -0.0464302
Log Pis Std                  3.981182
Log Pis Max                  16.694613
Log Pis Min                  -6.8252063
Policy mu Mean               0.051084857
Policy mu Std                0.9166088
Policy mu Max                3.3369873
Policy mu Min                -2.651164
Policy log std Mean          -0.48058796
Policy log std Std           0.2742504
Policy log std Max           -0.0041770935
Policy log std Min           -2.6100702
Z mean eval                  1.9761477
Z variance eval              0.042614684
total_rewards                [10412.79478474 11122.31697936 11263.68689292 10765.25121594
 10677.51969168 11076.16035287 11023.38883807 10989.80138139
 11077.08028867 10956.57526464]
total_rewards_mean           10936.457569029031
total_rewards_std            237.12967944979815
total_rewards_max            11263.686892919362
total_rewards_min            10412.794784737769
Number of train steps total  1932000
Number of env steps total    5798000
Number of rollouts total     0
Train Time (s)               146.34212571708485
(Previous) Eval Time (s)     20.615726411808282
Sample Time (s)              6.473025491926819
Epoch Time (s)               173.43087762081996
Total Train Time (s)         82969.49496896612
Epoch                        482
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:56:29.324363 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #482 | Epoch Duration: 173.51673483848572
2020-01-13 06:56:29.324496 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #482 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9789568
Z variance train             0.042562027
KL Divergence                54.525787
KL Loss                      5.452579
QF Loss                      415.30884
VF Loss                      90.72963
Policy Loss                  -1390.0847
Q Predictions Mean           1387.2959
Q Predictions Std            1414.0348
Q Predictions Max            5019.422
Q Predictions Min            699.47723
V Predictions Mean           1392.0417
V Predictions Std            1411.001
V Predictions Max            5019.1846
V Predictions Min            696.22516
Log Pis Mean                 -0.079107806
Log Pis Std                  4.091357
Log Pis Max                  17.440125
Log Pis Min                  -7.5784945
Policy mu Mean               0.016362902
Policy mu Std                0.93215674
Policy mu Max                4.23165
Policy mu Min                -3.4624796
Policy log std Mean          -0.48944935
Policy log std Std           0.29558548
Policy log std Max           0.33884355
Policy log std Min           -3.0141518
Z mean eval                  1.9454267
Z variance eval              0.04254834
total_rewards                [10715.70098637 10667.65604079 11065.85269419 10879.59185096
 10622.53924284 10373.9616072  11056.1380031  10650.78119119
 10784.70231981 10602.96571051]
total_rewards_mean           10741.988964695545
total_rewards_std            201.9681794420593
total_rewards_max            11065.85269418751
total_rewards_min            10373.961607199722
Number of train steps total  1936000
Number of env steps total    5810000
Number of rollouts total     0
Train Time (s)               146.23701600497589
(Previous) Eval Time (s)     20.69924806896597
Sample Time (s)              6.304866271559149
Epoch Time (s)               173.241130345501
Total Train Time (s)         83142.8266882482
Epoch                        483
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:59:22.659126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #483 | Epoch Duration: 173.33453249931335
2020-01-13 06:59:22.659257 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #483 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9451978
Z variance train             0.0426062
KL Divergence                54.307434
KL Loss                      5.4307437
QF Loss                      93.58286
VF Loss                      33.579403
Policy Loss                  -1385.7599
Q Predictions Mean           1384.6838
Q Predictions Std            1405.13
Q Predictions Max            5087.316
Q Predictions Min            686.1892
V Predictions Mean           1385.3654
V Predictions Std            1400.3682
V Predictions Max            5052.7607
V Predictions Min            707.45
Log Pis Mean                 -0.4753527
Log Pis Std                  3.5704572
Log Pis Max                  11.902157
Log Pis Min                  -7.3502254
Policy mu Mean               0.03301279
Policy mu Std                0.86823106
Policy mu Max                2.7155745
Policy mu Min                -2.6191165
Policy log std Mean          -0.4934486
Policy log std Std           0.26674742
Policy log std Max           -0.0540002
Policy log std Min           -2.8198137
Z mean eval                  1.95738
Z variance eval              0.054835726
total_rewards                [10356.75829916 11058.51401962 11077.00772916 11035.04407885
 10979.48302005 10937.30410438 11055.14572195 11134.61747748
 11144.16262557 11108.61672486]
total_rewards_mean           10988.665380110357
total_rewards_std            219.3518659918495
total_rewards_max            11144.162625565496
total_rewards_min            10356.758299160785
Number of train steps total  1940000
Number of env steps total    5822000
Number of rollouts total     0
Train Time (s)               146.39351431978866
(Previous) Eval Time (s)     21.153218193911016
Sample Time (s)              6.453431409783661
Epoch Time (s)               174.00016392348334
Total Train Time (s)         83316.90810581436
Epoch                        484
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:02:16.745677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #484 | Epoch Duration: 174.08632349967957
2020-01-13 07:02:16.745814 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #484 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9557072
Z variance train             0.054739468
KL Divergence                53.76587
KL Loss                      5.376587
QF Loss                      102.346924
VF Loss                      78.00208
Policy Loss                  -1572.4355
Q Predictions Mean           1566.0039
Q Predictions Std            1531.2759
Q Predictions Max            4966.7393
Q Predictions Min            695.5759
V Predictions Mean           1569.5193
V Predictions Std            1526.9531
V Predictions Max            4952.2666
V Predictions Min            700.0793
Log Pis Mean                 0.15987879
Log Pis Std                  4.252282
Log Pis Max                  22.14328
Log Pis Min                  -7.5532575
Policy mu Mean               0.024124483
Policy mu Std                0.9453691
Policy mu Max                4.5093217
Policy mu Min                -3.8601558
Policy log std Mean          -0.5027843
Policy log std Std           0.2819894
Policy log std Max           0.2391034
Policy log std Min           -2.4361587
Z mean eval                  1.9583254
Z variance eval              0.055874597
total_rewards                [11009.12229625 10871.39475379 10986.65734384 10712.36166389
 10770.65279228 11045.18750013 10966.61321259 11211.39310888
 11282.76218016  9161.91563331]
total_rewards_mean           10801.806048511973
total_rewards_std            571.4613115496348
total_rewards_max            11282.762180162412
total_rewards_min            9161.915633305362
Number of train steps total  1944000
Number of env steps total    5834000
Number of rollouts total     0
Train Time (s)               146.3954515978694
(Previous) Eval Time (s)     20.738516284618527
Sample Time (s)              6.472948368173093
Epoch Time (s)               173.60691625066102
Total Train Time (s)         83490.60799352312
Epoch                        485
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:05:10.447759 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #485 | Epoch Duration: 173.7018482685089
2020-01-13 07:05:10.447900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #485 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9594568
Z variance train             0.05595585
KL Divergence                54.853333
KL Loss                      5.4853334
QF Loss                      93.67799
VF Loss                      251.47589
Policy Loss                  -1493.9791
Q Predictions Mean           1492.3896
Q Predictions Std            1513.509
Q Predictions Max            5019.5713
Q Predictions Min            713.07666
V Predictions Mean           1496.6304
V Predictions Std            1512.919
V Predictions Max            5039.502
V Predictions Min            720.80316
Log Pis Mean                 -0.049738526
Log Pis Std                  3.9673846
Log Pis Max                  19.076355
Log Pis Min                  -7.6999006
Policy mu Mean               -0.011742544
Policy mu Std                0.9130639
Policy mu Max                4.165495
Policy mu Min                -3.399548
Policy log std Mean          -0.50905174
Policy log std Std           0.2847112
Policy log std Max           -0.06492394
Policy log std Min           -2.7844129
Z mean eval                  1.9226011
Z variance eval              0.053735264
total_rewards                [11097.25885303 11011.27930944  4318.4229068  10664.97383921
 10722.56941573  7016.23552817 10935.51691758 11112.5833255
 11015.1763217  11048.44702624]
total_rewards_mean           9894.24634433899
total_rewards_std            2202.388422199075
total_rewards_max            11112.58332549745
total_rewards_min            4318.422906797959
Number of train steps total  1948000
Number of env steps total    5846000
Number of rollouts total     0
Train Time (s)               146.76564952731133
(Previous) Eval Time (s)     21.27900206670165
Sample Time (s)              6.492278041318059
Epoch Time (s)               174.53692963533103
Total Train Time (s)         83665.22462728061
Epoch                        486
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:08:05.066744 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #486 | Epoch Duration: 174.61874914169312
2020-01-13 07:08:05.066876 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #486 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9212223
Z variance train             0.05382859
KL Divergence                53.12845
KL Loss                      5.3128448
QF Loss                      114.50653
VF Loss                      83.81926
Policy Loss                  -1292.2568
Q Predictions Mean           1287.6536
Q Predictions Std            1287.3813
Q Predictions Max            4963.4424
Q Predictions Min            710.7223
V Predictions Mean           1294.7427
V Predictions Std            1289.64
V Predictions Max            4958.143
V Predictions Min            715.3325
Log Pis Mean                 -0.59941816
Log Pis Std                  3.7429721
Log Pis Max                  15.335223
Log Pis Min                  -7.383543
Policy mu Mean               0.011817004
Policy mu Std                0.8345059
Policy mu Max                3.2484727
Policy mu Min                -2.9993284
Policy log std Mean          -0.49974445
Policy log std Std           0.25557977
Policy log std Max           -0.040153086
Policy log std Min           -2.5204318
Z mean eval                  1.9446714
Z variance eval              0.049134355
total_rewards                [10928.14771469 10816.9790382  11089.63604125 11086.88300115
 11185.3028744  10655.16679217 11018.49110733 10853.29618325
 10853.38799265 10892.06035118]
total_rewards_mean           10937.935109627693
total_rewards_std            149.65936951715716
total_rewards_max            11185.302874404384
total_rewards_min            10655.166792170658
Number of train steps total  1952000
Number of env steps total    5858000
Number of rollouts total     0
Train Time (s)               147.72733874525875
(Previous) Eval Time (s)     17.47055237693712
Sample Time (s)              6.40812756260857
Epoch Time (s)               171.60601868480444
Total Train Time (s)         83836.90765724238
Epoch                        487
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:10:56.754169 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #487 | Epoch Duration: 171.68716549873352
2020-01-13 07:10:56.754344 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9446996
Z variance train             0.049068123
KL Divergence                53.445724
KL Loss                      5.3445725
QF Loss                      305.7442
VF Loss                      66.65883
Policy Loss                  -1490.2375
Q Predictions Mean           1487.143
Q Predictions Std            1485.9208
Q Predictions Max            5002.408
Q Predictions Min            705.7877
V Predictions Mean           1490.3641
V Predictions Std            1480.8246
V Predictions Max            4986.288
V Predictions Min            708.4897
Log Pis Mean                 0.014526013
Log Pis Std                  4.227763
Log Pis Max                  22.754826
Log Pis Min                  -6.7148705
Policy mu Mean               0.07356844
Policy mu Std                0.91941
Policy mu Max                3.8309798
Policy mu Min                -3.7071712
Policy log std Mean          -0.5026904
Policy log std Std           0.31373593
Policy log std Max           -0.029058099
Policy log std Min           -3.042889
Z mean eval                  1.9381412
Z variance eval              0.06005478
total_rewards                [10468.48163604 11099.68284002 11130.36353529 11148.78269826
 10616.90396092 10869.5582145  10982.32229454 10938.68057022
 10615.96235365 11115.32122731]
total_rewards_mean           10898.605933074885
total_rewards_std            236.09445608991933
total_rewards_max            11148.782698261128
total_rewards_min            10468.48163603935
Number of train steps total  1956000
Number of env steps total    5870000
Number of rollouts total     0
Train Time (s)               146.08274261187762
(Previous) Eval Time (s)     17.419769917149097
Sample Time (s)              6.389797583222389
Epoch Time (s)               169.8923101122491
Total Train Time (s)         84006.88329979079
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:13:46.736399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #488 | Epoch Duration: 169.9819095134735
2020-01-13 07:13:46.736597 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #488 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9375412
Z variance train             0.059852958
KL Divergence                52.882275
KL Loss                      5.2882276
QF Loss                      9205.094
VF Loss                      126.374176
Policy Loss                  -1343.932
Q Predictions Mean           1340.2211
Q Predictions Std            1316.7458
Q Predictions Max            4979.33
Q Predictions Min            712.22064
V Predictions Mean           1337.8865
V Predictions Std            1312.4347
V Predictions Max            4956.414
V Predictions Min            710.1344
Log Pis Mean                 -0.31710798
Log Pis Std                  3.6837862
Log Pis Max                  17.153667
Log Pis Min                  -7.7848554
Policy mu Mean               0.057055544
Policy mu Std                0.889537
Policy mu Max                2.8416789
Policy mu Min                -3.5108619
Policy log std Mean          -0.4834763
Policy log std Std           0.2683077
Policy log std Max           0.0358842
Policy log std Min           -2.5037935
Z mean eval                  1.9335206
Z variance eval              0.04502097
total_rewards                [10279.4984387  10102.36011311 10011.87503935 10497.77784695
 10158.70099246 10294.68555273 10426.48812872 10504.52952331
  7085.33263948 10196.28866769]
total_rewards_mean           9955.753694250398
total_rewards_std            969.4960661662184
total_rewards_max            10504.529523313282
total_rewards_min            7085.332639479658
Number of train steps total  1960000
Number of env steps total    5882000
Number of rollouts total     0
Train Time (s)               146.72635693196207
(Previous) Eval Time (s)     20.985753951128572
Sample Time (s)              6.367701159790158
Epoch Time (s)               174.0798120428808
Total Train Time (s)         84181.05207213946
Epoch                        489
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:16:40.909771 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #489 | Epoch Duration: 174.17302250862122
2020-01-13 07:16:40.909976 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #489 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9343103
Z variance train             0.044902317
KL Divergence                53.374916
KL Loss                      5.3374915
QF Loss                      410.21814
VF Loss                      136.72723
Policy Loss                  -1368.079
Q Predictions Mean           1366.7825
Q Predictions Std            1391.4911
Q Predictions Max            5057.355
Q Predictions Min            703.56305
V Predictions Mean           1373.2458
V Predictions Std            1388.1617
V Predictions Max            5043.0713
V Predictions Min            712.02625
Log Pis Mean                 -0.24347012
Log Pis Std                  4.084296
Log Pis Max                  24.356047
Log Pis Min                  -8.301779
Policy mu Mean               0.028199038
Policy mu Std                0.91468996
Policy mu Max                3.6019006
Policy mu Min                -3.6024704
Policy log std Mean          -0.49217138
Policy log std Std           0.266083
Policy log std Max           -0.021850526
Policy log std Min           -2.7541308
Z mean eval                  1.9350755
Z variance eval              0.033555787
total_rewards                [10976.99257723 11001.49132812 11129.42707009 10729.05839897
 11497.68066896 11156.04488128 10718.02832826 10966.3656533
 10891.49952413 10872.95348216]
total_rewards_mean           10993.954191250175
total_rewards_std            217.00582533620235
total_rewards_max            11497.68066895682
total_rewards_min            10718.028328257642
Number of train steps total  1964000
Number of env steps total    5894000
Number of rollouts total     0
Train Time (s)               147.9416747679934
(Previous) Eval Time (s)     17.9857235760428
Sample Time (s)              6.3824056959711015
Epoch Time (s)               172.3098040400073
Total Train Time (s)         84353.448759072
Epoch                        490
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:19:33.311434 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #490 | Epoch Duration: 172.4013020992279
2020-01-13 07:19:33.311622 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #490 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9340433
Z variance train             0.03345848
KL Divergence                53.00472
KL Loss                      5.300472
QF Loss                      4360.878
VF Loss                      90.465965
Policy Loss                  -1386.9103
Q Predictions Mean           1386.6255
Q Predictions Std            1389.5698
Q Predictions Max            5035.524
Q Predictions Min            711.2699
V Predictions Mean           1383.1174
V Predictions Std            1386.9846
V Predictions Max            5027.6772
V Predictions Min            709.4045
Log Pis Mean                 -0.3000763
Log Pis Std                  3.6581514
Log Pis Max                  18.211031
Log Pis Min                  -6.398287
Policy mu Mean               0.032862693
Policy mu Std                0.8911175
Policy mu Max                3.2790208
Policy mu Min                -3.559864
Policy log std Mean          -0.5110021
Policy log std Std           0.2713104
Policy log std Max           0.12447268
Policy log std Min           -2.8964915
Z mean eval                  1.9444809
Z variance eval              0.059387065
total_rewards                [10677.87155359 10937.86790553 10769.43592864 10930.45396975
 10682.35675995 10773.01893938 10814.55661306 10895.78934051
 10827.63894164 10832.4268923 ]
total_rewards_mean           10814.141684436076
total_rewards_std            86.97485948994915
total_rewards_max            10937.867905533181
total_rewards_min            10677.87155359129
Number of train steps total  1968000
Number of env steps total    5906000
Number of rollouts total     0
Train Time (s)               146.5605505942367
(Previous) Eval Time (s)     20.715407208073884
Sample Time (s)              6.482214357238263
Epoch Time (s)               173.75817215954885
Total Train Time (s)         84527.28812773107
Epoch                        491
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:22:27.153081 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #491 | Epoch Duration: 173.84133124351501
2020-01-13 07:22:27.153213 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #491 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9447606
Z variance train             0.059369873
KL Divergence                51.16221
KL Loss                      5.116221
QF Loss                      4631.518
VF Loss                      66.615
Policy Loss                  -1372.0012
Q Predictions Mean           1371.612
Q Predictions Std            1367.8993
Q Predictions Max            4986.0195
Q Predictions Min            706.3628
V Predictions Mean           1367.3417
V Predictions Std            1363.2114
V Predictions Max            4944.6606
V Predictions Min            706.88495
Log Pis Mean                 0.01598242
Log Pis Std                  4.293718
Log Pis Max                  20.177704
Log Pis Min                  -8.025471
Policy mu Mean               -0.016672349
Policy mu Std                0.92411095
Policy mu Max                3.0789747
Policy mu Min                -4.0825872
Policy log std Mean          -0.4950594
Policy log std Std           0.2656351
Policy log std Max           -0.031531036
Policy log std Min           -2.3704424
Z mean eval                  1.9338996
Z variance eval              0.06801527
total_rewards                [10535.73710344 11303.53433008 10778.5455754  10826.84732061
 10819.93002365 11226.66975857 10734.50915949 10749.74231605
 11161.18720322 10915.07232051]
total_rewards_mean           10905.177511103504
total_rewards_std            233.85822436597962
total_rewards_max            11303.534330080794
total_rewards_min            10535.737103443967
Number of train steps total  1972000
Number of env steps total    5918000
Number of rollouts total     0
Train Time (s)               147.8821032908745
(Previous) Eval Time (s)     17.333984605968
Sample Time (s)              6.351521612145007
Epoch Time (s)               171.56760950898752
Total Train Time (s)         84698.9335016869
Epoch                        492
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:25:18.801126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #492 | Epoch Duration: 171.64781832695007
2020-01-13 07:25:18.801249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9332927
Z variance train             0.067967705
KL Divergence                50.04956
KL Loss                      5.0049562
QF Loss                      123.61888
VF Loss                      71.96081
Policy Loss                  -1379.7454
Q Predictions Mean           1374.2703
Q Predictions Std            1393.9899
Q Predictions Max            5034.424
Q Predictions Min            710.8836
V Predictions Mean           1378.1123
V Predictions Std            1389.2223
V Predictions Max            5036.7026
V Predictions Min            713.86084
Log Pis Mean                 0.02567634
Log Pis Std                  4.0299897
Log Pis Max                  16.520973
Log Pis Min                  -7.567665
Policy mu Mean               0.05566053
Policy mu Std                0.90914106
Policy mu Max                3.275959
Policy mu Min                -2.7109885
Policy log std Mean          -0.47848177
Policy log std Std           0.30573928
Policy log std Max           -0.013814092
Policy log std Min           -2.8033571
Z mean eval                  1.9287109
Z variance eval              0.046984974
total_rewards                [ 9984.92942351 10160.40369556 10211.90127334  9995.57488896
 10325.12715843  9750.86663642 10210.63015936 10264.28486565
 10121.43634555  9988.64526621]
total_rewards_mean           10101.379971300079
total_rewards_std            162.77640661482283
total_rewards_max            10325.12715842606
total_rewards_min            9750.8666364242
Number of train steps total  1976000
Number of env steps total    5930000
Number of rollouts total     0
Train Time (s)               145.5660469578579
(Previous) Eval Time (s)     17.52568938676268
Sample Time (s)              5.3674680553376675
Epoch Time (s)               168.45920439995825
Total Train Time (s)         84867.48035105085
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:28:07.351988 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #493 | Epoch Duration: 168.55064797401428
2020-01-13 07:28:07.352111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9293587
Z variance train             0.04691381
KL Divergence                51.124096
KL Loss                      5.1124096
QF Loss                      450.9043
VF Loss                      102.18129
Policy Loss                  -1572.074
Q Predictions Mean           1568.7886
Q Predictions Std            1525.6692
Q Predictions Max            5118.533
Q Predictions Min            709.25653
V Predictions Mean           1572.0203
V Predictions Std            1523.0581
V Predictions Max            5093.862
V Predictions Min            709.3226
Log Pis Mean                 0.20608917
Log Pis Std                  4.9643555
Log Pis Max                  17.942144
Log Pis Min                  -7.464965
Policy mu Mean               0.07818348
Policy mu Std                0.9880751
Policy mu Max                3.4904933
Policy mu Min                -3.679077
Policy log std Mean          -0.48626027
Policy log std Std           0.33424005
Policy log std Max           0.24560654
Policy log std Min           -2.85629
Z mean eval                  1.9441601
Z variance eval              0.047016706
total_rewards                [10264.60269134 10997.50446412 10363.28450375 10789.53524384
 10874.24331543 10932.98585968 10724.54929325 11011.00915417
  4251.69878184 10859.60728065]
total_rewards_mean           10106.902058806816
total_rewards_std            1966.4652938483482
total_rewards_max            11011.009154173325
total_rewards_min            4251.698781840886
Number of train steps total  1980000
Number of env steps total    5942000
Number of rollouts total     0
Train Time (s)               146.5278155207634
(Previous) Eval Time (s)     20.660610872786492
Sample Time (s)              5.472637462895364
Epoch Time (s)               172.66106385644525
Total Train Time (s)         85040.2244244623
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:31:00.099515 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #494 | Epoch Duration: 172.74730491638184
2020-01-13 07:31:00.099651 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #494 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9462849
Z variance train             0.04713069
KL Divergence                51.057434
KL Loss                      5.1057434
QF Loss                      395.48895
VF Loss                      49.001217
Policy Loss                  -1536.409
Q Predictions Mean           1535.6903
Q Predictions Std            1514.0067
Q Predictions Max            5112.707
Q Predictions Min            703.2636
V Predictions Mean           1533.152
V Predictions Std            1505.4829
V Predictions Max            5085.004
V Predictions Min            706.32605
Log Pis Mean                 0.3129847
Log Pis Std                  4.385354
Log Pis Max                  18.13654
Log Pis Min                  -9.528437
Policy mu Mean               0.07712681
Policy mu Std                0.9752122
Policy mu Max                3.4178593
Policy mu Min                -3.5831227
Policy log std Mean          -0.5119776
Policy log std Std           0.2923961
Policy log std Max           0.026080638
Policy log std Min           -2.831251
Z mean eval                  1.9695852
Z variance eval              0.058959454
total_rewards                [10608.69482356 11081.46955808  3945.81888488 10824.12324169
 10413.33055545 10688.50597685 10833.36193388 10980.25242261
 10833.6180529  10906.7073154 ]
total_rewards_mean           10111.58827652928
total_rewards_std            2063.1325991763597
total_rewards_max            11081.469558077617
total_rewards_min            3945.8188848825102
Number of train steps total  1984000
Number of env steps total    5954000
Number of rollouts total     0
Train Time (s)               146.55975976586342
(Previous) Eval Time (s)     18.630853567738086
Sample Time (s)              6.406934988219291
Epoch Time (s)               171.5975483218208
Total Train Time (s)         85211.91761019407
Epoch                        495
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:33:51.797876 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #495 | Epoch Duration: 171.69809985160828
2020-01-13 07:33:51.798128 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #495 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9683117
Z variance train             0.058931697
KL Divergence                50.343777
KL Loss                      5.0343776
QF Loss                      145.66403
VF Loss                      32.28474
Policy Loss                  -1315.7747
Q Predictions Mean           1315.4602
Q Predictions Std            1324.735
Q Predictions Max            5069.4946
Q Predictions Min            716.09094
V Predictions Mean           1315.8942
V Predictions Std            1322.0679
V Predictions Max            5069.3286
V Predictions Min            716.59064
Log Pis Mean                 -0.3150779
Log Pis Std                  3.6002717
Log Pis Max                  12.82064
Log Pis Min                  -6.2894506
Policy mu Mean               0.07082063
Policy mu Std                0.90497804
Policy mu Max                3.8145833
Policy mu Min                -3.034503
Policy log std Mean          -0.46858993
Policy log std Std           0.2878816
Policy log std Max           0.029656291
Policy log std Min           -2.8382206
Z mean eval                  1.9343226
Z variance eval              0.048055835
total_rewards                [10854.53066512 10834.67827645 10416.78250519 11071.16244572
 10421.87905435  3855.66428912 11051.57184703 11065.80308809
 11137.54355798 10828.52064855]
total_rewards_mean           10153.8136377594
total_rewards_std            2113.3966835624233
total_rewards_max            11137.54355798461
total_rewards_min            3855.6642891153224
Number of train steps total  1988000
Number of env steps total    5966000
Number of rollouts total     0
Train Time (s)               145.48283686721697
(Previous) Eval Time (s)     20.801163877360523
Sample Time (s)              6.496887960005552
Epoch Time (s)               172.78088870458305
Total Train Time (s)         85384.7826434793
Epoch                        496
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:36:44.665720 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #496 | Epoch Duration: 172.86741733551025
2020-01-13 07:36:44.665860 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #496 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9336386
Z variance train             0.04797704
KL Divergence                51.09329
KL Loss                      5.1093287
QF Loss                      4813.1104
VF Loss                      61.234474
Policy Loss                  -1626.9344
Q Predictions Mean           1624.384
Q Predictions Std            1559.3126
Q Predictions Max            5015.9053
Q Predictions Min            729.92285
V Predictions Mean           1627.2981
V Predictions Std            1558.1582
V Predictions Max            5011.3145
V Predictions Min            730.961
Log Pis Mean                 0.5093559
Log Pis Std                  4.4558587
Log Pis Max                  17.12281
Log Pis Min                  -7.025797
Policy mu Mean               0.013515919
Policy mu Std                0.9870281
Policy mu Max                3.3298657
Policy mu Min                -2.9134212
Policy log std Mean          -0.5230395
Policy log std Std           0.31566152
Policy log std Max           0.081062436
Policy log std Min           -2.9508858
Z mean eval                  1.9212301
Z variance eval              0.04078402
total_rewards                [10261.44805494 10693.82639448 10625.35963338 11128.96876985
 11011.67025831 10508.50958605 10862.12952648 10829.05622319
 10447.83084557 11142.86166819]
total_rewards_mean           10751.16609604388
total_rewards_std            281.46683253110604
total_rewards_max            11142.861668188125
total_rewards_min            10261.44805494406
Number of train steps total  1992000
Number of env steps total    5978000
Number of rollouts total     0
Train Time (s)               146.29631162295118
(Previous) Eval Time (s)     21.086207349784672
Sample Time (s)              6.484760878607631
Epoch Time (s)               173.86727985134348
Total Train Time (s)         85558.74689351534
Epoch                        497
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:39:38.632953 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #497 | Epoch Duration: 173.9669952392578
2020-01-13 07:39:38.633110 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #497 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.922147
Z variance train             0.04080583
KL Divergence                51.910995
KL Loss                      5.1910996
QF Loss                      195.6391
VF Loss                      128.22949
Policy Loss                  -1428.0156
Q Predictions Mean           1425.239
Q Predictions Std            1403.5796
Q Predictions Max            4986.506
Q Predictions Min            723.7554
V Predictions Mean           1422.5061
V Predictions Std            1395.3865
V Predictions Max            4973.1816
V Predictions Min            722.0271
Log Pis Mean                 0.059744097
Log Pis Std                  4.1543946
Log Pis Max                  12.816454
Log Pis Min                  -9.699412
Policy mu Mean               0.058047216
Policy mu Std                0.92973983
Policy mu Max                2.8766944
Policy mu Min                -3.0656548
Policy log std Mean          -0.5112796
Policy log std Std           0.27993947
Policy log std Max           0.048995286
Policy log std Min           -2.4944253
Z mean eval                  1.9678091
Z variance eval              0.06536892
total_rewards                [10335.00216843 10992.86569192 11126.51949252 11099.21400092
  7210.41453546 10914.30602086 10710.60427923 10709.17435236
 10808.20112206 10725.28490591]
total_rewards_mean           10463.1586569671
total_rewards_std            1106.1204013389724
total_rewards_max            11126.519492521935
total_rewards_min            7210.414535455862
Number of train steps total  1996000
Number of env steps total    5990000
Number of rollouts total     0
Train Time (s)               143.9210781501606
(Previous) Eval Time (s)     20.730806838721037
Sample Time (s)              6.5298263086006045
Epoch Time (s)               171.18171129748225
Total Train Time (s)         85730.01020016521
Epoch                        498
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:42:29.898853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #498 | Epoch Duration: 171.2656421661377
2020-01-13 07:42:29.898987 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #498 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9674351
Z variance train             0.06523304
KL Divergence                51.367996
KL Loss                      5.1368
QF Loss                      225.59964
VF Loss                      71.424446
Policy Loss                  -1469.0365
Q Predictions Mean           1468.3701
Q Predictions Std            1471.0298
Q Predictions Max            5080.473
Q Predictions Min            717.2096
V Predictions Mean           1471.218
V Predictions Std            1468.2836
V Predictions Max            5064.6714
V Predictions Min            720.6552
Log Pis Mean                 -0.12104863
Log Pis Std                  4.266109
Log Pis Max                  17.547075
Log Pis Min                  -12.351983
Policy mu Mean               -0.010652614
Policy mu Std                0.9155258
Policy mu Max                3.28209
Policy mu Min                -2.6966798
Policy log std Mean          -0.4783775
Policy log std Std           0.28886473
Policy log std Max           -0.02190137
Policy log std Min           -2.7130966
Z mean eval                  1.9334366
Z variance eval              0.06347112
total_rewards                [10707.17166018 10830.01247721 10919.39405581 10773.18910855
 10494.5456633  10773.7245833  11253.59412496 11007.18957873
 10914.24894746 10911.82638243]
total_rewards_mean           10858.489658193004
total_rewards_std            189.34283076971823
total_rewards_max            11253.594124960337
total_rewards_min            10494.54566329862
Number of train steps total  2000000
Number of env steps total    6002000
Number of rollouts total     0
Train Time (s)               143.24613559106365
(Previous) Eval Time (s)     20.925614381674677
Sample Time (s)              5.953868164215237
Epoch Time (s)               170.12561813695356
Total Train Time (s)         85900.30776325567
Epoch                        499
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:45:20.206020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #499 | Epoch Duration: 170.3068881034851
2020-01-13 07:45:20.206332 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #499 | Started Training: True
2020-01-13 07:45:21.049499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Variant:
2020-01-13 07:45:21.049849 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] {
  "env_name": "Humanoid-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0043402454
Z variance train             0.69638485
KL Divergence                0.14567924
KL Loss                      0.014567924
QF Loss                      1191.7229
VF Loss                      130.72073
Policy Loss                  -11.4011345
Q Predictions Mean           0.00764025
Q Predictions Std            0.011238864
Q Predictions Max            0.04310349
Q Predictions Min            -0.021389062
V Predictions Mean           0.0038442065
V Predictions Std            0.014050508
V Predictions Max            0.04862334
V Predictions Min            -0.03060108
Log Pis Mean                 -11.315548
Log Pis Std                  0.9056481
Log Pis Max                  -8.520826
Log Pis Min                  -13.320554
Policy mu Mean               0.0018080731
Policy mu Std                0.010425097
Policy mu Max                0.031899374
Policy mu Min                -0.032006025
Policy log std Mean          0.00021106945
Policy log std Std           0.01053859
Policy log std Max           0.03166568
Policy log std Min           -0.03848222
Z mean eval                  0.06853108
Z variance eval              0.06645299
total_rewards                [300.4675976  257.790033   270.98363495 236.65626187 227.05380714
 231.23973644 252.71536936 356.64839267 185.96261949 285.55899107]
total_rewards_mean           260.5076443587644
total_rewards_std            44.43746335918658
total_rewards_max            356.64839266778534
total_rewards_min            185.96261949305804
Number of train steps total  4000
Number of env steps total    4358
Number of rollouts total     0
Train Time (s)               606.2097322354093
(Previous) Eval Time (s)     0
Sample Time (s)              12.368887207470834
Epoch Time (s)               618.5786194428802
Total Train Time (s)         620.1729110521264
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:55:41.349556 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #0 | Epoch Duration: 620.1761212348938
2020-01-13 07:55:41.349743 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.068718895
Z variance train             0.067393266
KL Divergence                5.2058916
KL Loss                      0.5205892
QF Loss                      6777.198
VF Loss                      1792.6904
Policy Loss                  -601.4089
Q Predictions Mean           603.1009
Q Predictions Std            169.09335
Q Predictions Max            802.5871
Q Predictions Min            20.418232
V Predictions Mean           632.77515
V Predictions Std            134.73769
V Predictions Max            769.3812
V Predictions Min            92.24913
Log Pis Mean                 0.71483517
Log Pis Std                  6.145467
Log Pis Max                  26.469664
Log Pis Min                  -9.940231
Policy mu Mean               0.44704154
Policy mu Std                0.9233956
Policy mu Max                2.526168
Policy mu Min                -2.2364988
Policy log std Mean          -0.33716184
Policy log std Std           0.1432918
Policy log std Max           -0.05204345
Policy log std Min           -0.82434314
Z mean eval                  0.10080697
Z variance eval              0.058994792
total_rewards                [114.18752964 125.47376289 171.46146922 103.63078731 157.82041163
 121.95409716 126.71050532 118.95999833 117.63061637 135.24163164]
total_rewards_mean           129.30708094931867
total_rewards_std            19.57549259210832
total_rewards_max            171.46146921602096
total_rewards_min            103.63078730857983
Number of train steps total  8000
Number of env steps total    6687
Number of rollouts total     0
Train Time (s)               621.2773914118297
(Previous) Eval Time (s)     0.60490966681391
Sample Time (s)              6.418831641320139
Epoch Time (s)               628.3011327199638
Total Train Time (s)         1248.5964274378493
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:06:09.773069 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #1 | Epoch Duration: 628.4231917858124
2020-01-13 08:06:09.773210 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.102051176
Z variance train             0.05930243
KL Divergence                5.2827034
KL Loss                      0.52827036
QF Loss                      13018.764
VF Loss                      7437.596
Policy Loss                  -935.868
Q Predictions Mean           931.0088
Q Predictions Std            378.8415
Q Predictions Max            1359.8055
Q Predictions Min            -6.659147
V Predictions Mean           986.6991
V Predictions Std            351.13986
V Predictions Max            1350.7948
V Predictions Min            14.575318
Log Pis Mean                 4.4488077
Log Pis Std                  8.438391
Log Pis Max                  35.271084
Log Pis Min                  -10.270897
Policy mu Mean               0.09873951
Policy mu Std                1.1868559
Policy mu Max                2.9305441
Policy mu Min                -2.7609706
Policy log std Mean          -0.39786327
Policy log std Std           0.15558182
Policy log std Max           -0.014882941
Policy log std Min           -0.9568889
Z mean eval                  0.06126678
Z variance eval              0.025563437
total_rewards                [259.54510548 183.80486826 201.28239908 200.86372364 236.93961822
 184.11252463 233.91623847 296.77038714 259.36011262 218.30325634]
total_rewards_mean           227.48982338686042
total_rewards_std            34.99112321223254
total_rewards_max            296.77038714198045
total_rewards_min            183.80486825672162
Number of train steps total  12000
Number of env steps total    8998
Number of rollouts total     0
Train Time (s)               619.3642974817194
(Previous) Eval Time (s)     1.341297369915992
Sample Time (s)              5.351354390848428
Epoch Time (s)               626.0569492424838
Total Train Time (s)         1874.7608123244718
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:16:35.938327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #2 | Epoch Duration: 626.1650166511536
2020-01-13 08:16:35.938466 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06493211
Z variance train             0.025519526
KL Divergence                7.3594866
KL Loss                      0.7359487
QF Loss                      58942.56
VF Loss                      15497.958
Policy Loss                  -1345.8572
Q Predictions Mean           1327.2117
Q Predictions Std            658.3403
Q Predictions Max            2074.3
Q Predictions Min            -21.098286
V Predictions Mean           1416.7246
V Predictions Std            642.6211
V Predictions Max            2211.509
V Predictions Min            33.298172
Log Pis Mean                 9.309435
Log Pis Std                  8.313051
Log Pis Max                  37.723755
Log Pis Min                  -12.419032
Policy mu Mean               0.40324426
Policy mu Std                1.2953775
Policy mu Max                3.0070953
Policy mu Min                -2.8816504
Policy log std Mean          -0.46636087
Policy log std Std           0.13018054
Policy log std Max           0.00043188035
Policy log std Min           -0.94616085
Z mean eval                  0.021212643
Z variance eval              0.1529579
total_rewards                [221.52511497 175.9044675  170.05536944 220.56471166 198.50536733
 189.09909771 232.25977924  76.43009398 326.99286915 187.29509795]
total_rewards_mean           199.86319689377007
total_rewards_std            59.23107997727441
total_rewards_max            326.9928691481779
total_rewards_min            76.43009398295604
Number of train steps total  16000
Number of env steps total    11345
Number of rollouts total     0
Train Time (s)               615.2338705831207
(Previous) Eval Time (s)     0.8878098907880485
Sample Time (s)              6.087246513925493
Epoch Time (s)               622.2089269878343
Total Train Time (s)         2497.0803658282384
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:26:58.259314 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #3 | Epoch Duration: 622.3207318782806
2020-01-13 08:26:58.259518 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021797288
Z variance train             0.1520433
KL Divergence                5.32824
KL Loss                      0.532824
QF Loss                      20974.734
VF Loss                      5795.7974
Policy Loss                  -1738.1931
Q Predictions Mean           1669.3455
Q Predictions Std            687.96246
Q Predictions Max            2601.8213
Q Predictions Min            8.84386
V Predictions Mean           1740.4476
V Predictions Std            643.1283
V Predictions Max            2505.2793
V Predictions Min            70.30013
Log Pis Mean                 9.967209
Log Pis Std                  10.781316
Log Pis Max                  47.371613
Log Pis Min                  -10.9389105
Policy mu Mean               0.38502744
Policy mu Std                1.3399967
Policy mu Max                3.3200307
Policy mu Min                -3.3523917
Policy log std Mean          -0.4645298
Policy log std Std           0.14009488
Policy log std Max           -0.02723467
Policy log std Min           -0.9718349
Z mean eval                  0.026663596
Z variance eval              0.03833467
total_rewards                [314.85892437 237.41393003 257.28374416 193.34702943 297.54286261
 369.55725462 267.64377322 309.05825765 233.45200818 272.00546536]
total_rewards_mean           275.21632496234304
total_rewards_std            47.30812696549875
total_rewards_max            369.5572546165351
total_rewards_min            193.34702943326081
Number of train steps total  20000
Number of env steps total    13603
Number of rollouts total     0
Train Time (s)               617.9801468239166
(Previous) Eval Time (s)     1.3422230896539986
Sample Time (s)              5.910424160305411
Epoch Time (s)               625.232794073876
Total Train Time (s)         3122.651546710171
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:37:23.831763 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #4 | Epoch Duration: 625.5720875263214
2020-01-13 08:37:23.831941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02767297
Z variance train             0.03849287
KL Divergence                5.990398
KL Loss                      0.5990398
QF Loss                      39249.76
VF Loss                      9138.6875
Policy Loss                  -1814.7124
Q Predictions Mean           1767.6455
Q Predictions Std            870.2788
Q Predictions Max            2912.692
Q Predictions Min            -26.974016
V Predictions Mean           1848.7086
V Predictions Std            837.70776
V Predictions Max            2808.0083
V Predictions Min            33.13639
Log Pis Mean                 12.9037895
Log Pis Std                  9.802577
Log Pis Max                  60.444176
Log Pis Min                  -10.142849
Policy mu Mean               0.24262844
Policy mu Std                1.4718003
Policy mu Max                4.376961
Policy mu Min                -3.4178994
Policy log std Mean          -0.4886926
Policy log std Std           0.1296628
Policy log std Max           -0.049118176
Policy log std Min           -1.023069
Z mean eval                  0.027715033
Z variance eval              0.13027146
total_rewards                [186.30042065 295.20523914 205.18211443 191.50377249 246.64898999
 245.09564436 299.35185474 233.62132586 263.25545701 227.59786978]
total_rewards_mean           239.3762688451402
total_rewards_std            37.17482481920771
total_rewards_max            299.3518547423652
total_rewards_min            186.30042064893416
Number of train steps total  24000
Number of env steps total    15944
Number of rollouts total     0
Train Time (s)               619.455240979325
(Previous) Eval Time (s)     1.3085952731780708
Sample Time (s)              6.460244078189135
Epoch Time (s)               627.2240803306922
Total Train Time (s)         3749.984698449727
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:47:51.166593 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #5 | Epoch Duration: 627.3345062732697
2020-01-13 08:47:51.166845 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028138716
Z variance train             0.12983575
KL Divergence                4.712037
KL Loss                      0.4712037
QF Loss                      29905.0
VF Loss                      6967.1445
Policy Loss                  -1936.4899
Q Predictions Mean           1897.7264
Q Predictions Std            855.9949
Q Predictions Max            3003.773
Q Predictions Min            46.52227
V Predictions Mean           1935.6002
V Predictions Std            826.5133
V Predictions Max            2994.6328
V Predictions Min            54.80488
Log Pis Mean                 9.883849
Log Pis Std                  10.906933
Log Pis Max                  47.076954
Log Pis Min                  -11.918604
Policy mu Mean               0.2899508
Policy mu Std                1.3494184
Policy mu Max                3.4780276
Policy mu Min                -3.6446702
Policy log std Mean          -0.45804015
Policy log std Std           0.13475382
Policy log std Max           -0.053323314
Policy log std Min           -0.9933896
Z mean eval                  0.11898961
Z variance eval              0.06472856
total_rewards                [190.04223599 195.46294958 132.45811933 183.14978    178.99626263
 219.99356648 173.24807781 141.79084341 186.35684932 189.73348795]
total_rewards_mean           179.12321724871262
total_rewards_std            24.17350747264556
total_rewards_max            219.9935664767187
total_rewards_min            132.45811932722103
Number of train steps total  28000
Number of env steps total    18385
Number of rollouts total     0
Train Time (s)               584.0295012309216
(Previous) Eval Time (s)     0.9014598377980292
Sample Time (s)              6.550785182509571
Epoch Time (s)               591.4817462512292
Total Train Time (s)         4341.5734233204275
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:57:42.754589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #6 | Epoch Duration: 591.5875728130341
2020-01-13 08:57:42.754737 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1209057
Z variance train             0.06514456
KL Divergence                6.7213116
KL Loss                      0.6721312
QF Loss                      52433.156
VF Loss                      4968.0566
Policy Loss                  -1646.8671
Q Predictions Mean           1616.579
Q Predictions Std            925.62695
Q Predictions Max            2723.943
Q Predictions Min            16.300262
V Predictions Mean           1667.1323
V Predictions Std            908.6433
V Predictions Max            2675.953
V Predictions Min            69.267
Log Pis Mean                 7.768812
Log Pis Std                  9.962883
Log Pis Max                  59.01145
Log Pis Min                  -10.656872
Policy mu Mean               0.20253089
Policy mu Std                1.3078691
Policy mu Max                6.7968607
Policy mu Min                -3.3347385
Policy log std Mean          -0.45481008
Policy log std Std           0.1432427
Policy log std Max           -0.04015836
Policy log std Min           -1.177388
Z mean eval                  0.17316036
Z variance eval              0.056867123
total_rewards                [206.28011519 226.55447022 232.5201941  228.94003954 197.16059508
 203.68498887 198.49333714 258.66326076 205.91305518 211.32775282]
total_rewards_mean           216.9537808896307
total_rewards_std            18.422631595867614
total_rewards_max            258.663260764035
total_rewards_min            197.16059507673208
Number of train steps total  32000
Number of env steps total    20706
Number of rollouts total     0
Train Time (s)               617.5781462988816
(Previous) Eval Time (s)     1.016481134109199
Sample Time (s)              6.123846739530563
Epoch Time (s)               624.7184741725214
Total Train Time (s)         4966.407778648194
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:08:07.589417 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #7 | Epoch Duration: 624.8345828056335
2020-01-13 09:08:07.589563 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17249987
Z variance train             0.0565616
KL Divergence                6.345482
KL Loss                      0.6345482
QF Loss                      10694.803
VF Loss                      6274.543
Policy Loss                  -1375.7006
Q Predictions Mean           1341.3367
Q Predictions Std            923.3774
Q Predictions Max            2774.493
Q Predictions Min            9.332965
V Predictions Mean           1390.8391
V Predictions Std            917.5956
V Predictions Max            2779.2986
V Predictions Min            12.72995
Log Pis Mean                 8.320689
Log Pis Std                  10.603148
Log Pis Max                  45.699726
Log Pis Min                  -16.686047
Policy mu Mean               0.4255521
Policy mu Std                1.2598251
Policy mu Max                3.8824682
Policy mu Min                -3.5324078
Policy log std Mean          -0.4509218
Policy log std Std           0.15203983
Policy log std Max           0.09161362
Policy log std Min           -1.0150139
Z mean eval                  0.060551323
Z variance eval              0.066377476
total_rewards                [161.69709352 156.46381172 204.64885998 168.88962316 167.65850778
  86.76230851 122.04247697 161.94981767 127.83172205 187.60225178]
total_rewards_mean           154.55464731317372
total_rewards_std            32.33431944891896
total_rewards_max            204.64885997921007
total_rewards_min            86.7623085116848
Number of train steps total  36000
Number of env steps total    23047
Number of rollouts total     0
Train Time (s)               621.396258554887
(Previous) Eval Time (s)     0.7619316130876541
Sample Time (s)              5.966347928158939
Epoch Time (s)               628.1245380961336
Total Train Time (s)         5594.802220939659
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:18:35.985778 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #8 | Epoch Duration: 628.3961007595062
2020-01-13 09:18:35.985959 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060336787
Z variance train             0.06687559
KL Divergence                6.184512
KL Loss                      0.61845124
QF Loss                      11169.865
VF Loss                      5349.2803
Policy Loss                  -1408.4935
Q Predictions Mean           1354.8009
Q Predictions Std            847.45044
Q Predictions Max            2677.9392
Q Predictions Min            68.17694
V Predictions Mean           1418.9104
V Predictions Std            854.2164
V Predictions Max            2720.4727
V Predictions Min            56.06941
Log Pis Mean                 10.170301
Log Pis Std                  10.93205
Log Pis Max                  46.794537
Log Pis Min                  -10.229253
Policy mu Mean               0.348507
Policy mu Std                1.335248
Policy mu Max                3.8288553
Policy mu Min                -3.6572106
Policy log std Mean          -0.45956635
Policy log std Std           0.15415768
Policy log std Max           0.056491986
Policy log std Min           -0.9972673
Z mean eval                  0.032951258
Z variance eval              0.06757961
total_rewards                [324.27957226 307.30226223 307.66744194 289.52332976 353.50882798
 283.69995831 319.02629185 311.91148328 428.37312342 246.14641019]
total_rewards_mean           317.1438701225581
total_rewards_std            45.6999839363902
total_rewards_max            428.37312341576126
total_rewards_min            246.14641019022397
Number of train steps total  40000
Number of env steps total    25356
Number of rollouts total     0
Train Time (s)               612.2805794770829
(Previous) Eval Time (s)     1.5034568873234093
Sample Time (s)              6.281712712254375
Epoch Time (s)               620.0657490766607
Total Train Time (s)         6214.972882105503
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:28:56.156574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #9 | Epoch Duration: 620.1704912185669
2020-01-13 09:28:56.156700 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #9 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032407414
Z variance train             0.06766488
KL Divergence                6.4773817
KL Loss                      0.64773816
QF Loss                      8557.959
VF Loss                      3624.6812
Policy Loss                  -1305.0465
Q Predictions Mean           1260.3103
Q Predictions Std            821.33417
Q Predictions Max            2837.478
Q Predictions Min            -61.89819
V Predictions Mean           1300.977
V Predictions Std            817.7476
V Predictions Max            2701.2356
V Predictions Min            61.454216
Log Pis Mean                 7.0536804
Log Pis Std                  9.512706
Log Pis Max                  43.67151
Log Pis Min                  -12.779663
Policy mu Mean               0.42505425
Policy mu Std                1.2079523
Policy mu Max                3.2710211
Policy mu Min                -4.441779
Policy log std Mean          -0.4217537
Policy log std Std           0.14563207
Policy log std Max           0.10602696
Policy log std Min           -1.0630231
Z mean eval                  0.056189917
Z variance eval              0.19453037
total_rewards                [196.22890586 252.93652706 188.71756074 276.03850116 209.7050575
 196.64648767 262.14460906 222.43988646 363.89701727 469.2435939 ]
total_rewards_mean           263.79981466787467
total_rewards_std            84.76246862717096
total_rewards_max            469.24359390148993
total_rewards_min            188.71756074479177
Number of train steps total  44000
Number of env steps total    27647
Number of rollouts total     0
Train Time (s)               618.8572295266204
(Previous) Eval Time (s)     1.3120173537172377
Sample Time (s)              5.344771404750645
Epoch Time (s)               625.5140182850882
Total Train Time (s)         6840.594247744419
Epoch                        10
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:39:21.779420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #10 | Epoch Duration: 625.6226122379303
2020-01-13 09:39:21.779597 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05661316
Z variance train             0.19331387
KL Divergence                5.329618
KL Loss                      0.5329618
QF Loss                      11855.51
VF Loss                      8560.756
Policy Loss                  -1180.7913
Q Predictions Mean           1160.2617
Q Predictions Std            753.1248
Q Predictions Max            2472.4097
Q Predictions Min            -23.571358
V Predictions Mean           1191.6394
V Predictions Std            758.8483
V Predictions Max            2477.5962
V Predictions Min            34.09246
Log Pis Mean                 6.6047883
Log Pis Std                  9.836729
Log Pis Max                  47.457035
Log Pis Min                  -12.467882
Policy mu Mean               0.23817736
Policy mu Std                1.2511116
Policy mu Max                3.818815
Policy mu Min                -3.5362554
Policy log std Mean          -0.42671636
Policy log std Std           0.14698945
Policy log std Max           0.06936492
Policy log std Min           -0.98039716
Z mean eval                  0.054499447
Z variance eval              0.05580773
total_rewards                [291.38811452 407.07610509 240.88021426 449.99448765 336.49681387
 366.39087859 385.1314432  335.70792929 380.68568096 345.65179676]
total_rewards_mean           353.9403464192836
total_rewards_std            55.94085555604307
total_rewards_max            449.9944876514992
total_rewards_min            240.8802142597599
Number of train steps total  48000
Number of env steps total    30018
Number of rollouts total     0
Train Time (s)               620.0605390421115
(Previous) Eval Time (s)     1.872207717038691
Sample Time (s)              6.219058820977807
Epoch Time (s)               628.151805580128
Total Train Time (s)         7468.866510207299
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:49:50.051727 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #11 | Epoch Duration: 628.2719957828522
2020-01-13 09:49:50.051874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05481906
Z variance train             0.05573485
KL Divergence                6.559971
KL Loss                      0.6559971
QF Loss                      5064.875
VF Loss                      2579.0376
Policy Loss                  -1033.8569
Q Predictions Mean           996.5437
Q Predictions Std            701.0634
Q Predictions Max            2507.3306
Q Predictions Min            -3.1998892
V Predictions Mean           1040.162
V Predictions Std            705.7361
V Predictions Max            2486.7727
V Predictions Min            18.807013
Log Pis Mean                 4.8319154
Log Pis Std                  9.709708
Log Pis Max                  47.470924
Log Pis Min                  -12.874664
Policy mu Mean               0.29224548
Policy mu Std                1.1747607
Policy mu Max                3.4727561
Policy mu Min                -3.687754
Policy log std Mean          -0.4092916
Policy log std Std           0.14793107
Policy log std Max           0.08522509
Policy log std Min           -0.9837956
Z mean eval                  0.033894077
Z variance eval              0.06371639
total_rewards                [427.13050736 423.38508121 612.55584848 307.97190452 318.91233558
 338.8013231  353.46972649 348.52110765 278.11165278 338.57643757]
total_rewards_mean           374.7435924761023
total_rewards_std            90.72953081526688
total_rewards_max            612.5558484845305
total_rewards_min            278.1116527810985
Number of train steps total  52000
Number of env steps total    32434
Number of rollouts total     0
Train Time (s)               620.1797642619349
(Previous) Eval Time (s)     1.923002720810473
Sample Time (s)              6.20877300016582
Epoch Time (s)               628.3115399829112
Total Train Time (s)         8097.300282844808
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:00:18.486411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #12 | Epoch Duration: 628.4344372749329
2020-01-13 10:00:18.486550 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033332583
Z variance train             0.06389205
KL Divergence                5.4138527
KL Loss                      0.5413853
QF Loss                      4530.2964
VF Loss                      2940.1514
Policy Loss                  -967.0379
Q Predictions Mean           931.0617
Q Predictions Std            606.87
Q Predictions Max            1989.1193
Q Predictions Min            10.619
V Predictions Mean           948.9748
V Predictions Std            608.2521
V Predictions Max            1934.6116
V Predictions Min            7.607077
Log Pis Mean                 3.078371
Log Pis Std                  8.763756
Log Pis Max                  42.022217
Log Pis Min                  -14.538452
Policy mu Mean               0.26435548
Policy mu Std                1.0812613
Policy mu Max                3.561141
Policy mu Min                -3.680192
Policy log std Mean          -0.3788092
Policy log std Std           0.14396068
Policy log std Max           0.030031428
Policy log std Min           -0.9546957
Z mean eval                  0.010777338
Z variance eval              0.16889435
total_rewards                [242.50314856 259.38979379 220.58021955 355.57982211 305.95509276
 235.14681228 265.3737716  264.24984348 252.83194509 243.96838517]
total_rewards_mean           264.5578834372621
total_rewards_std            37.24657621862289
total_rewards_max            355.5798221147917
total_rewards_min            220.58021955184998
Number of train steps total  56000
Number of env steps total    34794
Number of rollouts total     0
Train Time (s)               615.7129907677881
(Previous) Eval Time (s)     1.5153833250515163
Sample Time (s)              6.548197476193309
Epoch Time (s)               623.776571569033
Total Train Time (s)         8721.381994694937
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:10:42.568984 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #13 | Epoch Duration: 624.0823030471802
2020-01-13 10:10:42.569119 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008941521
Z variance train             0.1698822
KL Divergence                3.6321898
KL Loss                      0.363219
QF Loss                      15527.259
VF Loss                      5002.762
Policy Loss                  -912.5708
Q Predictions Mean           887.77795
Q Predictions Std            509.1785
Q Predictions Max            1688.4668
Q Predictions Min            1.2384433
V Predictions Mean           927.02515
V Predictions Std            500.28857
V Predictions Max            1832.3231
V Predictions Min            10.503605
Log Pis Mean                 2.413116
Log Pis Std                  9.310196
Log Pis Max                  41.967873
Log Pis Min                  -16.636398
Policy mu Mean               0.2875795
Policy mu Std                1.0779662
Policy mu Max                4.2069
Policy mu Min                -3.5824509
Policy log std Mean          -0.38639307
Policy log std Std           0.14380433
Policy log std Max           0.039361924
Policy log std Min           -1.0131205
Z mean eval                  0.030892273
Z variance eval              0.0975278
total_rewards                [383.82102647 342.90040891 304.81269884 381.67489628 554.21877349
 253.15126732 294.97472568 373.99629702 349.25926541 393.26734038]
total_rewards_mean           363.207669979742
total_rewards_std            76.84805188558542
total_rewards_max            554.2187734877473
total_rewards_min            253.15126731529975
Number of train steps total  60000
Number of env steps total    37132
Number of rollouts total     0
Train Time (s)               618.4731858312152
(Previous) Eval Time (s)     1.7222810699604452
Sample Time (s)              6.210482593625784
Epoch Time (s)               626.4059494948015
Total Train Time (s)         9347.907741439994
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:21:09.096191 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #14 | Epoch Duration: 626.5269651412964
2020-01-13 10:21:09.096364 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029462436
Z variance train             0.09739886
KL Divergence                4.119316
KL Loss                      0.4119316
QF Loss                      3685.9697
VF Loss                      1377.1599
Policy Loss                  -853.8672
Q Predictions Mean           838.3723
Q Predictions Std            455.32877
Q Predictions Max            1666.1711
Q Predictions Min            27.55964
V Predictions Mean           856.83594
V Predictions Std            459.05447
V Predictions Max            1603.5948
V Predictions Min            32.51732
Log Pis Mean                 1.6620548
Log Pis Std                  7.7078204
Log Pis Max                  32.77373
Log Pis Min                  -13.13362
Policy mu Mean               0.4035405
Policy mu Std                1.0009712
Policy mu Max                3.4183106
Policy mu Min                -3.09776
Policy log std Mean          -0.38000622
Policy log std Std           0.1276395
Policy log std Max           -0.027733997
Policy log std Min           -1.0426953
Z mean eval                  0.04492682
Z variance eval              0.06851921
total_rewards                [249.07871886 301.84578341 381.84800081 284.79411333 318.53139962
 584.1512816  435.99232767 214.75655345 369.30484061 210.23452427]
total_rewards_mean           335.05375436182214
total_rewards_std            108.14146503776479
total_rewards_max            584.1512816032645
total_rewards_min            210.23452426826296
Number of train steps total  64000
Number of env steps total    39629
Number of rollouts total     0
Train Time (s)               611.6057959948666
(Previous) Eval Time (s)     1.7835876317694783
Sample Time (s)              7.052610348910093
Epoch Time (s)               620.4419939755462
Total Train Time (s)         9968.45341799967
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:31:29.642144 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #15 | Epoch Duration: 620.5456595420837
2020-01-13 10:31:29.642283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045401625
Z variance train             0.068848506
KL Divergence                5.125695
KL Loss                      0.51256955
QF Loss                      3980.7
VF Loss                      1038.4625
Policy Loss                  -853.7392
Q Predictions Mean           841.3761
Q Predictions Std            415.49136
Q Predictions Max            1391.4944
Q Predictions Min            13.481223
V Predictions Mean           859.87415
V Predictions Std            408.09122
V Predictions Max            1377.8715
V Predictions Min            24.771786
Log Pis Mean                 -0.65506625
Log Pis Std                  7.2247953
Log Pis Max                  31.819893
Log Pis Min                  -14.7767515
Policy mu Mean               0.2646987
Policy mu Std                0.94748163
Policy mu Max                2.9161146
Policy mu Min                -2.9556494
Policy log std Mean          -0.33925033
Policy log std Std           0.119088665
Policy log std Max           0.01744318
Policy log std Min           -0.9089734
Z mean eval                  0.02926143
Z variance eval              0.04325978
total_rewards                [299.54810356 365.81775039 426.78332046 367.07637527 308.26767197
 394.74262769 528.95156226 371.65184196 362.04440082 280.70028723]
total_rewards_mean           370.5583941614937
total_rewards_std            67.77895830043467
total_rewards_max            528.9515622635404
total_rewards_min            280.7002872266004
Number of train steps total  68000
Number of env steps total    42066
Number of rollouts total     0
Train Time (s)               609.6534370970912
(Previous) Eval Time (s)     1.7253268077038229
Sample Time (s)              6.4752484848722816
Epoch Time (s)               617.8540123896673
Total Train Time (s)         10586.404594317544
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:41:47.594023 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #16 | Epoch Duration: 617.9516425132751
2020-01-13 10:41:47.594159 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030014148
Z variance train             0.043344777
KL Divergence                5.89343
KL Loss                      0.589343
QF Loss                      3678.4966
VF Loss                      1301.9327
Policy Loss                  -801.92
Q Predictions Mean           784.9763
Q Predictions Std            397.9849
Q Predictions Max            1343.7847
Q Predictions Min            56.0845
V Predictions Mean           809.6121
V Predictions Std            393.48245
V Predictions Max            1352.0197
V Predictions Min            69.921776
Log Pis Mean                 -0.7260581
Log Pis Std                  7.09322
Log Pis Max                  31.664663
Log Pis Min                  -16.4595
Policy mu Mean               0.2880924
Policy mu Std                0.9284168
Policy mu Max                2.94774
Policy mu Min                -3.3786511
Policy log std Mean          -0.33781528
Policy log std Std           0.12888488
Policy log std Max           -0.046652652
Policy log std Min           -0.9360233
Z mean eval                  0.019284582
Z variance eval              0.114475295
total_rewards                [269.76165738 448.20828126 454.88339664 389.06500868 396.94077679
 333.8365008  367.98535475 335.97540554 293.08672705 310.87010322]
total_rewards_mean           360.0613212107013
total_rewards_std            59.45795574387775
total_rewards_max            454.8833966397536
total_rewards_min            269.7616573772618
Number of train steps total  72000
Number of env steps total    44503
Number of rollouts total     0
Train Time (s)               609.8853801796213
(Previous) Eval Time (s)     1.690373548772186
Sample Time (s)              5.876716621685773
Epoch Time (s)               617.4524703500792
Total Train Time (s)         11203.963494356256
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:52:05.153547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #17 | Epoch Duration: 617.5592904090881
2020-01-13 10:52:05.153684 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01884113
Z variance train             0.11447022
KL Divergence                4.819152
KL Loss                      0.4819152
QF Loss                      1706.7675
VF Loss                      859.30975
Policy Loss                  -785.56433
Q Predictions Mean           766.868
Q Predictions Std            404.27884
Q Predictions Max            1315.4604
Q Predictions Min            0.63584054
V Predictions Mean           775.4791
V Predictions Std            397.74152
V Predictions Max            1317.0824
V Predictions Min            39.621193
Log Pis Mean                 -1.2021241
Log Pis Std                  6.198236
Log Pis Max                  30.08073
Log Pis Min                  -11.653976
Policy mu Mean               0.3104961
Policy mu Std                0.8851932
Policy mu Max                3.112736
Policy mu Min                -2.9523327
Policy log std Mean          -0.3243126
Policy log std Std           0.11800627
Policy log std Max           -0.040773734
Policy log std Min           -0.89751434
Z mean eval                  0.02086604
Z variance eval              0.1116446
total_rewards                [309.4948116  478.61143575 497.98924595 459.90183392 387.67078359
 287.62511217 318.70867006 458.99390787 412.56598514 374.41771087]
total_rewards_mean           398.5979496925855
total_rewards_std            71.56986482945501
total_rewards_max            497.9892459496171
total_rewards_min            287.62511217078617
Number of train steps total  76000
Number of env steps total    46913
Number of rollouts total     0
Train Time (s)               605.0408186009154
(Previous) Eval Time (s)     1.9868756011128426
Sample Time (s)              6.551526281051338
Epoch Time (s)               613.5792204830796
Total Train Time (s)         11817.645128930453
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:02:18.836178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #18 | Epoch Duration: 613.6823813915253
2020-01-13 11:02:18.836312 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021943254
Z variance train             0.11130246
KL Divergence                4.1444
KL Loss                      0.41444
QF Loss                      1259.9016
VF Loss                      736.43945
Policy Loss                  -788.0246
Q Predictions Mean           773.9684
Q Predictions Std            399.75513
Q Predictions Max            1335.4652
Q Predictions Min            11.557592
V Predictions Mean           775.5751
V Predictions Std            398.76968
V Predictions Max            1331.7654
V Predictions Min            49.70333
Log Pis Mean                 -1.4725137
Log Pis Std                  6.5780625
Log Pis Max                  22.119844
Log Pis Min                  -15.345551
Policy mu Mean               0.2935252
Policy mu Std                0.89373255
Policy mu Max                2.7509274
Policy mu Min                -2.8177714
Policy log std Mean          -0.33053124
Policy log std Std           0.119649425
Policy log std Max           -0.056657784
Policy log std Min           -0.8468338
Z mean eval                  0.017091123
Z variance eval              0.13143946
total_rewards                [509.15168066 549.30362634 600.84002348 411.55831374 454.28878945
 439.65868181 472.40304079 448.31336773 557.57560347 445.29004242]
total_rewards_mean           488.8383169880482
total_rewards_std            58.93320837589466
total_rewards_max            600.8400234786819
total_rewards_min            411.5583137362613
Number of train steps total  80000
Number of env steps total    49400
Number of rollouts total     0
Train Time (s)               605.5517834899947
(Previous) Eval Time (s)     2.531769667286426
Sample Time (s)              6.764254912734032
Epoch Time (s)               614.8478080700152
Total Train Time (s)         12432.595210982021
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:12:33.786773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #19 | Epoch Duration: 614.9503643512726
2020-01-13 11:12:33.786907 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017399441
Z variance train             0.13100716
KL Divergence                3.9804883
KL Loss                      0.39804885
QF Loss                      1312.365
VF Loss                      565.85815
Policy Loss                  -749.9998
Q Predictions Mean           736.3123
Q Predictions Std            403.18985
Q Predictions Max            1342.3492
Q Predictions Min            -0.83727586
V Predictions Mean           751.26196
V Predictions Std            400.7347
V Predictions Max            1339.4352
V Predictions Min            -1.3809786
Log Pis Mean                 -2.0198967
Log Pis Std                  7.314555
Log Pis Max                  32.39582
Log Pis Min                  -13.283704
Policy mu Mean               0.2425232
Policy mu Std                0.8829452
Policy mu Max                2.8670433
Policy mu Min                -2.6865842
Policy log std Mean          -0.31757757
Policy log std Std           0.12041418
Policy log std Max           -0.0098653585
Policy log std Min           -1.0059648
Z mean eval                  0.035507705
Z variance eval              0.044178743
total_rewards                [359.18406121 395.74708417 354.03942334 399.32316793 430.73863611
 652.603158   500.73522971 452.17451011 390.69199933 390.12987823]
total_rewards_mean           432.53671481404444
total_rewards_std            84.27189693154476
total_rewards_max            652.6031580032809
total_rewards_min            354.03942334384686
Number of train steps total  84000
Number of env steps total    52228
Number of rollouts total     0
Train Time (s)               608.5965428240597
(Previous) Eval Time (s)     2.291784966364503
Sample Time (s)              11.465284641366452
Epoch Time (s)               622.3536124317907
Total Train Time (s)         13055.066663160454
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:22:56.259053 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #20 | Epoch Duration: 622.4720492362976
2020-01-13 11:22:56.259181 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03732509
Z variance train             0.04413726
KL Divergence                5.5811768
KL Loss                      0.5581177
QF Loss                      2523.0344
VF Loss                      1172.2198
Policy Loss                  -810.9617
Q Predictions Mean           783.75494
Q Predictions Std            433.42188
Q Predictions Max            1363.4594
Q Predictions Min            -61.115677
V Predictions Mean           810.1228
V Predictions Std            429.70837
V Predictions Max            1375.6624
V Predictions Min            -1.1654041
Log Pis Mean                 -1.6753621
Log Pis Std                  6.435284
Log Pis Max                  24.595543
Log Pis Min                  -12.277819
Policy mu Mean               0.19942604
Policy mu Std                0.9090934
Policy mu Max                3.8105614
Policy mu Min                -3.7129443
Policy log std Mean          -0.32829157
Policy log std Std           0.12038885
Policy log std Max           0.0042862594
Policy log std Min           -0.867207
Z mean eval                  0.030763399
Z variance eval              0.08460708
total_rewards                [563.22859625 388.09209782 438.25394601 317.87838869 400.10474211
 510.91171731 328.74431041 431.19139982 602.10972358 377.51792721]
total_rewards_mean           435.80328492195497
total_rewards_std            90.48725035923167
total_rewards_max            602.1097235751301
total_rewards_min            317.8783886935403
Number of train steps total  88000
Number of env steps total    55088
Number of rollouts total     0
Train Time (s)               600.618961807806
(Previous) Eval Time (s)     2.2408209280110896
Sample Time (s)              7.16003959113732
Epoch Time (s)               610.0198223269545
Total Train Time (s)         13665.187823066022
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:33:06.380771 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #21 | Epoch Duration: 610.1214964389801
2020-01-13 11:33:06.380905 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03245915
Z variance train             0.08523266
KL Divergence                4.9619026
KL Loss                      0.49619028
QF Loss                      1554.9082
VF Loss                      732.9863
Policy Loss                  -797.17834
Q Predictions Mean           781.46814
Q Predictions Std            415.95972
Q Predictions Max            1370.1582
Q Predictions Min            36.568195
V Predictions Mean           784.6194
V Predictions Std            420.53534
V Predictions Max            1376.792
V Predictions Min            8.545077
Log Pis Mean                 -1.4523785
Log Pis Std                  5.4408536
Log Pis Max                  26.968199
Log Pis Min                  -15.039082
Policy mu Mean               0.30057648
Policy mu Std                0.8649148
Policy mu Max                2.9174578
Policy mu Min                -2.6070676
Policy log std Mean          -0.33433595
Policy log std Std           0.116920285
Policy log std Max           -0.062478364
Policy log std Min           -0.8232209
Z mean eval                  0.030337611
Z variance eval              0.101013005
total_rewards                [441.09486182 446.09074616 403.33593248 482.24551871 422.00795642
 417.06243772 387.56233435 373.98933618 371.68074064 418.00658764]
total_rewards_mean           416.3076452144064
total_rewards_std            32.652948036483416
total_rewards_max            482.2455187144768
total_rewards_min            371.680740643328
Number of train steps total  92000
Number of env steps total    57954
Number of rollouts total     0
Train Time (s)               607.0199704961851
(Previous) Eval Time (s)     2.1607807306572795
Sample Time (s)              7.254433034919202
Epoch Time (s)               616.4351842617616
Total Train Time (s)         14281.732058817055
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:43:22.925790 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #22 | Epoch Duration: 616.5447890758514
2020-01-13 11:43:22.925930 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030841947
Z variance train             0.10133548
KL Divergence                4.6069703
KL Loss                      0.46069703
QF Loss                      1278.0786
VF Loss                      669.827
Policy Loss                  -784.04266
Q Predictions Mean           779.04517
Q Predictions Std            416.05978
Q Predictions Max            1391.7638
Q Predictions Min            17.408361
V Predictions Mean           778.20074
V Predictions Std            408.82877
V Predictions Max            1386.6552
V Predictions Min            11.697655
Log Pis Mean                 -2.3892436
Log Pis Std                  5.329727
Log Pis Max                  17.55904
Log Pis Min                  -14.954213
Policy mu Mean               0.26839694
Policy mu Std                0.84977144
Policy mu Max                2.905533
Policy mu Min                -2.4649675
Policy log std Mean          -0.3232534
Policy log std Std           0.1089467
Policy log std Max           0.008204788
Policy log std Min           -0.9332549
Z mean eval                  0.0477522
Z variance eval              0.110343
total_rewards                [431.00856827 547.33017223 358.26598247 353.6481415  293.01259677
 391.93671578 552.21142474 567.07759078 403.84937458 387.09438072]
total_rewards_mean           428.5434947842865
total_rewards_std            90.10358254763727
total_rewards_max            567.0775907847651
total_rewards_min            293.01259676591064
Number of train steps total  96000
Number of env steps total    60785
Number of rollouts total     0
Train Time (s)               609.236483943183
(Previous) Eval Time (s)     2.141372077167034
Sample Time (s)              6.677159772254527
Epoch Time (s)               618.0550157926045
Total Train Time (s)         14899.90920251282
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:53:41.103740 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #23 | Epoch Duration: 618.1777126789093
2020-01-13 11:53:41.103870 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048544105
Z variance train             0.11061786
KL Divergence                3.904406
KL Loss                      0.3904406
QF Loss                      1912.5381
VF Loss                      824.75104
Policy Loss                  -829.2701
Q Predictions Mean           811.35144
Q Predictions Std            418.4545
Q Predictions Max            1384.928
Q Predictions Min            17.805546
V Predictions Mean           826.61365
V Predictions Std            416.46576
V Predictions Max            1393.829
V Predictions Min            56.828606
Log Pis Mean                 -2.1269832
Log Pis Std                  5.6519737
Log Pis Max                  27.851414
Log Pis Min                  -13.196211
Policy mu Mean               0.26555544
Policy mu Std                0.8575209
Policy mu Max                3.015927
Policy mu Min                -3.0840886
Policy log std Mean          -0.32414022
Policy log std Std           0.1160506
Policy log std Max           0.025746971
Policy log std Min           -0.87429833
Z mean eval                  0.04118206
Z variance eval              0.051545672
total_rewards                [671.51083011 529.9348452  714.64301846 491.80144665 534.44384028
 486.87173765 383.55614332 437.87220261 252.78543235 417.38921498]
total_rewards_mean           492.0808711619776
total_rewards_std            127.49161700522491
total_rewards_max            714.643018455515
total_rewards_min            252.78543235486515
Number of train steps total  100000
Number of env steps total    63677
Number of rollouts total     0
Train Time (s)               612.1987726059742
(Previous) Eval Time (s)     2.5179346930235624
Sample Time (s)              6.949718456249684
Epoch Time (s)               621.6664257552475
Total Train Time (s)         15521.685531751718
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:04:02.880966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #24 | Epoch Duration: 621.7770006656647
2020-01-13 12:04:02.881104 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042155955
Z variance train             0.05168696
KL Divergence                5.5460806
KL Loss                      0.55460805
QF Loss                      1176.2163
VF Loss                      708.9727
Policy Loss                  -811.5829
Q Predictions Mean           798.23596
Q Predictions Std            428.2217
Q Predictions Max            1412.3212
Q Predictions Min            10.530852
V Predictions Mean           801.4988
V Predictions Std            422.23105
V Predictions Max            1400.6875
V Predictions Min            24.608953
Log Pis Mean                 -1.69923
Log Pis Std                  6.81837
Log Pis Max                  32.55288
Log Pis Min                  -12.278776
Policy mu Mean               0.31568062
Policy mu Std                0.85132223
Policy mu Max                2.9434896
Policy mu Min                -3.082546
Policy log std Mean          -0.3276481
Policy log std Std           0.11711932
Policy log std Max           -0.060532227
Policy log std Min           -0.87392145
Z mean eval                  0.06535418
Z variance eval              0.06617593
total_rewards                [562.21680455 414.60416185 725.66424085 457.40591398 438.89936588
 441.67617946 439.06799429 377.61106614 424.54370988 379.77695128]
total_rewards_mean           466.14663881682674
total_rewards_std            99.20455343263299
total_rewards_max            725.6642408537904
total_rewards_min            377.61106613658166
Number of train steps total  104000
Number of env steps total    66383
Number of rollouts total     0
Train Time (s)               611.543492496945
(Previous) Eval Time (s)     2.46562291495502
Sample Time (s)              6.729081969708204
Epoch Time (s)               620.7381973816082
Total Train Time (s)         16142.545939490665
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:14:23.742207 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #25 | Epoch Duration: 620.8610036373138
2020-01-13 12:14:23.742344 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0670184
Z variance train             0.06624363
KL Divergence                4.7303386
KL Loss                      0.47303388
QF Loss                      1415.1191
VF Loss                      1003.5268
Policy Loss                  -864.9739
Q Predictions Mean           857.7815
Q Predictions Std            435.95502
Q Predictions Max            1474.1246
Q Predictions Min            14.159474
V Predictions Mean           869.76117
V Predictions Std            425.60843
V Predictions Max            1450.181
V Predictions Min            44.75704
Log Pis Mean                 -2.023017
Log Pis Std                  6.801514
Log Pis Max                  33.859585
Log Pis Min                  -13.232526
Policy mu Mean               0.21327792
Policy mu Std                0.87488854
Policy mu Max                3.071818
Policy mu Min                -3.439757
Policy log std Mean          -0.3333187
Policy log std Std           0.12785724
Policy log std Max           -0.040468976
Policy log std Min           -0.9326554
Z mean eval                  0.071024805
Z variance eval              0.08132839
total_rewards                [467.21967328 394.40688479 497.84530893 509.41876144 528.08727377
 433.29605137 446.15333663 421.00080281 537.71302346 523.03126958]
total_rewards_mean           475.81723860614
total_rewards_std            47.750509540908475
total_rewards_max            537.7130234599447
total_rewards_min            394.40688479068245
Number of train steps total  108000
Number of env steps total    69159
Number of rollouts total     0
Train Time (s)               617.4211919740774
(Previous) Eval Time (s)     2.3718103682622313
Sample Time (s)              6.7871438870206475
Epoch Time (s)               626.5801462293603
Total Train Time (s)         16769.250483348034
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:24:50.451736 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #26 | Epoch Duration: 626.709242105484
2020-01-13 12:24:50.452047 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.070423655
Z variance train             0.0813449
KL Divergence                4.652231
KL Loss                      0.46522313
QF Loss                      1289.3586
VF Loss                      579.4412
Policy Loss                  -851.6979
Q Predictions Mean           842.0922
Q Predictions Std            419.8952
Q Predictions Max            1441.2498
Q Predictions Min            36.571728
V Predictions Mean           841.0561
V Predictions Std            421.1822
V Predictions Max            1438.8893
V Predictions Min            39.50779
Log Pis Mean                 -2.834858
Log Pis Std                  5.324415
Log Pis Max                  24.150787
Log Pis Min                  -14.363508
Policy mu Mean               0.2588805
Policy mu Std                0.8325554
Policy mu Max                2.9642396
Policy mu Min                -3.150439
Policy log std Mean          -0.31730956
Policy log std Std           0.11608731
Policy log std Max           -0.051335387
Policy log std Min           -0.83448285
Z mean eval                  0.06738392
Z variance eval              0.051000226
total_rewards                [455.4200753  391.10331436 528.43925183 492.4791676  538.32684086
 532.69656189 534.27730584 560.21358373 347.87088427 358.08216278]
total_rewards_mean           473.89091484544076
total_rewards_std            76.49635948505745
total_rewards_max            560.2135837334621
total_rewards_min            347.8708842707505
Number of train steps total  112000
Number of env steps total    71932
Number of rollouts total     0
Train Time (s)               606.509810521733
(Previous) Eval Time (s)     2.3446211898699403
Sample Time (s)              6.30486993258819
Epoch Time (s)               615.1593016441911
Total Train Time (s)         17384.514378423803
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:35:05.713590 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #27 | Epoch Duration: 615.261322259903
2020-01-13 12:35:05.713727 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06731297
Z variance train             0.05093476
KL Divergence                5.2412786
KL Loss                      0.5241279
QF Loss                      1380.5405
VF Loss                      700.3502
Policy Loss                  -873.9782
Q Predictions Mean           860.1001
Q Predictions Std            434.68777
Q Predictions Max            1474.7375
Q Predictions Min            14.785358
V Predictions Mean           876.5842
V Predictions Std            434.95535
V Predictions Max            1478.8612
V Predictions Min            0.8796439
Log Pis Mean                 -2.4013958
Log Pis Std                  6.0466595
Log Pis Max                  24.71059
Log Pis Min                  -12.742112
Policy mu Mean               0.23275273
Policy mu Std                0.8681949
Policy mu Max                2.757377
Policy mu Min                -3.207464
Policy log std Mean          -0.31740472
Policy log std Std           0.11995541
Policy log std Max           0.030013457
Policy log std Min           -0.81191707
Z mean eval                  0.060190298
Z variance eval              0.14171836
total_rewards                [571.78590457 455.65198454 465.82493738 411.07861138 321.01096338
 427.75339962 527.51256822 528.78083281 512.17527309 472.59766551]
total_rewards_mean           469.41721405089737
total_rewards_std            68.25166101937667
total_rewards_max            571.7859045665298
total_rewards_min            321.0109633752697
Number of train steps total  116000
Number of env steps total    74841
Number of rollouts total     0
Train Time (s)               611.1676101847552
(Previous) Eval Time (s)     2.2628547409549356
Sample Time (s)              7.0403459328226745
Epoch Time (s)               620.4708108585328
Total Train Time (s)         18005.106573668774
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:45:26.306579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #28 | Epoch Duration: 620.5927500724792
2020-01-13 12:45:26.306733 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06191771
Z variance train             0.14167456
KL Divergence                3.9860404
KL Loss                      0.39860404
QF Loss                      1382.77
VF Loss                      793.3561
Policy Loss                  -853.3927
Q Predictions Mean           841.15515
Q Predictions Std            468.417
Q Predictions Max            1498.874
Q Predictions Min            13.255581
V Predictions Mean           846.8412
V Predictions Std            467.8199
V Predictions Max            1482.9531
V Predictions Min            -5.844466
Log Pis Mean                 -1.8102661
Log Pis Std                  6.4245567
Log Pis Max                  29.935246
Log Pis Min                  -15.693123
Policy mu Mean               0.2886956
Policy mu Std                0.8496243
Policy mu Max                3.4637718
Policy mu Min                -2.989703
Policy log std Mean          -0.32865828
Policy log std Std           0.119504005
Policy log std Max           -0.021822184
Policy log std Min           -0.8985682
Z mean eval                  0.09403913
Z variance eval              0.19218169
total_rewards                [409.06816805 269.4964671  524.72832788 415.33701951 617.06467828
 734.05176156 463.39395139 425.08550593 483.24350487 508.44579296]
total_rewards_mean           484.9915177536406
total_rewards_std            119.46376168672461
total_rewards_max            734.0517615614359
total_rewards_min            269.4964671041627
Number of train steps total  120000
Number of env steps total    77858
Number of rollouts total     0
Train Time (s)               607.8083266238682
(Previous) Eval Time (s)     2.484282192774117
Sample Time (s)              7.43673289148137
Epoch Time (s)               617.7293417081237
Total Train Time (s)         18622.93221313879
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:55:44.133189 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #29 | Epoch Duration: 617.8263585567474
2020-01-13 12:55:44.133319 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09399406
Z variance train             0.19268312
KL Divergence                3.5768027
KL Loss                      0.3576803
QF Loss                      1346.8445
VF Loss                      636.35596
Policy Loss                  -847.4227
Q Predictions Mean           841.85767
Q Predictions Std            453.79742
Q Predictions Max            1493.2983
Q Predictions Min            -4.427484
V Predictions Mean           847.49475
V Predictions Std            449.3778
V Predictions Max            1489.0857
V Predictions Min            19.962395
Log Pis Mean                 -2.821162
Log Pis Std                  6.0225034
Log Pis Max                  27.485846
Log Pis Min                  -15.2020855
Policy mu Mean               0.2618389
Policy mu Std                0.8405374
Policy mu Max                3.0705476
Policy mu Min                -2.9674902
Policy log std Mean          -0.322696
Policy log std Std           0.11671467
Policy log std Max           0.038034365
Policy log std Min           -1.0393103
Z mean eval                  0.0886577
Z variance eval              0.14932445
total_rewards                [333.41642637 517.62541775 534.78507634 553.2842636  447.34635809
 499.66729544 445.20077073 421.5403276  299.03317015 511.08450776]
total_rewards_mean           456.2983613836965
total_rewards_std            80.90336822017059
total_rewards_max            553.2842636001735
total_rewards_min            299.0331701453251
Number of train steps total  124000
Number of env steps total    80685
Number of rollouts total     0
Train Time (s)               606.3360614147969
(Previous) Eval Time (s)     2.4545674389228225
Sample Time (s)              7.094578966964036
Epoch Time (s)               615.8852078206837
Total Train Time (s)         19238.91958815325
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:06:00.121265 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #30 | Epoch Duration: 615.9878516197205
2020-01-13 13:06:00.121395 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08512698
Z variance train             0.14961073
KL Divergence                3.0433538
KL Loss                      0.3043354
QF Loss                      1523.1149
VF Loss                      775.1148
Policy Loss                  -860.24835
Q Predictions Mean           859.70715
Q Predictions Std            449.62445
Q Predictions Max            1494.5829
Q Predictions Min            23.224909
V Predictions Mean           873.7372
V Predictions Std            447.12082
V Predictions Max            1501.3652
V Predictions Min            47.410816
Log Pis Mean                 -2.424923
Log Pis Std                  6.0639844
Log Pis Max                  30.893566
Log Pis Min                  -13.54823
Policy mu Mean               0.24601673
Policy mu Std                0.8477698
Policy mu Max                2.7925732
Policy mu Min                -2.8437762
Policy log std Mean          -0.32491168
Policy log std Std           0.123982124
Policy log std Max           -0.018819511
Policy log std Min           -0.9634791
Z mean eval                  0.10126662
Z variance eval              0.09654404
total_rewards                [620.73332303 374.62373114 424.4480372  447.41547338 524.73935764
 515.30639944 534.49584749 531.53525138 509.04212542 490.23320315]
total_rewards_mean           497.2572749262731
total_rewards_std            64.7314898673099
total_rewards_max            620.7333230270572
total_rewards_min            374.62373113700954
Number of train steps total  128000
Number of env steps total    83479
Number of rollouts total     0
Train Time (s)               614.769242094364
(Previous) Eval Time (s)     2.5641017141751945
Sample Time (s)              6.759815101046115
Epoch Time (s)               624.0931589095853
Total Train Time (s)         19863.113502623048
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:16:24.317250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #31 | Epoch Duration: 624.1957433223724
2020-01-13 13:16:24.317427 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #31 | Started Training: True
