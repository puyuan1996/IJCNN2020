---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0006429219
Z variance train             0.69233894
KL Divergence                0.15005128
KL Loss                      0.015005128
QF Loss                      41.014656
VF Loss                      4.412744
Policy Loss                  -2.0703828
Q Predictions Mean           0.0062027173
Q Predictions Std            0.00047991856
Q Predictions Max            0.007425264
Q Predictions Min            0.0046445215
V Predictions Mean           0.0010421779
V Predictions Std            0.00034087352
V Predictions Max            0.002060153
V Predictions Min            -0.00013086724
Log Pis Mean                 -2.0530977
Log Pis Std                  0.36131054
Log Pis Max                  -0.87553036
Log Pis Min                  -2.704667
Policy mu Mean               0.00072097266
Policy mu Std                0.0009051732
Policy mu Max                0.002585583
Policy mu Min                -0.0007546327
Policy log std Mean          -0.00024021283
Policy log std Std           0.0010355052
Policy log std Max           0.0013663655
Policy log std Min           -0.0019208916
Z mean eval                  0.016897932
Z variance eval              0.0074978145
total_rewards                [38.22339057 40.13921878 39.78810414 40.36440671 38.34571265 38.91801178
 39.96088585 39.8144981  40.27736666 40.02457323]
total_rewards_mean           39.58561684822189
total_rewards_std            0.7521384967066785
total_rewards_max            40.36440670527788
total_rewards_min            38.223390570168505
Number of train steps total  4000
Number of env steps total    4278
Number of rollouts total     0
Train Time (s)               137.97806604066864
(Previous) Eval Time (s)     0
Sample Time (s)              14.082128460053355
Epoch Time (s)               152.060194500722
Total Train Time (s)         152.5528233977966
Epoch                        0
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:33:01.766244 UTC | [2020_01_11_02_30_29] Iteration #0 | Epoch Duration: 152.55770707130432
2020-01-11 02:33:01.766501 UTC | [2020_01_11_02_30_29] Iteration #0 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014388141
Z variance train             0.007515853
KL Divergence                9.888719
KL Loss                      0.9888719
QF Loss                      3169.8503
VF Loss                      247.62395
Policy Loss                  -209.97762
Q Predictions Mean           212.98608
Q Predictions Std            113.061554
Q Predictions Max            458.88928
Q Predictions Min            -7.570993
V Predictions Mean           221.06853
V Predictions Std            103.9153
V Predictions Max            461.17926
V Predictions Min            14.078594
Log Pis Mean                 2.4564514
Log Pis Std                  2.1280437
Log Pis Max                  8.618195
Log Pis Min                  -5.3356233
Policy mu Mean               1.3657866
Policy mu Std                0.59303296
Policy mu Max                2.7400744
Policy mu Min                -2.1858404
Policy log std Mean          -0.5754762
Policy log std Std           0.08189308
Policy log std Max           -0.324416
Policy log std Min           -0.84974724
Z mean eval                  0.6560978
Z variance eval              0.0013408542
total_rewards                [239.99131272 238.41720031 217.71311981 243.58055671 255.3549253
 222.79701716 271.06837026 254.80391299 279.25688712 279.83925923]
total_rewards_mean           250.28225616194595
total_rewards_std            20.73443611548193
total_rewards_max            279.8392592278159
total_rewards_min            217.71311980611577
Number of train steps total  8000
Number of env steps total    6548
Number of rollouts total     0
Train Time (s)               143.56793195195496
(Previous) Eval Time (s)     3.3657529950141907
Sample Time (s)              6.258920396212488
Epoch Time (s)               153.19260534318164
Total Train Time (s)         305.82955528842285
Epoch                        1
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:35:35.042892 UTC | [2020_01_11_02_30_29] Iteration #1 | Epoch Duration: 153.27621936798096
2020-01-11 02:35:35.043110 UTC | [2020_01_11_02_30_29] Iteration #1 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6711799
Z variance train             0.001299253
KL Divergence                16.689816
KL Loss                      1.6689816
QF Loss                      12759.455
VF Loss                      2249.3752
Policy Loss                  -698.84827
Q Predictions Mean           658.37885
Q Predictions Std            196.5816
Q Predictions Max            1207.3162
Q Predictions Min            -24.14618
V Predictions Mean           697.14124
V Predictions Std            135.00566
V Predictions Max            1119.7834
V Predictions Min            -8.406482
Log Pis Mean                 3.5985017
Log Pis Std                  2.9939911
Log Pis Max                  12.743549
Log Pis Min                  -3.6869724
Policy mu Mean               0.31167406
Policy mu Std                1.6227313
Policy mu Max                3.4946947
Policy mu Min                -3.477896
Policy log std Mean          -0.77255106
Policy log std Std           0.22762576
Policy log std Max           -0.20085947
Policy log std Min           -1.7123406
Z mean eval                  0.69435793
Z variance eval              0.0017707702
total_rewards                [23.88314348 16.35898764 16.25043954 19.66365327 17.92713859 18.15073074
 20.78502424 17.74807696 16.1008808  17.82891948]
total_rewards_mean           18.46969947368749
total_rewards_std            2.289336211726058
total_rewards_max            23.883143480298454
total_rewards_min            16.1008807969039
Number of train steps total  12000
Number of env steps total    8937
Number of rollouts total     0
Train Time (s)               142.94396378286183
(Previous) Eval Time (s)     0.2791957431472838
Sample Time (s)              8.53642943315208
Epoch Time (s)               151.7595889591612
Total Train Time (s)         457.67815011693165
Epoch                        2
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:38:06.894010 UTC | [2020_01_11_02_30_29] Iteration #2 | Epoch Duration: 151.85067105293274
2020-01-11 02:38:06.894287 UTC | [2020_01_11_02_30_29] Iteration #2 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6959704
Z variance train             0.0017664874
KL Divergence                17.978905
KL Loss                      1.7978905
QF Loss                      7422.719
VF Loss                      3698.6704
Policy Loss                  -1507.9847
Q Predictions Mean           1402.9729
Q Predictions Std            415.6025
Q Predictions Max            2096.5151
Q Predictions Min            -4.187426
V Predictions Mean           1516.9377
V Predictions Std            267.8342
V Predictions Max            2093.5369
V Predictions Min            187.98703
Log Pis Mean                 6.8610773
Log Pis Std                  3.126428
Log Pis Max                  20.206003
Log Pis Min                  -1.0355854
Policy mu Mean               0.3460587
Policy mu Std                2.2652745
Policy mu Max                4.8650846
Policy mu Min                -3.4184701
Policy log std Mean          -0.8066278
Policy log std Std           0.3643787
Policy log std Max           -0.17216866
Policy log std Min           -2.5092928
Z mean eval                  0.539454
Z variance eval              0.003996846
total_rewards                [24.43381898 23.33027345 17.61649062 17.3155071  27.78416983  0.85671376
 13.74724261 11.67212623 19.34292721 24.69817488]
total_rewards_mean           18.07974446710826
total_rewards_std            7.515164898540787
total_rewards_max            27.78416983348656
total_rewards_min            0.8567137594770896
Number of train steps total  16000
Number of env steps total    11318
Number of rollouts total     0
Train Time (s)               141.34629634814337
(Previous) Eval Time (s)     0.5937562612816691
Sample Time (s)              6.745269004255533
Epoch Time (s)               148.68532161368057
Total Train Time (s)         606.4462630408816
Epoch                        3
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:40:35.661669 UTC | [2020_01_11_02_30_29] Iteration #3 | Epoch Duration: 148.76722073554993
2020-01-11 02:40:35.661838 UTC | [2020_01_11_02_30_29] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.53133154
Z variance train             0.0034263642
KL Divergence                15.934438
KL Loss                      1.5934438
QF Loss                      98194.61
VF Loss                      2398.5933
Policy Loss                  -1833.4232
Q Predictions Mean           1761.3032
Q Predictions Std            378.2661
Q Predictions Max            2558.8562
Q Predictions Min            -55.06848
V Predictions Mean           1818.3574
V Predictions Std            217.49107
V Predictions Max            2548.2488
V Predictions Min            856.81494
Log Pis Mean                 3.897527
Log Pis Std                  3.916458
Log Pis Max                  18.681892
Log Pis Min                  -3.9662657
Policy mu Mean               -0.01565967
Policy mu Std                1.705889
Policy mu Max                4.406372
Policy mu Min                -4.073835
Policy log std Mean          -0.9097597
Policy log std Std           0.30760628
Policy log std Max           -0.1471211
Policy log std Min           -1.7762955
Z mean eval                  0.37196404
Z variance eval              0.004503501
total_rewards                [104.70321143 129.17938291 127.5359323  130.76166453 126.34479454
 114.9792766  123.07284057 134.58211296 123.47716215 124.10289235]
total_rewards_mean           123.87392703254113
total_rewards_std            8.107109440636965
total_rewards_max            134.5821129600193
total_rewards_min            104.70321142698263
Number of train steps total  20000
Number of env steps total    13690
Number of rollouts total     0
Train Time (s)               143.4341135667637
(Previous) Eval Time (s)     2.1897515449672937
Sample Time (s)              7.116108471062034
Epoch Time (s)               152.73997358279303
Total Train Time (s)         759.2892796043307
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:43:08.506238 UTC | [2020_01_11_02_30_29] Iteration #4 | Epoch Duration: 152.84426188468933
2020-01-11 02:43:08.506442 UTC | [2020_01_11_02_30_29] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.37635767
Z variance train             0.004187441
KL Divergence                13.612614
KL Loss                      1.3612614
QF Loss                      98211.53
VF Loss                      24412.035
Policy Loss                  -1799.2435
Q Predictions Mean           1713.6597
Q Predictions Std            460.65842
Q Predictions Max            2975.6465
Q Predictions Min            -32.882446
V Predictions Mean           1898.4749
V Predictions Std            358.3721
V Predictions Max            2745.6455
V Predictions Min            139.8643
Log Pis Mean                 5.5909452
Log Pis Std                  4.196209
Log Pis Max                  21.623547
Log Pis Min                  -2.8034449
Policy mu Mean               0.82359105
Policy mu Std                1.8069326
Policy mu Max                4.9114394
Policy mu Min                -4.0704193
Policy log std Mean          -0.9655773
Policy log std Std           0.42715192
Policy log std Max           0.010056198
Policy log std Min           -2.2336438
Z mean eval                  0.316656
Z variance eval              0.0043151
total_rewards                [ 41.69903341  82.01295684  13.71775591  16.53150119  40.88706133
  19.67345648 317.78501822  15.24651608  81.44099796 306.61128128]
total_rewards_mean           93.56055786876627
total_rewards_std            111.94297951736364
total_rewards_max            317.7850182158535
total_rewards_min            13.717755909330176
Number of train steps total  24000
Number of env steps total    16073
Number of rollouts total     0
Train Time (s)               141.99564313003793
(Previous) Eval Time (s)     1.434006379917264
Sample Time (s)              8.535303621552885
Epoch Time (s)               151.96495313150808
Total Train Time (s)         911.3384833130985
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:45:40.556990 UTC | [2020_01_11_02_30_29] Iteration #5 | Epoch Duration: 152.05037927627563
2020-01-11 02:45:40.557239 UTC | [2020_01_11_02_30_29] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.31369346
Z variance train             0.0041466253
KL Divergence                12.420212
KL Loss                      1.2420212
QF Loss                      149663.55
VF Loss                      15684.243
Policy Loss                  -2289.4314
Q Predictions Mean           2178.0066
Q Predictions Std            505.69037
Q Predictions Max            3604.5034
Q Predictions Min            -43.43756
V Predictions Mean           2366.1804
V Predictions Std            421.07376
V Predictions Max            3701.5647
V Predictions Min            -329.85382
Log Pis Mean                 5.6650124
Log Pis Std                  3.9281921
Log Pis Max                  19.947615
Log Pis Min                  -6.42096
Policy mu Mean               0.5809738
Policy mu Std                1.947192
Policy mu Max                5.9093323
Policy mu Min                -4.578021
Policy log std Mean          -0.945254
Policy log std Std           0.41305846
Policy log std Max           0.24588531
Policy log std Min           -3.0664337
Z mean eval                  0.2941875
Z variance eval              0.0029586102
total_rewards                [285.92337391 277.50640497 289.4673285  301.32515378 319.09060013
 294.60902456 307.37260063 309.34957511 289.45775101 296.2088357 ]
total_rewards_mean           297.0310648299999
total_rewards_std            11.787518930524726
total_rewards_max            319.09060013328633
total_rewards_min            277.50640497094537
Number of train steps total  28000
Number of env steps total    18757
Number of rollouts total     0
Train Time (s)               138.28977762022987
(Previous) Eval Time (s)     4.5695248269476
Sample Time (s)              9.257368283346295
Epoch Time (s)               152.11667073052377
Total Train Time (s)         1063.5399297005497
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:48:12.760334 UTC | [2020_01_11_02_30_29] Iteration #6 | Epoch Duration: 152.20290732383728
2020-01-11 02:48:12.760616 UTC | [2020_01_11_02_30_29] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2953978
Z variance train             0.0029857983
KL Divergence                13.691562
KL Loss                      1.3691562
QF Loss                      54786.273
VF Loss                      14901.015
Policy Loss                  -2737.7488
Q Predictions Mean           2605.398
Q Predictions Std            628.1969
Q Predictions Max            3915.2424
Q Predictions Min            -56.776894
V Predictions Mean           2668.0442
V Predictions Std            471.84882
V Predictions Max            3793.531
V Predictions Min            -112.49427
Log Pis Mean                 5.9608884
Log Pis Std                  3.6706192
Log Pis Max                  17.5176
Log Pis Min                  -3.5808907
Policy mu Mean               0.9159439
Policy mu Std                1.8574685
Policy mu Max                6.9506497
Policy mu Min                -4.862166
Policy log std Mean          -0.9596724
Policy log std Std           0.43970966
Policy log std Max           0.12021962
Policy log std Min           -2.6836138
Z mean eval                  0.25071687
Z variance eval              0.0015255779
total_rewards                [ 83.64658937 480.01587944 376.60266591 378.66371085 468.41269705
 365.36025083 375.44316956 468.91079199 366.28233722 371.97370547]
total_rewards_mean           373.53117976900853
total_rewards_std            106.59878418348863
total_rewards_max            480.01587943928513
total_rewards_min            83.64658937153087
Number of train steps total  32000
Number of env steps total    21300
Number of rollouts total     0
Train Time (s)               135.71930120931938
(Previous) Eval Time (s)     5.9226668030023575
Sample Time (s)              9.793030515313148
Epoch Time (s)               151.4349985276349
Total Train Time (s)         1215.0573596158065
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:50:44.278530 UTC | [2020_01_11_02_30_29] Iteration #7 | Epoch Duration: 151.51757311820984
2020-01-11 02:50:44.278859 UTC | [2020_01_11_02_30_29] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2172502
Z variance train             0.0023178898
KL Divergence                13.416191
KL Loss                      1.3416191
QF Loss                      93475.8
VF Loss                      14950.486
Policy Loss                  -2660.4675
Q Predictions Mean           2579.415
Q Predictions Std            549.0372
Q Predictions Max            3217.962
Q Predictions Min            -50.069206
V Predictions Mean           2726.6394
V Predictions Std            363.15057
V Predictions Max            3412.89
V Predictions Min            197.4643
Log Pis Mean                 5.380951
Log Pis Std                  3.8097835
Log Pis Max                  22.936499
Log Pis Min                  -3.2982368
Policy mu Mean               0.81109357
Policy mu Std                1.7482315
Policy mu Max                5.7719274
Policy mu Min                -6.6595383
Policy log std Mean          -1.0530113
Policy log std Std           0.42750362
Policy log std Max           0.27331993
Policy log std Min           -2.3898542
Z mean eval                  0.19167224
Z variance eval              0.0013359232
total_rewards                [319.6751875   99.62280719 338.95677498  84.71258418 335.34448189
 100.91076649 395.54884316  90.56635712 376.95054118 383.95338166]
total_rewards_mean           252.62417253646467
total_rewards_std            131.45610956751224
total_rewards_max            395.5488431570857
total_rewards_min            84.71258418451441
Number of train steps total  36000
Number of env steps total    23929
Number of rollouts total     0
Train Time (s)               135.43772410880774
(Previous) Eval Time (s)     2.116916451137513
Sample Time (s)              10.189491805620492
Epoch Time (s)               147.74413236556575
Total Train Time (s)         1362.8893656604923
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:53:12.111922 UTC | [2020_01_11_02_30_29] Iteration #8 | Epoch Duration: 147.83280873298645
2020-01-11 02:53:12.112158 UTC | [2020_01_11_02_30_29] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21357782
Z variance train             0.0007276485
KL Divergence                16.636826
KL Loss                      1.6636826
QF Loss                      127842.375
VF Loss                      10357.309
Policy Loss                  -2313.9246
Q Predictions Mean           2209.344
Q Predictions Std            643.9082
Q Predictions Max            3107.3364
Q Predictions Min            -61.63575
V Predictions Mean           2319.2095
V Predictions Std            514.14417
V Predictions Max            3194.9963
V Predictions Min            -303.7246
Log Pis Mean                 5.2509623
Log Pis Std                  3.7634046
Log Pis Max                  22.091671
Log Pis Min                  -4.636205
Policy mu Mean               0.8290588
Policy mu Std                1.7717671
Policy mu Max                6.850341
Policy mu Min                -4.762521
Policy log std Mean          -1.0380448
Policy log std Std           0.46702823
Policy log std Max           0.36572614
Policy log std Min           -2.4578433
Z mean eval                  0.14566807
Z variance eval              0.0007017214
total_rewards                [248.92313505 250.70737529 256.68767529 268.1647504  231.97959951
 254.14652823 275.45371048 239.07844839 248.77843451 254.91261358]
total_rewards_mean           252.8832270719112
total_rewards_std            11.949641766828018
total_rewards_max            275.4537104796104
total_rewards_min            231.97959951230837
Number of train steps total  40000
Number of env steps total    26414
Number of rollouts total     0
Train Time (s)               135.75281985476613
(Previous) Eval Time (s)     4.65821027290076
Sample Time (s)              9.17350648296997
Epoch Time (s)               149.58453661063686
Total Train Time (s)         1512.5550873894244
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:55:41.777485 UTC | [2020_01_11_02_30_29] Iteration #9 | Epoch Duration: 149.66516852378845
2020-01-11 02:55:41.777624 UTC | [2020_01_11_02_30_29] Iteration #9 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14225012
Z variance train             0.000701782
KL Divergence                17.053509
KL Loss                      1.7053509
QF Loss                      25781.654
VF Loss                      7778.3076
Policy Loss                  -2282.7385
Q Predictions Mean           2222.8574
Q Predictions Std            498.7885
Q Predictions Max            2816.7483
Q Predictions Min            -46.920464
V Predictions Mean           2301.8477
V Predictions Std            364.42996
V Predictions Max            2693.3423
V Predictions Min            -34.329094
Log Pis Mean                 4.237398
Log Pis Std                  3.675126
Log Pis Max                  21.700964
Log Pis Min                  -5.9373856
Policy mu Mean               0.47876582
Policy mu Std                1.693023
Policy mu Max                4.9248157
Policy mu Min                -4.8435764
Policy log std Mean          -0.972799
Policy log std Std           0.4151775
Policy log std Max           0.20451736
Policy log std Min           -2.4702213
Z mean eval                  0.20404704
Z variance eval              0.00019006038
total_rewards                [-1.06463928 -1.42745027 -1.41491052 -1.72075987 -1.04399743 -1.36738382
 -0.61510511 -1.06974048 -1.0157947  -1.33759233]
total_rewards_mean           -1.2077373792052024
total_rewards_std            0.291739920945638
total_rewards_max            -0.6151051082316777
total_rewards_min            -1.7207598668568322
Number of train steps total  44000
Number of env steps total    29001
Number of rollouts total     0
Train Time (s)               136.08139022719115
(Previous) Eval Time (s)     0.26686645997688174
Sample Time (s)              9.85587207833305
Epoch Time (s)               146.20412876550108
Total Train Time (s)         1658.8484107893892
Epoch                        10
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:58:08.072750 UTC | [2020_01_11_02_30_29] Iteration #10 | Epoch Duration: 146.29500436782837
2020-01-11 02:58:08.072941 UTC | [2020_01_11_02_30_29] Iteration #10 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09838971
Z variance train             0.0005096923
KL Divergence                17.753044
KL Loss                      1.7753044
QF Loss                      13314.828
VF Loss                      4473.1147
Policy Loss                  -2162.137
Q Predictions Mean           2114.025
Q Predictions Std            448.31555
Q Predictions Max            3276.0789
Q Predictions Min            26.317543
V Predictions Mean           2198.3662
V Predictions Std            388.59964
V Predictions Max            3355.1094
V Predictions Min            238.03752
Log Pis Mean                 5.3110237
Log Pis Std                  3.0481713
Log Pis Max                  18.22381
Log Pis Min                  -1.4730978
Policy mu Mean               0.02687881
Policy mu Std                1.918539
Policy mu Max                4.5254736
Policy mu Min                -4.3315187
Policy log std Mean          -0.9254591
Policy log std Std           0.40629718
Policy log std Max           0.017957687
Policy log std Min           -2.2752798
Z mean eval                  0.09233029
Z variance eval              0.0064105853
total_rewards                [42.15839129 35.84614718 34.86036506 35.33762661 31.02351404 35.17694454
 32.78249107 55.68514466 29.30384291 30.78842795]
total_rewards_mean           36.296289530782715
total_rewards_std            7.308270693295796
total_rewards_max            55.68514466221806
total_rewards_min            29.303842905880565
Number of train steps total  48000
Number of env steps total    31438
Number of rollouts total     0
Train Time (s)               134.9458443610929
(Previous) Eval Time (s)     1.8231482189148664
Sample Time (s)              6.757214202545583
Epoch Time (s)               143.52620678255334
Total Train Time (s)         1802.4524024254642
Epoch                        11
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:00:31.678032 UTC | [2020_01_11_02_30_29] Iteration #11 | Epoch Duration: 143.6049325466156
2020-01-11 03:00:31.678230 UTC | [2020_01_11_02_30_29] Iteration #11 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.065642886
Z variance train             0.0026477631
KL Divergence                13.78945
KL Loss                      1.378945
QF Loss                      42858.383
VF Loss                      3060.2642
Policy Loss                  -2033.7351
Q Predictions Mean           1933.3671
Q Predictions Std            563.31354
Q Predictions Max            2457.985
Q Predictions Min            -22.166473
V Predictions Mean           2051.5742
V Predictions Std            470.8721
V Predictions Max            2473.4648
V Predictions Min            -46.880154
Log Pis Mean                 4.891754
Log Pis Std                  3.7691748
Log Pis Max                  19.31246
Log Pis Min                  -4.191919
Policy mu Mean               0.39426413
Policy mu Std                1.7694741
Policy mu Max                5.0340433
Policy mu Min                -4.426901
Policy log std Mean          -1.017481
Policy log std Std           0.3992745
Policy log std Max           0.044923007
Policy log std Min           -2.2358932
Z mean eval                  0.07412673
Z variance eval              0.0019837054
total_rewards                [14.50392016 12.67431593 15.29498781 11.05229291  9.50423406 11.15606351
 15.3884372  21.94646699 10.98239219 23.55362566]
total_rewards_mean           14.605673641324284
total_rewards_std            4.499562652300285
total_rewards_max            23.553625662138245
total_rewards_min            9.504234055799662
Number of train steps total  52000
Number of env steps total    33937
Number of rollouts total     0
Train Time (s)               135.36695221997797
(Previous) Eval Time (s)     1.2603685888461769
Sample Time (s)              7.846739017870277
Epoch Time (s)               144.47405982669443
Total Train Time (s)         1947.059398368001
Epoch                        12
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:02:56.290704 UTC | [2020_01_11_02_30_29] Iteration #12 | Epoch Duration: 144.61230087280273
2020-01-11 03:02:56.290937 UTC | [2020_01_11_02_30_29] Iteration #12 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06951976
Z variance train             0.0013433138
KL Divergence                15.073669
KL Loss                      1.507367
QF Loss                      26643.229
VF Loss                      1978.6207
Policy Loss                  -1749.9391
Q Predictions Mean           1700.7587
Q Predictions Std            579.92786
Q Predictions Max            2416.211
Q Predictions Min            -36.764343
V Predictions Mean           1743.2228
V Predictions Std            512.1834
V Predictions Max            2415.2034
V Predictions Min            -81.16471
Log Pis Mean                 4.3277907
Log Pis Std                  3.7088854
Log Pis Max                  15.366065
Log Pis Min                  -3.3076696
Policy mu Mean               0.22280745
Policy mu Std                1.7821457
Policy mu Max                4.511631
Policy mu Min                -3.7640898
Policy log std Mean          -0.93709797
Policy log std Std           0.44234696
Policy log std Max           0.13038799
Policy log std Min           -2.9418712
Z mean eval                  0.055693634
Z variance eval              0.0013808478
total_rewards                [ 995.86836731  990.95753945 1000.28489258  994.25700739 1011.62322735
  995.29930006  993.80778553 1005.91615812 1005.14167185  999.75903723]
total_rewards_mean           999.2914986873823
total_rewards_std            6.196088777862921
total_rewards_max            1011.6232273461352
total_rewards_min            990.9575394533952
Number of train steps total  56000
Number of env steps total    36230
Number of rollouts total     0
Train Time (s)               135.81650254735723
(Previous) Eval Time (s)     33.35109789902344
Sample Time (s)              6.844270074274391
Epoch Time (s)               176.01187052065507
Total Train Time (s)         2123.15291457437
Epoch                        13
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:05:52.381177 UTC | [2020_01_11_02_30_29] Iteration #13 | Epoch Duration: 176.09008359909058
2020-01-11 03:05:52.381367 UTC | [2020_01_11_02_30_29] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06077087
Z variance train             0.0014026725
KL Divergence                14.562202
KL Loss                      1.4562203
QF Loss                      18441.89
VF Loss                      2408.685
Policy Loss                  -1652.1941
Q Predictions Mean           1618.1041
Q Predictions Std            539.1627
Q Predictions Max            2232.9324
Q Predictions Min            -130.06111
V Predictions Mean           1676.7926
V Predictions Std            512.3785
V Predictions Max            2258.0374
V Predictions Min            -142.03767
Log Pis Mean                 3.605422
Log Pis Std                  3.386251
Log Pis Max                  16.358515
Log Pis Min                  -4.396473
Policy mu Mean               0.32351252
Policy mu Std                1.5526797
Policy mu Max                4.0975847
Policy mu Min                -4.3382134
Policy log std Mean          -1.0278023
Policy log std Std           0.41404918
Policy log std Max           0.14621904
Policy log std Min           -2.8620248
Z mean eval                  0.03376046
Z variance eval              0.00059890683
total_rewards                [507.67143189 317.73263168 325.69620934 524.3768484  144.28623312
 721.82606784 456.62364078 288.07917659 438.96942447 373.4395039 ]
total_rewards_mean           409.8701168018109
total_rewards_std            150.09851788949013
total_rewards_max            721.8260678443789
total_rewards_min            144.28623312176683
Number of train steps total  60000
Number of env steps total    38574
Number of rollouts total     0
Train Time (s)               138.18919231416658
(Previous) Eval Time (s)     10.257146304938942
Sample Time (s)              7.8114110585302114
Epoch Time (s)               156.25774967763573
Total Train Time (s)         2279.504822254181
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:08:28.734904 UTC | [2020_01_11_02_30_29] Iteration #14 | Epoch Duration: 156.35338926315308
2020-01-11 03:08:28.735103 UTC | [2020_01_11_02_30_29] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0267844
Z variance train             0.0008649728
KL Divergence                15.703648
KL Loss                      1.5703648
QF Loss                      7253.79
VF Loss                      7715.0464
Policy Loss                  -1619.2946
Q Predictions Mean           1573.2909
Q Predictions Std            478.5663
Q Predictions Max            2247.246
Q Predictions Min            -116.496574
V Predictions Mean           1698.3557
V Predictions Std            438.69308
V Predictions Max            2401.0688
V Predictions Min            -122.271225
Log Pis Mean                 2.977364
Log Pis Std                  3.0715084
Log Pis Max                  14.687985
Log Pis Min                  -4.274711
Policy mu Mean               -0.11924278
Policy mu Std                1.4476715
Policy mu Max                3.2449722
Policy mu Min                -4.2447457
Policy log std Mean          -0.9833813
Policy log std Std           0.48462147
Policy log std Max           0.03545624
Policy log std Min           -3.7400842
Z mean eval                  0.04724317
Z variance eval              0.0013775587
total_rewards                [358.95425816 646.6085294  426.90358631 372.35258869 719.25079826
 477.3993758  347.92968885 983.17176519 499.94627406 183.46607093]
total_rewards_mean           501.59829356373194
total_rewards_std            216.4151404525973
total_rewards_max            983.1717651916645
total_rewards_min            183.4660709270294
Number of train steps total  64000
Number of env steps total    41390
Number of rollouts total     0
Train Time (s)               137.58662161324173
(Previous) Eval Time (s)     11.348272344097495
Sample Time (s)              11.302175141870975
Epoch Time (s)               160.2370690992102
Total Train Time (s)         2439.8322404217906
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:11:09.062978 UTC | [2020_01_11_02_30_29] Iteration #15 | Epoch Duration: 160.32770347595215
2020-01-11 03:11:09.063227 UTC | [2020_01_11_02_30_29] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04515377
Z variance train             0.0013702959
KL Divergence                14.456864
KL Loss                      1.4456865
QF Loss                      9278.544
VF Loss                      1159.327
Policy Loss                  -1543.1523
Q Predictions Mean           1493.121
Q Predictions Std            445.1639
Q Predictions Max            2097.0754
Q Predictions Min            -75.88156
V Predictions Mean           1534.7703
V Predictions Std            398.6779
V Predictions Max            2094.804
V Predictions Min            -77.95616
Log Pis Mean                 3.5681467
Log Pis Std                  3.1532242
Log Pis Max                  17.035744
Log Pis Min                  -6.305955
Policy mu Mean               0.3335676
Policy mu Std                1.5710168
Policy mu Max                4.448852
Policy mu Min                -3.3833547
Policy log std Mean          -0.95104045
Policy log std Std           0.44610298
Policy log std Max           0.6903773
Policy log std Min           -3.0482085
Z mean eval                  0.028297495
Z variance eval              0.00067496
total_rewards                [322.3612487  338.44176268 414.64507233 309.37940468 343.46868056
 326.63326583 423.45726173 405.55697287 414.86361365 359.44876746]
total_rewards_mean           365.8256050486728
total_rewards_std            41.94018398898873
total_rewards_max            423.4572617343033
total_rewards_min            309.3794046785247
Number of train steps total  68000
Number of env steps total    43905
Number of rollouts total     0
Train Time (s)               137.22267567785457
(Previous) Eval Time (s)     6.2232845881953835
Sample Time (s)              10.4527090722695
Epoch Time (s)               153.89866933831945
Total Train Time (s)         2593.811633273959
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:13:43.044938 UTC | [2020_01_11_02_30_29] Iteration #16 | Epoch Duration: 153.98144960403442
2020-01-11 03:13:43.045241 UTC | [2020_01_11_02_30_29] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030005896
Z variance train             0.0007151282
KL Divergence                15.930381
KL Loss                      1.5930381
QF Loss                      18411.715
VF Loss                      1662.8256
Policy Loss                  -1446.0162
Q Predictions Mean           1404.9696
Q Predictions Std            404.1976
Q Predictions Max            1873.5822
Q Predictions Min            -62.23001
V Predictions Mean           1429.2526
V Predictions Std            344.65018
V Predictions Max            1868.4393
V Predictions Min            -65.28445
Log Pis Mean                 2.5714424
Log Pis Std                  2.7203562
Log Pis Max                  10.354985
Log Pis Min                  -5.5836043
Policy mu Mean               0.4030579
Policy mu Std                1.3398337
Policy mu Max                4.0332355
Policy mu Min                -3.3363893
Policy log std Mean          -0.93126553
Policy log std Std           0.42024451
Policy log std Max           0.15226728
Policy log std Min           -3.012756
Z mean eval                  0.026371542
Z variance eval              0.00041077012
total_rewards                [307.45258527 313.08417503 342.56029473 288.54812714 314.12262759
 293.86323628 337.56307808 302.77448075 301.3702505  280.12087729]
total_rewards_mean           308.14597326677966
total_rewards_std            18.864093144403412
total_rewards_max            342.56029472685935
total_rewards_min            280.12087729147606
Number of train steps total  72000
Number of env steps total    46965
Number of rollouts total     0
Train Time (s)               137.74441779917106
(Previous) Eval Time (s)     4.76470830803737
Sample Time (s)              13.017798598855734
Epoch Time (s)               155.52692470606416
Total Train Time (s)         2749.4226525845006
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:16:18.656257 UTC | [2020_01_11_02_30_29] Iteration #17 | Epoch Duration: 155.6108319759369
2020-01-11 03:16:18.656445 UTC | [2020_01_11_02_30_29] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026950007
Z variance train             0.00024479558
KL Divergence                18.451515
KL Loss                      1.8451515
QF Loss                      7522.384
VF Loss                      713.66547
Policy Loss                  -1376.5972
Q Predictions Mean           1357.0321
Q Predictions Std            346.11765
Q Predictions Max            1693.5791
Q Predictions Min            -68.6321
V Predictions Mean           1387.6836
V Predictions Std            325.486
V Predictions Max            1688.5695
V Predictions Min            -59.179672
Log Pis Mean                 2.4247556
Log Pis Std                  2.7702677
Log Pis Max                  16.098673
Log Pis Min                  -4.387846
Policy mu Mean               0.49734446
Policy mu Std                1.2682174
Policy mu Max                4.8837557
Policy mu Min                -2.970897
Policy log std Mean          -0.8452236
Policy log std Std           0.38225684
Policy log std Max           0.3406156
Policy log std Min           -3.2529407
Z mean eval                  0.008400915
Z variance eval              0.0005695112
total_rewards                [308.18395883 312.94871583 332.84634843 339.13608991 320.12313687
 276.910583   313.01204232 367.13094272 350.02720045 336.51341319]
total_rewards_mean           325.6832431564758
total_rewards_std            23.872078736616047
total_rewards_max            367.13094272377117
total_rewards_min            276.9105829950785
Number of train steps total  76000
Number of env steps total    49584
Number of rollouts total     0
Train Time (s)               137.500290711876
(Previous) Eval Time (s)     4.073781932704151
Sample Time (s)              10.213929895777255
Epoch Time (s)               151.7880025403574
Total Train Time (s)         2901.292684772052
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:18:50.527562 UTC | [2020_01_11_02_30_29] Iteration #18 | Epoch Duration: 151.87095975875854
2020-01-11 03:18:50.527743 UTC | [2020_01_11_02_30_29] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01393338
Z variance train             0.00092060724
KL Divergence                15.102727
KL Loss                      1.5102727
QF Loss                      1777.538
VF Loss                      503.6107
Policy Loss                  -1209.2521
Q Predictions Mean           1202.3579
Q Predictions Std            394.6239
Q Predictions Max            1613.1862
Q Predictions Min            -45.005554
V Predictions Mean           1201.2727
V Predictions Std            370.0105
V Predictions Max            1602.1978
V Predictions Min            -14.792131
Log Pis Mean                 1.9890049
Log Pis Std                  2.29687
Log Pis Max                  10.916193
Log Pis Min                  -3.8977263
Policy mu Mean               0.6369386
Policy mu Std                1.1268995
Policy mu Max                4.277391
Policy mu Min                -3.2698348
Policy log std Mean          -0.84885
Policy log std Std           0.37230417
Policy log std Max           0.42087984
Policy log std Min           -3.3856573
Z mean eval                  0.016949315
Z variance eval              0.00069337635
total_rewards                [307.6521746  305.80316269 312.09360616 312.52218191 311.90641247
 310.12432819 303.79809708 292.35527193 315.73225016 284.61688896]
total_rewards_mean           305.6604374150109
total_rewards_std            9.360358935285682
total_rewards_max            315.7322501570165
total_rewards_min            284.6168889632097
Number of train steps total  80000
Number of env steps total    52389
Number of rollouts total     0
Train Time (s)               137.25510866288096
(Previous) Eval Time (s)     4.3446665201336145
Sample Time (s)              10.415997279342264
Epoch Time (s)               152.01577246235684
Total Train Time (s)         3053.3882462796755
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:21:22.625342 UTC | [2020_01_11_02_30_29] Iteration #19 | Epoch Duration: 152.09737277030945
2020-01-11 03:21:22.625618 UTC | [2020_01_11_02_30_29] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017316733
Z variance train             0.00074312644
KL Divergence                15.676246
KL Loss                      1.5676246
QF Loss                      17711.865
VF Loss                      1177.8916
Policy Loss                  -1099.4238
Q Predictions Mean           1070.0049
Q Predictions Std            376.28574
Q Predictions Max            1505.9657
Q Predictions Min            -75.00879
V Predictions Mean           1126.7617
V Predictions Std            344.82516
V Predictions Max            1520.8284
V Predictions Min            -74.37307
Log Pis Mean                 2.5732372
Log Pis Std                  2.5606287
Log Pis Max                  12.0575695
Log Pis Min                  -4.6120644
Policy mu Mean               0.85413474
Policy mu Std                1.1357377
Policy mu Max                4.049391
Policy mu Min                -3.9958942
Policy log std Mean          -0.79175025
Policy log std Std           0.35218632
Policy log std Max           0.40044707
Policy log std Min           -2.827095
Z mean eval                  0.0044833496
Z variance eval              0.0007146996
total_rewards                [300.98593291 305.37115531 282.73456574 294.01647424 286.28640056
 293.30537409 301.24496208 303.35416941 310.23783964 292.45938565]
total_rewards_mean           296.9996259632005
total_rewards_std            8.252588468547831
total_rewards_max            310.2378396422088
total_rewards_min            282.7345657353373
Number of train steps total  84000
Number of env steps total    56058
Number of rollouts total     0
Train Time (s)               138.7101157340221
(Previous) Eval Time (s)     3.822071536909789
Sample Time (s)              10.732660420704633
Epoch Time (s)               153.26484769163653
Total Train Time (s)         3206.7386782574467
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:23:55.975976 UTC | [2020_01_11_02_30_29] Iteration #20 | Epoch Duration: 153.35017609596252
2020-01-11 03:23:55.976162 UTC | [2020_01_11_02_30_29] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00465841
Z variance train             0.00072037464
KL Divergence                15.656756
KL Loss                      1.5656756
QF Loss                      4110.034
VF Loss                      270.33636
Policy Loss                  -1039.3806
Q Predictions Mean           1013.03516
Q Predictions Std            350.4381
Q Predictions Max            1325.8805
Q Predictions Min            -77.31261
V Predictions Mean           1042.7913
V Predictions Std            333.2628
V Predictions Max            1327.5284
V Predictions Min            -72.829346
Log Pis Mean                 2.6335835
Log Pis Std                  2.3345778
Log Pis Max                  10.958917
Log Pis Min                  -2.2779417
Policy mu Mean               0.6352112
Policy mu Std                1.2404734
Policy mu Max                3.5750093
Policy mu Min                -3.0792334
Policy log std Mean          -0.7772586
Policy log std Std           0.28975725
Policy log std Max           -0.021783352
Policy log std Min           -2.6887982
Z mean eval                  0.009848021
Z variance eval              0.00092497293
total_rewards                [ 53.42286314  36.38988598 176.86708725 167.96162024  55.39721456
 180.91867143  55.6679647   58.99855793  47.94360553  53.74548776]
total_rewards_mean           88.73129585186781
total_rewards_std            57.014213884404036
total_rewards_max            180.91867142885687
total_rewards_min            36.38988597502198
Number of train steps total  88000
Number of env steps total    59627
Number of rollouts total     0
Train Time (s)               138.8251697202213
(Previous) Eval Time (s)     1.2443367568776011
Sample Time (s)              10.066411650273949
Epoch Time (s)               150.13591812737286
Total Train Time (s)         3356.9633571002632
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:26:26.201892 UTC | [2020_01_11_02_30_29] Iteration #21 | Epoch Duration: 150.22558498382568
2020-01-11 03:26:26.202066 UTC | [2020_01_11_02_30_29] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010583661
Z variance train             0.0009252077
KL Divergence                15.055164
KL Loss                      1.5055164
QF Loss                      16706.297
VF Loss                      750.95404
Policy Loss                  -1024.1237
Q Predictions Mean           1004.2575
Q Predictions Std            328.52792
Q Predictions Max            1322.409
Q Predictions Min            -60.03087
V Predictions Mean           1032.5061
V Predictions Std            298.49515
V Predictions Max            1312.2815
V Predictions Min            -42.259933
Log Pis Mean                 2.1789389
Log Pis Std                  2.4970405
Log Pis Max                  9.321548
Log Pis Min                  -4.520757
Policy mu Mean               0.3815991
Policy mu Std                1.290021
Policy mu Max                3.3531933
Policy mu Min                -2.9528158
Policy log std Mean          -0.7241244
Policy log std Std           0.33925134
Policy log std Max           0.06170243
Policy log std Min           -2.6484966
Z mean eval                  0.011282241
Z variance eval              0.0009992326
total_rewards                [242.0900257  257.83295676 359.40910256 345.81484342 343.76241415
 346.93565773 491.16821568 425.77926525 472.57729698 564.48723988]
total_rewards_mean           384.98570181114934
total_rewards_std            97.34197937525404
total_rewards_max            564.4872398843758
total_rewards_min            242.09002569672182
Number of train steps total  92000
Number of env steps total    62854
Number of rollouts total     0
Train Time (s)               140.69714435795322
(Previous) Eval Time (s)     5.435250661801547
Sample Time (s)              7.499540213029832
Epoch Time (s)               153.6319352327846
Total Train Time (s)         3510.685840609949
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:28:59.925697 UTC | [2020_01_11_02_30_29] Iteration #22 | Epoch Duration: 153.7234926223755
2020-01-11 03:28:59.925877 UTC | [2020_01_11_02_30_29] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010872346
Z variance train             0.0009994061
KL Divergence                14.954158
KL Loss                      1.4954158
QF Loss                      6207.6245
VF Loss                      452.1352
Policy Loss                  -951.92816
Q Predictions Mean           935.67993
Q Predictions Std            315.6332
Q Predictions Max            1204.7036
Q Predictions Min            -72.11498
V Predictions Mean           963.9675
V Predictions Std            294.65057
V Predictions Max            1218.5328
V Predictions Min            -5.285438
Log Pis Mean                 1.3111098
Log Pis Std                  2.4503367
Log Pis Max                  11.752139
Log Pis Min                  -6.0328565
Policy mu Mean               0.1482228
Policy mu Std                1.1916279
Policy mu Max                3.4498186
Policy mu Min                -3.6648927
Policy log std Mean          -0.7062535
Policy log std Std           0.3391592
Policy log std Max           0.48400158
Policy log std Min           -3.1724193
Z mean eval                  0.0049254177
Z variance eval              0.0007906798
total_rewards                [ 12.53889982 505.837269    17.42059998  12.19940726 406.51088079
  24.44467741 364.38007376  11.99692711   9.70777362  26.3670473 ]
total_rewards_mean           139.1403556062285
total_rewards_std            190.3773486779882
total_rewards_max            505.83726899951876
total_rewards_min            9.70777362371189
Number of train steps total  96000
Number of env steps total    66671
Number of rollouts total     0
Train Time (s)               146.3362103831023
(Previous) Eval Time (s)     2.5373757649213076
Sample Time (s)              12.935952339321375
Epoch Time (s)               161.80953848734498
Total Train Time (s)         3672.5818274919875
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:31:41.823109 UTC | [2020_01_11_02_30_29] Iteration #23 | Epoch Duration: 161.89707159996033
2020-01-11 03:31:41.823321 UTC | [2020_01_11_02_30_29] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0056009507
Z variance train             0.00079035247
KL Divergence                15.442234
KL Loss                      1.5442234
QF Loss                      8133.723
VF Loss                      393.7694
Policy Loss                  -908.8509
Q Predictions Mean           877.04956
Q Predictions Std            286.78043
Q Predictions Max            1152.81
Q Predictions Min            -57.840023
V Predictions Mean           914.0612
V Predictions Std            263.4569
V Predictions Max            1150.5607
V Predictions Min            -29.392614
Log Pis Mean                 1.6431898
Log Pis Std                  2.4678245
Log Pis Max                  10.278278
Log Pis Min                  -5.8339286
Policy mu Mean               -0.12538357
Policy mu Std                1.248454
Policy mu Max                3.2056677
Policy mu Min                -2.8881812
Policy log std Mean          -0.7353938
Policy log std Std           0.34867406
Policy log std Max           0.15410054
Policy log std Min           -3.155645
Z mean eval                  0.011282637
Z variance eval              0.0008680122
total_rewards                [200.3430121  312.42061417 226.31061708 338.25929731 270.22303638
 275.11966808 284.83571368 350.46820335 185.07433931 196.23665973]
total_rewards_mean           263.92911611744233
total_rewards_std            56.76797610862821
total_rewards_max            350.468203347418
total_rewards_min            185.07433931254417
Number of train steps total  100000
Number of env steps total    69928
Number of rollouts total     0
Train Time (s)               144.2005313136615
(Previous) Eval Time (s)     4.286753422114998
Sample Time (s)              7.846125324256718
Epoch Time (s)               156.3334100600332
Total Train Time (s)         3829.004614276346
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:34:18.247908 UTC | [2020_01_11_02_30_29] Iteration #24 | Epoch Duration: 156.42441415786743
2020-01-11 03:34:18.248241 UTC | [2020_01_11_02_30_29] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010587143
Z variance train             0.0008683163
KL Divergence                15.287709
KL Loss                      1.5287709
QF Loss                      1259.7991
VF Loss                      571.25146
Policy Loss                  -820.26294
Q Predictions Mean           804.35095
Q Predictions Std            280.02744
Q Predictions Max            1132.0579
Q Predictions Min            -18.256243
V Predictions Mean           838.1782
V Predictions Std            261.08304
V Predictions Max            1168.97
V Predictions Min            -23.91388
Log Pis Mean                 1.3595209
Log Pis Std                  2.6865675
Log Pis Max                  17.271599
Log Pis Min                  -4.6625867
Policy mu Mean               0.3432218
Policy mu Std                1.158687
Policy mu Max                4.1033554
Policy mu Min                -3.232
Policy log std Mean          -0.6713689
Policy log std Std           0.2630689
Policy log std Max           0.06345022
Policy log std Min           -2.2411458
Z mean eval                  0.003519185
Z variance eval              0.0006215713
total_rewards                [278.0043081  388.27886888 330.49770911 291.30481528 347.50818845
 272.28637245 295.67316063 287.50741054 274.89735044 299.96035589]
total_rewards_mean           306.5918539774641
total_rewards_std            35.606409959111105
total_rewards_max            388.2788688806363
total_rewards_min            272.2863724488796
Number of train steps total  104000
Number of env steps total    73464
Number of rollouts total     0
Train Time (s)               144.63049847492948
(Previous) Eval Time (s)     4.22920182114467
Sample Time (s)              9.966993565671146
Epoch Time (s)               158.8266938617453
Total Train Time (s)         3987.9297397746705
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:36:57.173890 UTC | [2020_01_11_02_30_29] Iteration #25 | Epoch Duration: 158.9254584312439
2020-01-11 03:36:57.174088 UTC | [2020_01_11_02_30_29] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0038525492
Z variance train             0.0006216676
KL Divergence                16.053928
KL Loss                      1.6053928
QF Loss                      8467.643
VF Loss                      1153.019
Policy Loss                  -792.6053
Q Predictions Mean           777.19934
Q Predictions Std            262.09726
Q Predictions Max            1033.4657
Q Predictions Min            -86.15581
V Predictions Mean           792.8697
V Predictions Std            261.7664
V Predictions Max            1035.179
V Predictions Min            -70.312454
Log Pis Mean                 1.8301278
Log Pis Std                  3.066799
Log Pis Max                  20.445406
Log Pis Min                  -4.511478
Policy mu Mean               0.35900688
Policy mu Std                1.2816186
Policy mu Max                4.8917146
Policy mu Min                -3.9301345
Policy log std Mean          -0.67773145
Policy log std Std           0.34997696
Policy log std Max           0.07699698
Policy log std Min           -3.1315527
Z mean eval                  0.013068305
Z variance eval              0.00070355885
total_rewards                [410.13263992 199.53179182 321.30840564 330.33528716 459.37134782
 311.46513106 402.3511772  370.73122974 370.59474019 368.58885903]
total_rewards_mean           354.44106095770803
total_rewards_std            66.8254748167368
total_rewards_max            459.3713478248586
total_rewards_min            199.53179181619694
Number of train steps total  108000
Number of env steps total    76960
Number of rollouts total     0
Train Time (s)               147.1908938549459
(Previous) Eval Time (s)     4.391388781834394
Sample Time (s)              10.456306966021657
Epoch Time (s)               162.03858960280195
Total Train Time (s)         4150.064713576343
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:39:39.310207 UTC | [2020_01_11_02_30_29] Iteration #26 | Epoch Duration: 162.13596510887146
2020-01-11 03:39:39.310411 UTC | [2020_01_11_02_30_29] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012768348
Z variance train             0.0007034974
KL Divergence                15.883944
KL Loss                      1.5883944
QF Loss                      8158.605
VF Loss                      631.5022
Policy Loss                  -752.05774
Q Predictions Mean           736.5278
Q Predictions Std            270.36258
Q Predictions Max            1038.5812
Q Predictions Min            -65.45383
V Predictions Mean           749.3208
V Predictions Std            255.03133
V Predictions Max            1035.3064
V Predictions Min            -5.3634872
Log Pis Mean                 1.8586891
Log Pis Std                  2.7618318
Log Pis Max                  13.541861
Log Pis Min                  -5.3138804
Policy mu Mean               0.6010727
Policy mu Std                1.1952679
Policy mu Max                4.3470335
Policy mu Min                -2.6228218
Policy log std Mean          -0.63618916
Policy log std Std           0.2955844
Policy log std Max           0.27117556
Policy log std Min           -2.3466702
Z mean eval                  0.008847779
Z variance eval              0.0005550304
total_rewards                [600.52327438 734.26126832 813.19987995 653.63650189 481.68176878
 692.03174831 598.60799399 748.78503411 677.76053868 479.39189144]
total_rewards_mean           647.9879899864701
total_rewards_std            104.17770448780443
total_rewards_max            813.1998799521538
total_rewards_min            479.39189143934965
Number of train steps total  112000
Number of env steps total    80202
Number of rollouts total     0
Train Time (s)               145.2110921209678
(Previous) Eval Time (s)     7.646821106784046
Sample Time (s)              9.121663176920265
Epoch Time (s)               161.97957640467212
Total Train Time (s)         4312.124414636288
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:42:21.370954 UTC | [2020_01_11_02_30_29] Iteration #27 | Epoch Duration: 162.06039953231812
2020-01-11 03:42:21.371141 UTC | [2020_01_11_02_30_29] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008430418
Z variance train             0.0005549439
KL Divergence                16.41725
KL Loss                      1.641725
QF Loss                      3061.0354
VF Loss                      506.22617
Policy Loss                  -767.1902
Q Predictions Mean           748.5952
Q Predictions Std            242.91116
Q Predictions Max            981.8879
Q Predictions Min            -36.267483
V Predictions Mean           763.94226
V Predictions Std            234.77972
V Predictions Max            979.3462
V Predictions Min            -43.056946
Log Pis Mean                 1.6715643
Log Pis Std                  2.4857955
Log Pis Max                  15.296965
Log Pis Min                  -5.3918605
Policy mu Mean               0.40825525
Policy mu Std                1.1976485
Policy mu Max                3.81896
Policy mu Min                -3.7175114
Policy log std Mean          -0.6801016
Policy log std Std           0.29800382
Policy log std Max           0.27558732
Policy log std Min           -3.0520895
Z mean eval                  0.004151289
Z variance eval              0.0006024084
total_rewards                [632.88823445 706.1971261  619.00507071 602.23231528 548.63406556
 409.62625205 234.43935804 555.24959909 751.43529662 682.26508019]
total_rewards_mean           574.1972398101977
total_rewards_std            145.01234916773757
total_rewards_max            751.4352966235689
total_rewards_min            234.43935803917245
Number of train steps total  116000
Number of env steps total    83790
Number of rollouts total     0
Train Time (s)               137.92039149580523
(Previous) Eval Time (s)     6.033665199764073
Sample Time (s)              11.672217166051269
Epoch Time (s)               155.62627386162058
Total Train Time (s)         4467.862731745932
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:44:57.110801 UTC | [2020_01_11_02_30_29] Iteration #28 | Epoch Duration: 155.73946452140808
2020-01-11 03:44:57.111050 UTC | [2020_01_11_02_30_29] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0044433335
Z variance train             0.0006028589
KL Divergence                16.285084
KL Loss                      1.6285084
QF Loss                      5102.6187
VF Loss                      562.8682
Policy Loss                  -735.14276
Q Predictions Mean           725.8268
Q Predictions Std            253.43362
Q Predictions Max            973.79333
Q Predictions Min            -77.65194
V Predictions Mean           749.1111
V Predictions Std            242.20207
V Predictions Max            997.96674
V Predictions Min            -81.917915
Log Pis Mean                 1.6381556
Log Pis Std                  2.7103193
Log Pis Max                  16.412611
Log Pis Min                  -4.9598675
Policy mu Mean               0.26500145
Policy mu Std                1.2816212
Policy mu Max                5.84238
Policy mu Min                -2.65781
Policy log std Mean          -0.65662795
Policy log std Std           0.29831707
Policy log std Max           0.15322256
Policy log std Min           -2.693678
Z mean eval                  0.013522279
Z variance eval              0.00054414605
total_rewards                [344.75444554 571.4222126  557.84377168 467.54851752 388.59823192
 592.99159541 639.19436655 302.93388332 389.12827871 621.45090037]
total_rewards_mean           487.58662036321357
total_rewards_std            117.63127640421132
total_rewards_max            639.194366552734
total_rewards_min            302.93388331948
Number of train steps total  120000
Number of env steps total    87376
Number of rollouts total     0
Train Time (s)               138.94316062005237
(Previous) Eval Time (s)     6.281885581091046
Sample Time (s)              9.70258832955733
Epoch Time (s)               154.92763453070074
Total Train Time (s)         4622.867036561482
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:47:32.116382 UTC | [2020_01_11_02_30_29] Iteration #29 | Epoch Duration: 155.00511837005615
2020-01-11 03:47:32.116599 UTC | [2020_01_11_02_30_29] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01339075
Z variance train             0.0005442315
KL Divergence                16.583206
KL Loss                      1.6583207
QF Loss                      1106.9861
VF Loss                      173.25293
Policy Loss                  -731.2184
Q Predictions Mean           721.70105
Q Predictions Std            276.55258
Q Predictions Max            977.1904
Q Predictions Min            -82.6759
V Predictions Mean           731.80994
V Predictions Std            264.10336
V Predictions Max            967.19775
V Predictions Min            -84.81125
Log Pis Mean                 1.7031174
Log Pis Std                  2.6524582
Log Pis Max                  12.547344
Log Pis Min                  -5.1050434
Policy mu Mean               0.33730647
Policy mu Std                1.2122695
Policy mu Max                3.1083755
Policy mu Min                -3.0758047
Policy log std Mean          -0.63099796
Policy log std Std           0.257287
Policy log std Max           -0.019328892
Policy log std Min           -2.686709
Z mean eval                  0.0029411917
Z variance eval              0.0005330198
total_rewards                [563.03495006 334.96342211 172.47291288 552.65261825 674.45025482
 397.83001702 339.52203828 442.57754277 352.99894064 450.87123405]
total_rewards_mean           428.1373930882125
total_rewards_std            135.48412599827114
total_rewards_max            674.4502548220875
total_rewards_min            172.47291287626734
Number of train steps total  124000
Number of env steps total    91140
Number of rollouts total     0
Train Time (s)               138.08521096315235
(Previous) Eval Time (s)     5.30701297800988
Sample Time (s)              8.778813186567277
Epoch Time (s)               152.1710371277295
Total Train Time (s)         4775.118607590906
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:50:04.372730 UTC | [2020_01_11_02_30_29] Iteration #30 | Epoch Duration: 152.2559676170349
2020-01-11 03:50:04.373030 UTC | [2020_01_11_02_30_29] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0031410954
Z variance train             0.00053258863
KL Divergence                16.48368
KL Loss                      1.6483681
QF Loss                      2319.7148
VF Loss                      423.04205
Policy Loss                  -749.12256
Q Predictions Mean           731.731
Q Predictions Std            265.56454
Q Predictions Max            961.2139
Q Predictions Min            -87.22032
V Predictions Mean           757.6476
V Predictions Std            248.18262
V Predictions Max            965.5875
V Predictions Min            -77.751396
Log Pis Mean                 1.5877907
Log Pis Std                  2.680659
Log Pis Max                  15.251237
Log Pis Min                  -6.531299
Policy mu Mean               0.2902228
Policy mu Std                1.244633
Policy mu Max                3.8015199
Policy mu Min                -2.985023
Policy log std Mean          -0.662211
Policy log std Std           0.29972595
Policy log std Max           0.13870305
Policy log std Min           -3.229247
Z mean eval                  0.007387423
Z variance eval              0.00052485475
total_rewards                [327.79229019 429.49544976 515.84655771 300.89771626 426.78266345
 281.98227057 306.69298436 480.84518844 326.44782433  79.53885713]
total_rewards_mean           347.6321802207389
total_rewards_std            118.27706574926634
total_rewards_max            515.8465577140445
total_rewards_min            79.53885713244394
Number of train steps total  128000
Number of env steps total    94722
Number of rollouts total     0
Train Time (s)               137.45523344399408
(Previous) Eval Time (s)     4.5327810840681195
Sample Time (s)              11.54452260863036
Epoch Time (s)               153.53253713669255
Total Train Time (s)         4928.753980013542
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:52:38.005993 UTC | [2020_01_11_02_30_29] Iteration #31 | Epoch Duration: 153.63271236419678
2020-01-11 03:52:38.006227 UTC | [2020_01_11_02_30_29] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007390842
Z variance train             0.0005251807
KL Divergence                16.472443
KL Loss                      1.6472443
QF Loss                      1198.8187
VF Loss                      535.47485
Policy Loss                  -774.5957
Q Predictions Mean           760.9925
Q Predictions Std            241.51074
Q Predictions Max            1000.15967
Q Predictions Min            -77.29889
V Predictions Mean           770.99915
V Predictions Std            223.26863
V Predictions Max            984.39307
V Predictions Min            -72.59375
Log Pis Mean                 1.6405382
Log Pis Std                  2.4203088
Log Pis Max                  15.354492
Log Pis Min                  -3.5191817
Policy mu Mean               0.45993975
Policy mu Std                1.1963103
Policy mu Max                5.124128
Policy mu Min                -2.8893402
Policy log std Mean          -0.66328794
Policy log std Std           0.31678522
Policy log std Max           0.23398101
Policy log std Min           -3.3075697
Z mean eval                  0.0065775267
Z variance eval              0.0005290361
total_rewards                [322.96413018 395.76256949 319.29251389 441.95061719 320.76781597
 480.37238236 466.44996667 510.01959564 521.40222149 328.53392709]
total_rewards_mean           410.75157399639073
total_rewards_std            78.85007134257827
total_rewards_max            521.4022214894076
total_rewards_min            319.29251388629643
Number of train steps total  132000
Number of env steps total    98153
Number of rollouts total     0
Train Time (s)               139.36046978691593
(Previous) Eval Time (s)     4.669717648997903
Sample Time (s)              10.21628097910434
Epoch Time (s)               154.24646841501817
Total Train Time (s)         5083.077596660703
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:55:12.332163 UTC | [2020_01_11_02_30_29] Iteration #32 | Epoch Duration: 154.32570457458496
2020-01-11 03:55:12.332457 UTC | [2020_01_11_02_30_29] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0065754154
Z variance train             0.00052899163
KL Divergence                16.627409
KL Loss                      1.662741
QF Loss                      450.9381
VF Loss                      115.958206
Policy Loss                  -814.2354
Q Predictions Mean           800.8275
Q Predictions Std            222.96617
Q Predictions Max            1019.8433
Q Predictions Min            -11.612116
V Predictions Mean           812.74646
V Predictions Std            217.24094
V Predictions Max            1023.71545
V Predictions Min            -16.546766
Log Pis Mean                 1.3036331
Log Pis Std                  2.304632
Log Pis Max                  8.628582
Log Pis Min                  -4.493493
Policy mu Mean               0.3327481
Policy mu Std                1.116831
Policy mu Max                2.7724233
Policy mu Min                -3.5894923
Policy log std Mean          -0.6052545
Policy log std Std           0.2752599
Policy log std Max           0.31018883
Policy log std Min           -2.4115884
Z mean eval                  0.0075099943
Z variance eval              0.0005780064
total_rewards                [654.48533588 732.54543057 684.05234412 715.23401372 625.83246618
 753.5255342  656.30799741 681.9242286  742.21656936 525.94567954]
total_rewards_mean           677.2069599578332
total_rewards_std            64.1097820514104
total_rewards_max            753.525534196317
total_rewards_min            525.9456795359433
Number of train steps total  136000
Number of env steps total    101778
Number of rollouts total     0
Train Time (s)               138.32277003489435
(Previous) Eval Time (s)     6.1991701307706535
Sample Time (s)              11.693197193089873
Epoch Time (s)               156.21513735875487
Total Train Time (s)         5239.378316745162
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:57:48.633522 UTC | [2020_01_11_02_30_29] Iteration #33 | Epoch Duration: 156.30087661743164
2020-01-11 03:57:48.633749 UTC | [2020_01_11_02_30_29] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007648648
Z variance train             0.00057847315
KL Divergence                16.499233
KL Loss                      1.6499233
QF Loss                      495.05643
VF Loss                      239.7721
Policy Loss                  -814.0739
Q Predictions Mean           793.99335
Q Predictions Std            273.32776
Q Predictions Max            1093.7687
Q Predictions Min            -42.066013
V Predictions Mean           804.74634
V Predictions Std            251.85718
V Predictions Max            1060.69
V Predictions Min            -49.065865
Log Pis Mean                 1.2218592
Log Pis Std                  2.2479975
Log Pis Max                  11.896313
Log Pis Min                  -4.9617095
Policy mu Mean               0.2997111
Policy mu Std                1.175397
Policy mu Max                3.555034
Policy mu Min                -2.752379
Policy log std Mean          -0.624492
Policy log std Std           0.2831943
Policy log std Max           0.26146108
Policy log std Min           -2.709768
Z mean eval                  0.011427262
Z variance eval              0.0006234859
total_rewards                [604.852637   559.21137727 553.19258132 623.06849918 572.06912843
 566.24734695 578.9059415  547.17100882 607.02135256 620.58869286]
total_rewards_mean           583.2328565864512
total_rewards_std            26.883841614392004
total_rewards_max            623.0684991800488
total_rewards_min            547.1710088181032
Number of train steps total  140000
Number of env steps total    105155
Number of rollouts total     0
Train Time (s)               138.34136413456872
(Previous) Eval Time (s)     6.057372470851988
Sample Time (s)              10.845290446653962
Epoch Time (s)               155.24402705207467
Total Train Time (s)         5394.707659455482
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:00:23.964851 UTC | [2020_01_11_02_30_29] Iteration #34 | Epoch Duration: 155.3308675289154
2020-01-11 04:00:23.965105 UTC | [2020_01_11_02_30_29] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011856029
Z variance train             0.00062282186
KL Divergence                16.370487
KL Loss                      1.6370487
QF Loss                      6643.892
VF Loss                      183.59625
Policy Loss                  -814.56024
Q Predictions Mean           801.7401
Q Predictions Std            264.10437
Q Predictions Max            1091.3197
Q Predictions Min            -9.910209
V Predictions Mean           811.11926
V Predictions Std            246.40044
V Predictions Max            1187.9713
V Predictions Min            -16.76594
Log Pis Mean                 1.2398573
Log Pis Std                  2.74043
Log Pis Max                  17.356855
Log Pis Min                  -4.115635
Policy mu Mean               0.28993925
Policy mu Std                1.2044189
Policy mu Max                4.121436
Policy mu Min                -2.6804667
Policy log std Mean          -0.6060111
Policy log std Std           0.3138014
Policy log std Max           0.18106997
Policy log std Min           -2.6478343
Z mean eval                  0.011892496
Z variance eval              0.00068789517
total_rewards                [348.93398919 661.8288553  634.82367142 657.91446669 378.55909559
 692.5494223  540.4656993  884.30418382 671.06601031 692.31212911]
total_rewards_mean           616.2757523030169
total_rewards_std            149.77359585582855
total_rewards_max            884.3041838174514
total_rewards_min            348.9339891905488
Number of train steps total  144000
Number of env steps total    108819
Number of rollouts total     0
Train Time (s)               137.67504357127473
(Previous) Eval Time (s)     5.6028756480664015
Sample Time (s)              11.948686973657459
Epoch Time (s)               155.2266061929986
Total Train Time (s)         5550.020511914976
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:02:59.278851 UTC | [2020_01_11_02_30_29] Iteration #35 | Epoch Duration: 155.31358075141907
2020-01-11 04:02:59.279066 UTC | [2020_01_11_02_30_29] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011579872
Z variance train             0.00068802404
KL Divergence                16.210506
KL Loss                      1.6210507
QF Loss                      433.45343
VF Loss                      496.05634
Policy Loss                  -825.6061
Q Predictions Mean           814.8236
Q Predictions Std            279.091
Q Predictions Max            1088.484
Q Predictions Min            -61.726017
V Predictions Mean           831.7853
V Predictions Std            264.54337
V Predictions Max            1083.5803
V Predictions Min            -38.591225
Log Pis Mean                 0.9499277
Log Pis Std                  2.5620291
Log Pis Max                  14.341349
Log Pis Min                  -5.8792768
Policy mu Mean               0.3726401
Policy mu Std                1.1579262
Policy mu Max                4.5233917
Policy mu Min                -3.0207686
Policy log std Mean          -0.5459193
Policy log std Std           0.2749069
Policy log std Max           0.44904238
Policy log std Min           -1.9608364
Z mean eval                  0.017315265
Z variance eval              0.00069260516
total_rewards                [ 75.08042083 505.82101929 542.8972745  491.56203798 754.74895538
 484.16616678 583.00086105 461.44244876 565.82316447 485.80123851]
total_rewards_mean           495.03435875496086
total_rewards_std            161.34224322867922
total_rewards_max            754.7489553786896
total_rewards_min            75.08042083223226
Number of train steps total  148000
Number of env steps total    112793
Number of rollouts total     0
Train Time (s)               137.79508446296677
(Previous) Eval Time (s)     5.3315113028511405
Sample Time (s)              13.383696265518665
Epoch Time (s)               156.51029203133658
Total Train Time (s)         5706.609237139113
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:05:35.868882 UTC | [2020_01_11_02_30_29] Iteration #36 | Epoch Duration: 156.58965706825256
2020-01-11 04:05:35.869060 UTC | [2020_01_11_02_30_29] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016799822
Z variance train             0.0006928245
KL Divergence                16.27216
KL Loss                      1.627216
QF Loss                      5192.1113
VF Loss                      315.6277
Policy Loss                  -867.9125
Q Predictions Mean           852.5077
Q Predictions Std            262.81076
Q Predictions Max            1097.7765
Q Predictions Min            -74.36069
V Predictions Mean           865.7311
V Predictions Std            238.91644
V Predictions Max            1099.4419
V Predictions Min            -60.406593
Log Pis Mean                 1.258065
Log Pis Std                  2.6352587
Log Pis Max                  14.160462
Log Pis Min                  -4.3648767
Policy mu Mean               0.11275729
Policy mu Std                1.1793245
Policy mu Max                3.535297
Policy mu Min                -3.1285057
Policy log std Mean          -0.60404116
Policy log std Std           0.2946148
Policy log std Max           0.15821469
Policy log std Min           -3.1964257
Z mean eval                  0.004778641
Z variance eval              0.00067300326
total_rewards                [590.77283782 656.36540484 646.10651512 567.42686983  79.42627057
 680.13147883 502.21241156 524.32219213  82.91817984 513.70075425]
total_rewards_mean           484.3382914782971
total_rewards_std            209.8097910101541
total_rewards_max            680.1314788263318
total_rewards_min            79.42627056762308
Number of train steps total  152000
Number of env steps total    116556
Number of rollouts total     0
Train Time (s)               138.19542086310685
(Previous) Eval Time (s)     5.227960345800966
Sample Time (s)              11.294917707331479
Epoch Time (s)               154.7182989162393
Total Train Time (s)         5861.416441882029
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:08:10.677988 UTC | [2020_01_11_02_30_29] Iteration #37 | Epoch Duration: 154.80876564979553
2020-01-11 04:08:10.678216 UTC | [2020_01_11_02_30_29] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0045690956
Z variance train             0.000672991
KL Divergence                15.938744
KL Loss                      1.5938743
QF Loss                      1741.2214
VF Loss                      447.53967
Policy Loss                  -822.7791
Q Predictions Mean           810.74176
Q Predictions Std            273.7859
Q Predictions Max            1089.3695
Q Predictions Min            -1.4516108
V Predictions Mean           825.2173
V Predictions Std            258.52362
V Predictions Max            1088.3934
V Predictions Min            -12.520863
Log Pis Mean                 1.0533006
Log Pis Std                  2.6506178
Log Pis Max                  9.17947
Log Pis Min                  -6.205677
Policy mu Mean               0.13771464
Policy mu Std                1.1860107
Policy mu Max                3.517284
Policy mu Min                -2.944876
Policy log std Mean          -0.59569335
Policy log std Std           0.35408053
Policy log std Max           0.27465802
Policy log std Min           -3.4176023
Z mean eval                  0.0118828
Z variance eval              0.0006506563
total_rewards                [787.15269591 697.03226607 791.81545934 750.47185922 792.68129342
 724.7500813  730.37842877 582.4774895  743.22851164 787.11359262]
total_rewards_mean           738.7101677797297
total_rewards_std            60.82053635311064
total_rewards_max            792.6812934187368
total_rewards_min            582.4774894971523
Number of train steps total  156000
Number of env steps total    120075
Number of rollouts total     0
Train Time (s)               137.67585598723963
(Previous) Eval Time (s)     7.723122344817966
Sample Time (s)              10.55086738243699
Epoch Time (s)               155.9498457144946
Total Train Time (s)         6017.451077239588
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:10:46.713985 UTC | [2020_01_11_02_30_29] Iteration #38 | Epoch Duration: 156.03558468818665
2020-01-11 04:10:46.714207 UTC | [2020_01_11_02_30_29] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012235562
Z variance train             0.00065106293
KL Divergence                16.155895
KL Loss                      1.6155895
QF Loss                      1228.6257
VF Loss                      559.8366
Policy Loss                  -834.7887
Q Predictions Mean           825.0106
Q Predictions Std            266.33588
Q Predictions Max            1096.3918
Q Predictions Min            -14.344137
V Predictions Mean           830.90356
V Predictions Std            258.05072
V Predictions Max            1089.8573
V Predictions Min            -10.2142515
Log Pis Mean                 1.0406564
Log Pis Std                  2.5505598
Log Pis Max                  11.892817
Log Pis Min                  -4.7570195
Policy mu Mean               -0.06666872
Policy mu Std                1.16566
Policy mu Max                3.8247027
Policy mu Min                -2.7512438
Policy log std Mean          -0.63236374
Policy log std Std           0.3124659
Policy log std Max           0.36037022
Policy log std Min           -3.0139227
Z mean eval                  0.013182824
Z variance eval              0.0005022205
total_rewards                [ 863.97337203  878.64012507  734.7325512  1065.95213297  744.70191622
  719.17806201  718.63636706  920.69138706  775.60697648  735.08132481]
total_rewards_mean           815.7194214905788
total_rewards_std            108.80358715367556
total_rewards_max            1065.9521329709569
total_rewards_min            718.6363670632448
Number of train steps total  160000
Number of env steps total    123239
Number of rollouts total     0
Train Time (s)               137.58911586087197
(Previous) Eval Time (s)     9.373000787105411
Sample Time (s)              8.84870040928945
Epoch Time (s)               155.81081705726683
Total Train Time (s)         6173.34266732214
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:13:22.605373 UTC | [2020_01_11_02_30_29] Iteration #39 | Epoch Duration: 155.89102697372437
2020-01-11 04:13:22.605512 UTC | [2020_01_11_02_30_29] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013221937
Z variance train             0.00050240464
KL Divergence                16.8769
KL Loss                      1.68769
QF Loss                      528.3109
VF Loss                      177.54686
Policy Loss                  -809.6535
Q Predictions Mean           796.4258
Q Predictions Std            281.06656
Q Predictions Max            1144.1166
Q Predictions Min            11.225025
V Predictions Mean           808.1398
V Predictions Std            275.61398
V Predictions Max            1142.0146
V Predictions Min            6.0167913
Log Pis Mean                 0.65712565
Log Pis Std                  2.681214
Log Pis Max                  10.50737
Log Pis Min                  -6.9934416
Policy mu Mean               -0.101747416
Policy mu Std                1.0749937
Policy mu Max                2.9970996
Policy mu Min                -3.260544
Policy log std Mean          -0.59605247
Policy log std Std           0.32823393
Policy log std Max           0.3952567
Policy log std Min           -2.7205265
Z mean eval                  0.012127076
Z variance eval              0.00045725534
total_rewards                [568.14657967 541.19084417 542.52409573 562.64991288 505.68660515
 501.40522779 548.25262337 543.18367737 497.65574952 558.71844811]
total_rewards_mean           536.9413763758786
total_rewards_std            24.714588477878113
total_rewards_max            568.1465796746753
total_rewards_min            497.65574951808753
Number of train steps total  164000
Number of env steps total    126859
Number of rollouts total     0
Train Time (s)               139.54626217577606
(Previous) Eval Time (s)     5.872457334306091
Sample Time (s)              10.585916033014655
Epoch Time (s)               156.0046355430968
Total Train Time (s)         6329.426850519143
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:15:58.692126 UTC | [2020_01_11_02_30_29] Iteration #40 | Epoch Duration: 156.08647966384888
2020-01-11 04:15:58.692348 UTC | [2020_01_11_02_30_29] Iteration #40 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011844147
Z variance train             0.0004571913
KL Divergence                17.017279
KL Loss                      1.7017279
QF Loss                      1476.1196
VF Loss                      227.49681
Policy Loss                  -854.2814
Q Predictions Mean           848.74426
Q Predictions Std            232.50772
Q Predictions Max            1119.775
Q Predictions Min            12.727946
V Predictions Mean           860.6052
V Predictions Std            224.27841
V Predictions Max            1138.7179
V Predictions Min            27.765196
Log Pis Mean                 0.65756774
Log Pis Std                  2.567642
Log Pis Max                  15.667475
Log Pis Min                  -5.8420753
Policy mu Mean               0.14033382
Policy mu Std                1.0831867
Policy mu Max                3.4996502
Policy mu Min                -2.7087836
Policy log std Mean          -0.6033654
Policy log std Std           0.31003118
Policy log std Max           0.09605932
Policy log std Min           -2.7318091
Z mean eval                  0.013758384
Z variance eval              0.0005117362
total_rewards                [599.92251266 972.28783672 577.22836553 775.04553376 567.05494873
 725.38715339 573.36986646 698.10615831 720.81673958 575.42147427]
total_rewards_mean           678.4640589400585
total_rewards_std            122.69218621527074
total_rewards_max            972.2878367182346
total_rewards_min            567.0549487262218
Number of train steps total  168000
Number of env steps total    130878
Number of rollouts total     0
Train Time (s)               138.53639970067888
(Previous) Eval Time (s)     6.6494891489855945
Sample Time (s)              11.209041913039982
Epoch Time (s)               156.39493076270446
Total Train Time (s)         6485.906505681574
Epoch                        41
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:18:35.174105 UTC | [2020_01_11_02_30_29] Iteration #41 | Epoch Duration: 156.48157358169556
2020-01-11 04:18:35.174354 UTC | [2020_01_11_02_30_29] Iteration #41 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01400996
Z variance train             0.00051148323
KL Divergence                16.713566
KL Loss                      1.6713566
QF Loss                      6361.8936
VF Loss                      430.14645
Policy Loss                  -870.46643
Q Predictions Mean           852.7612
Q Predictions Std            228.9732
Q Predictions Max            1085.8978
Q Predictions Min            -24.906076
V Predictions Mean           860.74756
V Predictions Std            208.62036
V Predictions Max            1077.8784
V Predictions Min            -34.98251
Log Pis Mean                 0.71152425
Log Pis Std                  2.510125
Log Pis Max                  11.603603
Log Pis Min                  -6.515665
Policy mu Mean               0.15464361
Policy mu Std                1.1089727
Policy mu Max                3.4102035
Policy mu Min                -2.5978103
Policy log std Mean          -0.55798
Policy log std Std           0.30358952
Policy log std Max           0.24772066
Policy log std Min           -3.3774962
Z mean eval                  0.0070328796
Z variance eval              0.00064478954
total_rewards                [703.5559107  646.06711482 386.49946513 883.31414262 567.98733393
 512.28598398 560.4447666  755.83580234 462.58958244 560.11879906]
total_rewards_mean           603.869890160753
total_rewards_std            139.13509019133434
total_rewards_max            883.3141426165035
total_rewards_min            386.4994651328646
Number of train steps total  172000
Number of env steps total    134736
Number of rollouts total     0
Train Time (s)               138.17852047411725
(Previous) Eval Time (s)     6.608219224028289
Sample Time (s)              11.454540577717125
Epoch Time (s)               156.24128027586266
Total Train Time (s)         6642.228872723877
Epoch                        42
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:21:11.498183 UTC | [2020_01_11_02_30_29] Iteration #42 | Epoch Duration: 156.3235855102539
2020-01-11 04:21:11.498546 UTC | [2020_01_11_02_30_29] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0070961826
Z variance train             0.00064517383
KL Divergence                15.932711
KL Loss                      1.5932711
QF Loss                      555.96375
VF Loss                      304.74313
Policy Loss                  -833.5619
Q Predictions Mean           822.0398
Q Predictions Std            285.27216
Q Predictions Max            1110.707
Q Predictions Min            -44.40766
V Predictions Mean           833.36035
V Predictions Std            269.31
V Predictions Max            1098.1282
V Predictions Min            -49.275238
Log Pis Mean                 0.74401855
Log Pis Std                  2.663679
Log Pis Max                  11.804773
Log Pis Min                  -5.77923
Policy mu Mean               0.14207351
Policy mu Std                1.1142603
Policy mu Max                3.3558774
Policy mu Min                -2.780973
Policy log std Mean          -0.590535
Policy log std Std           0.2816906
Policy log std Max           0.27336127
Policy log std Min           -3.071605
Z mean eval                  0.0076819942
Z variance eval              0.00077429466
total_rewards                [574.72238172 477.14390421 229.04837449 426.0679965  791.81591679
 783.40334321 619.03227564 200.28031683 394.03707961 926.49521574]
total_rewards_mean           542.2046804736241
total_rewards_std            230.16843274547625
total_rewards_max            926.4952157439961
total_rewards_min            200.28031682524028
Number of train steps total  176000
Number of env steps total    139015
Number of rollouts total     0
Train Time (s)               138.30930287204683
(Previous) Eval Time (s)     6.008469883352518
Sample Time (s)              12.093208301346749
Epoch Time (s)               156.4109810567461
Total Train Time (s)         6798.7213494908065
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:23:47.991380 UTC | [2020_01_11_02_30_29] Iteration #43 | Epoch Duration: 156.4926474094391
2020-01-11 04:23:47.991596 UTC | [2020_01_11_02_30_29] Iteration #43 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00771752
Z variance train             0.0007733417
KL Divergence                15.650864
KL Loss                      1.5650864
QF Loss                      391.26035
VF Loss                      2372.9065
Policy Loss                  -847.774
Q Predictions Mean           837.1545
Q Predictions Std            267.88562
Q Predictions Max            1160.7091
Q Predictions Min            -27.896461
V Predictions Mean           845.0764
V Predictions Std            249.63977
V Predictions Max            1152.7797
V Predictions Min            -26.85383
Log Pis Mean                 0.74658763
Log Pis Std                  2.469824
Log Pis Max                  10.126218
Log Pis Min                  -5.0950775
Policy mu Mean               0.08826041
Policy mu Std                1.1099505
Policy mu Max                3.460964
Policy mu Min                -2.9490798
Policy log std Mean          -0.59695727
Policy log std Std           0.30960223
Policy log std Max           0.17456788
Policy log std Min           -3.087162
Z mean eval                  0.014615093
Z variance eval              0.0010417722
total_rewards                [273.64921517 847.34851337 672.94499906 771.74744332 622.08751309
 549.20939569 827.73939321 743.93235282 865.96824672 606.15740697]
total_rewards_mean           678.0784479407777
total_rewards_std            169.69624560527646
total_rewards_max            865.968246717926
total_rewards_min            273.6492151674239
Number of train steps total  180000
Number of env steps total    142732
Number of rollouts total     0
Train Time (s)               145.07887452514842
(Previous) Eval Time (s)     6.721716734115034
Sample Time (s)              10.852832186967134
Epoch Time (s)               162.6534234462306
Total Train Time (s)         6961.477595825214
Epoch                        44
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:26:30.748677 UTC | [2020_01_11_02_30_29] Iteration #44 | Epoch Duration: 162.75684785842896
2020-01-11 04:26:30.748960 UTC | [2020_01_11_02_30_29] Iteration #44 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014081759
Z variance train             0.0010427951
KL Divergence                15.0371685
KL Loss                      1.5037168
QF Loss                      2474.7935
VF Loss                      949.855
Policy Loss                  -886.9795
Q Predictions Mean           879.9302
Q Predictions Std            233.20924
Q Predictions Max            1194.4874
Q Predictions Min            1.642827
V Predictions Mean           896.9103
V Predictions Std            226.43877
V Predictions Max            1178.0592
V Predictions Min            3.1069214
Log Pis Mean                 0.77971095
Log Pis Std                  2.4122407
Log Pis Max                  12.106567
Log Pis Min                  -5.179507
Policy mu Mean               0.15462677
Policy mu Std                1.061809
Policy mu Max                2.9201424
Policy mu Min                -3.1894126
Policy log std Mean          -0.6256473
Policy log std Std           0.29349542
Policy log std Max           0.287592
Policy log std Min           -2.5486836
Z mean eval                  0.010905582
Z variance eval              0.0008430139
total_rewards                [605.56675654 681.57219989 586.73168442 680.375676   853.17185486
 582.29887494 605.55523423 615.4055157  618.07104041 614.86508529]
total_rewards_mean           644.3613922282645
total_rewards_std            76.72484642090726
total_rewards_max            853.1718548587526
total_rewards_min            582.2988749398052
Number of train steps total  184000
Number of env steps total    146305
Number of rollouts total     0
Train Time (s)               147.72502272762358
(Previous) Eval Time (s)     6.357787608169019
Sample Time (s)              11.186185003258288
Epoch Time (s)               165.2689953390509
Total Train Time (s)         7126.993626198266
Epoch                        45
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:29:16.266346 UTC | [2020_01_11_02_30_29] Iteration #45 | Epoch Duration: 165.51721858978271
2020-01-11 04:29:16.266550 UTC | [2020_01_11_02_30_29] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01125509
Z variance train             0.00084272353
KL Divergence                15.307177
KL Loss                      1.5307177
QF Loss                      921.7018
VF Loss                      130.67471
Policy Loss                  -904.2544
Q Predictions Mean           895.3026
Q Predictions Std            229.48708
Q Predictions Max            1213.4691
Q Predictions Min            10.544163
V Predictions Mean           900.8296
V Predictions Std            220.60797
V Predictions Max            1192.3542
V Predictions Min            119.629456
Log Pis Mean                 0.7822172
Log Pis Std                  2.3618565
Log Pis Max                  12.729123
Log Pis Min                  -5.3441377
Policy mu Mean               0.15367036
Policy mu Std                1.0741162
Policy mu Max                3.6829605
Policy mu Min                -3.1522493
Policy log std Mean          -0.6318136
Policy log std Std           0.3196342
Policy log std Max           0.43415308
Policy log std Min           -2.6869102
Z mean eval                  0.008647338
Z variance eval              0.00070467574
total_rewards                [ 231.08411044  811.73696104  236.53883313  735.00498662  712.16198832
  864.27569569  232.816221   1091.34916889  712.70555844  835.04417031]
total_rewards_mean           646.2717693894303
total_rewards_std            289.21778424611745
total_rewards_max            1091.3491688944573
total_rewards_min            231.08411044138947
Number of train steps total  188000
Number of env steps total    150492
Number of rollouts total     0
Train Time (s)               147.07895697839558
(Previous) Eval Time (s)     6.586352291982621
Sample Time (s)              13.186006043106318
Epoch Time (s)               166.85131531348452
Total Train Time (s)         7293.93561704969
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:32:03.210303 UTC | [2020_01_11_02_30_29] Iteration #46 | Epoch Duration: 166.94358801841736
2020-01-11 04:32:03.210598 UTC | [2020_01_11_02_30_29] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008740543
Z variance train             0.00070428767
KL Divergence                15.792393
KL Loss                      1.5792392
QF Loss                      513.25946
VF Loss                      386.2409
Policy Loss                  -877.272
Q Predictions Mean           866.70447
Q Predictions Std            279.70776
Q Predictions Max            1233.4778
Q Predictions Min            -42.528908
V Predictions Mean           877.2594
V Predictions Std            271.6481
V Predictions Max            1194.9878
V Predictions Min            -42.7548
Log Pis Mean                 0.86749506
Log Pis Std                  2.3552897
Log Pis Max                  9.506899
Log Pis Min                  -5.421359
Policy mu Mean               0.1690828
Policy mu Std                1.0750355
Policy mu Max                3.4108558
Policy mu Min                -2.6868262
Policy log std Mean          -0.647152
Policy log std Std           0.2746412
Policy log std Max           0.13384205
Policy log std Min           -2.5685372
Z mean eval                  0.013159616
Z variance eval              0.0007843798
total_rewards                [1138.29136974  773.58213549  718.28370006  664.84063354  797.60842429
  685.53460802  617.22664687  816.65107089  670.4262489   621.3943709 ]
total_rewards_mean           750.3839208686587
total_rewards_std            145.24040051949993
total_rewards_max            1138.291369736948
total_rewards_min            617.2266468707064
Number of train steps total  192000
Number of env steps total    153968
Number of rollouts total     0
Train Time (s)               145.72149353893474
(Previous) Eval Time (s)     7.2984210518188775
Sample Time (s)              10.121746274176985
Epoch Time (s)               163.1416608649306
Total Train Time (s)         7457.164550461341
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:34:46.444004 UTC | [2020_01_11_02_30_29] Iteration #47 | Epoch Duration: 163.23321104049683
2020-01-11 04:34:46.444258 UTC | [2020_01_11_02_30_29] Iteration #47 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013580549
Z variance train             0.000784471
KL Divergence                15.669644
KL Loss                      1.5669645
QF Loss                      696.7454
VF Loss                      453.01056
Policy Loss                  -870.4412
Q Predictions Mean           863.9374
Q Predictions Std            292.1891
Q Predictions Max            1188.986
Q Predictions Min            -28.963566
V Predictions Mean           867.26886
V Predictions Std            287.84723
V Predictions Max            1168.5654
V Predictions Min            -28.292854
Log Pis Mean                 0.934977
Log Pis Std                  2.425083
Log Pis Max                  14.492033
Log Pis Min                  -6.0918374
Policy mu Mean               0.105029605
Policy mu Std                1.0991673
Policy mu Max                4.302842
Policy mu Min                -2.7560868
Policy log std Mean          -0.62770444
Policy log std Std           0.24367937
Policy log std Max           0.15548307
Policy log std Min           -1.6269257
Z mean eval                  0.010646222
Z variance eval              0.00071912195
total_rewards                [859.29708937 709.00261586 752.05927589 709.11334624 822.55175917
 707.90099433 865.41432355 755.42953813 717.45817821 638.08618726]
total_rewards_mean           753.6313308011902
total_rewards_std            70.10023847375055
total_rewards_max            865.4143235533912
total_rewards_min            638.0861872557349
Number of train steps total  196000
Number of env steps total    157897
Number of rollouts total     0
Train Time (s)               145.18256133329123
(Previous) Eval Time (s)     7.417731390334666
Sample Time (s)              13.068927698768675
Epoch Time (s)               165.66922042239457
Total Train Time (s)         7623.027401491534
Epoch                        48
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:37:32.305339 UTC | [2020_01_11_02_30_29] Iteration #48 | Epoch Duration: 165.8609004020691
2020-01-11 04:37:32.305549 UTC | [2020_01_11_02_30_29] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011017522
Z variance train             0.00071931386
KL Divergence                15.7261505
KL Loss                      1.572615
QF Loss                      382.83636
VF Loss                      212.82239
Policy Loss                  -863.1194
Q Predictions Mean           859.6792
Q Predictions Std            293.4171
Q Predictions Max            1154.9893
Q Predictions Min            -64.92987
V Predictions Mean           856.84045
V Predictions Std            294.88574
V Predictions Max            1137.3369
V Predictions Min            -152.14595
Log Pis Mean                 0.9172466
Log Pis Std                  2.4193044
Log Pis Max                  11.790569
Log Pis Min                  -4.8536887
Policy mu Mean               0.12532802
Policy mu Std                1.1343378
Policy mu Max                2.9322383
Policy mu Min                -4.4112396
Policy log std Mean          -0.6261911
Policy log std Std           0.24656498
Policy log std Max           0.13997608
Policy log std Min           -1.9371104
Z mean eval                  0.012868379
Z variance eval              0.0007326822
total_rewards                [216.59246946 623.74379917 207.34554581 244.58774355 244.48594432
 634.46572114 244.80297284 635.77345105 639.47508019 648.52338877]
total_rewards_mean           433.9796116305914
total_rewards_std            202.82218818450917
total_rewards_max            648.5233887737988
total_rewards_min            207.3455458102642
Number of train steps total  200000
Number of env steps total    161247
Number of rollouts total     0
Train Time (s)               142.4676596140489
(Previous) Eval Time (s)     4.213915986008942
Sample Time (s)              10.062335197813809
Epoch Time (s)               156.74391079787165
Total Train Time (s)         7779.851136570796
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:40:09.130215 UTC | [2020_01_11_02_30_29] Iteration #49 | Epoch Duration: 156.82451367378235
2020-01-11 04:40:09.130403 UTC | [2020_01_11_02_30_29] Iteration #49 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01322076
Z variance train             0.0007324795
KL Divergence                15.785167
KL Loss                      1.5785167
QF Loss                      1894.3613
VF Loss                      297.52957
Policy Loss                  -914.08844
Q Predictions Mean           901.9203
Q Predictions Std            246.84314
Q Predictions Max            1212.7395
Q Predictions Min            12.629384
V Predictions Mean           915.3398
V Predictions Std            237.22047
V Predictions Max            1195.9476
V Predictions Min            -20.682686
Log Pis Mean                 0.78350204
Log Pis Std                  2.4230006
Log Pis Max                  10.4566965
Log Pis Min                  -5.9424086
Policy mu Mean               0.20946865
Policy mu Std                1.062106
Policy mu Max                3.157429
Policy mu Min                -2.8611405
Policy log std Mean          -0.60203826
Policy log std Std           0.3204284
Policy log std Max           0.14600801
Policy log std Min           -3.930078
Z mean eval                  0.012643928
Z variance eval              0.0007844314
total_rewards                [270.02630956 277.80725657 281.52582791 269.71442451 585.31365488
 269.66331126 255.83132235 270.84690283 260.05784911 268.96570235]
total_rewards_mean           300.9752561326826
total_rewards_std            95.03863130556863
total_rewards_max            585.3136548797148
total_rewards_min            255.83132235384141
Number of train steps total  204000
Number of env steps total    164979
Number of rollouts total     0
Train Time (s)               138.49044170137495
(Previous) Eval Time (s)     3.717059591319412
Sample Time (s)              10.371318000368774
Epoch Time (s)               152.57881929306313
Total Train Time (s)         7932.517190427054
Epoch                        50
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:42:41.797683 UTC | [2020_01_11_02_30_29] Iteration #50 | Epoch Duration: 152.6671359539032
2020-01-11 04:42:41.797853 UTC | [2020_01_11_02_30_29] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012992251
Z variance train             0.00078469
KL Divergence                15.4552765
KL Loss                      1.5455277
QF Loss                      605.20264
VF Loss                      194.11592
Policy Loss                  -901.2768
Q Predictions Mean           892.9541
Q Predictions Std            270.46976
Q Predictions Max            1197.123
Q Predictions Min            -24.45933
V Predictions Mean           903.81836
V Predictions Std            260.4274
V Predictions Max            1189.7477
V Predictions Min            -4.3160834
Log Pis Mean                 0.590436
Log Pis Std                  2.0351057
Log Pis Max                  7.1780596
Log Pis Min                  -6.433021
Policy mu Mean               0.18132056
Policy mu Std                1.0273234
Policy mu Max                2.8647888
Policy mu Min                -2.4400132
Policy log std Mean          -0.62883455
Policy log std Std           0.2651141
Policy log std Max           0.016689241
Policy log std Min           -2.8774564
Z mean eval                  0.0070800604
Z variance eval              0.0007158292
total_rewards                [ 792.93584532  869.35099053   58.8372909   908.98158537 1002.52849477
  686.74651609  640.69053496  925.65684674  679.507042   1071.24870949]
total_rewards_mean           763.6483856175515
total_rewards_std            271.28433749715356
total_rewards_max            1071.2487094896765
total_rewards_min            58.837290903734164
Number of train steps total  208000
Number of env steps total    168557
Number of rollouts total     0
Train Time (s)               138.61725886072963
(Previous) Eval Time (s)     7.769066918641329
Sample Time (s)              9.348426347598433
Epoch Time (s)               155.7347521269694
Total Train Time (s)         8088.632149715442
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:45:17.915598 UTC | [2020_01_11_02_30_29] Iteration #51 | Epoch Duration: 156.11757636070251
2020-01-11 04:45:17.915809 UTC | [2020_01_11_02_30_29] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.006783257
Z variance train             0.00071529555
KL Divergence                15.672457
KL Loss                      1.5672457
QF Loss                      465.59918
VF Loss                      226.20366
Policy Loss                  -888.52045
Q Predictions Mean           875.6498
Q Predictions Std            294.01535
Q Predictions Max            1199.3345
Q Predictions Min            -25.582623
V Predictions Mean           896.3828
V Predictions Std            286.34845
V Predictions Max            1207.7137
V Predictions Min            -0.89897925
Log Pis Mean                 0.8939282
Log Pis Std                  2.2847216
Log Pis Max                  8.960467
Log Pis Min                  -7.226452
Policy mu Mean               0.107013084
Policy mu Std                1.1155258
Policy mu Max                3.5666478
Policy mu Min                -2.915791
Policy log std Mean          -0.586737
Policy log std Std           0.29647428
Policy log std Max           0.17775464
Policy log std Min           -2.3604145
Z mean eval                  0.006627
Z variance eval              0.00072028587
total_rewards                [ 890.62300354  710.33979654 1837.64300479 1960.10233373  771.45544612
  722.80611948  938.76877769  779.44324049  757.50347256  692.11265639]
total_rewards_mean           1006.0797851331638
total_rewards_std            453.21096711169764
total_rewards_max            1960.1023337349238
total_rewards_min            692.1126563859784
Number of train steps total  212000
Number of env steps total    171956
Number of rollouts total     0
Train Time (s)               138.45876025315374
(Previous) Eval Time (s)     9.939713572151959
Sample Time (s)              9.981942567974329
Epoch Time (s)               158.38041639328003
Total Train Time (s)         8247.099975297693
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:47:56.384451 UTC | [2020_01_11_02_30_29] Iteration #52 | Epoch Duration: 158.46846628189087
2020-01-11 04:47:56.384721 UTC | [2020_01_11_02_30_29] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.006811551
Z variance train             0.00072033977
KL Divergence                15.687322
KL Loss                      1.5687321
QF Loss                      494.15067
VF Loss                      181.53098
Policy Loss                  -912.61597
Q Predictions Mean           905.05286
Q Predictions Std            260.6655
Q Predictions Max            1238.7272
Q Predictions Min            29.384422
V Predictions Mean           912.0127
V Predictions Std            249.81245
V Predictions Max            1225.5511
V Predictions Min            46.06262
Log Pis Mean                 0.85647935
Log Pis Std                  2.5588803
Log Pis Max                  16.532352
Log Pis Min                  -5.749599
Policy mu Mean               0.15216288
Policy mu Std                1.1069247
Policy mu Max                4.353659
Policy mu Min                -3.0318794
Policy log std Mean          -0.6108758
Policy log std Std           0.2754333
Policy log std Max           0.10847312
Policy log std Min           -2.455072
Z mean eval                  0.008149639
Z variance eval              0.0007184516
total_rewards                [ 533.0295056   795.60989412 1173.46110848 1688.28323282  692.68476832
  498.96011862  243.92166598  914.94542861  625.13673608  930.098733  ]
total_rewards_mean           809.6131191632887
total_rewards_std            383.5320943808125
total_rewards_max            1688.2832328178038
total_rewards_min            243.92166598430512
Number of train steps total  216000
Number of env steps total    175325
Number of rollouts total     0
Train Time (s)               139.64966601412743
(Previous) Eval Time (s)     8.547006423119456
Sample Time (s)              9.393975423183292
Epoch Time (s)               157.59064786043018
Total Train Time (s)         8404.769584559835
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:50:34.055529 UTC | [2020_01_11_02_30_29] Iteration #53 | Epoch Duration: 157.6706347465515
2020-01-11 04:50:34.055729 UTC | [2020_01_11_02_30_29] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0078650145
Z variance train             0.0007183408
KL Divergence                15.68861
KL Loss                      1.568861
QF Loss                      1849.9388
VF Loss                      276.58386
Policy Loss                  -914.48474
Q Predictions Mean           895.7997
Q Predictions Std            296.71658
Q Predictions Max            1305.0441
Q Predictions Min            -5.794385
V Predictions Mean           908.68616
V Predictions Std            272.67075
V Predictions Max            1293.0334
V Predictions Min            2.0158284
Log Pis Mean                 1.0254972
Log Pis Std                  2.4558237
Log Pis Max                  10.311296
Log Pis Min                  -4.4189196
Policy mu Mean               0.2298005
Policy mu Std                1.14541
Policy mu Max                3.868618
Policy mu Min                -2.8902369
Policy log std Mean          -0.61820793
Policy log std Std           0.30556196
Policy log std Max           0.25851822
Policy log std Min           -3.7961276
Z mean eval                  0.011277271
Z variance eval              0.00055214635
total_rewards                [ 551.93149165  707.52240353  764.76144869  845.60458756  637.92566857
  675.98091926  762.67340448  934.55666623  672.94893987 1719.72451298]
total_rewards_mean           827.3630042800254
total_rewards_std            314.5007199778725
total_rewards_max            1719.7245129753785
total_rewards_min            551.9314916482741
Number of train steps total  220000
Number of env steps total    178806
Number of rollouts total     0
Train Time (s)               137.81418229267
(Previous) Eval Time (s)     8.398325894027948
Sample Time (s)              8.686401852872223
Epoch Time (s)               154.89891003957018
Total Train Time (s)         8559.747424689122
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:53:09.034446 UTC | [2020_01_11_02_30_29] Iteration #54 | Epoch Duration: 154.9785714149475
2020-01-11 04:53:09.034610 UTC | [2020_01_11_02_30_29] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011516701
Z variance train             0.00055208855
KL Divergence                16.37126
KL Loss                      1.637126
QF Loss                      324.88287
VF Loss                      135.54318
Policy Loss                  -860.9929
Q Predictions Mean           855.1251
Q Predictions Std            315.9166
Q Predictions Max            1296.8773
Q Predictions Min            -37.701427
V Predictions Mean           865.5649
V Predictions Std            312.81592
V Predictions Max            1303.8938
V Predictions Min            -35.290993
Log Pis Mean                 0.5774403
Log Pis Std                  2.2510593
Log Pis Max                  8.386188
Log Pis Min                  -5.205064
Policy mu Mean               0.06863415
Policy mu Std                1.0460246
Policy mu Max                2.816774
Policy mu Min                -2.7625551
Policy log std Mean          -0.5774083
Policy log std Std           0.26867455
Policy log std Max           0.18233305
Policy log std Min           -2.2895954
Z mean eval                  0.006685128
Z variance eval              0.000720785
total_rewards                [602.66574706 617.2730043  810.67018524 686.72972947 770.18970434
 565.38409069 656.06305875 682.33122516 643.28940305 662.2027101 ]
total_rewards_mean           669.679885815434
total_rewards_std            70.34487495832475
total_rewards_max            810.6701852407406
total_rewards_min            565.3840906878736
Number of train steps total  224000
Number of env steps total    182356
Number of rollouts total     0
Train Time (s)               139.7358672437258
(Previous) Eval Time (s)     6.328356234822422
Sample Time (s)              10.55118182208389
Epoch Time (s)               156.61540530063212
Total Train Time (s)         8716.440589504316
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:55:45.729438 UTC | [2020_01_11_02_30_29] Iteration #55 | Epoch Duration: 156.69468760490417
2020-01-11 04:55:45.729631 UTC | [2020_01_11_02_30_29] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00651929
Z variance train             0.0007208864
KL Divergence                15.629989
KL Loss                      1.5629989
QF Loss                      1908.9829
VF Loss                      640.67633
Policy Loss                  -944.0283
Q Predictions Mean           934.76733
Q Predictions Std            280.44745
Q Predictions Max            1393.6095
Q Predictions Min            10.818992
V Predictions Mean           939.0119
V Predictions Std            267.54294
V Predictions Max            1367.0792
V Predictions Min            15.725019
Log Pis Mean                 0.9500397
Log Pis Std                  2.4202955
Log Pis Max                  11.744942
Log Pis Min                  -7.02398
Policy mu Mean               0.2842008
Policy mu Std                1.094666
Policy mu Max                4.335913
Policy mu Min                -2.9153204
Policy log std Mean          -0.6307799
Policy log std Std           0.29962027
Policy log std Max           0.0012128353
Policy log std Min           -3.8505309
Z mean eval                  0.013387904
Z variance eval              0.00067037146
total_rewards                [665.03166402 629.39224525 682.59969668 760.90217928 838.33042367
 753.83891022 778.89961137 745.62850453 757.36083598 788.46092036]
total_rewards_mean           740.0444991348661
total_rewards_std            59.700175745690885
total_rewards_max            838.3304236664798
total_rewards_min            629.392245245404
Number of train steps total  228000
Number of env steps total    186218
Number of rollouts total     0
Train Time (s)               138.25867208605632
(Previous) Eval Time (s)     6.6348691722378135
Sample Time (s)              12.28462396003306
Epoch Time (s)               157.1781652183272
Total Train Time (s)         8873.70213325182
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:58:22.992147 UTC | [2020_01_11_02_30_29] Iteration #56 | Epoch Duration: 157.26237797737122
2020-01-11 04:58:22.992315 UTC | [2020_01_11_02_30_29] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013283578
Z variance train             0.00067034963
KL Divergence                15.8393135
KL Loss                      1.5839313
QF Loss                      1908.17
VF Loss                      201.63895
Policy Loss                  -956.28516
Q Predictions Mean           940.8385
Q Predictions Std            304.10098
Q Predictions Max            1243.8436
Q Predictions Min            -9.27714
V Predictions Mean           948.92957
V Predictions Std            285.59113
V Predictions Max            1229.5677
V Predictions Min            -15.39353
Log Pis Mean                 0.9026896
Log Pis Std                  2.3528137
Log Pis Max                  8.962559
Log Pis Min                  -3.747745
Policy mu Mean               0.20414688
Policy mu Std                1.1110525
Policy mu Max                3.408797
Policy mu Min                -2.9052308
Policy log std Mean          -0.6295918
Policy log std Std           0.2546631
Policy log std Max           0.10724199
Policy log std Min           -2.4473686
Z mean eval                  0.009001143
Z variance eval              0.00074576825
total_rewards                [ 677.72431487 1331.59182528 1056.58274207  595.50896356  955.09595234
 1026.91105079  849.47420238  868.21652266 1799.90196395 1050.10330734]
total_rewards_mean           1021.1110845249219
total_rewards_std            325.7747004178749
total_rewards_max            1799.9019639522426
total_rewards_min            595.5089635629312
Number of train steps total  232000
Number of env steps total    189577
Number of rollouts total     0
Train Time (s)               138.68498583510518
(Previous) Eval Time (s)     10.331825111061335
Sample Time (s)              10.349080148153007
Epoch Time (s)               159.36589109431952
Total Train Time (s)         9033.150351830758
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:01:02.442025 UTC | [2020_01_11_02_30_29] Iteration #57 | Epoch Duration: 159.4495494365692
2020-01-11 05:01:02.442216 UTC | [2020_01_11_02_30_29] Iteration #57 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00917213
Z variance train             0.00074601703
KL Divergence                15.615274
KL Loss                      1.5615275
QF Loss                      4496.9697
VF Loss                      128.75926
Policy Loss                  -916.7629
Q Predictions Mean           902.19653
Q Predictions Std            328.64078
Q Predictions Max            1301.5869
Q Predictions Min            -16.748169
V Predictions Mean           916.5712
V Predictions Std            321.72156
V Predictions Max            1283.8059
V Predictions Min            -18.914585
Log Pis Mean                 1.1125146
Log Pis Std                  2.3709338
Log Pis Max                  10.663563
Log Pis Min                  -5.1661577
Policy mu Mean               0.17309916
Policy mu Std                1.1382655
Policy mu Max                4.645203
Policy mu Min                -2.8609643
Policy log std Mean          -0.63078785
Policy log std Std           0.26218376
Policy log std Max           0.103675544
Policy log std Min           -2.085342
Z mean eval                  0.008808457
Z variance eval              0.00086377905
total_rewards                [1255.80385434  976.27890158  861.74602886  929.29170776  897.2138764
  687.65965819  796.92084144 1018.65473391  785.78116181  560.01269374]
total_rewards_mean           876.9363458006752
total_rewards_std            181.06757193434356
total_rewards_max            1255.8038543366715
total_rewards_min            560.0126937356704
Number of train steps total  236000
Number of env steps total    192936
Number of rollouts total     0
Train Time (s)               138.83869985817
(Previous) Eval Time (s)     8.58391766808927
Sample Time (s)              10.21391394501552
Epoch Time (s)               157.6365314712748
Total Train Time (s)         9190.870897316374
Epoch                        58
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:03:40.163978 UTC | [2020_01_11_02_30_29] Iteration #58 | Epoch Duration: 157.72162294387817
2020-01-11 05:03:40.164160 UTC | [2020_01_11_02_30_29] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009000434
Z variance train             0.0008639932
KL Divergence                15.373426
KL Loss                      1.5373427
QF Loss                      15257.331
VF Loss                      265.01233
Policy Loss                  -962.9918
Q Predictions Mean           948.5906
Q Predictions Std            314.2864
Q Predictions Max            1335.4667
Q Predictions Min            -49.448914
V Predictions Mean           974.57104
V Predictions Std            299.8662
V Predictions Max            1340.6458
V Predictions Min            -45.060593
Log Pis Mean                 1.1151896
Log Pis Std                  2.6978939
Log Pis Max                  12.606423
Log Pis Min                  -4.4274206
Policy mu Mean               0.20338845
Policy mu Std                1.1369437
Policy mu Max                3.513571
Policy mu Min                -2.9702613
Policy log std Mean          -0.630501
Policy log std Std           0.28975883
Policy log std Max           0.2836038
Policy log std Min           -2.534966
Z mean eval                  0.010839365
Z variance eval              0.0008779701
total_rewards                [ 985.99909352  822.04632379  736.3103796   933.05422429  955.62125702
 1426.27985588 1140.0598396   912.49655814  931.40143709  657.7136611 ]
total_rewards_mean           950.0982630019956
total_rewards_std            203.4204895015599
total_rewards_max            1426.2798558784586
total_rewards_min            657.7136611047986
Number of train steps total  240000
Number of env steps total    196329
Number of rollouts total     0
Train Time (s)               138.43867370672524
(Previous) Eval Time (s)     9.218783469870687
Sample Time (s)              9.721638819668442
Epoch Time (s)               157.37909599626437
Total Train Time (s)         9348.32932718331
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:06:17.624284 UTC | [2020_01_11_02_30_29] Iteration #59 | Epoch Duration: 157.45997524261475
2020-01-11 05:06:17.624496 UTC | [2020_01_11_02_30_29] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010793884
Z variance train             0.00087766844
KL Divergence                15.289541
KL Loss                      1.5289541
QF Loss                      328.10428
VF Loss                      247.45625
Policy Loss                  -967.1243
Q Predictions Mean           960.97327
Q Predictions Std            306.62787
Q Predictions Max            1331.1906
Q Predictions Min            -35.746857
V Predictions Mean           963.30304
V Predictions Std            299.81842
V Predictions Max            1313.7941
V Predictions Min            -41.312065
Log Pis Mean                 0.6685386
Log Pis Std                  2.3756156
Log Pis Max                  9.297034
Log Pis Min                  -4.559843
Policy mu Mean               0.10886397
Policy mu Std                1.0747132
Policy mu Max                2.7645419
Policy mu Min                -2.5292373
Policy log std Mean          -0.64604586
Policy log std Std           0.25910863
Policy log std Max           -0.011512637
Policy log std Min           -2.394396
Z mean eval                  0.0067082373
Z variance eval              0.0007702875
total_rewards                [1123.9498535  1036.35023965  935.91434052 1182.10288736  859.81206408
  836.34928722  870.59437789 1065.40736353  794.22805241  557.29849625]
total_rewards_mean           926.2006962386083
total_rewards_std            174.72115908989622
total_rewards_max            1182.1028873572761
total_rewards_min            557.2984962458287
Number of train steps total  244000
Number of env steps total    199769
Number of rollouts total     0
Train Time (s)               137.87046392215416
(Previous) Eval Time (s)     7.960768025834113
Sample Time (s)              9.397500585764647
Epoch Time (s)               155.22873253375292
Total Train Time (s)         9503.64563816227
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:08:52.941750 UTC | [2020_01_11_02_30_29] Iteration #60 | Epoch Duration: 155.31710696220398
2020-01-11 05:08:52.941933 UTC | [2020_01_11_02_30_29] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.006632358
Z variance train             0.0007702318
KL Divergence                15.513245
KL Loss                      1.5513245
QF Loss                      279.33557
VF Loss                      117.19946
Policy Loss                  -980.1953
Q Predictions Mean           974.5142
Q Predictions Std            297.83417
Q Predictions Max            1323.6307
Q Predictions Min            -4.6073933
V Predictions Mean           977.8037
V Predictions Std            291.5335
V Predictions Max            1324.2842
V Predictions Min            17.115131
Log Pis Mean                 0.7199784
Log Pis Std                  2.4173346
Log Pis Max                  8.37419
Log Pis Min                  -4.485335
Policy mu Mean               0.03657
Policy mu Std                1.0898944
Policy mu Max                3.2547433
Policy mu Min                -2.8222246
Policy log std Mean          -0.6131388
Policy log std Std           0.24087226
Policy log std Max           0.20140797
Policy log std Min           -2.1267786
Z mean eval                  0.0109672835
Z variance eval              0.0007564721
total_rewards                [ 810.55908219  946.59756111  807.28014487 1280.15831957 1613.77495358
  833.99671071 1010.29360236  829.9721533   738.6458705   877.17164005]
total_rewards_mean           974.8450038229436
total_rewards_std            257.82291785264744
total_rewards_max            1613.7749535843718
total_rewards_min            738.6458704965817
Number of train steps total  248000
Number of env steps total    203399
Number of rollouts total     0
Train Time (s)               138.94230598583817
(Previous) Eval Time (s)     8.790077396202832
Sample Time (s)              10.840012005064636
Epoch Time (s)               158.57239538710564
Total Train Time (s)         9662.296501792036
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:11:31.594141 UTC | [2020_01_11_02_30_29] Iteration #61 | Epoch Duration: 158.65206575393677
2020-01-11 05:11:31.594332 UTC | [2020_01_11_02_30_29] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011156706
Z variance train             0.0007565003
KL Divergence                15.577925
KL Loss                      1.5577925
QF Loss                      2573.1829
VF Loss                      77.680244
Policy Loss                  -989.17474
Q Predictions Mean           987.469
Q Predictions Std            268.93903
Q Predictions Max            1328.0873
Q Predictions Min            120.74545
V Predictions Mean           989.4527
V Predictions Std            263.02823
V Predictions Max            1302.4109
V Predictions Min            114.02859
Log Pis Mean                 1.1096253
Log Pis Std                  2.437482
Log Pis Max                  13.782255
Log Pis Min                  -4.5458956
Policy mu Mean               0.26586282
Policy mu Std                1.0934459
Policy mu Max                3.544906
Policy mu Min                -2.828
Policy log std Mean          -0.6344268
Policy log std Std           0.28733233
Policy log std Max           0.31679296
Policy log std Min           -3.320788
Z mean eval                  0.0113703
Z variance eval              0.00091615925
total_rewards                [ 774.54770142  773.17245529  534.52125175 2631.58320624  795.72202618
  663.93645245  766.03200567  536.74332391  663.51259765  791.57730724]
total_rewards_mean           893.1348327786752
total_rewards_std            587.1534567700307
total_rewards_max            2631.5832062380773
total_rewards_min            534.5212517464558
Number of train steps total  252000
Number of env steps total    206833
Number of rollouts total     0
Train Time (s)               139.42330736201257
(Previous) Eval Time (s)     8.911056550685316
Sample Time (s)              10.18361526960507
Epoch Time (s)               158.51797918230295
Total Train Time (s)         9820.901371193118
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:14:10.201702 UTC | [2020_01_11_02_30_29] Iteration #62 | Epoch Duration: 158.60720443725586
2020-01-11 05:14:10.201988 UTC | [2020_01_11_02_30_29] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011601372
Z variance train             0.0009160248
KL Divergence                15.087294
KL Loss                      1.5087293
QF Loss                      297.51767
VF Loss                      262.07037
Policy Loss                  -967.06915
Q Predictions Mean           954.28516
Q Predictions Std            317.06387
Q Predictions Max            1351.3043
Q Predictions Min            -1.2985761
V Predictions Mean           977.44495
V Predictions Std            300.97772
V Predictions Max            1364.4963
V Predictions Min            8.890618
Log Pis Mean                 1.087213
Log Pis Std                  2.3904274
Log Pis Max                  9.87849
Log Pis Min                  -4.873427
Policy mu Mean               0.061735738
Policy mu Std                1.12573
Policy mu Max                3.3268833
Policy mu Min                -2.777995
Policy log std Mean          -0.665186
Policy log std Std           0.27257463
Policy log std Max           0.005049646
Policy log std Min           -2.8778408
Z mean eval                  0.01978576
Z variance eval              0.00087055407
total_rewards                [1188.62852503  884.03139168  777.16127903  903.15926418  683.79455045
  655.69126878  783.87583164  753.63599321  666.59686925 1039.60100112]
total_rewards_mean           833.6175974382852
total_rewards_std            164.28596380087086
total_rewards_max            1188.6285250336641
total_rewards_min            655.6912687834018
Number of train steps total  256000
Number of env steps total    210605
Number of rollouts total     0
Train Time (s)               138.0541413188912
(Previous) Eval Time (s)     8.185116687323898
Sample Time (s)              11.03411720879376
Epoch Time (s)               157.27337521500885
Total Train Time (s)         9978.268613217864
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:16:47.570142 UTC | [2020_01_11_02_30_29] Iteration #63 | Epoch Duration: 157.36797213554382
2020-01-11 05:16:47.570336 UTC | [2020_01_11_02_30_29] Iteration #63 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01985397
Z variance train             0.0008706177
KL Divergence                15.270507
KL Loss                      1.5270507
QF Loss                      875.80994
VF Loss                      1085.1548
Policy Loss                  -985.0052
Q Predictions Mean           976.60345
Q Predictions Std            318.155
Q Predictions Max            1367.3193
Q Predictions Min            18.232216
V Predictions Mean           984.1228
V Predictions Std            305.46643
V Predictions Max            1373.2572
V Predictions Min            -1.6665876
Log Pis Mean                 0.99261963
Log Pis Std                  2.6513984
Log Pis Max                  15.810034
Log Pis Min                  -5.4079685
Policy mu Mean               0.16969806
Policy mu Std                1.1299095
Policy mu Max                3.7524803
Policy mu Min                -3.5013812
Policy log std Mean          -0.62661463
Policy log std Std           0.27352425
Policy log std Max           0.12947506
Policy log std Min           -3.9088712
Z mean eval                  0.016243717
Z variance eval              0.00094206556
total_rewards                [675.12655146 709.41074027 764.8706617  694.60897331 803.37266433
 700.46689665 827.28250114 744.48333964 762.60782158 761.93412307]
total_rewards_mean           744.4164273140539
total_rewards_std            46.7307494989397
total_rewards_max            827.2825011407054
total_rewards_min            675.1265514603132
Number of train steps total  260000
Number of env steps total    214132
Number of rollouts total     0
Train Time (s)               138.9632884338498
(Previous) Eval Time (s)     7.31530555896461
Sample Time (s)              10.38566810078919
Epoch Time (s)               156.6642620936036
Total Train Time (s)         10135.020624291617
Epoch                        64
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:19:24.324957 UTC | [2020_01_11_02_30_29] Iteration #64 | Epoch Duration: 156.7544651031494
2020-01-11 05:19:24.325156 UTC | [2020_01_11_02_30_29] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016167363
Z variance train             0.00094256003
KL Divergence                15.222805
KL Loss                      1.5222806
QF Loss                      266.4328
VF Loss                      78.23451
Policy Loss                  -983.7346
Q Predictions Mean           979.8694
Q Predictions Std            313.0238
Q Predictions Max            1321.087
Q Predictions Min            9.751647
V Predictions Mean           986.5726
V Predictions Std            309.3455
V Predictions Max            1323.1526
V Predictions Min            17.138607
Log Pis Mean                 0.90457994
Log Pis Std                  2.3674333
Log Pis Max                  8.203261
Log Pis Min                  -5.157848
Policy mu Mean               0.13182507
Policy mu Std                1.1188755
Policy mu Max                2.8436494
Policy mu Min                -2.6317925
Policy log std Mean          -0.61325973
Policy log std Std           0.24049468
Policy log std Max           0.06060064
Policy log std Min           -1.7851398
Z mean eval                  0.01563794
Z variance eval              0.0007720788
total_rewards                [ 814.626117    811.35860736  912.21049833  808.10718183  748.17419767
  771.99876649  839.97970323  678.83860001 1850.71679623  770.23305694]
total_rewards_mean           900.6243525085758
total_rewards_std            321.92973791995195
total_rewards_max            1850.7167962273654
total_rewards_min            678.8386000067383
Number of train steps total  264000
Number of env steps total    217539
Number of rollouts total     0
Train Time (s)               146.24026833707467
(Previous) Eval Time (s)     8.678216761443764
Sample Time (s)              8.914894006680697
Epoch Time (s)               163.83337910519913
Total Train Time (s)         10298.936784168705
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:22:08.243388 UTC | [2020_01_11_02_30_29] Iteration #65 | Epoch Duration: 163.91802644729614
2020-01-11 05:22:08.243786 UTC | [2020_01_11_02_30_29] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015288169
Z variance train             0.0007721459
KL Divergence                15.782891
KL Loss                      1.5782892
QF Loss                      563.31537
VF Loss                      292.17648
Policy Loss                  -984.5218
Q Predictions Mean           977.19965
Q Predictions Std            333.43314
Q Predictions Max            1411.372
Q Predictions Min            -18.405855
V Predictions Mean           986.4252
V Predictions Std            325.09003
V Predictions Max            1416.0508
V Predictions Min            -25.97712
Log Pis Mean                 0.963069
Log Pis Std                  2.4611993
Log Pis Max                  10.2111025
Log Pis Min                  -4.445394
Policy mu Mean               0.16408087
Policy mu Std                1.0992938
Policy mu Max                3.9763496
Policy mu Min                -2.715066
Policy log std Mean          -0.64151883
Policy log std Std           0.31442645
Policy log std Max           0.5854165
Policy log std Min           -3.4289503
Z mean eval                  0.012246643
Z variance eval              0.00081490434
total_rewards                [ 777.68545901  955.97987247 1041.39773476  340.89857321 1071.11367987
  846.97781992  738.05046035  811.55558487  789.23511736  810.79016485]
total_rewards_mean           818.3684466651854
total_rewards_std            192.46136697939667
total_rewards_max            1071.1136798671653
total_rewards_min            340.8985732053994
Number of train steps total  268000
Number of env steps total    220976
Number of rollouts total     0
Train Time (s)               146.82659036898986
(Previous) Eval Time (s)     8.191262599546462
Sample Time (s)              9.976482829544693
Epoch Time (s)               164.994335798081
Total Train Time (s)         10464.014817683958
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:24:53.322523 UTC | [2020_01_11_02_30_29] Iteration #66 | Epoch Duration: 165.07844471931458
2020-01-11 05:24:53.322727 UTC | [2020_01_11_02_30_29] Iteration #66 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012175349
Z variance train             0.00081559934
KL Divergence                15.46356
KL Loss                      1.5463561
QF Loss                      348.9848
VF Loss                      149.69762
Policy Loss                  -991.78143
Q Predictions Mean           981.29816
Q Predictions Std            311.43134
Q Predictions Max            1334.9437
Q Predictions Min            -26.26595
V Predictions Mean           990.81824
V Predictions Std            303.20944
V Predictions Max            1355.4719
V Predictions Min            -44.02663
Log Pis Mean                 0.85071456
Log Pis Std                  2.4373896
Log Pis Max                  8.41597
Log Pis Min                  -7.431643
Policy mu Mean               0.14526333
Policy mu Std                1.1255757
Policy mu Max                3.4654503
Policy mu Min                -2.9239166
Policy log std Mean          -0.6486904
Policy log std Std           0.24707673
Policy log std Max           0.12512946
Policy log std Min           -1.7146705
Z mean eval                  0.0072825677
Z variance eval              0.0009250846
total_rewards                [719.4082938  700.44569644 293.96885456 742.415731   716.52056488
 756.801773   706.05372787 760.68008382 746.06795562 808.05795742]
total_rewards_mean           695.0420638390699
total_rewards_std            137.04317709299852
total_rewards_max            808.0579574167954
total_rewards_min            293.9688545580012
Number of train steps total  272000
Number of env steps total    224387
Number of rollouts total     0
Train Time (s)               145.51684794574976
(Previous) Eval Time (s)     6.745173254050314
Sample Time (s)              10.24125080741942
Epoch Time (s)               162.5032720072195
Total Train Time (s)         10626.600116366055
Epoch                        67
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:27:35.909743 UTC | [2020_01_11_02_30_29] Iteration #67 | Epoch Duration: 162.58686685562134
2020-01-11 05:27:35.909926 UTC | [2020_01_11_02_30_29] Iteration #67 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007840876
Z variance train             0.00092587434
KL Divergence                15.014675
KL Loss                      1.5014676
QF Loss                      603.10815
VF Loss                      150.0909
Policy Loss                  -960.2987
Q Predictions Mean           945.3624
Q Predictions Std            352.82367
Q Predictions Max            1410.6237
Q Predictions Min            -6.842727
V Predictions Mean           966.22003
V Predictions Std            343.85178
V Predictions Max            1412.7231
V Predictions Min            -25.432178
Log Pis Mean                 0.9388634
Log Pis Std                  2.5156462
Log Pis Max                  11.261815
Log Pis Min                  -4.678603
Policy mu Mean               0.14986844
Policy mu Std                1.1451474
Policy mu Max                3.8814535
Policy mu Min                -3.1248307
Policy log std Mean          -0.6171687
Policy log std Std           0.28821895
Policy log std Max           0.24742174
Policy log std Min           -3.3633862
Z mean eval                  0.013018275
Z variance eval              0.0012281139
total_rewards                [805.64962185 820.43399419 715.59685613 789.83540777 805.29246533
 762.93634651 838.68248737 986.97419881 691.76167    805.12710341]
total_rewards_mean           802.2290151387978
total_rewards_std            75.64801689970024
total_rewards_max            986.974198806495
total_rewards_min            691.7616700001878
Number of train steps total  276000
Number of env steps total    228044
Number of rollouts total     0
Train Time (s)               147.3682029079646
(Previous) Eval Time (s)     6.159384466242045
Sample Time (s)              10.68659271672368
Epoch Time (s)               164.2141800909303
Total Train Time (s)         10790.901647167746
Epoch                        68
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:30:20.213445 UTC | [2020_01_11_02_30_29] Iteration #68 | Epoch Duration: 164.3033263683319
2020-01-11 05:30:20.214105 UTC | [2020_01_11_02_30_29] Iteration #68 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013234827
Z variance train             0.0012269892
KL Divergence                14.389814
KL Loss                      1.4389814
QF Loss                      683.1231
VF Loss                      142.25659
Policy Loss                  -1005.4452
Q Predictions Mean           982.8102
Q Predictions Std            328.82236
Q Predictions Max            1365.1655
Q Predictions Min            -29.395163
V Predictions Mean           1005.3895
V Predictions Std            300.92178
V Predictions Max            1349.5573
V Predictions Min            6.143924
Log Pis Mean                 0.7951951
Log Pis Std                  2.7089558
Log Pis Max                  11.119886
Log Pis Min                  -5.661471
Policy mu Mean               0.21214662
Policy mu Std                1.0958133
Policy mu Max                3.8132117
Policy mu Min                -3.8905022
Policy log std Mean          -0.59191805
Policy log std Std           0.2936979
Policy log std Max           0.5016706
Policy log std Min           -3.4100552
Z mean eval                  0.011766339
Z variance eval              0.0012751482
total_rewards                [670.7411589  672.83986368 617.23780252 580.0540779  653.77175816
 832.43479135 663.46685433 710.07636497 916.80953911 658.06752313]
total_rewards_mean           697.5499734049835
total_rewards_std            96.25345140612987
total_rewards_max            916.8095391063695
total_rewards_min            580.0540779012462
Number of train steps total  280000
Number of env steps total    231462
Number of rollouts total     0
Train Time (s)               147.71943330718204
(Previous) Eval Time (s)     6.741791108623147
Sample Time (s)              10.514038979075849
Epoch Time (s)               164.97526339488104
Total Train Time (s)         10955.990614932962
Epoch                        69
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:33:05.303809 UTC | [2020_01_11_02_30_29] Iteration #69 | Epoch Duration: 165.08925008773804
2020-01-11 05:33:05.304030 UTC | [2020_01_11_02_30_29] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012027165
Z variance train             0.0012751801
KL Divergence                14.23365
KL Loss                      1.423365
QF Loss                      2294.0908
VF Loss                      176.09854
Policy Loss                  -1015.7784
Q Predictions Mean           1008.4779
Q Predictions Std            307.08115
Q Predictions Max            1324.0757
Q Predictions Min            26.063513
V Predictions Mean           1016.125
V Predictions Std            299.9906
V Predictions Max            1315.6777
V Predictions Min            29.400192
Log Pis Mean                 1.0397968
Log Pis Std                  2.5767179
Log Pis Max                  12.599012
Log Pis Min                  -4.914974
Policy mu Mean               0.056799848
Policy mu Std                1.1431129
Policy mu Max                3.6974127
Policy mu Min                -2.6813815
Policy log std Mean          -0.62538844
Policy log std Std           0.2527828
Policy log std Max           0.072724044
Policy log std Min           -3.0571728
Z mean eval                  0.0073219
Z variance eval              0.0010824428
total_rewards                [1021.21418924  724.63353044  680.82679453  724.94216119  773.38540365
  875.73950556  655.29141938  777.09397084  991.83957403  666.52555252]
total_rewards_mean           789.1492101394917
total_rewards_std            124.82078237726301
total_rewards_max            1021.2141892413271
total_rewards_min            655.2914193800783
Number of train steps total  284000
Number of env steps total    235606
Number of rollouts total     0
Train Time (s)               141.21280976198614
(Previous) Eval Time (s)     7.367621990852058
Sample Time (s)              13.173634380102158
Epoch Time (s)               161.75406613294035
Total Train Time (s)         11117.831906552427
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:35:47.146544 UTC | [2020_01_11_02_30_29] Iteration #70 | Epoch Duration: 161.84236574172974
2020-01-11 05:35:47.146725 UTC | [2020_01_11_02_30_29] Iteration #70 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0070592463
Z variance train             0.0010816443
KL Divergence                14.6060295
KL Loss                      1.460603
QF Loss                      1869.1726
VF Loss                      100.5209
Policy Loss                  -1042.2761
Q Predictions Mean           1038.8108
Q Predictions Std            291.81757
Q Predictions Max            1409.4641
Q Predictions Min            2.6968164
V Predictions Mean           1041.4703
V Predictions Std            280.84033
V Predictions Max            1396.2347
V Predictions Min            37.821194
Log Pis Mean                 0.7629518
Log Pis Std                  2.2427742
Log Pis Max                  10.148329
Log Pis Min                  -4.446307
Policy mu Mean               0.12090951
Policy mu Std                1.0500219
Policy mu Max                3.3055656
Policy mu Min                -2.7519958
Policy log std Mean          -0.60844046
Policy log std Std           0.294264
Policy log std Max           0.4239971
Policy log std Min           -3.6837323
Z mean eval                  0.0146319
Z variance eval              0.0011362124
total_rewards                [755.26378097 798.63368708 962.86489627 965.02213792 803.80088403
 875.70888063 809.53767209 800.86160748 792.40325885 677.95880348]
total_rewards_mean           824.2055608790272
total_rewards_std            84.07802315411296
total_rewards_max            965.0221379164184
total_rewards_min            677.9588034798446
Number of train steps total  288000
Number of env steps total    239218
Number of rollouts total     0
Train Time (s)               138.2725185258314
(Previous) Eval Time (s)     8.4331299145706
Sample Time (s)              10.503797759767622
Epoch Time (s)               157.20944620016962
Total Train Time (s)         11275.124676279258
Epoch                        71
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:38:24.441249 UTC | [2020_01_11_02_30_29] Iteration #71 | Epoch Duration: 157.29438018798828
2020-01-11 05:38:24.441447 UTC | [2020_01_11_02_30_29] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01472275
Z variance train             0.0011360991
KL Divergence                14.578954
KL Loss                      1.4578954
QF Loss                      2804.9019
VF Loss                      272.27936
Policy Loss                  -1019.38275
Q Predictions Mean           1020.15625
Q Predictions Std            311.55408
Q Predictions Max            1381.7216
Q Predictions Min            14.80366
V Predictions Mean           1028.7871
V Predictions Std            303.15637
V Predictions Max            1375.26
V Predictions Min            18.890942
Log Pis Mean                 0.459548
Log Pis Std                  2.5088856
Log Pis Max                  11.558502
Log Pis Min                  -8.703865
Policy mu Mean               0.07451078
Policy mu Std                1.0669143
Policy mu Max                4.004367
Policy mu Min                -2.4596047
Policy log std Mean          -0.616563
Policy log std Std           0.30663657
Policy log std Max           0.19253534
Policy log std Min           -3.7454357
Z mean eval                  0.0032027967
Z variance eval              0.0010139615
total_rewards                [ 673.52226226  804.63175932  657.66955752 1223.53688173 1032.97805865
  654.93186618  669.03969551  666.47534262 1556.57695167  940.07566682]
total_rewards_mean           887.9438042276664
total_rewards_std            289.939862788428
total_rewards_max            1556.576951670036
total_rewards_min            654.9318661805358
Number of train steps total  292000
Number of env steps total    242634
Number of rollouts total     0
Train Time (s)               138.93498908821493
(Previous) Eval Time (s)     8.143375028856099
Sample Time (s)              8.181848994456232
Epoch Time (s)               155.26021311152726
Total Train Time (s)         11430.46466735797
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:40:59.782849 UTC | [2020_01_11_02_30_29] Iteration #72 | Epoch Duration: 155.3412585258484
2020-01-11 05:40:59.783035 UTC | [2020_01_11_02_30_29] Iteration #72 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0027814074
Z variance train             0.0010136564
KL Divergence                14.79289
KL Loss                      1.4792889
QF Loss                      580.09186
VF Loss                      145.17906
Policy Loss                  -1004.356
Q Predictions Mean           994.47705
Q Predictions Std            344.5912
Q Predictions Max            1371.3975
Q Predictions Min            -22.995897
V Predictions Mean           1002.1489
V Predictions Std            332.8114
V Predictions Max            1369.9979
V Predictions Min            -4.7647605
Log Pis Mean                 0.93887883
Log Pis Std                  2.5209002
Log Pis Max                  10.394713
Log Pis Min                  -3.6920917
Policy mu Mean               0.19070835
Policy mu Std                1.0912367
Policy mu Max                3.9876704
Policy mu Min                -2.7191439
Policy log std Mean          -0.6139297
Policy log std Std           0.2743572
Policy log std Max           0.16813725
Policy log std Min           -2.8060155
Z mean eval                  0.017972719
Z variance eval              0.0009280377
total_rewards                [646.93355063 805.61560176 822.09414629 656.96213597 657.93941176
 847.11925672 667.42233939 898.15104639 683.2255136  651.82334826]
total_rewards_mean           733.72863507746
total_rewards_std            92.57127877844053
total_rewards_max            898.1510463909023
total_rewards_min            646.933550626321
Number of train steps total  296000
Number of env steps total    246633
Number of rollouts total     0
Train Time (s)               139.53045461699367
(Previous) Eval Time (s)     6.739505564328283
Sample Time (s)              12.843743269797415
Epoch Time (s)               159.11370345111936
Total Train Time (s)         11589.665145345964
Epoch                        73
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:43:38.985385 UTC | [2020_01_11_02_30_29] Iteration #73 | Epoch Duration: 159.20220065116882
2020-01-11 05:43:38.985596 UTC | [2020_01_11_02_30_29] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01799224
Z variance train             0.00092706335
KL Divergence                14.971173
KL Loss                      1.4971174
QF Loss                      483.65546
VF Loss                      132.08786
Policy Loss                  -1012.2032
Q Predictions Mean           1001.5833
Q Predictions Std            336.88712
Q Predictions Max            1390.404
Q Predictions Min            -34.16217
V Predictions Mean           1013.7816
V Predictions Std            325.60474
V Predictions Max            1396.5408
V Predictions Min            -9.329412
Log Pis Mean                 0.71678853
Log Pis Std                  2.2051275
Log Pis Max                  8.1363325
Log Pis Min                  -5.103076
Policy mu Mean               0.11200047
Policy mu Std                1.0668374
Policy mu Max                3.4135723
Policy mu Min                -2.8939984
Policy log std Mean          -0.6369683
Policy log std Std           0.31299117
Policy log std Max           0.18397361
Policy log std Min           -2.9277043
Z mean eval                  0.012855424
Z variance eval              0.0011241373
total_rewards                [1022.9050591   906.47312444 1550.9059847   796.36333475  994.50407251
  816.20351039  799.12389376  863.29395979  982.25340228 1552.88357594]
total_rewards_mean           1028.4909917664404
total_rewards_std            272.940679280017
total_rewards_max            1552.8835759440435
total_rewards_min            796.363334748178
Number of train steps total  300000
Number of env steps total    250427
Number of rollouts total     0
Train Time (s)               138.5862767379731
(Previous) Eval Time (s)     9.923377050086856
Sample Time (s)              10.209533412009478
Epoch Time (s)               158.71918720006943
Total Train Time (s)         11748.467664729338
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:46:17.789320 UTC | [2020_01_11_02_30_29] Iteration #74 | Epoch Duration: 158.80356812477112
2020-01-11 05:46:17.789524 UTC | [2020_01_11_02_30_29] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013105879
Z variance train             0.0011249714
KL Divergence                14.710684
KL Loss                      1.4710684
QF Loss                      294.41418
VF Loss                      219.50156
Policy Loss                  -1020.34186
Q Predictions Mean           1016.9267
Q Predictions Std            332.6264
Q Predictions Max            1407.952
Q Predictions Min            1.454452
V Predictions Mean           1030.2642
V Predictions Std            332.1351
V Predictions Max            1418.2686
V Predictions Min            -13.005003
Log Pis Mean                 0.7267982
Log Pis Std                  2.2122812
Log Pis Max                  8.523773
Log Pis Min                  -6.5397015
Policy mu Mean               0.100325584
Policy mu Std                1.0404128
Policy mu Max                3.0475745
Policy mu Min                -2.7655573
Policy log std Mean          -0.626806
Policy log std Std           0.26077354
Policy log std Max           0.26343936
Policy log std Min           -2.0321903
Z mean eval                  0.0075476347
Z variance eval              0.0010317767
total_rewards                [ 743.79128393  936.72582592  829.65804047 1200.05492112  752.86025713
  760.18222854  651.57795431  637.65734431  798.62459822  575.12985699]
total_rewards_mean           788.6262310934951
total_rewards_std            168.59525766004978
total_rewards_max            1200.0549211172743
total_rewards_min            575.1298569866719
Number of train steps total  304000
Number of env steps total    254054
Number of rollouts total     0
Train Time (s)               138.73751368187368
(Previous) Eval Time (s)     8.153703999239951
Sample Time (s)              10.686748513020575
Epoch Time (s)               157.5779661941342
Total Train Time (s)         11906.184657240286
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:48:55.515316 UTC | [2020_01_11_02_30_29] Iteration #75 | Epoch Duration: 157.7256257534027
2020-01-11 05:48:55.515878 UTC | [2020_01_11_02_30_29] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007944495
Z variance train             0.0010319639
KL Divergence                14.789697
KL Loss                      1.4789697
QF Loss                      1260.8896
VF Loss                      187.01848
Policy Loss                  -1015.9802
Q Predictions Mean           1006.9767
Q Predictions Std            322.1268
Q Predictions Max            1379.4612
Q Predictions Min            -18.106068
V Predictions Mean           1023.78467
V Predictions Std            310.2713
V Predictions Max            1375.9718
V Predictions Min            7.8490934
Log Pis Mean                 0.57230365
Log Pis Std                  2.6095133
Log Pis Max                  12.112181
Log Pis Min                  -5.5245094
Policy mu Mean               0.084679045
Policy mu Std                1.083606
Policy mu Max                3.7419755
Policy mu Min                -2.56564
Policy log std Mean          -0.57759374
Policy log std Std           0.28137738
Policy log std Max           0.18279815
Policy log std Min           -2.1152573
Z mean eval                  0.009367182
Z variance eval              0.0010156682
total_rewards                [ 811.73406544  904.01815449  816.56372439 1744.36290065  785.03075617
  689.23300675 1005.04774417  834.65882342  969.73759305  655.925595  ]
total_rewards_mean           921.6312363526253
total_rewards_std            293.3290020471517
total_rewards_max            1744.3629006452497
total_rewards_min            655.9255950028282
Number of train steps total  308000
Number of env steps total    257467
Number of rollouts total     0
Train Time (s)               137.49370330013335
(Previous) Eval Time (s)     8.230111373122782
Sample Time (s)              8.616896715015173
Epoch Time (s)               154.3407113882713
Total Train Time (s)         12060.615076624323
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:51:29.940181 UTC | [2020_01_11_02_30_29] Iteration #76 | Epoch Duration: 154.42387986183167
2020-01-11 05:51:29.940371 UTC | [2020_01_11_02_30_29] Iteration #76 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009085851
Z variance train             0.0010147818
KL Divergence                15.094413
KL Loss                      1.5094413
QF Loss                      530.5521
VF Loss                      285.3611
Policy Loss                  -1011.33655
Q Predictions Mean           1006.5161
Q Predictions Std            339.689
Q Predictions Max            1404.9448
Q Predictions Min            -38.025173
V Predictions Mean           1009.0917
V Predictions Std            329.96414
V Predictions Max            1403.8684
V Predictions Min            -30.19553
Log Pis Mean                 0.53622866
Log Pis Std                  2.3646648
Log Pis Max                  7.680292
Log Pis Min                  -6.6879826
Policy mu Mean               0.11207051
Policy mu Std                1.0495479
Policy mu Max                2.495058
Policy mu Min                -2.67341
Policy log std Mean          -0.6092667
Policy log std Std           0.28437987
Policy log std Max           0.26235986
Policy log std Min           -2.4593291
Z mean eval                  0.010353101
Z variance eval              0.0008746313
total_rewards                [635.49233193 950.80658872 538.15358982 909.83168591 676.87101647
 639.57216436 218.7393814  944.29513849 643.35208791 719.26151198]
total_rewards_mean           687.6375496991853
total_rewards_std            208.52310231798657
total_rewards_max            950.8065887217426
total_rewards_min            218.7393813992624
Number of train steps total  312000
Number of env steps total    260872
Number of rollouts total     0
Train Time (s)               141.09089576872066
(Previous) Eval Time (s)     6.843845568597317
Sample Time (s)              10.195465215481818
Epoch Time (s)               158.1302065527998
Total Train Time (s)         12218.833298134152
Epoch                        77
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:54:08.161006 UTC | [2020_01_11_02_30_29] Iteration #77 | Epoch Duration: 158.22045826911926
2020-01-11 05:54:08.161300 UTC | [2020_01_11_02_30_29] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010415937
Z variance train             0.0008751138
KL Divergence                15.614288
KL Loss                      1.5614289
QF Loss                      319.1173
VF Loss                      173.48033
Policy Loss                  -1042.459
Q Predictions Mean           1035.5723
Q Predictions Std            308.3646
Q Predictions Max            1408.3217
Q Predictions Min            22.064058
V Predictions Mean           1048.0831
V Predictions Std            304.2668
V Predictions Max            1396.247
V Predictions Min            34.96855
Log Pis Mean                 0.59848726
Log Pis Std                  2.1638227
Log Pis Max                  6.1226797
Log Pis Min                  -5.4082875
Policy mu Mean               0.040022504
Policy mu Std                1.0211437
Policy mu Max                2.952524
Policy mu Min                -2.443318
Policy log std Mean          -0.5886584
Policy log std Std           0.30729717
Policy log std Max           0.2286641
Policy log std Min           -2.72054
Z mean eval                  0.009715231
Z variance eval              0.0008485407
total_rewards                [1019.21486207  805.96411124  660.18915476 2759.41655642 1048.41228672
  759.67134106  925.62572438  808.4306483  1173.27289298  564.32592215]
total_rewards_mean           1052.4523500084592
total_rewards_std            595.2891765447702
total_rewards_max            2759.416556415614
total_rewards_min            564.3259221548631
Number of train steps total  316000
Number of env steps total    264489
Number of rollouts total     0
Train Time (s)               139.14973589684814
(Previous) Eval Time (s)     10.797346083912998
Sample Time (s)              10.353805350605398
Epoch Time (s)               160.30088733136654
Total Train Time (s)         12379.253625505138
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:56:48.582500 UTC | [2020_01_11_02_30_29] Iteration #78 | Epoch Duration: 160.42097926139832
2020-01-11 05:56:48.582704 UTC | [2020_01_11_02_30_29] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009766653
Z variance train             0.0008485083
KL Divergence                15.516509
KL Loss                      1.5516509
QF Loss                      374.54324
VF Loss                      176.13127
Policy Loss                  -1018.55835
Q Predictions Mean           1012.00476
Q Predictions Std            327.099
Q Predictions Max            1389.8466
Q Predictions Min            -23.766249
V Predictions Mean           1021.52057
V Predictions Std            323.5958
V Predictions Max            1423.1023
V Predictions Min            -41.679462
Log Pis Mean                 0.8401957
Log Pis Std                  2.2836206
Log Pis Max                  7.2849474
Log Pis Min                  -5.3804
Policy mu Mean               0.15813927
Policy mu Std                1.0704427
Policy mu Max                2.9151108
Policy mu Min                -3.1936026
Policy log std Mean          -0.5776379
Policy log std Std           0.2711169
Policy log std Max           0.18921018
Policy log std Min           -1.8626053
Z mean eval                  0.005504173
Z variance eval              0.00092227786
total_rewards                [ 370.26696327  967.88993153 1334.91599855  372.87464358  366.09487566
  928.87485033 1311.1800119   835.96746701  950.3193453   915.8593021 ]
total_rewards_mean           835.4243389225476
total_rewards_std            342.40037972655807
total_rewards_max            1334.9159985497727
total_rewards_min            366.0948756564166
Number of train steps total  320000
Number of env steps total    268081
Number of rollouts total     0
Train Time (s)               140.0108754178509
(Previous) Eval Time (s)     7.9618834550492465
Sample Time (s)              11.184865817893296
Epoch Time (s)               159.15762469079345
Total Train Time (s)         12538.509344851132
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:59:27.839688 UTC | [2020_01_11_02_30_29] Iteration #79 | Epoch Duration: 159.25684309005737
2020-01-11 05:59:27.839846 UTC | [2020_01_11_02_30_29] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0052187783
Z variance train             0.00092389295
KL Divergence                15.097071
KL Loss                      1.5097071
QF Loss                      333.0993
VF Loss                      223.41252
Policy Loss                  -1039.9243
Q Predictions Mean           1037.9607
Q Predictions Std            299.3688
Q Predictions Max            1424.7363
Q Predictions Min            -31.088352
V Predictions Mean           1048.5076
V Predictions Std            295.45477
V Predictions Max            1427.7931
V Predictions Min            25.769665
Log Pis Mean                 0.41712403
Log Pis Std                  2.4620428
Log Pis Max                  9.190482
Log Pis Min                  -7.559733
Policy mu Mean               0.059489995
Policy mu Std                1.047186
Policy mu Max                2.7211773
Policy mu Min                -2.5890362
Policy log std Mean          -0.57271767
Policy log std Std           0.25607133
Policy log std Max           0.16611439
Policy log std Min           -1.4808085
Z mean eval                  0.0054682842
Z variance eval              0.000993955
total_rewards                [1463.41972421  277.00168353 1446.41155807  286.62536789 1334.45471969
  921.05678256  852.39247898  271.92937313  959.35845608 1196.90742329]
total_rewards_mean           900.9557567437141
total_rewards_std            453.6479370199392
total_rewards_max            1463.4197242125408
total_rewards_min            271.92937313155954
Number of train steps total  324000
Number of env steps total    271641
Number of rollouts total     0
Train Time (s)               138.70936339488253
(Previous) Eval Time (s)     9.019690678920597
Sample Time (s)              9.912177994847298
Epoch Time (s)               157.64123206865042
Total Train Time (s)         12696.228269509505
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:02:05.560418 UTC | [2020_01_11_02_30_29] Iteration #80 | Epoch Duration: 157.7204351425171
2020-01-11 06:02:05.560602 UTC | [2020_01_11_02_30_29] Iteration #80 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.005594562
Z variance train             0.0009936392
KL Divergence                15.067199
KL Loss                      1.50672
QF Loss                      348.5976
VF Loss                      72.952965
Policy Loss                  -1043.7069
Q Predictions Mean           1033.3778
Q Predictions Std            300.5405
Q Predictions Max            1430.1053
Q Predictions Min            -27.434563
V Predictions Mean           1042.7252
V Predictions Std            295.04913
V Predictions Max            1431.607
V Predictions Min            -34.06447
Log Pis Mean                 0.6918725
Log Pis Std                  2.5565982
Log Pis Max                  9.977959
Log Pis Min                  -4.498138
Policy mu Mean               -0.020907165
Policy mu Std                1.0996933
Policy mu Max                3.6285944
Policy mu Min                -2.79054
Policy log std Mean          -0.5747098
Policy log std Std           0.26859513
Policy log std Max           0.23182434
Policy log std Min           -1.5992622
Z mean eval                  0.0113815
Z variance eval              0.0010641546
total_rewards                [855.06821371 648.6732044  976.14439144 838.88315178 854.92755708
 653.13400879 673.92064717 825.7120214  642.01862687 638.85851937]
total_rewards_mean           760.7340342003024
total_rewards_std            116.24170974607289
total_rewards_max            976.1443914357924
total_rewards_min            638.8585193691739
Number of train steps total  328000
Number of env steps total    275563
Number of rollouts total     0
Train Time (s)               138.28942824620754
(Previous) Eval Time (s)     7.617683128919452
Sample Time (s)              9.90647692186758
Epoch Time (s)               155.81358829699457
Total Train Time (s)         12852.122176348697
Epoch                        81
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:04:41.456329 UTC | [2020_01_11_02_30_29] Iteration #81 | Epoch Duration: 155.8955783843994
2020-01-11 06:04:41.456531 UTC | [2020_01_11_02_30_29] Iteration #81 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011156956
Z variance train             0.0010641586
KL Divergence                14.95747
KL Loss                      1.495747
QF Loss                      392.74506
VF Loss                      871.1767
Policy Loss                  -1040.0386
Q Predictions Mean           1037.6416
Q Predictions Std            340.2392
Q Predictions Max            1488.4637
Q Predictions Min            -10.652286
V Predictions Mean           1050.5726
V Predictions Std            338.1253
V Predictions Max            1513.2677
V Predictions Min            -17.472588
Log Pis Mean                 0.7668438
Log Pis Std                  2.9926732
Log Pis Max                  27.02211
Log Pis Min                  -4.3697844
Policy mu Mean               0.023667118
Policy mu Std                1.1481992
Policy mu Max                7.1739006
Policy mu Min                -8.569379
Policy log std Mean          -0.57272315
Policy log std Std           0.2906737
Policy log std Max           1.0693302
Policy log std Min           -2.6605196
Z mean eval                  0.011342125
Z variance eval              0.0011295315
total_rewards                [ 931.63231368  903.20228851  744.10451631  956.43457665 1184.2946092
  972.35263851  933.0907083   932.14337045  971.11263067  682.60766793]
total_rewards_mean           921.0975320198984
total_rewards_std            128.2774396628636
total_rewards_max            1184.2946091991566
total_rewards_min            682.6076679299285
Number of train steps total  332000
Number of env steps total    279136
Number of rollouts total     0
Train Time (s)               140.49194870702922
(Previous) Eval Time (s)     7.945036011748016
Sample Time (s)              10.059569215867668
Epoch Time (s)               158.4965539346449
Total Train Time (s)         13010.7032007128
Epoch                        82
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:07:20.039840 UTC | [2020_01_11_02_30_29] Iteration #82 | Epoch Duration: 158.58312916755676
2020-01-11 06:07:20.040045 UTC | [2020_01_11_02_30_29] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011055567
Z variance train             0.0011289706
KL Divergence                14.629563
KL Loss                      1.4629563
QF Loss                      3853.952
VF Loss                      119.86509
Policy Loss                  -1047.6849
Q Predictions Mean           1039.2472
Q Predictions Std            354.8352
Q Predictions Max            1443.6974
Q Predictions Min            -37.75194
V Predictions Mean           1050.4269
V Predictions Std            338.66934
V Predictions Max            1447.8961
V Predictions Min            -17.748209
Log Pis Mean                 0.48809674
Log Pis Std                  2.4907076
Log Pis Max                  10.736223
Log Pis Min                  -5.7696424
Policy mu Mean               0.09853578
Policy mu Std                1.0421296
Policy mu Max                3.370689
Policy mu Min                -2.9481754
Policy log std Mean          -0.57661957
Policy log std Std           0.26513562
Policy log std Max           0.2051453
Policy log std Min           -2.6071782
Z mean eval                  0.011963138
Z variance eval              0.001006448
total_rewards                [ 779.01391143  601.20665942 1730.57528563  348.9269001   751.96520584
  739.18897546  567.33912429  513.61067591  771.56402042  388.67974112]
total_rewards_mean           719.207049961034
total_rewards_std            368.2756731846714
total_rewards_max            1730.5752856329636
total_rewards_min            348.9269000965849
Number of train steps total  336000
Number of env steps total    282890
Number of rollouts total     0
Train Time (s)               140.07119968812913
(Previous) Eval Time (s)     7.623515889048576
Sample Time (s)              10.407401960343122
Epoch Time (s)               158.10211753752083
Total Train Time (s)         13168.886292838491
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:09:58.224237 UTC | [2020_01_11_02_30_29] Iteration #83 | Epoch Duration: 158.18403482437134
2020-01-11 06:09:58.224460 UTC | [2020_01_11_02_30_29] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011531621
Z variance train             0.0010060009
KL Divergence                14.906896
KL Loss                      1.4906896
QF Loss                      1984.9187
VF Loss                      287.65228
Policy Loss                  -1052.8312
Q Predictions Mean           1044.867
Q Predictions Std            349.8001
Q Predictions Max            1426.8173
Q Predictions Min            -6.413842
V Predictions Mean           1052.091
V Predictions Std            340.7622
V Predictions Max            1428.4922
V Predictions Min            79.54436
Log Pis Mean                 0.6275798
Log Pis Std                  2.748605
Log Pis Max                  21.4715
Log Pis Min                  -4.7372456
Policy mu Mean               0.06774496
Policy mu Std                1.1017573
Policy mu Max                3.507916
Policy mu Min                -8.232542
Policy log std Mean          -0.59409195
Policy log std Std           0.29682973
Policy log std Max           0.37859762
Policy log std Min           -3.8230941
Z mean eval                  0.02196348
Z variance eval              0.0009769177
total_rewards                [ 811.62094878  924.20140757  602.45750529  914.67575201  777.43036673
  204.97655734  963.04471437 1054.37704596  596.07129505  966.99904249]
total_rewards_mean           781.5854635596907
total_rewards_std            240.76394930368033
total_rewards_max            1054.377045962065
total_rewards_min            204.9765573356294
Number of train steps total  340000
Number of env steps total    286470
Number of rollouts total     0
Train Time (s)               139.38503876700997
(Previous) Eval Time (s)     6.858726573176682
Sample Time (s)              10.152018564753234
Epoch Time (s)               156.3957839049399
Total Train Time (s)         13325.507229023613
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:12:34.846904 UTC | [2020_01_11_02_30_29] Iteration #84 | Epoch Duration: 156.62228345870972
2020-01-11 06:12:34.847121 UTC | [2020_01_11_02_30_29] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021325612
Z variance train             0.00097618194
KL Divergence                14.947208
KL Loss                      1.4947208
QF Loss                      262.78442
VF Loss                      108.12426
Policy Loss                  -1069.8289
Q Predictions Mean           1063.8883
Q Predictions Std            322.40088
Q Predictions Max            1474.6104
Q Predictions Min            -40.562057
V Predictions Mean           1075.1416
V Predictions Std            314.1551
V Predictions Max            1475.9161
V Predictions Min            -27.86357
Log Pis Mean                 0.9786332
Log Pis Std                  2.3697119
Log Pis Max                  10.924982
Log Pis Min                  -4.049833
Policy mu Mean               0.122766696
Policy mu Std                1.1000288
Policy mu Max                3.092522
Policy mu Min                -2.9182777
Policy log std Mean          -0.60203314
Policy log std Std           0.27620727
Policy log std Max           0.0871523
Policy log std Min           -3.8089561
Z mean eval                  0.010578992
Z variance eval              0.0008736545
total_rewards                [1861.8333018   677.82365756  596.8931004   575.77109322  603.36625174
 1122.64096038  610.31792824 1154.03256408  899.11465531  550.01883846]
total_rewards_mean           865.1812351189249
total_rewards_std            395.96171048877983
total_rewards_max            1861.8333018045087
total_rewards_min            550.0188384558
Number of train steps total  344000
Number of env steps total    290337
Number of rollouts total     0
Train Time (s)               139.72663385095075
(Previous) Eval Time (s)     7.585914951749146
Sample Time (s)              11.39339223690331
Epoch Time (s)               158.7059410396032
Total Train Time (s)         13484.304041541647
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:15:13.645241 UTC | [2020_01_11_02_30_29] Iteration #85 | Epoch Duration: 158.79786205291748
2020-01-11 06:15:13.645425 UTC | [2020_01_11_02_30_29] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011113868
Z variance train             0.00087292877
KL Divergence                15.181042
KL Loss                      1.5181042
QF Loss                      344.42883
VF Loss                      581.05646
Policy Loss                  -1052.9972
Q Predictions Mean           1048.4011
Q Predictions Std            321.40182
Q Predictions Max            1429.505
Q Predictions Min            -18.387392
V Predictions Mean           1042.9984
V Predictions Std            317.30176
V Predictions Max            1410.5793
V Predictions Min            -17.46838
Log Pis Mean                 0.5898948
Log Pis Std                  2.3446317
Log Pis Max                  8.856453
Log Pis Min                  -5.284693
Policy mu Mean               0.07732282
Policy mu Std                1.0587628
Policy mu Max                2.8230639
Policy mu Min                -2.850909
Policy log std Mean          -0.56814903
Policy log std Std           0.23786101
Policy log std Max           0.1659177
Policy log std Min           -1.909831
Z mean eval                  0.01944087
Z variance eval              0.0007803834
total_rewards                [1077.20744961 1058.7442612   952.02620084  792.53113243  783.61387643
  658.25734748  927.29873474  788.92291419  912.4638333  1292.0316388 ]
total_rewards_mean           924.3097389025928
total_rewards_std            174.31626497813926
total_rewards_max            1292.0316388038996
total_rewards_min            658.2573474774742
Number of train steps total  348000
Number of env steps total    294440
Number of rollouts total     0
Train Time (s)               144.7562559642829
(Previous) Eval Time (s)     9.702137626707554
Sample Time (s)              12.433791073039174
Epoch Time (s)               166.89218466402963
Total Train Time (s)         13651.282339799218
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:18:00.625575 UTC | [2020_01_11_02_30_29] Iteration #86 | Epoch Duration: 166.98000717163086
2020-01-11 06:18:00.625763 UTC | [2020_01_11_02_30_29] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019807283
Z variance train             0.0007806121
KL Divergence                15.430325
KL Loss                      1.5430325
QF Loss                      362.2173
VF Loss                      981.4644
Policy Loss                  -1032.2234
Q Predictions Mean           1020.89703
Q Predictions Std            358.2366
Q Predictions Max            1408.0948
Q Predictions Min            9.594255
V Predictions Mean           1038.763
V Predictions Std            341.82657
V Predictions Max            1426.3752
V Predictions Min            15.580296
Log Pis Mean                 1.161912
Log Pis Std                  2.7755423
Log Pis Max                  21.13478
Log Pis Min                  -4.799568
Policy mu Mean               0.22748484
Policy mu Std                1.150872
Policy mu Max                4.462991
Policy mu Min                -2.837394
Policy log std Mean          -0.6177421
Policy log std Std           0.28122786
Policy log std Max           0.26520234
Policy log std Min           -2.5453482
Z mean eval                  0.01826572
Z variance eval              0.000823436
total_rewards                [ 656.95612601 1218.89419437  743.98456568  637.52514822  754.78593117
  978.19540692  644.25869104  484.50274779  593.71949882  529.44435156]
total_rewards_mean           724.2266661575527
total_rewards_std            210.0946243228478
total_rewards_max            1218.8941943660532
total_rewards_min            484.50274779434733
Number of train steps total  352000
Number of env steps total    297992
Number of rollouts total     0
Train Time (s)               148.39118988718837
(Previous) Eval Time (s)     7.043918814975768
Sample Time (s)              10.431379577610642
Epoch Time (s)               165.86648827977479
Total Train Time (s)         13817.23200900713
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:20:46.579352 UTC | [2020_01_11_02_30_29] Iteration #87 | Epoch Duration: 165.95342445373535
2020-01-11 06:20:46.579588 UTC | [2020_01_11_02_30_29] Iteration #87 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018026277
Z variance train             0.00082351285
KL Divergence                15.444263
KL Loss                      1.5444263
QF Loss                      187.65826
VF Loss                      119.745804
Policy Loss                  -1113.9269
Q Predictions Mean           1113.0786
Q Predictions Std            264.03915
Q Predictions Max            1450.0677
Q Predictions Min            5.7930355
V Predictions Mean           1120.5948
V Predictions Std            261.75223
V Predictions Max            1449.0061
V Predictions Min            -4.8044662
Log Pis Mean                 0.61502784
Log Pis Std                  2.3264554
Log Pis Max                  8.128854
Log Pis Min                  -4.945716
Policy mu Mean               0.20606226
Policy mu Std                1.0347917
Policy mu Max                2.6143498
Policy mu Min                -2.7245255
Policy log std Mean          -0.5759886
Policy log std Std           0.269029
Policy log std Max           0.22518855
Policy log std Min           -1.65922
Z mean eval                  0.012620199
Z variance eval              0.0007778568
total_rewards                [953.3191079  914.07631682 941.19576808 920.77257866 714.90460367
 834.93262254 924.21966146 872.21678725 859.54845328 910.4532841 ]
total_rewards_mean           884.563918375479
total_rewards_std            66.62214510251736
total_rewards_max            953.3191079036152
total_rewards_min            714.9046036684407
Number of train steps total  356000
Number of env steps total    302050
Number of rollouts total     0
Train Time (s)               148.285067002289
(Previous) Eval Time (s)     8.683126251213253
Sample Time (s)              12.224875233601779
Epoch Time (s)               169.19306848710403
Total Train Time (s)         13986.51005018549
Epoch                        88
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:23:35.858541 UTC | [2020_01_11_02_30_29] Iteration #88 | Epoch Duration: 169.2787253856659
2020-01-11 06:23:35.858988 UTC | [2020_01_11_02_30_29] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011658985
Z variance train             0.0007792971
KL Divergence                15.638927
KL Loss                      1.5638927
QF Loss                      452.67786
VF Loss                      131.87321
Policy Loss                  -1069.5734
Q Predictions Mean           1068.1097
Q Predictions Std            324.8145
Q Predictions Max            1481.3767
Q Predictions Min            20.441635
V Predictions Mean           1070.1444
V Predictions Std            323.43192
V Predictions Max            1475.3582
V Predictions Min            20.375269
Log Pis Mean                 0.65689504
Log Pis Std                  2.484831
Log Pis Max                  10.332464
Log Pis Min                  -4.504403
Policy mu Mean               0.081001274
Policy mu Std                1.0697544
Policy mu Max                3.5710576
Policy mu Min                -3.5575874
Policy log std Mean          -0.6054906
Policy log std Std           0.28301087
Policy log std Max           0.12511468
Policy log std Min           -3.1293597
Z mean eval                  0.022444464
Z variance eval              0.00097445317
total_rewards                [ 918.19563232  918.95818639 1001.30889933  932.85718447  517.73925958
  669.19378943  951.35921952  665.06582188  854.05894945  706.30119378]
total_rewards_mean           813.5038136155541
total_rewards_std            152.99480532607126
total_rewards_max            1001.3088993277663
total_rewards_min            517.7392595843371
Number of train steps total  360000
Number of env steps total    305607
Number of rollouts total     0
Train Time (s)               148.46273759799078
(Previous) Eval Time (s)     7.773570874705911
Sample Time (s)              10.195418904069811
Epoch Time (s)               166.4317273767665
Total Train Time (s)         14153.02432786068
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:26:22.373452 UTC | [2020_01_11_02_30_29] Iteration #89 | Epoch Duration: 166.51413321495056
2020-01-11 06:26:22.373666 UTC | [2020_01_11_02_30_29] Iteration #89 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022357773
Z variance train             0.000974089
KL Divergence                15.013481
KL Loss                      1.5013481
QF Loss                      3187.1924
VF Loss                      99.846436
Policy Loss                  -1070.4705
Q Predictions Mean           1061.534
Q Predictions Std            339.51517
Q Predictions Max            1429.4131
Q Predictions Min            -51.07347
V Predictions Mean           1066.7253
V Predictions Std            326.5654
V Predictions Max            1429.3232
V Predictions Min            -45.33102
Log Pis Mean                 0.58794653
Log Pis Std                  2.463194
Log Pis Max                  10.165717
Log Pis Min                  -5.867791
Policy mu Mean               0.15844657
Policy mu Std                1.0475166
Policy mu Max                3.5717936
Policy mu Min                -2.6243875
Policy log std Mean          -0.56671333
Policy log std Std           0.25487393
Policy log std Max           0.33873093
Policy log std Min           -2.1265492
Z mean eval                  0.010065554
Z variance eval              0.0010467998
total_rewards                [741.00368515 991.73016245 756.58232352 914.96367543 736.57457116
 780.32701196 764.60584376 957.56309596 607.1928193  823.31205495]
total_rewards_mean           807.385524362983
total_rewards_std            110.9071908314145
total_rewards_max            991.7301624488658
total_rewards_min            607.192819297988
Number of train steps total  364000
Number of env steps total    309497
Number of rollouts total     0
Train Time (s)               146.91105326078832
(Previous) Eval Time (s)     7.780294512398541
Sample Time (s)              12.006109396927059
Epoch Time (s)               166.69745717011392
Total Train Time (s)         14319.80209512217
Epoch                        90
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:29:09.153181 UTC | [2020_01_11_02_30_29] Iteration #90 | Epoch Duration: 166.77936720848083
2020-01-11 06:29:09.153365 UTC | [2020_01_11_02_30_29] Iteration #90 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009909078
Z variance train             0.0010468995
KL Divergence                15.048971
KL Loss                      1.5048971
QF Loss                      164.0513
VF Loss                      98.44459
Policy Loss                  -1091.865
Q Predictions Mean           1084.0742
Q Predictions Std            307.54498
Q Predictions Max            1469.7034
Q Predictions Min            46.004738
V Predictions Mean           1096.8892
V Predictions Std            298.71927
V Predictions Max            1483.4573
V Predictions Min            65.445984
Log Pis Mean                 0.47618234
Log Pis Std                  2.2150824
Log Pis Max                  9.302381
Log Pis Min                  -4.8625393
Policy mu Mean               0.12841012
Policy mu Std                1.0247138
Policy mu Max                3.2714338
Policy mu Min                -2.772741
Policy log std Mean          -0.5870073
Policy log std Std           0.23949018
Policy log std Max           0.21184915
Policy log std Min           -1.5667008
Z mean eval                  0.022755573
Z variance eval              0.001067966
total_rewards                [793.36741611 767.4716696  877.7454792  806.13826155 782.26459054
 777.12019851 841.58277146 828.77650652 848.0504878  785.40395195]
total_rewards_mean           810.7921333243197
total_rewards_std            34.5493242972227
total_rewards_max            877.7454792015209
total_rewards_min            767.4716695963081
Number of train steps total  368000
Number of env steps total    313076
Number of rollouts total     0
Train Time (s)               142.2846857351251
(Previous) Eval Time (s)     7.158874784130603
Sample Time (s)              10.564469955395907
Epoch Time (s)               160.0080304746516
Total Train Time (s)         14479.901751552243
Epoch                        91
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:31:49.254147 UTC | [2020_01_11_02_30_29] Iteration #91 | Epoch Duration: 160.10064148902893
2020-01-11 06:31:49.254333 UTC | [2020_01_11_02_30_29] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023231953
Z variance train             0.0010673772
KL Divergence                14.926561
KL Loss                      1.4926561
QF Loss                      276.08215
VF Loss                      101.98308
Policy Loss                  -1092.5101
Q Predictions Mean           1087.3357
Q Predictions Std            281.06992
Q Predictions Max            1467.5171
Q Predictions Min            34.383656
V Predictions Mean           1096.813
V Predictions Std            269.09042
V Predictions Max            1463.8604
V Predictions Min            41.194534
Log Pis Mean                 0.4975434
Log Pis Std                  2.3353312
Log Pis Max                  9.52192
Log Pis Min                  -4.4498296
Policy mu Mean               0.03205001
Policy mu Std                1.1067317
Policy mu Max                3.246793
Policy mu Min                -2.8464932
Policy log std Mean          -0.5608512
Policy log std Std           0.27875715
Policy log std Max           0.28164142
Policy log std Min           -2.3926404
Z mean eval                  0.012386064
Z variance eval              0.0010848187
total_rewards                [ 909.49738277  774.22598279  775.45803789  802.56033765 1212.72020766
  923.96029275  897.42105244  872.95788302 1312.23375872  999.22834987]
total_rewards_mean           948.026328556249
total_rewards_std            172.26087706821076
total_rewards_max            1312.2337587205955
total_rewards_min            774.2259827886032
Number of train steps total  372000
Number of env steps total    316630
Number of rollouts total     0
Train Time (s)               139.04071132605895
(Previous) Eval Time (s)     9.490134880878031
Sample Time (s)              9.956163698807359
Epoch Time (s)               158.48700990574434
Total Train Time (s)         14638.474192774855
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:34:27.828551 UTC | [2020_01_11_02_30_29] Iteration #92 | Epoch Duration: 158.57399892807007
2020-01-11 06:34:27.828839 UTC | [2020_01_11_02_30_29] Iteration #92 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012737992
Z variance train             0.0010842467
KL Divergence                14.928357
KL Loss                      1.4928358
QF Loss                      1170.2213
VF Loss                      232.07153
Policy Loss                  -1026.842
Q Predictions Mean           1023.23846
Q Predictions Std            360.04727
Q Predictions Max            1489.4651
Q Predictions Min            -3.820857
V Predictions Mean           1037.1826
V Predictions Std            357.58365
V Predictions Max            1515.1053
V Predictions Min            -1.9559789
Log Pis Mean                 0.6954497
Log Pis Std                  2.5068204
Log Pis Max                  11.183395
Log Pis Min                  -5.2274156
Policy mu Mean               0.124090254
Policy mu Std                1.1088004
Policy mu Max                2.9911005
Policy mu Min                -3.1907675
Policy log std Mean          -0.5975954
Policy log std Std           0.23269928
Policy log std Max           0.17691386
Policy log std Min           -2.0601544
Z mean eval                  0.008898343
Z variance eval              0.0007419234
total_rewards                [1274.74469106 1765.92621095  684.79464504  915.53331682  852.8129157
  855.71694516  725.62790418  672.75601856  704.47297153  611.00200224]
total_rewards_mean           906.3387621256209
total_rewards_std            338.28957156724397
total_rewards_max            1765.9262109512767
total_rewards_min            611.0020022449246
Number of train steps total  376000
Number of env steps total    320223
Number of rollouts total     0
Train Time (s)               138.946250368841
(Previous) Eval Time (s)     8.54584989277646
Sample Time (s)              9.880113475490361
Epoch Time (s)               157.3722137371078
Total Train Time (s)         14795.938075100537
Epoch                        93
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:37:05.294127 UTC | [2020_01_11_02_30_29] Iteration #93 | Epoch Duration: 157.46508383750916
2020-01-11 06:37:05.294304 UTC | [2020_01_11_02_30_29] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008887234
Z variance train             0.0007423166
KL Divergence                15.778983
KL Loss                      1.5778984
QF Loss                      198.35146
VF Loss                      162.99518
Policy Loss                  -1091.9863
Q Predictions Mean           1081.3451
Q Predictions Std            325.9227
Q Predictions Max            1467.2532
Q Predictions Min            -12.563006
V Predictions Mean           1088.2411
V Predictions Std            317.0653
V Predictions Max            1467.3209
V Predictions Min            -21.047087
Log Pis Mean                 0.6267359
Log Pis Std                  2.3261857
Log Pis Max                  16.846298
Log Pis Min                  -3.9966934
Policy mu Mean               0.14390232
Policy mu Std                1.0257614
Policy mu Max                5.8038197
Policy mu Min                -2.6492238
Policy log std Mean          -0.6058559
Policy log std Std           0.27633196
Policy log std Max           0.18449938
Policy log std Min           -3.4597306
Z mean eval                  0.012694174
Z variance eval              0.0005675505
total_rewards                [ 743.65957409  952.65983962  624.10703196  964.96054099 1177.71675882
  740.41528879  523.55544676  962.09019909  621.03112102  899.40981681]
total_rewards_mean           820.9605617937501
total_rewards_std            192.6300645504485
total_rewards_max            1177.7167588169698
total_rewards_min            523.5554467616968
Number of train steps total  380000
Number of env steps total    323788
Number of rollouts total     0
Train Time (s)               138.62448217812926
(Previous) Eval Time (s)     8.295973701868206
Sample Time (s)              9.162317452486604
Epoch Time (s)               156.08277333248407
Total Train Time (s)         14952.101743516512
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:39:41.459849 UTC | [2020_01_11_02_30_29] Iteration #94 | Epoch Duration: 156.16539788246155
2020-01-11 06:39:41.460057 UTC | [2020_01_11_02_30_29] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012680215
Z variance train             0.00056728395
KL Divergence                16.40276
KL Loss                      1.640276
QF Loss                      160.3067
VF Loss                      70.97385
Policy Loss                  -1088.1979
Q Predictions Mean           1083.8405
Q Predictions Std            337.57812
Q Predictions Max            1518.5409
Q Predictions Min            -42.951153
V Predictions Mean           1090.9146
V Predictions Std            322.47186
V Predictions Max            1521.9988
V Predictions Min            -22.605822
Log Pis Mean                 0.54984045
Log Pis Std                  2.7357142
Log Pis Max                  17.834988
Log Pis Min                  -3.963043
Policy mu Mean               -0.04930325
Policy mu Std                1.0854609
Policy mu Max                4.4708138
Policy mu Min                -3.7575266
Policy log std Mean          -0.5896127
Policy log std Std           0.3015413
Policy log std Max           0.12635905
Policy log std Min           -3.0215127
Z mean eval                  0.02079683
Z variance eval              0.00064204156
total_rewards                [1458.00180565 1125.73800153 1096.64193217 1639.40073508 1629.17049643
 2284.98769082  538.84094882 2793.59301776 1623.09227246  551.35777357]
total_rewards_mean           1474.0824674316614
total_rewards_std            668.0137044368822
total_rewards_max            2793.5930177638625
total_rewards_min            538.8409488249143
Number of train steps total  384000
Number of env steps total    327747
Number of rollouts total     0
Train Time (s)               139.18450501793995
(Previous) Eval Time (s)     14.777741055935621
Sample Time (s)              11.137049697339535
Epoch Time (s)               165.0992957712151
Total Train Time (s)         15117.286430362612
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:42:26.646635 UTC | [2020_01_11_02_30_29] Iteration #95 | Epoch Duration: 165.18640089035034
2020-01-11 06:42:26.646903 UTC | [2020_01_11_02_30_29] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020548882
Z variance train             0.0006420606
KL Divergence                16.112034
KL Loss                      1.6112034
QF Loss                      731.7553
VF Loss                      348.14047
Policy Loss                  -1092.2942
Q Predictions Mean           1088.3616
Q Predictions Std            334.1242
Q Predictions Max            1530.2003
Q Predictions Min            20.60766
V Predictions Mean           1080.0599
V Predictions Std            332.0577
V Predictions Max            1512.818
V Predictions Min            17.288794
Log Pis Mean                 0.39008465
Log Pis Std                  2.2400944
Log Pis Max                  7.0759053
Log Pis Min                  -4.633103
Policy mu Mean               -0.057560235
Policy mu Std                1.0611188
Policy mu Max                2.8846157
Policy mu Min                -2.8393114
Policy log std Mean          -0.582666
Policy log std Std           0.2310175
Policy log std Max           0.12668186
Policy log std Min           -1.616368
Z mean eval                  0.03104808
Z variance eval              0.0008596342
total_rewards                [1142.9652429   940.67032311  871.48277041  979.35742435  611.37548905
  730.78257124  603.06724096  668.55764125  904.18032488 1189.83250434]
total_rewards_mean           864.2271532477159
total_rewards_std            198.1650027108044
total_rewards_max            1189.8325043405885
total_rewards_min            603.067240959425
Number of train steps total  388000
Number of env steps total    331688
Number of rollouts total     0
Train Time (s)               141.37987844180316
(Previous) Eval Time (s)     8.485608667135239
Sample Time (s)              10.489310562144965
Epoch Time (s)               160.35479767108336
Total Train Time (s)         15277.724598265253
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:45:07.087073 UTC | [2020_01_11_02_30_29] Iteration #96 | Epoch Duration: 160.4399697780609
2020-01-11 06:45:07.087296 UTC | [2020_01_11_02_30_29] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030969927
Z variance train             0.00085948344
KL Divergence                15.595341
KL Loss                      1.5595341
QF Loss                      1663.7764
VF Loss                      127.71635
Policy Loss                  -1090.7003
Q Predictions Mean           1081.5803
Q Predictions Std            308.0583
Q Predictions Max            1486.0911
Q Predictions Min            69.75766
V Predictions Mean           1083.4548
V Predictions Std            298.50198
V Predictions Max            1478.6918
V Predictions Min            50.79936
Log Pis Mean                 0.4746395
Log Pis Std                  2.3663955
Log Pis Max                  7.8684177
Log Pis Min                  -8.065649
Policy mu Mean               0.018823348
Policy mu Std                1.0730729
Policy mu Max                2.7451537
Policy mu Min                -2.7737777
Policy log std Mean          -0.59259754
Policy log std Std           0.2638409
Policy log std Max           0.3865565
Policy log std Min           -2.344631
Z mean eval                  0.018734418
Z variance eval              0.0006006563
total_rewards                [1289.68122688  543.40823609  621.11309595 1148.27347796  773.57296192
  967.27785174  871.41736062  916.89136743  837.98887866  834.86337956]
total_rewards_mean           880.4487836816965
total_rewards_std            210.7853928851368
total_rewards_max            1289.681226884075
total_rewards_min            543.4082360938188
Number of train steps total  392000
Number of env steps total    335255
Number of rollouts total     0
Train Time (s)               140.3106390698813
(Previous) Eval Time (s)     8.731920931953937
Sample Time (s)              10.014314665924758
Epoch Time (s)               159.05687466775998
Total Train Time (s)         15436.893101934344
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:47:46.257537 UTC | [2020_01_11_02_30_29] Iteration #97 | Epoch Duration: 159.170090675354
2020-01-11 06:47:46.257738 UTC | [2020_01_11_02_30_29] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01694424
Z variance train             0.00060080073
KL Divergence                16.288292
KL Loss                      1.6288292
QF Loss                      993.00824
VF Loss                      289.0353
Policy Loss                  -1104.2512
Q Predictions Mean           1091.8513
Q Predictions Std            329.0823
Q Predictions Max            1515.2972
Q Predictions Min            -17.560093
V Predictions Mean           1107.7037
V Predictions Std            317.40906
V Predictions Max            1481.6387
V Predictions Min            -0.8351084
Log Pis Mean                 0.7456937
Log Pis Std                  2.295895
Log Pis Max                  6.056836
Log Pis Min                  -6.3174467
Policy mu Mean               -0.012427412
Policy mu Std                1.0488843
Policy mu Max                2.5172908
Policy mu Min                -3.1288826
Policy log std Mean          -0.6101745
Policy log std Std           0.2847105
Policy log std Max           0.14991349
Policy log std Min           -2.0498044
Z mean eval                  0.027263567
Z variance eval              0.0007471501
total_rewards                [ 656.9333335  1054.52213754 1155.25958284  906.90914738  368.36982089
  869.22057591  636.879684    366.47561132  366.96029884  745.29720902]
total_rewards_mean           712.6827401237333
total_rewards_std            272.54522536080805
total_rewards_max            1155.2595828399287
total_rewards_min            366.47561132174894
Number of train steps total  396000
Number of env steps total    338810
Number of rollouts total     0
Train Time (s)               139.68891646014526
(Previous) Eval Time (s)     7.4637719499878585
Sample Time (s)              10.217027528211474
Epoch Time (s)               157.3697159383446
Total Train Time (s)         15594.347299805377
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:50:23.713226 UTC | [2020_01_11_02_30_29] Iteration #98 | Epoch Duration: 157.45534253120422
2020-01-11 06:50:23.713412 UTC | [2020_01_11_02_30_29] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027721336
Z variance train             0.0007470972
KL Divergence                15.946004
KL Loss                      1.5946004
QF Loss                      433.5552
VF Loss                      126.32732
Policy Loss                  -1084.0121
Q Predictions Mean           1082.1237
Q Predictions Std            345.99658
Q Predictions Max            1546.9476
Q Predictions Min            12.003377
V Predictions Mean           1086.4435
V Predictions Std            345.32013
V Predictions Max            1536.534
V Predictions Min            12.559578
Log Pis Mean                 0.6655346
Log Pis Std                  2.3844233
Log Pis Max                  11.459348
Log Pis Min                  -3.6492734
Policy mu Mean               0.09471055
Policy mu Std                1.0636774
Policy mu Max                3.868688
Policy mu Min                -2.913056
Policy log std Mean          -0.5930097
Policy log std Std           0.27054787
Policy log std Max           0.5007357
Policy log std Min           -3.4457963
Z mean eval                  0.027307954
Z variance eval              0.00086891913
total_rewards                [1070.16598334  899.39878379  811.41748018 2259.84990279  933.95441806
 1364.77814576 1065.98867201 1020.49498371 1134.62844062 1123.99950104]
total_rewards_mean           1168.4676311303965
total_rewards_std            391.11583244292575
total_rewards_max            2259.849902792318
total_rewards_min            811.4174801775414
Number of train steps total  400000
Number of env steps total    342903
Number of rollouts total     0
Train Time (s)               139.9735127002932
(Previous) Eval Time (s)     9.868460673373193
Sample Time (s)              12.196148597635329
Epoch Time (s)               162.03812197130173
Total Train Time (s)         15756.463748780545
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:53:05.832766 UTC | [2020_01_11_02_30_29] Iteration #99 | Epoch Duration: 162.1192009449005
2020-01-11 06:53:05.832979 UTC | [2020_01_11_02_30_29] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027873676
Z variance train             0.0008688434
KL Divergence                15.391174
KL Loss                      1.5391175
QF Loss                      367.84314
VF Loss                      145.33647
Policy Loss                  -1156.5481
Q Predictions Mean           1148.6665
Q Predictions Std            277.8991
Q Predictions Max            1507.6151
Q Predictions Min            -32.068104
V Predictions Mean           1150.7153
V Predictions Std            267.40268
V Predictions Max            1492.473
V Predictions Min            11.108629
Log Pis Mean                 0.61255705
Log Pis Std                  2.3422477
Log Pis Max                  9.122147
Log Pis Min                  -3.7329528
Policy mu Mean               0.030293122
Policy mu Std                1.0647999
Policy mu Max                3.926828
Policy mu Min                -3.3316195
Policy log std Mean          -0.56578827
Policy log std Std           0.25706902
Policy log std Max           0.24789965
Policy log std Min           -2.0825133
Z mean eval                  0.008880543
Z variance eval              0.0008439982
total_rewards                [1546.49057482 1236.31068505 1594.20498928 1262.30168573 2425.16711395
 1730.21932877 2421.21704641 1401.83349048 1216.94809663 1079.83244646]
total_rewards_mean           1591.4525457570373
total_rewards_std            455.774572243579
total_rewards_max            2425.1671139484533
total_rewards_min            1079.832446464151
Number of train steps total  404000
Number of env steps total    346998
Number of rollouts total     0
Train Time (s)               140.14894935581833
(Previous) Eval Time (s)     15.302745583001524
Sample Time (s)              8.9369549555704
Epoch Time (s)               164.38864989439026
Total Train Time (s)         15920.932756095193
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:55:50.301383 UTC | [2020_01_11_02_30_29] Iteration #100 | Epoch Duration: 164.4682583808899
2020-01-11 06:55:50.301507 UTC | [2020_01_11_02_30_29] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008055859
Z variance train             0.0008435592
KL Divergence                15.287424
KL Loss                      1.5287424
QF Loss                      744.87634
VF Loss                      275.80078
Policy Loss                  -1106.5288
Q Predictions Mean           1103.8
Q Predictions Std            299.8569
Q Predictions Max            1487.7731
Q Predictions Min            19.944645
V Predictions Mean           1107.4058
V Predictions Std            300.88004
V Predictions Max            1497.8923
V Predictions Min            43.79839
Log Pis Mean                 0.53330564
Log Pis Std                  2.4662602
Log Pis Max                  14.24217
Log Pis Min                  -3.8751726
Policy mu Mean               0.09617137
Policy mu Std                1.0439405
Policy mu Max                3.8607652
Policy mu Min                -2.6000235
Policy log std Mean          -0.6173212
Policy log std Std           0.3003197
Policy log std Max           0.17701149
Policy log std Min           -3.1923294
Z mean eval                  0.026604736
Z variance eval              0.0008369199
total_rewards                [1734.48256892 1510.63019842 1287.52807627 1028.65834179 1373.64502534
 1174.37203822 1020.69073502  971.59852325 1526.22246881 1556.65292109]
total_rewards_mean           1318.4480897142632
total_rewards_std            250.526087399651
total_rewards_max            1734.4825689246932
total_rewards_min            971.5985232504146
Number of train steps total  408000
Number of env steps total    351108
Number of rollouts total     0
Train Time (s)               140.75668281596154
(Previous) Eval Time (s)     11.409170930739492
Sample Time (s)              9.698039997834712
Epoch Time (s)               161.86389374453574
Total Train Time (s)         16082.878163668327
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:58:32.249381 UTC | [2020_01_11_02_30_29] Iteration #101 | Epoch Duration: 161.94776487350464
2020-01-11 06:58:32.249577 UTC | [2020_01_11_02_30_29] Iteration #101 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02594326
Z variance train             0.0008369305
KL Divergence                15.379346
KL Loss                      1.5379347
QF Loss                      357.23843
VF Loss                      80.15402
Policy Loss                  -1096.1824
Q Predictions Mean           1092.7568
Q Predictions Std            318.92493
Q Predictions Max            1496.3414
Q Predictions Min            25.761585
V Predictions Mean           1096.0471
V Predictions Std            315.5881
V Predictions Max            1500.4281
V Predictions Min            28.992569
Log Pis Mean                 0.5590519
Log Pis Std                  2.3270628
Log Pis Max                  10.851515
Log Pis Min                  -6.877763
Policy mu Mean               0.10788914
Policy mu Std                1.0246882
Policy mu Max                3.0138307
Policy mu Min                -2.5569913
Policy log std Mean          -0.62058866
Policy log std Std           0.29370326
Policy log std Max           0.05999446
Policy log std Min           -2.6582375
Z mean eval                  0.015521419
Z variance eval              0.000749346
total_rewards                [1097.25986116 1569.09350465 2026.19453584 1170.2427494  1261.6355564
 1630.88090457 1403.2494611   980.68370947 1405.36936683 2082.33967266]
total_rewards_mean           1462.6949322082608
total_rewards_std            352.100742898017
total_rewards_max            2082.3396726587744
total_rewards_min            980.6837094665294
Number of train steps total  412000
Number of env steps total    355176
Number of rollouts total     0
Train Time (s)               139.56108671799302
(Previous) Eval Time (s)     13.336574296932667
Sample Time (s)              9.708859487902373
Epoch Time (s)               162.60652050282806
Total Train Time (s)         16245.580210522749
Epoch                        102
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:01:14.957476 UTC | [2020_01_11_02_30_29] Iteration #102 | Epoch Duration: 162.70774912834167
2020-01-11 07:01:14.957683 UTC | [2020_01_11_02_30_29] Iteration #102 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015341637
Z variance train             0.0007493196
KL Divergence                15.711512
KL Loss                      1.5711511
QF Loss                      177.45181
VF Loss                      81.28997
Policy Loss                  -1126.3306
Q Predictions Mean           1124.859
Q Predictions Std            322.41156
Q Predictions Max            1514.1353
Q Predictions Min            6.957311
V Predictions Mean           1123.4432
V Predictions Std            317.07245
V Predictions Max            1496.6964
V Predictions Min            14.69849
Log Pis Mean                 0.47461367
Log Pis Std                  2.1827493
Log Pis Max                  7.8491373
Log Pis Min                  -6.745948
Policy mu Mean               0.117709726
Policy mu Std                1.0026495
Policy mu Max                3.7155325
Policy mu Min                -2.8194473
Policy log std Mean          -0.6022909
Policy log std Std           0.26469368
Policy log std Max           0.27450573
Policy log std Min           -2.1812565
Z mean eval                  0.028195074
Z variance eval              0.0008438237
total_rewards                [ 855.72715809 1016.41074283 1865.97621543 1348.70903489 1524.6716893
  990.3131636  1572.45103568 2109.01691116 1855.52628656  762.51383542]
total_rewards_mean           1390.131607294713
total_rewards_std            446.305710381724
total_rewards_max            2109.016911157528
total_rewards_min            762.5138354159882
Number of train steps total  416000
Number of env steps total    359381
Number of rollouts total     0
Train Time (s)               140.8179158680141
(Previous) Eval Time (s)     13.255792255047709
Sample Time (s)              9.581092560198158
Epoch Time (s)               163.65480068325996
Total Train Time (s)         16409.328475780785
Epoch                        103
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:03:58.703791 UTC | [2020_01_11_02_30_29] Iteration #103 | Epoch Duration: 163.74596071243286
2020-01-11 07:03:58.703983 UTC | [2020_01_11_02_30_29] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028111517
Z variance train             0.00084427773
KL Divergence                15.7640915
KL Loss                      1.5764092
QF Loss                      1462.358
VF Loss                      164.02867
Policy Loss                  -1075.4581
Q Predictions Mean           1061.7727
Q Predictions Std            367.3152
Q Predictions Max            1518.0691
Q Predictions Min            -57.08826
V Predictions Mean           1074.8933
V Predictions Std            356.02832
V Predictions Max            1517.4552
V Predictions Min            -2.1551795
Log Pis Mean                 0.7788511
Log Pis Std                  2.4895425
Log Pis Max                  9.992336
Log Pis Min                  -4.6571136
Policy mu Mean               0.12087104
Policy mu Std                1.0750827
Policy mu Max                3.4160166
Policy mu Min                -2.7593381
Policy log std Mean          -0.5947748
Policy log std Std           0.2725305
Policy log std Max           0.1992982
Policy log std Min           -2.6360393
Z mean eval                  0.017164623
Z variance eval              0.0006110979
total_rewards                [1130.31951807  369.18916083  954.38850781  861.54724422  895.39656853
  701.50024339  861.27795049  734.73787661 1183.08056729 1126.13233709]
total_rewards_mean           881.756997433462
total_rewards_std            231.39158003750845
total_rewards_max            1183.080567289262
total_rewards_min            369.18916083081933
Number of train steps total  420000
Number of env steps total    363778
Number of rollouts total     0
Train Time (s)               140.23357980092987
(Previous) Eval Time (s)     8.687756233848631
Sample Time (s)              10.280257421080023
Epoch Time (s)               159.20159345585853
Total Train Time (s)         16568.6065189722
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:06:37.983807 UTC | [2020_01_11_02_30_29] Iteration #104 | Epoch Duration: 159.27967262268066
2020-01-11 07:06:37.984020 UTC | [2020_01_11_02_30_29] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017545918
Z variance train             0.00061124144
KL Divergence                16.534874
KL Loss                      1.6534874
QF Loss                      1043.5295
VF Loss                      319.97076
Policy Loss                  -1091.3472
Q Predictions Mean           1079.113
Q Predictions Std            341.98978
Q Predictions Max            1503.2686
Q Predictions Min            -13.47522
V Predictions Mean           1089.7732
V Predictions Std            339.09702
V Predictions Max            1517.7064
V Predictions Min            39.589035
Log Pis Mean                 0.3662257
Log Pis Std                  2.4828491
Log Pis Max                  12.175522
Log Pis Min                  -5.4187117
Policy mu Mean               0.078239866
Policy mu Std                1.0106604
Policy mu Max                4.88894
Policy mu Min                -2.7418242
Policy log std Mean          -0.62085396
Policy log std Std           0.3018757
Policy log std Max           0.11557901
Policy log std Min           -3.2921286
Z mean eval                  0.01366892
Z variance eval              0.000749201
total_rewards                [1049.3137158   768.09702705  802.95359021 2247.22348739 1773.00264718
  751.83381095  861.17685594 2182.56464058  900.27456041  795.51602852]
total_rewards_mean           1213.1956364043067
total_rewards_std            576.6012621411716
total_rewards_max            2247.223487387427
total_rewards_min            751.8338109537885
Number of train steps total  424000
Number of env steps total    368059
Number of rollouts total     0
Train Time (s)               139.89742302056402
(Previous) Eval Time (s)     12.2000641413033
Sample Time (s)              10.77055762289092
Epoch Time (s)               162.86804478475824
Total Train Time (s)         16731.560151528567
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:09:20.939988 UTC | [2020_01_11_02_30_29] Iteration #105 | Epoch Duration: 162.95578265190125
2020-01-11 07:09:20.940268 UTC | [2020_01_11_02_30_29] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0136555135
Z variance train             0.0007490829
KL Divergence                15.994545
KL Loss                      1.5994545
QF Loss                      378.007
VF Loss                      94.4965
Policy Loss                  -1116.2623
Q Predictions Mean           1113.2808
Q Predictions Std            290.80447
Q Predictions Max            1457.3855
Q Predictions Min            64.55431
V Predictions Mean           1112.9563
V Predictions Std            289.068
V Predictions Max            1456.0167
V Predictions Min            60.69317
Log Pis Mean                 0.41899037
Log Pis Std                  2.2615378
Log Pis Max                  8.958602
Log Pis Min                  -4.616238
Policy mu Mean               0.08656972
Policy mu Std                1.0347623
Policy mu Max                3.8999422
Policy mu Min                -2.7824955
Policy log std Mean          -0.5825755
Policy log std Std           0.26811886
Policy log std Max           0.32737523
Policy log std Min           -2.442422
Z mean eval                  0.020757634
Z variance eval              0.00065606425
total_rewards                [ 854.69973908 1245.30890127 1515.21663139 1119.83541907 1056.63711993
 2611.9411527  2110.45086007  795.55687277 1846.63041435  783.08070792]
total_rewards_mean           1393.935781853817
total_rewards_std            587.3278906481897
total_rewards_max            2611.9411527017965
total_rewards_min            783.0807079212433
Number of train steps total  428000
Number of env steps total    372145
Number of rollouts total     0
Train Time (s)               141.2988974871114
(Previous) Eval Time (s)     13.652050260920078
Sample Time (s)              9.108971189241856
Epoch Time (s)               164.05991893727332
Total Train Time (s)         16895.70280107204
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:12:05.084690 UTC | [2020_01_11_02_30_29] Iteration #106 | Epoch Duration: 164.14424204826355
2020-01-11 07:12:05.084888 UTC | [2020_01_11_02_30_29] Iteration #106 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020630898
Z variance train             0.0006561511
KL Divergence                16.014193
KL Loss                      1.6014193
QF Loss                      323.216
VF Loss                      106.637634
Policy Loss                  -1105.0743
Q Predictions Mean           1098.7722
Q Predictions Std            329.83707
Q Predictions Max            1532.3204
Q Predictions Min            7.5729423
V Predictions Mean           1106.3855
V Predictions Std            326.965
V Predictions Max            1534.621
V Predictions Min            17.997341
Log Pis Mean                 0.4230662
Log Pis Std                  2.1471658
Log Pis Max                  7.321933
Log Pis Min                  -6.3816705
Policy mu Mean               0.07291011
Policy mu Std                1.029685
Policy mu Max                2.9654477
Policy mu Min                -3.504515
Policy log std Mean          -0.5741184
Policy log std Std           0.22663997
Policy log std Max           0.15912753
Policy log std Min           -1.3734624
Z mean eval                  0.021190103
Z variance eval              0.0006408806
total_rewards                [ 921.19526175  619.08433226  854.96656265 1649.63377081  808.8119266
  960.1029844  1437.7362737   601.41661786  892.44595646  926.27080812]
total_rewards_mean           967.1664494617542
total_rewards_std            314.51796793410637
total_rewards_max            1649.633770812486
total_rewards_min            601.4166178553694
Number of train steps total  432000
Number of env steps total    376244
Number of rollouts total     0
Train Time (s)               147.0248095053248
(Previous) Eval Time (s)     9.680298428982496
Sample Time (s)              10.180041974876076
Epoch Time (s)               166.88514990918338
Total Train Time (s)         17062.675205808133
Epoch                        107
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:14:52.059524 UTC | [2020_01_11_02_30_29] Iteration #107 | Epoch Duration: 166.97446513175964
2020-01-11 07:14:52.059771 UTC | [2020_01_11_02_30_29] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021132642
Z variance train             0.0006411808
KL Divergence                15.900427
KL Loss                      1.5900427
QF Loss                      403.2594
VF Loss                      144.05043
Policy Loss                  -1094.898
Q Predictions Mean           1088.4285
Q Predictions Std            334.49777
Q Predictions Max            1485.6282
Q Predictions Min            -15.915828
V Predictions Mean           1101.5115
V Predictions Std            330.4663
V Predictions Max            1480.4698
V Predictions Min            7.680575
Log Pis Mean                 0.46696168
Log Pis Std                  2.1739783
Log Pis Max                  9.000934
Log Pis Min                  -3.877637
Policy mu Mean               0.11571878
Policy mu Std                1.0077726
Policy mu Max                2.770181
Policy mu Min                -2.9659824
Policy log std Mean          -0.5979273
Policy log std Std           0.2698091
Policy log std Max           0.42513663
Policy log std Min           -2.8556132
Z mean eval                  0.0133389635
Z variance eval              0.0006972111
total_rewards                [1688.91092963 2512.02548005 1653.38638062 3109.03006148  380.3995861
 1010.99333151 3031.46467634  655.38537719 3100.01470265  670.09699286]
total_rewards_mean           1781.170751843528
total_rewards_std            1033.5373573193947
total_rewards_max            3109.0300614784364
total_rewards_min            380.39958609810145
Number of train steps total  436000
Number of env steps total    380853
Number of rollouts total     0
Train Time (s)               146.24151778686792
(Previous) Eval Time (s)     18.28408919693902
Sample Time (s)              12.56173375993967
Epoch Time (s)               177.0873407437466
Total Train Time (s)         17239.84367914917
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:17:49.227999 UTC | [2020_01_11_02_30_29] Iteration #108 | Epoch Duration: 177.16807651519775
2020-01-11 07:17:49.228138 UTC | [2020_01_11_02_30_29] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013090273
Z variance train             0.0006974129
KL Divergence                15.893804
KL Loss                      1.5893804
QF Loss                      1302.4209
VF Loss                      92.07946
Policy Loss                  -1106.4333
Q Predictions Mean           1099.823
Q Predictions Std            318.13223
Q Predictions Max            1491.1105
Q Predictions Min            22.03013
V Predictions Mean           1109.1832
V Predictions Std            315.96228
V Predictions Max            1499.4502
V Predictions Min            27.072456
Log Pis Mean                 0.41984597
Log Pis Std                  2.189697
Log Pis Max                  7.413355
Log Pis Min                  -6.9206057
Policy mu Mean               0.02921471
Policy mu Std                1.0057861
Policy mu Max                2.8074818
Policy mu Min                -2.6205468
Policy log std Mean          -0.60714644
Policy log std Std           0.2770787
Policy log std Max           0.25319433
Policy log std Min           -2.5347679
Z mean eval                  0.018298768
Z variance eval              0.0007301264
total_rewards                [1875.55870819 1717.01636142 1895.22554082 1561.21153002 1481.94667429
 2401.70977741  493.72009694 1939.87702965  868.46437235  910.19742927]
total_rewards_mean           1514.4927520358583
total_rewards_std            557.8702301186576
total_rewards_max            2401.709777414026
total_rewards_min            493.72009694349896
Number of train steps total  440000
Number of env steps total    384948
Number of rollouts total     0
Train Time (s)               146.5271234549582
(Previous) Eval Time (s)     14.449284448288381
Sample Time (s)              8.868990077171475
Epoch Time (s)               169.84539798041806
Total Train Time (s)         17409.772913979366
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:20:39.160304 UTC | [2020_01_11_02_30_29] Iteration #109 | Epoch Duration: 169.93202662467957
2020-01-11 07:20:39.160561 UTC | [2020_01_11_02_30_29] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018532714
Z variance train             0.00073063193
KL Divergence                15.786639
KL Loss                      1.578664
QF Loss                      835.2706
VF Loss                      192.10558
Policy Loss                  -1077.9117
Q Predictions Mean           1065.0308
Q Predictions Std            366.34354
Q Predictions Max            1508.7322
Q Predictions Min            -4.589297
V Predictions Mean           1086.2374
V Predictions Std            355.9685
V Predictions Max            1532.6287
V Predictions Min            -5.010955
Log Pis Mean                 0.6199204
Log Pis Std                  2.3002963
Log Pis Max                  8.557642
Log Pis Min                  -7.177579
Policy mu Mean               0.04156479
Policy mu Std                1.0535932
Policy mu Max                2.9426835
Policy mu Min                -2.623291
Policy log std Mean          -0.6114312
Policy log std Std           0.27999213
Policy log std Max           0.13677347
Policy log std Min           -2.8850863
Z mean eval                  0.015464956
Z variance eval              0.0008018045
total_rewards                [1361.80350597  985.73631841 3023.62269701 1742.4899707  1037.17684897
 2160.09929545 3105.29080138 1969.4160073   954.32363233 3192.54237849]
total_rewards_mean           1953.2501456017399
total_rewards_std            849.6554986676313
total_rewards_max            3192.542378494188
total_rewards_min            954.3236323319919
Number of train steps total  444000
Number of env steps total    389031
Number of rollouts total     0
Train Time (s)               149.71598908910528
(Previous) Eval Time (s)     19.01902115577832
Sample Time (s)              8.876810756511986
Epoch Time (s)               177.61182100139558
Total Train Time (s)         17587.467816260643
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:23:36.857015 UTC | [2020_01_11_02_30_29] Iteration #110 | Epoch Duration: 177.69628763198853
2020-01-11 07:23:36.857243 UTC | [2020_01_11_02_30_29] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015505274
Z variance train             0.0008019141
KL Divergence                15.535839
KL Loss                      1.553584
QF Loss                      354.6729
VF Loss                      267.7059
Policy Loss                  -1127.4065
Q Predictions Mean           1124.6018
Q Predictions Std            301.29434
Q Predictions Max            1493.1832
Q Predictions Min            7.293427
V Predictions Mean           1141.0713
V Predictions Std            301.9855
V Predictions Max            1510.4246
V Predictions Min            20.503864
Log Pis Mean                 0.16211075
Log Pis Std                  1.8618741
Log Pis Max                  6.611455
Log Pis Min                  -4.0241585
Policy mu Mean               0.17380881
Policy mu Std                0.9636585
Policy mu Max                2.5889132
Policy mu Min                -2.7593758
Policy log std Mean          -0.57405704
Policy log std Std           0.23380537
Policy log std Max           0.061040163
Policy log std Min           -1.9191868
Z mean eval                  0.01526898
Z variance eval              0.0008217076
total_rewards                [1181.85437625 3016.47447981 1178.05193173  967.18129912 1204.24976181
 1015.55376253 1452.31171847 2253.12108993 1060.39919224 1933.74859153]
total_rewards_mean           1526.294620344139
total_rewards_std            636.753669907936
total_rewards_max            3016.474479809289
total_rewards_min            967.1812991249681
Number of train steps total  448000
Number of env steps total    393133
Number of rollouts total     0
Train Time (s)               146.61411048285663
(Previous) Eval Time (s)     15.186515659093857
Sample Time (s)              8.407094068825245
Epoch Time (s)               170.20772021077573
Total Train Time (s)         17757.75730820559
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:26:27.148607 UTC | [2020_01_11_02_30_29] Iteration #111 | Epoch Duration: 170.29120659828186
2020-01-11 07:26:27.148802 UTC | [2020_01_11_02_30_29] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0151529135
Z variance train             0.00082087825
KL Divergence                15.53805
KL Loss                      1.553805
QF Loss                      182.88025
VF Loss                      165.67307
Policy Loss                  -1135.1733
Q Predictions Mean           1127.0997
Q Predictions Std            331.75024
Q Predictions Max            1497.9076
Q Predictions Min            29.533133
V Predictions Mean           1127.4465
V Predictions Std            328.13425
V Predictions Max            1481.1223
V Predictions Min            25.519997
Log Pis Mean                 0.31285048
Log Pis Std                  2.1432211
Log Pis Max                  9.1011715
Log Pis Min                  -6.1183133
Policy mu Mean               0.1294193
Policy mu Std                1.005885
Policy mu Max                3.05313
Policy mu Min                -2.6335964
Policy log std Mean          -0.60298103
Policy log std Std           0.24695109
Policy log std Max           0.26078916
Policy log std Min           -2.0960076
Z mean eval                  0.028359074
Z variance eval              0.0008885758
total_rewards                [3051.55884307 1235.59262398  712.19411557 3035.86393899 1133.09919576
 1862.20143116 1778.80659228 1624.61036703 1926.16429958  916.03183461]
total_rewards_mean           1727.612324203655
total_rewards_std            762.9148260534729
total_rewards_max            3051.5588430727075
total_rewards_min            712.1941155683124
Number of train steps total  452000
Number of env steps total    397262
Number of rollouts total     0
Train Time (s)               139.2355621419847
(Previous) Eval Time (s)     17.15675731515512
Sample Time (s)              9.06818145653233
Epoch Time (s)               165.46050091367215
Total Train Time (s)         17923.29770960333
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:29:12.691269 UTC | [2020_01_11_02_30_29] Iteration #112 | Epoch Duration: 165.5423035621643
2020-01-11 07:29:12.691487 UTC | [2020_01_11_02_30_29] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02854693
Z variance train             0.0008888266
KL Divergence                15.406959
KL Loss                      1.5406959
QF Loss                      382.29382
VF Loss                      86.67772
Policy Loss                  -1110.7429
Q Predictions Mean           1097.033
Q Predictions Std            354.91782
Q Predictions Max            1550.8322
Q Predictions Min            13.378464
V Predictions Mean           1106.2787
V Predictions Std            348.1009
V Predictions Max            1551.6497
V Predictions Min            12.99805
Log Pis Mean                 0.3906133
Log Pis Std                  2.3273501
Log Pis Max                  8.545973
Log Pis Min                  -5.5511303
Policy mu Mean               0.06642569
Policy mu Std                1.0128404
Policy mu Max                2.4126918
Policy mu Min                -3.0112202
Policy log std Mean          -0.5979236
Policy log std Std           0.24537778
Policy log std Max           0.15129828
Policy log std Min           -2.1958485
Z mean eval                  0.009221194
Z variance eval              0.0009515524
total_rewards                [ 992.76610593  968.41931745  909.15981422  732.82262291 1420.96825709
  773.84796876 1261.5168805   718.26537425 1018.80652963  744.3675111 ]
total_rewards_mean           954.0940381841353
total_rewards_std            223.92809859237005
total_rewards_max            1420.9682570930227
total_rewards_min            718.2653742547809
Number of train steps total  456000
Number of env steps total    401268
Number of rollouts total     0
Train Time (s)               140.23929825797677
(Previous) Eval Time (s)     9.261535100173205
Sample Time (s)              10.266545593738556
Epoch Time (s)               159.76737895188853
Total Train Time (s)         18083.154898297507
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:31:52.550693 UTC | [2020_01_11_02_30_29] Iteration #113 | Epoch Duration: 159.8590383529663
2020-01-11 07:31:52.550923 UTC | [2020_01_11_02_30_29] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009184313
Z variance train             0.0009515089
KL Divergence                15.192442
KL Loss                      1.5192442
QF Loss                      250.96463
VF Loss                      107.77775
Policy Loss                  -1119.773
Q Predictions Mean           1113.2483
Q Predictions Std            344.1616
Q Predictions Max            1518.9133
Q Predictions Min            -3.0876336
V Predictions Mean           1112.5344
V Predictions Std            336.79517
V Predictions Max            1513.8856
V Predictions Min            -2.594534
Log Pis Mean                 0.46179342
Log Pis Std                  2.3614974
Log Pis Max                  8.987861
Log Pis Min                  -5.014021
Policy mu Mean               0.08443967
Policy mu Std                1.0398489
Policy mu Max                2.8678946
Policy mu Min                -3.1230319
Policy log std Mean          -0.5907371
Policy log std Std           0.22725038
Policy log std Max           0.23971683
Policy log std Min           -1.5719924
Z mean eval                  0.007885603
Z variance eval              0.0012887397
total_rewards                [2085.68332558  719.59041563 1675.06518189 1187.68344716 1424.10805797
 2343.22424116  480.92431404 2059.19263837 1120.6165119   959.59608437]
total_rewards_mean           1405.568421805682
total_rewards_std            591.1892155708857
total_rewards_max            2343.224241159907
total_rewards_min            480.92431403880704
Number of train steps total  460000
Number of env steps total    405376
Number of rollouts total     0
Train Time (s)               140.24246572097763
(Previous) Eval Time (s)     14.697318569757044
Sample Time (s)              10.025917171966285
Epoch Time (s)               164.96570146270096
Total Train Time (s)         18248.1992995888
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:34:37.597268 UTC | [2020_01_11_02_30_29] Iteration #114 | Epoch Duration: 165.0461940765381
2020-01-11 07:34:37.597440 UTC | [2020_01_11_02_30_29] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008331932
Z variance train             0.0012891882
KL Divergence                14.188927
KL Loss                      1.4188927
QF Loss                      316.54358
VF Loss                      123.725296
Policy Loss                  -1116.2626
Q Predictions Mean           1117.5151
Q Predictions Std            334.58078
Q Predictions Max            1493.7982
Q Predictions Min            0.371984
V Predictions Mean           1116.6072
V Predictions Std            332.93387
V Predictions Max            1509.236
V Predictions Min            -22.79777
Log Pis Mean                 0.36449203
Log Pis Std                  2.3494108
Log Pis Max                  9.15442
Log Pis Min                  -5.339925
Policy mu Mean               0.10151473
Policy mu Std                0.9693126
Policy mu Max                3.1921108
Policy mu Min                -2.7977226
Policy log std Mean          -0.58132416
Policy log std Std           0.26476052
Policy log std Max           0.39386207
Policy log std Min           -2.4204216
Z mean eval                  0.025152493
Z variance eval              0.0009485202
total_rewards                [ 856.87333203 1984.10763466  937.79130313 1448.64155697 2972.11732387
 1249.88463344 1973.4128663  1236.45998142 1034.67848565 2243.47790661]
total_rewards_mean           1593.7445024094586
total_rewards_std            645.8600319507923
total_rewards_max            2972.1173238719316
total_rewards_min            856.8733320326236
Number of train steps total  464000
Number of env steps total    409647
Number of rollouts total     0
Train Time (s)               141.172486953903
(Previous) Eval Time (s)     15.065003877971321
Sample Time (s)              10.52172822970897
Epoch Time (s)               166.75921906158328
Total Train Time (s)         18415.036034956574
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:37:24.436500 UTC | [2020_01_11_02_30_29] Iteration #115 | Epoch Duration: 166.83892154693604
2020-01-11 07:37:24.436681 UTC | [2020_01_11_02_30_29] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02463202
Z variance train             0.0009492246
KL Divergence                15.070181
KL Loss                      1.5070181
QF Loss                      383.7691
VF Loss                      94.00833
Policy Loss                  -1127.708
Q Predictions Mean           1126.7102
Q Predictions Std            335.7239
Q Predictions Max            1547.2285
Q Predictions Min            -33.38267
V Predictions Mean           1126.1418
V Predictions Std            330.9747
V Predictions Max            1524.9257
V Predictions Min            -19.302137
Log Pis Mean                 0.28941065
Log Pis Std                  2.1152625
Log Pis Max                  7.800603
Log Pis Min                  -6.0600643
Policy mu Mean               -0.043088447
Policy mu Std                0.9867549
Policy mu Max                2.4747033
Policy mu Min                -2.6814895
Policy log std Mean          -0.5739646
Policy log std Std           0.24844213
Policy log std Max           0.46344936
Policy log std Min           -1.7217383
Z mean eval                  0.017167935
Z variance eval              0.00097183057
total_rewards                [1667.66715699 2433.72410979 1050.77664155  958.66199694 2598.33373426
  805.14195171 2762.93219187 1132.40996295 1989.57185173  982.0257951 ]
total_rewards_mean           1638.1245392886512
total_rewards_std            716.3295537089317
total_rewards_max            2762.9321918687324
total_rewards_min            805.1419517074424
Number of train steps total  468000
Number of env steps total    413753
Number of rollouts total     0
Train Time (s)               140.46187692740932
(Previous) Eval Time (s)     16.405949358362705
Sample Time (s)              10.261132725980133
Epoch Time (s)               167.12895901175216
Total Train Time (s)         18582.243836184498
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:40:11.645902 UTC | [2020_01_11_02_30_29] Iteration #116 | Epoch Duration: 167.20908546447754
2020-01-11 07:40:11.646071 UTC | [2020_01_11_02_30_29] Iteration #116 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017305134
Z variance train             0.00097162265
KL Divergence                14.93526
KL Loss                      1.493526
QF Loss                      190.78796
VF Loss                      177.93745
Policy Loss                  -1079.1292
Q Predictions Mean           1074.6406
Q Predictions Std            348.1834
Q Predictions Max            1497.4672
Q Predictions Min            7.7142386
V Predictions Mean           1076.0024
V Predictions Std            343.14166
V Predictions Max            1497.5905
V Predictions Min            5.70399
Log Pis Mean                 0.68615115
Log Pis Std                  2.5717854
Log Pis Max                  13.888285
Log Pis Min                  -5.158338
Policy mu Mean               0.027752092
Policy mu Std                1.0826851
Policy mu Max                3.6190495
Policy mu Min                -3.5593514
Policy log std Mean          -0.5832272
Policy log std Std           0.26339844
Policy log std Max           0.52638376
Policy log std Min           -2.6514583
Z mean eval                  0.020752575
Z variance eval              0.00082504546
total_rewards                [ 894.66014039  984.50577328 1504.15879104  994.88793221  990.9733987
 1535.78115162  976.67373976 3009.4448799   726.17533465 1740.49023586]
total_rewards_mean           1335.7751377420022
total_rewards_std            639.2926437997746
total_rewards_max            3009.4448799037605
total_rewards_min            726.1753346505989
Number of train steps total  472000
Number of env steps total    417805
Number of rollouts total     0
Train Time (s)               140.55737448716536
(Previous) Eval Time (s)     14.169080507941544
Sample Time (s)              10.019907877314836
Epoch Time (s)               164.74636287242174
Total Train Time (s)         18747.07958922442
Epoch                        117
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:42:56.483820 UTC | [2020_01_11_02_30_29] Iteration #117 | Epoch Duration: 164.83761882781982
2020-01-11 07:42:56.483999 UTC | [2020_01_11_02_30_29] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020865856
Z variance train             0.00082502107
KL Divergence                15.445344
KL Loss                      1.5445344
QF Loss                      216.22786
VF Loss                      71.51429
Policy Loss                  -1085.6406
Q Predictions Mean           1083.9888
Q Predictions Std            339.57053
Q Predictions Max            1539.7665
Q Predictions Min            -19.513004
V Predictions Mean           1085.4346
V Predictions Std            336.92325
V Predictions Max            1538.6744
V Predictions Min            -31.648724
Log Pis Mean                 0.47497416
Log Pis Std                  2.5088706
Log Pis Max                  10.612953
Log Pis Min                  -4.9113674
Policy mu Mean               -0.010579874
Policy mu Std                1.0759962
Policy mu Max                2.7978547
Policy mu Min                -3.0649476
Policy log std Mean          -0.5810366
Policy log std Std           0.23473512
Policy log std Max           0.30320448
Policy log std Min           -1.636971
Z mean eval                  0.012412252
Z variance eval              0.00085389183
total_rewards                [ 794.83741386  729.89403222  371.09910602  850.50673697  629.62637055
 1883.01053954 1922.1819706  1439.66044331  626.06692559  371.97144232]
total_rewards_mean           961.8854980988181
total_rewards_std            548.9296204618045
total_rewards_max            1922.1819705968023
total_rewards_min            371.09910602307184
Number of train steps total  476000
Number of env steps total    421915
Number of rollouts total     0
Train Time (s)               138.91159912291914
(Previous) Eval Time (s)     9.829870108049363
Sample Time (s)              9.946102357469499
Epoch Time (s)               158.687571588438
Total Train Time (s)         18905.845890574157
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:45:35.252312 UTC | [2020_01_11_02_30_29] Iteration #118 | Epoch Duration: 158.76817202568054
2020-01-11 07:45:35.252483 UTC | [2020_01_11_02_30_29] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012997498
Z variance train             0.0008539172
KL Divergence                15.325867
KL Loss                      1.5325867
QF Loss                      174.64452
VF Loss                      226.34056
Policy Loss                  -1098.8285
Q Predictions Mean           1098.7887
Q Predictions Std            361.06207
Q Predictions Max            1543.3525
Q Predictions Min            -47.426178
V Predictions Mean           1103.3303
V Predictions Std            356.06448
V Predictions Max            1550.0767
V Predictions Min            -52.756836
Log Pis Mean                 0.13938
Log Pis Std                  2.3295166
Log Pis Max                  12.936522
Log Pis Min                  -6.19224
Policy mu Mean               -0.0560371
Policy mu Std                1.0184766
Policy mu Max                4.236071
Policy mu Min                -2.8803656
Policy log std Mean          -0.5537895
Policy log std Std           0.2369671
Policy log std Max           0.14889312
Policy log std Min           -2.1134286
Z mean eval                  0.021915322
Z variance eval              0.00086034666
total_rewards                [1181.99664202  862.93149856 1442.67867615 1156.40841335 1746.45271277
  879.53583113  779.71500411  979.56177877 1016.14443582 1560.8057734 ]
total_rewards_mean           1160.623076606774
total_rewards_std            308.18031304181795
total_rewards_max            1746.4527127703882
total_rewards_min            779.7150041068674
Number of train steps total  480000
Number of env steps total    426337
Number of rollouts total     0
Train Time (s)               140.0666081700474
(Previous) Eval Time (s)     12.206178203690797
Sample Time (s)              10.392936905846
Epoch Time (s)               162.6657232795842
Total Train Time (s)         19068.58944705315
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:48:17.997980 UTC | [2020_01_11_02_30_29] Iteration #119 | Epoch Duration: 162.74535489082336
2020-01-11 07:48:17.998171 UTC | [2020_01_11_02_30_29] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021627462
Z variance train             0.00086060783
KL Divergence                15.307621
KL Loss                      1.5307621
QF Loss                      267.76263
VF Loss                      259.86377
Policy Loss                  -1118.3137
Q Predictions Mean           1109.1108
Q Predictions Std            340.33096
Q Predictions Max            1497.8612
Q Predictions Min            -0.3210234
V Predictions Mean           1121.7312
V Predictions Std            330.33362
V Predictions Max            1499.291
V Predictions Min            43.90143
Log Pis Mean                 0.37903374
Log Pis Std                  2.4996169
Log Pis Max                  15.025437
Log Pis Min                  -5.361432
Policy mu Mean               0.09658593
Policy mu Std                1.0335045
Policy mu Max                4.132601
Policy mu Min                -2.6604233
Policy log std Mean          -0.5928907
Policy log std Std           0.2447877
Policy log std Max           0.27639335
Policy log std Min           -1.5474186
Z mean eval                  0.012550423
Z variance eval              0.0011697498
total_rewards                [3084.77298727 1103.55143479 1129.80105438 1186.84544627 1106.48579042
  892.12581574  913.44958862 1120.75605834 1410.55575673 1333.35989387]
total_rewards_mean           1328.170382643057
total_rewards_std            604.6930422051959
total_rewards_max            3084.772987270143
total_rewards_min            892.1258157422224
Number of train steps total  484000
Number of env steps total    430566
Number of rollouts total     0
Train Time (s)               139.49300179025158
(Previous) Eval Time (s)     11.956757991109043
Sample Time (s)              9.27927247621119
Epoch Time (s)               160.72903225757182
Total Train Time (s)         19229.69094362203
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:50:59.101906 UTC | [2020_01_11_02_30_29] Iteration #120 | Epoch Duration: 161.10354447364807
2020-01-11 07:50:59.102167 UTC | [2020_01_11_02_30_29] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012839103
Z variance train             0.0011706878
KL Divergence                14.512515
KL Loss                      1.4512515
QF Loss                      4197.295
VF Loss                      64.0882
Policy Loss                  -1129.9595
Q Predictions Mean           1125.1691
Q Predictions Std            321.97595
Q Predictions Max            1517.1616
Q Predictions Min            -7.3822737
V Predictions Mean           1131.7031
V Predictions Std            316.97427
V Predictions Max            1514.3085
V Predictions Min            -26.987589
Log Pis Mean                 0.57466656
Log Pis Std                  2.44611
Log Pis Max                  16.007679
Log Pis Min                  -5.288535
Policy mu Mean               0.23974268
Policy mu Std                1.0034161
Policy mu Max                4.6835523
Policy mu Min                -3.2258008
Policy log std Mean          -0.5979218
Policy log std Std           0.28626683
Policy log std Max           0.54194784
Policy log std Min           -3.6509764
Z mean eval                  0.01687088
Z variance eval              0.0010699454
total_rewards                [3135.94409534 1624.58228373 1398.35888281 2937.0966432  3129.58049682
  942.27746877  903.70385713 1412.90486538  783.18510004 1847.62154706]
total_rewards_mean           1811.525524030137
total_rewards_std            880.984449158812
total_rewards_max            3135.9440953387552
total_rewards_min            783.1851000438629
Number of train steps total  488000
Number of env steps total    434875
Number of rollouts total     0
Train Time (s)               140.30525485705584
(Previous) Eval Time (s)     18.01164991594851
Sample Time (s)              10.02480619540438
Epoch Time (s)               168.34171096840873
Total Train Time (s)         19398.11310240114
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:53:47.526081 UTC | [2020_01_11_02_30_29] Iteration #121 | Epoch Duration: 168.42372632026672
2020-01-11 07:53:47.526300 UTC | [2020_01_11_02_30_29] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016963694
Z variance train             0.0010696198
KL Divergence                14.801624
KL Loss                      1.4801625
QF Loss                      137.93085
VF Loss                      105.4701
Policy Loss                  -1141.5117
Q Predictions Mean           1136.5956
Q Predictions Std            334.88535
Q Predictions Max            1508.1624
Q Predictions Min            24.241827
V Predictions Mean           1139.0459
V Predictions Std            324.12418
V Predictions Max            1510.8727
V Predictions Min            20.90223
Log Pis Mean                 0.5182874
Log Pis Std                  2.4504278
Log Pis Max                  11.432848
Log Pis Min                  -4.9255085
Policy mu Mean               0.030219316
Policy mu Std                1.004688
Policy mu Max                3.1125972
Policy mu Min                -2.8563335
Policy log std Mean          -0.60804874
Policy log std Std           0.2626881
Policy log std Max           0.26223153
Policy log std Min           -3.091886
Z mean eval                  0.019090272
Z variance eval              0.0011068418
total_rewards                [ 869.45237358  869.26596175 1794.81282581  954.27595037 1462.60212956
  863.39087404  860.09745846  959.06562083 1161.2516804  1181.70065864]
total_rewards_mean           1097.591553342726
total_rewards_std            297.5969484623635
total_rewards_max            1794.8128258069328
total_rewards_min            860.097458458974
Number of train steps total  492000
Number of env steps total    439133
Number of rollouts total     0
Train Time (s)               140.88117629196495
(Previous) Eval Time (s)     10.631522063631564
Sample Time (s)              9.5246840598993
Epoch Time (s)               161.0373824154958
Total Train Time (s)         19559.227523047477
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:56:28.642605 UTC | [2020_01_11_02_30_29] Iteration #122 | Epoch Duration: 161.11613130569458
2020-01-11 07:56:28.642857 UTC | [2020_01_11_02_30_29] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019183923
Z variance train             0.0011053723
KL Divergence                15.039907
KL Loss                      1.5039908
QF Loss                      494.8416
VF Loss                      83.03173
Policy Loss                  -1123.189
Q Predictions Mean           1115.0144
Q Predictions Std            357.06012
Q Predictions Max            1502.8627
Q Predictions Min            8.260422
V Predictions Mean           1118.5552
V Predictions Std            354.2796
V Predictions Max            1507.0546
V Predictions Min            -8.624498
Log Pis Mean                 0.15853962
Log Pis Std                  2.2194214
Log Pis Max                  10.527069
Log Pis Min                  -6.8228436
Policy mu Mean               0.12932642
Policy mu Std                0.97505367
Policy mu Max                3.5743687
Policy mu Min                -3.0490136
Policy log std Mean          -0.59319484
Policy log std Std           0.2298385
Policy log std Max           0.01986599
Policy log std Min           -1.8726983
Z mean eval                  0.023675364
Z variance eval              0.0010590935
total_rewards                [ 795.42115893  828.52941387  697.8815749  1100.96977358  849.93934913
  892.49706872  877.89194496  783.33099605  864.79198638 1705.58907888]
total_rewards_mean           939.6842345411499
total_rewards_std            273.5714267225676
total_rewards_max            1705.5890788836348
total_rewards_min            697.8815748962784
Number of train steps total  496000
Number of env steps total    443461
Number of rollouts total     0
Train Time (s)               139.30509101133794
(Previous) Eval Time (s)     9.147581864148378
Sample Time (s)              10.170348771847785
Epoch Time (s)               158.6230216473341
Total Train Time (s)         19717.93396660406
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:59:07.351628 UTC | [2020_01_11_02_30_29] Iteration #123 | Epoch Duration: 158.7085907459259
2020-01-11 07:59:07.351848 UTC | [2020_01_11_02_30_29] Iteration #123 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023701573
Z variance train             0.0010598735
KL Divergence                14.918924
KL Loss                      1.4918925
QF Loss                      512.6847
VF Loss                      1891.6196
Policy Loss                  -1129.3538
Q Predictions Mean           1117.6089
Q Predictions Std            350.35202
Q Predictions Max            1527.7487
Q Predictions Min            -18.290693
V Predictions Mean           1124.4109
V Predictions Std            334.88922
V Predictions Max            1530.6617
V Predictions Min            36.324337
Log Pis Mean                 0.328216
Log Pis Std                  2.457963
Log Pis Max                  11.445877
Log Pis Min                  -4.4272404
Policy mu Mean               -0.022225538
Policy mu Std                1.0028974
Policy mu Max                3.4782736
Policy mu Min                -2.982692
Policy log std Mean          -0.5905509
Policy log std Std           0.24650866
Policy log std Max           0.26787144
Policy log std Min           -2.2218664
Z mean eval                  0.010510484
Z variance eval              0.0012309116
total_rewards                [ 709.45614177 1041.68251768 2316.76500759  764.30693138 1677.2579449
  820.31791042  843.19631829 1187.62995251 1956.90895413  783.98541444]
total_rewards_mean           1210.1507093112925
total_rewards_std            542.8659766444665
total_rewards_max            2316.76500758724
total_rewards_min            709.4561417691139
Number of train steps total  500000
Number of env steps total    447731
Number of rollouts total     0
Train Time (s)               139.49772253632545
(Previous) Eval Time (s)     12.496802824083716
Sample Time (s)              10.172199268359691
Epoch Time (s)               162.16672462876886
Total Train Time (s)         19880.45517241163
Epoch                        124
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:01:49.874569 UTC | [2020_01_11_02_30_29] Iteration #124 | Epoch Duration: 162.52256059646606
2020-01-11 08:01:49.874774 UTC | [2020_01_11_02_30_29] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012099216
Z variance train             0.0012300864
KL Divergence                14.545448
KL Loss                      1.4545449
QF Loss                      251.95639
VF Loss                      531.01843
Policy Loss                  -1143.8895
Q Predictions Mean           1139.4719
Q Predictions Std            330.41064
Q Predictions Max            1542.5957
Q Predictions Min            21.47255
V Predictions Mean           1141.7576
V Predictions Std            320.54605
V Predictions Max            1528.3115
V Predictions Min            18.46525
Log Pis Mean                 0.5908887
Log Pis Std                  2.5141413
Log Pis Max                  11.938213
Log Pis Min                  -5.017335
Policy mu Mean               0.04347119
Policy mu Std                1.0527167
Policy mu Max                4.573772
Policy mu Min                -2.6164603
Policy log std Mean          -0.6012637
Policy log std Std           0.3040262
Policy log std Max           0.1875366
Policy log std Min           -3.7665694
Z mean eval                  0.038488712
Z variance eval              0.001017251
total_rewards                [ 629.93777329 1070.11513609  696.4834896   775.10189042 1131.68949187
  649.79157808  964.56752555 1167.88312564  957.71916026  805.29497061]
total_rewards_mean           884.8584141405843
total_rewards_std            190.02993207176982
total_rewards_max            1167.883125639939
total_rewards_min            629.9377732888723
Number of train steps total  504000
Number of env steps total    451958
Number of rollouts total     0
Train Time (s)               140.2362144398503
(Previous) Eval Time (s)     8.696945968084037
Sample Time (s)              9.30679492559284
Epoch Time (s)               158.23995533352718
Total Train Time (s)         20038.790874326136
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:04:28.212996 UTC | [2020_01_11_02_30_29] Iteration #125 | Epoch Duration: 158.3380331993103
2020-01-11 08:04:28.213262 UTC | [2020_01_11_02_30_29] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038753927
Z variance train             0.0010176195
KL Divergence                14.900828
KL Loss                      1.4900829
QF Loss                      215.77728
VF Loss                      92.88412
Policy Loss                  -1091.5035
Q Predictions Mean           1085.3997
Q Predictions Std            372.9655
Q Predictions Max            1522.158
Q Predictions Min            22.428267
V Predictions Mean           1086.979
V Predictions Std            370.04178
V Predictions Max            1507.7174
V Predictions Min            23.44666
Log Pis Mean                 0.31327057
Log Pis Std                  2.1019773
Log Pis Max                  6.910595
Log Pis Min                  -6.8804827
Policy mu Mean               0.048962634
Policy mu Std                0.99924225
Policy mu Max                2.294844
Policy mu Min                -2.730329
Policy log std Mean          -0.5764324
Policy log std Std           0.2391421
Policy log std Max           0.20647651
Policy log std Min           -1.528049
Z mean eval                  0.028030807
Z variance eval              0.0011415747
total_rewards                [2760.701855   1471.18580169 2781.39530858 1666.32292403 2787.56475075
 1685.78162927 1722.60314186  908.36684389 1031.9137942  3082.90326333]
total_rewards_mean           1989.8739312611876
total_rewards_std            753.4374015334646
total_rewards_max            3082.9032633331394
total_rewards_min            908.366843893092
Number of train steps total  508000
Number of env steps total    456261
Number of rollouts total     0
Train Time (s)               140.49433793127537
(Previous) Eval Time (s)     20.821640260051936
Sample Time (s)              10.191639019176364
Epoch Time (s)               171.50761721050367
Total Train Time (s)         20210.39812544454
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:07:19.822343 UTC | [2020_01_11_02_30_29] Iteration #126 | Epoch Duration: 171.60885334014893
2020-01-11 08:07:19.822565 UTC | [2020_01_11_02_30_29] Iteration #126 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027928274
Z variance train             0.0011419288
KL Divergence                14.713461
KL Loss                      1.4713461
QF Loss                      234.83551
VF Loss                      88.825745
Policy Loss                  -1139.9506
Q Predictions Mean           1137.0613
Q Predictions Std            317.22015
Q Predictions Max            1522.1444
Q Predictions Min            70.896225
V Predictions Mean           1138.1438
V Predictions Std            314.36923
V Predictions Max            1504.6924
V Predictions Min            67.25106
Log Pis Mean                 0.4919719
Log Pis Std                  2.2870088
Log Pis Max                  7.4368973
Log Pis Min                  -4.1368585
Policy mu Mean               -0.05486219
Policy mu Std                1.0791968
Policy mu Max                2.678823
Policy mu Min                -2.570404
Policy log std Mean          -0.5788467
Policy log std Std           0.23129134
Policy log std Max           0.11974627
Policy log std Min           -2.3642304
Z mean eval                  0.030377466
Z variance eval              0.0010711199
total_rewards                [ 734.30403945 1413.91816599  985.77658764  903.72329874  880.0272791
 1053.82202944  920.59914684 2323.92485048  802.31923797  810.09496021]
total_rewards_mean           1082.8509595866751
total_rewards_std            451.02823224681856
total_rewards_max            2323.924850479308
total_rewards_min            734.3040394531748
Number of train steps total  512000
Number of env steps total    460584
Number of rollouts total     0
Train Time (s)               145.9772958829999
(Previous) Eval Time (s)     11.301143513061106
Sample Time (s)              9.869285142980516
Epoch Time (s)               167.14772453904152
Total Train Time (s)         20377.62633455405
Epoch                        127
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:10:07.052925 UTC | [2020_01_11_02_30_29] Iteration #127 | Epoch Duration: 167.23019337654114
2020-01-11 08:10:07.053127 UTC | [2020_01_11_02_30_29] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029736876
Z variance train             0.001072235
KL Divergence                14.85872
KL Loss                      1.485872
QF Loss                      320.90094
VF Loss                      322.5379
Policy Loss                  -1113.1163
Q Predictions Mean           1109.8479
Q Predictions Std            340.79926
Q Predictions Max            1528.4762
Q Predictions Min            -22.44586
V Predictions Mean           1126.2107
V Predictions Std            337.79633
V Predictions Max            1533.8295
V Predictions Min            -11.842815
Log Pis Mean                 0.522303
Log Pis Std                  2.1599503
Log Pis Max                  8.820848
Log Pis Min                  -4.745637
Policy mu Mean               0.10623547
Policy mu Std                1.0249453
Policy mu Max                3.2852604
Policy mu Min                -2.484987
Policy log std Mean          -0.62072706
Policy log std Std           0.2840115
Policy log std Max           0.1418302
Policy log std Min           -2.9411137
Z mean eval                  0.021667972
Z variance eval              0.0010965137
total_rewards                [ 996.06568391 1011.7013379  1013.1821422  2760.66954123 1410.25825723
  925.07997889  771.64825176  714.81337343  911.8323475  1483.73405321]
total_rewards_mean           1199.8984967276708
total_rewards_std            570.0756319799063
total_rewards_max            2760.6695412318472
total_rewards_min            714.8133734328649
Number of train steps total  516000
Number of env steps total    464967
Number of rollouts total     0
Train Time (s)               149.4264877717942
(Previous) Eval Time (s)     12.48998795915395
Sample Time (s)              10.089338952675462
Epoch Time (s)               172.0058146836236
Total Train Time (s)         20549.709864543285
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:12:59.138360 UTC | [2020_01_11_02_30_29] Iteration #128 | Epoch Duration: 172.08508825302124
2020-01-11 08:12:59.138546 UTC | [2020_01_11_02_30_29] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02127619
Z variance train             0.001096753
KL Divergence                14.67511
KL Loss                      1.467511
QF Loss                      255.42924
VF Loss                      99.40993
Policy Loss                  -1131.708
Q Predictions Mean           1133.0444
Q Predictions Std            334.27332
Q Predictions Max            1554.5123
Q Predictions Min            -4.8405247
V Predictions Mean           1134.7211
V Predictions Std            336.1786
V Predictions Max            1557.3978
V Predictions Min            -17.876167
Log Pis Mean                 0.32072178
Log Pis Std                  2.1937613
Log Pis Max                  9.096193
Log Pis Min                  -5.1994605
Policy mu Mean               -0.022473967
Policy mu Std                1.0177444
Policy mu Max                2.6315408
Policy mu Min                -2.8497865
Policy log std Mean          -0.58836794
Policy log std Std           0.20527466
Policy log std Max           0.05431074
Policy log std Min           -1.2940792
Z mean eval                  0.015426812
Z variance eval              0.0010243206
total_rewards                [1611.2885754   900.69358773 1383.71723927 1594.58206583  912.17218379
 1106.11410692 1692.39763977  948.87049738  836.85154193  746.59589344]
total_rewards_mean           1173.3283331474768
total_rewards_std            342.886108659442
total_rewards_max            1692.3976397672463
total_rewards_min            746.5958934423298
Number of train steps total  520000
Number of env steps total    469301
Number of rollouts total     0
Train Time (s)               148.9915031278506
(Previous) Eval Time (s)     12.487663992214948
Sample Time (s)              10.357971449848264
Epoch Time (s)               171.8371385699138
Total Train Time (s)         20721.626007474493
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:15:51.056711 UTC | [2020_01_11_02_30_29] Iteration #129 | Epoch Duration: 171.91802048683167
2020-01-11 08:15:51.056895 UTC | [2020_01_11_02_30_29] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015655119
Z variance train             0.0010244728
KL Divergence                14.994921
KL Loss                      1.499492
QF Loss                      243.91307
VF Loss                      129.44012
Policy Loss                  -1138.6631
Q Predictions Mean           1131.6367
Q Predictions Std            334.39886
Q Predictions Max            1534.7163
Q Predictions Min            14.288412
V Predictions Mean           1133.536
V Predictions Std            323.73438
V Predictions Max            1528.757
V Predictions Min            19.939722
Log Pis Mean                 0.5823045
Log Pis Std                  2.3521187
Log Pis Max                  13.512504
Log Pis Min                  -4.1531672
Policy mu Mean               0.035510805
Policy mu Std                1.0242717
Policy mu Max                3.3838933
Policy mu Min                -2.8457131
Policy log std Mean          -0.62046176
Policy log std Std           0.22761427
Policy log std Max           0.055608332
Policy log std Min           -1.9091808
Z mean eval                  0.016566921
Z variance eval              0.0010029699
total_rewards                [1071.77755887  698.73395421  861.90939542  874.51786497  883.88566094
 1134.31848232  796.54353342  808.64049687  825.92054907  914.45721273]
total_rewards_mean           887.0704708822719
total_rewards_std            122.61951535873078
total_rewards_max            1134.318482322352
total_rewards_min            698.7339542115353
Number of train steps total  524000
Number of env steps total    473585
Number of rollouts total     0
Train Time (s)               150.40959742572159
(Previous) Eval Time (s)     9.359233822207898
Sample Time (s)              10.319907748140395
Epoch Time (s)               170.08873899606988
Total Train Time (s)         20891.798947331496
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:18:41.232170 UTC | [2020_01_11_02_30_29] Iteration #130 | Epoch Duration: 170.1751217842102
2020-01-11 08:18:41.232386 UTC | [2020_01_11_02_30_29] Iteration #130 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016864063
Z variance train             0.0010036868
KL Divergence                15.034899
KL Loss                      1.5034899
QF Loss                      903.5708
VF Loss                      256.78738
Policy Loss                  -1124.5687
Q Predictions Mean           1110.5632
Q Predictions Std            375.30377
Q Predictions Max            1568.486
Q Predictions Min            -18.034767
V Predictions Mean           1132.6484
V Predictions Std            360.4509
V Predictions Max            1575.9105
V Predictions Min            -26.674152
Log Pis Mean                 0.69967675
Log Pis Std                  2.2022014
Log Pis Max                  8.875393
Log Pis Min                  -5.348793
Policy mu Mean               0.031236673
Policy mu Std                1.0590954
Policy mu Max                3.3807425
Policy mu Min                -2.6802032
Policy log std Mean          -0.63024884
Policy log std Std           0.23289233
Policy log std Max           0.09978354
Policy log std Min           -3.6022995
Z mean eval                  0.024059778
Z variance eval              0.0009858598
total_rewards                [1744.64191583  918.5736577   654.17281491  665.56897809 1448.1968493
  849.36116685  638.93136135  647.896643    952.40281315  643.97603886]
total_rewards_mean           916.3722239057539
total_rewards_std            364.6319645555736
total_rewards_max            1744.6419158334204
total_rewards_min            638.931361354884
Number of train steps total  528000
Number of env steps total    477843
Number of rollouts total     0
Train Time (s)               149.37558391690254
(Previous) Eval Time (s)     9.35232017794624
Sample Time (s)              9.825626318808645
Epoch Time (s)               168.55353041365743
Total Train Time (s)         21060.43128280854
Epoch                        131
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:21:29.866693 UTC | [2020_01_11_02_30_29] Iteration #131 | Epoch Duration: 168.63414311408997
2020-01-11 08:21:29.866902 UTC | [2020_01_11_02_30_29] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024286097
Z variance train             0.0009859381
KL Divergence                14.8396225
KL Loss                      1.4839623
QF Loss                      428.98483
VF Loss                      131.91116
Policy Loss                  -1170.694
Q Predictions Mean           1159.5159
Q Predictions Std            302.2512
Q Predictions Max            1509.8939
Q Predictions Min            -1.0732036
V Predictions Mean           1166.953
V Predictions Std            296.94208
V Predictions Max            1517.7772
V Predictions Min            -22.09129
Log Pis Mean                 0.4370006
Log Pis Std                  2.2603276
Log Pis Max                  10.8135605
Log Pis Min                  -4.1549416
Policy mu Mean               0.028463734
Policy mu Std                1.0230361
Policy mu Max                3.9185362
Policy mu Min                -2.7313392
Policy log std Mean          -0.58321315
Policy log std Std           0.24874356
Policy log std Max           0.19278646
Policy log std Min           -3.3457239
Z mean eval                  0.027222335
Z variance eval              0.0009641965
total_rewards                [1875.28663233 2743.27753228 2038.01447146  911.60326948 1516.06686238
 2205.09667576  867.93972712 1549.836511   1365.59295854  858.47744059]
total_rewards_mean           1593.1192080926007
total_rewards_std            597.0391338210924
total_rewards_max            2743.2775322767448
total_rewards_min            858.4774405924126
Number of train steps total  532000
Number of env steps total    482168
Number of rollouts total     0
Train Time (s)               140.24438672699034
(Previous) Eval Time (s)     15.799705849029124
Sample Time (s)              9.900173705536872
Epoch Time (s)               165.94426628155634
Total Train Time (s)         21226.673694314435
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:24:16.111281 UTC | [2020_01_11_02_30_29] Iteration #132 | Epoch Duration: 166.24423146247864
2020-01-11 08:24:16.111511 UTC | [2020_01_11_02_30_29] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027791563
Z variance train             0.00096417684
KL Divergence                14.975432
KL Loss                      1.4975432
QF Loss                      335.25757
VF Loss                      447.14233
Policy Loss                  -1125.8853
Q Predictions Mean           1123.4312
Q Predictions Std            372.22855
Q Predictions Max            1530.9104
Q Predictions Min            -31.396015
V Predictions Mean           1124.0747
V Predictions Std            364.82007
V Predictions Max            1516.7023
V Predictions Min            -67.88205
Log Pis Mean                 0.3151621
Log Pis Std                  2.2283797
Log Pis Max                  7.9523983
Log Pis Min                  -5.096655
Policy mu Mean               -0.001996531
Policy mu Std                1.0046681
Policy mu Max                2.4565892
Policy mu Min                -2.5652707
Policy log std Mean          -0.59990734
Policy log std Std           0.22394957
Policy log std Max           0.18683445
Policy log std Min           -1.7038083
Z mean eval                  0.02695145
Z variance eval              0.00090167887
total_rewards                [ 943.77522091 1027.34359452  827.98281204  828.42970279  831.17909436
  832.45006596  820.28469081  910.18526679  744.53280878 1121.93290886]
total_rewards_mean           888.8096165822583
total_rewards_std            107.87541027858576
total_rewards_max            1121.9329088589384
total_rewards_min            744.5328087793987
Number of train steps total  536000
Number of env steps total    486401
Number of rollouts total     0
Train Time (s)               140.00093790283427
(Previous) Eval Time (s)     9.549167901277542
Sample Time (s)              9.968888408970088
Epoch Time (s)               159.5189942130819
Total Train Time (s)         21386.2758479747
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:26:55.715535 UTC | [2020_01_11_02_30_29] Iteration #133 | Epoch Duration: 159.60386085510254
2020-01-11 08:26:55.715890 UTC | [2020_01_11_02_30_29] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026909992
Z variance train             0.0009019777
KL Divergence                15.103734
KL Loss                      1.5103735
QF Loss                      694.9181
VF Loss                      63.02265
Policy Loss                  -1173.0454
Q Predictions Mean           1166.4043
Q Predictions Std            345.7561
Q Predictions Max            1547.2457
Q Predictions Min            24.563618
V Predictions Mean           1170.6976
V Predictions Std            339.58356
V Predictions Max            1544.303
V Predictions Min            34.55896
Log Pis Mean                 0.57581407
Log Pis Std                  2.1289525
Log Pis Max                  6.839485
Log Pis Min                  -4.761752
Policy mu Mean               0.013519258
Policy mu Std                1.0281556
Policy mu Max                3.353948
Policy mu Min                -3.0422213
Policy log std Mean          -0.6174163
Policy log std Std           0.22613025
Policy log std Max           0.4369653
Policy log std Min           -1.723568
Z mean eval                  0.025571857
Z variance eval              0.0008559561
total_rewards                [ 855.89990022 1161.18002351 1329.99848318 2407.1546522  2490.92273767
 1169.11603836 1183.23691342 2523.33276259  953.40843254 2575.47862708]
total_rewards_mean           1664.9728570784039
total_rewards_std            693.0880926007247
total_rewards_max            2575.478627078282
total_rewards_min            855.899900222204
Number of train steps total  540000
Number of env steps total    490909
Number of rollouts total     0
Train Time (s)               140.5240926798433
(Previous) Eval Time (s)     16.286545432172716
Sample Time (s)              10.257211243268102
Epoch Time (s)               167.06784935528412
Total Train Time (s)         21553.430934646167
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:29:42.872994 UTC | [2020_01_11_02_30_29] Iteration #134 | Epoch Duration: 167.1568796634674
2020-01-11 08:29:42.873202 UTC | [2020_01_11_02_30_29] Iteration #134 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025901627
Z variance train             0.00085622433
KL Divergence                15.222976
KL Loss                      1.5222976
QF Loss                      341.1846
VF Loss                      102.66162
Policy Loss                  -1123.3041
Q Predictions Mean           1118.7584
Q Predictions Std            361.31625
Q Predictions Max            1545.5325
Q Predictions Min            25.023773
V Predictions Mean           1119.9531
V Predictions Std            357.91608
V Predictions Max            1538.7146
V Predictions Min            30.751125
Log Pis Mean                 0.59704
Log Pis Std                  2.2478824
Log Pis Max                  8.826216
Log Pis Min                  -4.8196454
Policy mu Mean               -0.04011636
Policy mu Std                1.0442336
Policy mu Max                3.1069386
Policy mu Min                -2.8886104
Policy log std Mean          -0.5807843
Policy log std Std           0.2140791
Policy log std Max           0.069918334
Policy log std Min           -1.5818653
Z mean eval                  0.011722229
Z variance eval              0.0007235785
total_rewards                [858.5927942  906.48505597 870.19455817 867.86202679 926.0545497
 668.28856348 862.95336748 901.7703138  840.63738599 847.39438166]
total_rewards_mean           855.0232997217888
total_rewards_std            67.44232946674008
total_rewards_max            926.0545496980486
total_rewards_min            668.288563479698
Number of train steps total  544000
Number of env steps total    495196
Number of rollouts total     0
Train Time (s)               140.7849889099598
(Previous) Eval Time (s)     8.264230147004128
Sample Time (s)              9.039603393524885
Epoch Time (s)               158.0888224504888
Total Train Time (s)         21711.606022334192
Epoch                        135
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:32:21.050277 UTC | [2020_01_11_02_30_29] Iteration #135 | Epoch Duration: 158.1769199371338
2020-01-11 08:32:21.050470 UTC | [2020_01_11_02_30_29] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011524314
Z variance train             0.00072333706
KL Divergence                15.618885
KL Loss                      1.5618886
QF Loss                      363.5221
VF Loss                      163.25098
Policy Loss                  -1155.5804
Q Predictions Mean           1147.3162
Q Predictions Std            355.75674
Q Predictions Max            1553.1069
Q Predictions Min            -14.478963
V Predictions Mean           1161.0353
V Predictions Std            341.2176
V Predictions Max            1552.7239
V Predictions Min            -11.27706
Log Pis Mean                 0.64572835
Log Pis Std                  2.257329
Log Pis Max                  9.967382
Log Pis Min                  -5.3809366
Policy mu Mean               0.11602727
Policy mu Std                1.0109508
Policy mu Max                3.6257358
Policy mu Min                -2.5704074
Policy log std Mean          -0.6362037
Policy log std Std           0.274464
Policy log std Max           -0.057603598
Policy log std Min           -2.9889393
Z mean eval                  0.020343583
Z variance eval              0.00094089395
total_rewards                [ 727.10256763 2869.79183724 1976.28251439 1197.61331541  657.65395955
  988.56734604 1017.35347586  886.11683693 1356.06001646 1591.54524146]
total_rewards_mean           1326.8087110966196
total_rewards_std            640.4717245899764
total_rewards_max            2869.791837235047
total_rewards_min            657.6539595500656
Number of train steps total  548000
Number of env steps total    499558
Number of rollouts total     0
Train Time (s)               141.21565970778465
(Previous) Eval Time (s)     14.066926036961377
Sample Time (s)              9.803192131686956
Epoch Time (s)               165.08577787643299
Total Train Time (s)         21876.781093522906
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:35:06.229112 UTC | [2020_01_11_02_30_29] Iteration #136 | Epoch Duration: 165.17848372459412
2020-01-11 08:35:06.229333 UTC | [2020_01_11_02_30_29] Iteration #136 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019928653
Z variance train             0.00094088307
KL Divergence                15.0716095
KL Loss                      1.507161
QF Loss                      671.89355
VF Loss                      100.937195
Policy Loss                  -1138.7689
Q Predictions Mean           1135.3989
Q Predictions Std            355.34183
Q Predictions Max            1553.6277
Q Predictions Min            38.963223
V Predictions Mean           1136.6638
V Predictions Std            353.3747
V Predictions Max            1524.3859
V Predictions Min            27.044025
Log Pis Mean                 0.35638094
Log Pis Std                  2.2002463
Log Pis Max                  9.94314
Log Pis Min                  -4.7408776
Policy mu Mean               0.0659441
Policy mu Std                1.0024853
Policy mu Max                4.011846
Policy mu Min                -2.7947814
Policy log std Mean          -0.60910344
Policy log std Std           0.229824
Policy log std Max           0.21471518
Policy log std Min           -2.0765662
Z mean eval                  0.01748943
Z variance eval              0.000999061
total_rewards                [ 856.27055273  652.39972037  665.30129438  835.92640501  731.5263223
 1948.94228027  655.65376579  830.28072611  906.92853667  764.49798509]
total_rewards_mean           884.7727588722486
total_rewards_std            364.9282572937931
total_rewards_max            1948.9422802729184
total_rewards_min            652.3997203651911
Number of train steps total  552000
Number of env steps total    503870
Number of rollouts total     0
Train Time (s)               139.80552787939087
(Previous) Eval Time (s)     9.504475991707295
Sample Time (s)              10.378361871931702
Epoch Time (s)               159.68836574302986
Total Train Time (s)         22036.551541379187
Epoch                        137
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:37:46.000929 UTC | [2020_01_11_02_30_29] Iteration #137 | Epoch Duration: 159.77142190933228
2020-01-11 08:37:46.001128 UTC | [2020_01_11_02_30_29] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017544596
Z variance train             0.0009981559
KL Divergence                14.921298
KL Loss                      1.4921298
QF Loss                      168.53018
VF Loss                      80.318886
Policy Loss                  -1185.8013
Q Predictions Mean           1185.3756
Q Predictions Std            289.46793
Q Predictions Max            1588.4509
Q Predictions Min            17.851383
V Predictions Mean           1184.3251
V Predictions Std            284.82608
V Predictions Max            1584.4728
V Predictions Min            113.57817
Log Pis Mean                 0.28648016
Log Pis Std                  2.3884945
Log Pis Max                  10.619409
Log Pis Min                  -6.210336
Policy mu Mean               0.1328814
Policy mu Std                1.0242472
Policy mu Max                3.2578938
Policy mu Min                -3.8760393
Policy log std Mean          -0.5497615
Policy log std Std           0.22761613
Policy log std Max           0.2666058
Policy log std Min           -1.9847987
Z mean eval                  0.015319022
Z variance eval              0.00072900427
total_rewards                [1586.85423483 1124.06011167  807.38924132  875.97039722  839.27009597
  878.19243449  876.21853582  909.33563151 1738.87621401  846.00109989]
total_rewards_mean           1048.2167996725948
total_rewards_std            319.8263963127967
total_rewards_max            1738.8762140122697
total_rewards_min            807.3892413188861
Number of train steps total  556000
Number of env steps total    508192
Number of rollouts total     0
Train Time (s)               139.0229263342917
(Previous) Eval Time (s)     10.83803282212466
Sample Time (s)              10.124372348655015
Epoch Time (s)               159.98533150507137
Total Train Time (s)         22196.618538060226
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:40:26.070501 UTC | [2020_01_11_02_30_29] Iteration #138 | Epoch Duration: 160.0692172050476
2020-01-11 08:40:26.070742 UTC | [2020_01_11_02_30_29] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014843693
Z variance train             0.0007283208
KL Divergence                15.758621
KL Loss                      1.5758622
QF Loss                      213.42114
VF Loss                      117.425156
Policy Loss                  -1136.7004
Q Predictions Mean           1134.1992
Q Predictions Std            361.39655
Q Predictions Max            1606.2767
Q Predictions Min            5.68474
V Predictions Mean           1131.4634
V Predictions Std            360.25397
V Predictions Max            1604.9764
V Predictions Min            -3.3709996
Log Pis Mean                 0.57814395
Log Pis Std                  2.3587346
Log Pis Max                  11.111317
Log Pis Min                  -5.195316
Policy mu Mean               -0.025259903
Policy mu Std                1.0339804
Policy mu Max                2.36843
Policy mu Min                -3.6607482
Policy log std Mean          -0.58209825
Policy log std Std           0.22311594
Policy log std Max           0.08361852
Policy log std Min           -1.472057
Z mean eval                  0.020288639
Z variance eval              0.0009945069
total_rewards                [ 820.42683012  846.02444412  971.32886649 1413.61232829 1095.92810304
  863.79497192  958.26197972 1299.21102007  347.01908308  813.18187805]
total_rewards_mean           942.8789504883238
total_rewards_std            278.4838308118776
total_rewards_max            1413.6123282907852
total_rewards_min            347.0190830816789
Number of train steps total  560000
Number of env steps total    512449
Number of rollouts total     0
Train Time (s)               140.65888554789126
(Previous) Eval Time (s)     8.621555152349174
Sample Time (s)              8.76541282236576
Epoch Time (s)               158.0458535226062
Total Train Time (s)         22354.741156777833
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:43:04.194610 UTC | [2020_01_11_02_30_29] Iteration #139 | Epoch Duration: 158.1237154006958
2020-01-11 08:43:04.194824 UTC | [2020_01_11_02_30_29] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020121856
Z variance train             0.0009946662
KL Divergence                15.209407
KL Loss                      1.5209407
QF Loss                      252.24158
VF Loss                      113.297615
Policy Loss                  -1146.7817
Q Predictions Mean           1144.0718
Q Predictions Std            348.8204
Q Predictions Max            1565.3743
Q Predictions Min            45.20065
V Predictions Mean           1144.8584
V Predictions Std            346.27826
V Predictions Max            1564.6688
V Predictions Min            31.914436
Log Pis Mean                 0.39627934
Log Pis Std                  2.1024857
Log Pis Max                  8.701351
Log Pis Min                  -6.444931
Policy mu Mean               0.16991353
Policy mu Std                0.98361987
Policy mu Max                3.0261812
Policy mu Min                -2.6878123
Policy log std Mean          -0.58977556
Policy log std Std           0.23403464
Policy log std Max           0.24352038
Policy log std Min           -1.9345572
Z mean eval                  0.012645187
Z variance eval              0.0010558823
total_rewards                [ 661.72544497 1599.98379624  848.65616156  991.49916174 1510.14570674
  637.90463733  817.77016994  880.79147889 1007.73988757  633.62760022]
total_rewards_mean           958.9844045215234
total_rewards_std            324.5971932564491
total_rewards_max            1599.983796235182
total_rewards_min            633.627600224092
Number of train steps total  564000
Number of env steps total    516953
Number of rollouts total     0
Train Time (s)               140.34846932487562
(Previous) Eval Time (s)     8.610660038888454
Sample Time (s)              10.697050499729812
Epoch Time (s)               159.6561798634939
Total Train Time (s)         22514.481226714794
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:45:43.936991 UTC | [2020_01_11_02_30_29] Iteration #140 | Epoch Duration: 159.7420163154602
2020-01-11 08:45:43.937206 UTC | [2020_01_11_02_30_29] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012135173
Z variance train             0.0010551072
KL Divergence                14.908368
KL Loss                      1.4908369
QF Loss                      1066.4354
VF Loss                      252.09033
Policy Loss                  -1165.8828
Q Predictions Mean           1156.5208
Q Predictions Std            355.57736
Q Predictions Max            1601.4204
Q Predictions Min            -0.8209051
V Predictions Mean           1153.0236
V Predictions Std            342.98373
V Predictions Max            1571.7422
V Predictions Min            27.687487
Log Pis Mean                 0.42193338
Log Pis Std                  2.3488097
Log Pis Max                  8.789948
Log Pis Min                  -6.922466
Policy mu Mean               0.14335614
Policy mu Std                0.986061
Policy mu Max                3.406191
Policy mu Min                -2.5060594
Policy log std Mean          -0.5957207
Policy log std Std           0.27177855
Policy log std Max           0.36129016
Policy log std Min           -2.4311275
Z mean eval                  0.018224075
Z variance eval              0.0007719131
total_rewards                [ 624.38574028  591.25601343  875.48743518  628.89278209 1761.23570692
 2251.35635502  601.02712001 1488.70783303  655.37066021  855.05775675]
total_rewards_mean           1033.2777402932302
total_rewards_std            559.7742807724469
total_rewards_max            2251.3563550220165
total_rewards_min            591.2560134313418
Number of train steps total  568000
Number of env steps total    521327
Number of rollouts total     0
Train Time (s)               140.18366189394146
(Previous) Eval Time (s)     10.239883589092642
Sample Time (s)              10.112017791252583
Epoch Time (s)               160.5355632742867
Total Train Time (s)         22675.106176319532
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:48:24.564692 UTC | [2020_01_11_02_30_29] Iteration #141 | Epoch Duration: 160.6273274421692
2020-01-11 08:48:24.564889 UTC | [2020_01_11_02_30_29] Iteration #141 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0182431
Z variance train             0.0007715461
KL Divergence                15.730225
KL Loss                      1.5730225
QF Loss                      317.74652
VF Loss                      209.57347
Policy Loss                  -1143.0452
Q Predictions Mean           1141.6187
Q Predictions Std            370.15732
Q Predictions Max            1579.2167
Q Predictions Min            -7.274633
V Predictions Mean           1151.9496
V Predictions Std            369.89136
V Predictions Max            1576.1213
V Predictions Min            1.2371653
Log Pis Mean                 0.051537946
Log Pis Std                  2.2403326
Log Pis Max                  9.059881
Log Pis Min                  -5.8652887
Policy mu Mean               -0.050966155
Policy mu Std                0.9540991
Policy mu Max                2.5518425
Policy mu Min                -2.6840205
Policy log std Mean          -0.5605334
Policy log std Std           0.26340228
Policy log std Max           0.25015283
Policy log std Min           -2.7064564
Z mean eval                  0.02070617
Z variance eval              0.000962525
total_rewards                [618.62271445 622.1385035  673.28396874 874.17971591 939.80059578
 936.11144685 893.77941192 643.24016205 780.10661612 640.06290076]
total_rewards_mean           762.132603607304
total_rewards_std            130.0642138553707
total_rewards_max            939.8005957791273
total_rewards_min            618.6227144527742
Number of train steps total  572000
Number of env steps total    525765
Number of rollouts total     0
Train Time (s)               141.21363030886278
(Previous) Eval Time (s)     7.699293165933341
Sample Time (s)              10.227087376173586
Epoch Time (s)               159.1400108509697
Total Train Time (s)         22834.33499573404
Epoch                        142
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:51:03.795817 UTC | [2020_01_11_02_30_29] Iteration #142 | Epoch Duration: 159.23078155517578
2020-01-11 08:51:03.796006 UTC | [2020_01_11_02_30_29] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01830673
Z variance train             0.0009638454
KL Divergence                15.343036
KL Loss                      1.5343035
QF Loss                      501.8238
VF Loss                      189.54472
Policy Loss                  -1150.5913
Q Predictions Mean           1147.1866
Q Predictions Std            364.63696
Q Predictions Max            1596.4277
Q Predictions Min            36.102753
V Predictions Mean           1143.835
V Predictions Std            358.25253
V Predictions Max            1587.444
V Predictions Min            24.848902
Log Pis Mean                 0.53022134
Log Pis Std                  2.24611
Log Pis Max                  9.022293
Log Pis Min                  -4.919174
Policy mu Mean               0.021790633
Policy mu Std                1.0425602
Policy mu Max                3.6005108
Policy mu Min                -2.9445953
Policy log std Mean          -0.5979526
Policy log std Std           0.26956657
Policy log std Max           0.30521905
Policy log std Min           -2.440126
Z mean eval                  0.017124418
Z variance eval              0.0008443268
total_rewards                [1055.07329131  835.67672786  784.73082089  728.13625381 1881.61335971
  955.84993377  865.55160927  986.41030762  910.47447244  809.28641778]
total_rewards_mean           981.2803194472423
total_rewards_std            314.423367635247
total_rewards_max            1881.6133597090688
total_rewards_min            728.1362538125487
Number of train steps total  576000
Number of env steps total    530129
Number of rollouts total     0
Train Time (s)               139.45353229297325
(Previous) Eval Time (s)     10.36406868416816
Sample Time (s)              9.951710760127753
Epoch Time (s)               159.76931173726916
Total Train Time (s)         22994.18649509363
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:53:43.649696 UTC | [2020_01_11_02_30_29] Iteration #143 | Epoch Duration: 159.85354614257812
2020-01-11 08:53:43.649899 UTC | [2020_01_11_02_30_29] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01698765
Z variance train             0.0008441236
KL Divergence                15.516541
KL Loss                      1.5516541
QF Loss                      189.97433
VF Loss                      54.751472
Policy Loss                  -1181.5524
Q Predictions Mean           1174.4678
Q Predictions Std            345.10992
Q Predictions Max            1543.2767
Q Predictions Min            -42.972775
V Predictions Mean           1183.062
V Predictions Std            331.01318
V Predictions Max            1550.3573
V Predictions Min            -11.742842
Log Pis Mean                 0.46280807
Log Pis Std                  2.2382855
Log Pis Max                  7.626729
Log Pis Min                  -6.5874696
Policy mu Mean               -0.002080626
Policy mu Std                1.0040135
Policy mu Max                2.8215516
Policy mu Min                -2.524844
Policy log std Mean          -0.5885838
Policy log std Std           0.2603399
Policy log std Max           0.47084695
Policy log std Min           -3.1666896
Z mean eval                  0.013254812
Z variance eval              0.00083067955
total_rewards                [ 836.34316592  844.32481237  908.47173731  910.84511948  941.04697488
  855.47793002  841.77375246  840.81933566 1695.6650741   904.5771331 ]
total_rewards_mean           957.9345035307124
total_rewards_std            248.48356386103112
total_rewards_max            1695.6650741028845
total_rewards_min            836.3431659238986
Number of train steps total  580000
Number of env steps total    534560
Number of rollouts total     0
Train Time (s)               141.0292823780328
(Previous) Eval Time (s)     9.085765291005373
Sample Time (s)              9.144923761021346
Epoch Time (s)               159.25997143005952
Total Train Time (s)         23153.536570537835
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:56:23.000837 UTC | [2020_01_11_02_30_29] Iteration #144 | Epoch Duration: 159.35080790519714
2020-01-11 08:56:23.000969 UTC | [2020_01_11_02_30_29] Iteration #144 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013362196
Z variance train             0.0008309134
KL Divergence                15.352856
KL Loss                      1.5352856
QF Loss                      203.12967
VF Loss                      100.98604
Policy Loss                  -1164.9335
Q Predictions Mean           1161.4044
Q Predictions Std            349.67538
Q Predictions Max            1545.155
Q Predictions Min            0.95536464
V Predictions Mean           1164.16
V Predictions Std            339.6565
V Predictions Max            1541.1556
V Predictions Min            20.338385
Log Pis Mean                 0.40767282
Log Pis Std                  2.134083
Log Pis Max                  15.886673
Log Pis Min                  -4.7599874
Policy mu Mean               0.13737576
Policy mu Std                0.98832405
Policy mu Max                4.1559234
Policy mu Min                -2.6545436
Policy log std Mean          -0.59076047
Policy log std Std           0.23698309
Policy log std Max           0.04957956
Policy log std Min           -1.9490069
Z mean eval                  0.03706664
Z variance eval              0.0007995626
total_rewards                [2159.29859076 1020.36990773 2916.62126272 2362.95917397 1940.8987326
 1580.87337467  902.60771489 2994.74577147  689.91776754 1440.20947606]
total_rewards_mean           1800.850177240757
total_rewards_std            772.205185980026
total_rewards_max            2994.7457714693396
total_rewards_min            689.9177675382505
Number of train steps total  584000
Number of env steps total    538951
Number of rollouts total     0
Train Time (s)               140.28953515272588
(Previous) Eval Time (s)     18.47353412490338
Sample Time (s)              9.13217377802357
Epoch Time (s)               167.89524305565283
Total Train Time (s)         23321.511625282
Epoch                        145
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:59:10.978425 UTC | [2020_01_11_02_30_29] Iteration #145 | Epoch Duration: 167.97734761238098
2020-01-11 08:59:10.978611 UTC | [2020_01_11_02_30_29] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037056953
Z variance train             0.00079951796
KL Divergence                15.417997
KL Loss                      1.5417998
QF Loss                      168.69931
VF Loss                      102.792274
Policy Loss                  -1192.4504
Q Predictions Mean           1193.0513
Q Predictions Std            328.0551
Q Predictions Max            1607.6863
Q Predictions Min            -2.2564445
V Predictions Mean           1193.9327
V Predictions Std            324.19208
V Predictions Max            1608.0405
V Predictions Min            10.435317
Log Pis Mean                 0.15843403
Log Pis Std                  1.917355
Log Pis Max                  5.7784514
Log Pis Min                  -4.6814175
Policy mu Mean               -0.015984565
Policy mu Std                0.9347207
Policy mu Max                2.4939356
Policy mu Min                -2.6751313
Policy log std Mean          -0.6096056
Policy log std Std           0.21834388
Policy log std Max           0.292355
Policy log std Min           -1.6311622
Z mean eval                  0.026315028
Z variance eval              0.000782346
total_rewards                [1128.88165164 1368.15379579  772.32082427 1199.72231627  975.01156131
 2428.45634126 1381.34130607 1041.08958572 1239.26289512 1568.17043396]
total_rewards_mean           1310.2410711394205
total_rewards_std            430.07733579910166
total_rewards_max            2428.456341262505
total_rewards_min            772.320824266151
Number of train steps total  588000
Number of env steps total    543486
Number of rollouts total     0
Train Time (s)               141.0398239591159
(Previous) Eval Time (s)     14.702272130642086
Sample Time (s)              9.642251478973776
Epoch Time (s)               165.38434756873176
Total Train Time (s)         23486.986698912922
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:01:56.454647 UTC | [2020_01_11_02_30_29] Iteration #146 | Epoch Duration: 165.47590517997742
2020-01-11 09:01:56.454774 UTC | [2020_01_11_02_30_29] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026273686
Z variance train             0.0007828468
KL Divergence                15.705091
KL Loss                      1.5705092
QF Loss                      163.96558
VF Loss                      102.68109
Policy Loss                  -1152.0791
Q Predictions Mean           1148.8279
Q Predictions Std            337.44516
Q Predictions Max            1583.1511
Q Predictions Min            24.049923
V Predictions Mean           1156.991
V Predictions Std            337.55957
V Predictions Max            1591.2888
V Predictions Min            26.78574
Log Pis Mean                 0.2961564
Log Pis Std                  2.1219008
Log Pis Max                  10.962305
Log Pis Min                  -6.553793
Policy mu Mean               0.015485287
Policy mu Std                0.9372446
Policy mu Max                3.8193831
Policy mu Min                -2.7062268
Policy log std Mean          -0.6118424
Policy log std Std           0.21376537
Policy log std Max           0.013984084
Policy log std Min           -2.6749465
Z mean eval                  0.020880198
Z variance eval              0.0008196216
total_rewards                [1003.38630796 3093.00919445 2556.33271921 1604.25684715 3151.01430185
  950.89296558  962.83229217 3145.82747236 1973.44711902  884.61315381]
total_rewards_mean           1932.561237356001
total_rewards_std            930.9906893298818
total_rewards_max            3151.0143018486488
total_rewards_min            884.6131538100261
Number of train steps total  592000
Number of env steps total    547822
Number of rollouts total     0
Train Time (s)               146.3393983868882
(Previous) Eval Time (s)     19.612731128931046
Sample Time (s)              8.88393153063953
Epoch Time (s)               174.83606104645878
Total Train Time (s)         23661.911529161967
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:04:51.383714 UTC | [2020_01_11_02_30_29] Iteration #147 | Epoch Duration: 174.92879438400269
2020-01-11 09:04:51.384098 UTC | [2020_01_11_02_30_29] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021149926
Z variance train             0.0008196529
KL Divergence                15.358051
KL Loss                      1.5358051
QF Loss                      199.44379
VF Loss                      82.700676
Policy Loss                  -1181.4845
Q Predictions Mean           1177.8037
Q Predictions Std            343.7265
Q Predictions Max            1591.0687
Q Predictions Min            -28.731558
V Predictions Mean           1177.0066
V Predictions Std            340.4652
V Predictions Max            1573.8531
V Predictions Min            -35.075592
Log Pis Mean                 0.40188557
Log Pis Std                  2.173175
Log Pis Max                  8.140558
Log Pis Min                  -6.1787715
Policy mu Mean               0.07979191
Policy mu Std                1.023658
Policy mu Max                3.061494
Policy mu Min                -2.5741932
Policy log std Mean          -0.59379643
Policy log std Std           0.2206876
Policy log std Max           0.4454021
Policy log std Min           -1.6580875
Z mean eval                  0.020286324
Z variance eval              0.0010394455
total_rewards                [ 916.42099259  996.8351313   941.97276291  714.58516222 1594.25359398
 1158.81143748 1681.71286479  922.71511663 1018.67692096 1183.53483134]
total_rewards_mean           1112.9518814200499
total_rewards_std            291.0911597974366
total_rewards_max            1681.7128647869743
total_rewards_min            714.5851622162711
Number of train steps total  596000
Number of env steps total    552200
Number of rollouts total     0
Train Time (s)               149.01952861994505
(Previous) Eval Time (s)     11.638950935099274
Sample Time (s)              10.209058340638876
Epoch Time (s)               170.8675378956832
Total Train Time (s)         23833.055526016746
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:07:42.529228 UTC | [2020_01_11_02_30_29] Iteration #148 | Epoch Duration: 171.14488053321838
2020-01-11 09:07:42.529436 UTC | [2020_01_11_02_30_29] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02032424
Z variance train             0.0010399595
KL Divergence                14.690756
KL Loss                      1.4690756
QF Loss                      297.98416
VF Loss                      111.227005
Policy Loss                  -1170.9891
Q Predictions Mean           1165.0474
Q Predictions Std            354.03503
Q Predictions Max            1582.6777
Q Predictions Min            8.368204
V Predictions Mean           1167.7003
V Predictions Std            344.19684
V Predictions Max            1576.4379
V Predictions Min            12.970667
Log Pis Mean                 0.34771508
Log Pis Std                  2.2378068
Log Pis Max                  9.387441
Log Pis Min                  -3.784601
Policy mu Mean               0.08228309
Policy mu Std                0.9816192
Policy mu Max                3.7613084
Policy mu Min                -2.564325
Policy log std Mean          -0.6163245
Policy log std Std           0.25023606
Policy log std Max           0.07642424
Policy log std Min           -2.4677906
Z mean eval                  0.015583672
Z variance eval              0.00092207256
total_rewards                [1385.49596712  592.53579838  712.7769824  1006.05577789  918.54848355
  641.43005218  721.0476981   391.57515369 1501.60530885 1217.4552091 ]
total_rewards_mean           908.85264312592
total_rewards_std            345.85923944513974
total_rewards_max            1501.605308851501
total_rewards_min            391.5751536850762
Number of train steps total  600000
Number of env steps total    556615
Number of rollouts total     0
Train Time (s)               148.31432821182534
(Previous) Eval Time (s)     9.864725050050765
Sample Time (s)              9.986504872795194
Epoch Time (s)               168.1655581346713
Total Train Time (s)         24001.303093505558
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:10:30.779427 UTC | [2020_01_11_02_30_29] Iteration #149 | Epoch Duration: 168.249755859375
2020-01-11 09:10:30.779629 UTC | [2020_01_11_02_30_29] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0154208075
Z variance train             0.0009222267
KL Divergence                15.018197
KL Loss                      1.5018197
QF Loss                      252.12361
VF Loss                      75.39055
Policy Loss                  -1193.0461
Q Predictions Mean           1192.7269
Q Predictions Std            324.3705
Q Predictions Max            1625.1915
Q Predictions Min            8.81792
V Predictions Mean           1190.4908
V Predictions Std            323.67804
V Predictions Max            1607.9797
V Predictions Min            -2.978667
Log Pis Mean                 0.3097712
Log Pis Std                  2.1302173
Log Pis Max                  9.391214
Log Pis Min                  -4.908403
Policy mu Mean               -0.07779322
Policy mu Std                0.96591866
Policy mu Max                2.2941434
Policy mu Min                -2.6670117
Policy log std Mean          -0.5546575
Policy log std Std           0.22944205
Policy log std Max           0.28654277
Policy log std Min           -1.569456
Z mean eval                  0.014058253
Z variance eval              0.0009571111
total_rewards                [ 166.78821788  861.49469686  152.03974904 3038.34942894 1118.20597146
 1796.209774    168.82989612 2951.89472982 2346.94700255 2739.47878015]
total_rewards_mean           1534.0238246844115
total_rewards_std            1128.017207728195
total_rewards_max            3038.349428941391
total_rewards_min            152.03974904035775
Number of train steps total  604000
Number of env steps total    561158
Number of rollouts total     0
Train Time (s)               149.37892100121826
(Previous) Eval Time (s)     16.29107815725729
Sample Time (s)              9.954459724482149
Epoch Time (s)               175.6244588829577
Total Train Time (s)         24177.07101986138
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:13:26.549726 UTC | [2020_01_11_02_30_29] Iteration #150 | Epoch Duration: 175.76993894577026
2020-01-11 09:13:26.549944 UTC | [2020_01_11_02_30_29] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013724228
Z variance train             0.0009570865
KL Divergence                15.000494
KL Loss                      1.5000495
QF Loss                      343.34296
VF Loss                      114.21539
Policy Loss                  -1212.5115
Q Predictions Mean           1213.717
Q Predictions Std            307.40955
Q Predictions Max            1570.379
Q Predictions Min            35.24047
V Predictions Mean           1213.938
V Predictions Std            302.23087
V Predictions Max            1569.922
V Predictions Min            53.674244
Log Pis Mean                 0.4369651
Log Pis Std                  2.278016
Log Pis Max                  10.609809
Log Pis Min                  -4.3554583
Policy mu Mean               0.07908397
Policy mu Std                1.033384
Policy mu Max                3.2786715
Policy mu Min                -3.1874516
Policy log std Mean          -0.6092282
Policy log std Std           0.2341289
Policy log std Max           0.117670536
Policy log std Min           -2.5200388
Z mean eval                  0.03286741
Z variance eval              0.00084644614
total_rewards                [1377.58900988 2097.96008665 1339.38821271 1182.53115349  945.69088437
 3021.21037636  960.04815927  949.9092547   624.58648362  946.71449361]
total_rewards_mean           1344.5628114653186
total_rewards_std            674.2015450961075
total_rewards_max            3021.2103763624277
total_rewards_min            624.5864836191998
Number of train steps total  608000
Number of env steps total    566105
Number of rollouts total     0
Train Time (s)               148.6480807121843
(Previous) Eval Time (s)     14.145555290859193
Sample Time (s)              12.120871611405164
Epoch Time (s)               174.91450761444867
Total Train Time (s)         24352.0760713676
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:16:21.557930 UTC | [2020_01_11_02_30_29] Iteration #151 | Epoch Duration: 175.00778460502625
2020-01-11 09:16:21.558286 UTC | [2020_01_11_02_30_29] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031918515
Z variance train             0.00084680796
KL Divergence                15.292226
KL Loss                      1.5292226
QF Loss                      449.94226
VF Loss                      168.6425
Policy Loss                  -1198.8539
Q Predictions Mean           1195.064
Q Predictions Std            328.34357
Q Predictions Max            1600.7498
Q Predictions Min            12.042031
V Predictions Mean           1196.3452
V Predictions Std            326.27167
V Predictions Max            1581.1127
V Predictions Min            7.7114205
Log Pis Mean                 0.07703429
Log Pis Std                  2.2208562
Log Pis Max                  7.3193555
Log Pis Min                  -6.9860215
Policy mu Mean               -0.05304013
Policy mu Std                0.9981872
Policy mu Max                2.2638822
Policy mu Min                -2.8935401
Policy log std Mean          -0.57178426
Policy log std Std           0.23967998
Policy log std Max           0.32684273
Policy log std Min           -2.1681175
Z mean eval                  0.018082414
Z variance eval              0.0007922167
total_rewards                [1503.497831    739.85124816  964.80470405 1687.1875781  1002.53778859
 1486.42312345  859.97851459  740.5607138  1737.12879954 1056.50671377]
total_rewards_mean           1177.8477015038982
total_rewards_std            367.21048415877584
total_rewards_max            1737.128799536465
total_rewards_min            739.8512481588302
Number of train steps total  612000
Number of env steps total    570602
Number of rollouts total     0
Train Time (s)               141.32767323916778
(Previous) Eval Time (s)     11.871244284324348
Sample Time (s)              10.246309507172555
Epoch Time (s)               163.44522703066468
Total Train Time (s)         24515.60427168291
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:19:05.087763 UTC | [2020_01_11_02_30_29] Iteration #152 | Epoch Duration: 163.5292887687683
2020-01-11 09:19:05.087969 UTC | [2020_01_11_02_30_29] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01815602
Z variance train             0.00079268496
KL Divergence                15.48896
KL Loss                      1.5488961
QF Loss                      232.01895
VF Loss                      204.5327
Policy Loss                  -1143.903
Q Predictions Mean           1140.0862
Q Predictions Std            388.02774
Q Predictions Max            1569.0011
Q Predictions Min            -37.293884
V Predictions Mean           1147.5043
V Predictions Std            382.0826
V Predictions Max            1572.1462
V Predictions Min            26.89771
Log Pis Mean                 0.11885926
Log Pis Std                  2.3075774
Log Pis Max                  10.302651
Log Pis Min                  -6.1885424
Policy mu Mean               0.12141607
Policy mu Std                0.9620147
Policy mu Max                3.8047674
Policy mu Min                -2.5344677
Policy log std Mean          -0.5940342
Policy log std Std           0.24935012
Policy log std Max           0.16967255
Policy log std Min           -2.9826276
Z mean eval                  0.02269826
Z variance eval              0.0010258688
total_rewards                [1004.42498982  929.73663638 2250.58787257 1040.69355016  912.10597018
 1518.55383658 1011.70556089 3098.47580806  902.63740947 2035.430048  ]
total_rewards_mean           1470.4351682109173
total_rewards_std            715.5030450925799
total_rewards_max            3098.4758080632914
total_rewards_min            902.6374094663341
Number of train steps total  616000
Number of env steps total    575093
Number of rollouts total     0
Train Time (s)               141.07804571278393
(Previous) Eval Time (s)     14.774148344993591
Sample Time (s)              9.079965976066887
Epoch Time (s)               164.9321600338444
Total Train Time (s)         24680.614363468718
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:21:50.100201 UTC | [2020_01_11_02_30_29] Iteration #153 | Epoch Duration: 165.0120825767517
2020-01-11 09:21:50.100417 UTC | [2020_01_11_02_30_29] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023047114
Z variance train             0.0010261366
KL Divergence                14.805248
KL Loss                      1.4805249
QF Loss                      256.44638
VF Loss                      146.88239
Policy Loss                  -1134.3319
Q Predictions Mean           1134.7245
Q Predictions Std            405.68268
Q Predictions Max            1590.7894
Q Predictions Min            14.490912
V Predictions Mean           1135.6672
V Predictions Std            400.77463
V Predictions Max            1599.229
V Predictions Min            28.304363
Log Pis Mean                 0.19118157
Log Pis Std                  2.426092
Log Pis Max                  10.907064
Log Pis Min                  -8.183714
Policy mu Mean               -0.031995084
Policy mu Std                0.97931546
Policy mu Max                2.702688
Policy mu Min                -2.6973767
Policy log std Mean          -0.5954209
Policy log std Std           0.24519081
Policy log std Max           -0.00033313036
Policy log std Min           -2.8878121
Z mean eval                  0.03346964
Z variance eval              0.0011696307
total_rewards                [1016.3283792   993.119495    853.79952132  973.32372614  950.68358452
 1263.691686    856.12280518  767.39444561  810.3220486  1019.04238835]
total_rewards_mean           950.3828079921592
total_rewards_std            134.4965599819136
total_rewards_max            1263.6916860042936
total_rewards_min            767.394445609251
Number of train steps total  620000
Number of env steps total    579467
Number of rollouts total     0
Train Time (s)               141.18061317503452
(Previous) Eval Time (s)     8.20211306028068
Sample Time (s)              10.458714832551777
Epoch Time (s)               159.84144106786698
Total Train Time (s)         24840.54057170311
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:24:30.037016 UTC | [2020_01_11_02_30_29] Iteration #154 | Epoch Duration: 159.93643712997437
2020-01-11 09:24:30.037435 UTC | [2020_01_11_02_30_29] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033514824
Z variance train             0.0011688626
KL Divergence                14.602093
KL Loss                      1.4602093
QF Loss                      530.26794
VF Loss                      79.34187
Policy Loss                  -1184.7765
Q Predictions Mean           1181.7688
Q Predictions Std            347.5469
Q Predictions Max            1591.8538
Q Predictions Min            15.547029
V Predictions Mean           1187.9003
V Predictions Std            344.30615
V Predictions Max            1587.1919
V Predictions Min            18.419947
Log Pis Mean                 0.12629935
Log Pis Std                  1.9307288
Log Pis Max                  6.246997
Log Pis Min                  -4.6268606
Policy mu Mean               0.14524734
Policy mu Std                0.9278485
Policy mu Max                2.8530748
Policy mu Min                -2.600793
Policy log std Mean          -0.58360106
Policy log std Std           0.23525581
Policy log std Max           0.1259796
Policy log std Min           -2.0238566
Z mean eval                  0.03011405
Z variance eval              0.0010784941
total_rewards                [ 973.93472811  853.18333824  927.2490208   893.5675454  1006.52178007
  885.40804264  977.42743402  976.11453935 1016.6188003  1006.25807883]
total_rewards_mean           951.6283307737692
total_rewards_std            54.79612527120862
total_rewards_max            1016.6188002953664
total_rewards_min            853.1833382356494
Number of train steps total  624000
Number of env steps total    584052
Number of rollouts total     0
Train Time (s)               139.18853831104934
(Previous) Eval Time (s)     8.284384911879897
Sample Time (s)              10.119149077683687
Epoch Time (s)               157.59207230061293
Total Train Time (s)         24998.22496890463
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:27:07.716988 UTC | [2020_01_11_02_30_29] Iteration #155 | Epoch Duration: 157.67917799949646
2020-01-11 09:27:07.717189 UTC | [2020_01_11_02_30_29] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029329702
Z variance train             0.0010765532
KL Divergence                14.799392
KL Loss                      1.4799392
QF Loss                      524.7429
VF Loss                      239.95294
Policy Loss                  -1213.069
Q Predictions Mean           1203.3107
Q Predictions Std            313.4649
Q Predictions Max            1584.8567
Q Predictions Min            -5.2775903
V Predictions Mean           1222.9329
V Predictions Std            304.93698
V Predictions Max            1603.9246
V Predictions Min            -18.997173
Log Pis Mean                 0.10437132
Log Pis Std                  2.0018106
Log Pis Max                  7.7897468
Log Pis Min                  -5.9288487
Policy mu Mean               0.06350377
Policy mu Std                0.9065136
Policy mu Max                3.0348294
Policy mu Min                -2.6474361
Policy log std Mean          -0.5801542
Policy log std Std           0.23507904
Policy log std Max           0.15849394
Policy log std Min           -2.4255846
Z mean eval                  0.022569833
Z variance eval              0.0012191802
total_rewards                [1292.90197257 1055.27020806  470.02828693  379.01364797 1263.61488957
  461.6646509   716.18984221 1059.25918283  446.49098366  434.0776206 ]
total_rewards_mean           757.8511285301872
total_rewards_std            351.9911438002122
total_rewards_max            1292.9019725694266
total_rewards_min            379.0136479692043
Number of train steps total  628000
Number of env steps total    588581
Number of rollouts total     0
Train Time (s)               142.1413832581602
(Previous) Eval Time (s)     8.214404326397926
Sample Time (s)              9.911867055110633
Epoch Time (s)               160.26765463966876
Total Train Time (s)         25158.570083275903
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:29:48.063638 UTC | [2020_01_11_02_30_29] Iteration #156 | Epoch Duration: 160.3463032245636
2020-01-11 09:29:48.063834 UTC | [2020_01_11_02_30_29] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02261657
Z variance train             0.0012193175
KL Divergence                14.352818
KL Loss                      1.4352818
QF Loss                      228.34485
VF Loss                      104.50213
Policy Loss                  -1182.6921
Q Predictions Mean           1177.673
Q Predictions Std            350.19287
Q Predictions Max            1623.4695
Q Predictions Min            141.6274
V Predictions Mean           1185.9591
V Predictions Std            345.43765
V Predictions Max            1623.4814
V Predictions Min            154.65242
Log Pis Mean                 0.38243282
Log Pis Std                  2.2806346
Log Pis Max                  9.140098
Log Pis Min                  -4.3345647
Policy mu Mean               -0.04738708
Policy mu Std                1.0098969
Policy mu Max                3.267589
Policy mu Min                -3.1947193
Policy log std Mean          -0.59350675
Policy log std Std           0.2114812
Policy log std Max           0.053814173
Policy log std Min           -2.4574652
Z mean eval                  0.01843272
Z variance eval              0.001113041
total_rewards                [1363.58103259  896.34606045  901.97914242 3036.66861529 3057.51106561
  965.75079721 2154.81855657  918.52137904  946.78647818  843.2856217 ]
total_rewards_mean           1508.5248749040006
total_rewards_std            855.3798859013251
total_rewards_max            3057.5110656052034
total_rewards_min            843.2856217011895
Number of train steps total  632000
Number of env steps total    593735
Number of rollouts total     0
Train Time (s)               140.25996363721788
(Previous) Eval Time (s)     15.387645442038774
Sample Time (s)              11.415888328105211
Epoch Time (s)               167.06349740736187
Total Train Time (s)         25325.716654650867
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:32:35.213262 UTC | [2020_01_11_02_30_29] Iteration #157 | Epoch Duration: 167.14928436279297
2020-01-11 09:32:35.213473 UTC | [2020_01_11_02_30_29] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018219681
Z variance train             0.0011123264
KL Divergence                14.581274
KL Loss                      1.4581274
QF Loss                      128.39738
VF Loss                      39.027172
Policy Loss                  -1169.8344
Q Predictions Mean           1168.2842
Q Predictions Std            373.23352
Q Predictions Max            1611.2517
Q Predictions Min            -39.2807
V Predictions Mean           1169.9868
V Predictions Std            371.8808
V Predictions Max            1611.154
V Predictions Min            -39.34831
Log Pis Mean                 0.19798589
Log Pis Std                  2.0717487
Log Pis Max                  6.6126785
Log Pis Min                  -4.718489
Policy mu Mean               0.054435004
Policy mu Std                1.0016258
Policy mu Max                2.2618499
Policy mu Min                -2.7270093
Policy log std Mean          -0.5833389
Policy log std Std           0.21245173
Policy log std Max           0.099098444
Policy log std Min           -1.815731
Z mean eval                  0.020480145
Z variance eval              0.0009820872
total_rewards                [3011.97666715 1598.80196244  860.53717566  916.60576857  897.11077162
 3202.88705538 2223.139499   1495.4011294   870.87140251 2012.78854546]
total_rewards_mean           1709.0119977183197
total_rewards_std            839.8358866521586
total_rewards_max            3202.887055383251
total_rewards_min            860.53717565881
Number of train steps total  636000
Number of env steps total    598266
Number of rollouts total     0
Train Time (s)               139.9679478299804
(Previous) Eval Time (s)     17.936561077833176
Sample Time (s)              9.56368793407455
Epoch Time (s)               167.46819684188813
Total Train Time (s)         25493.26405484695
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:35:22.765934 UTC | [2020_01_11_02_30_29] Iteration #158 | Epoch Duration: 167.55229330062866
2020-01-11 09:35:22.766206 UTC | [2020_01_11_02_30_29] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019174106
Z variance train             0.0009814848
KL Divergence                14.832497
KL Loss                      1.4832497
QF Loss                      317.82965
VF Loss                      101.728325
Policy Loss                  -1189.6862
Q Predictions Mean           1190.843
Q Predictions Std            345.33194
Q Predictions Max            1621.3044
Q Predictions Min            -52.1796
V Predictions Mean           1194.1125
V Predictions Std            341.96298
V Predictions Max            1624.272
V Predictions Min            -35.15316
Log Pis Mean                 0.46396026
Log Pis Std                  2.1780868
Log Pis Max                  9.952086
Log Pis Min                  -5.937273
Policy mu Mean               0.04499979
Policy mu Std                0.99215674
Policy mu Max                2.3144875
Policy mu Min                -2.943399
Policy log std Mean          -0.61325574
Policy log std Std           0.20995654
Policy log std Max           0.014578581
Policy log std Min           -1.5990623
Z mean eval                  0.016649798
Z variance eval              0.0008256618
total_rewards                [ 995.74389474 2464.37929491 1813.35668167  975.34289398  906.78759343
  723.0644304   930.74234372  853.26005825 1187.35635934  857.89182539]
total_rewards_mean           1170.7925375836312
total_rewards_std            517.8695997950848
total_rewards_max            2464.3792949053955
total_rewards_min            723.064430399005
Number of train steps total  640000
Number of env steps total    602694
Number of rollouts total     0
Train Time (s)               141.0995187438093
(Previous) Eval Time (s)     11.619385980069637
Sample Time (s)              8.57077503297478
Epoch Time (s)               161.28967975685373
Total Train Time (s)         25654.639642272145
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:38:04.143855 UTC | [2020_01_11_02_30_29] Iteration #159 | Epoch Duration: 161.3774163722992
2020-01-11 09:38:04.144042 UTC | [2020_01_11_02_30_29] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01650709
Z variance train             0.00082557014
KL Divergence                15.348835
KL Loss                      1.5348835
QF Loss                      3027.4268
VF Loss                      60.549164
Policy Loss                  -1200.8329
Q Predictions Mean           1198.158
Q Predictions Std            351.05658
Q Predictions Max            1595.9241
Q Predictions Min            8.389992
V Predictions Mean           1205.2672
V Predictions Std            346.04623
V Predictions Max            1597.057
V Predictions Min            3.216503
Log Pis Mean                 0.22801939
Log Pis Std                  2.1876576
Log Pis Max                  8.556745
Log Pis Min                  -4.4661007
Policy mu Mean               0.035294194
Policy mu Std                1.0205648
Policy mu Max                2.848833
Policy mu Min                -2.974081
Policy log std Mean          -0.5841624
Policy log std Std           0.22313479
Policy log std Max           0.34259224
Policy log std Min           -1.7670107
Z mean eval                  0.013118543
Z variance eval              0.0009885214
total_rewards                [1925.224353   1377.49274858 1347.10876034 3106.11379459 3078.29785359
 2404.63875933  954.64616199 1558.76754039 2032.40873519  943.48040119]
total_rewards_mean           1872.8179108188626
total_rewards_std            749.1529910646358
total_rewards_max            3106.1137945867367
total_rewards_min            943.4804011915651
Number of train steps total  644000
Number of env steps total    607241
Number of rollouts total     0
Train Time (s)               141.23632273776457
(Previous) Eval Time (s)     19.562789626885206
Sample Time (s)              10.244908419903368
Epoch Time (s)               171.04402078455314
Total Train Time (s)         25825.77128703799
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:40:55.275315 UTC | [2020_01_11_02_30_29] Iteration #160 | Epoch Duration: 171.131108045578
2020-01-11 09:40:55.275541 UTC | [2020_01_11_02_30_29] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013454696
Z variance train             0.0009892138
KL Divergence                14.840016
KL Loss                      1.4840016
QF Loss                      96.63597
VF Loss                      60.730923
Policy Loss                  -1198.873
Q Predictions Mean           1196.4205
Q Predictions Std            334.02643
Q Predictions Max            1614.0748
Q Predictions Min            -27.030155
V Predictions Mean           1199.6235
V Predictions Std            330.8737
V Predictions Max            1608.7126
V Predictions Min            -34.281013
Log Pis Mean                 0.22512825
Log Pis Std                  2.1444883
Log Pis Max                  6.405611
Log Pis Min                  -4.929509
Policy mu Mean               -0.037730526
Policy mu Std                1.0107261
Policy mu Max                2.2749357
Policy mu Min                -2.6892948
Policy log std Mean          -0.5721857
Policy log std Std           0.20335482
Policy log std Max           0.097804725
Policy log std Min           -1.7152941
Z mean eval                  0.022809906
Z variance eval              0.00082883425
total_rewards                [ 980.85051444 1998.18791633 1234.98820468 1519.2175995  1259.96424514
 1397.27791349 1333.46834058 1269.25346067 1179.22227772 1770.35291435]
total_rewards_mean           1394.2783386905453
total_rewards_std            283.1381384596194
total_rewards_max            1998.1879163346882
total_rewards_min            980.8505144399991
Number of train steps total  648000
Number of env steps total    611734
Number of rollouts total     0
Train Time (s)               140.81168807204813
(Previous) Eval Time (s)     14.191744845826179
Sample Time (s)              10.377303267363459
Epoch Time (s)               165.38073618523777
Total Train Time (s)         25991.23244541278
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:40.739327 UTC | [2020_01_11_02_30_29] Iteration #161 | Epoch Duration: 165.46362018585205
2020-01-11 09:43:40.739609 UTC | [2020_01_11_02_30_29] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022736304
Z variance train             0.00082890486
KL Divergence                15.437572
KL Loss                      1.5437572
QF Loss                      233.41397
VF Loss                      163.08463
Policy Loss                  -1193.6416
Q Predictions Mean           1189.872
Q Predictions Std            352.88312
Q Predictions Max            1628.3428
Q Predictions Min            72.076515
V Predictions Mean           1202.8789
V Predictions Std            353.24564
V Predictions Max            1644.588
V Predictions Min            70.00378
Log Pis Mean                 0.3359142
Log Pis Std                  2.2847831
Log Pis Max                  10.090454
Log Pis Min                  -5.325394
Policy mu Mean               0.023039727
Policy mu Std                0.9837639
Policy mu Max                2.5041947
Policy mu Min                -2.655865
Policy log std Mean          -0.55085766
Policy log std Std           0.21466595
Policy log std Max           0.1969809
Policy log std Min           -1.2852998
Z mean eval                  0.022234477
Z variance eval              0.000918971
total_rewards                [2809.31306549 1943.92518636  865.41034561 2075.57195182  864.98693832
  799.68758725 1303.27674404 3039.26391363 3063.39618526  707.31624188]
total_rewards_mean           1747.214815965382
total_rewards_std            916.977284071987
total_rewards_max            3063.396185255696
total_rewards_min            707.316241880635
Number of train steps total  652000
Number of env steps total    616217
Number of rollouts total     0
Train Time (s)               141.62785387784243
(Previous) Eval Time (s)     17.937705683056265
Sample Time (s)              9.253620041068643
Epoch Time (s)               168.81917960196733
Total Train Time (s)         26160.141312330496
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:29.651372 UTC | [2020_01_11_02_30_29] Iteration #162 | Epoch Duration: 168.91144514083862
2020-01-11 09:46:29.651612 UTC | [2020_01_11_02_30_29] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02251208
Z variance train             0.00091854285
KL Divergence                15.1567745
KL Loss                      1.5156775
QF Loss                      230.3443
VF Loss                      75.114006
Policy Loss                  -1187.7427
Q Predictions Mean           1185.5604
Q Predictions Std            348.12018
Q Predictions Max            1599.462
Q Predictions Min            34.29991
V Predictions Mean           1189.0531
V Predictions Std            346.04123
V Predictions Max            1595.8743
V Predictions Min            27.794117
Log Pis Mean                 0.35883075
Log Pis Std                  2.0391476
Log Pis Max                  6.557662
Log Pis Min                  -4.3638163
Policy mu Mean               0.020057362
Policy mu Std                0.94598573
Policy mu Max                2.2187138
Policy mu Min                -2.8107755
Policy log std Mean          -0.5936286
Policy log std Std           0.21830033
Policy log std Max           0.091371715
Policy log std Min           -1.7260435
Z mean eval                  0.023798246
Z variance eval              0.0008931624
total_rewards                [ 748.27567201  918.67568501 1962.60326734  535.63592521  847.53554574
  601.47764089 2055.82535905 2054.98088517 1427.20592241 1717.30030004]
total_rewards_mean           1286.9516202878194
total_rewards_std            591.2400070960302
total_rewards_max            2055.8253590480317
total_rewards_min            535.6359252129761
Number of train steps total  656000
Number of env steps total    620678
Number of rollouts total     0
Train Time (s)               141.06823817128316
(Previous) Eval Time (s)     12.548101335763931
Sample Time (s)              10.495427413843572
Epoch Time (s)               164.11176692089066
Total Train Time (s)         26324.336611253675
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:49:13.849169 UTC | [2020_01_11_02_30_29] Iteration #163 | Epoch Duration: 164.19738173484802
2020-01-11 09:49:13.849365 UTC | [2020_01_11_02_30_29] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023865297
Z variance train             0.0008938139
KL Divergence                15.171471
KL Loss                      1.5171471
QF Loss                      156.52982
VF Loss                      87.34804
Policy Loss                  -1194.2979
Q Predictions Mean           1193.6658
Q Predictions Std            354.4382
Q Predictions Max            1619.3015
Q Predictions Min            8.329104
V Predictions Mean           1198.2145
V Predictions Std            351.92682
V Predictions Max            1636.0424
V Predictions Min            16.646341
Log Pis Mean                 0.15682861
Log Pis Std                  2.013924
Log Pis Max                  11.607097
Log Pis Min                  -4.7591887
Policy mu Mean               0.066089034
Policy mu Std                0.9588545
Policy mu Max                3.4038
Policy mu Min                -2.891816
Policy log std Mean          -0.61399627
Policy log std Std           0.22128938
Policy log std Max           0.046919823
Policy log std Min           -1.697242
Z mean eval                  0.0260312
Z variance eval              0.0014599287
total_rewards                [1803.51040921 3111.42835396 1422.48925477 1392.33547403 3024.56974619
 1086.26272826 3076.4236419   896.38194582 1257.71779888 1112.30595904]
total_rewards_mean           1818.3425312064203
total_rewards_std            851.2910684340299
total_rewards_max            3111.4283539558373
total_rewards_min            896.3819458198744
Number of train steps total  660000
Number of env steps total    625145
Number of rollouts total     0
Train Time (s)               141.07851141877472
(Previous) Eval Time (s)     18.106048002373427
Sample Time (s)              9.950345270801336
Epoch Time (s)               169.1349046919495
Total Train Time (s)         26493.558333288413
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:52:03.071725 UTC | [2020_01_11_02_30_29] Iteration #164 | Epoch Duration: 169.22220873832703
2020-01-11 09:52:03.071947 UTC | [2020_01_11_02_30_29] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025377372
Z variance train             0.001460258
KL Divergence                14.199184
KL Loss                      1.4199184
QF Loss                      241.3775
VF Loss                      81.58805
Policy Loss                  -1217.093
Q Predictions Mean           1214.9912
Q Predictions Std            362.70004
Q Predictions Max            1599.3817
Q Predictions Min            2.5595794
V Predictions Mean           1220.1967
V Predictions Std            360.32648
V Predictions Max            1610.7897
V Predictions Min            -14.926551
Log Pis Mean                 0.52968764
Log Pis Std                  2.4655764
Log Pis Max                  9.757647
Log Pis Min                  -5.003135
Policy mu Mean               0.013312798
Policy mu Std                1.0425735
Policy mu Max                2.8195
Policy mu Min                -2.6686847
Policy log std Mean          -0.57310253
Policy log std Std           0.21003734
Policy log std Max           -0.031982303
Policy log std Min           -1.8286444
Z mean eval                  0.0133961635
Z variance eval              0.001741368
total_rewards                [1457.69450697 3154.27379863 1185.44973325  863.82266674 2078.45689256
  851.83454435 2991.60606216  886.01221595 2048.31668378 3032.6855691 ]
total_rewards_mean           1855.0152673498283
total_rewards_std            893.7613407537448
total_rewards_max            3154.2737986332536
total_rewards_min            851.834544351686
Number of train steps total  664000
Number of env steps total    629751
Number of rollouts total     0
Train Time (s)               140.4116903259419
(Previous) Eval Time (s)     18.77048537088558
Sample Time (s)              10.125339357648045
Epoch Time (s)               169.30751505447552
Total Train Time (s)         26662.95266213361
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:54:52.469634 UTC | [2020_01_11_02_30_29] Iteration #165 | Epoch Duration: 169.3975043296814
2020-01-11 09:54:52.469906 UTC | [2020_01_11_02_30_29] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013385524
Z variance train             0.0017418861
KL Divergence                13.873386
KL Loss                      1.3873386
QF Loss                      329.72607
VF Loss                      395.4832
Policy Loss                  -1172.0475
Q Predictions Mean           1162.7454
Q Predictions Std            389.34738
Q Predictions Max            1625.9368
Q Predictions Min            39.941364
V Predictions Mean           1167.6597
V Predictions Std            378.09628
V Predictions Max            1623.2772
V Predictions Min            40.88345
Log Pis Mean                 0.35270262
Log Pis Std                  2.5739207
Log Pis Max                  14.162932
Log Pis Min                  -5.8243294
Policy mu Mean               -0.07935363
Policy mu Std                1.01469
Policy mu Max                4.2162127
Policy mu Min                -2.9706678
Policy log std Mean          -0.59869355
Policy log std Std           0.21280384
Policy log std Max           -0.007136166
Policy log std Min           -1.6860828
Z mean eval                  0.01942633
Z variance eval              0.0015997381
total_rewards                [3116.68889647 3122.45880882 3111.86591886 3137.91655462 3106.08467222
 3107.94789091 2404.43020917 2324.30929867 3111.51597252 3121.43893476]
total_rewards_mean           2966.465715702279
total_rewards_std            301.7040217618923
total_rewards_max            3137.9165546168024
total_rewards_min            2324.3092986735323
Number of train steps total  668000
Number of env steps total    634218
Number of rollouts total     0
Train Time (s)               141.75885669514537
(Previous) Eval Time (s)     30.503291436936706
Sample Time (s)              10.075627957005054
Epoch Time (s)               182.33777608908713
Total Train Time (s)         26845.370454001706
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:57:54.888512 UTC | [2020_01_11_02_30_29] Iteration #166 | Epoch Duration: 182.41842937469482
2020-01-11 09:57:54.888631 UTC | [2020_01_11_02_30_29] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01938532
Z variance train             0.0015993456
KL Divergence                14.103758
KL Loss                      1.4103758
QF Loss                      232.99359
VF Loss                      65.67101
Policy Loss                  -1208.0453
Q Predictions Mean           1198.382
Q Predictions Std            347.2998
Q Predictions Max            1649.5057
Q Predictions Min            -5.4656672
V Predictions Mean           1208.6296
V Predictions Std            329.6935
V Predictions Max            1647.9398
V Predictions Min            21.11534
Log Pis Mean                 0.6156992
Log Pis Std                  2.5574574
Log Pis Max                  15.882179
Log Pis Min                  -4.836786
Policy mu Mean               0.17529674
Policy mu Std                1.0761437
Policy mu Max                4.61306
Policy mu Min                -2.675278
Policy log std Mean          -0.6089589
Policy log std Std           0.22137907
Policy log std Max           0.0022370815
Policy log std Min           -2.4374065
Z mean eval                  0.019371908
Z variance eval              0.0011374857
total_rewards                [ 910.28896577  800.13093071 1116.8605813  1792.80055071 1816.40675415
 1674.29043572 1075.22753076  822.41585246 1473.21114021  947.78876414]
total_rewards_mean           1242.9421505920438
total_rewards_std            385.3587451944825
total_rewards_max            1816.4067541499792
total_rewards_min            800.1309307073707
Number of train steps total  672000
Number of env steps total    638564
Number of rollouts total     0
Train Time (s)               146.72403362579644
(Previous) Eval Time (s)     12.853016208857298
Sample Time (s)              9.87142096599564
Epoch Time (s)               169.44847080064937
Total Train Time (s)         27014.899816442747
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:00:44.421774 UTC | [2020_01_11_02_30_29] Iteration #167 | Epoch Duration: 169.53301787376404
2020-01-11 10:00:44.422021 UTC | [2020_01_11_02_30_29] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018244278
Z variance train             0.0011371893
KL Divergence                14.745987
KL Loss                      1.4745988
QF Loss                      120.339554
VF Loss                      124.32913
Policy Loss                  -1211.535
Q Predictions Mean           1210.3394
Q Predictions Std            363.63083
Q Predictions Max            1602.2494
Q Predictions Min            2.5272837
V Predictions Mean           1212.1445
V Predictions Std            362.97208
V Predictions Max            1607.8549
V Predictions Min            -7.649545
Log Pis Mean                 0.38446617
Log Pis Std                  2.0759432
Log Pis Max                  9.103727
Log Pis Min                  -5.3035984
Policy mu Mean               0.28280824
Policy mu Std                0.963782
Policy mu Max                3.0679715
Policy mu Min                -2.548587
Policy log std Mean          -0.5710649
Policy log std Std           0.2196296
Policy log std Max           0.13830554
Policy log std Min           -1.8319806
Z mean eval                  0.028329372
Z variance eval              0.0011436378
total_rewards                [1953.10770486 1525.68966087 2876.90431631  892.13269846 3147.70901255
 2278.80014902 3244.51637945 3165.67681869 1663.07170926  975.13496024]
total_rewards_mean           2172.274340969126
total_rewards_std            859.8356718066273
total_rewards_max            3244.5163794501063
total_rewards_min            892.1326984625408
Number of train steps total  676000
Number of env steps total    643016
Number of rollouts total     0
Train Time (s)               150.03291288996115
(Previous) Eval Time (s)     22.651911658700556
Sample Time (s)              9.735288164112717
Epoch Time (s)               182.42011271277443
Total Train Time (s)         27197.404811585788
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:03:46.929239 UTC | [2020_01_11_02_30_29] Iteration #168 | Epoch Duration: 182.50704789161682
2020-01-11 10:03:46.929477 UTC | [2020_01_11_02_30_29] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028229142
Z variance train             0.0011439251
KL Divergence                14.684952
KL Loss                      1.4684952
QF Loss                      396.30133
VF Loss                      123.57591
Policy Loss                  -1192.6238
Q Predictions Mean           1185.2996
Q Predictions Std            369.87772
Q Predictions Max            1603.4949
Q Predictions Min            3.2475843
V Predictions Mean           1192.0454
V Predictions Std            372.738
V Predictions Max            1616.2863
V Predictions Min            -39.39244
Log Pis Mean                 0.6171878
Log Pis Std                  2.3955362
Log Pis Max                  10.550264
Log Pis Min                  -3.9623737
Policy mu Mean               -0.11115607
Policy mu Std                1.0995607
Policy mu Max                2.986264
Policy mu Min                -3.6259515
Policy log std Mean          -0.5985692
Policy log std Std           0.22526519
Policy log std Max           0.01551187
Policy log std Min           -2.1356785
Z mean eval                  0.008571071
Z variance eval              0.0009816798
total_rewards                [3185.461793   3171.70831175 3085.18775261 2272.90271395 3189.01785003
 1368.48469008 3172.73115051 1923.00327139 3124.98541168 1668.0173615 ]
total_rewards_mean           2616.1500306498956
total_rewards_std            693.0747656761546
total_rewards_max            3189.01785003088
total_rewards_min            1368.484690083208
Number of train steps total  680000
Number of env steps total    647562
Number of rollouts total     0
Train Time (s)               149.4816533010453
(Previous) Eval Time (s)     26.315756181720644
Sample Time (s)              9.454548371490091
Epoch Time (s)               185.25195785425603
Total Train Time (s)         27382.747484927997
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:52.277551 UTC | [2020_01_11_02_30_29] Iteration #169 | Epoch Duration: 185.34791946411133
2020-01-11 10:06:52.277816 UTC | [2020_01_11_02_30_29] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008584527
Z variance train             0.0009816192
KL Divergence                14.964897
KL Loss                      1.4964898
QF Loss                      258.1758
VF Loss                      39.8976
Policy Loss                  -1193.989
Q Predictions Mean           1190.8716
Q Predictions Std            383.09964
Q Predictions Max            1610.2188
Q Predictions Min            7.6710615
V Predictions Mean           1192.6101
V Predictions Std            373.69412
V Predictions Max            1596.307
V Predictions Min            39.208134
Log Pis Mean                 0.20590428
Log Pis Std                  2.041553
Log Pis Max                  7.817563
Log Pis Min                  -3.9912243
Policy mu Mean               0.0053675123
Policy mu Std                0.9444243
Policy mu Max                3.3011367
Policy mu Min                -2.619388
Policy log std Mean          -0.5517198
Policy log std Std           0.20651133
Policy log std Max           0.013706982
Policy log std Min           -1.6028378
Z mean eval                  0.014556328
Z variance eval              0.0010329928
total_rewards                [3152.96807132 1479.62960348 1043.3554621  1007.35171169  977.42464917
 3131.36012353 3127.30544595 2631.71804805 1469.23346009 3156.2424516 ]
total_rewards_mean           2117.6589026971365
total_rewards_std            947.4352225939226
total_rewards_max            3156.242451597013
total_rewards_min            977.424649172528
Number of train steps total  684000
Number of env steps total    651982
Number of rollouts total     0
Train Time (s)               149.60070847906172
(Previous) Eval Time (s)     21.8142955978401
Sample Time (s)              10.483760595787317
Epoch Time (s)               181.89876467268914
Total Train Time (s)         27564.735591930803
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:54.265025 UTC | [2020_01_11_02_30_29] Iteration #170 | Epoch Duration: 181.98699259757996
2020-01-11 10:09:54.265223 UTC | [2020_01_11_02_30_29] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01431637
Z variance train             0.0010339097
KL Divergence                14.925371
KL Loss                      1.4925371
QF Loss                      316.07416
VF Loss                      97.63321
Policy Loss                  -1215.9452
Q Predictions Mean           1214.6309
Q Predictions Std            382.30652
Q Predictions Max            1632.8057
Q Predictions Min            -2.8104293
V Predictions Mean           1210.8733
V Predictions Std            379.9912
V Predictions Max            1631.8046
V Predictions Min            -25.816122
Log Pis Mean                 0.2573446
Log Pis Std                  2.3339465
Log Pis Max                  10.104036
Log Pis Min                  -7.873964
Policy mu Mean               -0.037121963
Policy mu Std                1.0073146
Policy mu Max                3.2825885
Policy mu Min                -3.2323155
Policy log std Mean          -0.5811303
Policy log std Std           0.23914203
Policy log std Max           0.10602313
Policy log std Min           -2.4502292
Z mean eval                  0.041341368
Z variance eval              0.0009539956
total_rewards                [ 870.15663381 3111.56309949  936.54460782 1846.54378248 3103.07203731
  991.77470667 2308.5675609  2841.78033182 2257.70390315  824.02609221]
total_rewards_mean           1909.173275564882
total_rewards_std            898.3612837377664
total_rewards_max            3111.563099492837
total_rewards_min            824.0260922106651
Number of train steps total  688000
Number of env steps total    656402
Number of rollouts total     0
Train Time (s)               148.15451464662328
(Previous) Eval Time (s)     19.559133602771908
Sample Time (s)              10.287093327846378
Epoch Time (s)               178.00074157724157
Total Train Time (s)         27742.81579013355
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:12:52.347810 UTC | [2020_01_11_02_30_29] Iteration #171 | Epoch Duration: 178.08243131637573
2020-01-11 10:12:52.348018 UTC | [2020_01_11_02_30_29] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039913256
Z variance train             0.0009539017
KL Divergence                15.2678
KL Loss                      1.52678
QF Loss                      156.10721
VF Loss                      48.9
Policy Loss                  -1218.2904
Q Predictions Mean           1211.4749
Q Predictions Std            365.15878
Q Predictions Max            1643.7007
Q Predictions Min            22.832102
V Predictions Mean           1218.7734
V Predictions Std            355.93176
V Predictions Max            1649.3938
V Predictions Min            1.0196699
Log Pis Mean                 0.48817295
Log Pis Std                  2.186105
Log Pis Max                  7.5304
Log Pis Min                  -4.029811
Policy mu Mean               -0.022747679
Policy mu Std                0.9841431
Policy mu Max                3.4618244
Policy mu Min                -2.8193614
Policy log std Mean          -0.60039896
Policy log std Std           0.2340564
Policy log std Max           0.08199686
Policy log std Min           -2.1833427
Z mean eval                  0.040040698
Z variance eval              0.0013517834
total_rewards                [2140.42265652 1441.72396606 2161.39963456 1915.91511062 1511.66460125
 2058.66410116 1980.94316757 3126.84676864 2316.41575141 2028.03775267]
total_rewards_mean           2068.2033510461824
total_rewards_std            439.4267375644301
total_rewards_max            3126.8467686396143
total_rewards_min            1441.723966056473
Number of train steps total  692000
Number of env steps total    661060
Number of rollouts total     0
Train Time (s)               140.6785190673545
(Previous) Eval Time (s)     21.679234619252384
Sample Time (s)              10.21031548595056
Epoch Time (s)               172.56806917255744
Total Train Time (s)         27915.463158903643
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:15:44.997715 UTC | [2020_01_11_02_30_29] Iteration #172 | Epoch Duration: 172.6495339870453
2020-01-11 10:15:44.997939 UTC | [2020_01_11_02_30_29] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039033644
Z variance train             0.001349245
KL Divergence                14.534387
KL Loss                      1.4534386
QF Loss                      800.72833
VF Loss                      152.41489
Policy Loss                  -1214.8512
Q Predictions Mean           1213.896
Q Predictions Std            336.4432
Q Predictions Max            1635.2931
Q Predictions Min            31.210285
V Predictions Mean           1207.2797
V Predictions Std            333.99435
V Predictions Max            1634.0016
V Predictions Min            22.799198
Log Pis Mean                 0.381746
Log Pis Std                  2.391892
Log Pis Max                  11.477777
Log Pis Min                  -5.480182
Policy mu Mean               0.11506369
Policy mu Std                1.0004286
Policy mu Max                3.2473037
Policy mu Min                -2.7026336
Policy log std Mean          -0.62082267
Policy log std Std           0.20543838
Policy log std Max           0.13834971
Policy log std Min           -1.9349151
Z mean eval                  0.03211386
Z variance eval              0.0011150104
total_rewards                [3202.65433238 1082.98521073 3171.43287246 1530.39306957 2205.75283555
 3170.31257037 1277.71644955  798.56079929 1565.79988016 3259.40564793]
total_rewards_mean           2126.501366799682
total_rewards_std            941.902383728502
total_rewards_max            3259.405647932747
total_rewards_min            798.5607992910258
Number of train steps total  696000
Number of env steps total    665524
Number of rollouts total     0
Train Time (s)               140.87620138796046
(Previous) Eval Time (s)     21.735820613335818
Sample Time (s)              9.427666809875518
Epoch Time (s)               172.0396888111718
Total Train Time (s)         28087.59116099449
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:18:37.128502 UTC | [2020_01_11_02_30_29] Iteration #173 | Epoch Duration: 172.1304121017456
2020-01-11 10:18:37.128690 UTC | [2020_01_11_02_30_29] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03271764
Z variance train             0.0011147441
KL Divergence                14.97001
KL Loss                      1.497001
QF Loss                      192.49942
VF Loss                      91.80605
Policy Loss                  -1246.8312
Q Predictions Mean           1245.0714
Q Predictions Std            336.9352
Q Predictions Max            1647.9576
Q Predictions Min            20.015076
V Predictions Mean           1245.8923
V Predictions Std            333.8078
V Predictions Max            1643.0061
V Predictions Min            17.314528
Log Pis Mean                 0.65019417
Log Pis Std                  2.2647054
Log Pis Max                  7.7515984
Log Pis Min                  -3.3540199
Policy mu Mean               0.05694889
Policy mu Std                1.0180746
Policy mu Max                2.4360766
Policy mu Min                -2.8257787
Policy log std Mean          -0.5827962
Policy log std Std           0.22226007
Policy log std Max           0.18235433
Policy log std Min           -1.6479826
Z mean eval                  0.055732656
Z variance eval              0.0015709506
total_rewards                [ 901.37411202 2167.22951051  907.22425171 3122.41120857 1695.55725216
 1337.01311363 3148.72235209 2375.47720088  951.67736466 1482.92869933]
total_rewards_mean           1808.9615065558944
total_rewards_std            817.5010394401842
total_rewards_max            3148.722352088915
total_rewards_min            901.3741120158313
Number of train steps total  700000
Number of env steps total    670078
Number of rollouts total     0
Train Time (s)               140.56561156874523
(Previous) Eval Time (s)     18.979488171171397
Sample Time (s)              9.002129572443664
Epoch Time (s)               168.5472293123603
Total Train Time (s)         28256.266994186677
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:21:25.806479 UTC | [2020_01_11_02_30_29] Iteration #174 | Epoch Duration: 168.6776282787323
2020-01-11 10:21:25.806722 UTC | [2020_01_11_02_30_29] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055741657
Z variance train             0.0015701562
KL Divergence                14.082195
KL Loss                      1.4082196
QF Loss                      179.28732
VF Loss                      75.64363
Policy Loss                  -1259.5413
Q Predictions Mean           1259.45
Q Predictions Std            339.53366
Q Predictions Max            1653.106
Q Predictions Min            -3.6458216
V Predictions Mean           1256.9004
V Predictions Std            339.14743
V Predictions Max            1646.673
V Predictions Min            -24.517702
Log Pis Mean                 0.62054455
Log Pis Std                  2.325383
Log Pis Max                  7.879088
Log Pis Min                  -6.4509616
Policy mu Mean               0.0071784654
Policy mu Std                1.0402068
Policy mu Max                2.4732468
Policy mu Min                -2.7259283
Policy log std Mean          -0.5709693
Policy log std Std           0.25840324
Policy log std Max           0.08783811
Policy log std Min           -2.5084822
Z mean eval                  0.039229374
Z variance eval              0.0014478109
total_rewards                [3015.8317201  3208.6316849  3205.8597207  2329.7169258  2131.43691196
 1464.66307176 1622.78607669 3175.59544341 1129.02971125 3190.01261651]
total_rewards_mean           2447.3563883080783
total_rewards_std            778.2758970495399
total_rewards_max            3208.631684901663
total_rewards_min            1129.0297112494147
Number of train steps total  704000
Number of env steps total    674682
Number of rollouts total     0
Train Time (s)               141.11411831807345
(Previous) Eval Time (s)     24.71044182078913
Sample Time (s)              9.114040275570005
Epoch Time (s)               174.93860041443259
Total Train Time (s)         28431.288763457444
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:24:20.830787 UTC | [2020_01_11_02_30_29] Iteration #175 | Epoch Duration: 175.0239040851593
2020-01-11 10:24:20.831009 UTC | [2020_01_11_02_30_29] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039362963
Z variance train             0.0014485159
KL Divergence                14.324931
KL Loss                      1.4324931
QF Loss                      191.18855
VF Loss                      58.432182
Policy Loss                  -1201.3926
Q Predictions Mean           1200.8137
Q Predictions Std            358.15463
Q Predictions Max            1646.307
Q Predictions Min            26.572266
V Predictions Mean           1201.4211
V Predictions Std            353.13177
V Predictions Max            1630.4285
V Predictions Min            31.076258
Log Pis Mean                 0.38211617
Log Pis Std                  2.0173159
Log Pis Max                  6.9243956
Log Pis Min                  -4.143398
Policy mu Mean               0.08447683
Policy mu Std                1.021199
Policy mu Max                2.3045835
Policy mu Min                -2.8672037
Policy log std Mean          -0.5670003
Policy log std Std           0.19816323
Policy log std Max           0.25559884
Policy log std Min           -1.1639332
Z mean eval                  0.020435268
Z variance eval              0.0011892745
total_rewards                [ 974.47836016 1102.47836384 2120.23180393 1055.43510491 1301.02863146
 1756.57506023 1915.65242089 3109.7127662   716.79569346  747.40327078]
total_rewards_mean           1479.9791475866089
total_rewards_std            711.4553289352033
total_rewards_max            3109.712766201692
total_rewards_min            716.7956934636607
Number of train steps total  708000
Number of env steps total    679109
Number of rollouts total     0
Train Time (s)               139.77661309670657
(Previous) Eval Time (s)     14.465920221060514
Sample Time (s)              9.752455641515553
Epoch Time (s)               163.99498895928264
Total Train Time (s)         28595.394805166405
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:27:04.939253 UTC | [2020_01_11_02_30_29] Iteration #176 | Epoch Duration: 164.10809564590454
2020-01-11 10:27:04.939446 UTC | [2020_01_11_02_30_29] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021114627
Z variance train             0.0011887739
KL Divergence                14.763903
KL Loss                      1.4763902
QF Loss                      1070.676
VF Loss                      128.38458
Policy Loss                  -1243.854
Q Predictions Mean           1236.0801
Q Predictions Std            360.21234
Q Predictions Max            1665.2557
Q Predictions Min            -18.77604
V Predictions Mean           1246.6704
V Predictions Std            350.7669
V Predictions Max            1664.6841
V Predictions Min            -26.520308
Log Pis Mean                 0.39634246
Log Pis Std                  2.3731723
Log Pis Max                  8.724444
Log Pis Min                  -7.825887
Policy mu Mean               0.12720057
Policy mu Std                1.015987
Policy mu Max                2.6996872
Policy mu Min                -2.9099715
Policy log std Mean          -0.5735398
Policy log std Std           0.22658455
Policy log std Max           0.12662905
Policy log std Min           -1.7970529
Z mean eval                  0.07194579
Z variance eval              0.0011175359
total_rewards                [ 713.39277651 1056.61929508 2521.91060657 1127.00851948 3147.78143744
 2611.99536644 1501.04356254 2674.21560725  879.83652193 2137.11176533]
total_rewards_mean           1837.0915458577765
total_rewards_std            835.6715315213221
total_rewards_max            3147.7814374392915
total_rewards_min            713.3927765146088
Number of train steps total  712000
Number of env steps total    683511
Number of rollouts total     0
Train Time (s)               140.5892866756767
(Previous) Eval Time (s)     18.527632360346615
Sample Time (s)              9.96028304984793
Epoch Time (s)               169.07720208587125
Total Train Time (s)         28764.550748774316
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:29:54.098029 UTC | [2020_01_11_02_30_29] Iteration #177 | Epoch Duration: 169.15842533111572
2020-01-11 10:29:54.098522 UTC | [2020_01_11_02_30_29] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.072165444
Z variance train             0.0011175044
KL Divergence                14.9764
KL Loss                      1.49764
QF Loss                      225.59477
VF Loss                      79.88362
Policy Loss                  -1257.8557
Q Predictions Mean           1256.8214
Q Predictions Std            332.52368
Q Predictions Max            1637.4042
Q Predictions Min            34.498154
V Predictions Mean           1260.095
V Predictions Std            331.4545
V Predictions Max            1635.8234
V Predictions Min            25.501698
Log Pis Mean                 0.4633175
Log Pis Std                  2.132367
Log Pis Max                  8.74766
Log Pis Min                  -4.632559
Policy mu Mean               0.007801611
Policy mu Std                1.0197611
Policy mu Max                2.7000384
Policy mu Min                -3.2181053
Policy log std Mean          -0.5972839
Policy log std Std           0.20520149
Policy log std Max           0.04889661
Policy log std Min           -2.607174
Z mean eval                  0.035822414
Z variance eval              0.0010251785
total_rewards                [3186.91336531 3162.92523898 3193.13698895 3253.99901996 2980.11987462
 3209.29572731 1695.62902162 3208.25313655 3124.75583506 1437.44857977]
total_rewards_mean           2845.2476788123577
total_rewards_std            645.7476076130407
total_rewards_max            3253.9990199573235
total_rewards_min            1437.448579767154
Number of train steps total  716000
Number of env steps total    688143
Number of rollouts total     0
Train Time (s)               139.23336194176227
(Previous) Eval Time (s)     28.36466373130679
Sample Time (s)              10.26231319271028
Epoch Time (s)               177.86033886577934
Total Train Time (s)         28942.491975329816
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:32:52.042080 UTC | [2020_01_11_02_30_29] Iteration #178 | Epoch Duration: 177.9432418346405
2020-01-11 10:32:52.042281 UTC | [2020_01_11_02_30_29] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035738774
Z variance train             0.0010255517
KL Divergence                15.012856
KL Loss                      1.5012856
QF Loss                      632.6107
VF Loss                      95.73607
Policy Loss                  -1254.2047
Q Predictions Mean           1250.4669
Q Predictions Std            340.32187
Q Predictions Max            1666.3505
Q Predictions Min            36.04921
V Predictions Mean           1248.3381
V Predictions Std            338.04077
V Predictions Max            1662.2653
V Predictions Min            37.856453
Log Pis Mean                 0.20175424
Log Pis Std                  2.2092178
Log Pis Max                  14.188293
Log Pis Min                  -5.9061327
Policy mu Mean               0.02725177
Policy mu Std                0.99291605
Policy mu Max                3.0248115
Policy mu Min                -3.77606
Policy log std Mean          -0.5702636
Policy log std Std           0.21590653
Policy log std Max           0.18274224
Policy log std Min           -1.637901
Z mean eval                  0.027232423
Z variance eval              0.0011635877
total_rewards                [2846.57251499 2383.31134109 3153.14128099  847.47106038 1883.02503092
 1419.30707975  834.10297349 3131.53450923 3132.0824125  1112.31666783]
total_rewards_mean           2074.2864871175448
total_rewards_std            923.3986937482468
total_rewards_max            3153.1412809877975
total_rewards_min            834.1029734924717
Number of train steps total  720000
Number of env steps total    692486
Number of rollouts total     0
Train Time (s)               140.3953180219978
(Previous) Eval Time (s)     19.879852512851357
Sample Time (s)              9.218058138154447
Epoch Time (s)               169.4932286730036
Total Train Time (s)         29112.07112557208
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:35:41.624994 UTC | [2020_01_11_02_30_29] Iteration #179 | Epoch Duration: 169.5825333595276
2020-01-11 10:35:41.625361 UTC | [2020_01_11_02_30_29] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027068848
Z variance train             0.0011629828
KL Divergence                14.668612
KL Loss                      1.4668611
QF Loss                      119.9935
VF Loss                      39.466385
Policy Loss                  -1254.2269
Q Predictions Mean           1253.3933
Q Predictions Std            340.13773
Q Predictions Max            1657.5521
Q Predictions Min            44.440575
V Predictions Mean           1255.4071
V Predictions Std            338.25296
V Predictions Max            1659.3964
V Predictions Min            35.90112
Log Pis Mean                 0.33506304
Log Pis Std                  2.2311265
Log Pis Max                  7.933917
Log Pis Min                  -8.263517
Policy mu Mean               0.08507363
Policy mu Std                0.9849117
Policy mu Max                3.1493735
Policy mu Min                -2.5847712
Policy log std Mean          -0.57826275
Policy log std Std           0.19629294
Policy log std Max           0.21145922
Policy log std Min           -1.3840362
Z mean eval                  0.01890536
Z variance eval              0.0011618113
total_rewards                [2066.85452099 1391.41324942 3144.62527302 3148.44668861 3166.90924117
 1116.18489443 1286.50594381 2200.7676554  1126.3020012  2061.64153169]
total_rewards_mean           2070.9650999739547
total_rewards_std            800.8070508669441
total_rewards_max            3166.909241170126
total_rewards_min            1116.1848944348958
Number of train steps total  724000
Number of env steps total    697062
Number of rollouts total     0
Train Time (s)               140.96627927199006
(Previous) Eval Time (s)     19.874743316788226
Sample Time (s)              10.076167888008058
Epoch Time (s)               170.91719047678635
Total Train Time (s)         29283.074558591004
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:38:32.631026 UTC | [2020_01_11_02_30_29] Iteration #180 | Epoch Duration: 171.00541758537292
2020-01-11 10:38:32.631270 UTC | [2020_01_11_02_30_29] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018749729
Z variance train             0.0011620418
KL Divergence                14.743204
KL Loss                      1.4743204
QF Loss                      186.21585
VF Loss                      267.1739
Policy Loss                  -1213.9
Q Predictions Mean           1208.1135
Q Predictions Std            359.35492
Q Predictions Max            1646.2324
Q Predictions Min            22.756973
V Predictions Mean           1216.467
V Predictions Std            354.18085
V Predictions Max            1644.1194
V Predictions Min            24.508907
Log Pis Mean                 0.23242638
Log Pis Std                  2.0999846
Log Pis Max                  8.654154
Log Pis Min                  -3.9992032
Policy mu Mean               0.047385383
Policy mu Std                0.98420197
Policy mu Max                3.2819333
Policy mu Min                -2.7680287
Policy log std Mean          -0.5755059
Policy log std Std           0.22781257
Policy log std Max           0.040168345
Policy log std Min           -2.9767334
Z mean eval                  0.035573624
Z variance eval              0.0013755815
total_rewards                [ 881.70324622  937.81008434 3168.99387385 2506.70957174 3152.77606629
 2293.94652131 1134.40964496 1870.32736521 1970.28707961 3182.68397125]
total_rewards_mean           2109.964742478094
total_rewards_std            863.840087783206
total_rewards_max            3182.6839712526194
total_rewards_min            881.7032462177701
Number of train steps total  728000
Number of env steps total    701605
Number of rollouts total     0
Train Time (s)               140.37739775702357
(Previous) Eval Time (s)     21.309480309020728
Sample Time (s)              9.657503379043192
Epoch Time (s)               171.3443814450875
Total Train Time (s)         29454.508707456756
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:41:24.067626 UTC | [2020_01_11_02_30_29] Iteration #181 | Epoch Duration: 171.43619871139526
2020-01-11 10:41:24.067814 UTC | [2020_01_11_02_30_29] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03534784
Z variance train             0.0013760229
KL Divergence                14.178757
KL Loss                      1.4178756
QF Loss                      311.21265
VF Loss                      129.34207
Policy Loss                  -1223.5623
Q Predictions Mean           1218.3499
Q Predictions Std            381.83475
Q Predictions Max            1671.3704
Q Predictions Min            -34.437218
V Predictions Mean           1222.8871
V Predictions Std            374.01266
V Predictions Max            1674.7714
V Predictions Min            -23.725727
Log Pis Mean                 0.2868352
Log Pis Std                  2.180966
Log Pis Max                  15.2711525
Log Pis Min                  -5.8350973
Policy mu Mean               0.06157884
Policy mu Std                0.9617502
Policy mu Max                3.366606
Policy mu Min                -3.069957
Policy log std Mean          -0.61720985
Policy log std Std           0.21296155
Policy log std Max           0.14350271
Policy log std Min           -2.0392475
Z mean eval                  0.019366978
Z variance eval              0.0012934352
total_rewards                [3116.39181648 2214.50547412  859.96061812 2799.16199209  949.45666766
 2790.82502092 1221.21819152 3118.1719775  2508.64240334 1628.8307097 ]
total_rewards_mean           2120.7164871446303
total_rewards_std            840.672777323255
total_rewards_max            3118.171977496035
total_rewards_min            859.9606181216388
Number of train steps total  732000
Number of env steps total    706296
Number of rollouts total     0
Train Time (s)               140.70852432399988
(Previous) Eval Time (s)     20.985376454889774
Sample Time (s)              9.91614508908242
Epoch Time (s)               171.61004586797208
Total Train Time (s)         29626.19688262418
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:44:15.758255 UTC | [2020_01_11_02_30_29] Iteration #182 | Epoch Duration: 171.6902973651886
2020-01-11 10:44:15.758436 UTC | [2020_01_11_02_30_29] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019390263
Z variance train             0.0012931845
KL Divergence                14.308871
KL Loss                      1.4308871
QF Loss                      230.11615
VF Loss                      76.34125
Policy Loss                  -1254.2368
Q Predictions Mean           1250.061
Q Predictions Std            364.54034
Q Predictions Max            1648.603
Q Predictions Min            17.944588
V Predictions Mean           1251.1001
V Predictions Std            360.72583
V Predictions Max            1650.3059
V Predictions Min            14.568273
Log Pis Mean                 0.31389606
Log Pis Std                  2.0680418
Log Pis Max                  8.544173
Log Pis Min                  -5.630135
Policy mu Mean               0.06747627
Policy mu Std                0.9900899
Policy mu Max                3.1039035
Policy mu Min                -2.9449654
Policy log std Mean          -0.5760478
Policy log std Std           0.21129097
Policy log std Max           0.09739268
Policy log std Min           -2.407002
Z mean eval                  0.020265104
Z variance eval              0.0011729081
total_rewards                [1586.12872557 3197.3917584  3208.80271485  786.59482363  602.26691506
 1656.13572119 3168.90315214 1072.49922028 2939.70263152 3176.90879062]
total_rewards_mean           2139.5334453262126
total_rewards_std            1044.5355325818232
total_rewards_max            3208.802714852208
total_rewards_min            602.2669150569857
Number of train steps total  736000
Number of env steps total    710963
Number of rollouts total     0
Train Time (s)               141.2967709330842
(Previous) Eval Time (s)     22.96566211618483
Sample Time (s)              11.184652334079146
Epoch Time (s)               175.44708538334817
Total Train Time (s)         29801.722307433374
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:47:11.288105 UTC | [2020_01_11_02_30_29] Iteration #183 | Epoch Duration: 175.52950024604797
2020-01-11 10:47:11.288365 UTC | [2020_01_11_02_30_29] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020505127
Z variance train             0.0011734876
KL Divergence                14.472759
KL Loss                      1.447276
QF Loss                      180.15543
VF Loss                      246.06012
Policy Loss                  -1210.1141
Q Predictions Mean           1202.0073
Q Predictions Std            405.44153
Q Predictions Max            1666.9939
Q Predictions Min            12.504207
V Predictions Mean           1206.9409
V Predictions Std            396.47318
V Predictions Max            1663.9395
V Predictions Min            25.769173
Log Pis Mean                 0.63435286
Log Pis Std                  2.1976175
Log Pis Max                  7.743311
Log Pis Min                  -4.595338
Policy mu Mean               0.12052526
Policy mu Std                1.0196004
Policy mu Max                3.4953911
Policy mu Min                -3.4332905
Policy log std Mean          -0.6031418
Policy log std Std           0.23489866
Policy log std Max           0.07369143
Policy log std Min           -2.174459
Z mean eval                  0.019815097
Z variance eval              0.0011494646
total_rewards                [ 934.78336701 3203.38564608 3127.37157244  957.15024096 2822.18982478
  803.30915619 3215.41654417 3142.93058396 3209.19341171 1400.56350276]
total_rewards_mean           2281.6293850055345
total_rewards_std            1042.1727431686893
total_rewards_max            3215.4165441661776
total_rewards_min            803.3091561878955
Number of train steps total  740000
Number of env steps total    715547
Number of rollouts total     0
Train Time (s)               140.8943424122408
(Previous) Eval Time (s)     23.341258890926838
Sample Time (s)              10.335399464238435
Epoch Time (s)               174.57100076740608
Total Train Time (s)         29976.37042171741
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:05.938565 UTC | [2020_01_11_02_30_29] Iteration #184 | Epoch Duration: 174.6500015258789
2020-01-11 10:50:05.938776 UTC | [2020_01_11_02_30_29] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019753598
Z variance train             0.0011503132
KL Divergence                14.486528
KL Loss                      1.4486529
QF Loss                      190.44647
VF Loss                      78.45883
Policy Loss                  -1223.1154
Q Predictions Mean           1220.7223
Q Predictions Std            357.58228
Q Predictions Max            1666.2507
Q Predictions Min            16.06541
V Predictions Mean           1222.598
V Predictions Std            356.01874
V Predictions Max            1658.4998
V Predictions Min            11.476043
Log Pis Mean                 0.30763233
Log Pis Std                  2.1495135
Log Pis Max                  8.141504
Log Pis Min                  -6.423053
Policy mu Mean               -0.050387163
Policy mu Std                1.0112622
Policy mu Max                3.3875155
Policy mu Min                -3.2478268
Policy log std Mean          -0.56689227
Policy log std Std           0.1985582
Policy log std Max           0.14093494
Policy log std Min           -1.6737719
Z mean eval                  0.015319887
Z variance eval              0.0011084337
total_rewards                [1107.96695818  863.1509957  2540.14423676  850.363292    906.92060753
 1820.62737436 2716.27619573 1410.55232729 1196.52119023 1291.73826644]
total_rewards_mean           1470.4261444227607
total_rewards_std            642.7903548992302
total_rewards_max            2716.276195730305
total_rewards_min            850.3632920005301
Number of train steps total  744000
Number of env steps total    720082
Number of rollouts total     0
Train Time (s)               140.40004195226356
(Previous) Eval Time (s)     15.5671420940198
Sample Time (s)              8.21651347912848
Epoch Time (s)               164.18369752541184
Total Train Time (s)         30140.643249221146
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:52:50.213752 UTC | [2020_01_11_02_30_29] Iteration #185 | Epoch Duration: 164.2748157978058
2020-01-11 10:52:50.213940 UTC | [2020_01_11_02_30_29] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015952641
Z variance train             0.001109329
KL Divergence                14.753653
KL Loss                      1.4753653
QF Loss                      2722.2422
VF Loss                      375.6824
Policy Loss                  -1243.4537
Q Predictions Mean           1241.4156
Q Predictions Std            354.62515
Q Predictions Max            1671.7635
Q Predictions Min            36.76936
V Predictions Mean           1247.542
V Predictions Std            347.14963
V Predictions Max            1672.0718
V Predictions Min            63.59777
Log Pis Mean                 0.3492797
Log Pis Std                  2.4820364
Log Pis Max                  18.033068
Log Pis Min                  -5.192386
Policy mu Mean               0.03631337
Policy mu Std                1.0345377
Policy mu Max                4.747511
Policy mu Min                -4.18723
Policy log std Mean          -0.5605914
Policy log std Std           0.23732519
Policy log std Max           0.65120333
Policy log std Min           -1.8949416
Z mean eval                  0.027760807
Z variance eval              0.0012296129
total_rewards                [1762.64648102 1218.62831008 3186.1837143   771.24598332  602.19960772
  957.15616958  840.77388449 1881.9600483  1885.45538255 2937.4139927 ]
total_rewards_mean           1604.3663574074837
total_rewards_std            854.9538074259125
total_rewards_max            3186.1837142976447
total_rewards_min            602.199607724913
Number of train steps total  748000
Number of env steps total    724619
Number of rollouts total     0
Train Time (s)               144.47225306695327
(Previous) Eval Time (s)     16.00984025001526
Sample Time (s)              10.239839316811413
Epoch Time (s)               170.72193263377994
Total Train Time (s)         30311.456631287
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:55:41.030003 UTC | [2020_01_11_02_30_29] Iteration #186 | Epoch Duration: 170.81591200828552
2020-01-11 10:55:41.030256 UTC | [2020_01_11_02_30_29] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02792924
Z variance train             0.0012297712
KL Divergence                14.627287
KL Loss                      1.4627287
QF Loss                      409.50577
VF Loss                      73.99736
Policy Loss                  -1247.5411
Q Predictions Mean           1247.0117
Q Predictions Std            351.36307
Q Predictions Max            1647.9998
Q Predictions Min            -40.016994
V Predictions Mean           1247.6195
V Predictions Std            350.04315
V Predictions Max            1638.2571
V Predictions Min            -10.394469
Log Pis Mean                 0.27875596
Log Pis Std                  2.2223146
Log Pis Max                  9.462092
Log Pis Min                  -5.5333323
Policy mu Mean               0.07233105
Policy mu Std                0.9590011
Policy mu Max                2.625366
Policy mu Min                -2.7290127
Policy log std Mean          -0.58623016
Policy log std Std           0.25283232
Policy log std Max           0.008979738
Policy log std Min           -3.6081834
Z mean eval                  0.028524483
Z variance eval              0.0015568591
total_rewards                [3181.92836548 3192.76866178 3279.35977763 1792.77603295  364.65497154
 3051.82137878 3221.0631     3243.61258153 3226.11942463 2448.15515753]
total_rewards_mean           2700.2259451841196
total_rewards_std            901.0356276209102
total_rewards_max            3279.3597776282595
total_rewards_min            364.65497154110443
Number of train steps total  752000
Number of env steps total    729159
Number of rollouts total     0
Train Time (s)               151.0172942536883
(Previous) Eval Time (s)     27.48026533331722
Sample Time (s)              10.41879261424765
Epoch Time (s)               188.91635220125318
Total Train Time (s)         30500.45185701968
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:50.027930 UTC | [2020_01_11_02_30_29] Iteration #187 | Epoch Duration: 188.99749398231506
2020-01-11 10:58:50.028126 UTC | [2020_01_11_02_30_29] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02836432
Z variance train             0.0015568596
KL Divergence                13.902024
KL Loss                      1.3902024
QF Loss                      100.88292
VF Loss                      56.74464
Policy Loss                  -1238.5197
Q Predictions Mean           1234.9126
Q Predictions Std            357.6674
Q Predictions Max            1671.8214
Q Predictions Min            25.370758
V Predictions Mean           1242.1692
V Predictions Std            353.86978
V Predictions Max            1674.2275
V Predictions Min            25.441141
Log Pis Mean                 0.4068613
Log Pis Std                  2.2204702
Log Pis Max                  12.585201
Log Pis Min                  -5.4783773
Policy mu Mean               0.10603247
Policy mu Std                1.018099
Policy mu Max                3.6900074
Policy mu Min                -2.6003993
Policy log std Mean          -0.60800195
Policy log std Std           0.21540004
Policy log std Max           0.019070387
Policy log std Min           -1.844692
Z mean eval                  0.032685578
Z variance eval              0.001412708
total_rewards                [ 976.69345632  645.66035904  854.16721864  908.38155665 1043.95139321
  861.97047259 1508.46341868 3192.89498192 1089.11002923 1901.62308241]
total_rewards_mean           1298.291596866702
total_rewards_std            719.3854497479466
total_rewards_max            3192.8949819155364
total_rewards_min            645.6603590364202
Number of train steps total  756000
Number of env steps total    733669
Number of rollouts total     0
Train Time (s)               150.19358803983778
(Previous) Eval Time (s)     12.008397634141147
Sample Time (s)              10.493214172311127
Epoch Time (s)               172.69519984629005
Total Train Time (s)         30673.223937852308
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:42.805219 UTC | [2020_01_11_02_30_29] Iteration #188 | Epoch Duration: 172.77693700790405
2020-01-11 11:01:42.805423 UTC | [2020_01_11_02_30_29] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032965608
Z variance train             0.0014115509
KL Divergence                14.134074
KL Loss                      1.4134074
QF Loss                      332.32495
VF Loss                      510.72653
Policy Loss                  -1261.8557
Q Predictions Mean           1255.1078
Q Predictions Std            358.96365
Q Predictions Max            1660.9644
Q Predictions Min            18.324755
V Predictions Mean           1261.1674
V Predictions Std            347.53964
V Predictions Max            1654.1173
V Predictions Min            24.358318
Log Pis Mean                 0.57463527
Log Pis Std                  2.4975994
Log Pis Max                  18.418446
Log Pis Min                  -5.44219
Policy mu Mean               0.09188992
Policy mu Std                1.0588807
Policy mu Max                4.677533
Policy mu Min                -2.7138746
Policy log std Mean          -0.5690022
Policy log std Std           0.22577785
Policy log std Max           0.26832342
Policy log std Min           -1.3881795
Z mean eval                  0.019698089
Z variance eval              0.0017343175
total_rewards                [1551.70044201 1285.82834836 1859.03429367  481.12067047  830.55329142
 1048.68247625 1011.14765157 1790.906678    883.92539117 1488.38361818]
total_rewards_mean           1223.1282861101995
total_rewards_std            424.74889822628967
total_rewards_max            1859.0342936742604
total_rewards_min            481.1206704659299
Number of train steps total  760000
Number of env steps total    738370
Number of rollouts total     0
Train Time (s)               148.44320059893653
(Previous) Eval Time (s)     12.983021403197199
Sample Time (s)              9.423897400964051
Epoch Time (s)               170.85011940309778
Total Train Time (s)         30844.179207456764
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:33.763712 UTC | [2020_01_11_02_30_29] Iteration #189 | Epoch Duration: 170.95808720588684
2020-01-11 11:04:33.764128 UTC | [2020_01_11_02_30_29] Iteration #189 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019047553
Z variance train             0.0017333895
KL Divergence                13.435653
KL Loss                      1.3435653
QF Loss                      255.96786
VF Loss                      120.75752
Policy Loss                  -1246.359
Q Predictions Mean           1240.3462
Q Predictions Std            358.2376
Q Predictions Max            1702.0455
Q Predictions Min            24.897434
V Predictions Mean           1250.368
V Predictions Std            350.6126
V Predictions Max            1703.5602
V Predictions Min            26.976435
Log Pis Mean                 0.57234687
Log Pis Std                  2.6238797
Log Pis Max                  22.227726
Log Pis Min                  -4.590367
Policy mu Mean               0.19971156
Policy mu Std                1.0749394
Policy mu Max                8.803721
Policy mu Min                -4.707981
Policy log std Mean          -0.55492145
Policy log std Std           0.24427249
Policy log std Max           1.7506797
Policy log std Min           -2.4008691
Z mean eval                  0.028909048
Z variance eval              0.0013609548
total_rewards                [1947.42153369 1785.0418152  3169.38156933 3192.13326265 2467.1780541
 3136.14650751 3169.91107553 1278.73637198 3153.29824329 1359.39175315]
total_rewards_mean           2465.8640186415637
total_rewards_std            761.9571365054632
total_rewards_max            3192.133262652178
total_rewards_min            1278.7363719777939
Number of train steps total  764000
Number of env steps total    742978
Number of rollouts total     0
Train Time (s)               149.71891257492825
(Previous) Eval Time (s)     26.026542528998107
Sample Time (s)              10.590562508441508
Epoch Time (s)               186.33601761236787
Total Train Time (s)         31030.59685492702
Epoch                        190
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:07:40.183512 UTC | [2020_01_11_02_30_29] Iteration #190 | Epoch Duration: 186.4191038608551
2020-01-11 11:07:40.183724 UTC | [2020_01_11_02_30_29] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029185226
Z variance train             0.0013609361
KL Divergence                14.060523
KL Loss                      1.4060524
QF Loss                      161.1066
VF Loss                      48.610012
Policy Loss                  -1230.0927
Q Predictions Mean           1225.4347
Q Predictions Std            394.4967
Q Predictions Max            1658.8302
Q Predictions Min            18.239227
V Predictions Mean           1232.9089
V Predictions Std            394.27643
V Predictions Max            1656.383
V Predictions Min            8.714419
Log Pis Mean                 0.26426885
Log Pis Std                  2.1103044
Log Pis Max                  6.5539837
Log Pis Min                  -5.613775
Policy mu Mean               0.17918469
Policy mu Std                0.9946088
Policy mu Max                2.79941
Policy mu Min                -2.6330202
Policy log std Mean          -0.5622832
Policy log std Std           0.19946659
Policy log std Max           0.07081568
Policy log std Min           -1.29398
Z mean eval                  0.028762896
Z variance eval              0.0013160192
total_rewards                [2092.72846223 2685.15340364 3157.0964463  1153.8205836   824.07340074
  929.38010837 1016.28008635  846.20353065 3166.03136422 1538.91900647]
total_rewards_mean           1740.9686392552917
total_rewards_std            908.9642122696065
total_rewards_max            3166.0313642159254
total_rewards_min            824.073400741782
Number of train steps total  768000
Number of env steps total    747557
Number of rollouts total     0
Train Time (s)               141.55605076625943
(Previous) Eval Time (s)     17.62921015918255
Sample Time (s)              9.860647176392376
Epoch Time (s)               169.04590810183436
Total Train Time (s)         31199.725642691832
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:10:29.314807 UTC | [2020_01_11_02_30_29] Iteration #191 | Epoch Duration: 169.13092231750488
2020-01-11 11:10:29.314995 UTC | [2020_01_11_02_30_29] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029048305
Z variance train             0.001316207
KL Divergence                14.341219
KL Loss                      1.434122
QF Loss                      189.52693
VF Loss                      174.59937
Policy Loss                  -1297.2184
Q Predictions Mean           1295.5431
Q Predictions Std            314.53696
Q Predictions Max            1679.0034
Q Predictions Min            163.9922
V Predictions Mean           1293.0287
V Predictions Std            310.0755
V Predictions Max            1676.9785
V Predictions Min            147.92995
Log Pis Mean                 0.1088742
Log Pis Std                  1.9907972
Log Pis Max                  7.5128746
Log Pis Min                  -4.3403063
Policy mu Mean               0.12404876
Policy mu Std                0.9577409
Policy mu Max                3.1201956
Policy mu Min                -2.894899
Policy log std Mean          -0.5943498
Policy log std Std           0.2073022
Policy log std Max           0.077675104
Policy log std Min           -1.3861699
Z mean eval                  0.022321684
Z variance eval              0.0015483557
total_rewards                [ 937.26742872 2642.18793361 1809.0504886  1608.46532278 2379.29292456
 2905.46794499  740.81229109 1176.23209226  834.34224187 3175.28634279]
total_rewards_mean           1820.8405011283255
total_rewards_std            858.9833694487055
total_rewards_max            3175.2863427905863
total_rewards_min            740.8122910935776
Number of train steps total  772000
Number of env steps total    752097
Number of rollouts total     0
Train Time (s)               140.40259119309485
(Previous) Eval Time (s)     18.05736742494628
Sample Time (s)              10.147444787900895
Epoch Time (s)               168.60740340594202
Total Train Time (s)         31368.410824299324
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:13:18.002753 UTC | [2020_01_11_02_30_29] Iteration #192 | Epoch Duration: 168.68761038780212
2020-01-11 11:13:18.002942 UTC | [2020_01_11_02_30_29] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022248017
Z variance train             0.0015494598
KL Divergence                14.244448
KL Loss                      1.4244448
QF Loss                      1320.6382
VF Loss                      838.39716
Policy Loss                  -1248.1006
Q Predictions Mean           1244.0876
Q Predictions Std            368.6112
Q Predictions Max            1670.3737
Q Predictions Min            36.156395
V Predictions Mean           1247.9482
V Predictions Std            363.42102
V Predictions Max            1683.5402
V Predictions Min            36.98302
Log Pis Mean                 0.4163549
Log Pis Std                  2.3316462
Log Pis Max                  17.953714
Log Pis Min                  -5.4996524
Policy mu Mean               0.03783669
Policy mu Std                1.018001
Policy mu Max                3.032497
Policy mu Min                -4.3683586
Policy log std Mean          -0.5523986
Policy log std Std           0.22864726
Policy log std Max           0.19652015
Policy log std Min           -1.7075939
Z mean eval                  0.023654193
Z variance eval              0.001141276
total_rewards                [1802.79566226 3170.27664198 2092.57941158  896.75065939 3118.18985839
 1022.81995517 1557.57981466  937.22926681  950.12160989 1371.2017195 ]
total_rewards_mean           1691.95445996185
total_rewards_std            819.3488292504618
total_rewards_max            3170.276641978315
total_rewards_min            896.750659386354
Number of train steps total  776000
Number of env steps total    756947
Number of rollouts total     0
Train Time (s)               141.4864336149767
(Previous) Eval Time (s)     15.981447231024504
Sample Time (s)              10.617613301612437
Epoch Time (s)               168.08549414761364
Total Train Time (s)         31536.573658313602
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:16:06.168893 UTC | [2020_01_11_02_30_29] Iteration #193 | Epoch Duration: 168.1657898426056
2020-01-11 11:16:06.169158 UTC | [2020_01_11_02_30_29] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023002056
Z variance train             0.0011412457
KL Divergence                14.704139
KL Loss                      1.4704139
QF Loss                      6588.8096
VF Loss                      268.84085
Policy Loss                  -1237.0037
Q Predictions Mean           1225.7074
Q Predictions Std            378.007
Q Predictions Max            1649.9695
Q Predictions Min            3.2718651
V Predictions Mean           1227.6277
V Predictions Std            369.32593
V Predictions Max            1645.3749
V Predictions Min            7.471777
Log Pis Mean                 0.65723413
Log Pis Std                  2.4420612
Log Pis Max                  19.164413
Log Pis Min                  -4.9006634
Policy mu Mean               0.0063754735
Policy mu Std                1.0838928
Policy mu Max                6.7783446
Policy mu Min                -2.682484
Policy log std Mean          -0.57318974
Policy log std Std           0.23703846
Policy log std Max           0.5156289
Policy log std Min           -1.8769487
Z mean eval                  0.022176605
Z variance eval              0.0009071501
total_rewards                [3185.64930401 2301.18582445  932.51519019 2623.80555342 2196.69242022
  917.61469626 3152.23763024 1394.95809213  888.69461134 3132.16520232]
total_rewards_mean           2072.5518524572963
total_rewards_std            916.1477763223482
total_rewards_max            3185.6493040061123
total_rewards_min            888.6946113397122
Number of train steps total  780000
Number of env steps total    761488
Number of rollouts total     0
Train Time (s)               141.26547289220616
(Previous) Eval Time (s)     21.49547209125012
Sample Time (s)              9.724586896132678
Epoch Time (s)               172.48553187958896
Total Train Time (s)         31709.148202660028
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:58.745693 UTC | [2020_01_11_02_30_29] Iteration #194 | Epoch Duration: 172.57636165618896
2020-01-11 11:18:58.745894 UTC | [2020_01_11_02_30_29] Iteration #194 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02167804
Z variance train             0.000906795
KL Divergence                15.274186
KL Loss                      1.5274186
QF Loss                      684.8204
VF Loss                      215.01112
Policy Loss                  -1224.7502
Q Predictions Mean           1220.4634
Q Predictions Std            396.58615
Q Predictions Max            1657.4548
Q Predictions Min            35.331184
V Predictions Mean           1223.5728
V Predictions Std            389.1184
V Predictions Max            1648.7015
V Predictions Min            28.61421
Log Pis Mean                 0.50765663
Log Pis Std                  2.2760563
Log Pis Max                  7.5574455
Log Pis Min                  -4.783786
Policy mu Mean               0.058155496
Policy mu Std                1.039602
Policy mu Max                2.7986984
Policy mu Min                -3.402096
Policy log std Mean          -0.59071517
Policy log std Std           0.2531435
Policy log std Max           0.112809
Policy log std Min           -2.9081578
Z mean eval                  0.034955803
Z variance eval              0.0008820059
total_rewards                [3204.78794423 3193.17174553 1914.27021061 3181.22171402  677.0297842
 1775.48276702 3176.53455045 3168.25225018 3174.8639333  3214.11809743]
total_rewards_mean           2667.9732996980574
total_rewards_std            849.7068266649663
total_rewards_max            3214.1180974294875
total_rewards_min            677.0297841979074
Number of train steps total  784000
Number of env steps total    766094
Number of rollouts total     0
Train Time (s)               141.63855211203918
(Previous) Eval Time (s)     25.94518241425976
Sample Time (s)              10.271642816718668
Epoch Time (s)               177.8553773430176
Total Train Time (s)         31887.246437971015
Epoch                        195
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:56.846673 UTC | [2020_01_11_02_30_29] Iteration #195 | Epoch Duration: 178.10062456130981
2020-01-11 11:21:56.846867 UTC | [2020_01_11_02_30_29] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03499223
Z variance train             0.0008823746
KL Divergence                15.146376
KL Loss                      1.5146376
QF Loss                      384.59222
VF Loss                      63.488907
Policy Loss                  -1257.4315
Q Predictions Mean           1257.3379
Q Predictions Std            336.47217
Q Predictions Max            1646.8201
Q Predictions Min            108.49375
V Predictions Mean           1260.3699
V Predictions Std            334.67673
V Predictions Max            1633.4183
V Predictions Min            99.16783
Log Pis Mean                 0.27049226
Log Pis Std                  2.1465836
Log Pis Max                  8.894888
Log Pis Min                  -4.359483
Policy mu Mean               0.050455227
Policy mu Std                0.9814815
Policy mu Max                2.5663824
Policy mu Min                -2.8637662
Policy log std Mean          -0.5786183
Policy log std Std           0.20278019
Policy log std Max           0.08757305
Policy log std Min           -1.3728755
Z mean eval                  0.025496488
Z variance eval              0.0011317609
total_rewards                [1603.11534139 2828.80697493 2418.41521356 3136.98867931 3167.80602352
 3122.01758517 1947.94884887 3185.54748116 3148.53016483 3063.75638178]
total_rewards_mean           2762.2932694515416
total_rewards_std            546.1655790102183
total_rewards_max            3185.5474811602785
total_rewards_min            1603.1153413876395
Number of train steps total  788000
Number of env steps total    770514
Number of rollouts total     0
Train Time (s)               142.65860717277974
(Previous) Eval Time (s)     28.008460272103548
Sample Time (s)              10.31648346176371
Epoch Time (s)               180.983550906647
Total Train Time (s)         32068.30998246325
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:24:57.912858 UTC | [2020_01_11_02_30_29] Iteration #196 | Epoch Duration: 181.06583786010742
2020-01-11 11:24:57.913055 UTC | [2020_01_11_02_30_29] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025415799
Z variance train             0.0011308958
KL Divergence                14.638413
KL Loss                      1.4638413
QF Loss                      225.69586
VF Loss                      39.59079
Policy Loss                  -1187.3744
Q Predictions Mean           1179.489
Q Predictions Std            420.62317
Q Predictions Max            1672.8708
Q Predictions Min            19.58421
V Predictions Mean           1185.7928
V Predictions Std            416.38077
V Predictions Max            1675.0852
V Predictions Min            13.026983
Log Pis Mean                 0.1757442
Log Pis Std                  2.215403
Log Pis Max                  9.623295
Log Pis Min                  -4.388132
Policy mu Mean               0.07771819
Policy mu Std                0.9882226
Policy mu Max                3.1644793
Policy mu Min                -2.5595963
Policy log std Mean          -0.5619835
Policy log std Std           0.23244551
Policy log std Max           0.25803006
Policy log std Min           -2.5158646
Z mean eval                  0.03974522
Z variance eval              0.0014460081
total_rewards                [1339.78291276 3036.06699598  891.26423847 1653.49497252  896.91313383
  831.56866298 3115.41092061 3141.65893781 3139.24991954 3044.86499409]
total_rewards_mean           2109.02756885966
total_rewards_std            1012.8674320225538
total_rewards_max            3141.6589378141507
total_rewards_min            831.5686629840064
Number of train steps total  792000
Number of env steps total    775136
Number of rollouts total     0
Train Time (s)               141.52649043127894
(Previous) Eval Time (s)     21.70146328676492
Sample Time (s)              9.469674643594772
Epoch Time (s)               172.69762836163864
Total Train Time (s)         32241.09041327657
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:27:50.696349 UTC | [2020_01_11_02_30_29] Iteration #197 | Epoch Duration: 172.78313159942627
2020-01-11 11:27:50.696598 UTC | [2020_01_11_02_30_29] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039712735
Z variance train             0.0014448187
KL Divergence                14.300406
KL Loss                      1.4300407
QF Loss                      919.08606
VF Loss                      52.800343
Policy Loss                  -1273.8922
Q Predictions Mean           1263.9004
Q Predictions Std            326.0466
Q Predictions Max            1639.0298
Q Predictions Min            13.374154
V Predictions Mean           1273.1824
V Predictions Std            322.1517
V Predictions Max            1658.9908
V Predictions Min            27.3763
Log Pis Mean                 0.44948977
Log Pis Std                  2.322228
Log Pis Max                  8.22838
Log Pis Min                  -5.868699
Policy mu Mean               0.06688108
Policy mu Std                1.000856
Policy mu Max                3.1437376
Policy mu Min                -2.5817156
Policy log std Mean          -0.5804143
Policy log std Std           0.21381487
Policy log std Max           0.18536419
Policy log std Min           -1.7563182
Z mean eval                  0.045750324
Z variance eval              0.001377634
total_rewards                [ 668.91768693 3172.38751974  974.40544651 1291.85928539 1608.84985794
  932.04428842 3254.52391479 3212.03047816  909.73608881 3165.20482291]
total_rewards_mean           1918.9959389606338
total_rewards_std            1073.1596873284273
total_rewards_max            3254.5239147931197
total_rewards_min            668.9176869282247
Number of train steps total  796000
Number of env steps total    779659
Number of rollouts total     0
Train Time (s)               141.77894537197426
(Previous) Eval Time (s)     18.010119538288563
Sample Time (s)              10.306739708408713
Epoch Time (s)               170.09580461867154
Total Train Time (s)         32411.277085414156
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:30:40.885955 UTC | [2020_01_11_02_30_29] Iteration #198 | Epoch Duration: 170.1891553401947
2020-01-11 11:30:40.886212 UTC | [2020_01_11_02_30_29] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046201132
Z variance train             0.0013787344
KL Divergence                14.203244
KL Loss                      1.4203244
QF Loss                      5544.113
VF Loss                      587.8667
Policy Loss                  -1281.0408
Q Predictions Mean           1276.9282
Q Predictions Std            357.0135
Q Predictions Max            1682.6206
Q Predictions Min            10.015279
V Predictions Mean           1276.1968
V Predictions Std            349.42004
V Predictions Max            1671.4022
V Predictions Min            6.929141
Log Pis Mean                 0.70285064
Log Pis Std                  2.4845715
Log Pis Max                  20.104698
Log Pis Min                  -5.124836
Policy mu Mean               0.017055042
Policy mu Std                1.0942081
Policy mu Max                9.159098
Policy mu Min                -2.959994
Policy log std Mean          -0.5833439
Policy log std Std           0.20870607
Policy log std Max           2.0
Policy log std Min           -1.8804374
Z mean eval                  0.02228889
Z variance eval              0.0013567408
total_rewards                [ 854.89948372 3185.52903108 3162.19752294 1872.66822985 1483.72202474
 3180.99892626  520.84011705 1238.5159648  3192.25855357  745.9421531 ]
total_rewards_mean           1943.7572007097035
total_rewards_std            1071.225142624139
total_rewards_max            3192.258553567186
total_rewards_min            520.840117047632
Number of train steps total  800000
Number of env steps total    784079
Number of rollouts total     0
Train Time (s)               140.0581934740767
(Previous) Eval Time (s)     20.39635946135968
Sample Time (s)              9.987699263729155
Epoch Time (s)               170.44225219916552
Total Train Time (s)         32581.798756585922
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:33:31.409942 UTC | [2020_01_11_02_30_29] Iteration #199 | Epoch Duration: 170.52356433868408
2020-01-11 11:33:31.410135 UTC | [2020_01_11_02_30_29] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022241518
Z variance train             0.0013570394
KL Divergence                14.191158
KL Loss                      1.4191159
QF Loss                      464.5663
VF Loss                      128.60796
Policy Loss                  -1199.4626
Q Predictions Mean           1197.4917
Q Predictions Std            412.4714
Q Predictions Max            1664.6892
Q Predictions Min            4.3158307
V Predictions Mean           1205.1421
V Predictions Std            411.47263
V Predictions Max            1670.9954
V Predictions Min            10.627058
Log Pis Mean                 0.58639926
Log Pis Std                  2.1456132
Log Pis Max                  7.905729
Log Pis Min                  -6.1406965
Policy mu Mean               -0.04233079
Policy mu Std                1.0461775
Policy mu Max                3.6494908
Policy mu Min                -3.2625406
Policy log std Mean          -0.5849452
Policy log std Std           0.21533574
Policy log std Max           0.023029983
Policy log std Min           -2.1321383
Z mean eval                  0.023534479
Z variance eval              0.001190195
total_rewards                [ 957.90148591 3087.66518209 1431.53074256  902.78658616 1402.53531817
 3154.91794795 3124.96832704 1581.61593605  848.25401122 3172.42408266]
total_rewards_mean           1966.4599619803557
total_rewards_std            980.6765837255296
total_rewards_max            3172.424082662795
total_rewards_min            848.2540112208293
Number of train steps total  804000
Number of env steps total    788714
Number of rollouts total     0
Train Time (s)               142.0767156239599
(Previous) Eval Time (s)     19.73558833869174
Sample Time (s)              9.672967268154025
Epoch Time (s)               171.48527123080567
Total Train Time (s)         32753.375624614302
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:36:22.989692 UTC | [2020_01_11_02_30_29] Iteration #200 | Epoch Duration: 171.57935333251953
2020-01-11 11:36:22.990004 UTC | [2020_01_11_02_30_29] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023989756
Z variance train             0.0011883118
KL Divergence                14.601866
KL Loss                      1.4601866
QF Loss                      1858.4025
VF Loss                      232.49149
Policy Loss                  -1270.242
Q Predictions Mean           1273.9253
Q Predictions Std            340.54785
Q Predictions Max            1654.103
Q Predictions Min            65.897995
V Predictions Mean           1259.6642
V Predictions Std            337.7595
V Predictions Max            1639.6421
V Predictions Min            57.990154
Log Pis Mean                 0.30416012
Log Pis Std                  2.2348998
Log Pis Max                  19.0985
Log Pis Min                  -5.4332647
Policy mu Mean               0.004556784
Policy mu Std                1.0573235
Policy mu Max                10.254896
Policy mu Min                -2.7565298
Policy log std Mean          -0.57316977
Policy log std Std           0.21714546
Policy log std Max           2.0
Policy log std Min           -1.2488164
Z mean eval                  0.016123816
Z variance eval              0.0012933479
total_rewards                [1065.583471    832.37847171 3176.27446836 1041.22457367 3186.18936515
 3182.48106181 3122.66473266 3182.44893864 2647.29623849 3145.0760648 ]
total_rewards_mean           2458.1617386297467
total_rewards_std            981.5439021831799
total_rewards_max            3186.1893651549926
total_rewards_min            832.3784717094918
Number of train steps total  808000
Number of env steps total    793380
Number of rollouts total     0
Train Time (s)               141.79386828280985
(Previous) Eval Time (s)     24.893460775725543
Sample Time (s)              8.862182188779116
Epoch Time (s)               175.5495112473145
Total Train Time (s)         32929.00271512568
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:39:18.619347 UTC | [2020_01_11_02_30_29] Iteration #201 | Epoch Duration: 175.6291151046753
2020-01-11 11:39:18.619544 UTC | [2020_01_11_02_30_29] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016066942
Z variance train             0.0012931959
KL Divergence                14.254324
KL Loss                      1.4254324
QF Loss                      145.6437
VF Loss                      154.08043
Policy Loss                  -1279.4031
Q Predictions Mean           1278.7705
Q Predictions Std            335.86087
Q Predictions Max            1674.5338
Q Predictions Min            13.186351
V Predictions Mean           1275.9265
V Predictions Std            330.1438
V Predictions Max            1660.6189
V Predictions Min            11.758193
Log Pis Mean                 0.08729624
Log Pis Std                  1.9893088
Log Pis Max                  7.7884326
Log Pis Min                  -5.5670586
Policy mu Mean               0.12541123
Policy mu Std                0.9159961
Policy mu Max                2.9425526
Policy mu Min                -2.5846992
Policy log std Mean          -0.56063384
Policy log std Std           0.21281816
Policy log std Max           0.5885007
Policy log std Min           -1.532727
Z mean eval                  0.031225055
Z variance eval              0.0010593801
total_rewards                [1967.64474672 3119.64879952  839.08380018 3145.42421963 3139.25200543
 2854.50879045  883.48626897 2622.34049974  962.99614966 3057.01940067]
total_rewards_mean           2259.1404680979404
total_rewards_std            953.808343096112
total_rewards_max            3145.4242196325704
total_rewards_min            839.0838001778214
Number of train steps total  812000
Number of env steps total    798159
Number of rollouts total     0
Train Time (s)               141.14113554917276
(Previous) Eval Time (s)     23.37327138381079
Sample Time (s)              10.341719454620034
Epoch Time (s)               174.85612638760358
Total Train Time (s)         33103.9388463581
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:42:13.558568 UTC | [2020_01_11_02_30_29] Iteration #202 | Epoch Duration: 174.93884253501892
2020-01-11 11:42:13.558788 UTC | [2020_01_11_02_30_29] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031201642
Z variance train             0.0010598082
KL Divergence                14.769658
KL Loss                      1.4769658
QF Loss                      335.15448
VF Loss                      82.5998
Policy Loss                  -1244.2052
Q Predictions Mean           1243.4861
Q Predictions Std            366.7829
Q Predictions Max            1665.3578
Q Predictions Min            -0.2844355
V Predictions Mean           1242.1378
V Predictions Std            361.2561
V Predictions Max            1659.1614
V Predictions Min            48.730804
Log Pis Mean                 0.48566365
Log Pis Std                  2.1543853
Log Pis Max                  7.5777416
Log Pis Min                  -4.3792524
Policy mu Mean               0.038600028
Policy mu Std                1.0360417
Policy mu Max                2.6498606
Policy mu Min                -3.0285678
Policy log std Mean          -0.58948725
Policy log std Std           0.27671877
Policy log std Max           0.41960233
Policy log std Min           -3.2053537
Z mean eval                  0.03677169
Z variance eval              0.0010590487
total_rewards                [3292.73262797  961.71254941 1623.22692419  932.59709559 3236.88928174
  865.54070485  608.67972965 2470.53467861  891.50658654 3213.53322743]
total_rewards_mean           1809.6953405975553
total_rewards_std            1065.0744228649212
total_rewards_max            3292.7326279671806
total_rewards_min            608.6797296537953
Number of train steps total  816000
Number of env steps total    802910
Number of rollouts total     0
Train Time (s)               142.5856940858066
(Previous) Eval Time (s)     17.740960633847862
Sample Time (s)              9.530123963020742
Epoch Time (s)               169.8567786826752
Total Train Time (s)         33273.88446374005
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:45:03.507146 UTC | [2020_01_11_02_30_29] Iteration #203 | Epoch Duration: 169.94816660881042
2020-01-11 11:45:03.507390 UTC | [2020_01_11_02_30_29] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036013253
Z variance train             0.0010609502
KL Divergence                14.699822
KL Loss                      1.4699823
QF Loss                      4180.297
VF Loss                      78.644264
Policy Loss                  -1260.9612
Q Predictions Mean           1257.8796
Q Predictions Std            359.60275
Q Predictions Max            1706.2385
Q Predictions Min            46.850193
V Predictions Mean           1258.6677
V Predictions Std            358.27734
V Predictions Max            1701.3671
V Predictions Min            34.619118
Log Pis Mean                 0.30805913
Log Pis Std                  2.1253524
Log Pis Max                  7.730088
Log Pis Min                  -6.274957
Policy mu Mean               0.12022221
Policy mu Std                0.98583394
Policy mu Max                2.7274714
Policy mu Min                -2.8553522
Policy log std Mean          -0.6030431
Policy log std Std           0.20125027
Policy log std Max           0.13706303
Policy log std Min           -1.4347908
Z mean eval                  0.025418457
Z variance eval              0.001133699
total_rewards                [2747.84124389 3212.00514224 3159.57386389 3190.64622153 3194.23086144
 3133.51013879  798.21632854  788.6390295   938.31879263 3176.68173643]
total_rewards_mean           2433.966335887702
total_rewards_std            1050.7932255480905
total_rewards_max            3212.005142236247
total_rewards_min            788.6390295048582
Number of train steps total  820000
Number of env steps total    807572
Number of rollouts total     0
Train Time (s)               141.5862265652977
(Previous) Eval Time (s)     24.19686742918566
Sample Time (s)              10.080620107706636
Epoch Time (s)               175.86371410219
Total Train Time (s)         33449.84100449877
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:47:59.466738 UTC | [2020_01_11_02_30_29] Iteration #204 | Epoch Duration: 175.95919370651245
2020-01-11 11:47:59.466953 UTC | [2020_01_11_02_30_29] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025663208
Z variance train             0.0011336305
KL Divergence                14.8610735
KL Loss                      1.4861073
QF Loss                      168.5797
VF Loss                      58.023132
Policy Loss                  -1278.8395
Q Predictions Mean           1279.9932
Q Predictions Std            335.38257
Q Predictions Max            1688.1997
Q Predictions Min            -8.869901
V Predictions Mean           1275.4443
V Predictions Std            333.1934
V Predictions Max            1687.8071
V Predictions Min            17.154356
Log Pis Mean                 0.26326922
Log Pis Std                  2.34649
Log Pis Max                  8.140151
Log Pis Min                  -6.3592978
Policy mu Mean               0.082414925
Policy mu Std                1.0043553
Policy mu Max                2.7836897
Policy mu Min                -2.6319594
Policy log std Mean          -0.5687082
Policy log std Std           0.21823324
Policy log std Max           0.5993694
Policy log std Min           -2.033339
Z mean eval                  0.014870109
Z variance eval              0.00090485933
total_rewards                [3190.80467867  893.72997284  611.29665597  855.24318856 3192.20260468
  904.45662634  605.27550135  957.92602939  820.5144476   885.06343086]
total_rewards_mean           1291.651313625124
total_rewards_std            956.5689896178424
total_rewards_max            3192.2026046819674
total_rewards_min            605.275501346051
Number of train steps total  824000
Number of env steps total    812176
Number of rollouts total     0
Train Time (s)               143.65167072368786
(Previous) Eval Time (s)     12.898623867891729
Sample Time (s)              9.27814210485667
Epoch Time (s)               165.82843669643626
Total Train Time (s)         33615.7579624597
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:50:45.390568 UTC | [2020_01_11_02_30_29] Iteration #205 | Epoch Duration: 165.92344689369202
2020-01-11 11:50:45.390808 UTC | [2020_01_11_02_30_29] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01498985
Z variance train             0.00090522796
KL Divergence                15.22694
KL Loss                      1.522694
QF Loss                      736.6267
VF Loss                      157.92981
Policy Loss                  -1215.6633
Q Predictions Mean           1205.3115
Q Predictions Std            417.4551
Q Predictions Max            1661.8555
Q Predictions Min            -0.94682956
V Predictions Mean           1216.2479
V Predictions Std            401.88998
V Predictions Max            1667.6447
V Predictions Min            66.176765
Log Pis Mean                 0.5449181
Log Pis Std                  2.2443428
Log Pis Max                  8.82923
Log Pis Min                  -4.0301228
Policy mu Mean               -0.0071242205
Policy mu Std                1.032525
Policy mu Max                3.801107
Policy mu Min                -3.1114523
Policy log std Mean          -0.60302204
Policy log std Std           0.24902238
Policy log std Max           0.08258271
Policy log std Min           -2.6138742
Z mean eval                  0.034131534
Z variance eval              0.0008929643
total_rewards                [ 950.98938603  625.81741502  603.73090262  594.35934907  938.63522164
 3112.7081974  1491.29078352 3115.743012   3149.327095    780.29647613]
total_rewards_mean           1536.2897838430194
total_rewards_std            1069.6183501508372
total_rewards_max            3149.327095004441
total_rewards_min            594.3593490675383
Number of train steps total  828000
Number of env steps total    816939
Number of rollouts total     0
Train Time (s)               153.23687676433474
(Previous) Eval Time (s)     16.01815042179078
Sample Time (s)              10.31479473831132
Epoch Time (s)               179.56982192443684
Total Train Time (s)         33795.457353567705
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:53:45.094137 UTC | [2020_01_11_02_30_29] Iteration #206 | Epoch Duration: 179.70313572883606
2020-01-11 11:53:45.094416 UTC | [2020_01_11_02_30_29] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033706654
Z variance train             0.0008922004
KL Divergence                15.115334
KL Loss                      1.5115334
QF Loss                      380.68213
VF Loss                      91.25826
Policy Loss                  -1261.1748
Q Predictions Mean           1258.2607
Q Predictions Std            381.1496
Q Predictions Max            1677.2659
Q Predictions Min            -14.440732
V Predictions Mean           1257.344
V Predictions Std            378.05933
V Predictions Max            1669.6593
V Predictions Min            15.377765
Log Pis Mean                 0.4909272
Log Pis Std                  2.3598523
Log Pis Max                  11.614944
Log Pis Min                  -4.9330683
Policy mu Mean               0.08768018
Policy mu Std                1.0207496
Policy mu Max                2.748396
Policy mu Min                -2.9933767
Policy log std Mean          -0.57512957
Policy log std Std           0.18221916
Policy log std Max           0.019998252
Policy log std Min           -1.228811
Z mean eval                  0.03225956
Z variance eval              0.00079897325
total_rewards                [1067.1279684   937.71192846  594.19448272 1734.79936053  279.91542606
  394.52127921  292.33238426  249.22504028 3074.16162916  852.02799163]
total_rewards_mean           947.6017490714319
total_rewards_std            834.2160012646738
total_rewards_max            3074.161629155325
total_rewards_min            249.22504028464462
Number of train steps total  832000
Number of env steps total    821658
Number of rollouts total     0
Train Time (s)               148.80664980784059
(Previous) Eval Time (s)     9.928283793386072
Sample Time (s)              10.195844027213752
Epoch Time (s)               168.9307776284404
Total Train Time (s)         33964.49897045549
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:56:34.137502 UTC | [2020_01_11_02_30_29] Iteration #207 | Epoch Duration: 169.04290223121643
2020-01-11 11:56:34.137693 UTC | [2020_01_11_02_30_29] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032116164
Z variance train             0.0007989787
KL Divergence                15.47077
KL Loss                      1.5470771
QF Loss                      160.75342
VF Loss                      76.64463
Policy Loss                  -1219.745
Q Predictions Mean           1217.5261
Q Predictions Std            407.288
Q Predictions Max            1667.8563
Q Predictions Min            -20.43074
V Predictions Mean           1214.6748
V Predictions Std            403.71234
V Predictions Max            1659.7936
V Predictions Min            -20.91267
Log Pis Mean                 0.53986955
Log Pis Std                  2.3192058
Log Pis Max                  7.632886
Log Pis Min                  -7.3157253
Policy mu Mean               0.098925956
Policy mu Std                1.024735
Policy mu Max                3.221085
Policy mu Min                -2.7577493
Policy log std Mean          -0.59603816
Policy log std Std           0.2154816
Policy log std Max           0.68519706
Policy log std Min           -1.6316886
Z mean eval                  0.034097828
Z variance eval              0.000984751
total_rewards                [2159.43708647  944.91669652 1864.84533751 1236.43456426 3249.41035151
 3221.09886382 3193.03941354 2437.92571856 1076.6338216  3226.32674676]
total_rewards_mean           2261.0068600565164
total_rewards_std            899.0209751408114
total_rewards_max            3249.4103515104575
total_rewards_min            944.9166965242962
Number of train steps total  836000
Number of env steps total    826430
Number of rollouts total     0
Train Time (s)               149.18416175292805
(Previous) Eval Time (s)     23.192869120277464
Sample Time (s)              10.357508913613856
Epoch Time (s)               182.73453978681937
Total Train Time (s)         34147.343098501675
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:36.984636 UTC | [2020_01_11_02_30_29] Iteration #208 | Epoch Duration: 182.84679746627808
2020-01-11 11:59:36.984835 UTC | [2020_01_11_02_30_29] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034284476
Z variance train             0.0009842619
KL Divergence                15.118834
KL Loss                      1.5118834
QF Loss                      111.715
VF Loss                      30.841764
Policy Loss                  -1272.32
Q Predictions Mean           1273.4303
Q Predictions Std            362.16592
Q Predictions Max            1673.499
Q Predictions Min            5.9644914
V Predictions Mean           1270.9148
V Predictions Std            360.58685
V Predictions Max            1662.8657
V Predictions Min            14.485902
Log Pis Mean                 0.24609476
Log Pis Std                  2.1705835
Log Pis Max                  6.3697042
Log Pis Min                  -5.3516283
Policy mu Mean               0.15438832
Policy mu Std                0.9800189
Policy mu Max                3.5554147
Policy mu Min                -2.7264028
Policy log std Mean          -0.5702913
Policy log std Std           0.24005824
Policy log std Max           0.49572164
Policy log std Min           -2.5768592
Z mean eval                  0.026103562
Z variance eval              0.0010439574
total_rewards                [1109.70062178  855.23996777  824.66683136 2282.82696891  813.14080815
 2487.93297712 2729.0344975  1118.74715082  859.03349735 1138.95875712]
total_rewards_mean           1421.9282077877565
total_rewards_std            722.5541843118591
total_rewards_max            2729.034497504033
total_rewards_min            813.1408081461424
Number of train steps total  840000
Number of env steps total    831124
Number of rollouts total     0
Train Time (s)               149.83125634817407
(Previous) Eval Time (s)     13.433359718881547
Sample Time (s)              10.320496963802725
Epoch Time (s)               173.58511303085834
Total Train Time (s)         34321.01670202846
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:30.661126 UTC | [2020_01_11_02_30_29] Iteration #209 | Epoch Duration: 173.67614316940308
2020-01-11 12:02:30.661311 UTC | [2020_01_11_02_30_29] Iteration #209 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025686175
Z variance train             0.0010435435
KL Divergence                14.948772
KL Loss                      1.4948772
QF Loss                      144.9094
VF Loss                      84.973145
Policy Loss                  -1263.7137
Q Predictions Mean           1262.2539
Q Predictions Std            366.92603
Q Predictions Max            1636.1016
Q Predictions Min            27.22362
V Predictions Mean           1261.3704
V Predictions Std            363.58377
V Predictions Max            1651.5276
V Predictions Min            43.50979
Log Pis Mean                 0.3276369
Log Pis Std                  2.2826293
Log Pis Max                  15.118626
Log Pis Min                  -5.403637
Policy mu Mean               0.0606491
Policy mu Std                0.99464583
Policy mu Max                3.7199433
Policy mu Min                -2.9476888
Policy log std Mean          -0.5884252
Policy log std Std           0.20644447
Policy log std Max           0.15538162
Policy log std Min           -1.8543143
Z mean eval                  0.017307932
Z variance eval              0.0007959716
total_rewards                [1055.16757504 1535.2708148  3243.92734903 3299.34559163 3245.0661683
  980.33565862 1027.79811776 3063.78336458  988.65513573 3327.97756944]
total_rewards_mean           2176.7327344932846
total_rewards_std            1071.6832875016576
total_rewards_max            3327.977569438422
total_rewards_min            980.3356586231482
Number of train steps total  844000
Number of env steps total    835699
Number of rollouts total     0
Train Time (s)               144.73156162165105
(Previous) Eval Time (s)     20.940153516829014
Sample Time (s)              10.114308523479849
Epoch Time (s)               175.78602366195992
Total Train Time (s)         34496.88315543858
Epoch                        210
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:26.530216 UTC | [2020_01_11_02_30_29] Iteration #210 | Epoch Duration: 175.8687572479248
2020-01-11 12:05:26.530413 UTC | [2020_01_11_02_30_29] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018374376
Z variance train             0.00079786294
KL Divergence                15.518862
KL Loss                      1.5518862
QF Loss                      1309.6074
VF Loss                      119.03383
Policy Loss                  -1269.6519
Q Predictions Mean           1262.8567
Q Predictions Std            386.54156
Q Predictions Max            1669.6892
Q Predictions Min            11.641957
V Predictions Mean           1261.6172
V Predictions Std            380.77734
V Predictions Max            1661.867
V Predictions Min            5.2547755
Log Pis Mean                 0.32959545
Log Pis Std                  2.2474048
Log Pis Max                  6.9883933
Log Pis Min                  -6.5968146
Policy mu Mean               0.010637094
Policy mu Std                1.0112926
Policy mu Max                2.3874729
Policy mu Min                -2.568008
Policy log std Mean          -0.58140665
Policy log std Std           0.21666583
Policy log std Max           0.11629659
Policy log std Min           -1.7303605
Z mean eval                  0.057299756
Z variance eval              0.0010078446
total_rewards                [ 986.21902383 3215.33330487 1128.81770666 3227.85962242 2015.22117409
 3265.75831879 3250.14463903 3295.42361873 3224.4125273   831.00314405]
total_rewards_mean           2444.01930797662
total_rewards_std            1025.1318331833022
total_rewards_max            3295.423618726575
total_rewards_min            831.0031440452901
Number of train steps total  848000
Number of env steps total    840343
Number of rollouts total     0
Train Time (s)               140.60507677588612
(Previous) Eval Time (s)     23.79044894594699
Sample Time (s)              10.205449463799596
Epoch Time (s)               174.6009751856327
Total Train Time (s)         34671.57263261406
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:08:21.223741 UTC | [2020_01_11_02_30_29] Iteration #211 | Epoch Duration: 174.69316482543945
2020-01-11 12:08:21.223997 UTC | [2020_01_11_02_30_29] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05692668
Z variance train             0.0010081723
KL Divergence                15.228474
KL Loss                      1.5228474
QF Loss                      212.1919
VF Loss                      37.19663
Policy Loss                  -1290.5614
Q Predictions Mean           1284.4574
Q Predictions Std            380.63174
Q Predictions Max            1709.1785
Q Predictions Min            -37.724503
V Predictions Mean           1290.4304
V Predictions Std            367.69122
V Predictions Max            1705.1377
V Predictions Min            92.97088
Log Pis Mean                 0.24895504
Log Pis Std                  2.390829
Log Pis Max                  17.384228
Log Pis Min                  -5.723591
Policy mu Mean               0.070505075
Policy mu Std                0.99036926
Policy mu Max                4.237807
Policy mu Min                -4.044639
Policy log std Mean          -0.5792592
Policy log std Std           0.20451415
Policy log std Max           0.22027206
Policy log std Min           -2.1947682
Z mean eval                  0.033292256
Z variance eval              0.0010762695
total_rewards                [1267.0396555   811.79211608 3201.78783952 3147.2064261  3193.15785643
 3153.5931873  3158.76746671 3211.90119736  910.86812228 3190.04226563]
total_rewards_mean           2524.615613289672
total_rewards_std            1006.2548547710293
total_rewards_max            3211.9011973643337
total_rewards_min            811.7921160793471
Number of train steps total  852000
Number of env steps total    845010
Number of rollouts total     0
Train Time (s)               142.74033774994314
(Previous) Eval Time (s)     24.882449645083398
Sample Time (s)              9.051995008252561
Epoch Time (s)               176.6747824032791
Total Train Time (s)         34848.33022188069
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:17.985304 UTC | [2020_01_11_02_30_29] Iteration #212 | Epoch Duration: 176.76111149787903
2020-01-11 12:11:17.985561 UTC | [2020_01_11_02_30_29] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03314978
Z variance train             0.0010765074
KL Divergence                14.976627
KL Loss                      1.4976628
QF Loss                      595.29913
VF Loss                      130.92906
Policy Loss                  -1237.1641
Q Predictions Mean           1234.6714
Q Predictions Std            400.40732
Q Predictions Max            1659.9227
Q Predictions Min            8.671944
V Predictions Mean           1238.9489
V Predictions Std            402.01392
V Predictions Max            1661.1267
V Predictions Min            -19.585629
Log Pis Mean                 0.40452975
Log Pis Std                  2.3791122
Log Pis Max                  8.450385
Log Pis Min                  -5.3719006
Policy mu Mean               0.0054630428
Policy mu Std                1.0055051
Policy mu Max                3.3000336
Policy mu Min                -3.3155348
Policy log std Mean          -0.6045763
Policy log std Std           0.22012736
Policy log std Max           0.049970627
Policy log std Min           -2.4051583
Z mean eval                  0.034876533
Z variance eval              0.0010328818
total_rewards                [3177.19572525 3225.64140593 1101.58887319 2136.80711491  816.59820899
 3175.72463095 2951.31262029 3150.54771961  834.89336334 3156.08581196]
total_rewards_mean           2372.6395474426986
total_rewards_std            1001.5375624792528
total_rewards_max            3225.641405928093
total_rewards_min            816.5982089898241
Number of train steps total  856000
Number of env steps total    849729
Number of rollouts total     0
Train Time (s)               140.88620657799765
(Previous) Eval Time (s)     22.885324926581234
Sample Time (s)              9.619768753182143
Epoch Time (s)               173.39130025776103
Total Train Time (s)         35021.812584483996
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:14:11.470362 UTC | [2020_01_11_02_30_29] Iteration #213 | Epoch Duration: 173.48460340499878
2020-01-11 12:14:11.470573 UTC | [2020_01_11_02_30_29] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035886742
Z variance train             0.0010326785
KL Divergence                14.896297
KL Loss                      1.4896297
QF Loss                      148.4199
VF Loss                      89.98981
Policy Loss                  -1248.5121
Q Predictions Mean           1250.0636
Q Predictions Std            336.28275
Q Predictions Max            1687.7612
Q Predictions Min            88.279106
V Predictions Mean           1249.5942
V Predictions Std            335.38705
V Predictions Max            1678.4962
V Predictions Min            78.4886
Log Pis Mean                 0.3367616
Log Pis Std                  2.2232523
Log Pis Max                  6.6878653
Log Pis Min                  -5.6400175
Policy mu Mean               0.06869542
Policy mu Std                0.9944519
Policy mu Max                2.6176183
Policy mu Min                -2.824955
Policy log std Mean          -0.59317595
Policy log std Std           0.20742482
Policy log std Max           0.2463336
Policy log std Min           -1.4718835
Z mean eval                  0.026253184
Z variance eval              0.0010695843
total_rewards                [3107.85954282  663.7169473  1264.62722544 1336.91739046 1150.13180454
 1014.96018565 1078.3753278  1076.61410809 1172.94418886 1039.7360586 ]
total_rewards_mean           1290.588277955337
total_rewards_std            629.4082930524277
total_rewards_max            3107.8595428161275
total_rewards_min            663.7169472969855
Number of train steps total  860000
Number of env steps total    854420
Number of rollouts total     0
Train Time (s)               141.1424210369587
(Previous) Eval Time (s)     11.773929002229124
Sample Time (s)              9.574385868385434
Epoch Time (s)               162.49073590757325
Total Train Time (s)         35184.39774632361
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:16:54.058322 UTC | [2020_01_11_02_30_29] Iteration #214 | Epoch Duration: 162.5875952243805
2020-01-11 12:16:54.058528 UTC | [2020_01_11_02_30_29] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027072925
Z variance train             0.0010686863
KL Divergence                14.892019
KL Loss                      1.4892019
QF Loss                      460.17233
VF Loss                      137.25406
Policy Loss                  -1272.6458
Q Predictions Mean           1277.4152
Q Predictions Std            408.65057
Q Predictions Max            1687.2045
Q Predictions Min            43.48521
V Predictions Mean           1270.3992
V Predictions Std            407.05615
V Predictions Max            1695.8992
V Predictions Min            36.493916
Log Pis Mean                 0.21558413
Log Pis Std                  2.04182
Log Pis Max                  7.1844096
Log Pis Min                  -5.837297
Policy mu Mean               -0.04756256
Policy mu Std                0.977315
Policy mu Max                2.2819393
Policy mu Min                -3.098732
Policy log std Mean          -0.58391804
Policy log std Std           0.21399714
Policy log std Max           0.06597054
Policy log std Min           -2.5364165
Z mean eval                  0.018743318
Z variance eval              0.0010739798
total_rewards                [ 911.07175302 1019.42531544 1085.3999123  3175.71607834  854.40473281
 3096.24836342 1502.42684894 2320.0795854  1292.93157322 3184.95643204]
total_rewards_mean           1844.2660594932483
total_rewards_std            942.9638875501539
total_rewards_max            3184.9564320384466
total_rewards_min            854.4047328078819
Number of train steps total  864000
Number of env steps total    859167
Number of rollouts total     0
Train Time (s)               141.9649640400894
(Previous) Eval Time (s)     18.532437397167087
Sample Time (s)              10.102262726519257
Epoch Time (s)               170.59966416377574
Total Train Time (s)         35355.17337878514
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:44.837512 UTC | [2020_01_11_02_30_29] Iteration #215 | Epoch Duration: 170.77879762649536
2020-01-11 12:19:44.837833 UTC | [2020_01_11_02_30_29] Iteration #215 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01889729
Z variance train             0.0010740402
KL Divergence                14.62896
KL Loss                      1.462896
QF Loss                      129.36414
VF Loss                      64.73399
Policy Loss                  -1287.6028
Q Predictions Mean           1289.3276
Q Predictions Std            333.03513
Q Predictions Max            1653.6586
Q Predictions Min            39.231796
V Predictions Mean           1288.6736
V Predictions Std            334.32675
V Predictions Max            1652.9221
V Predictions Min            38.95928
Log Pis Mean                 0.25467563
Log Pis Std                  2.0074022
Log Pis Max                  9.586813
Log Pis Min                  -5.1730156
Policy mu Mean               0.077043675
Policy mu Std                0.9472694
Policy mu Max                3.205802
Policy mu Min                -2.980227
Policy log std Mean          -0.5878176
Policy log std Std           0.18096815
Policy log std Max           0.09057963
Policy log std Min           -1.2986331
Z mean eval                  0.052904975
Z variance eval              0.0010887312
total_rewards                [2646.53780501  789.24495093  987.39945874 3073.95270455 1412.8478497
 3264.86239827 2966.60631718 3230.16879841 2592.09900737 3322.01197078]
total_rewards_mean           2428.57312609361
total_rewards_std            933.6213584960669
total_rewards_max            3322.011970777559
total_rewards_min            789.2449509296529
Number of train steps total  868000
Number of env steps total    863875
Number of rollouts total     0
Train Time (s)               141.47955177770928
(Previous) Eval Time (s)     23.576233885716647
Sample Time (s)              9.14843044243753
Epoch Time (s)               174.20421610586345
Total Train Time (s)         35529.46092960704
Epoch                        216
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:39.136950 UTC | [2020_01_11_02_30_29] Iteration #216 | Epoch Duration: 174.29872918128967
2020-01-11 12:22:39.137354 UTC | [2020_01_11_02_30_29] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0530385
Z variance train             0.0010880051
KL Divergence                14.69548
KL Loss                      1.4695481
QF Loss                      478.63574
VF Loss                      46.955566
Policy Loss                  -1255.3147
Q Predictions Mean           1257.0464
Q Predictions Std            388.1284
Q Predictions Max            1679.3884
Q Predictions Min            -33.31979
V Predictions Mean           1256.5498
V Predictions Std            382.08963
V Predictions Max            1674.6821
V Predictions Min            -18.21145
Log Pis Mean                 0.2934957
Log Pis Std                  2.1224058
Log Pis Max                  8.778585
Log Pis Min                  -6.5120883
Policy mu Mean               -0.045781787
Policy mu Std                1.0122714
Policy mu Max                3.157596
Policy mu Min                -2.7092173
Policy log std Mean          -0.58718973
Policy log std Std           0.21124844
Policy log std Max           0.10878128
Policy log std Min           -1.9458861
Z mean eval                  0.028674316
Z variance eval              0.0012255914
total_rewards                [3229.22114553 1053.35566504 2651.94983441 3224.62901199 3210.36542863
 2662.13052784 3169.22434471 3140.4833473  1156.01391607 3197.0094727 ]
total_rewards_mean           2669.438269421653
total_rewards_std            810.353767654182
total_rewards_max            3229.2211455259276
total_rewards_min            1053.3556650402993
Number of train steps total  872000
Number of env steps total    868512
Number of rollouts total     0
Train Time (s)               141.67232347512618
(Previous) Eval Time (s)     25.2398847672157
Sample Time (s)              10.028436976019293
Epoch Time (s)               176.94064521836117
Total Train Time (s)         35706.48873403156
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:25:36.159870 UTC | [2020_01_11_02_30_29] Iteration #217 | Epoch Duration: 177.0222351551056
2020-01-11 12:25:36.160102 UTC | [2020_01_11_02_30_29] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029196948
Z variance train             0.0012253054
KL Divergence                14.456201
KL Loss                      1.4456201
QF Loss                      1168.0605
VF Loss                      261.24005
Policy Loss                  -1307.5625
Q Predictions Mean           1302.8154
Q Predictions Std            371.16757
Q Predictions Max            1661.1935
Q Predictions Min            37.627563
V Predictions Mean           1313.4417
V Predictions Std            367.3593
V Predictions Max            1664.487
V Predictions Min            37.742912
Log Pis Mean                 0.10159589
Log Pis Std                  1.9762173
Log Pis Max                  8.687454
Log Pis Min                  -4.9194784
Policy mu Mean               0.039068792
Policy mu Std                0.9342061
Policy mu Max                2.2003877
Policy mu Min                -2.6936245
Policy log std Mean          -0.57933146
Policy log std Std           0.21560486
Policy log std Max           0.24419266
Policy log std Min           -1.3775688
Z mean eval                  0.03295699
Z variance eval              0.001079764
total_rewards                [ 924.71053241 2161.05333891 3205.03595054 1434.31842507 3285.58106803
 2429.34598642 3255.0377989  1759.40451179 2884.66579402 3233.84721332]
total_rewards_mean           2457.3000619404356
total_rewards_std            814.7474868901571
total_rewards_max            3285.581068030017
total_rewards_min            924.7105324111315
Number of train steps total  876000
Number of env steps total    873174
Number of rollouts total     0
Train Time (s)               141.04812921304256
(Previous) Eval Time (s)     24.58419662574306
Sample Time (s)              10.165224962867796
Epoch Time (s)               175.79755080165341
Total Train Time (s)         35882.490742975846
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:28:32.165429 UTC | [2020_01_11_02_30_29] Iteration #218 | Epoch Duration: 176.00507235527039
2020-01-11 12:28:32.165723 UTC | [2020_01_11_02_30_29] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032879658
Z variance train             0.0010775957
KL Divergence                14.663176
KL Loss                      1.4663175
QF Loss                      1083.5131
VF Loss                      83.64528
Policy Loss                  -1277.67
Q Predictions Mean           1267.7142
Q Predictions Std            353.16772
Q Predictions Max            1695.1256
Q Predictions Min            27.41238
V Predictions Mean           1274.1385
V Predictions Std            345.67557
V Predictions Max            1690.8584
V Predictions Min            30.151749
Log Pis Mean                 0.30139878
Log Pis Std                  2.3227534
Log Pis Max                  10.342147
Log Pis Min                  -5.0738506
Policy mu Mean               0.083200626
Policy mu Std                0.9802902
Policy mu Max                2.911241
Policy mu Min                -2.8070369
Policy log std Mean          -0.59339076
Policy log std Std           0.20858216
Policy log std Max           0.113126874
Policy log std Min           -1.5543706
Z mean eval                  0.02904294
Z variance eval              0.0008833379
total_rewards                [3233.30048905  871.91295151 3227.99657395  836.16614851 3241.87662329
 3174.66150392 3195.89528522 3197.74342232 1434.1824808  3239.17315321]
total_rewards_mean           2565.290863177377
total_rewards_std            1005.1417466551871
total_rewards_max            3241.8766232884204
total_rewards_min            836.1661485129755
Number of train steps total  880000
Number of env steps total    877862
Number of rollouts total     0
Train Time (s)               142.8048656550236
(Previous) Eval Time (s)     23.426090287044644
Sample Time (s)              8.980227802414447
Epoch Time (s)               175.2111837444827
Total Train Time (s)         36057.78006299585
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:31:27.456762 UTC | [2020_01_11_02_30_29] Iteration #219 | Epoch Duration: 175.29087281227112
2020-01-11 12:31:27.456944 UTC | [2020_01_11_02_30_29] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028634941
Z variance train             0.0008835665
KL Divergence                15.116725
KL Loss                      1.5116725
QF Loss                      165.8494
VF Loss                      72.69095
Policy Loss                  -1259.7968
Q Predictions Mean           1259.1635
Q Predictions Std            387.77893
Q Predictions Max            1682.4401
Q Predictions Min            -16.196276
V Predictions Mean           1264.1808
V Predictions Std            385.24182
V Predictions Max            1692.2305
V Predictions Min            -36.506035
Log Pis Mean                 0.20735827
Log Pis Std                  1.9128542
Log Pis Max                  7.1361914
Log Pis Min                  -3.5448594
Policy mu Mean               0.04670235
Policy mu Std                0.92399913
Policy mu Max                3.3063817
Policy mu Min                -2.6349344
Policy log std Mean          -0.58735776
Policy log std Std           0.23117496
Policy log std Max           0.34424794
Policy log std Min           -2.0150647
Z mean eval                  0.020017277
Z variance eval              0.00079580693
total_rewards                [1690.16702676  961.49517726  887.26266461  402.49932331  870.11609675
  918.9242819  2175.19523336  936.91908856  951.93460432  924.71914539]
total_rewards_mean           1071.9232642209915
total_rewards_std            470.3492298170447
total_rewards_max            2175.195233355943
total_rewards_min            402.49932330835236
Number of train steps total  884000
Number of env steps total    882523
Number of rollouts total     0
Train Time (s)               141.81236418196931
(Previous) Eval Time (s)     10.494356227107346
Sample Time (s)              9.993382792454213
Epoch Time (s)               162.30010320153087
Total Train Time (s)         36220.16677790601
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:34:09.847115 UTC | [2020_01_11_02_30_29] Iteration #220 | Epoch Duration: 162.39001774787903
2020-01-11 12:34:09.847382 UTC | [2020_01_11_02_30_29] Iteration #220 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020702185
Z variance train             0.0007957706
KL Divergence                15.497396
KL Loss                      1.5497397
QF Loss                      362.80847
VF Loss                      100.93357
Policy Loss                  -1280.8762
Q Predictions Mean           1275.1343
Q Predictions Std            347.2937
Q Predictions Max            1689.7617
Q Predictions Min            -27.773527
V Predictions Mean           1276.1818
V Predictions Std            348.75656
V Predictions Max            1690.4863
V Predictions Min            -7.832191
Log Pis Mean                 0.19532229
Log Pis Std                  1.906996
Log Pis Max                  5.9967747
Log Pis Min                  -4.0207167
Policy mu Mean               0.08577311
Policy mu Std                0.94542223
Policy mu Max                3.450576
Policy mu Min                -2.5735352
Policy log std Mean          -0.57461244
Policy log std Std           0.21673617
Policy log std Max           0.4386757
Policy log std Min           -1.9403512
Z mean eval                  0.026486944
Z variance eval              0.00072296883
total_rewards                [ 940.8942358   840.900902   3223.49654522  891.30825328  923.1159071
  861.56694355  251.05268129 3142.26542098 3133.26979388 1268.65528279]
total_rewards_mean           1547.652596588718
total_rewards_std            1085.5246151373583
total_rewards_max            3223.4965452192046
total_rewards_min            251.05268128707047
Number of train steps total  888000
Number of env steps total    887258
Number of rollouts total     0
Train Time (s)               141.59695027722046
(Previous) Eval Time (s)     14.786215516272932
Sample Time (s)              9.749856237787753
Epoch Time (s)               166.13302203128114
Total Train Time (s)         36386.376918272115
Epoch                        221
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:36:56.060087 UTC | [2020_01_11_02_30_29] Iteration #221 | Epoch Duration: 166.21252250671387
2020-01-11 12:36:56.060302 UTC | [2020_01_11_02_30_29] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026638988
Z variance train             0.00072275085
KL Divergence                15.680239
KL Loss                      1.5680239
QF Loss                      225.52896
VF Loss                      50.25553
Policy Loss                  -1239.562
Q Predictions Mean           1241.2693
Q Predictions Std            389.34012
Q Predictions Max            1713.3168
Q Predictions Min            10.265585
V Predictions Mean           1240.0006
V Predictions Std            389.42038
V Predictions Max            1702.0212
V Predictions Min            -1.5885929
Log Pis Mean                 0.36128575
Log Pis Std                  2.1037803
Log Pis Max                  8.943313
Log Pis Min                  -5.867482
Policy mu Mean               0.033644635
Policy mu Std                0.9970451
Policy mu Max                2.8917992
Policy mu Min                -3.6258698
Policy log std Mean          -0.5886826
Policy log std Std           0.2172133
Policy log std Max           0.081869364
Policy log std Min           -1.8848385
Z mean eval                  0.022961324
Z variance eval              0.00074546115
total_rewards                [2586.86195939 2920.49776595  876.24325426 1549.36623866  901.37867236
  880.73677462 3210.6446215  1617.81928228 2143.7491717  2917.37274486]
total_rewards_mean           1960.46704855758
total_rewards_std            870.3834000973444
total_rewards_max            3210.6446214998327
total_rewards_min            876.2432542564676
Number of train steps total  892000
Number of env steps total    891995
Number of rollouts total     0
Train Time (s)               141.1741210659966
(Previous) Eval Time (s)     19.585300198290497
Sample Time (s)              10.341631157323718
Epoch Time (s)               171.1010524216108
Total Train Time (s)         36557.56426846236
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:39:47.250127 UTC | [2020_01_11_02_30_29] Iteration #222 | Epoch Duration: 171.18965530395508
2020-01-11 12:39:47.250332 UTC | [2020_01_11_02_30_29] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023382919
Z variance train             0.0007452468
KL Divergence                15.918173
KL Loss                      1.5918173
QF Loss                      154.97833
VF Loss                      99.19938
Policy Loss                  -1261.5114
Q Predictions Mean           1257.6891
Q Predictions Std            361.2472
Q Predictions Max            1669.742
Q Predictions Min            15.0119915
V Predictions Mean           1262.4045
V Predictions Std            348.90002
V Predictions Max            1664.3065
V Predictions Min            24.320023
Log Pis Mean                 0.2281247
Log Pis Std                  2.285587
Log Pis Max                  9.937354
Log Pis Min                  -4.285075
Policy mu Mean               -0.0307332
Policy mu Std                1.0128725
Policy mu Max                2.5345936
Policy mu Min                -3.7110507
Policy log std Mean          -0.5696091
Policy log std Std           0.22730185
Policy log std Max           0.15939838
Policy log std Min           -2.2475562
Z mean eval                  0.050608538
Z variance eval              0.00079175056
total_rewards                [ 865.84443634  939.95276837 1083.51385433 2737.66088003 1256.81606077
 3227.62901737  616.75645431 3223.07090753 3174.64198905 3228.54458699]
total_rewards_mean           2035.4430955088108
total_rewards_std            1101.785069912546
total_rewards_max            3228.544586985282
total_rewards_min            616.756454308264
Number of train steps total  896000
Number of env steps total    896909
Number of rollouts total     0
Train Time (s)               140.9171277587302
(Previous) Eval Time (s)     19.887005382217467
Sample Time (s)              10.386704351287335
Epoch Time (s)               171.190837492235
Total Train Time (s)         36728.83768957434
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:42:38.526522 UTC | [2020_01_11_02_30_29] Iteration #223 | Epoch Duration: 171.27604150772095
2020-01-11 12:42:38.526721 UTC | [2020_01_11_02_30_29] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05079078
Z variance train             0.00079220685
KL Divergence                15.791903
KL Loss                      1.5791903
QF Loss                      933.26166
VF Loss                      160.21745
Policy Loss                  -1279.3778
Q Predictions Mean           1272.2991
Q Predictions Std            364.773
Q Predictions Max            1665.7278
Q Predictions Min            41.70346
V Predictions Mean           1278.3538
V Predictions Std            367.50812
V Predictions Max            1664.4138
V Predictions Min            48.131767
Log Pis Mean                 0.19657852
Log Pis Std                  2.267955
Log Pis Max                  10.32671
Log Pis Min                  -6.4990816
Policy mu Mean               0.013220728
Policy mu Std                0.99480003
Policy mu Max                2.984881
Policy mu Min                -3.2332685
Policy log std Mean          -0.58521146
Policy log std Std           0.23962119
Policy log std Max           0.10576314
Policy log std Min           -2.9851723
Z mean eval                  0.039124183
Z variance eval              0.00065149565
total_rewards                [3167.78331311 1052.51657324 2526.52558248 3204.22431986 3159.20935912
 3131.22855381 2110.20001848  928.1484667  3209.19606912  986.35618047]
total_rewards_mean           2347.538843638741
total_rewards_std            951.581772247989
total_rewards_max            3209.1960691248187
total_rewards_min            928.1484666981307
Number of train steps total  900000
Number of env steps total    901616
Number of rollouts total     0
Train Time (s)               141.9031213838607
(Previous) Eval Time (s)     22.871061375830323
Sample Time (s)              10.337483297567815
Epoch Time (s)               175.11166605725884
Total Train Time (s)         36904.11157055292
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:45:33.801722 UTC | [2020_01_11_02_30_29] Iteration #224 | Epoch Duration: 175.2748486995697
2020-01-11 12:45:33.801866 UTC | [2020_01_11_02_30_29] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039658487
Z variance train             0.00065122166
KL Divergence                16.111866
KL Loss                      1.6111866
QF Loss                      164.66904
VF Loss                      226.62149
Policy Loss                  -1267.2256
Q Predictions Mean           1266.7406
Q Predictions Std            384.09662
Q Predictions Max            1684.2249
Q Predictions Min            22.723124
V Predictions Mean           1268.6472
V Predictions Std            382.11725
V Predictions Max            1695.8915
V Predictions Min            39.150238
Log Pis Mean                 0.41937497
Log Pis Std                  2.277495
Log Pis Max                  9.776022
Log Pis Min                  -3.6924808
Policy mu Mean               -0.032733947
Policy mu Std                0.96865034
Policy mu Max                2.4832032
Policy mu Min                -3.281718
Policy log std Mean          -0.5914082
Policy log std Std           0.1991105
Policy log std Max           0.14786762
Policy log std Min           -1.8674202
Z mean eval                  0.019009516
Z variance eval              0.0006171449
total_rewards                [ 980.62059265 1444.38994137 1392.23049641 1021.20501796 1195.24761325
  862.62234609 3278.78409316  939.3153354   963.88565485 1912.55880944]
total_rewards_mean           1399.0859900600876
total_rewards_std            696.2081420491852
total_rewards_max            3278.7840931620926
total_rewards_min            862.6223460928309
Number of train steps total  904000
Number of env steps total    906314
Number of rollouts total     0
Train Time (s)               147.33601910062134
(Previous) Eval Time (s)     13.418793908786029
Sample Time (s)              9.73351201415062
Epoch Time (s)               170.488325023558
Total Train Time (s)         37074.685678851325
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:48:24.380112 UTC | [2020_01_11_02_30_29] Iteration #225 | Epoch Duration: 170.57809567451477
2020-01-11 12:48:24.380428 UTC | [2020_01_11_02_30_29] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018939655
Z variance train             0.00061712216
KL Divergence                16.139227
KL Loss                      1.6139227
QF Loss                      116.19495
VF Loss                      41.98425
Policy Loss                  -1278.191
Q Predictions Mean           1276.829
Q Predictions Std            368.84015
Q Predictions Max            1724.1409
Q Predictions Min            24.243553
V Predictions Mean           1277.2551
V Predictions Std            366.27667
V Predictions Max            1705.787
V Predictions Min            33.922264
Log Pis Mean                 0.124028765
Log Pis Std                  1.970323
Log Pis Max                  5.758157
Log Pis Min                  -6.6732144
Policy mu Mean               0.070738144
Policy mu Std                0.95314574
Policy mu Max                2.3756614
Policy mu Min                -2.9166112
Policy log std Mean          -0.576773
Policy log std Std           0.19838747
Policy log std Max           0.7765935
Policy log std Min           -1.3120712
Z mean eval                  0.025964309
Z variance eval              0.0005632002
total_rewards                [3220.91646208  560.68452385 3211.00680933 2451.57877036 3294.80169463
 1845.84070812  860.62258404  978.91477261 1155.28203251 2194.59635356]
total_rewards_mean           1977.4244711069489
total_rewards_std            1001.0054454894632
total_rewards_max            3294.8016946304106
total_rewards_min            560.684523846826
Number of train steps total  908000
Number of env steps total    910952
Number of rollouts total     0
Train Time (s)               148.24625954637304
(Previous) Eval Time (s)     19.986529473681003
Sample Time (s)              10.134333011228591
Epoch Time (s)               178.36712203128263
Total Train Time (s)         37253.13892155234
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:22.836262 UTC | [2020_01_11_02_30_29] Iteration #226 | Epoch Duration: 178.4556269645691
2020-01-11 12:51:22.836506 UTC | [2020_01_11_02_30_29] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024371061
Z variance train             0.00056330767
KL Divergence                16.287743
KL Loss                      1.6287743
QF Loss                      193.13348
VF Loss                      65.98816
Policy Loss                  -1235.6078
Q Predictions Mean           1237.2244
Q Predictions Std            399.23654
Q Predictions Max            1670.1476
Q Predictions Min            36.413876
V Predictions Mean           1239.6819
V Predictions Std            397.13794
V Predictions Max            1669.274
V Predictions Min            36.97032
Log Pis Mean                 0.03666697
Log Pis Std                  1.8706859
Log Pis Max                  7.1491394
Log Pis Min                  -5.003452
Policy mu Mean               0.07062324
Policy mu Std                0.92827225
Policy mu Max                2.2096958
Policy mu Min                -2.508116
Policy log std Mean          -0.5499353
Policy log std Std           0.18903536
Policy log std Max           -0.00031095743
Policy log std Min           -1.2708007
Z mean eval                  0.025947478
Z variance eval              0.00060280255
total_rewards                [2980.29554158  578.13863927 1394.82560536  601.61518969  270.23272189
 2364.91368701 2101.39030159  841.14292735 2104.74011266 3236.13324813]
total_rewards_mean           1647.342797454699
total_rewards_std            1003.9022173673332
total_rewards_max            3236.133248134388
total_rewards_min            270.2327218937395
Number of train steps total  912000
Number of env steps total    915568
Number of rollouts total     0
Train Time (s)               147.51050419174135
(Previous) Eval Time (s)     16.849247626960278
Sample Time (s)              10.40398119436577
Epoch Time (s)               174.7637330130674
Total Train Time (s)         37428.00064282771
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:54:17.704450 UTC | [2020_01_11_02_30_29] Iteration #227 | Epoch Duration: 174.8677544593811
2020-01-11 12:54:17.704796 UTC | [2020_01_11_02_30_29] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025882293
Z variance train             0.0006039988
KL Divergence                16.218746
KL Loss                      1.6218747
QF Loss                      118.75882
VF Loss                      62.89491
Policy Loss                  -1244.3767
Q Predictions Mean           1242.3215
Q Predictions Std            411.935
Q Predictions Max            1672.2484
Q Predictions Min            -35.38199
V Predictions Mean           1243.1453
V Predictions Std            409.84637
V Predictions Max            1677.7012
V Predictions Min            -48.716225
Log Pis Mean                 0.30215013
Log Pis Std                  2.1215003
Log Pis Max                  6.6549854
Log Pis Min                  -4.484494
Policy mu Mean               0.061409194
Policy mu Std                1.0145818
Policy mu Max                2.6954463
Policy mu Min                -2.6062236
Policy log std Mean          -0.56511027
Policy log std Std           0.20923556
Policy log std Max           0.3226506
Policy log std Min           -1.9503171
Z mean eval                  0.030774105
Z variance eval              0.0006213911
total_rewards                [3238.27737235 3240.28070048  923.72503103 3230.77234575 3186.51583964
 3265.58790384 3204.60150151  943.34314459  885.80071322 3360.45614565]
total_rewards_mean           2547.936069807592
total_rewards_std            1068.262988186646
total_rewards_max            3360.4561456549973
total_rewards_min            885.8007132214108
Number of train steps total  916000
Number of env steps total    920172
Number of rollouts total     0
Train Time (s)               152.41032390482724
(Previous) Eval Time (s)     25.411512842867523
Sample Time (s)              10.382874227128923
Epoch Time (s)               188.20471097482368
Total Train Time (s)         37616.3025391968
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:57:26.005572 UTC | [2020_01_11_02_30_29] Iteration #228 | Epoch Duration: 188.30053424835205
2020-01-11 12:57:26.005789 UTC | [2020_01_11_02_30_29] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030806398
Z variance train             0.000620843
KL Divergence                16.046333
KL Loss                      1.6046333
QF Loss                      175.69649
VF Loss                      142.13525
Policy Loss                  -1274.2516
Q Predictions Mean           1275.6991
Q Predictions Std            344.21463
Q Predictions Max            1646.898
Q Predictions Min            105.84654
V Predictions Mean           1280.3478
V Predictions Std            344.4487
V Predictions Max            1658.2659
V Predictions Min            89.654594
Log Pis Mean                 0.1710753
Log Pis Std                  2.1187632
Log Pis Max                  9.06791
Log Pis Min                  -6.4805727
Policy mu Mean               0.14110489
Policy mu Std                0.9688164
Policy mu Max                2.860216
Policy mu Min                -2.8682332
Policy log std Mean          -0.60219115
Policy log std Std           0.21720529
Policy log std Max           0.90953606
Policy log std Min           -1.6599733
Z mean eval                  0.04826583
Z variance eval              0.0007491595
total_rewards                [3269.05618217 3202.98714718 3186.41745424 3237.32487068 3210.79576238
 3275.86755572 3248.33458006 3220.73268061 2822.77213563 3236.33716316]
total_rewards_mean           3191.0625531836727
total_rewards_std            125.6249547526817
total_rewards_max            3275.867555722783
total_rewards_min            2822.77213562734
Number of train steps total  920000
Number of env steps total    924825
Number of rollouts total     0
Train Time (s)               147.75515358196571
(Previous) Eval Time (s)     29.191528043244034
Sample Time (s)              8.672907378990203
Epoch Time (s)               185.61958900419995
Total Train Time (s)         37802.0025068433
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:00:31.709316 UTC | [2020_01_11_02_30_29] Iteration #229 | Epoch Duration: 185.7033610343933
2020-01-11 13:00:31.709524 UTC | [2020_01_11_02_30_29] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04843653
Z variance train             0.0007501181
KL Divergence                15.53268
KL Loss                      1.553268
QF Loss                      1249.0063
VF Loss                      70.785164
Policy Loss                  -1289.7758
Q Predictions Mean           1288.9357
Q Predictions Std            335.40234
Q Predictions Max            1670.5322
Q Predictions Min            47.228634
V Predictions Mean           1288.8875
V Predictions Std            333.23703
V Predictions Max            1666.9448
V Predictions Min            49.881767
Log Pis Mean                 0.19949669
Log Pis Std                  2.324341
Log Pis Max                  13.949607
Log Pis Min                  -4.438253
Policy mu Mean               0.02258525
Policy mu Std                0.989171
Policy mu Max                5.0801077
Policy mu Min                -3.6984982
Policy log std Mean          -0.5826687
Policy log std Std           0.21593958
Policy log std Max           0.15271282
Policy log std Min           -1.7343001
Z mean eval                  0.05284494
Z variance eval              0.00084154337
total_rewards                [3189.26682346 3247.30608501 1879.93948281  968.12382883  226.28936245
 3180.39845172 3170.08087281 3151.60873904 3263.61834804 3131.50853346]
total_rewards_mean           2540.814052763038
total_rewards_std            1060.0111965885703
total_rewards_max            3263.6183480361665
total_rewards_min            226.28936245489044
Number of train steps total  924000
Number of env steps total    929561
Number of rollouts total     0
Train Time (s)               142.03014643024653
(Previous) Eval Time (s)     25.207559460774064
Sample Time (s)              10.37664916459471
Epoch Time (s)               177.6143550556153
Total Train Time (s)         37979.72055183072
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:29.429755 UTC | [2020_01_11_02_30_29] Iteration #230 | Epoch Duration: 177.7200562953949
2020-01-11 13:03:29.429984 UTC | [2020_01_11_02_30_29] Iteration #230 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05257676
Z variance train             0.0008415018
KL Divergence                15.229919
KL Loss                      1.522992
QF Loss                      214.94794
VF Loss                      79.82213
Policy Loss                  -1264.4031
Q Predictions Mean           1259.3931
Q Predictions Std            376.4652
Q Predictions Max            1688.788
Q Predictions Min            26.17588
V Predictions Mean           1265.4487
V Predictions Std            373.1861
V Predictions Max            1690.5525
V Predictions Min            24.201416
Log Pis Mean                 0.22727683
Log Pis Std                  2.17386
Log Pis Max                  10.670784
Log Pis Min                  -5.259393
Policy mu Mean               0.07144802
Policy mu Std                0.99241
Policy mu Max                3.2156878
Policy mu Min                -2.7644513
Policy log std Mean          -0.5840981
Policy log std Std           0.20329598
Policy log std Max           0.29801202
Policy log std Min           -1.3391252
Z mean eval                  0.055942625
Z variance eval              0.00078597694
total_rewards                [ 879.71012665 3219.76514886 1062.74690708 3203.57140965 1621.9063325
 2744.73822037  598.69614886  610.32684916 3235.5213673   949.25191551]
total_rewards_mean           1812.6234425934697
total_rewards_std            1092.7864635024514
total_rewards_max            3235.52136730077
total_rewards_min            598.6961488607383
Number of train steps total  928000
Number of env steps total    934341
Number of rollouts total     0
Train Time (s)               142.2142680757679
(Previous) Eval Time (s)     17.244388055987656
Sample Time (s)              10.454716068692505
Epoch Time (s)               169.91337220044807
Total Train Time (s)         38149.71388591034
Epoch                        231
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:06:19.426340 UTC | [2020_01_11_02_30_29] Iteration #231 | Epoch Duration: 169.996178150177
2020-01-11 13:06:19.426563 UTC | [2020_01_11_02_30_29] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056270383
Z variance train             0.0007864336
KL Divergence                15.422388
KL Loss                      1.5422388
QF Loss                      201.05135
VF Loss                      49.317665
Policy Loss                  -1269.2905
Q Predictions Mean           1265.197
Q Predictions Std            355.2357
Q Predictions Max            1665.788
Q Predictions Min            49.964188
V Predictions Mean           1272.2821
V Predictions Std            355.56873
V Predictions Max            1680.1454
V Predictions Min            48.823524
Log Pis Mean                 0.16344786
Log Pis Std                  2.1342907
Log Pis Max                  12.071579
Log Pis Min                  -5.6959844
Policy mu Mean               0.062170487
Policy mu Std                0.9577515
Policy mu Max                3.4245017
Policy mu Min                -2.6109025
Policy log std Mean          -0.58326054
Policy log std Std           0.184887
Policy log std Max           0.16970897
Policy log std Min           -1.1254444
Z mean eval                  0.02584925
Z variance eval              0.0007482294
total_rewards                [ 813.5358777  3206.18429929  789.70311691 3259.14045649 3247.32202645
  864.11513406 1005.95941801 1159.84971791  827.72875838 1140.67914534]
total_rewards_mean           1631.4217950538064
total_rewards_std            1058.6311924749061
total_rewards_max            3259.1404564917866
total_rewards_min            789.7031169050114
Number of train steps total  932000
Number of env steps total    939005
Number of rollouts total     0
Train Time (s)               141.73514315206558
(Previous) Eval Time (s)     16.204953328240663
Sample Time (s)              9.361110100056976
Epoch Time (s)               167.3012065803632
Total Train Time (s)         38317.09496569075
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:06.813730 UTC | [2020_01_11_02_30_29] Iteration #232 | Epoch Duration: 167.38697957992554
2020-01-11 13:09:06.814043 UTC | [2020_01_11_02_30_29] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025694896
Z variance train             0.0007482539
KL Divergence                15.604812
KL Loss                      1.5604812
QF Loss                      211.6893
VF Loss                      61.844852
Policy Loss                  -1275.7285
Q Predictions Mean           1271.178
Q Predictions Std            376.4923
Q Predictions Max            1674.8065
Q Predictions Min            35.394737
V Predictions Mean           1275.2821
V Predictions Std            373.4264
V Predictions Max            1682.4863
V Predictions Min            45.453796
Log Pis Mean                 0.04180624
Log Pis Std                  1.9800551
Log Pis Max                  6.5581613
Log Pis Min                  -5.1712694
Policy mu Mean               0.20260994
Policy mu Std                0.91743046
Policy mu Max                2.420745
Policy mu Min                -3.2892396
Policy log std Mean          -0.55131793
Policy log std Std           0.2042165
Policy log std Max           0.14195544
Policy log std Min           -1.2912555
Z mean eval                  0.032113668
Z variance eval              0.00068743015
total_rewards                [ 888.20313999 1093.83592465 3265.4957865  3232.89729512  578.82106587
 3373.06637501 1229.49756545  929.91485565 3300.78049169 2402.30598379]
total_rewards_mean           2029.481848370194
total_rewards_std            1125.5108246702885
total_rewards_max            3373.066375005533
total_rewards_min            578.8210658652549
Number of train steps total  936000
Number of env steps total    943715
Number of rollouts total     0
Train Time (s)               141.0950766899623
(Previous) Eval Time (s)     19.64295349875465
Sample Time (s)              9.295366576872766
Epoch Time (s)               170.0333967655897
Total Train Time (s)         38487.20985589642
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:11:56.931258 UTC | [2020_01_11_02_30_29] Iteration #233 | Epoch Duration: 170.11695408821106
2020-01-11 13:11:56.931467 UTC | [2020_01_11_02_30_29] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032137644
Z variance train             0.0006869458
KL Divergence                15.814948
KL Loss                      1.5814948
QF Loss                      171.45242
VF Loss                      126.06034
Policy Loss                  -1295.5028
Q Predictions Mean           1293.5813
Q Predictions Std            354.88168
Q Predictions Max            1703.6566
Q Predictions Min            -29.100561
V Predictions Mean           1289.9814
V Predictions Std            355.97153
V Predictions Max            1685.6022
V Predictions Min            -37.13951
Log Pis Mean                 0.2143995
Log Pis Std                  2.1566072
Log Pis Max                  7.014638
Log Pis Min                  -4.766744
Policy mu Mean               0.024298003
Policy mu Std                0.9767788
Policy mu Max                3.285056
Policy mu Min                -2.654825
Policy log std Mean          -0.57020146
Policy log std Std           0.22161895
Policy log std Max           0.2715385
Policy log std Min           -1.8044083
Z mean eval                  0.029948836
Z variance eval              0.0009096234
total_rewards                [1382.50993389 3051.55014555 1173.71153878  888.82134772 1615.32235294
  937.87296408 3252.83872245 1494.55737221 3277.63803849 2875.38884133]
total_rewards_mean           1995.0211257468363
total_rewards_std            943.6157504427478
total_rewards_max            3277.6380384899853
total_rewards_min            888.8213477186099
Number of train steps total  940000
Number of env steps total    948440
Number of rollouts total     0
Train Time (s)               142.24294079467654
(Previous) Eval Time (s)     19.387936075218022
Sample Time (s)              9.82439969619736
Epoch Time (s)               171.45527656609192
Total Train Time (s)         38658.74351646891
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:14:48.468174 UTC | [2020_01_11_02_30_29] Iteration #234 | Epoch Duration: 171.5365526676178
2020-01-11 13:14:48.468402 UTC | [2020_01_11_02_30_29] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030500878
Z variance train             0.000909264
KL Divergence                15.431783
KL Loss                      1.5431783
QF Loss                      307.81366
VF Loss                      219.44225
Policy Loss                  -1310.8524
Q Predictions Mean           1309.463
Q Predictions Std            336.6583
Q Predictions Max            1691.4576
Q Predictions Min            23.37009
V Predictions Mean           1301.5626
V Predictions Std            335.60522
V Predictions Max            1670.9475
V Predictions Min            14.590335
Log Pis Mean                 0.28748238
Log Pis Std                  2.3669786
Log Pis Max                  10.688753
Log Pis Min                  -6.7637486
Policy mu Mean               -0.070653036
Policy mu Std                0.9876976
Policy mu Max                2.5450075
Policy mu Min                -3.3575306
Policy log std Mean          -0.5616626
Policy log std Std           0.21067323
Policy log std Max           0.060640752
Policy log std Min           -1.83938
Z mean eval                  0.015103079
Z variance eval              0.0010371241
total_rewards                [3206.5559578  3149.38016628 3221.35493174 3222.20302402 1683.43004084
 3162.17542896  978.48287835 3213.57452655 1460.71044999 2846.14961134]
total_rewards_mean           2614.401701586896
total_rewards_std            834.3486471232831
total_rewards_max            3222.2030240189565
total_rewards_min            978.4828783532645
Number of train steps total  944000
Number of env steps total    953234
Number of rollouts total     0
Train Time (s)               142.37093215016648
(Previous) Eval Time (s)     26.508231416810304
Sample Time (s)              10.26799297844991
Epoch Time (s)               179.1471565454267
Total Train Time (s)         38837.974597636145
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:17:47.702246 UTC | [2020_01_11_02_30_29] Iteration #235 | Epoch Duration: 179.23370003700256
2020-01-11 13:17:47.702631 UTC | [2020_01_11_02_30_29] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015677977
Z variance train             0.0010370583
KL Divergence                15.046224
KL Loss                      1.5046223
QF Loss                      101.47044
VF Loss                      71.8856
Policy Loss                  -1283.5431
Q Predictions Mean           1282.5687
Q Predictions Std            380.9143
Q Predictions Max            1652.8878
Q Predictions Min            -48.32241
V Predictions Mean           1281.975
V Predictions Std            380.4145
V Predictions Max            1654.1982
V Predictions Min            -56.908497
Log Pis Mean                 0.285648
Log Pis Std                  2.1696823
Log Pis Max                  11.307381
Log Pis Min                  -3.327142
Policy mu Mean               0.03659054
Policy mu Std                0.98991907
Policy mu Max                2.8834817
Policy mu Min                -3.360261
Policy log std Mean          -0.5652749
Policy log std Std           0.2304737
Policy log std Max           0.4277315
Policy log std Min           -1.995554
Z mean eval                  0.029560039
Z variance eval              0.0012434532
total_rewards                [3269.25721273 3253.66013436  932.89980981 3291.70090652 1404.21342791
 3183.92650791  891.20936319  961.88131541 3228.68495556  926.13994039]
total_rewards_mean           2134.357357380076
total_rewards_std            1119.6403663833225
total_rewards_max            3291.700906517199
total_rewards_min            891.2093631920425
Number of train steps total  948000
Number of env steps total    958014
Number of rollouts total     0
Train Time (s)               141.24189171893522
(Previous) Eval Time (s)     19.382302711252123
Sample Time (s)              9.950646000914276
Epoch Time (s)               170.57484043110162
Total Train Time (s)         39008.63263609959
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:20:38.363456 UTC | [2020_01_11_02_30_29] Iteration #236 | Epoch Duration: 170.66061687469482
2020-01-11 13:20:38.363647 UTC | [2020_01_11_02_30_29] Iteration #236 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02955321
Z variance train             0.0012436786
KL Divergence                14.4927845
KL Loss                      1.4492785
QF Loss                      113.43897
VF Loss                      83.96091
Policy Loss                  -1303.8242
Q Predictions Mean           1302.4868
Q Predictions Std            352.028
Q Predictions Max            1655.674
Q Predictions Min            66.155365
V Predictions Mean           1300.9009
V Predictions Std            349.9648
V Predictions Max            1658.0392
V Predictions Min            63.586502
Log Pis Mean                 0.09460725
Log Pis Std                  1.9932984
Log Pis Max                  6.831274
Log Pis Min                  -6.224195
Policy mu Mean               -0.0088807745
Policy mu Std                0.9235044
Policy mu Max                2.919585
Policy mu Min                -2.6214018
Policy log std Mean          -0.57218903
Policy log std Std           0.19324851
Policy log std Max           0.097929776
Policy log std Min           -1.3690567
Z mean eval                  0.018262878
Z variance eval              0.0012302736
total_rewards                [1702.87022745 3283.83853693 2557.19169732 3254.37396255 1512.1552624
 3275.60215065 1706.71547111 3259.14657339 3309.93356375 1594.37950014]
total_rewards_mean           2545.6206945696085
total_rewards_std            778.4919952672358
total_rewards_max            3309.9335637542335
total_rewards_min            1512.1552623995742
Number of train steps total  952000
Number of env steps total    962646
Number of rollouts total     0
Train Time (s)               142.18617321783677
(Previous) Eval Time (s)     24.065944073721766
Sample Time (s)              9.950858220923692
Epoch Time (s)               176.20297551248223
Total Train Time (s)         39184.91633031564
Epoch                        237
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:23:34.650102 UTC | [2020_01_11_02_30_29] Iteration #237 | Epoch Duration: 176.2863130569458
2020-01-11 13:23:34.650299 UTC | [2020_01_11_02_30_29] Iteration #237 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020598948
Z variance train             0.0012296115
KL Divergence                14.490407
KL Loss                      1.4490408
QF Loss                      173.87573
VF Loss                      80.108665
Policy Loss                  -1289.6108
Q Predictions Mean           1290.4518
Q Predictions Std            328.86624
Q Predictions Max            1667.9822
Q Predictions Min            51.678833
V Predictions Mean           1285.3948
V Predictions Std            325.35733
V Predictions Max            1666.894
V Predictions Min            45.571182
Log Pis Mean                 0.047736153
Log Pis Std                  1.851102
Log Pis Max                  4.724369
Log Pis Min                  -4.6899137
Policy mu Mean               0.086489476
Policy mu Std                0.9246277
Policy mu Max                2.4155762
Policy mu Min                -2.6205266
Policy log std Mean          -0.57697076
Policy log std Std           0.2098776
Policy log std Max           0.012736917
Policy log std Min           -1.4243649
Z mean eval                  0.023978803
Z variance eval              0.0012134088
total_rewards                [ 917.15285559 3193.87338471 3126.4476382  3202.8420747  3162.3235255
 3165.55644046 1687.29249971 3136.72888476 3147.71613494 3155.45908629]
total_rewards_mean           2789.5392524866406
total_rewards_std            763.654174445845
total_rewards_max            3202.84207469705
total_rewards_min            917.1528555931201
Number of train steps total  956000
Number of env steps total    967204
Number of rollouts total     0
Train Time (s)               140.5940645658411
(Previous) Eval Time (s)     27.81045060697943
Sample Time (s)              10.308984658215195
Epoch Time (s)               178.71349983103573
Total Train Time (s)         39363.71097045578
Epoch                        238
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:26:33.448029 UTC | [2020_01_11_02_30_29] Iteration #238 | Epoch Duration: 178.7975890636444
2020-01-11 13:26:33.448230 UTC | [2020_01_11_02_30_29] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023797657
Z variance train             0.001213783
KL Divergence                14.573389
KL Loss                      1.4573389
QF Loss                      874.308
VF Loss                      932.14233
Policy Loss                  -1271.5088
Q Predictions Mean           1267.3854
Q Predictions Std            377.6127
Q Predictions Max            1654.797
Q Predictions Min            47.260376
V Predictions Mean           1271.1099
V Predictions Std            372.7905
V Predictions Max            1649.9249
V Predictions Min            62.581417
Log Pis Mean                 0.097192064
Log Pis Std                  2.9244435
Log Pis Max                  24.354914
Log Pis Min                  -7.123782
Policy mu Mean               0.014580707
Policy mu Std                1.0321875
Policy mu Max                8.624263
Policy mu Min                -6.344847
Policy log std Mean          -0.56893486
Policy log std Std           0.24197616
Policy log std Max           0.025812149
Policy log std Min           -2.9260647
Z mean eval                  0.012447456
Z variance eval              0.0012612998
total_rewards                [3220.45793703 3215.34868627 3183.76127557 2496.4358248  2554.41842079
 3149.82713172 3126.10187243 3138.37665745 2247.37413361 1170.31772748]
total_rewards_mean           2750.241966714287
total_rewards_std            626.7978062787098
total_rewards_max            3220.4579370300626
total_rewards_min            1170.3177274768698
Number of train steps total  960000
Number of env steps total    971934
Number of rollouts total     0
Train Time (s)               141.48872163891792
(Previous) Eval Time (s)     27.857093908358365
Sample Time (s)              10.07518566865474
Epoch Time (s)               179.42100121593103
Total Train Time (s)         39543.2221275894
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:29:32.962322 UTC | [2020_01_11_02_30_29] Iteration #239 | Epoch Duration: 179.51392769813538
2020-01-11 13:29:32.962538 UTC | [2020_01_11_02_30_29] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012405763
Z variance train             0.0012613952
KL Divergence                14.365338
KL Loss                      1.4365338
QF Loss                      135.50983
VF Loss                      109.57744
Policy Loss                  -1291.772
Q Predictions Mean           1292.8788
Q Predictions Std            359.38644
Q Predictions Max            1680.4788
Q Predictions Min            -9.209054
V Predictions Mean           1289.4617
V Predictions Std            356.9893
V Predictions Max            1677.0015
V Predictions Min            -42.181923
Log Pis Mean                 0.09619972
Log Pis Std                  1.9308311
Log Pis Max                  6.207286
Log Pis Min                  -4.8865514
Policy mu Mean               -0.0046953685
Policy mu Std                0.9533336
Policy mu Max                3.8038397
Policy mu Min                -2.6416779
Policy log std Mean          -0.5873468
Policy log std Std           0.20186628
Policy log std Max           0.24638861
Policy log std Min           -2.178991
Z mean eval                  0.03288211
Z variance eval              0.0013973505
total_rewards                [1593.99642821 1574.67588631 3206.12766357 3258.56451297 3270.53097873
 3281.28283788 1748.61812845 3223.91017371 1323.16735178  921.08567324]
total_rewards_mean           2340.195963484748
total_rewards_std            930.9337965617041
total_rewards_max            3281.2828378764466
total_rewards_min            921.0856732383422
Number of train steps total  964000
Number of env steps total    976764
Number of rollouts total     0
Train Time (s)               142.34346138779074
(Previous) Eval Time (s)     23.01118366373703
Sample Time (s)              10.363134917337447
Epoch Time (s)               175.71777996886522
Total Train Time (s)         39719.087314576376
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:32:28.831074 UTC | [2020_01_11_02_30_29] Iteration #240 | Epoch Duration: 175.86835646629333
2020-01-11 13:32:28.831375 UTC | [2020_01_11_02_30_29] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033028077
Z variance train             0.0013982819
KL Divergence                14.146221
KL Loss                      1.4146222
QF Loss                      180.24971
VF Loss                      209.47003
Policy Loss                  -1290.2267
Q Predictions Mean           1289.9529
Q Predictions Std            352.0049
Q Predictions Max            1697.9817
Q Predictions Min            -46.666325
V Predictions Mean           1281.8599
V Predictions Std            349.88052
V Predictions Max            1684.6002
V Predictions Min            -51.963432
Log Pis Mean                 0.0769532
Log Pis Std                  2.1052356
Log Pis Max                  7.133071
Log Pis Min                  -4.7075057
Policy mu Mean               0.104461186
Policy mu Std                0.9804816
Policy mu Max                2.2632496
Policy mu Min                -2.6698334
Policy log std Mean          -0.56550217
Policy log std Std           0.19684589
Policy log std Max           0.057836533
Policy log std Min           -1.9560974
Z mean eval                  0.024897518
Z variance eval              0.0012202539
total_rewards                [2295.3264503  3286.5514304  2212.00616504 1543.34317015 1303.58307628
 1731.22998441 1212.45985267 1365.80669764 1195.88318301 1138.04582818]
total_rewards_mean           1728.423583807631
total_rewards_std            650.1999847956665
total_rewards_max            3286.5514303981086
total_rewards_min            1138.0458281810686
Number of train steps total  968000
Number of env steps total    981650
Number of rollouts total     0
Train Time (s)               142.6694097132422
(Previous) Eval Time (s)     16.950843460392207
Sample Time (s)              10.071164994500577
Epoch Time (s)               169.691418168135
Total Train Time (s)         39888.877015369944
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:35:18.624320 UTC | [2020_01_11_02_30_29] Iteration #241 | Epoch Duration: 169.79277300834656
2020-01-11 13:35:18.624502 UTC | [2020_01_11_02_30_29] Iteration #241 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025248956
Z variance train             0.0012205666
KL Divergence                14.440622
KL Loss                      1.4440622
QF Loss                      490.99408
VF Loss                      79.49293
Policy Loss                  -1296.4757
Q Predictions Mean           1292.2224
Q Predictions Std            359.96246
Q Predictions Max            1673.2473
Q Predictions Min            -27.91677
V Predictions Mean           1292.4282
V Predictions Std            351.04062
V Predictions Max            1671.2616
V Predictions Min            20.32254
Log Pis Mean                 0.18338096
Log Pis Std                  2.2287652
Log Pis Max                  9.271864
Log Pis Min                  -5.3448634
Policy mu Mean               0.025141759
Policy mu Std                0.98995954
Policy mu Max                2.5336373
Policy mu Min                -2.9322488
Policy log std Mean          -0.5578043
Policy log std Std           0.20700565
Policy log std Max           -0.019493818
Policy log std Min           -2.231312
Z mean eval                  0.04164564
Z variance eval              0.001010973
total_rewards                [1979.41735571 3197.1305865  3175.25541993  847.27846781 3191.3158173
 2745.45466447 1443.4171262  3254.68560721 3206.5254751  3217.0654989 ]
total_rewards_mean           2625.7546019119886
total_rewards_std            838.0786331501428
total_rewards_max            3254.685607213199
total_rewards_min            847.2784678063745
Number of train steps total  972000
Number of env steps total    986618
Number of rollouts total     0
Train Time (s)               143.0260280435905
(Previous) Eval Time (s)     26.115332515910268
Sample Time (s)              10.13275647116825
Epoch Time (s)               179.274117030669
Total Train Time (s)         40068.22836990794
Epoch                        242
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:38:17.978234 UTC | [2020_01_11_02_30_29] Iteration #242 | Epoch Duration: 179.35357809066772
2020-01-11 13:38:17.978450 UTC | [2020_01_11_02_30_29] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041315056
Z variance train             0.0010115625
KL Divergence                14.794555
KL Loss                      1.4794555
QF Loss                      125.88307
VF Loss                      43.13381
Policy Loss                  -1293.1394
Q Predictions Mean           1290.165
Q Predictions Std            357.36105
Q Predictions Max            1690.0063
Q Predictions Min            21.447523
V Predictions Mean           1294.8524
V Predictions Std            355.9522
V Predictions Max            1687.8115
V Predictions Min            14.67326
Log Pis Mean                 0.16139218
Log Pis Std                  1.9257456
Log Pis Max                  6.126349
Log Pis Min                  -4.284605
Policy mu Mean               0.12981217
Policy mu Std                0.9004275
Policy mu Max                2.694337
Policy mu Min                -2.492693
Policy log std Mean          -0.5692671
Policy log std Std           0.19037117
Policy log std Max           0.007096052
Policy log std Min           -1.2868599
Z mean eval                  0.024315277
Z variance eval              0.0011006087
total_rewards                [3231.22216513 1956.62229085  918.39672653  931.47109819 1466.33006477
 2207.83073908  831.18013729 3249.90035459 3268.84443505 1786.14196448]
total_rewards_mean           1984.7939975966415
total_rewards_std            934.8361631375378
total_rewards_max            3268.844435049893
total_rewards_min            831.1801372922764
Number of train steps total  976000
Number of env steps total    991417
Number of rollouts total     0
Train Time (s)               143.02563985157758
(Previous) Eval Time (s)     19.727608202956617
Sample Time (s)              10.168802863452584
Epoch Time (s)               172.92205091798678
Total Train Time (s)         40241.240957963746
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:41:10.994228 UTC | [2020_01_11_02_30_29] Iteration #243 | Epoch Duration: 173.01557207107544
2020-01-11 13:41:10.994555 UTC | [2020_01_11_02_30_29] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025214687
Z variance train             0.0011011349
KL Divergence                14.619537
KL Loss                      1.4619538
QF Loss                      156.11234
VF Loss                      60.706078
Policy Loss                  -1284.0836
Q Predictions Mean           1283.8055
Q Predictions Std            350.83728
Q Predictions Max            1715.1521
Q Predictions Min            -4.9171276
V Predictions Mean           1281.6677
V Predictions Std            348.74777
V Predictions Max            1707.5128
V Predictions Min            -11.235828
Log Pis Mean                 0.06778139
Log Pis Std                  2.0415528
Log Pis Max                  6.054071
Log Pis Min                  -6.2740726
Policy mu Mean               -0.03171469
Policy mu Std                0.94992846
Policy mu Max                3.1512024
Policy mu Min                -2.8258052
Policy log std Mean          -0.56068045
Policy log std Std           0.20033698
Policy log std Max           0.2176866
Policy log std Min           -1.7771649
Z mean eval                  0.037695773
Z variance eval              0.0010910888
total_rewards                [1107.22976304 2459.23755497 1606.74432963 3203.5231969  1132.79681292
  388.27375592 3207.26220102 2715.5879741  1172.68597293 3228.32078917]
total_rewards_mean           2022.166235059686
total_rewards_std            1005.9132169612361
total_rewards_max            3228.3207891691663
total_rewards_min            388.2737559228111
Number of train steps total  980000
Number of env steps total    996416
Number of rollouts total     0
Train Time (s)               149.3456261754036
(Previous) Eval Time (s)     21.020248488057405
Sample Time (s)              10.289129883982241
Epoch Time (s)               180.65500454744324
Total Train Time (s)         40421.98604155518
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:44:11.743622 UTC | [2020_01_11_02_30_29] Iteration #244 | Epoch Duration: 180.74886083602905
2020-01-11 13:44:11.743869 UTC | [2020_01_11_02_30_29] Iteration #244 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037613355
Z variance train             0.0010909174
KL Divergence                14.6676235
KL Loss                      1.4667624
QF Loss                      353.6126
VF Loss                      96.1227
Policy Loss                  -1261.3896
Q Predictions Mean           1257.886
Q Predictions Std            385.7222
Q Predictions Max            1678.4807
Q Predictions Min            -26.307777
V Predictions Mean           1262.04
V Predictions Std            381.09564
V Predictions Max            1680.1959
V Predictions Min            -14.99415
Log Pis Mean                 0.65516067
Log Pis Std                  2.5824673
Log Pis Max                  11.746212
Log Pis Min                  -6.946137
Policy mu Mean               0.032222357
Policy mu Std                1.0868988
Policy mu Max                3.1964486
Policy mu Min                -3.2835596
Policy log std Mean          -0.55337125
Policy log std Std           0.20687144
Policy log std Max           0.057389855
Policy log std Min           -1.8177297
Z mean eval                  0.019014109
Z variance eval              0.0012163051
total_rewards                [3203.98844793 3280.47483054 2531.33540296 3249.89661698 1121.9891376
 1977.37360448 2307.12882228  923.33392511 3212.55790875 1391.29125166]
total_rewards_mean           2319.936994828098
total_rewards_std            881.8130205602648
total_rewards_max            3280.47483053572
total_rewards_min            923.3339251147581
Number of train steps total  984000
Number of env steps total    1001285
Number of rollouts total     0
Train Time (s)               151.38883172394708
(Previous) Eval Time (s)     24.006410067901015
Sample Time (s)              9.744188525248319
Epoch Time (s)               185.1394303170964
Total Train Time (s)         40607.21063283924
Epoch                        245
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:47:16.972401 UTC | [2020_01_11_02_30_29] Iteration #245 | Epoch Duration: 185.22830748558044
2020-01-11 13:47:16.972724 UTC | [2020_01_11_02_30_29] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019619608
Z variance train             0.0012169677
KL Divergence                14.524019
KL Loss                      1.452402
QF Loss                      101.555084
VF Loss                      90.67421
Policy Loss                  -1304.8505
Q Predictions Mean           1299.4216
Q Predictions Std            343.1233
Q Predictions Max            1687.4393
Q Predictions Min            45.6222
V Predictions Mean           1300.0222
V Predictions Std            339.0838
V Predictions Max            1692.2141
V Predictions Min            49.34967
Log Pis Mean                 0.43019095
Log Pis Std                  2.2747397
Log Pis Max                  12.50654
Log Pis Min                  -5.6417522
Policy mu Mean               0.14904547
Policy mu Std                0.9900487
Policy mu Max                3.1801553
Policy mu Min                -2.757677
Policy log std Mean          -0.57624036
Policy log std Std           0.19917637
Policy log std Max           0.036957204
Policy log std Min           -2.0216026
Z mean eval                  0.024109386
Z variance eval              0.0014293323
total_rewards                [1456.04145012 2858.81301884 3271.09990224 2516.45034303  552.88737657
  846.54359735  883.0154561  1510.99584611 3282.96806878 1884.53904807]
total_rewards_mean           1906.33541072231
total_rewards_std            969.4766897254458
total_rewards_max            3282.9680687784344
total_rewards_min            552.8873765713928
Number of train steps total  988000
Number of env steps total    1006133
Number of rollouts total     0
Train Time (s)               149.4138333387673
(Previous) Eval Time (s)     19.26165194483474
Sample Time (s)              9.742394108790904
Epoch Time (s)               178.41787939239293
Total Train Time (s)         40785.71112978645
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:50:15.475658 UTC | [2020_01_11_02_30_29] Iteration #246 | Epoch Duration: 178.50274968147278
2020-01-11 13:50:15.475886 UTC | [2020_01_11_02_30_29] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023917463
Z variance train             0.0014300186
KL Divergence                14.483124
KL Loss                      1.4483124
QF Loss                      101.11865
VF Loss                      80.4418
Policy Loss                  -1304.1156
Q Predictions Mean           1302.3962
Q Predictions Std            335.14886
Q Predictions Max            1697.029
Q Predictions Min            119.339554
V Predictions Mean           1309.9712
V Predictions Std            335.6546
V Predictions Max            1708.6865
V Predictions Min            133.40602
Log Pis Mean                 0.1504333
Log Pis Std                  2.0011063
Log Pis Max                  7.491584
Log Pis Min                  -6.2473574
Policy mu Mean               0.0031511046
Policy mu Std                0.9562107
Policy mu Max                2.3514645
Policy mu Min                -2.8522248
Policy log std Mean          -0.5698731
Policy log std Std           0.1841923
Policy log std Max           0.013303161
Policy log std Min           -1.2789091
Z mean eval                  0.041548222
Z variance eval              0.0010344649
total_rewards                [3340.14080845 1325.30224417 3209.23311917 2552.18209639 2274.35566125
 2100.93643091 3168.60050548 3186.66060395 3042.52891898 3179.15592563]
total_rewards_mean           2737.9096314365643
total_rewards_std            625.2809749834142
total_rewards_max            3340.1408084476084
total_rewards_min            1325.3022441667333
Number of train steps total  992000
Number of env steps total    1011328
Number of rollouts total     0
Train Time (s)               151.4445037068799
(Previous) Eval Time (s)     27.325941807124764
Sample Time (s)              11.920461035799235
Epoch Time (s)               190.6909065498039
Total Train Time (s)         40976.48690606374
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:53:26.256220 UTC | [2020_01_11_02_30_29] Iteration #247 | Epoch Duration: 190.78014516830444
2020-01-11 13:53:26.256476 UTC | [2020_01_11_02_30_29] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04163198
Z variance train             0.0010346754
KL Divergence                15.064535
KL Loss                      1.5064535
QF Loss                      156.07092
VF Loss                      59.08725
Policy Loss                  -1289.9147
Q Predictions Mean           1287.7476
Q Predictions Std            360.16208
Q Predictions Max            1663.2307
Q Predictions Min            31.070318
V Predictions Mean           1286.4363
V Predictions Std            358.0665
V Predictions Max            1654.8363
V Predictions Min            23.710585
Log Pis Mean                 0.31267142
Log Pis Std                  2.1159549
Log Pis Max                  6.118579
Log Pis Min                  -5.4903245
Policy mu Mean               -0.047688276
Policy mu Std                0.9996783
Policy mu Max                3.281238
Policy mu Min                -2.8456075
Policy log std Mean          -0.5653591
Policy log std Std           0.18768084
Policy log std Max           0.16787207
Policy log std Min           -1.243259
Z mean eval                  0.033730455
Z variance eval              0.0013620935
total_rewards                [3147.69271514 3191.77516357 1189.13546491 2195.17115738 1272.77816991
 3206.43908653 1427.35533479 3188.02160063 3186.74852982 3225.44457793]
total_rewards_mean           2523.0561800620885
total_rewards_std            856.2121577765384
total_rewards_max            3225.4445779320317
total_rewards_min            1189.135464908539
Number of train steps total  996000
Number of env steps total    1016025
Number of rollouts total     0
Train Time (s)               146.80977205000818
(Previous) Eval Time (s)     25.12135358992964
Sample Time (s)              10.629991568159312
Epoch Time (s)               182.56111720809713
Total Train Time (s)         41159.13315295521
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:56:28.903883 UTC | [2020_01_11_02_30_29] Iteration #248 | Epoch Duration: 182.64720010757446
2020-01-11 13:56:28.904076 UTC | [2020_01_11_02_30_29] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033414144
Z variance train             0.0013617971
KL Divergence                14.257591
KL Loss                      1.4257592
QF Loss                      232.56186
VF Loss                      130.43988
Policy Loss                  -1286.9506
Q Predictions Mean           1281.5369
Q Predictions Std            363.70993
Q Predictions Max            1696.2137
Q Predictions Min            -14.63499
V Predictions Mean           1291.5576
V Predictions Std            354.20563
V Predictions Max            1703.9451
V Predictions Min            22.55665
Log Pis Mean                 0.40067434
Log Pis Std                  2.0916014
Log Pis Max                  9.430838
Log Pis Min                  -4.3035364
Policy mu Mean               0.0104648145
Policy mu Std                0.9979642
Policy mu Max                2.8664703
Policy mu Min                -3.446316
Policy log std Mean          -0.58920765
Policy log std Std           0.1978218
Policy log std Max           -0.0014723539
Policy log std Min           -2.5424192
Z mean eval                  0.005864392
Z variance eval              0.0013047204
total_rewards                [2289.83068326 3133.43767171 3301.10243231 1175.19143818 1289.41502532
 2545.15396249 3291.87082013 1133.15912508 1144.16908662 2854.64813758]
total_rewards_mean           2215.7978382690194
total_rewards_std            892.272916340574
total_rewards_max            3301.1024323071188
total_rewards_min            1133.1591250836545
Number of train steps total  1000000
Number of env steps total    1020854
Number of rollouts total     0
Train Time (s)               141.91073261154816
(Previous) Eval Time (s)     20.615461656358093
Sample Time (s)              8.289050585124642
Epoch Time (s)               170.8152448530309
Total Train Time (s)         41330.043843450956
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:59:19.818896 UTC | [2020_01_11_02_30_29] Iteration #249 | Epoch Duration: 170.91464924812317
2020-01-11 13:59:19.819113 UTC | [2020_01_11_02_30_29] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0057709543
Z variance train             0.0013043223
KL Divergence                14.26528
KL Loss                      1.426528
QF Loss                      153.96185
VF Loss                      41.92839
Policy Loss                  -1336.7173
Q Predictions Mean           1334.4644
Q Predictions Std            296.41595
Q Predictions Max            1669.7013
Q Predictions Min            82.44029
V Predictions Mean           1335.1982
V Predictions Std            292.53207
V Predictions Max            1672.7837
V Predictions Min            78.07002
Log Pis Mean                 0.19824877
Log Pis Std                  2.05633
Log Pis Max                  6.040367
Log Pis Min                  -6.0021315
Policy mu Mean               0.15129115
Policy mu Std                0.966922
Policy mu Max                3.0126615
Policy mu Min                -2.5561638
Policy log std Mean          -0.5867513
Policy log std Std           0.2021376
Policy log std Max           -0.0025455356
Policy log std Min           -2.3247662
Z mean eval                  0.019891886
Z variance eval              0.0013214367
total_rewards                [ 832.08074951 2224.41066967 2170.67966195 3252.03230146 2206.57565868
  887.90103634 3149.75409816  905.18831907 3243.00798202 3246.6845658 ]
total_rewards_mean           2211.8315042647014
total_rewards_std            972.7107511421917
total_rewards_max            3252.032301456925
total_rewards_min            832.0807495125326
Number of train steps total  1004000
Number of env steps total    1025575
Number of rollouts total     0
Train Time (s)               142.41903070965782
(Previous) Eval Time (s)     21.743525352794677
Sample Time (s)              10.460822685621679
Epoch Time (s)               174.62337874807417
Total Train Time (s)         41504.74743310781
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:02:14.525238 UTC | [2020_01_11_02_30_29] Iteration #250 | Epoch Duration: 174.70593070983887
2020-01-11 14:02:14.525450 UTC | [2020_01_11_02_30_29] Iteration #250 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019798428
Z variance train             0.0013211427
KL Divergence                14.137325
KL Loss                      1.4137325
QF Loss                      313.42883
VF Loss                      38.197216
Policy Loss                  -1274.8638
Q Predictions Mean           1271.3125
Q Predictions Std            378.77682
Q Predictions Max            1696.1321
Q Predictions Min            2.5844388
V Predictions Mean           1275.6079
V Predictions Std            377.2057
V Predictions Max            1692.6073
V Predictions Min            3.2314162
Log Pis Mean                 0.07819082
Log Pis Std                  2.2461085
Log Pis Max                  15.009188
Log Pis Min                  -7.2183723
Policy mu Mean               0.15613288
Policy mu Std                0.97247404
Policy mu Max                3.052158
Policy mu Min                -4.7880664
Policy log std Mean          -0.54794717
Policy log std Std           0.1888479
Policy log std Max           0.056611776
Policy log std Min           -1.328382
Z mean eval                  0.06462359
Z variance eval              0.0012361193
total_rewards                [3229.26197038  945.81476586  859.71946438 3135.88035484 3199.4569293
 2652.71284677 3221.87101213  838.1627179  3232.22897522 3184.49503499]
total_rewards_mean           2449.9604071761373
total_rewards_std            1040.057405199594
total_rewards_max            3232.228975216972
total_rewards_min            838.1627179009703
Number of train steps total  1008000
Number of env steps total    1030409
Number of rollouts total     0
Train Time (s)               142.62905906513333
(Previous) Eval Time (s)     25.105203100014478
Sample Time (s)              9.696395055856556
Epoch Time (s)               177.43065722100437
Total Train Time (s)         41682.25813527452
Epoch                        251
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:05:12.038988 UTC | [2020_01_11_02_30_29] Iteration #251 | Epoch Duration: 177.51338386535645
2020-01-11 14:05:12.039210 UTC | [2020_01_11_02_30_29] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06469553
Z variance train             0.00123715
KL Divergence                14.362239
KL Loss                      1.4362239
QF Loss                      131.45903
VF Loss                      38.649574
Policy Loss                  -1292.7601
Q Predictions Mean           1291.4314
Q Predictions Std            347.15237
Q Predictions Max            1691.8578
Q Predictions Min            55.11381
V Predictions Mean           1290.8866
V Predictions Std            346.13995
V Predictions Max            1683.7421
V Predictions Min            48.32383
Log Pis Mean                 -0.008439969
Log Pis Std                  2.0985029
Log Pis Max                  6.064663
Log Pis Min                  -7.238646
Policy mu Mean               0.105751835
Policy mu Std                0.9481896
Policy mu Max                3.5374901
Policy mu Min                -2.623099
Policy log std Mean          -0.5308802
Policy log std Std           0.19566108
Policy log std Max           0.067986846
Policy log std Min           -1.0422773
Z mean eval                  0.037776783
Z variance eval              0.0010205441
total_rewards                [3131.12571822 3202.44537845 3198.67901883 3121.50334303 3215.72227516
 3273.27776581 3214.3230223  3146.40963407 1661.01060234 2224.33106705]
total_rewards_mean           2938.8827825262942
total_rewards_std            515.577659923417
total_rewards_max            3273.2777658135756
total_rewards_min            1661.0106023380667
Number of train steps total  1012000
Number of env steps total    1035335
Number of rollouts total     0
Train Time (s)               142.41278864396736
(Previous) Eval Time (s)     29.282480510883033
Sample Time (s)              10.057980770245194
Epoch Time (s)               181.7532499250956
Total Train Time (s)         41864.115094915964
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:08:13.899300 UTC | [2020_01_11_02_30_29] Iteration #252 | Epoch Duration: 181.85993671417236
2020-01-11 14:08:13.899501 UTC | [2020_01_11_02_30_29] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038096808
Z variance train             0.001020338
KL Divergence                14.748781
KL Loss                      1.4748782
QF Loss                      106.35022
VF Loss                      41.605324
Policy Loss                  -1312.3724
Q Predictions Mean           1307.2568
Q Predictions Std            354.03815
Q Predictions Max            1717.5676
Q Predictions Min            22.173744
V Predictions Mean           1308.7708
V Predictions Std            351.53653
V Predictions Max            1711.2827
V Predictions Min            29.158829
Log Pis Mean                 0.15051125
Log Pis Std                  1.9457059
Log Pis Max                  5.801499
Log Pis Min                  -4.915971
Policy mu Mean               -0.004553102
Policy mu Std                0.97192675
Policy mu Max                2.3383753
Policy mu Min                -2.6613982
Policy log std Mean          -0.55475074
Policy log std Std           0.19121511
Policy log std Max           0.14454138
Policy log std Min           -1.6086357
Z mean eval                  0.035252105
Z variance eval              0.001117564
total_rewards                [1639.63513363 1581.90640317 3192.57412894 2477.09701906 3212.62640412
 3195.09482423 1322.81801597 3227.04621247  940.30515097 1401.70583121]
total_rewards_mean           2219.080912376421
total_rewards_std            884.2169765909482
total_rewards_max            3227.046212468073
total_rewards_min            940.3051509740818
Number of train steps total  1016000
Number of env steps total    1040064
Number of rollouts total     0
Train Time (s)               142.83961022365838
(Previous) Eval Time (s)     21.742343559861183
Sample Time (s)              10.115056982729584
Epoch Time (s)               174.69701076624915
Total Train Time (s)         42038.88948643487
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:11:08.676877 UTC | [2020_01_11_02_30_29] Iteration #253 | Epoch Duration: 174.77722907066345
2020-01-11 14:11:08.677062 UTC | [2020_01_11_02_30_29] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034754433
Z variance train             0.001117348
KL Divergence                14.702211
KL Loss                      1.4702212
QF Loss                      8026.5796
VF Loss                      69.127846
Policy Loss                  -1331.9355
Q Predictions Mean           1329.4136
Q Predictions Std            317.901
Q Predictions Max            1682.467
Q Predictions Min            27.840559
V Predictions Mean           1334.4028
V Predictions Std            313.9562
V Predictions Max            1678.6871
V Predictions Min            39.269253
Log Pis Mean                 0.19462787
Log Pis Std                  1.9443234
Log Pis Max                  5.824608
Log Pis Min                  -4.3407054
Policy mu Mean               0.004713721
Policy mu Std                0.9919786
Policy mu Max                2.583242
Policy mu Min                -3.2999125
Policy log std Mean          -0.5614819
Policy log std Std           0.18361673
Policy log std Max           0.035485685
Policy log std Min           -1.383471
Z mean eval                  0.051684033
Z variance eval              0.0011366726
total_rewards                [3233.02550226 3266.50742682  853.22256186 3353.11718588 1454.06782027
 1047.43333975 1907.77854026  873.7229055  1465.69759683 3267.30600893]
total_rewards_mean           2072.1878888356814
total_rewards_std            1029.1880443536188
total_rewards_max            3353.117185876302
total_rewards_min            853.2225618624512
Number of train steps total  1020000
Number of env steps total    1044820
Number of rollouts total     0
Train Time (s)               143.21313555212691
(Previous) Eval Time (s)     19.97789000486955
Sample Time (s)              8.917999919038266
Epoch Time (s)               172.10902547603473
Total Train Time (s)         42211.15469328873
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:14:00.945147 UTC | [2020_01_11_02_30_29] Iteration #254 | Epoch Duration: 172.26793432235718
2020-01-11 14:14:00.945380 UTC | [2020_01_11_02_30_29] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05081551
Z variance train             0.0011369133
KL Divergence                14.650656
KL Loss                      1.4650656
QF Loss                      942.6827
VF Loss                      39.616615
Policy Loss                  -1307.6046
Q Predictions Mean           1303.8844
Q Predictions Std            360.90247
Q Predictions Max            1696.2465
Q Predictions Min            50.134632
V Predictions Mean           1304.7849
V Predictions Std            360.0054
V Predictions Max            1695.8132
V Predictions Min            43.36402
Log Pis Mean                 0.080653995
Log Pis Std                  2.1666753
Log Pis Max                  6.7746315
Log Pis Min                  -5.8139024
Policy mu Mean               -0.01375706
Policy mu Std                0.94967204
Policy mu Max                2.9438767
Policy mu Min                -2.6656
Policy log std Mean          -0.54543316
Policy log std Std           0.20562899
Policy log std Max           0.3768996
Policy log std Min           -1.9527271
Z mean eval                  0.05743588
Z variance eval              0.0011557812
total_rewards                [1054.45085588 2227.94779588 3244.19753948 2677.06106543  830.97300242
 3197.700673   3201.33886987 1496.40647663 3228.9324263  1148.98144844]
total_rewards_mean           2230.7990153326414
total_rewards_std            956.6723971198401
total_rewards_max            3244.197539480265
total_rewards_min            830.973002415643
Number of train steps total  1024000
Number of env steps total    1049631
Number of rollouts total     0
Train Time (s)               142.6078417878598
(Previous) Eval Time (s)     21.338419083040208
Sample Time (s)              10.434614571277052
Epoch Time (s)               174.38087544217706
Total Train Time (s)         42385.64237446897
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:16:55.436171 UTC | [2020_01_11_02_30_29] Iteration #255 | Epoch Duration: 174.49062991142273
2020-01-11 14:16:55.436393 UTC | [2020_01_11_02_30_29] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057468273
Z variance train             0.0011558246
KL Divergence                14.674435
KL Loss                      1.4674435
QF Loss                      78.89154
VF Loss                      36.94104
Policy Loss                  -1308.6322
Q Predictions Mean           1309.0461
Q Predictions Std            368.01837
Q Predictions Max            1685.3168
Q Predictions Min            18.969784
V Predictions Mean           1309.3927
V Predictions Std            368.29224
V Predictions Max            1683.475
V Predictions Min            24.388083
Log Pis Mean                 0.1446276
Log Pis Std                  2.0623698
Log Pis Max                  7.796536
Log Pis Min                  -5.551111
Policy mu Mean               0.019148916
Policy mu Std                0.9417422
Policy mu Max                2.6685312
Policy mu Min                -3.0921416
Policy log std Mean          -0.5518584
Policy log std Std           0.19520617
Policy log std Max           0.10989624
Policy log std Min           -1.1815362
Z mean eval                  0.02965421
Z variance eval              0.0010797015
total_rewards                [3306.26549958 3281.91547636 3260.32454939 2470.23815081 1345.43050797
 3267.46614734 3285.47338356 2416.92710198 3303.21196076 2459.93479935]
total_rewards_mean           2839.718757709899
total_rewards_std            622.8166607245573
total_rewards_max            3306.265499583831
total_rewards_min            1345.4305079707397
Number of train steps total  1028000
Number of env steps total    1054315
Number of rollouts total     0
Train Time (s)               143.6340227080509
(Previous) Eval Time (s)     24.484135422855616
Sample Time (s)              9.581382836215198
Epoch Time (s)               177.69954096712172
Total Train Time (s)         42563.43409556849
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:19:53.230767 UTC | [2020_01_11_02_30_29] Iteration #256 | Epoch Duration: 177.79421210289001
2020-01-11 14:19:53.230962 UTC | [2020_01_11_02_30_29] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030407753
Z variance train             0.0010794299
KL Divergence                14.743196
KL Loss                      1.4743196
QF Loss                      179.05228
VF Loss                      40.048965
Policy Loss                  -1308.1134
Q Predictions Mean           1305.6307
Q Predictions Std            355.1522
Q Predictions Max            1694.7002
Q Predictions Min            42.35915
V Predictions Mean           1305.696
V Predictions Std            353.82697
V Predictions Max            1696.168
V Predictions Min            64.385056
Log Pis Mean                 0.013012715
Log Pis Std                  2.1438766
Log Pis Max                  8.076396
Log Pis Min                  -8.916115
Policy mu Mean               -0.019853534
Policy mu Std                0.9589687
Policy mu Max                2.2436225
Policy mu Min                -2.6257582
Policy log std Mean          -0.53749347
Policy log std Std           0.18369988
Policy log std Max           0.1977973
Policy log std Min           -1.0983756
Z mean eval                  0.062021933
Z variance eval              0.0013822623
total_rewards                [2857.46399798 1186.48381209 3279.31631859 1145.06611542  945.25961734
 1514.52309317 3266.76041828  868.83491023 2682.02693719 1811.69550329]
total_rewards_mean           1955.7430723583243
total_rewards_std            920.7621503650824
total_rewards_max            3279.316318594937
total_rewards_min            868.8349102272016
Number of train steps total  1032000
Number of env steps total    1059151
Number of rollouts total     0
Train Time (s)               141.84476284589618
(Previous) Eval Time (s)     18.90581420622766
Sample Time (s)              10.561660144012421
Epoch Time (s)               171.31223719613627
Total Train Time (s)         42734.8271807055
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:22:44.627274 UTC | [2020_01_11_02_30_29] Iteration #257 | Epoch Duration: 171.39607644081116
2020-01-11 14:22:44.627509 UTC | [2020_01_11_02_30_29] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062121022
Z variance train             0.0013822301
KL Divergence                14.157385
KL Loss                      1.4157385
QF Loss                      140.15405
VF Loss                      33.476944
Policy Loss                  -1321.9148
Q Predictions Mean           1320.5942
Q Predictions Std            362.19635
Q Predictions Max            1708.6729
Q Predictions Min            26.15184
V Predictions Mean           1322.3789
V Predictions Std            362.47693
V Predictions Max            1713.2899
V Predictions Min            32.983994
Log Pis Mean                 0.11457038
Log Pis Std                  1.9799861
Log Pis Max                  7.1735153
Log Pis Min                  -4.3012056
Policy mu Mean               0.053356815
Policy mu Std                0.9423916
Policy mu Max                2.9998643
Policy mu Min                -2.6945922
Policy log std Mean          -0.55679154
Policy log std Std           0.18811244
Policy log std Max           0.24699134
Policy log std Min           -1.1519248
Z mean eval                  0.0061083734
Z variance eval              0.0015471496
total_rewards                [3260.93123105 3296.05447866 3298.09686328 3278.31867497 3314.03419966
 3282.34032174 3296.95760916 2125.3619518  3298.59066715 3320.54813399]
total_rewards_mean           3177.1234131449937
total_rewards_std            350.9623793373953
total_rewards_max            3320.548133988625
total_rewards_min            2125.361951801986
Number of train steps total  1036000
Number of env steps total    1063920
Number of rollouts total     0
Train Time (s)               141.22674793889746
(Previous) Eval Time (s)     31.29638016363606
Sample Time (s)              10.395896641537547
Epoch Time (s)               182.91902474407107
Total Train Time (s)         42917.83193598408
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:25:47.636737 UTC | [2020_01_11_02_30_29] Iteration #258 | Epoch Duration: 183.0090367794037
2020-01-11 14:25:47.637025 UTC | [2020_01_11_02_30_29] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.006087368
Z variance train             0.0015464906
KL Divergence                13.9637375
KL Loss                      1.3963737
QF Loss                      132.63507
VF Loss                      46.714226
Policy Loss                  -1324.6855
Q Predictions Mean           1324.6146
Q Predictions Std            361.2173
Q Predictions Max            1708.5416
Q Predictions Min            37.631187
V Predictions Mean           1326.5875
V Predictions Std            357.36423
V Predictions Max            1704.3928
V Predictions Min            45.87891
Log Pis Mean                 0.074977726
Log Pis Std                  1.919879
Log Pis Max                  6.8997126
Log Pis Min                  -6.8669705
Policy mu Mean               -0.019729009
Policy mu Std                0.93580866
Policy mu Max                2.7635584
Policy mu Min                -2.5785441
Policy log std Mean          -0.55921525
Policy log std Std           0.18247491
Policy log std Max           0.08836293
Policy log std Min           -1.2189648
Z mean eval                  0.042113923
Z variance eval              0.001507656
total_rewards                [3264.40338355 2366.6659378  3178.61986384 3203.69353407 2156.17321513
 3213.22973955 2188.5090311  3198.50633873 2020.21650969  119.77195935]
total_rewards_mean           2490.978951280876
total_rewards_std            930.8337763858574
total_rewards_max            3264.4033835482146
total_rewards_min            119.77195934936059
Number of train steps total  1040000
Number of env steps total    1068680
Number of rollouts total     0
Train Time (s)               142.62406294280663
(Previous) Eval Time (s)     24.659488703124225
Sample Time (s)              8.963839688804
Epoch Time (s)               176.24739133473486
Total Train Time (s)         43094.45730151888
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:28:44.264359 UTC | [2020_01_11_02_30_29] Iteration #259 | Epoch Duration: 176.62714529037476
2020-01-11 14:28:44.264565 UTC | [2020_01_11_02_30_29] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042318933
Z variance train             0.0015077533
KL Divergence                13.919676
KL Loss                      1.3919677
QF Loss                      75.748924
VF Loss                      27.070066
Policy Loss                  -1329.7535
Q Predictions Mean           1328.2722
Q Predictions Std            352.94348
Q Predictions Max            1743.9874
Q Predictions Min            34.35924
V Predictions Mean           1327.5391
V Predictions Std            351.83887
V Predictions Max            1740.4475
V Predictions Min            -5.3211365
Log Pis Mean                 0.28799486
Log Pis Std                  2.090992
Log Pis Max                  8.5384
Log Pis Min                  -3.772739
Policy mu Mean               0.042017166
Policy mu Std                0.9691271
Policy mu Max                2.6830053
Policy mu Min                -2.668849
Policy log std Mean          -0.523333
Policy log std Std           0.18569241
Policy log std Max           0.25619227
Policy log std Min           -1.0931879
Z mean eval                  0.0508546
Z variance eval              0.0018815991
total_rewards                [3285.49166173 1338.48970864 2404.05334331 3234.1137732  1631.63896389
 3271.67201584 3216.15907706 1108.92580442 1367.64734412 3183.57318189]
total_rewards_mean           2404.1764874109294
total_rewards_std            892.7152573717907
total_rewards_max            3285.4916617307854
total_rewards_min            1108.9258044218645
Number of train steps total  1044000
Number of env steps total    1073867
Number of rollouts total     0
Train Time (s)               141.34385223966092
(Previous) Eval Time (s)     24.251015093177557
Sample Time (s)              9.283851616550237
Epoch Time (s)               174.8787189493887
Total Train Time (s)         43269.414052254055
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:31:39.223915 UTC | [2020_01_11_02_30_29] Iteration #260 | Epoch Duration: 174.95920538902283
2020-01-11 14:31:39.224090 UTC | [2020_01_11_02_30_29] Iteration #260 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051382743
Z variance train             0.0018801743
KL Divergence                13.545507
KL Loss                      1.3545507
QF Loss                      150.55612
VF Loss                      55.87815
Policy Loss                  -1298.211
Q Predictions Mean           1296.8759
Q Predictions Std            371.54123
Q Predictions Max            1691.9746
Q Predictions Min            3.7466545
V Predictions Mean           1300.6724
V Predictions Std            369.76807
V Predictions Max            1690.015
V Predictions Min            9.068493
Log Pis Mean                 0.1521177
Log Pis Std                  2.1006882
Log Pis Max                  9.399103
Log Pis Min                  -4.9600844
Policy mu Mean               0.09747837
Policy mu Std                0.95079905
Policy mu Max                2.658257
Policy mu Min                -2.8625374
Policy log std Mean          -0.5571951
Policy log std Std           0.19321612
Policy log std Max           0.13534826
Policy log std Min           -1.226387
Z mean eval                  0.045604963
Z variance eval              0.0015869283
total_rewards                [2982.14436103 2507.14194085 3186.81711325 3215.10207677 3053.4492253
 3203.46011382 3274.87132642 3215.90288489  866.81295938 2115.13408031]
total_rewards_mean           2762.0836082007354
total_rewards_std            725.1379950171921
total_rewards_max            3274.8713264171743
total_rewards_min            866.8129593791442
Number of train steps total  1048000
Number of env steps total    1078984
Number of rollouts total     0
Train Time (s)               141.24967787694186
(Previous) Eval Time (s)     27.422310941386968
Sample Time (s)              10.120385000482202
Epoch Time (s)               178.79237381881103
Total Train Time (s)         43448.288571876474
Epoch                        261
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:34:38.101887 UTC | [2020_01_11_02_30_29] Iteration #261 | Epoch Duration: 178.87765264511108
2020-01-11 14:34:38.102072 UTC | [2020_01_11_02_30_29] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043993644
Z variance train             0.0015849508
KL Divergence                13.763291
KL Loss                      1.3763292
QF Loss                      136.23633
VF Loss                      55.508354
Policy Loss                  -1351.2585
Q Predictions Mean           1353.4397
Q Predictions Std            356.16138
Q Predictions Max            1696.5626
Q Predictions Min            46.63764
V Predictions Mean           1351.14
V Predictions Std            353.4052
V Predictions Max            1689.2167
V Predictions Min            50.07741
Log Pis Mean                 -0.027609654
Log Pis Std                  1.8863181
Log Pis Max                  6.433804
Log Pis Min                  -5.30538
Policy mu Mean               0.040312935
Policy mu Std                0.90487444
Policy mu Max                2.2819507
Policy mu Min                -2.5169058
Policy log std Mean          -0.55357593
Policy log std Std           0.17803304
Policy log std Max           0.08563006
Policy log std Min           -1.1530304
Z mean eval                  0.040284216
Z variance eval              0.0017869284
total_rewards                [ 965.16424846 1253.11754546  746.52952337 1757.75577054 1208.69343956
 3220.88100623 1019.94233974 1206.38022902 2279.07172597  344.46686359]
total_rewards_mean           1400.2002691944676
total_rewards_std            786.5573482960962
total_rewards_max            3220.8810062308576
total_rewards_min            344.46686358858824
Number of train steps total  1052000
Number of env steps total    1083969
Number of rollouts total     0
Train Time (s)               145.36887012189254
(Previous) Eval Time (s)     13.855503843165934
Sample Time (s)              10.556687351316214
Epoch Time (s)               169.7810613163747
Total Train Time (s)         43618.190444257576
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:37:28.008302 UTC | [2020_01_11_02_30_29] Iteration #262 | Epoch Duration: 169.9060571193695
2020-01-11 14:37:28.008549 UTC | [2020_01_11_02_30_29] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040279157
Z variance train             0.001786878
KL Divergence                13.427902
KL Loss                      1.3427902
QF Loss                      120.22694
VF Loss                      27.08243
Policy Loss                  -1357.1923
Q Predictions Mean           1355.8708
Q Predictions Std            294.65533
Q Predictions Max            1705.0249
Q Predictions Min            249.14996
V Predictions Mean           1357.8572
V Predictions Std            291.5148
V Predictions Max            1704.787
V Predictions Min            259.60788
Log Pis Mean                 0.21610133
Log Pis Std                  2.1296546
Log Pis Max                  6.9677563
Log Pis Min                  -5.421155
Policy mu Mean               -0.018770644
Policy mu Std                0.9777899
Policy mu Max                2.7094772
Policy mu Min                -2.705134
Policy log std Mean          -0.5352812
Policy log std Std           0.19675416
Policy log std Max           0.20256507
Policy log std Min           -1.2076344
Z mean eval                  0.037970413
Z variance eval              0.0017358933
total_rewards                [1162.93991219  881.30106964 2176.14822235 2014.95788375 2541.93982161
 1244.11607777 1576.45473184 1632.74443344  818.97181802 1144.70237956]
total_rewards_mean           1519.4276350154482
total_rewards_std            545.8570277758433
total_rewards_max            2541.9398216081927
total_rewards_min            818.9718180157091
Number of train steps total  1056000
Number of env steps total    1088890
Number of rollouts total     0
Train Time (s)               152.6744021368213
(Previous) Eval Time (s)     14.602903669700027
Sample Time (s)              10.235390668269247
Epoch Time (s)               177.51269647479057
Total Train Time (s)         43795.80110255908
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:40:25.621220 UTC | [2020_01_11_02_30_29] Iteration #263 | Epoch Duration: 177.61249613761902
2020-01-11 14:40:25.621418 UTC | [2020_01_11_02_30_29] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038287148
Z variance train             0.0017352679
KL Divergence                13.4896755
KL Loss                      1.3489676
QF Loss                      134.93948
VF Loss                      69.90562
Policy Loss                  -1307.875
Q Predictions Mean           1306.093
Q Predictions Std            378.0773
Q Predictions Max            1705.2727
Q Predictions Min            50.533234
V Predictions Mean           1310.9196
V Predictions Std            377.9967
V Predictions Max            1698.8843
V Predictions Min            41.13217
Log Pis Mean                 0.26830655
Log Pis Std                  2.1124532
Log Pis Max                  6.7870526
Log Pis Min                  -5.3061066
Policy mu Mean               -0.015173037
Policy mu Std                0.9652062
Policy mu Max                3.029268
Policy mu Min                -2.6625838
Policy log std Mean          -0.5475854
Policy log std Std           0.18854825
Policy log std Max           0.16598636
Policy log std Min           -1.1515718
Z mean eval                  0.052449785
Z variance eval              0.0021770166
total_rewards                [3257.75337519 3298.05573806 2204.4553327  3111.6955494  2303.84574518
  877.18326999 2275.10276273  902.47109245 2169.76785402  922.17930126]
total_rewards_mean           2132.251002099388
total_rewards_std            905.1777403298526
total_rewards_max            3298.0557380614755
total_rewards_min            877.1832699922301
Number of train steps total  1060000
Number of env steps total    1093783
Number of rollouts total     0
Train Time (s)               151.1525557897985
(Previous) Eval Time (s)     21.437125351745635
Sample Time (s)              10.140117733273655
Epoch Time (s)               182.7297988748178
Total Train Time (s)         43978.610602930654
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:43:28.433372 UTC | [2020_01_11_02_30_29] Iteration #264 | Epoch Duration: 182.81181073188782
2020-01-11 14:43:28.433547 UTC | [2020_01_11_02_30_29] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052048344
Z variance train             0.0021797586
KL Divergence                13.049482
KL Loss                      1.3049482
QF Loss                      151.87975
VF Loss                      67.87248
Policy Loss                  -1288.3798
Q Predictions Mean           1286.3108
Q Predictions Std            379.13867
Q Predictions Max            1686.6406
Q Predictions Min            -28.498308
V Predictions Mean           1286.7666
V Predictions Std            377.77713
V Predictions Max            1688.3602
V Predictions Min            -25.132454
Log Pis Mean                 0.2723621
Log Pis Std                  2.0742989
Log Pis Max                  10.712696
Log Pis Min                  -4.747196
Policy mu Mean               0.031086301
Policy mu Std                0.9648518
Policy mu Max                2.8922877
Policy mu Min                -2.5842838
Policy log std Mean          -0.56097704
Policy log std Std           0.21130748
Policy log std Max           0.65461123
Policy log std Min           -1.4207166
Z mean eval                  0.026697543
Z variance eval              0.0025365453
total_rewards                [1836.61583443 3138.80096394 1070.30689429 1090.21923799 1360.89333102
 1261.01418278 1123.71598985 1269.45627643 1562.35133642 1361.86754966]
total_rewards_mean           1507.524159680894
total_rewards_std            586.9533492164104
total_rewards_max            3138.8009639392703
total_rewards_min            1070.3068942942627
Number of train steps total  1064000
Number of env steps total    1098879
Number of rollouts total     0
Train Time (s)               150.26915501290932
(Previous) Eval Time (s)     15.341288805007935
Sample Time (s)              10.21051954710856
Epoch Time (s)               175.82096336502582
Total Train Time (s)         44154.507941354066
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:46:24.334488 UTC | [2020_01_11_02_30_29] Iteration #265 | Epoch Duration: 175.90081214904785
2020-01-11 14:46:24.334677 UTC | [2020_01_11_02_30_29] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026763195
Z variance train             0.0025383069
KL Divergence                12.626259
KL Loss                      1.2626259
QF Loss                      79.24242
VF Loss                      43.351025
Policy Loss                  -1340.0276
Q Predictions Mean           1339.47
Q Predictions Std            323.2085
Q Predictions Max            1695.5614
Q Predictions Min            -41.976746
V Predictions Mean           1340.945
V Predictions Std            318.1114
V Predictions Max            1687.4307
V Predictions Min            -56.00355
Log Pis Mean                 0.038982537
Log Pis Std                  2.319525
Log Pis Max                  11.671632
Log Pis Min                  -4.805281
Policy mu Mean               -0.029713444
Policy mu Std                0.9248323
Policy mu Max                3.8278658
Policy mu Min                -2.6711125
Policy log std Mean          -0.52541566
Policy log std Std           0.1972169
Policy log std Max           0.0745399
Policy log std Min           -1.3669026
Z mean eval                  0.03497119
Z variance eval              0.0024825248
total_rewards                [3275.38272219 3247.6636035  1200.56361317 3295.27672856 1530.36743004
 3028.35321097 1943.03583407 2578.08022791 1413.77347115 1025.14149763]
total_rewards_mean           2253.7638339183954
total_rewards_std            881.2288265703235
total_rewards_max            3295.2767285576097
total_rewards_min            1025.1414976331694
Number of train steps total  1068000
Number of env steps total    1103981
Number of rollouts total     0
Train Time (s)               150.2455853591673
(Previous) Eval Time (s)     22.606379855889827
Sample Time (s)              9.874437144491822
Epoch Time (s)               182.72640235954896
Total Train Time (s)         44337.3188804565
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:49:27.148929 UTC | [2020_01_11_02_30_29] Iteration #266 | Epoch Duration: 182.8140950202942
2020-01-11 14:49:27.149156 UTC | [2020_01_11_02_30_29] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03498744
Z variance train             0.0024836536
KL Divergence                12.568235
KL Loss                      1.2568235
QF Loss                      112.268105
VF Loss                      35.686893
Policy Loss                  -1320.6521
Q Predictions Mean           1319.8047
Q Predictions Std            380.8625
Q Predictions Max            1732.1802
Q Predictions Min            55.420055
V Predictions Mean           1322.7539
V Predictions Std            379.1276
V Predictions Max            1730.3304
V Predictions Min            57.786835
Log Pis Mean                 -0.010267183
Log Pis Std                  1.9453062
Log Pis Max                  8.888752
Log Pis Min                  -4.017737
Policy mu Mean               0.0015570335
Policy mu Std                0.94120526
Policy mu Max                2.1804638
Policy mu Min                -2.7818475
Policy log std Mean          -0.5246936
Policy log std Std           0.16513959
Policy log std Max           0.10745072
Policy log std Min           -1.0831414
Z mean eval                  0.04223134
Z variance eval              0.0030706378
total_rewards                [1762.12659247 2798.2067139  3224.53273377 2750.89514781 1816.38532613
  864.82451365  902.71483102 1088.59589358  857.05854128  867.39567473]
total_rewards_mean           1693.2735968341585
total_rewards_std            881.0430436373623
total_rewards_max            3224.532733770193
total_rewards_min            857.0585412759945
Number of train steps total  1072000
Number of env steps total    1108873
Number of rollouts total     0
Train Time (s)               144.85509249195457
(Previous) Eval Time (s)     16.052532866131514
Sample Time (s)              10.078788080252707
Epoch Time (s)               170.9864134383388
Total Train Time (s)         44508.391910264734
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:52:18.226107 UTC | [2020_01_11_02_30_29] Iteration #267 | Epoch Duration: 171.0767753124237
2020-01-11 14:52:18.226366 UTC | [2020_01_11_02_30_29] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04290218
Z variance train             0.0030711473
KL Divergence                12.040024
KL Loss                      1.2040024
QF Loss                      78.25074
VF Loss                      32.25983
Policy Loss                  -1309.1833
Q Predictions Mean           1309.748
Q Predictions Std            369.44592
Q Predictions Max            1686.3883
Q Predictions Min            80.52155
V Predictions Mean           1310.5479
V Predictions Std            369.81046
V Predictions Max            1686.9126
V Predictions Min            82.818985
Log Pis Mean                 0.02535215
Log Pis Std                  2.0272443
Log Pis Max                  6.3619366
Log Pis Min                  -6.1311283
Policy mu Mean               0.026382908
Policy mu Std                0.9219794
Policy mu Max                2.2005773
Policy mu Min                -2.7314067
Policy log std Mean          -0.54571426
Policy log std Std           0.19307955
Policy log std Max           0.03690362
Policy log std Min           -1.2229942
Z mean eval                  0.029568832
Z variance eval              0.002908843
total_rewards                [3268.92780441 3293.28284853 3032.40654533 3220.17994336 3287.98214142
 3258.15811116 2821.09554649 3249.36720816 3221.10518415  936.20108605]
total_rewards_mean           2958.870641907256
total_rewards_std            688.6852500005683
total_rewards_max            3293.2828485319715
total_rewards_min            936.2010860546285
Number of train steps total  1076000
Number of env steps total    1114110
Number of rollouts total     0
Train Time (s)               141.9973643538542
(Previous) Eval Time (s)     27.657952486071736
Sample Time (s)              10.277804184705019
Epoch Time (s)               179.93312102463096
Total Train Time (s)         44688.41928292299
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:55:18.256449 UTC | [2020_01_11_02_30_29] Iteration #268 | Epoch Duration: 180.0299038887024
2020-01-11 14:55:18.256660 UTC | [2020_01_11_02_30_29] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029724408
Z variance train             0.0029084247
KL Divergence                12.238885
KL Loss                      1.2238885
QF Loss                      706.3371
VF Loss                      142.85414
Policy Loss                  -1306.1569
Q Predictions Mean           1300.0938
Q Predictions Std            390.45236
Q Predictions Max            1687.0735
Q Predictions Min            15.98781
V Predictions Mean           1298.4003
V Predictions Std            387.4468
V Predictions Max            1694.3358
V Predictions Min            15.400768
Log Pis Mean                 -0.030115888
Log Pis Std                  2.1104047
Log Pis Max                  6.7119412
Log Pis Min                  -6.065082
Policy mu Mean               -0.046760086
Policy mu Std                0.965487
Policy mu Max                2.9666667
Policy mu Min                -3.355536
Policy log std Mean          -0.54022735
Policy log std Std           0.18767427
Policy log std Max           0.12549514
Policy log std Min           -1.325238
Z mean eval                  0.051512025
Z variance eval              0.003349639
total_rewards                [3255.89412508 2222.90148064 2870.59208367 3191.00216417 3212.63626899
 3237.70161506 3250.70142975 1634.61427799 3258.02911696 1305.05237114]
total_rewards_mean           2743.912493345334
total_rewards_std            709.581295140892
total_rewards_max            3258.029116955241
total_rewards_min            1305.0523711374028
Number of train steps total  1080000
Number of env steps total    1119163
Number of rollouts total     0
Train Time (s)               142.48935109423473
(Previous) Eval Time (s)     27.296558597125113
Sample Time (s)              9.823387966491282
Epoch Time (s)               179.60929765785113
Total Train Time (s)         44868.109578486066
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:58:17.950387 UTC | [2020_01_11_02_30_29] Iteration #269 | Epoch Duration: 179.69356441497803
2020-01-11 14:58:17.950659 UTC | [2020_01_11_02_30_29] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05147894
Z variance train             0.0033482905
KL Divergence                12.025784
KL Loss                      1.2025784
QF Loss                      94.43878
VF Loss                      30.95382
Policy Loss                  -1327.1687
Q Predictions Mean           1326.4829
Q Predictions Std            385.79654
Q Predictions Max            1762.1265
Q Predictions Min            50.054085
V Predictions Mean           1325.5212
V Predictions Std            384.2055
V Predictions Max            1749.2891
V Predictions Min            50.62639
Log Pis Mean                 0.100506075
Log Pis Std                  2.0706325
Log Pis Max                  6.1630845
Log Pis Min                  -6.194601
Policy mu Mean               0.020610668
Policy mu Std                0.95638263
Policy mu Max                2.6180797
Policy mu Min                -2.4852028
Policy log std Mean          -0.54267675
Policy log std Std           0.18266416
Policy log std Max           0.13671911
Policy log std Min           -1.1057218
Z mean eval                  0.051606487
Z variance eval              0.003117749
total_rewards                [3200.84919165 2439.18381806 3228.09922696 3271.08243413 3171.19898084
 2690.82009712 3231.66359319 1414.27086407 3280.07949202 3247.21342894]
total_rewards_mean           2917.4461126987553
total_rewards_std            569.6388246689476
total_rewards_max            3280.079492016632
total_rewards_min            1414.270864070175
Number of train steps total  1084000
Number of env steps total    1124086
Number of rollouts total     0
Train Time (s)               143.45793685968965
(Previous) Eval Time (s)     29.022427862975746
Sample Time (s)              9.544624440837651
Epoch Time (s)               182.02498916350305
Total Train Time (s)         45050.227492150385
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:01:20.076520 UTC | [2020_01_11_02_30_29] Iteration #270 | Epoch Duration: 182.12559032440186
2020-01-11 15:01:20.076831 UTC | [2020_01_11_02_30_29] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051584132
Z variance train             0.0031165653
KL Divergence                12.225325
KL Loss                      1.2225325
QF Loss                      62.951603
VF Loss                      17.65978
Policy Loss                  -1309.1036
Q Predictions Mean           1306.706
Q Predictions Std            353.64362
Q Predictions Max            1700.8903
Q Predictions Min            55.10003
V Predictions Mean           1310.2755
V Predictions Std            354.058
V Predictions Max            1702.6699
V Predictions Min            51.26509
Log Pis Mean                 -0.27684388
Log Pis Std                  1.96803
Log Pis Max                  5.869832
Log Pis Min                  -5.0323405
Policy mu Mean               0.033066902
Policy mu Std                0.8897018
Policy mu Max                2.1838334
Policy mu Min                -2.6113796
Policy log std Mean          -0.52223325
Policy log std Std           0.18663374
Policy log std Max           0.14625132
Policy log std Min           -1.198287
Z mean eval                  0.032935336
Z variance eval              0.0030815585
total_rewards                [1922.4450446  1142.93577954  845.72243512 1418.642535   1114.63867734
  853.60960412  784.43269827 2297.11198763 2235.91357708  784.75626437]
total_rewards_mean           1340.0208603064432
total_rewards_std            570.2288980928115
total_rewards_max            2297.111987630504
total_rewards_min            784.4326982718947
Number of train steps total  1088000
Number of env steps total    1129296
Number of rollouts total     0
Train Time (s)               142.09035973995924
(Previous) Eval Time (s)     13.205946412403136
Sample Time (s)              10.715724091976881
Epoch Time (s)               166.01203024433926
Total Train Time (s)         45216.32366995001
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:04:06.171528 UTC | [2020_01_11_02_30_29] Iteration #271 | Epoch Duration: 166.09450030326843
2020-01-11 15:04:06.171747 UTC | [2020_01_11_02_30_29] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032924205
Z variance train             0.0030812514
KL Divergence                12.315702
KL Loss                      1.2315702
QF Loss                      185.52171
VF Loss                      40.423347
Policy Loss                  -1335.0314
Q Predictions Mean           1334.4711
Q Predictions Std            365.45575
Q Predictions Max            1728.2393
Q Predictions Min            4.2378798
V Predictions Mean           1336.3676
V Predictions Std            365.32846
V Predictions Max            1726.8534
V Predictions Min            -24.04073
Log Pis Mean                 -0.054825984
Log Pis Std                  1.9507192
Log Pis Max                  6.7218285
Log Pis Min                  -5.0965567
Policy mu Mean               0.07896206
Policy mu Std                0.94430995
Policy mu Max                2.2603023
Policy mu Min                -2.554668
Policy log std Mean          -0.5337876
Policy log std Std           0.18910265
Policy log std Max           0.25955355
Policy log std Min           -1.0943713
Z mean eval                  0.06018119
Z variance eval              0.0028388803
total_rewards                [1114.38122765 3313.71130899 3276.54278797 2437.46839408 3273.88242505
 3276.2432957  3319.38930559 3291.38496907 1277.19207968 1047.77835984]
total_rewards_mean           2562.797415361911
total_rewards_std            961.9201003020795
total_rewards_max            3319.389305588547
total_rewards_min            1047.7783598427507
Number of train steps total  1092000
Number of env steps total    1134390
Number of rollouts total     0
Train Time (s)               143.5779525297694
(Previous) Eval Time (s)     24.627240924164653
Sample Time (s)              9.807651777751744
Epoch Time (s)               178.0128452316858
Total Train Time (s)         45394.461189867
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:07:04.312912 UTC | [2020_01_11_02_30_29] Iteration #272 | Epoch Duration: 178.14093542099
2020-01-11 15:07:04.313189 UTC | [2020_01_11_02_30_29] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05985739
Z variance train             0.0028384705
KL Divergence                12.384109
KL Loss                      1.2384108
QF Loss                      96.24513
VF Loss                      49.925667
Policy Loss                  -1359.4911
Q Predictions Mean           1354.9523
Q Predictions Std            376.32977
Q Predictions Max            1756.4978
Q Predictions Min            40.129368
V Predictions Mean           1355.4497
V Predictions Std            376.2171
V Predictions Max            1762.5718
V Predictions Min            35.971222
Log Pis Mean                 0.05181808
Log Pis Std                  2.11808
Log Pis Max                  6.679846
Log Pis Min                  -6.366116
Policy mu Mean               0.068904676
Policy mu Std                0.9554836
Policy mu Max                2.523389
Policy mu Min                -2.603373
Policy log std Mean          -0.5310213
Policy log std Std           0.1940173
Policy log std Max           0.17804432
Policy log std Min           -1.0990939
Z mean eval                  0.038851656
Z variance eval              0.0024911698
total_rewards                [2930.60631333 3311.03568934 1834.0013888  3295.64582482 2966.94531156
 3289.8094519  3294.95996628 1849.56339752 3264.74156709 2373.47280494]
total_rewards_mean           2841.0781715578423
total_rewards_std            570.4532176835402
total_rewards_max            3311.0356893428475
total_rewards_min            1834.0013887994069
Number of train steps total  1096000
Number of env steps total    1139433
Number of rollouts total     0
Train Time (s)               143.415202380158
(Previous) Eval Time (s)     26.902997077908367
Sample Time (s)              10.20547162508592
Epoch Time (s)               180.5236710831523
Total Train Time (s)         45575.073440619744
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:10:04.927091 UTC | [2020_01_11_02_30_29] Iteration #273 | Epoch Duration: 180.61373448371887
2020-01-11 15:10:04.927273 UTC | [2020_01_11_02_30_29] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038808733
Z variance train             0.0024926
KL Divergence                12.612983
KL Loss                      1.2612983
QF Loss                      108.63223
VF Loss                      64.80874
Policy Loss                  -1377.7332
Q Predictions Mean           1374.8147
Q Predictions Std            319.9871
Q Predictions Max            1737.2485
Q Predictions Min            218.0821
V Predictions Mean           1372.7976
V Predictions Std            320.16464
V Predictions Max            1733.3643
V Predictions Min            202.45784
Log Pis Mean                 -0.007281024
Log Pis Std                  1.9724092
Log Pis Max                  6.3019524
Log Pis Min                  -6.2453556
Policy mu Mean               0.04492463
Policy mu Std                0.9557841
Policy mu Max                3.2569938
Policy mu Min                -2.560843
Policy log std Mean          -0.50983256
Policy log std Std           0.20249662
Policy log std Max           0.2677533
Policy log std Min           -1.1292651
Z mean eval                  0.047153164
Z variance eval              0.0024069755
total_rewards                [1267.32471615 1359.67851345  991.37442354  339.59071487 1080.15235483
 1073.22629472  856.67807836 3137.97189161 1070.96733746 1349.40606613]
total_rewards_mean           1252.6370391133
total_rewards_std            687.6891493143902
total_rewards_max            3137.9718916131487
total_rewards_min            339.59071487255835
Number of train steps total  1100000
Number of env steps total    1144486
Number of rollouts total     0
Train Time (s)               144.2001646249555
(Previous) Eval Time (s)     12.861963524017483
Sample Time (s)              9.06557166064158
Epoch Time (s)               166.12769980961457
Total Train Time (s)         45741.28231975017
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:12:51.139943 UTC | [2020_01_11_02_30_29] Iteration #274 | Epoch Duration: 166.21253538131714
2020-01-11 15:12:51.140146 UTC | [2020_01_11_02_30_29] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04729885
Z variance train             0.0024079487
KL Divergence                12.695342
KL Loss                      1.2695342
QF Loss                      81.49349
VF Loss                      37.34825
Policy Loss                  -1362.5004
Q Predictions Mean           1362.6826
Q Predictions Std            344.20483
Q Predictions Max            1717.6018
Q Predictions Min            67.399605
V Predictions Mean           1364.8665
V Predictions Std            343.81592
V Predictions Max            1712.7891
V Predictions Min            75.93149
Log Pis Mean                 -0.15078095
Log Pis Std                  1.7794331
Log Pis Max                  6.8303604
Log Pis Min                  -4.8021054
Policy mu Mean               0.057084512
Policy mu Std                0.8895285
Policy mu Max                2.0131788
Policy mu Min                -2.5814686
Policy log std Mean          -0.5082431
Policy log std Std           0.18631215
Policy log std Max           0.08709055
Policy log std Min           -1.1204557
Z mean eval                  0.036429357
Z variance eval              0.0028748568
total_rewards                [ 939.62803567 3287.80796388 1628.14624258 3322.7778472  3294.50211036
 2334.48947247 3291.439056   1400.22413348 1966.86977789 1620.43966746]
total_rewards_mean           2308.632430699933
total_rewards_std            876.2786791721506
total_rewards_max            3322.7778471982374
total_rewards_min            939.6280356733322
Number of train steps total  1104000
Number of env steps total    1149590
Number of rollouts total     0
Train Time (s)               141.830686846748
(Previous) Eval Time (s)     21.682315838057548
Sample Time (s)              9.761515880934894
Epoch Time (s)               173.27451856574044
Total Train Time (s)         45914.66369291721
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:15:44.524747 UTC | [2020_01_11_02_30_29] Iteration #275 | Epoch Duration: 173.3844494819641
2020-01-11 15:15:44.524953 UTC | [2020_01_11_02_30_29] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036397427
Z variance train             0.0028743162
KL Divergence                12.297007
KL Loss                      1.2297007
QF Loss                      69.93375
VF Loss                      84.23111
Policy Loss                  -1328.4248
Q Predictions Mean           1327.7103
Q Predictions Std            364.10443
Q Predictions Max            1739.6558
Q Predictions Min            18.579252
V Predictions Mean           1326.1042
V Predictions Std            363.60287
V Predictions Max            1739.1581
V Predictions Min            26.672867
Log Pis Mean                 0.047732197
Log Pis Std                  1.9834414
Log Pis Max                  5.615556
Log Pis Min                  -5.060755
Policy mu Mean               0.03997751
Policy mu Std                0.94815123
Policy mu Max                2.2211077
Policy mu Min                -2.7422867
Policy log std Mean          -0.5392618
Policy log std Std           0.18293574
Policy log std Max           0.15893185
Policy log std Min           -1.1196587
Z mean eval                  0.031101042
Z variance eval              0.0026660997
total_rewards                [1060.39104828 1143.18509055 2543.45463695 1699.86896243 1905.25766015
 1502.27355898 2347.69770659 1742.37651488 1248.48240238 1446.44349403]
total_rewards_mean           1663.9431075221469
total_rewards_std            467.787428718646
total_rewards_max            2543.454636953469
total_rewards_min            1060.3910482800156
Number of train steps total  1108000
Number of env steps total    1154761
Number of rollouts total     0
Train Time (s)               142.21243581129238
(Previous) Eval Time (s)     15.095734552945942
Sample Time (s)              10.838967555668205
Epoch Time (s)               168.14713791990653
Total Train Time (s)         46082.907022844534
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:18:32.771546 UTC | [2020_01_11_02_30_29] Iteration #276 | Epoch Duration: 168.24644351005554
2020-01-11 15:18:32.771742 UTC | [2020_01_11_02_30_29] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031190539
Z variance train             0.0026669255
KL Divergence                12.465995
KL Loss                      1.2465996
QF Loss                      185.28093
VF Loss                      66.60233
Policy Loss                  -1360.919
Q Predictions Mean           1359.8813
Q Predictions Std            350.209
Q Predictions Max            1749.0093
Q Predictions Min            83.295296
V Predictions Mean           1362.5513
V Predictions Std            348.84058
V Predictions Max            1744.7339
V Predictions Min            79.515686
Log Pis Mean                 0.36116335
Log Pis Std                  2.225477
Log Pis Max                  7.804285
Log Pis Min                  -5.791614
Policy mu Mean               -0.031152489
Policy mu Std                0.97634983
Policy mu Max                2.3791192
Policy mu Min                -2.6854181
Policy log std Mean          -0.5291119
Policy log std Std           0.19136822
Policy log std Max           0.1042884
Policy log std Min           -1.2258167
Z mean eval                  0.028848518
Z variance eval              0.0031514328
total_rewards                [1165.67081744 1691.80402075 1587.60256802 1633.08011132  857.45524085
 2682.49262771 2198.36255217 1359.17164231  760.09865274 1532.73081733]
total_rewards_mean           1546.8469050634244
total_rewards_std            549.474636201479
total_rewards_max            2682.492627710527
total_rewards_min            760.0986527406999
Number of train steps total  1112000
Number of env steps total    1159800
Number of rollouts total     0
Train Time (s)               141.47805378073826
(Previous) Eval Time (s)     15.115723965223879
Sample Time (s)              10.14615532476455
Epoch Time (s)               166.7399330707267
Total Train Time (s)         46249.72816098202
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:21:19.596146 UTC | [2020_01_11_02_30_29] Iteration #277 | Epoch Duration: 166.82425212860107
2020-01-11 15:21:19.596353 UTC | [2020_01_11_02_30_29] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028281879
Z variance train             0.003153165
KL Divergence                12.146885
KL Loss                      1.2146885
QF Loss                      97.25697
VF Loss                      37.374374
Policy Loss                  -1345.4902
Q Predictions Mean           1345.4991
Q Predictions Std            377.65463
Q Predictions Max            1744.6752
Q Predictions Min            35.090267
V Predictions Mean           1346.5762
V Predictions Std            376.21
V Predictions Max            1746.4258
V Predictions Min            41.966026
Log Pis Mean                 -0.05753886
Log Pis Std                  1.8525913
Log Pis Max                  5.5376625
Log Pis Min                  -4.36992
Policy mu Mean               0.033190478
Policy mu Std                0.92045313
Policy mu Max                2.2985806
Policy mu Min                -2.6754582
Policy log std Mean          -0.52768594
Policy log std Std           0.19041075
Policy log std Max           0.20755708
Policy log std Min           -1.1138909
Z mean eval                  0.023654992
Z variance eval              0.0035389296
total_rewards                [1949.84089648 1828.6466239  1656.85711199  778.09883212  823.32381952
 1091.42536335 2879.08713583 1162.18166987 1085.39174289 1557.41587832]
total_rewards_mean           1481.2269074256292
total_rewards_std            605.6904840353264
total_rewards_max            2879.087135825398
total_rewards_min            778.0988321243764
Number of train steps total  1116000
Number of env steps total    1164864
Number of rollouts total     0
Train Time (s)               141.99527284596115
(Previous) Eval Time (s)     13.972372692078352
Sample Time (s)              9.142312528565526
Epoch Time (s)               165.10995806660503
Total Train Time (s)         46414.91580909584
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:24:04.786735 UTC | [2020_01_11_02_30_29] Iteration #278 | Epoch Duration: 165.19023537635803
2020-01-11 15:24:04.786924 UTC | [2020_01_11_02_30_29] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023225583
Z variance train             0.003537964
KL Divergence                11.783401
KL Loss                      1.1783401
QF Loss                      107.43323
VF Loss                      93.57498
Policy Loss                  -1352.4758
Q Predictions Mean           1355.6921
Q Predictions Std            382.68253
Q Predictions Max            1771.8245
Q Predictions Min            36.617275
V Predictions Mean           1357.0286
V Predictions Std            384.24844
V Predictions Max            1772.6047
V Predictions Min            29.394886
Log Pis Mean                 -0.037802078
Log Pis Std                  1.9715143
Log Pis Max                  6.2274113
Log Pis Min                  -4.3391814
Policy mu Mean               0.03338963
Policy mu Std                0.9249382
Policy mu Max                2.3320594
Policy mu Min                -2.704485
Policy log std Mean          -0.532397
Policy log std Std           0.20590721
Policy log std Max           0.10493386
Policy log std Min           -1.2234569
Z mean eval                  0.03045787
Z variance eval              0.0037462537
total_rewards                [2027.85289522 1083.13397041 1382.34982331  901.2359841  1609.79818162
 1104.95209944 1113.36505533 1083.82992433 2427.30779323  893.65094535]
total_rewards_mean           1362.7476672337366
total_rewards_std            485.2571858437705
total_rewards_max            2427.307793227259
total_rewards_min            893.6509453503745
Number of train steps total  1120000
Number of env steps total    1169798
Number of rollouts total     0
Train Time (s)               143.09670045925304
(Previous) Eval Time (s)     13.428982861805707
Sample Time (s)              9.753989458549768
Epoch Time (s)               166.27967277960852
Total Train Time (s)         46581.28718347009
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:26:51.163371 UTC | [2020_01_11_02_30_29] Iteration #279 | Epoch Duration: 166.37628555297852
2020-01-11 15:26:51.163636 UTC | [2020_01_11_02_30_29] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03055441
Z variance train             0.0037434988
KL Divergence                11.579932
KL Loss                      1.1579932
QF Loss                      128.79874
VF Loss                      38.10032
Policy Loss                  -1345.476
Q Predictions Mean           1347.786
Q Predictions Std            349.349
Q Predictions Max            1747.1802
Q Predictions Min            49.377193
V Predictions Mean           1348.4583
V Predictions Std            348.67175
V Predictions Max            1747.2697
V Predictions Min            52.83125
Log Pis Mean                 -0.1028617
Log Pis Std                  2.0179408
Log Pis Max                  5.4308414
Log Pis Min                  -5.234357
Policy mu Mean               -0.03838532
Policy mu Std                0.9082532
Policy mu Max                2.1698487
Policy mu Min                -2.5894516
Policy log std Mean          -0.51525426
Policy log std Std           0.19380768
Policy log std Max           0.21700406
Policy log std Min           -1.1258852
Z mean eval                  0.018065615
Z variance eval              0.0034381605
total_rewards                [3400.18093156 2199.97168957 2321.86489261 1249.27440337 3360.30226631
 1230.45164487 3372.27915751 1910.85312483 2043.86766488 2063.55377553]
total_rewards_mean           2315.25995510504
total_rewards_std            775.4663427799774
total_rewards_max            3400.180931558054
total_rewards_min            1230.4516448696888
Number of train steps total  1124000
Number of env steps total    1175593
Number of rollouts total     0
Train Time (s)               142.4367312900722
(Previous) Eval Time (s)     21.029554908163846
Sample Time (s)              10.54914656933397
Epoch Time (s)               174.01543276757002
Total Train Time (s)         46755.394154130016
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:29:45.272563 UTC | [2020_01_11_02_30_29] Iteration #280 | Epoch Duration: 174.10873913764954
2020-01-11 15:29:45.272745 UTC | [2020_01_11_02_30_29] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018076923
Z variance train             0.0034389202
KL Divergence                11.723156
KL Loss                      1.1723156
QF Loss                      87.43439
VF Loss                      36.723293
Policy Loss                  -1362.6403
Q Predictions Mean           1363.748
Q Predictions Std            353.0466
Q Predictions Max            1751.7738
Q Predictions Min            9.889019
V Predictions Mean           1364.4171
V Predictions Std            353.892
V Predictions Max            1756.9021
V Predictions Min            -1.3801752
Log Pis Mean                 -0.05550437
Log Pis Std                  1.9438195
Log Pis Max                  6.95627
Log Pis Min                  -6.0248156
Policy mu Mean               -0.022576734
Policy mu Std                0.9093527
Policy mu Max                2.4694839
Policy mu Min                -2.4953322
Policy log std Mean          -0.530335
Policy log std Std           0.20474628
Policy log std Max           0.09174621
Policy log std Min           -1.1359142
Z mean eval                  0.03328704
Z variance eval              0.003046318
total_rewards                [3360.4765995  3338.96758038 3369.24834111  834.39333092 3352.29867187
 3320.17657328 3331.59132868 3361.17089504 3324.25042607 3334.48322504]
total_rewards_mean           3092.7056971881398
total_rewards_std            752.9367505043246
total_rewards_max            3369.248341105901
total_rewards_min            834.3933309186201
Number of train steps total  1128000
Number of env steps total    1180848
Number of rollouts total     0
Train Time (s)               144.71628722827882
(Previous) Eval Time (s)     28.986735132988542
Sample Time (s)              10.113402585033327
Epoch Time (s)               183.81642494630069
Total Train Time (s)         46939.306652219035
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:32:49.188948 UTC | [2020_01_11_02_30_29] Iteration #281 | Epoch Duration: 183.91604828834534
2020-01-11 15:32:49.189161 UTC | [2020_01_11_02_30_29] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033339955
Z variance train             0.0030467852
KL Divergence                12.102297
KL Loss                      1.2102298
QF Loss                      93.68474
VF Loss                      30.089388
Policy Loss                  -1347.786
Q Predictions Mean           1345.4202
Q Predictions Std            388.53522
Q Predictions Max            1762.6772
Q Predictions Min            28.679068
V Predictions Mean           1347.5026
V Predictions Std            387.77408
V Predictions Max            1751.7482
V Predictions Min            27.066402
Log Pis Mean                 0.046587057
Log Pis Std                  2.0126145
Log Pis Max                  6.569522
Log Pis Min                  -5.0074997
Policy mu Mean               -0.03234587
Policy mu Std                0.9348191
Policy mu Max                2.3092225
Policy mu Min                -2.7070575
Policy log std Mean          -0.53540015
Policy log std Std           0.19856513
Policy log std Max           0.029942453
Policy log std Min           -1.1443231
Z mean eval                  0.059547402
Z variance eval              0.0030115296
total_rewards                [1376.49263344  817.09078572  874.43764392 2006.99665959 1374.14614565
 1763.11776055  845.12530679  832.50428979  859.68654678 1603.89698802]
total_rewards_mean           1235.3494760259991
total_rewards_std            425.425831177761
total_rewards_max            2006.9966595921937
total_rewards_min            817.0907857234915
Number of train steps total  1132000
Number of env steps total    1186128
Number of rollouts total     0
Train Time (s)               152.52251073392108
(Previous) Eval Time (s)     12.712576230987906
Sample Time (s)              10.687407194636762
Epoch Time (s)               175.92249415954575
Total Train Time (s)         47115.31871987553
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:35:45.204219 UTC | [2020_01_11_02_30_29] Iteration #282 | Epoch Duration: 176.01489663124084
2020-01-11 15:35:45.204437 UTC | [2020_01_11_02_30_29] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0596176
Z variance train             0.0030122579
KL Divergence                12.102118
KL Loss                      1.2102118
QF Loss                      112.30866
VF Loss                      40.804585
Policy Loss                  -1361.1176
Q Predictions Mean           1363.0148
Q Predictions Std            369.53394
Q Predictions Max            1722.8749
Q Predictions Min            58.27231
V Predictions Mean           1357.4768
V Predictions Std            367.61838
V Predictions Max            1712.4543
V Predictions Min            55.059116
Log Pis Mean                 -0.114772916
Log Pis Std                  1.8857498
Log Pis Max                  5.4537935
Log Pis Min                  -4.693456
Policy mu Mean               0.004484696
Policy mu Std                0.8707674
Policy mu Max                2.3239887
Policy mu Min                -2.4790792
Policy log std Mean          -0.50306445
Policy log std Std           0.20114817
Policy log std Max           0.17728215
Policy log std Min           -1.1305332
Z mean eval                  0.04758291
Z variance eval              0.0027855942
total_rewards                [2706.68407751 1051.34492711 3370.90363171   70.68258147 1477.46392974
 1145.58488785 2151.64736102 1663.21345182 1178.41735392 1604.51098523]
total_rewards_mean           1642.0453187393007
total_rewards_std            876.9593262021315
total_rewards_max            3370.903631713651
total_rewards_min            70.68258146828433
Number of train steps total  1136000
Number of env steps total    1191491
Number of rollouts total     0
Train Time (s)               151.22182288113981
(Previous) Eval Time (s)     16.251691416837275
Sample Time (s)              10.507927571423352
Epoch Time (s)               177.98144186940044
Total Train Time (s)         47293.38187580928
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:38:43.270602 UTC | [2020_01_11_02_30_29] Iteration #283 | Epoch Duration: 178.0660240650177
2020-01-11 15:38:43.270783 UTC | [2020_01_11_02_30_29] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04789424
Z variance train             0.002784654
KL Divergence                12.3803215
KL Loss                      1.2380322
QF Loss                      81.95989
VF Loss                      47.225636
Policy Loss                  -1440.5446
Q Predictions Mean           1439.3748
Q Predictions Std            294.40796
Q Predictions Max            1771.6599
Q Predictions Min            232.9797
V Predictions Mean           1437.5669
V Predictions Std            293.8162
V Predictions Max            1766.0582
V Predictions Min            217.7386
Log Pis Mean                 -0.07599585
Log Pis Std                  1.9933616
Log Pis Max                  6.5400896
Log Pis Min                  -5.2066746
Policy mu Mean               0.03437152
Policy mu Std                0.8783099
Policy mu Max                2.4079056
Policy mu Min                -2.531675
Policy log std Mean          -0.5207751
Policy log std Std           0.20144103
Policy log std Max           0.22346222
Policy log std Min           -1.28777
Z mean eval                  0.049123548
Z variance eval              0.0027682285
total_rewards                [3372.10423243 3346.07989931 3355.97759454 1708.4169979  1957.37021024
 3003.84436611 3369.01513969 3364.94084581 3362.51137977 2043.21223611]
total_rewards_mean           2888.347290191966
total_rewards_std            658.1625374499462
total_rewards_max            3372.104232425541
total_rewards_min            1708.416997902733
Number of train steps total  1140000
Number of env steps total    1197075
Number of rollouts total     0
Train Time (s)               151.43269694643095
(Previous) Eval Time (s)     28.691148487851024
Sample Time (s)              10.395057062152773
Epoch Time (s)               190.51890249643475
Total Train Time (s)         47483.991899094544
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:41:53.884294 UTC | [2020_01_11_02_30_29] Iteration #284 | Epoch Duration: 190.61336541175842
2020-01-11 15:41:53.884493 UTC | [2020_01_11_02_30_29] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0490197
Z variance train             0.0027687564
KL Divergence                12.45969
KL Loss                      1.245969
QF Loss                      110.65782
VF Loss                      21.78322
Policy Loss                  -1384.9077
Q Predictions Mean           1385.7682
Q Predictions Std            325.05923
Q Predictions Max            1738.5604
Q Predictions Min            96.3755
V Predictions Mean           1386.2078
V Predictions Std            323.8971
V Predictions Max            1744.3442
V Predictions Min            108.56471
Log Pis Mean                 0.03185484
Log Pis Std                  2.0498421
Log Pis Max                  7.176211
Log Pis Min                  -4.3938646
Policy mu Mean               -0.11407576
Policy mu Std                0.904544
Policy mu Max                2.161618
Policy mu Min                -2.7061884
Policy log std Mean          -0.51081145
Policy log std Std           0.19567941
Policy log std Max           0.08861512
Policy log std Min           -1.107048
Z mean eval                  0.026907038
Z variance eval              0.0030173871
total_rewards                [1089.48455352 2215.97201751  952.25007828 1971.33006419 3388.46144393
 1474.79921182 1192.77677465  891.61403486  914.64225442 2738.96836024]
total_rewards_mean           1683.0298793430707
total_rewards_std            823.2526396047986
total_rewards_max            3388.4614439256134
total_rewards_min            891.6140348639638
Number of train steps total  1144000
Number of env steps total    1202283
Number of rollouts total     0
Train Time (s)               152.0816243593581
(Previous) Eval Time (s)     16.44772385712713
Sample Time (s)              10.594463290181011
Epoch Time (s)               179.12381150666624
Total Train Time (s)         47663.2165268329
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:44:53.113546 UTC | [2020_01_11_02_30_29] Iteration #285 | Epoch Duration: 179.22887992858887
2020-01-11 15:44:53.113841 UTC | [2020_01_11_02_30_29] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027091399
Z variance train             0.003017967
KL Divergence                12.273922
KL Loss                      1.2273922
QF Loss                      86.73009
VF Loss                      34.813797
Policy Loss                  -1412.3834
Q Predictions Mean           1413.8999
Q Predictions Std            321.144
Q Predictions Max            1761.9786
Q Predictions Min            197.87411
V Predictions Mean           1410.7927
V Predictions Std            321.355
V Predictions Max            1762.95
V Predictions Min            191.3973
Log Pis Mean                 -0.04938564
Log Pis Std                  1.9957578
Log Pis Max                  6.6488743
Log Pis Min                  -5.9189506
Policy mu Mean               -0.068714194
Policy mu Std                0.90109855
Policy mu Max                2.5528975
Policy mu Min                -2.662429
Policy log std Mean          -0.5054601
Policy log std Std           0.19857068
Policy log std Max           0.16113484
Policy log std Min           -1.2493231
Z mean eval                  0.005458104
Z variance eval              0.0042011226
total_rewards                [1356.39431712 1755.42749756 1118.35253396 1154.76643718 1444.76207027
 1243.8511912  3360.18255317 2079.86787012 1158.79703332 1935.66263522]
total_rewards_mean           1660.8064139116445
total_rewards_std            652.957156910954
total_rewards_max            3360.18255317329
total_rewards_min            1118.3525339560551
Number of train steps total  1148000
Number of env steps total    1207592
Number of rollouts total     0
Train Time (s)               146.71765728434548
(Previous) Eval Time (s)     16.17692581610754
Sample Time (s)              10.57354844873771
Epoch Time (s)               173.46813154919073
Total Train Time (s)         47836.765679992735
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:47:46.665577 UTC | [2020_01_11_02_30_29] Iteration #286 | Epoch Duration: 173.5515673160553
2020-01-11 15:47:46.665762 UTC | [2020_01_11_02_30_29] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.006408991
Z variance train             0.0042032762
KL Divergence                11.429247
KL Loss                      1.1429247
QF Loss                      111.40334
VF Loss                      62.760963
Policy Loss                  -1340.0399
Q Predictions Mean           1340.343
Q Predictions Std            390.95673
Q Predictions Max            1732.5962
Q Predictions Min            49.17972
V Predictions Mean           1334.6588
V Predictions Std            390.08286
V Predictions Max            1724.117
V Predictions Min            40.35471
Log Pis Mean                 -0.1272389
Log Pis Std                  2.1416638
Log Pis Max                  5.74156
Log Pis Min                  -9.5218935
Policy mu Mean               -0.086779356
Policy mu Std                0.9246824
Policy mu Max                2.6629658
Policy mu Min                -2.6624036
Policy log std Mean          -0.5012374
Policy log std Std           0.1919958
Policy log std Max           0.011441469
Policy log std Min           -1.0686549
Z mean eval                  0.04013046
Z variance eval              0.004601716
total_rewards                [1460.6211431  1858.97243749 1105.74192429 1387.17863083 1175.39855373
 2598.09283834  840.89341883 1107.00643776 3355.71833503 1354.44678849]
total_rewards_mean           1624.407050789711
total_rewards_std            742.2078237387858
total_rewards_max            3355.718335032761
total_rewards_min            840.8934188290159
Number of train steps total  1152000
Number of env steps total    1213339
Number of rollouts total     0
Train Time (s)               144.04432414099574
(Previous) Eval Time (s)     14.736106740310788
Sample Time (s)              9.122434684075415
Epoch Time (s)               167.90286556538194
Total Train Time (s)         48004.74854049366
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:50:34.651839 UTC | [2020_01_11_02_30_29] Iteration #287 | Epoch Duration: 167.98592019081116
2020-01-11 15:50:34.652050 UTC | [2020_01_11_02_30_29] Iteration #287 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040081725
Z variance train             0.004601596
KL Divergence                11.188635
KL Loss                      1.1188635
QF Loss                      212.64413
VF Loss                      25.41802
Policy Loss                  -1398.1605
Q Predictions Mean           1397.9742
Q Predictions Std            357.52243
Q Predictions Max            1746.0729
Q Predictions Min            8.012371
V Predictions Mean           1397.2896
V Predictions Std            355.9474
V Predictions Max            1738.8239
V Predictions Min            15.024559
Log Pis Mean                 0.019845873
Log Pis Std                  1.9586974
Log Pis Max                  5.4540896
Log Pis Min                  -4.4145074
Policy mu Mean               -0.0059425044
Policy mu Std                0.9135249
Policy mu Max                2.1909585
Policy mu Min                -2.5365481
Policy log std Mean          -0.5005416
Policy log std Std           0.2007989
Policy log std Max           0.34329814
Policy log std Min           -1.1404426
Z mean eval                  0.03660301
Z variance eval              0.004301358
total_rewards                [1226.37923595 1279.29442775 1946.27990986 1514.58252869 1168.6742018
  452.44805377 1089.21062149 3395.0041169   838.7704525   786.84808003]
total_rewards_mean           1369.7491628740922
total_rewards_std            778.8482157083506
total_rewards_max            3395.004116899661
total_rewards_min            452.44805377167546
Number of train steps total  1156000
Number of env steps total    1218821
Number of rollouts total     0
Train Time (s)               144.24367749504745
(Previous) Eval Time (s)     13.666397787630558
Sample Time (s)              9.985891301184893
Epoch Time (s)               167.8959665838629
Total Train Time (s)         48172.73548045941
Epoch                        288
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:53:22.642361 UTC | [2020_01_11_02_30_29] Iteration #288 | Epoch Duration: 167.99015307426453
2020-01-11 15:53:22.642579 UTC | [2020_01_11_02_30_29] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03674539
Z variance train             0.004302577
KL Divergence                11.463962
KL Loss                      1.1463962
QF Loss                      89.52772
VF Loss                      54.214653
Policy Loss                  -1387.2664
Q Predictions Mean           1386.7549
Q Predictions Std            340.5335
Q Predictions Max            1765.1617
Q Predictions Min            82.49935
V Predictions Mean           1382.8298
V Predictions Std            340.25378
V Predictions Max            1758.9156
V Predictions Min            84.186264
Log Pis Mean                 -0.027447987
Log Pis Std                  1.9649196
Log Pis Max                  6.1642294
Log Pis Min                  -4.7738814
Policy mu Mean               -0.09774294
Policy mu Std                0.90043086
Policy mu Max                2.2142267
Policy mu Min                -2.868093
Policy log std Mean          -0.51691467
Policy log std Std           0.20022681
Policy log std Max           0.17544037
Policy log std Min           -1.2496849
Z mean eval                  0.055515528
Z variance eval              0.004178194
total_rewards                [ 936.94077868 1151.18586287 1092.29776257 1513.33947957  901.03471388
 1476.10576694 1109.58540337  871.11392525  858.67847314 1696.89126343]
total_rewards_mean           1160.7173429709703
total_rewards_std            284.8315120461201
total_rewards_max            1696.8912634328444
total_rewards_min            858.6784731367942
Number of train steps total  1160000
Number of env steps total    1224260
Number of rollouts total     0
Train Time (s)               143.99121302179992
(Previous) Eval Time (s)     11.725776004139334
Sample Time (s)              9.554550624918193
Epoch Time (s)               165.27153965085745
Total Train Time (s)         48338.13232945604
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:56:08.042366 UTC | [2020_01_11_02_30_29] Iteration #289 | Epoch Duration: 165.3996319770813
2020-01-11 15:56:08.042548 UTC | [2020_01_11_02_30_29] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055532373
Z variance train             0.0041792262
KL Divergence                11.499882
KL Loss                      1.1499882
QF Loss                      82.364975
VF Loss                      34.45837
Policy Loss                  -1393.0529
Q Predictions Mean           1390.6113
Q Predictions Std            335.7866
Q Predictions Max            1731.6274
Q Predictions Min            142.1878
V Predictions Mean           1390.969
V Predictions Std            334.15384
V Predictions Max            1727.6816
V Predictions Min            142.00311
Log Pis Mean                 -0.10971096
Log Pis Std                  1.9964192
Log Pis Max                  6.0341864
Log Pis Min                  -5.679167
Policy mu Mean               -0.045082647
Policy mu Std                0.8888097
Policy mu Max                2.2402706
Policy mu Min                -2.6737082
Policy log std Mean          -0.5109889
Policy log std Std           0.18864298
Policy log std Max           0.06225717
Policy log std Min           -1.1371238
Z mean eval                  0.04685577
Z variance eval              0.004048293
total_rewards                [2534.20780466  903.32562275 2453.95797384 1949.92198475 2474.76631584
 2133.63412484 1466.94979445 2248.7522662  1400.57593338 1906.07017618]
total_rewards_mean           1947.216199689489
total_rewards_std            512.4656467671394
total_rewards_max            2534.2078046635597
total_rewards_min            903.3256227455187
Number of train steps total  1164000
Number of env steps total    1229660
Number of rollouts total     0
Train Time (s)               142.35723510198295
(Previous) Eval Time (s)     18.873411695938557
Sample Time (s)              9.43667700747028
Epoch Time (s)               170.6673238053918
Total Train Time (s)         48508.88160806941
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:58:58.795406 UTC | [2020_01_11_02_30_29] Iteration #290 | Epoch Duration: 170.75271248817444
2020-01-11 15:58:58.795614 UTC | [2020_01_11_02_30_29] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046978865
Z variance train             0.004052791
KL Divergence                11.555088
KL Loss                      1.1555089
QF Loss                      87.377396
VF Loss                      28.357292
Policy Loss                  -1415.3395
Q Predictions Mean           1412.4082
Q Predictions Std            336.16077
Q Predictions Max            1762.5392
Q Predictions Min            32.983475
V Predictions Mean           1415.0122
V Predictions Std            334.1876
V Predictions Max            1753.2529
V Predictions Min            43.849743
Log Pis Mean                 -0.0068703517
Log Pis Std                  1.9464339
Log Pis Max                  6.1704016
Log Pis Min                  -4.1995606
Policy mu Mean               0.032169346
Policy mu Std                0.90977055
Policy mu Max                2.4743552
Policy mu Min                -2.4967701
Policy log std Mean          -0.5082479
Policy log std Std           0.20282204
Policy log std Max           0.1839642
Policy log std Min           -1.0723749
Z mean eval                  0.028337926
Z variance eval              0.0039785537
total_rewards                [1397.00314615 1310.99892046 1130.56509048 1209.16312206  922.44765976
 1977.40869763 1066.33389663 1341.33617165 1312.37091931 1120.08704268]
total_rewards_mean           1278.7714666825973
total_rewards_std            270.599733806411
total_rewards_max            1977.4086976344306
total_rewards_min            922.4476597608702
Number of train steps total  1168000
Number of env steps total    1235167
Number of rollouts total     0
Train Time (s)               142.5546905384399
(Previous) Eval Time (s)     12.565720071084797
Sample Time (s)              9.355638279113919
Epoch Time (s)               164.47604888863862
Total Train Time (s)         48673.445979693905
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:01:43.363211 UTC | [2020_01_11_02_30_29] Iteration #291 | Epoch Duration: 164.56743121147156
2020-01-11 16:01:43.363405 UTC | [2020_01_11_02_30_29] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027805645
Z variance train             0.0039808024
KL Divergence                11.47587
KL Loss                      1.1475871
QF Loss                      132.82056
VF Loss                      22.94638
Policy Loss                  -1410.4865
Q Predictions Mean           1411.5043
Q Predictions Std            331.85217
Q Predictions Max            1798.2593
Q Predictions Min            91.79095
V Predictions Mean           1411.1694
V Predictions Std            330.30908
V Predictions Max            1789.4385
V Predictions Min            102.48607
Log Pis Mean                 -0.20119813
Log Pis Std                  1.8709614
Log Pis Max                  5.6298738
Log Pis Min                  -5.845277
Policy mu Mean               0.007720489
Policy mu Std                0.8750004
Policy mu Max                2.5876322
Policy mu Min                -2.7375958
Policy log std Mean          -0.49489722
Policy log std Std           0.18126571
Policy log std Max           0.008902788
Policy log std Min           -1.0076417
Z mean eval                  0.053502522
Z variance eval              0.0038948997
total_rewards                [2497.0407317  1192.5243852  3403.54800843 1108.00480783 1570.01610977
 2058.87462984 1948.95076331  473.41271783 3401.53321468  819.90370156]
total_rewards_mean           1847.38090701551
total_rewards_std            964.888214501995
total_rewards_max            3403.548008432098
total_rewards_min            473.41271783496103
Number of train steps total  1172000
Number of env steps total    1240573
Number of rollouts total     0
Train Time (s)               143.87056172499433
(Previous) Eval Time (s)     18.164715397171676
Sample Time (s)              9.811373425181955
Epoch Time (s)               171.84665054734796
Total Train Time (s)         48845.38785388181
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:04:35.308563 UTC | [2020_01_11_02_30_29] Iteration #292 | Epoch Duration: 171.94501519203186
2020-01-11 16:04:35.308749 UTC | [2020_01_11_02_30_29] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05348549
Z variance train             0.003895574
KL Divergence                11.582305
KL Loss                      1.1582305
QF Loss                      91.86542
VF Loss                      33.2857
Policy Loss                  -1374.9083
Q Predictions Mean           1374.8961
Q Predictions Std            389.53235
Q Predictions Max            1774.9934
Q Predictions Min            10.26672
V Predictions Mean           1374.141
V Predictions Std            389.86188
V Predictions Max            1767.845
V Predictions Min            14.671339
Log Pis Mean                 -0.008475259
Log Pis Std                  1.9857329
Log Pis Max                  6.473583
Log Pis Min                  -4.889684
Policy mu Mean               -0.025939995
Policy mu Std                0.90400285
Policy mu Max                2.3057926
Policy mu Min                -2.511519
Policy log std Mean          -0.53549653
Policy log std Std           0.19541551
Policy log std Max           0.06590873
Policy log std Min           -1.0710326
Z mean eval                  0.052427985
Z variance eval              0.0039466736
total_rewards                [3337.95587273 3366.94178343 3387.5402309  2538.33141451 1788.06090475
  890.37734856 1934.36233369 3387.98365391 1450.19373477 3349.36040222]
total_rewards_mean           2543.1107679477527
total_rewards_std            908.5196342442658
total_rewards_max            3387.9836539081857
total_rewards_min            890.3773485648558
Number of train steps total  1176000
Number of env steps total    1246063
Number of rollouts total     0
Train Time (s)               144.67756109591573
(Previous) Eval Time (s)     24.948487584013492
Sample Time (s)              10.184872835874557
Epoch Time (s)               179.81092151580378
Total Train Time (s)         49025.27621806087
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:07:35.199985 UTC | [2020_01_11_02_30_29] Iteration #293 | Epoch Duration: 179.89109182357788
2020-01-11 16:07:35.200172 UTC | [2020_01_11_02_30_29] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05228842
Z variance train             0.003945337
KL Divergence                11.564423
KL Loss                      1.1564423
QF Loss                      160.68971
VF Loss                      41.58558
Policy Loss                  -1443.2164
Q Predictions Mean           1443.717
Q Predictions Std            320.38434
Q Predictions Max            1768.9619
Q Predictions Min            39.387295
V Predictions Mean           1438.524
V Predictions Std            320.6209
V Predictions Max            1762.3375
V Predictions Min            37.237103
Log Pis Mean                 -0.11122215
Log Pis Std                  1.9643352
Log Pis Max                  5.322358
Log Pis Min                  -5.951763
Policy mu Mean               -0.006122274
Policy mu Std                0.9060196
Policy mu Max                3.393362
Policy mu Min                -2.556441
Policy log std Mean          -0.51265055
Policy log std Std           0.20351651
Policy log std Max           0.018381953
Policy log std Min           -1.1905944
Z mean eval                  0.024629828
Z variance eval              0.0040402035
total_rewards                [1110.92563547 1138.36101729 1135.45359707 1075.0003732   320.38437897
 1015.47632783  562.59731979 1065.014674   1083.85665403  569.56792284]
total_rewards_mean           907.6637900485148
total_rewards_std            286.37909787612455
total_rewards_max            1138.3610172939366
total_rewards_min            320.38437897014757
Number of train steps total  1180000
Number of env steps total    1251376
Number of rollouts total     0
Train Time (s)               143.27193023776636
(Previous) Eval Time (s)     9.522991081234068
Sample Time (s)              10.155828779097646
Epoch Time (s)               162.95075009809807
Total Train Time (s)         49188.306855805684
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:10:18.234272 UTC | [2020_01_11_02_30_29] Iteration #294 | Epoch Duration: 163.03395009040833
2020-01-11 16:10:18.234473 UTC | [2020_01_11_02_30_29] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024654869
Z variance train             0.0040405085
KL Divergence                11.454036
KL Loss                      1.1454036
QF Loss                      64.46774
VF Loss                      19.523758
Policy Loss                  -1399.8726
Q Predictions Mean           1398.6973
Q Predictions Std            339.9736
Q Predictions Max            1764.6334
Q Predictions Min            59.642056
V Predictions Mean           1400.5781
V Predictions Std            339.2795
V Predictions Max            1766.6086
V Predictions Min            64.63959
Log Pis Mean                 -0.031752184
Log Pis Std                  2.0166597
Log Pis Max                  6.464761
Log Pis Min                  -4.9555445
Policy mu Mean               -0.014912258
Policy mu Std                0.91468555
Policy mu Max                2.1363366
Policy mu Min                -2.5296814
Policy log std Mean          -0.5297932
Policy log std Std           0.18919075
Policy log std Max           0.074929476
Policy log std Min           -1.1645697
Z mean eval                  0.042292297
Z variance eval              0.0037288163
total_rewards                [1295.79667616 1151.02994946 1000.13626748 3394.27896051 2712.15486764
 3383.9722003  2673.72633663 1023.21704932  848.03231202  331.15471188]
total_rewards_mean           1781.3499331406358
total_rewards_std            1078.1903876370554
total_rewards_max            3394.2789605094686
total_rewards_min            331.15471187706976
Number of train steps total  1184000
Number of env steps total    1256782
Number of rollouts total     0
Train Time (s)               142.14712422620505
(Previous) Eval Time (s)     17.907173110172153
Sample Time (s)              10.725942782126367
Epoch Time (s)               170.78024011850357
Total Train Time (s)         49359.166785054374
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:13:09.098820 UTC | [2020_01_11_02_30_29] Iteration #295 | Epoch Duration: 170.86419987678528
2020-01-11 16:13:09.098999 UTC | [2020_01_11_02_30_29] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042150967
Z variance train             0.0037274577
KL Divergence                11.509119
KL Loss                      1.1509119
QF Loss                      81.0047
VF Loss                      46.54168
Policy Loss                  -1410.8126
Q Predictions Mean           1409.6904
Q Predictions Std            353.63657
Q Predictions Max            1755.3639
Q Predictions Min            9.72138
V Predictions Mean           1408.8167
V Predictions Std            349.82657
V Predictions Max            1755.6927
V Predictions Min            16.154528
Log Pis Mean                 -0.16017188
Log Pis Std                  2.035659
Log Pis Max                  7.8292003
Log Pis Min                  -5.855883
Policy mu Mean               -0.13125348
Policy mu Std                0.89811766
Policy mu Max                2.4386485
Policy mu Min                -2.5235312
Policy log std Mean          -0.5054936
Policy log std Std           0.20162165
Policy log std Max           0.046201408
Policy log std Min           -1.0964371
Z mean eval                  0.019755227
Z variance eval              0.0033096876
total_rewards                [1457.08026277 1129.1771736   483.33806231 1284.62606102 1282.23365376
 1025.71323312 1040.61807483  463.17074796 1393.74605067 1658.22083576]
total_rewards_mean           1121.7924155780229
total_rewards_std            371.97712791296055
total_rewards_max            1658.220835756453
total_rewards_min            463.170747956253
Number of train steps total  1188000
Number of env steps total    1262214
Number of rollouts total     0
Train Time (s)               143.26311743119732
(Previous) Eval Time (s)     10.534103075042367
Sample Time (s)              10.300255939830095
Epoch Time (s)               164.09747644606978
Total Train Time (s)         49523.35705804359
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:15:53.293846 UTC | [2020_01_11_02_30_29] Iteration #296 | Epoch Duration: 164.19470024108887
2020-01-11 16:15:53.294075 UTC | [2020_01_11_02_30_29] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01966388
Z variance train             0.003307845
KL Divergence                11.858597
KL Loss                      1.1858597
QF Loss                      85.90974
VF Loss                      39.69961
Policy Loss                  -1413.0084
Q Predictions Mean           1412.2615
Q Predictions Std            339.26532
Q Predictions Max            1762.2783
Q Predictions Min            63.540302
V Predictions Mean           1409.5393
V Predictions Std            336.0226
V Predictions Max            1758.4609
V Predictions Min            70.58114
Log Pis Mean                 -0.17347957
Log Pis Std                  2.0005138
Log Pis Max                  5.72245
Log Pis Min                  -5.518265
Policy mu Mean               -0.021991586
Policy mu Std                0.92331016
Policy mu Max                2.5331488
Policy mu Min                -2.5286822
Policy log std Mean          -0.49799395
Policy log std Std           0.19654988
Policy log std Max           -0.0046545863
Policy log std Min           -1.1633579
Z mean eval                  0.03455461
Z variance eval              0.0035492387
total_rewards                [2989.10931619 1599.31710036 1352.0393289   897.64388606 2231.25679786
 1077.47568604 2587.02227796  922.58051992  822.74951936 2432.57275449]
total_rewards_mean           1691.1767187132773
total_rewards_std            761.787664472567
total_rewards_max            2989.1093161925564
total_rewards_min            822.7495193581564
Number of train steps total  1192000
Number of env steps total    1267792
Number of rollouts total     0
Train Time (s)               143.12336167879403
(Previous) Eval Time (s)     16.199418066069484
Sample Time (s)              10.820772307459265
Epoch Time (s)               170.14355205232278
Total Train Time (s)         49693.58351965668
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:18:43.523837 UTC | [2020_01_11_02_30_29] Iteration #297 | Epoch Duration: 170.22960448265076
2020-01-11 16:18:43.524044 UTC | [2020_01_11_02_30_29] Iteration #297 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034943905
Z variance train             0.0035494212
KL Divergence                11.755795
KL Loss                      1.1755794
QF Loss                      78.07297
VF Loss                      30.855412
Policy Loss                  -1412.6599
Q Predictions Mean           1414.0977
Q Predictions Std            333.11746
Q Predictions Max            1779.9977
Q Predictions Min            101.43732
V Predictions Mean           1414.4316
V Predictions Std            333.83646
V Predictions Max            1775.5118
V Predictions Min            99.915215
Log Pis Mean                 -0.35606506
Log Pis Std                  1.7842556
Log Pis Max                  5.5466695
Log Pis Min                  -4.595473
Policy mu Mean               0.0045753405
Policy mu Std                0.8414133
Policy mu Max                2.589011
Policy mu Min                -2.5079877
Policy log std Mean          -0.49154142
Policy log std Std           0.19314073
Policy log std Max           0.044644237
Policy log std Min           -1.1234032
Z mean eval                  0.037752252
Z variance eval              0.0032326665
total_rewards                [ 909.33327123 1920.3572551  1134.04206683 1695.27450452  236.6186677
 1074.45974824 1197.6054198  2052.04075552 1890.71497091  853.68717658]
total_rewards_mean           1296.413383643057
total_rewards_std            550.1778323891675
total_rewards_max            2052.040755516472
total_rewards_min            236.61866770093164
Number of train steps total  1196000
Number of env steps total    1273130
Number of rollouts total     0
Train Time (s)               143.2017068248242
(Previous) Eval Time (s)     11.8062351658009
Sample Time (s)              10.07608839822933
Epoch Time (s)               165.08403038885444
Total Train Time (s)         49858.75064438442
Epoch                        298
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:21:28.695120 UTC | [2020_01_11_02_30_29] Iteration #298 | Epoch Duration: 165.17092323303223
2020-01-11 16:21:28.695469 UTC | [2020_01_11_02_30_29] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03772005
Z variance train             0.0032333788
KL Divergence                12.130501
KL Loss                      1.2130501
QF Loss                      79.37025
VF Loss                      38.039276
Policy Loss                  -1404.3163
Q Predictions Mean           1405.6931
Q Predictions Std            361.71585
Q Predictions Max            1790.9896
Q Predictions Min            19.19835
V Predictions Mean           1405.5968
V Predictions Std            361.3837
V Predictions Max            1799.6223
V Predictions Min            18.891596
Log Pis Mean                 -0.03521059
Log Pis Std                  2.1097276
Log Pis Max                  8.304135
Log Pis Min                  -6.064652
Policy mu Mean               0.04073037
Policy mu Std                0.92230165
Policy mu Max                2.6252823
Policy mu Min                -2.5439572
Policy log std Mean          -0.49745655
Policy log std Std           0.20144664
Policy log std Max           0.1274957
Policy log std Min           -1.1396906
Z mean eval                  0.040268335
Z variance eval              0.0031090016
total_rewards                [ 786.48853527  779.45711947 1560.20347609 1044.07837083 1266.47927948
 1031.39848518 2511.66612591  691.68491685 2952.46079235 2473.84540926]
total_rewards_mean           1509.7762510696755
total_rewards_std            790.4297601707875
total_rewards_max            2952.460792346974
total_rewards_min            691.6849168477104
Number of train steps total  1200000
Number of env steps total    1278673
Number of rollouts total     0
Train Time (s)               144.07676591305062
(Previous) Eval Time (s)     13.255362401716411
Sample Time (s)              9.834740312770009
Epoch Time (s)               167.16686862753704
Total Train Time (s)         50025.99556792341
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:24:15.943716 UTC | [2020_01_11_02_30_29] Iteration #299 | Epoch Duration: 167.24810552597046
2020-01-11 16:24:15.943907 UTC | [2020_01_11_02_30_29] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04029522
Z variance train             0.0031099087
KL Divergence                12.100895
KL Loss                      1.2100896
QF Loss                      80.180664
VF Loss                      18.18649
Policy Loss                  -1402.9358
Q Predictions Mean           1402.8723
Q Predictions Std            340.7414
Q Predictions Max            1774.2863
Q Predictions Min            28.506973
V Predictions Mean           1404.2893
V Predictions Std            340.6155
V Predictions Max            1781.1948
V Predictions Min            32.861034
Log Pis Mean                 -0.12971497
Log Pis Std                  2.0141952
Log Pis Max                  6.26291
Log Pis Min                  -6.3345575
Policy mu Mean               -0.047450274
Policy mu Std                0.91063124
Policy mu Max                2.5534778
Policy mu Min                -2.6571925
Policy log std Mean          -0.4894308
Policy log std Std           0.199058
Policy log std Max           0.04478872
Policy log std Min           -1.389816
Z mean eval                  0.028327316
Z variance eval              0.003166601
total_rewards                [  63.13345787 2476.73662912 1388.42224152  752.56677116 1059.16496468
  816.19927026 1656.10781831  821.95964702  978.90927835 1072.7735816 ]
total_rewards_mean           1108.5973659900433
total_rewards_std            604.8000497296712
total_rewards_max            2476.736629115662
total_rewards_min            63.13345787270972
Number of train steps total  1204000
Number of env steps total    1284505
Number of rollouts total     0
Train Time (s)               143.4426295547746
(Previous) Eval Time (s)     10.924948676023632
Sample Time (s)              10.184230203740299
Epoch Time (s)               164.55180843453854
Total Train Time (s)         50190.630802895874
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:27:00.582538 UTC | [2020_01_11_02_30_29] Iteration #300 | Epoch Duration: 164.6384711265564
2020-01-11 16:27:00.582739 UTC | [2020_01_11_02_30_29] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028532574
Z variance train             0.0031683035
KL Divergence                11.939101
KL Loss                      1.1939101
QF Loss                      167.42282
VF Loss                      75.533875
Policy Loss                  -1384.3702
Q Predictions Mean           1384.6672
Q Predictions Std            369.90103
Q Predictions Max            1777.2046
Q Predictions Min            85.665955
V Predictions Mean           1387.1318
V Predictions Std            368.49045
V Predictions Max            1781.9435
V Predictions Min            90.01372
Log Pis Mean                 -0.2771916
Log Pis Std                  1.9006933
Log Pis Max                  7.197567
Log Pis Min                  -4.098156
Policy mu Mean               -0.022309458
Policy mu Std                0.8654134
Policy mu Max                2.1226692
Policy mu Min                -2.5898664
Policy log std Mean          -0.5140738
Policy log std Std           0.21021149
Policy log std Max           0.12104374
Policy log std Min           -1.1959512
Z mean eval                  0.044607956
Z variance eval              0.0028165968
total_rewards                [ 224.67816654 1145.0455582  1706.97992146  772.1846554   897.44028354
 1242.16643822 2609.13596424 1368.91657422 1403.48879408 1051.68690075]
total_rewards_mean           1242.1723256643304
total_rewards_std            595.6059149173417
total_rewards_max            2609.135964238289
total_rewards_min            224.67816653571248
Number of train steps total  1208000
Number of env steps total    1290321
Number of rollouts total     0
Train Time (s)               150.22426744783297
(Previous) Eval Time (s)     12.133293010760099
Sample Time (s)              10.063493439462036
Epoch Time (s)               172.4210538980551
Total Train Time (s)         50363.13764377264
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:29:53.094865 UTC | [2020_01_11_02_30_29] Iteration #301 | Epoch Duration: 172.51194310188293
2020-01-11 16:29:53.095243 UTC | [2020_01_11_02_30_29] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04469664
Z variance train             0.0028152927
KL Divergence                12.232019
KL Loss                      1.223202
QF Loss                      65.99515
VF Loss                      26.26389
Policy Loss                  -1406.9769
Q Predictions Mean           1404.7378
Q Predictions Std            365.6481
Q Predictions Max            1815.0269
Q Predictions Min            7.794427
V Predictions Mean           1405.7979
V Predictions Std            365.0661
V Predictions Max            1811.0052
V Predictions Min            8.018396
Log Pis Mean                 0.034538463
Log Pis Std                  1.8552163
Log Pis Max                  7.864646
Log Pis Min                  -3.798543
Policy mu Mean               0.010893784
Policy mu Std                0.88442934
Policy mu Max                2.9400136
Policy mu Min                -2.47656
Policy log std Mean          -0.5150655
Policy log std Std           0.202722
Policy log std Max           0.034688294
Policy log std Min           -1.1931882
Z mean eval                  0.040142037
Z variance eval              0.0030241464
total_rewards                [1056.0671402   822.53937098 1591.95403052 1586.13142177  804.50346058
 2168.44091089  832.94562356 1061.07343181 1271.77113269 1327.02094714]
total_rewards_mean           1252.2447470127352
total_rewards_std            413.30784281127217
total_rewards_max            2168.4409108860696
total_rewards_min            804.5034605765532
Number of train steps total  1212000
Number of env steps total    1296058
Number of rollouts total     0
Train Time (s)               151.89997356105596
(Previous) Eval Time (s)     12.526710154023021
Sample Time (s)              10.600288004614413
Epoch Time (s)               175.0269717196934
Total Train Time (s)         50538.25615324499
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:32:48.216448 UTC | [2020_01_11_02_30_29] Iteration #302 | Epoch Duration: 175.12100172042847
2020-01-11 16:32:48.216666 UTC | [2020_01_11_02_30_29] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039973143
Z variance train             0.0030248875
KL Divergence                12.10453
KL Loss                      1.210453
QF Loss                      92.19849
VF Loss                      30.108393
Policy Loss                  -1446.451
Q Predictions Mean           1444.3782
Q Predictions Std            298.4387
Q Predictions Max            1819.4806
Q Predictions Min            152.04053
V Predictions Mean           1448.1453
V Predictions Std            297.28714
V Predictions Max            1829.374
V Predictions Min            155.01195
Log Pis Mean                 -0.12935972
Log Pis Std                  2.062079
Log Pis Max                  5.5809097
Log Pis Min                  -4.4266977
Policy mu Mean               0.030025572
Policy mu Std                0.9027629
Policy mu Max                2.3979225
Policy mu Min                -2.3638625
Policy log std Mean          -0.5445805
Policy log std Std           0.17867479
Policy log std Max           0.07848364
Policy log std Min           -1.0667492
Z mean eval                  0.025415942
Z variance eval              0.0028326665
total_rewards                [1343.08599249 1129.31274299 1869.07152781 1116.4050625  1732.44316082
 1054.83198474 1273.03423254 1598.38075601  997.62052374 1019.75071129]
total_rewards_mean           1313.3936694922827
total_rewards_std            298.9300630876891
total_rewards_max            1869.0715278113848
total_rewards_min            997.6205237431993
Number of train steps total  1216000
Number of env steps total    1301887
Number of rollouts total     0
Train Time (s)               151.5791426007636
(Previous) Eval Time (s)     12.859721222892404
Sample Time (s)              10.330628994852304
Epoch Time (s)               174.7694928185083
Total Train Time (s)         50713.11078068102
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:35:43.074331 UTC | [2020_01_11_02_30_29] Iteration #303 | Epoch Duration: 174.85751247406006
2020-01-11 16:35:43.074538 UTC | [2020_01_11_02_30_29] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02535972
Z variance train             0.0028338358
KL Divergence                12.458362
KL Loss                      1.2458361
QF Loss                      91.42384
VF Loss                      28.490404
Policy Loss                  -1418.6925
Q Predictions Mean           1420.3674
Q Predictions Std            352.12866
Q Predictions Max            1835.7799
Q Predictions Min            44.32613
V Predictions Mean           1417.7285
V Predictions Std            350.8815
V Predictions Max            1825.3044
V Predictions Min            33.68943
Log Pis Mean                 -0.16749775
Log Pis Std                  1.8514935
Log Pis Max                  6.1079645
Log Pis Min                  -5.5800323
Policy mu Mean               -0.047878157
Policy mu Std                0.8687258
Policy mu Max                2.4391668
Policy mu Min                -2.3717775
Policy log std Mean          -0.52556795
Policy log std Std           0.2105363
Policy log std Max           0.2529655
Policy log std Min           -1.153136
Z mean eval                  0.015768258
Z variance eval              0.0029551717
total_rewards                [ 802.34383508 1162.72272151 3425.86543444 2214.33411452 1109.18773138
  849.39083224 1872.5516207   872.78312745 3444.52676325 3007.61551172]
total_rewards_mean           1876.1321692280787
total_rewards_std            1027.9721784374467
total_rewards_max            3444.526763245391
total_rewards_min            802.3438350795965
Number of train steps total  1220000
Number of env steps total    1307647
Number of rollouts total     0
Train Time (s)               151.48957371292636
(Previous) Eval Time (s)     17.08144521806389
Sample Time (s)              9.859768032096326
Epoch Time (s)               178.43078696308658
Total Train Time (s)         50891.62324539432
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:38:41.591625 UTC | [2020_01_11_02_30_29] Iteration #304 | Epoch Duration: 178.51690411567688
2020-01-11 16:38:41.591974 UTC | [2020_01_11_02_30_29] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01590066
Z variance train             0.002953836
KL Divergence                12.180977
KL Loss                      1.2180977
QF Loss                      72.15164
VF Loss                      69.322235
Policy Loss                  -1427.7577
Q Predictions Mean           1424.9949
Q Predictions Std            350.35663
Q Predictions Max            1764.3685
Q Predictions Min            30.037148
V Predictions Mean           1423.2151
V Predictions Std            347.90704
V Predictions Max            1761.4655
V Predictions Min            34.012314
Log Pis Mean                 -0.21537593
Log Pis Std                  1.7854328
Log Pis Max                  5.956077
Log Pis Min                  -4.2665696
Policy mu Mean               0.03151955
Policy mu Std                0.8571915
Policy mu Max                2.5293856
Policy mu Min                -3.077542
Policy log std Mean          -0.50990397
Policy log std Std           0.19657671
Policy log std Max           0.031012714
Policy log std Min           -1.2134968
Z mean eval                  0.029390853
Z variance eval              0.0027181287
total_rewards                [1260.02168634  846.46287504  918.59053965 1802.22849348  611.59486073
 1304.78380339  939.19492604 1086.29921797 1367.67457697 2105.55151967]
total_rewards_mean           1224.2402499265643
total_rewards_std            430.217546535424
total_rewards_max            2105.5515196660785
total_rewards_min            611.5948607282962
Number of train steps total  1224000
Number of env steps total    1313539
Number of rollouts total     0
Train Time (s)               150.11717212339863
(Previous) Eval Time (s)     12.51871283724904
Sample Time (s)              10.103194251190871
Epoch Time (s)               172.73907921183854
Total Train Time (s)         51064.44020153023
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:41:34.411560 UTC | [2020_01_11_02_30_29] Iteration #305 | Epoch Duration: 172.81933116912842
2020-01-11 16:41:34.411752 UTC | [2020_01_11_02_30_29] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029347206
Z variance train             0.002721343
KL Divergence                12.365154
KL Loss                      1.2365154
QF Loss                      13239.713
VF Loss                      43.04161
Policy Loss                  -1433.6533
Q Predictions Mean           1433.0779
Q Predictions Std            293.97543
Q Predictions Max            1750.8156
Q Predictions Min            49.344353
V Predictions Mean           1436.8456
V Predictions Std            292.67218
V Predictions Max            1738.0957
V Predictions Min            82.165634
Log Pis Mean                 -0.06403744
Log Pis Std                  1.9589763
Log Pis Max                  5.5276995
Log Pis Min                  -4.1373606
Policy mu Mean               -0.0729711
Policy mu Std                0.93534523
Policy mu Max                2.7587833
Policy mu Min                -2.540287
Policy log std Mean          -0.49531746
Policy log std Std           0.20344359
Policy log std Max           0.08199394
Policy log std Min           -1.1961534
Z mean eval                  0.052437473
Z variance eval              0.0025190366
total_rewards                [1704.46068675 1576.75719224 2375.21434854  895.49297613  928.33162529
  810.17835886 2237.07324914 1061.33633421 1157.85453997  818.18239344]
total_rewards_mean           1356.4881704570732
total_rewards_std            556.1895776216405
total_rewards_max            2375.214348540739
total_rewards_min            810.1783588556981
Number of train steps total  1228000
Number of env steps total    1319103
Number of rollouts total     0
Train Time (s)               143.1344550261274
(Previous) Eval Time (s)     11.663524537347257
Sample Time (s)              9.832140621263534
Epoch Time (s)               164.6301201847382
Total Train Time (s)         51229.15330418572
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:44:19.129057 UTC | [2020_01_11_02_30_29] Iteration #306 | Epoch Duration: 164.71715784072876
2020-01-11 16:44:19.129250 UTC | [2020_01_11_02_30_29] Iteration #306 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052432798
Z variance train             0.0025169228
KL Divergence                12.493548
KL Loss                      1.2493548
QF Loss                      44.837437
VF Loss                      18.598822
Policy Loss                  -1395.926
Q Predictions Mean           1394.1012
Q Predictions Std            347.42548
Q Predictions Max            1771.6594
Q Predictions Min            56.04731
V Predictions Mean           1395.3838
V Predictions Std            346.95938
V Predictions Max            1771.5752
V Predictions Min            72.184296
Log Pis Mean                 0.11133039
Log Pis Std                  2.1794586
Log Pis Max                  11.810415
Log Pis Min                  -4.7793703
Policy mu Mean               -0.06536032
Policy mu Std                0.9315612
Policy mu Max                2.3897777
Policy mu Min                -4.953941
Policy log std Mean          -0.50315547
Policy log std Std           0.20192426
Policy log std Max           0.53762764
Policy log std Min           -1.179837
Z mean eval                  0.03068451
Z variance eval              0.002850954
total_rewards                [ 442.08439361  908.39361602  792.75932475  763.94854981  443.6743604
 1013.18671594  988.51237314  794.55006715 1083.01010954 1639.06081406]
total_rewards_mean           886.9180324428896
total_rewards_std            325.2319747156164
total_rewards_max            1639.060814061465
total_rewards_min            442.0843936059033
Number of train steps total  1232000
Number of env steps total    1324803
Number of rollouts total     0
Train Time (s)               142.65893764887005
(Previous) Eval Time (s)     8.014476826880127
Sample Time (s)              9.751813318114728
Epoch Time (s)               160.4252277938649
Total Train Time (s)         51389.6554296324
Epoch                        307
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:46:59.634807 UTC | [2020_01_11_02_30_29] Iteration #307 | Epoch Duration: 160.5054099559784
2020-01-11 16:46:59.634983 UTC | [2020_01_11_02_30_29] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030715331
Z variance train             0.0028499695
KL Divergence                12.189154
KL Loss                      1.2189153
QF Loss                      51.059437
VF Loss                      18.42826
Policy Loss                  -1444.3936
Q Predictions Mean           1444.6798
Q Predictions Std            299.16476
Q Predictions Max            1839.0986
Q Predictions Min            21.39327
V Predictions Mean           1443.9518
V Predictions Std            300.3066
V Predictions Max            1837.6742
V Predictions Min            11.5161085
Log Pis Mean                 -0.29992962
Log Pis Std                  1.9109057
Log Pis Max                  7.3031964
Log Pis Min                  -3.6432471
Policy mu Mean               -0.079425976
Policy mu Std                0.8672071
Policy mu Max                2.083564
Policy mu Min                -3.3220747
Policy log std Mean          -0.4809165
Policy log std Std           0.19865577
Policy log std Max           0.1029371
Policy log std Min           -1.1977301
Z mean eval                  0.063207515
Z variance eval              0.0029674768
total_rewards                [1592.13306094  795.58107132 2542.86920528 2407.90768701  815.48064016
  778.76362127 1803.91982711  804.27190939  751.11910131 3362.76670502]
total_rewards_mean           1565.4812828794898
total_rewards_std            892.7242012235268
total_rewards_max            3362.7667050157456
total_rewards_min            751.1191013071281
Number of train steps total  1236000
Number of env steps total    1330941
Number of rollouts total     0
Train Time (s)               142.55749185802415
(Previous) Eval Time (s)     15.055732427164912
Sample Time (s)              10.758387858513743
Epoch Time (s)               168.3716121437028
Total Train Time (s)         51558.112031471916
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:49:48.094980 UTC | [2020_01_11_02_30_29] Iteration #308 | Epoch Duration: 168.45983338356018
2020-01-11 16:49:48.095229 UTC | [2020_01_11_02_30_29] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06296935
Z variance train             0.0029685642
KL Divergence                12.141795
KL Loss                      1.2141795
QF Loss                      135.02042
VF Loss                      30.870388
Policy Loss                  -1460.3167
Q Predictions Mean           1460.9258
Q Predictions Std            299.77698
Q Predictions Max            1816.1371
Q Predictions Min            220.01233
V Predictions Mean           1460.4917
V Predictions Std            300.58594
V Predictions Max            1810.2499
V Predictions Min            206.57106
Log Pis Mean                 0.034059923
Log Pis Std                  1.9235703
Log Pis Max                  6.2340617
Log Pis Min                  -3.298014
Policy mu Mean               -0.18249957
Policy mu Std                0.908034
Policy mu Max                1.893815
Policy mu Min                -2.6224928
Policy log std Mean          -0.5270605
Policy log std Std           0.1966201
Policy log std Max           0.048695743
Policy log std Min           -1.1832316
Z mean eval                  0.0347025
Z variance eval              0.002983137
total_rewards                [ 810.23172005 1020.67596048  765.73758207  968.36159008 1084.01289102
 1338.43848852 1301.52176324 1563.84134492 1039.41481631   82.86990058]
total_rewards_mean           997.5106057272618
total_rewards_std            382.80148293181986
total_rewards_max            1563.8413449160096
total_rewards_min            82.86990057641015
Number of train steps total  1240000
Number of env steps total    1336677
Number of rollouts total     0
Train Time (s)               143.30964144319296
(Previous) Eval Time (s)     9.484791707247496
Sample Time (s)              9.84724578820169
Epoch Time (s)               162.64167893864214
Total Train Time (s)         51720.83272209717
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:52:30.819841 UTC | [2020_01_11_02_30_29] Iteration #309 | Epoch Duration: 162.72444081306458
2020-01-11 16:52:30.820061 UTC | [2020_01_11_02_30_29] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034910142
Z variance train             0.0029832118
KL Divergence                12.134499
KL Loss                      1.2134498
QF Loss                      68.235115
VF Loss                      25.005625
Policy Loss                  -1408.7706
Q Predictions Mean           1409.3007
Q Predictions Std            353.31564
Q Predictions Max            1774.4879
Q Predictions Min            66.56487
V Predictions Mean           1409.8396
V Predictions Std            354.45792
V Predictions Max            1771.3047
V Predictions Min            57.960197
Log Pis Mean                 0.0314193
Log Pis Std                  2.0922065
Log Pis Max                  7.262476
Log Pis Min                  -6.02909
Policy mu Mean               0.044293504
Policy mu Std                0.91952205
Policy mu Max                2.5645401
Policy mu Min                -2.9172583
Policy log std Mean          -0.52676225
Policy log std Std           0.18871136
Policy log std Max           0.010764241
Policy log std Min           -1.1342056
Z mean eval                  0.040772624
Z variance eval              0.0035215653
total_rewards                [2601.27386047 1406.12219202 3373.21481558 2118.4439293  1099.20519092
 1477.4498256  1436.96963073 1491.83698762 2271.07945587 3379.78780152]
total_rewards_mean           2065.5383689630476
total_rewards_std            787.9110030612875
total_rewards_max            3379.787801517506
total_rewards_min            1099.2051909231895
Number of train steps total  1244000
Number of env steps total    1342481
Number of rollouts total     0
Train Time (s)               142.33784964401275
(Previous) Eval Time (s)     18.022570497822016
Sample Time (s)              10.281444667372853
Epoch Time (s)               170.64186480920762
Total Train Time (s)         51891.70790350763
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:55:21.698314 UTC | [2020_01_11_02_30_29] Iteration #310 | Epoch Duration: 170.8780813217163
2020-01-11 16:55:21.698499 UTC | [2020_01_11_02_30_29] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04059932
Z variance train             0.0035209768
KL Divergence                11.755653
KL Loss                      1.1755654
QF Loss                      78.822266
VF Loss                      28.671041
Policy Loss                  -1397.2368
Q Predictions Mean           1399.467
Q Predictions Std            398.7486
Q Predictions Max            1795.5294
Q Predictions Min            86.710785
V Predictions Mean           1399.834
V Predictions Std            398.0205
V Predictions Max            1793.0709
V Predictions Min            92.35741
Log Pis Mean                 -0.18242905
Log Pis Std                  1.8142992
Log Pis Max                  6.693751
Log Pis Min                  -4.673805
Policy mu Mean               -0.04136118
Policy mu Std                0.8486466
Policy mu Max                1.6995273
Policy mu Min                -2.6312926
Policy log std Mean          -0.52444786
Policy log std Std           0.18504325
Policy log std Max           -0.044552565
Policy log std Min           -1.187578
Z mean eval                  0.021422457
Z variance eval              0.0037632906
total_rewards                [ 329.84952038 2432.78738177 1549.26430358 3375.80893256  755.41067765
 3065.02542977 1750.13275846 3350.75780371 1451.17057939 3348.59138749]
total_rewards_mean           2140.879877475852
total_rewards_std            1075.3800967069737
total_rewards_max            3375.8089325563647
total_rewards_min            329.8495203827588
Number of train steps total  1248000
Number of env steps total    1348011
Number of rollouts total     0
Train Time (s)               142.37771569285542
(Previous) Eval Time (s)     20.992916527204216
Sample Time (s)              10.423891608137637
Epoch Time (s)               173.79452382819727
Total Train Time (s)         52065.57886052225
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:58:15.573189 UTC | [2020_01_11_02_30_29] Iteration #311 | Epoch Duration: 173.87453937530518
2020-01-11 16:58:15.573390 UTC | [2020_01_11_02_30_29] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021583885
Z variance train             0.003761777
KL Divergence                11.551937
KL Loss                      1.1551937
QF Loss                      75.62746
VF Loss                      71.38044
Policy Loss                  -1428.8213
Q Predictions Mean           1428.207
Q Predictions Std            354.79648
Q Predictions Max            1805.905
Q Predictions Min            73.168106
V Predictions Mean           1424.0234
V Predictions Std            348.48914
V Predictions Max            1795.4441
V Predictions Min            118.15288
Log Pis Mean                 -0.25527352
Log Pis Std                  1.7297031
Log Pis Max                  7.659957
Log Pis Min                  -3.988678
Policy mu Mean               0.019519886
Policy mu Std                0.8457142
Policy mu Max                2.3215246
Policy mu Min                -2.5022404
Policy log std Mean          -0.5040969
Policy log std Std           0.18278062
Policy log std Max           0.09864241
Policy log std Min           -1.1200703
Z mean eval                  0.017567433
Z variance eval              0.0039948043
total_rewards                [1400.57269172  790.6178731  1894.59319784  765.00563198 1349.44810481
  764.02994064 2143.81353664  744.32321671 2318.92449455 1129.44885173]
total_rewards_mean           1330.077753971907
total_rewards_std            572.5469553561604
total_rewards_max            2318.9244945473374
total_rewards_min            744.3232167146352
Number of train steps total  1252000
Number of env steps total    1353679
Number of rollouts total     0
Train Time (s)               142.22645981470123
(Previous) Eval Time (s)     12.88512273086235
Sample Time (s)              9.009194530081004
Epoch Time (s)               164.12077707564458
Total Train Time (s)         52229.789233986754
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:00:59.787752 UTC | [2020_01_11_02_30_29] Iteration #312 | Epoch Duration: 164.21419644355774
2020-01-11 17:00:59.787990 UTC | [2020_01_11_02_30_29] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017619029
Z variance train             0.0039953114
KL Divergence                11.472271
KL Loss                      1.1472272
QF Loss                      79.53921
VF Loss                      21.627695
Policy Loss                  -1436.9578
Q Predictions Mean           1438.5991
Q Predictions Std            339.7102
Q Predictions Max            1784.1866
Q Predictions Min            42.74123
V Predictions Mean           1435.388
V Predictions Std            337.7088
V Predictions Max            1787.3258
V Predictions Min            48.90776
Log Pis Mean                 0.14442343
Log Pis Std                  2.196183
Log Pis Max                  7.4199123
Log Pis Min                  -5.973868
Policy mu Mean               -0.04732066
Policy mu Std                0.9506564
Policy mu Max                2.6042068
Policy mu Min                -2.4410508
Policy log std Mean          -0.5299821
Policy log std Std           0.18934149
Policy log std Max           -0.05737436
Policy log std Min           -1.1931074
Z mean eval                  0.057334058
Z variance eval              0.0035530725
total_rewards                [3402.87859833 3295.62982174 3396.73703045 3422.89217781 3419.03760333
  945.24671614  850.80194611 3396.88697909 3384.17666089 3394.8422895 ]
total_rewards_mean           2890.9129823377198
total_rewards_std            997.226840170329
total_rewards_max            3422.892177805001
total_rewards_min            850.8019461074076
Number of train steps total  1256000
Number of env steps total    1359393
Number of rollouts total     0
Train Time (s)               144.14256312977523
(Previous) Eval Time (s)     27.0630115121603
Sample Time (s)              10.280494678299874
Epoch Time (s)               181.4860693202354
Total Train Time (s)         52411.36195087433
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:04:01.365018 UTC | [2020_01_11_02_30_29] Iteration #313 | Epoch Duration: 181.57684111595154
2020-01-11 17:04:01.365265 UTC | [2020_01_11_02_30_29] Iteration #313 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06131751
Z variance train             0.0035459776
KL Divergence                11.7708435
KL Loss                      1.1770843
QF Loss                      143.24815
VF Loss                      63.191933
Policy Loss                  -1453.7102
Q Predictions Mean           1458.4259
Q Predictions Std            331.51257
Q Predictions Max            1772.6527
Q Predictions Min            104.834816
V Predictions Mean           1457.969
V Predictions Std            330.54126
V Predictions Max            1771.817
V Predictions Min            101.15381
Log Pis Mean                 -0.13309371
Log Pis Std                  1.9361746
Log Pis Max                  7.4038744
Log Pis Min                  -4.3981347
Policy mu Mean               -0.027357327
Policy mu Std                0.8678176
Policy mu Max                2.037892
Policy mu Min                -2.5895643
Policy log std Mean          -0.5014934
Policy log std Std           0.18542208
Policy log std Max           0.0047081113
Policy log std Min           -1.1995211
Z mean eval                  0.043650676
Z variance eval              0.0036267329
total_rewards                [ 820.29626159  809.88227128  951.20001826  975.51240282  839.8019243
 2674.43218514  954.53492792  783.3066763   792.20836468  832.79443114]
total_rewards_mean           1043.3969463416365
total_rewards_std            547.9170573060458
total_rewards_max            2674.4321851412346
total_rewards_min            783.3066762996078
Number of train steps total  1260000
Number of env steps total    1365004
Number of rollouts total     0
Train Time (s)               141.56525699002668
(Previous) Eval Time (s)     10.067639465909451
Sample Time (s)              9.277974439784884
Epoch Time (s)               160.91087089572102
Total Train Time (s)         52572.35075300699
Epoch                        314
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:06:42.356511 UTC | [2020_01_11_02_30_29] Iteration #314 | Epoch Duration: 160.99107694625854
2020-01-11 17:06:42.356683 UTC | [2020_01_11_02_30_29] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043676306
Z variance train             0.003627066
KL Divergence                11.64427
KL Loss                      1.164427
QF Loss                      121.348015
VF Loss                      18.495028
Policy Loss                  -1459.264
Q Predictions Mean           1456.877
Q Predictions Std            336.7722
Q Predictions Max            1796.4678
Q Predictions Min            62.304832
V Predictions Mean           1458.8308
V Predictions Std            336.12973
V Predictions Max            1802.1045
V Predictions Min            95.31694
Log Pis Mean                 -0.14433886
Log Pis Std                  2.022026
Log Pis Max                  6.4248395
Log Pis Min                  -5.0417795
Policy mu Mean               -0.04788217
Policy mu Std                0.8992961
Policy mu Max                2.2981942
Policy mu Min                -2.7524977
Policy log std Mean          -0.5096521
Policy log std Std           0.19297166
Policy log std Max           0.07241905
Policy log std Min           -1.0827202
Z mean eval                  0.043121926
Z variance eval              0.004216599
total_rewards                [ 757.89561297  815.09265966  810.42918049  843.37360143  925.39153834
 1346.32673905  814.21137019 3399.76409055  908.94683949  795.09040516]
total_rewards_mean           1141.6522037322884
total_rewards_std            769.5318754227067
total_rewards_max            3399.7640905453577
total_rewards_min            757.8956129657831
Number of train steps total  1264000
Number of env steps total    1371020
Number of rollouts total     0
Train Time (s)               144.3315914575942
(Previous) Eval Time (s)     10.749515410978347
Sample Time (s)              9.832817178685218
Epoch Time (s)               164.91392404725775
Total Train Time (s)         52737.5688130958
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:09:27.578794 UTC | [2020_01_11_02_30_29] Iteration #315 | Epoch Duration: 165.22195982933044
2020-01-11 17:09:27.579021 UTC | [2020_01_11_02_30_29] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043085843
Z variance train             0.00421643
KL Divergence                11.199725
KL Loss                      1.1199726
QF Loss                      84.52251
VF Loss                      15.999886
Policy Loss                  -1477.3265
Q Predictions Mean           1474.164
Q Predictions Std            286.62122
Q Predictions Max            1805.2167
Q Predictions Min            57.0287
V Predictions Mean           1475.7708
V Predictions Std            283.84457
V Predictions Max            1791.3011
V Predictions Min            62.40124
Log Pis Mean                 -0.14858124
Log Pis Std                  2.0568507
Log Pis Max                  5.8797903
Log Pis Min                  -4.7176085
Policy mu Mean               -0.058926985
Policy mu Std                0.8814304
Policy mu Max                2.6360078
Policy mu Min                -2.4458752
Policy log std Mean          -0.5223897
Policy log std Std           0.20149454
Policy log std Max           -0.0031263828
Policy log std Min           -1.1289698
Z mean eval                  0.03358847
Z variance eval              0.0037612733
total_rewards                [1337.34654952 3381.48368579  868.59811137 3191.83233506 1374.30413477
 1132.83833212 1335.61582062  861.72497273 1304.8772781   905.09546045]
total_rewards_mean           1569.371668052268
total_rewards_std            880.6978093553415
total_rewards_max            3381.4836857868086
total_rewards_min            861.7249727293326
Number of train steps total  1268000
Number of env steps total    1376884
Number of rollouts total     0
Train Time (s)               142.7318037278019
(Previous) Eval Time (s)     15.301849441602826
Sample Time (s)              9.991657757665962
Epoch Time (s)               168.02531092707068
Total Train Time (s)         52905.6818749411
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:12:15.694868 UTC | [2020_01_11_02_30_29] Iteration #316 | Epoch Duration: 168.11563992500305
2020-01-11 17:12:15.695052 UTC | [2020_01_11_02_30_29] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033849433
Z variance train             0.003762881
KL Divergence                11.4930105
KL Loss                      1.149301
QF Loss                      58.567368
VF Loss                      20.461044
Policy Loss                  -1474.4733
Q Predictions Mean           1475.4854
Q Predictions Std            288.93973
Q Predictions Max            1806.694
Q Predictions Min            190.39146
V Predictions Mean           1476.1449
V Predictions Std            287.7487
V Predictions Max            1807.5752
V Predictions Min            200.5336
Log Pis Mean                 -0.22076319
Log Pis Std                  2.0624118
Log Pis Max                  7.3882246
Log Pis Min                  -7.453711
Policy mu Mean               -0.12479138
Policy mu Std                0.8739248
Policy mu Max                2.1722202
Policy mu Min                -2.5260637
Policy log std Mean          -0.5485861
Policy log std Std           0.1873095
Policy log std Max           0.017786324
Policy log std Min           -1.1395454
Z mean eval                  0.04717325
Z variance eval              0.0037027155
total_rewards                [ 910.15082698 1693.03274296  818.36916201  813.44924818  838.50853514
  780.98565432  972.50250042  828.85146606  890.82227598  911.05072348]
total_rewards_mean           945.7723135552718
total_rewards_std            255.0839548961344
total_rewards_max            1693.032742964332
total_rewards_min            780.9856543243279
Number of train steps total  1272000
Number of env steps total    1382645
Number of rollouts total     0
Train Time (s)               143.47038864996284
(Previous) Eval Time (s)     8.721873590257019
Sample Time (s)              10.38189959898591
Epoch Time (s)               162.57416183920577
Total Train Time (s)         53068.35177615611
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:14:58.368657 UTC | [2020_01_11_02_30_29] Iteration #317 | Epoch Duration: 162.67344307899475
2020-01-11 17:14:58.368864 UTC | [2020_01_11_02_30_29] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047000114
Z variance train             0.0037023923
KL Divergence                11.587843
KL Loss                      1.1587843
QF Loss                      55.78287
VF Loss                      25.348679
Policy Loss                  -1450.3334
Q Predictions Mean           1448.6168
Q Predictions Std            322.38486
Q Predictions Max            1809.4608
Q Predictions Min            222.52434
V Predictions Mean           1447.7207
V Predictions Std            321.44406
V Predictions Max            1809.2748
V Predictions Min            222.23004
Log Pis Mean                 -0.13389218
Log Pis Std                  1.948765
Log Pis Max                  6.930516
Log Pis Min                  -6.5283313
Policy mu Mean               -0.036050107
Policy mu Std                0.8686426
Policy mu Max                2.2100706
Policy mu Min                -2.711319
Policy log std Mean          -0.5239602
Policy log std Std           0.18219651
Policy log std Max           0.10572934
Policy log std Min           -1.1744092
Z mean eval                  0.035572175
Z variance eval              0.003291135
total_rewards                [2970.31777024  749.0181191  1059.21085718 2480.55931715 2256.02029847
  805.80260065  787.99083854 3352.26495491 3372.17218159 1387.81870419]
total_rewards_mean           1922.1175642024286
total_rewards_std            1029.9854340976503
total_rewards_max            3372.1721815922056
total_rewards_min            749.0181190953085
Number of train steps total  1276000
Number of env steps total    1388379
Number of rollouts total     0
Train Time (s)               143.48467753315344
(Previous) Eval Time (s)     18.23587056994438
Sample Time (s)              10.095013115089387
Epoch Time (s)               171.8155612181872
Total Train Time (s)         53240.253723151516
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:17:50.274559 UTC | [2020_01_11_02_30_29] Iteration #318 | Epoch Duration: 171.90551495552063
2020-01-11 17:17:50.274808 UTC | [2020_01_11_02_30_29] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0353979
Z variance train             0.0032933583
KL Divergence                11.8826475
KL Loss                      1.1882647
QF Loss                      59.493675
VF Loss                      24.862595
Policy Loss                  -1427.9093
Q Predictions Mean           1428.4016
Q Predictions Std            369.85892
Q Predictions Max            1787.7319
Q Predictions Min            13.144102
V Predictions Mean           1429.7681
V Predictions Std            368.2483
V Predictions Max            1797.2126
V Predictions Min            30.966787
Log Pis Mean                 0.08767859
Log Pis Std                  2.016883
Log Pis Max                  7.3126974
Log Pis Min                  -4.8438387
Policy mu Mean               -0.16343826
Policy mu Std                0.9063217
Policy mu Max                2.1484034
Policy mu Min                -2.4921498
Policy log std Mean          -0.5248489
Policy log std Std           0.18696104
Policy log std Max           0.21456373
Policy log std Min           -1.0939457
Z mean eval                  0.021975493
Z variance eval              0.0031891693
total_rewards                [ 170.89518055  862.90962403 3361.39346541  739.49879186 1922.29060538
 1084.27616719 1948.12352187  737.74251523 3365.51950653 3357.22538698]
total_rewards_mean           1754.9874765024244
total_rewards_std            1167.3826000485133
total_rewards_max            3365.5195065281814
total_rewards_min            170.8951805465383
Number of train steps total  1280000
Number of env steps total    1394347
Number of rollouts total     0
Train Time (s)               144.51597243640572
(Previous) Eval Time (s)     17.243445843923837
Sample Time (s)              9.93909258581698
Epoch Time (s)               171.69851086614653
Total Train Time (s)         53412.03596415231
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:20:42.060601 UTC | [2020_01_11_02_30_29] Iteration #319 | Epoch Duration: 171.78555631637573
2020-01-11 17:20:42.060803 UTC | [2020_01_11_02_30_29] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021962682
Z variance train             0.0031883053
KL Divergence                11.8999195
KL Loss                      1.189992
QF Loss                      44.448032
VF Loss                      23.672697
Policy Loss                  -1449.7902
Q Predictions Mean           1448.7378
Q Predictions Std            318.70657
Q Predictions Max            1806.6165
Q Predictions Min            74.00736
V Predictions Mean           1452.0559
V Predictions Std            317.26276
V Predictions Max            1808.0026
V Predictions Min            91.669914
Log Pis Mean                 -0.42003378
Log Pis Std                  1.8295964
Log Pis Max                  5.549117
Log Pis Min                  -4.7945237
Policy mu Mean               -0.01604273
Policy mu Std                0.86012846
Policy mu Max                2.4960475
Policy mu Min                -2.3459446
Policy log std Mean          -0.4954201
Policy log std Std           0.20456031
Policy log std Max           0.405582
Policy log std Min           -1.1729051
Z mean eval                  0.07862113
Z variance eval              0.0036697746
total_rewards                [ 887.58578793 2534.60731788 2894.0793523  2197.45916166 3377.08907252
 3375.62815236  856.46273051 3274.25817606  879.05354457 3345.71159638]
total_rewards_mean           2362.1934892179024
total_rewards_std            1041.028160317257
total_rewards_max            3377.0890725195973
total_rewards_min            856.4627305072755
Number of train steps total  1284000
Number of env steps total    1400616
Number of rollouts total     0
Train Time (s)               142.7651908271946
(Previous) Eval Time (s)     22.770540731959045
Sample Time (s)              10.30200367514044
Epoch Time (s)               175.8377352342941
Total Train Time (s)         53587.95481233671
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:23:37.982902 UTC | [2020_01_11_02_30_29] Iteration #320 | Epoch Duration: 175.92194628715515
2020-01-11 17:23:37.983105 UTC | [2020_01_11_02_30_29] Iteration #320 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07841353
Z variance train             0.0036705066
KL Divergence                11.639497
KL Loss                      1.1639497
QF Loss                      57.57948
VF Loss                      27.905182
Policy Loss                  -1446.0496
Q Predictions Mean           1442.5024
Q Predictions Std            328.1909
Q Predictions Max            1786.2677
Q Predictions Min            190.16508
V Predictions Mean           1444.7042
V Predictions Std            327.9756
V Predictions Max            1788.8766
V Predictions Min            197.59697
Log Pis Mean                 -0.11798068
Log Pis Std                  1.9195739
Log Pis Max                  7.6927648
Log Pis Min                  -6.046482
Policy mu Mean               -0.041467026
Policy mu Std                0.85319084
Policy mu Max                1.9690466
Policy mu Min                -2.7601926
Policy log std Mean          -0.503144
Policy log std Std           0.18992902
Policy log std Max           -0.002888143
Policy log std Min           -1.250355
Z mean eval                  0.032187898
Z variance eval              0.0038426288
total_rewards                [ 762.47209697  874.23678045 1325.04827431  873.38588994  819.09302658
  847.26396459 1374.27992177 1344.5083131   857.5504929  1082.55107325]
total_rewards_mean           1016.0389833851016
total_rewards_std            230.92954004910862
total_rewards_max            1374.2799217691331
total_rewards_min            762.4720969720993
Number of train steps total  1288000
Number of env steps total    1406741
Number of rollouts total     0
Train Time (s)               150.37972924485803
(Previous) Eval Time (s)     10.096051774919033
Sample Time (s)              8.251634296495467
Epoch Time (s)               168.72741531627253
Total Train Time (s)         53756.76841479726
Epoch                        321
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:26:26.802007 UTC | [2020_01_11_02_30_29] Iteration #321 | Epoch Duration: 168.81867098808289
2020-01-11 17:26:26.802390 UTC | [2020_01_11_02_30_29] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03193131
Z variance train             0.0038426884
KL Divergence                11.517923
KL Loss                      1.1517924
QF Loss                      43.94749
VF Loss                      22.601358
Policy Loss                  -1506.3738
Q Predictions Mean           1506.244
Q Predictions Std            250.57109
Q Predictions Max            1788.3624
Q Predictions Min            153.47142
V Predictions Mean           1508.8596
V Predictions Std            250.71312
V Predictions Max            1794.085
V Predictions Min            169.06888
Log Pis Mean                 -0.39415509
Log Pis Std                  1.771306
Log Pis Max                  6.075114
Log Pis Min                  -4.8392034
Policy mu Mean               -0.120720185
Policy mu Std                0.7967139
Policy mu Max                2.0420005
Policy mu Min                -2.3217103
Policy log std Mean          -0.4995235
Policy log std Std           0.20035401
Policy log std Max           0.05161035
Policy log std Min           -1.1443038
Z mean eval                  0.06521575
Z variance eval              0.0037871164
total_rewards                [ 905.85226857  973.25198089  832.18349144 1550.6094238   825.22107521
 1710.00104447  978.34217653  918.81191243  901.72040138  684.95661485]
total_rewards_mean           1028.0950389581028
total_rewards_std            313.6303547904292
total_rewards_max            1710.001044474392
total_rewards_min            684.9566148539506
Number of train steps total  1292000
Number of env steps total    1413242
Number of rollouts total     0
Train Time (s)               151.25301511771977
(Previous) Eval Time (s)     9.261796462815255
Sample Time (s)              10.270685752853751
Epoch Time (s)               170.78549733338878
Total Train Time (s)         53927.65831410512
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:29:17.694692 UTC | [2020_01_11_02_30_29] Iteration #322 | Epoch Duration: 170.8920032978058
2020-01-11 17:29:17.694917 UTC | [2020_01_11_02_30_29] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06523224
Z variance train             0.0037874922
KL Divergence                11.559946
KL Loss                      1.1559947
QF Loss                      56.737953
VF Loss                      25.56891
Policy Loss                  -1416.5725
Q Predictions Mean           1416.7815
Q Predictions Std            358.01892
Q Predictions Max            1814.3882
Q Predictions Min            86.638794
V Predictions Mean           1416.6497
V Predictions Std            356.73328
V Predictions Max            1822.0602
V Predictions Min            83.85623
Log Pis Mean                 -0.22708787
Log Pis Std                  1.8045393
Log Pis Max                  6.209449
Log Pis Min                  -4.4610915
Policy mu Mean               -0.03231164
Policy mu Std                0.8463659
Policy mu Max                2.2840896
Policy mu Min                -2.6664865
Policy log std Mean          -0.5204968
Policy log std Std           0.19984697
Policy log std Max           -0.0018665195
Policy log std Min           -1.1777573
Z mean eval                  0.04794191
Z variance eval              0.0036909375
total_rewards                [ 819.65383932 3341.26932367  862.89284603  807.01956223  875.14852126
  874.36267519  846.01672311  837.83720596 1857.99502217  884.48533363]
total_rewards_mean           1200.6681052586061
total_rewards_std            774.4875122739807
total_rewards_max            3341.2693236744926
total_rewards_min            807.019562230389
Number of train steps total  1296000
Number of env steps total    1419229
Number of rollouts total     0
Train Time (s)               150.32252763491124
(Previous) Eval Time (s)     11.181386644952
Sample Time (s)              10.518590758554637
Epoch Time (s)               172.02250503841788
Total Train Time (s)         54099.7671486903
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:32:09.807013 UTC | [2020_01_11_02_30_29] Iteration #323 | Epoch Duration: 172.1119418144226
2020-01-11 17:32:09.807210 UTC | [2020_01_11_02_30_29] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047900982
Z variance train             0.0036927045
KL Divergence                11.629752
KL Loss                      1.1629752
QF Loss                      43.892975
VF Loss                      27.396576
Policy Loss                  -1489.0605
Q Predictions Mean           1489.6375
Q Predictions Std            313.30197
Q Predictions Max            1831.5089
Q Predictions Min            78.874954
V Predictions Mean           1486.324
V Predictions Std            309.52567
V Predictions Max            1825.1345
V Predictions Min            95.56154
Log Pis Mean                 -0.3864277
Log Pis Std                  1.8704934
Log Pis Max                  5.9342437
Log Pis Min                  -7.2413645
Policy mu Mean               -0.05855185
Policy mu Std                0.83729136
Policy mu Max                2.1897104
Policy mu Min                -2.3278854
Policy log std Mean          -0.52113163
Policy log std Std           0.18261659
Policy log std Max           0.008839548
Policy log std Min           -1.1577653
Z mean eval                  0.024754703
Z variance eval              0.0039122617
total_rewards                [ 752.97470656  886.37971184 2704.42643543  767.36696214  826.76994456
  993.4477195   873.82722081 3227.72496839  797.78879183  793.32737384]
total_rewards_mean           1262.4033834902282
total_rewards_std            862.3743937235071
total_rewards_max            3227.7249683902496
total_rewards_min            752.9747065610288
Number of train steps total  1300000
Number of env steps total    1425336
Number of rollouts total     0
Train Time (s)               154.67278281692415
(Previous) Eval Time (s)     12.558167504146695
Sample Time (s)              10.46653849631548
Epoch Time (s)               177.69748881738633
Total Train Time (s)         54277.56501387106
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:35:07.610428 UTC | [2020_01_11_02_30_29] Iteration #324 | Epoch Duration: 177.80302381515503
2020-01-11 17:35:07.610777 UTC | [2020_01_11_02_30_29] Iteration #324 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024735434
Z variance train             0.0039129118
KL Divergence                11.422545
KL Loss                      1.1422546
QF Loss                      38.74314
VF Loss                      12.773687
Policy Loss                  -1464.4304
Q Predictions Mean           1462.9054
Q Predictions Std            335.11542
Q Predictions Max            1819.5581
Q Predictions Min            21.508574
V Predictions Mean           1463.4474
V Predictions Std            333.08832
V Predictions Max            1819.7297
V Predictions Min            35.92181
Log Pis Mean                 -0.3689174
Log Pis Std                  1.8373976
Log Pis Max                  6.5856333
Log Pis Min                  -5.91415
Policy mu Mean               -0.055599272
Policy mu Std                0.83686405
Policy mu Max                2.054212
Policy mu Min                -2.339853
Policy log std Mean          -0.5111788
Policy log std Std           0.19273464
Policy log std Max           0.09256613
Policy log std Min           -1.1831872
Z mean eval                  0.046136737
Z variance eval              0.003950741
total_rewards                [1137.85116623  872.98007547 3364.44890951 1396.93468992  885.3943653
  880.80790708  844.71367437  874.58369438 1749.48288902 1374.95272686]
total_rewards_mean           1338.2150098136913
total_rewards_std            735.4534191817265
total_rewards_max            3364.4489095141867
total_rewards_min            844.7136743712608
Number of train steps total  1304000
Number of env steps total    1431683
Number of rollouts total     0
Train Time (s)               150.0076886001043
(Previous) Eval Time (s)     12.097564185969532
Sample Time (s)              10.381426095496863
Epoch Time (s)               172.4866788815707
Total Train Time (s)         54450.1492578662
Epoch                        325
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:38:00.199702 UTC | [2020_01_11_02_30_29] Iteration #325 | Epoch Duration: 172.58869433403015
2020-01-11 17:38:00.199979 UTC | [2020_01_11_02_30_29] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04499514
Z variance train             0.003946756
KL Divergence                11.457127
KL Loss                      1.1457127
QF Loss                      322.5579
VF Loss                      276.1616
Policy Loss                  -1465.7177
Q Predictions Mean           1466.2517
Q Predictions Std            332.40005
Q Predictions Max            1816.4716
Q Predictions Min            54.40425
V Predictions Mean           1476.2925
V Predictions Std            329.13754
V Predictions Max            1819.5305
V Predictions Min            62.43708
Log Pis Mean                 -0.20575698
Log Pis Std                  1.9654878
Log Pis Max                  5.73058
Log Pis Min                  -3.8448799
Policy mu Mean               -0.031684026
Policy mu Std                0.850125
Policy mu Max                2.4829092
Policy mu Min                -2.5153959
Policy log std Mean          -0.5143092
Policy log std Std           0.18707342
Policy log std Max           0.03896743
Policy log std Min           -1.2425408
Z mean eval                  0.05370499
Z variance eval              0.0039639715
total_rewards                [3438.23780917  844.38097003 1127.05769732 3383.3363296  3356.78310255
  806.9253143  3166.38479103  950.41067494 1132.46346703 2500.78290373]
total_rewards_mean           2070.6763059710984
total_rewards_std            1129.5778670926854
total_rewards_max            3438.2378091652986
total_rewards_min            806.92531430397
Number of train steps total  1308000
Number of env steps total    1437536
Number of rollouts total     0
Train Time (s)               143.80312438542023
(Previous) Eval Time (s)     19.318991832900792
Sample Time (s)              9.152108226902783
Epoch Time (s)               172.2742244452238
Total Train Time (s)         54622.53089884063
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:40:52.590105 UTC | [2020_01_11_02_30_29] Iteration #326 | Epoch Duration: 172.3899631500244
2020-01-11 17:40:52.590290 UTC | [2020_01_11_02_30_29] Iteration #326 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053698618
Z variance train             0.0039657964
KL Divergence                11.498541
KL Loss                      1.1498541
QF Loss                      41.41103
VF Loss                      25.49425
Policy Loss                  -1426.355
Q Predictions Mean           1426.0339
Q Predictions Std            382.1
Q Predictions Max            1831.0106
Q Predictions Min            31.616312
V Predictions Mean           1424.5282
V Predictions Std            381.488
V Predictions Max            1827.8182
V Predictions Min            47.28525
Log Pis Mean                 -0.22089747
Log Pis Std                  1.842821
Log Pis Max                  5.424783
Log Pis Min                  -4.738339
Policy mu Mean               -0.018428905
Policy mu Std                0.8335178
Policy mu Max                2.1967673
Policy mu Min                -2.39877
Policy log std Mean          -0.5195059
Policy log std Std           0.19697228
Policy log std Max           -0.03701991
Policy log std Min           -1.1631912
Z mean eval                  0.049788047
Z variance eval              0.0040737903
total_rewards                [1017.03158005  885.19021045  919.3968747  3370.00146194 3379.9634256
  874.87133127 3373.01689272 3411.63577549  895.11016331  840.32827691]
total_rewards_mean           1896.6545992453507
total_rewards_std            1214.930317638118
total_rewards_max            3411.635775491641
total_rewards_min            840.3282769100473
Number of train steps total  1312000
Number of env steps total    1443913
Number of rollouts total     0
Train Time (s)               142.70132262678817
(Previous) Eval Time (s)     18.545584890060127
Sample Time (s)              9.292037328705192
Epoch Time (s)               170.5389448455535
Total Train Time (s)         54793.149279791396
Epoch                        327
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:43:43.212398 UTC | [2020_01_11_02_30_29] Iteration #327 | Epoch Duration: 170.62195229530334
2020-01-11 17:43:43.212610 UTC | [2020_01_11_02_30_29] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050383657
Z variance train             0.0040737614
KL Divergence                11.315453
KL Loss                      1.1315453
QF Loss                      207.64183
VF Loss                      135.1058
Policy Loss                  -1501.7286
Q Predictions Mean           1503.6177
Q Predictions Std            291.561
Q Predictions Max            1842.269
Q Predictions Min            139.58429
V Predictions Mean           1493.5854
V Predictions Std            289.2639
V Predictions Max            1819.4156
V Predictions Min            129.39828
Log Pis Mean                 -0.023541942
Log Pis Std                  1.9845706
Log Pis Max                  7.6122646
Log Pis Min                  -5.725943
Policy mu Mean               -0.11939609
Policy mu Std                0.9087276
Policy mu Max                2.220627
Policy mu Min                -2.3829565
Policy log std Mean          -0.5253325
Policy log std Std           0.18663126
Policy log std Max           0.08545393
Policy log std Min           -1.0926464
Z mean eval                  0.03216612
Z variance eval              0.0042787604
total_rewards                [1545.00372138 2133.28552379  850.42238373 3402.5594646   843.12510254
  789.79671002  909.88898894  743.54920425  785.73865514 1647.26451768]
total_rewards_mean           1365.0634272088969
total_rewards_std            815.5279861176967
total_rewards_max            3402.559464602332
total_rewards_min            743.5492042547842
Number of train steps total  1316000
Number of env steps total    1450104
Number of rollouts total     0
Train Time (s)               143.27192719932646
(Previous) Eval Time (s)     13.295452597085387
Sample Time (s)              10.132400594651699
Epoch Time (s)               166.69978039106354
Total Train Time (s)         54959.92710914556
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:46:29.993776 UTC | [2020_01_11_02_30_29] Iteration #328 | Epoch Duration: 166.7810206413269
2020-01-11 17:46:29.993968 UTC | [2020_01_11_02_30_29] Iteration #328 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032128267
Z variance train             0.0042757047
KL Divergence                11.170038
KL Loss                      1.1170038
QF Loss                      48.123466
VF Loss                      24.042166
Policy Loss                  -1438.0061
Q Predictions Mean           1437.1372
Q Predictions Std            341.76907
Q Predictions Max            1795.3068
Q Predictions Min            39.98887
V Predictions Mean           1436.8005
V Predictions Std            339.1502
V Predictions Max            1795.2947
V Predictions Min            59.367325
Log Pis Mean                 -0.11026209
Log Pis Std                  1.9851532
Log Pis Max                  6.592819
Log Pis Min                  -5.097127
Policy mu Mean               -0.07344043
Policy mu Std                0.858612
Policy mu Max                2.278713
Policy mu Min                -2.4008992
Policy log std Mean          -0.5262235
Policy log std Std           0.18420151
Policy log std Max           0.15716302
Policy log std Min           -1.1694105
Z mean eval                  0.044453517
Z variance eval              0.0033672503
total_rewards                [1571.46290189 1487.3849918  1397.77657619 1124.74561986 3375.1326019
 1586.29301406 1601.30712047  729.0708647  2375.79329548 3404.15803764]
total_rewards_mean           1865.312502399387
total_rewards_std            856.9127534870755
total_rewards_max            3404.158037643781
total_rewards_min            729.0708647047974
Number of train steps total  1320000
Number of env steps total    1455998
Number of rollouts total     0
Train Time (s)               143.04203281877562
(Previous) Eval Time (s)     16.833809333853424
Sample Time (s)              8.50081691890955
Epoch Time (s)               168.3766590715386
Total Train Time (s)         55128.41120526334
Epoch                        329
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:49:18.481483 UTC | [2020_01_11_02_30_29] Iteration #329 | Epoch Duration: 168.48737406730652
2020-01-11 17:49:18.481680 UTC | [2020_01_11_02_30_29] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044442248
Z variance train             0.0033672254
KL Divergence                11.773218
KL Loss                      1.1773218
QF Loss                      78.750854
VF Loss                      21.786472
Policy Loss                  -1448.9918
Q Predictions Mean           1449.1221
Q Predictions Std            331.50897
Q Predictions Max            1795.9008
Q Predictions Min            56.80688
V Predictions Mean           1449.289
V Predictions Std            331.3936
V Predictions Max            1794.5782
V Predictions Min            66.24374
Log Pis Mean                 -0.1268631
Log Pis Std                  1.8864443
Log Pis Max                  6.505224
Log Pis Min                  -4.320711
Policy mu Mean               -0.06386826
Policy mu Std                0.87986827
Policy mu Max                2.1614041
Policy mu Min                -2.5371878
Policy log std Mean          -0.5575163
Policy log std Std           0.18554588
Policy log std Max           -0.045697093
Policy log std Min           -1.2353029
Z mean eval                  0.025460979
Z variance eval              0.0030364883
total_rewards                [2869.43119841  779.94496997 3394.51746992 1273.89996351  787.07032574
 1909.93178156 1947.10625123 1071.17526561  791.2209883   838.99244297]
total_rewards_mean           1566.3290657224484
total_rewards_std            893.8427932668681
total_rewards_max            3394.5174699166896
total_rewards_min            779.9449699693384
Number of train steps total  1324000
Number of env steps total    1462364
Number of rollouts total     0
Train Time (s)               144.1394131188281
(Previous) Eval Time (s)     16.124524957034737
Sample Time (s)              10.401988995727152
Epoch Time (s)               170.66592707158998
Total Train Time (s)         55299.18012971897
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:52:09.254285 UTC | [2020_01_11_02_30_29] Iteration #330 | Epoch Duration: 170.77245616912842
2020-01-11 17:52:09.254517 UTC | [2020_01_11_02_30_29] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025381768
Z variance train             0.0030368308
KL Divergence                12.061806
KL Loss                      1.2061806
QF Loss                      100.92264
VF Loss                      30.158703
Policy Loss                  -1480.6057
Q Predictions Mean           1479.4729
Q Predictions Std            297.85077
Q Predictions Max            1795.6147
Q Predictions Min            221.71576
V Predictions Mean           1479.0348
V Predictions Std            297.1206
V Predictions Max            1793.2737
V Predictions Min            219.01964
Log Pis Mean                 -0.17307633
Log Pis Std                  1.9407871
Log Pis Max                  7.7719803
Log Pis Min                  -4.0078645
Policy mu Mean               -0.14916837
Policy mu Std                0.8922964
Policy mu Max                2.2086668
Policy mu Min                -2.851978
Policy log std Mean          -0.53305435
Policy log std Std           0.20363685
Policy log std Max           0.07969922
Policy log std Min           -1.4496917
Z mean eval                  0.032534696
Z variance eval              0.003100704
total_rewards                [1898.50453974 2060.73828465  850.69081905 3260.46747904  880.63232908
 1569.36530418 1860.69574863 2004.37130451 1771.7565511   798.84791873]
total_rewards_mean           1695.6070278706065
total_rewards_std            703.5514134006154
total_rewards_max            3260.467479037969
total_rewards_min            798.8479187347046
Number of train steps total  1328000
Number of env steps total    1468647
Number of rollouts total     0
Train Time (s)               143.97162781702355
(Previous) Eval Time (s)     16.798757305834442
Sample Time (s)              10.411241273395717
Epoch Time (s)               171.1816263962537
Total Train Time (s)         55470.44447941519
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:55:00.522287 UTC | [2020_01_11_02_30_29] Iteration #331 | Epoch Duration: 171.26761627197266
2020-01-11 17:55:00.522500 UTC | [2020_01_11_02_30_29] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032678492
Z variance train             0.0030988702
KL Divergence                12.095841
KL Loss                      1.2095841
QF Loss                      50.672184
VF Loss                      31.21571
Policy Loss                  -1465.8683
Q Predictions Mean           1462.8295
Q Predictions Std            320.57428
Q Predictions Max            1802.2957
Q Predictions Min            55.956882
V Predictions Mean           1462.5365
V Predictions Std            321.4125
V Predictions Max            1807.729
V Predictions Min            57.59719
Log Pis Mean                 -0.064506225
Log Pis Std                  2.0433042
Log Pis Max                  7.812275
Log Pis Min                  -4.300319
Policy mu Mean               -0.14860535
Policy mu Std                0.8711347
Policy mu Max                2.140575
Policy mu Min                -2.3811903
Policy log std Mean          -0.49947774
Policy log std Std           0.21046484
Policy log std Max           0.050549984
Policy log std Min           -1.5671957
Z mean eval                  0.029684622
Z variance eval              0.0036636877
total_rewards                [3354.69640709 1757.99749231 1320.50668206  863.19188283 1904.62078834
 1955.37708815 1286.24738356 2075.0763498  2897.52993005  555.77595979]
total_rewards_mean           1797.1019963985364
total_rewards_std            815.6988502229663
total_rewards_max            3354.6964070897493
total_rewards_min            555.775959790041
Number of train steps total  1332000
Number of env steps total    1474826
Number of rollouts total     0
Train Time (s)               143.82391975307837
(Previous) Eval Time (s)     17.510504434350878
Sample Time (s)              10.290481274016201
Epoch Time (s)               171.62490546144545
Total Train Time (s)         55642.14740980556
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:57:52.230472 UTC | [2020_01_11_02_30_29] Iteration #332 | Epoch Duration: 171.70778608322144
2020-01-11 17:57:52.230797 UTC | [2020_01_11_02_30_29] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029772889
Z variance train             0.0036657795
KL Divergence                11.756892
KL Loss                      1.1756892
QF Loss                      91.85219
VF Loss                      38.908543
Policy Loss                  -1447.3684
Q Predictions Mean           1446.0186
Q Predictions Std            330.1006
Q Predictions Max            1793.3555
Q Predictions Min            39.162945
V Predictions Mean           1450.8623
V Predictions Std            331.76016
V Predictions Max            1799.3976
V Predictions Min            31.411095
Log Pis Mean                 -0.3077147
Log Pis Std                  1.7077199
Log Pis Max                  4.8998837
Log Pis Min                  -3.8226237
Policy mu Mean               -0.05309261
Policy mu Std                0.83501524
Policy mu Max                1.7708724
Policy mu Min                -2.4611025
Policy log std Mean          -0.523581
Policy log std Std           0.20056725
Policy log std Max           0.10074633
Policy log std Min           -1.2064469
Z mean eval                  0.048606616
Z variance eval              0.0035848408
total_rewards                [2954.66729653  922.48928156 1391.91861048 3349.29594722 2817.56634805
 3365.57543376  759.95880899 2944.33500799 3374.96242831 3395.09397852]
total_rewards_mean           2527.58631414199
total_rewards_std            1013.8441194688513
total_rewards_max            3395.0939785233118
total_rewards_min            759.9588089910599
Number of train steps total  1336000
Number of env steps total    1480781
Number of rollouts total     0
Train Time (s)               143.7878061560914
(Previous) Eval Time (s)     24.44186775572598
Sample Time (s)              9.7717011468485
Epoch Time (s)               178.00137505866587
Total Train Time (s)         55820.236277189106
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:00:50.323818 UTC | [2020_01_11_02_30_29] Iteration #333 | Epoch Duration: 178.09276747703552
2020-01-11 18:00:50.324152 UTC | [2020_01_11_02_30_29] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04847432
Z variance train             0.0035847332
KL Divergence                11.72917
KL Loss                      1.172917
QF Loss                      51.889843
VF Loss                      16.809692
Policy Loss                  -1504.457
Q Predictions Mean           1504.79
Q Predictions Std            304.74005
Q Predictions Max            1823.8447
Q Predictions Min            46.709133
V Predictions Mean           1503.2284
V Predictions Std            304.12018
V Predictions Max            1818.9902
V Predictions Min            64.58978
Log Pis Mean                 -0.10603985
Log Pis Std                  1.9118919
Log Pis Max                  6.6383147
Log Pis Min                  -5.0170054
Policy mu Mean               -0.06192267
Policy mu Std                0.88523597
Policy mu Max                2.1161504
Policy mu Min                -2.5622869
Policy log std Mean          -0.525304
Policy log std Std           0.19902575
Policy log std Max           0.109847486
Policy log std Min           -1.0686978
Z mean eval                  0.051569093
Z variance eval              0.0031933873
total_rewards                [1007.65914143  827.56985473 2547.07345979 2851.72074851 1251.96764265
  842.8019898  2120.46250813 1607.35380456 2409.57576493 2085.23525723]
total_rewards_mean           1755.1420171762518
total_rewards_std            709.003198924855
total_rewards_max            2851.720748512223
total_rewards_min            827.5698547300615
Number of train steps total  1340000
Number of env steps total    1486887
Number of rollouts total     0
Train Time (s)               142.82637427700683
(Previous) Eval Time (s)     17.201265909243375
Sample Time (s)              10.935711539816111
Epoch Time (s)               170.96335172606632
Total Train Time (s)         55991.315415875055
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:03:41.406178 UTC | [2020_01_11_02_30_29] Iteration #334 | Epoch Duration: 171.08182573318481
2020-01-11 18:03:41.406394 UTC | [2020_01_11_02_30_29] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051609002
Z variance train             0.003195143
KL Divergence                12.059916
KL Loss                      1.2059916
QF Loss                      84.43544
VF Loss                      28.806355
Policy Loss                  -1472.1721
Q Predictions Mean           1474.8065
Q Predictions Std            312.3361
Q Predictions Max            1813.851
Q Predictions Min            167.87732
V Predictions Mean           1473.2996
V Predictions Std            311.7474
V Predictions Max            1801.5182
V Predictions Min            186.21764
Log Pis Mean                 -0.14153516
Log Pis Std                  1.9711448
Log Pis Max                  6.8786263
Log Pis Min                  -5.7453322
Policy mu Mean               -0.04021491
Policy mu Std                0.88215697
Policy mu Max                1.9700199
Policy mu Min                -2.6048071
Policy log std Mean          -0.52329737
Policy log std Std           0.20589791
Policy log std Max           0.17203963
Policy log std Min           -1.2471097
Z mean eval                  0.014203973
Z variance eval              0.0036682128
total_rewards                [3388.08615227 1655.00799376 1289.31393776 2012.51584255 3387.10190377
  892.91610055 3411.18708091 2197.70010568 1322.97946497 3222.97545575]
total_rewards_mean           2277.9784037976124
total_rewards_std            944.0635877568961
total_rewards_max            3411.1870809075717
total_rewards_min            892.9161005520191
Number of train steps total  1344000
Number of env steps total    1493099
Number of rollouts total     0
Train Time (s)               143.71331937424839
(Previous) Eval Time (s)     21.181130876764655
Sample Time (s)              9.972725831437856
Epoch Time (s)               174.8671760824509
Total Train Time (s)         56166.29111768445
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:06:36.385280 UTC | [2020_01_11_02_30_29] Iteration #335 | Epoch Duration: 174.978741645813
2020-01-11 18:06:36.385464 UTC | [2020_01_11_02_30_29] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014218847
Z variance train             0.0036715618
KL Divergence                11.699944
KL Loss                      1.1699944
QF Loss                      128.1977
VF Loss                      40.190815
Policy Loss                  -1479.0675
Q Predictions Mean           1483.8014
Q Predictions Std            288.89554
Q Predictions Max            1782.2916
Q Predictions Min            111.82704
V Predictions Mean           1483.2686
V Predictions Std            285.58374
V Predictions Max            1774.9084
V Predictions Min            126.92891
Log Pis Mean                 -0.25589454
Log Pis Std                  2.0816307
Log Pis Max                  8.525573
Log Pis Min                  -5.4816594
Policy mu Mean               -0.044047397
Policy mu Std                0.85241616
Policy mu Max                2.37912
Policy mu Min                -2.5508418
Policy log std Mean          -0.52902055
Policy log std Std           0.20508993
Policy log std Max           0.08447367
Policy log std Min           -1.2802036
Z mean eval                  0.026725177
Z variance eval              0.0031676262
total_rewards                [1782.16008417  796.8757921  2021.10821709 1832.65599304 1202.23953951
 1140.78503273 1428.88691346 2981.48764926  837.97948869  895.67206982]
total_rewards_mean           1491.9850779871967
total_rewards_std            646.2671408825563
total_rewards_max            2981.4876492629132
total_rewards_min            796.8757920996125
Number of train steps total  1348000
Number of env steps total    1499325
Number of rollouts total     0
Train Time (s)               143.57613091310486
(Previous) Eval Time (s)     13.926985268015414
Sample Time (s)              9.890820203814656
Epoch Time (s)               167.39393638493493
Total Train Time (s)         56333.866711372044
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:09:23.965060 UTC | [2020_01_11_02_30_29] Iteration #336 | Epoch Duration: 167.57943153381348
2020-01-11 18:09:23.965368 UTC | [2020_01_11_02_30_29] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026803862
Z variance train             0.0031674993
KL Divergence                12.04479
KL Loss                      1.2044791
QF Loss                      106.93758
VF Loss                      25.040695
Policy Loss                  -1471.7368
Q Predictions Mean           1468.4883
Q Predictions Std            331.8907
Q Predictions Max            1816.1978
Q Predictions Min            193.4516
V Predictions Mean           1473.3774
V Predictions Std            333.86383
V Predictions Max            1823.9938
V Predictions Min            194.62045
Log Pis Mean                 -0.09444527
Log Pis Std                  1.9192393
Log Pis Max                  6.648069
Log Pis Min                  -4.489753
Policy mu Mean               -0.10178956
Policy mu Std                0.886933
Policy mu Max                2.0289996
Policy mu Min                -2.3516638
Policy log std Mean          -0.533851
Policy log std Std           0.1972279
Policy log std Max           -0.015253365
Policy log std Min           -1.1541965
Z mean eval                  0.02691029
Z variance eval              0.0034200146
total_rewards                [1497.44812812 2213.20069161 1671.57078247  924.05377169 1093.29345195
  973.76045718  809.64963496 1928.58743894 3384.17495796 1129.98972122]
total_rewards_mean           1562.5729036104638
total_rewards_std            749.685975445484
total_rewards_max            3384.1749579596717
total_rewards_min            809.6496349638135
Number of train steps total  1352000
Number of env steps total    1505397
Number of rollouts total     0
Train Time (s)               144.23277426417917
(Previous) Eval Time (s)     15.008000754751265
Sample Time (s)              9.803450494538993
Epoch Time (s)               169.04422551346943
Total Train Time (s)         56503.1112142764
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:12:13.213727 UTC | [2020_01_11_02_30_29] Iteration #337 | Epoch Duration: 169.24812841415405
2020-01-11 18:12:13.213998 UTC | [2020_01_11_02_30_29] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026879486
Z variance train             0.0034196652
KL Divergence                11.944893
KL Loss                      1.1944894
QF Loss                      52.257523
VF Loss                      19.008066
Policy Loss                  -1466.0901
Q Predictions Mean           1463.9121
Q Predictions Std            341.9379
Q Predictions Max            1813.2935
Q Predictions Min            44.15187
V Predictions Mean           1465.5374
V Predictions Std            337.91974
V Predictions Max            1813.9731
V Predictions Min            63.733875
Log Pis Mean                 -0.05153859
Log Pis Std                  1.9410752
Log Pis Max                  5.3842406
Log Pis Min                  -7.747362
Policy mu Mean               -0.06996647
Policy mu Std                0.8774627
Policy mu Max                2.4092572
Policy mu Min                -2.516371
Policy log std Mean          -0.5209518
Policy log std Std           0.19959462
Policy log std Max           0.05049944
Policy log std Min           -1.4515905
Z mean eval                  0.06744836
Z variance eval              0.0031828203
total_rewards                [1170.26541699 1466.10844135  580.21609156 1519.16700631  618.62957935
 1731.00487846 1443.48034714 1732.0398662   976.05558139 1223.76060683]
total_rewards_mean           1246.0727815582682
total_rewards_std            393.636002132678
total_rewards_max            1732.0398661982924
total_rewards_min            580.2160915564898
Number of train steps total  1356000
Number of env steps total    1511490
Number of rollouts total     0
Train Time (s)               142.2730224863626
(Previous) Eval Time (s)     11.994889922905713
Sample Time (s)              9.527667593210936
Epoch Time (s)               163.79558000247926
Total Train Time (s)         56667.00738393515
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:14:57.113386 UTC | [2020_01_11_02_30_29] Iteration #338 | Epoch Duration: 163.89920139312744
2020-01-11 18:14:57.113611 UTC | [2020_01_11_02_30_29] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06746341
Z variance train             0.003182375
KL Divergence                12.068139
KL Loss                      1.2068139
QF Loss                      57.452198
VF Loss                      16.915705
Policy Loss                  -1450.1937
Q Predictions Mean           1449.7886
Q Predictions Std            341.97403
Q Predictions Max            1826.5004
Q Predictions Min            78.05749
V Predictions Mean           1448.5491
V Predictions Std            339.78415
V Predictions Max            1824.3617
V Predictions Min            73.22544
Log Pis Mean                 0.02949509
Log Pis Std                  2.0614927
Log Pis Max                  7.0059204
Log Pis Min                  -4.8003216
Policy mu Mean               -0.16081484
Policy mu Std                0.8612416
Policy mu Max                2.202924
Policy mu Min                -2.7674534
Policy log std Mean          -0.5372967
Policy log std Std           0.21997772
Policy log std Max           0.045173705
Policy log std Min           -1.3214579
Z mean eval                  0.03742594
Z variance eval              0.0036985062
total_rewards                [1195.74087875  898.99014558  838.27945095 3417.1137748  1253.84805525
  905.22445608  917.59285249 2115.80788331 2822.81375276 1996.94569812]
total_rewards_mean           1636.2356948084027
total_rewards_std            866.6568834698415
total_rewards_max            3417.113774795768
total_rewards_min            838.2794509524788
Number of train steps total  1360000
Number of env steps total    1517649
Number of rollouts total     0
Train Time (s)               143.12977043027058
(Previous) Eval Time (s)     15.409661769866943
Sample Time (s)              10.113992934115231
Epoch Time (s)               168.65342513425276
Total Train Time (s)         56835.73977598408
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:17:45.849598 UTC | [2020_01_11_02_30_29] Iteration #339 | Epoch Duration: 168.73583602905273
2020-01-11 18:17:45.849804 UTC | [2020_01_11_02_30_29] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037405703
Z variance train             0.003699274
KL Divergence                11.709234
KL Loss                      1.1709235
QF Loss                      47.202156
VF Loss                      17.331425
Policy Loss                  -1442.0306
Q Predictions Mean           1443.087
Q Predictions Std            360.19736
Q Predictions Max            1844.2162
Q Predictions Min            31.23546
V Predictions Mean           1443.0488
V Predictions Std            360.07352
V Predictions Max            1840.4382
V Predictions Min            25.927921
Log Pis Mean                 -0.07923891
Log Pis Std                  1.9350569
Log Pis Max                  6.4101224
Log Pis Min                  -5.1526165
Policy mu Mean               -0.062479455
Policy mu Std                0.88073665
Policy mu Max                2.319515
Policy mu Min                -2.5846584
Policy log std Mean          -0.518092
Policy log std Std           0.20281327
Policy log std Max           0.21186644
Policy log std Min           -1.217027
Z mean eval                  0.044472568
Z variance eval              0.0038683526
total_rewards                [2255.15862011 2108.09916005 1403.70375949 1139.88926109 1759.84294007
 1940.432677   1868.80309544 1195.55019934 1050.38818947 3108.47042661]
total_rewards_mean           1783.0338328690552
total_rewards_std            596.4438723780992
total_rewards_max            3108.470426614762
total_rewards_min            1050.3881894731426
Number of train steps total  1364000
Number of env steps total    1524913
Number of rollouts total     0
Train Time (s)               150.12146720802411
(Previous) Eval Time (s)     17.838739048223943
Sample Time (s)              11.036578981205821
Epoch Time (s)               178.99678523745388
Total Train Time (s)         57014.862923074514
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:20:44.976789 UTC | [2020_01_11_02_30_29] Iteration #340 | Epoch Duration: 179.12683582305908
2020-01-11 18:20:44.977013 UTC | [2020_01_11_02_30_29] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04426869
Z variance train             0.003868873
KL Divergence                11.557262
KL Loss                      1.1557263
QF Loss                      33.992348
VF Loss                      16.395159
Policy Loss                  -1459.3843
Q Predictions Mean           1459.079
Q Predictions Std            329.62726
Q Predictions Max            1803.4863
Q Predictions Min            95.048584
V Predictions Mean           1461.5339
V Predictions Std            327.6111
V Predictions Max            1807.8694
V Predictions Min            141.68314
Log Pis Mean                 -0.45052773
Log Pis Std                  1.9653409
Log Pis Max                  5.884056
Log Pis Min                  -5.761569
Policy mu Mean               -0.039395254
Policy mu Std                0.8322311
Policy mu Max                2.3015394
Policy mu Min                -2.4210029
Policy log std Mean          -0.52255386
Policy log std Std           0.19266407
Policy log std Max           0.25721508
Policy log std Min           -1.0559843
Z mean eval                  0.025959864
Z variance eval              0.00344708
total_rewards                [ 953.31462686 1148.86758633 1494.13755978 3300.72456256 1183.41298037
 1184.77719968  953.20661837 1747.82264779  884.72566147  924.67602816]
total_rewards_mean           1377.566547137246
total_rewards_std            691.6975270855354
total_rewards_max            3300.7245625614805
total_rewards_min            884.7256614734616
Number of train steps total  1368000
Number of env steps total    1531543
Number of rollouts total     0
Train Time (s)               152.22123574325815
(Previous) Eval Time (s)     13.45140996715054
Sample Time (s)              10.132144031580538
Epoch Time (s)               175.80478974198923
Total Train Time (s)         57190.78567370493
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:23:40.903577 UTC | [2020_01_11_02_30_29] Iteration #341 | Epoch Duration: 175.92641019821167
2020-01-11 18:23:40.903800 UTC | [2020_01_11_02_30_29] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025755981
Z variance train             0.0034479909
KL Divergence                11.907754
KL Loss                      1.1907754
QF Loss                      57.25197
VF Loss                      15.752719
Policy Loss                  -1480.2681
Q Predictions Mean           1481.627
Q Predictions Std            296.69275
Q Predictions Max            1821.8002
Q Predictions Min            70.6583
V Predictions Mean           1481.5842
V Predictions Std            296.4128
V Predictions Max            1821.8381
V Predictions Min            86.02465
Log Pis Mean                 -0.27324623
Log Pis Std                  1.7872368
Log Pis Max                  6.4499764
Log Pis Min                  -5.3617005
Policy mu Mean               -0.09622923
Policy mu Std                0.81619185
Policy mu Max                1.9094731
Policy mu Min                -2.4920769
Policy log std Mean          -0.50888544
Policy log std Std           0.21002887
Policy log std Max           0.16343564
Policy log std Min           -1.2951771
Z mean eval                  0.037540715
Z variance eval              0.0033965218
total_rewards                [ 819.24713394  711.9946836  1272.50295566 1738.22989135 2194.59512356
 1286.80555857  991.01794043  931.51494332 1448.41879005 1584.56700397]
total_rewards_mean           1297.889402445887
total_rewards_std            436.3900485528125
total_rewards_max            2194.5951235631737
total_rewards_min            711.9946835957115
Number of train steps total  1372000
Number of env steps total    1538516
Number of rollouts total     0
Train Time (s)               151.44860836304724
(Previous) Eval Time (s)     12.90280045196414
Sample Time (s)              10.431349596939981
Epoch Time (s)               174.78275841195136
Total Train Time (s)         57365.7011775705
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:26:35.824504 UTC | [2020_01_11_02_30_29] Iteration #342 | Epoch Duration: 174.92052793502808
2020-01-11 18:26:35.824870 UTC | [2020_01_11_02_30_29] Iteration #342 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03697278
Z variance train             0.0033990468
KL Divergence                11.799866
KL Loss                      1.1799866
QF Loss                      58.541183
VF Loss                      62.530945
Policy Loss                  -1493.4022
Q Predictions Mean           1493.8132
Q Predictions Std            312.17947
Q Predictions Max            1836.2135
Q Predictions Min            40.405403
V Predictions Mean           1496.7253
V Predictions Std            311.33502
V Predictions Max            1837.936
V Predictions Min            75.22623
Log Pis Mean                 -0.1415503
Log Pis Std                  2.0923538
Log Pis Max                  6.641401
Log Pis Min                  -6.68291
Policy mu Mean               -0.1267321
Policy mu Std                0.8635594
Policy mu Max                2.4035776
Policy mu Min                -2.8921494
Policy log std Mean          -0.5334672
Policy log std Std           0.21362342
Policy log std Max           -0.012273073
Policy log std Min           -1.3999631
Z mean eval                  0.03090996
Z variance eval              0.0037220672
total_rewards                [2972.75506971 1506.87884947  686.88889387 1053.47787124 2864.2627895
  859.00963238 1311.83748652  910.88197529 2383.43062525  917.29450531]
total_rewards_mean           1546.6717698546338
total_rewards_std            823.5500049896256
total_rewards_max            2972.7550697140477
total_rewards_min            686.8888938742169
Number of train steps total  1376000
Number of env steps total    1545835
Number of rollouts total     0
Train Time (s)               152.84910758119076
(Previous) Eval Time (s)     15.355547714047134
Sample Time (s)              10.241967637557536
Epoch Time (s)               178.44662293279544
Total Train Time (s)         57544.26151025761
Epoch                        343
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:29:34.388923 UTC | [2020_01_11_02_30_29] Iteration #343 | Epoch Duration: 178.56383109092712
2020-01-11 18:29:34.389207 UTC | [2020_01_11_02_30_29] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030706042
Z variance train             0.003721082
KL Divergence                11.612812
KL Loss                      1.1612812
QF Loss                      64.90903
VF Loss                      26.513756
Policy Loss                  -1490.2262
Q Predictions Mean           1490.3572
Q Predictions Std            326.19507
Q Predictions Max            1818.7664
Q Predictions Min            75.96104
V Predictions Mean           1487.9044
V Predictions Std            325.23264
V Predictions Max            1819.6829
V Predictions Min            98.397606
Log Pis Mean                 -0.106627166
Log Pis Std                  1.9855138
Log Pis Max                  6.5794353
Log Pis Min                  -7.160779
Policy mu Mean               -0.16617408
Policy mu Std                0.8679013
Policy mu Max                2.004999
Policy mu Min                -2.6027532
Policy log std Mean          -0.54085964
Policy log std Std           0.20721702
Policy log std Max           0.060365677
Policy log std Min           -1.4519999
Z mean eval                  0.033405207
Z variance eval              0.004399949
total_rewards                [1578.40671797  947.79395203 1582.57453349 2052.96533234 2554.51816071
 1688.81261673 1833.4363397  1481.2829078  1844.76736877 1016.57383645]
total_rewards_mean           1658.1131765988298
total_rewards_std            445.5810645543274
total_rewards_max            2554.518160713589
total_rewards_min            947.7939520310204
Number of train steps total  1380000
Number of env steps total    1552571
Number of rollouts total     0
Train Time (s)               152.66001038905233
(Previous) Eval Time (s)     16.30101221287623
Sample Time (s)              9.39015434263274
Epoch Time (s)               178.3511769445613
Total Train Time (s)         57722.755332142115
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:32:32.887518 UTC | [2020_01_11_02_30_29] Iteration #344 | Epoch Duration: 178.4980878829956
2020-01-11 18:32:32.887968 UTC | [2020_01_11_02_30_29] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03351856
Z variance train             0.004400461
KL Divergence                11.151374
KL Loss                      1.1151375
QF Loss                      46.662453
VF Loss                      11.904257
Policy Loss                  -1445.9717
Q Predictions Mean           1445.8127
Q Predictions Std            351.0335
Q Predictions Max            1828.747
Q Predictions Min            52.01625
V Predictions Mean           1445.987
V Predictions Std            347.80777
V Predictions Max            1820.8145
V Predictions Min            67.871735
Log Pis Mean                 -0.07037919
Log Pis Std                  1.905754
Log Pis Max                  7.3018203
Log Pis Min                  -4.8500466
Policy mu Mean               -0.11402521
Policy mu Std                0.8666202
Policy mu Max                2.3825219
Policy mu Min                -2.7375572
Policy log std Mean          -0.51313347
Policy log std Std           0.22610378
Policy log std Max           0.18006015
Policy log std Min           -1.5081501
Z mean eval                  0.050559215
Z variance eval              0.0043697255
total_rewards                [ 992.79177681 1164.49865405 1047.55987079  874.78134401 1108.55020797
 1089.17474044 1248.0444829  1411.43777958  331.419184    620.09718749]
total_rewards_mean           988.835522803323
total_rewards_std            297.6030597462722
total_rewards_max            1411.4377795833911
total_rewards_min            331.4191839964217
Number of train steps total  1384000
Number of env steps total    1559101
Number of rollouts total     0
Train Time (s)               143.6968829156831
(Previous) Eval Time (s)     9.250175103079528
Sample Time (s)              8.498083143495023
Epoch Time (s)               161.44514116225764
Total Train Time (s)         57884.29035333684
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:35:14.426738 UTC | [2020_01_11_02_30_29] Iteration #345 | Epoch Duration: 161.53848266601562
2020-01-11 18:35:14.427002 UTC | [2020_01_11_02_30_29] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05067767
Z variance train             0.004367332
KL Divergence                11.231249
KL Loss                      1.123125
QF Loss                      119.74024
VF Loss                      70.73518
Policy Loss                  -1487.5553
Q Predictions Mean           1488.3943
Q Predictions Std            309.40326
Q Predictions Max            1837.1982
Q Predictions Min            12.7254095
V Predictions Mean           1481.6089
V Predictions Std            308.00458
V Predictions Max            1831.912
V Predictions Min            43.048084
Log Pis Mean                 -0.2624932
Log Pis Std                  1.8647555
Log Pis Max                  5.0756526
Log Pis Min                  -5.914749
Policy mu Mean               -0.13823777
Policy mu Std                0.8582415
Policy mu Max                2.791561
Policy mu Min                -2.4851873
Policy log std Mean          -0.50625104
Policy log std Std           0.22617422
Policy log std Max           0.25370175
Policy log std Min           -1.270935
Z mean eval                  0.013368617
Z variance eval              0.004102266
total_rewards                [ 922.07560448  926.87114208  845.09595968 1643.3665847  2739.91915654
 1038.3635556  3401.10176736 1943.24067072 1634.90906834 3414.87502362]
total_rewards_mean           1850.9818533130951
total_rewards_std            955.3087834418759
total_rewards_max            3414.8750236192764
total_rewards_min            845.0959596779192
Number of train steps total  1388000
Number of env steps total    1566133
Number of rollouts total     0
Train Time (s)               143.6741005210206
(Previous) Eval Time (s)     17.610919523984194
Sample Time (s)              10.140169341117144
Epoch Time (s)               171.42518938612193
Total Train Time (s)         58056.07110587647
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:38:06.210673 UTC | [2020_01_11_02_30_29] Iteration #346 | Epoch Duration: 171.78350162506104
2020-01-11 18:38:06.210906 UTC | [2020_01_11_02_30_29] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013060774
Z variance train             0.0040947013
KL Divergence                11.5392685
KL Loss                      1.1539268
QF Loss                      106.93404
VF Loss                      183.68204
Policy Loss                  -1494.958
Q Predictions Mean           1500.8434
Q Predictions Std            267.53088
Q Predictions Max            1829.3281
Q Predictions Min            37.245995
V Predictions Mean           1506.3418
V Predictions Std            269.61725
V Predictions Max            1838.9896
V Predictions Min            59.206993
Log Pis Mean                 -0.30968866
Log Pis Std                  1.9271255
Log Pis Max                  6.5549936
Log Pis Min                  -7.1316633
Policy mu Mean               -0.043521088
Policy mu Std                0.8404004
Policy mu Max                2.223723
Policy mu Min                -2.2635596
Policy log std Mean          -0.5028514
Policy log std Std           0.22575104
Policy log std Max           0.058725536
Policy log std Min           -1.3217378
Z mean eval                  0.114739135
Z variance eval              0.004108171
total_rewards                [2101.96531068 1104.97586223 1928.7978123   582.74848086 1904.46729732
 1951.01974149 1822.07020209  870.84133202 1295.9642852   875.15218493]
total_rewards_mean           1443.8002509123003
total_rewards_std            530.1592129914245
total_rewards_max            2101.9653106809383
total_rewards_min            582.7484808602817
Number of train steps total  1392000
Number of env steps total    1573199
Number of rollouts total     0
Train Time (s)               142.50908441701904
(Previous) Eval Time (s)     12.346682927105576
Sample Time (s)              11.124657911714166
Epoch Time (s)               165.98042525583878
Total Train Time (s)         58222.27428681869
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:40:52.417709 UTC | [2020_01_11_02_30_29] Iteration #347 | Epoch Duration: 166.20665168762207
2020-01-11 18:40:52.417951 UTC | [2020_01_11_02_30_29] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.114749
Z variance train             0.0041064555
KL Divergence                11.559467
KL Loss                      1.1559467
QF Loss                      44.97262
VF Loss                      14.838648
Policy Loss                  -1468.6106
Q Predictions Mean           1468.1517
Q Predictions Std            340.0272
Q Predictions Max            1808.4082
Q Predictions Min            60.93171
V Predictions Mean           1466.9087
V Predictions Std            338.9433
V Predictions Max            1807.5725
V Predictions Min            57.72728
Log Pis Mean                 -0.4672665
Log Pis Std                  1.7695026
Log Pis Max                  5.804829
Log Pis Min                  -4.5426702
Policy mu Mean               -0.059249032
Policy mu Std                0.80319273
Policy mu Max                2.2341883
Policy mu Min                -2.3554282
Policy log std Mean          -0.4965875
Policy log std Std           0.18751559
Policy log std Max           0.13104045
Policy log std Min           -1.1405817
Z mean eval                  0.027019396
Z variance eval              0.004306306
total_rewards                [3397.49085099  828.50920109 2222.99842617 2493.21639278 3291.60905728
 2256.52045778  741.32121418  816.19236729 1927.98162274  825.21669803]
total_rewards_mean           1880.105628834704
total_rewards_std            978.7567332501957
total_rewards_max            3397.4908509891084
total_rewards_min            741.3212141806374
Number of train steps total  1396000
Number of env steps total    1580300
Number of rollouts total     0
Train Time (s)               143.9951219027862
(Previous) Eval Time (s)     18.175844537559897
Sample Time (s)              10.559568678028882
Epoch Time (s)               172.73053511837497
Total Train Time (s)         58395.08597503323
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:43:45.233144 UTC | [2020_01_11_02_30_29] Iteration #348 | Epoch Duration: 172.81503653526306
2020-01-11 18:43:45.233389 UTC | [2020_01_11_02_30_29] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026501289
Z variance train             0.0043075653
KL Divergence                11.288975
KL Loss                      1.1288975
QF Loss                      72.99833
VF Loss                      30.347744
Policy Loss                  -1518.0916
Q Predictions Mean           1514.8683
Q Predictions Std            298.3406
Q Predictions Max            1853.3209
Q Predictions Min            45.41525
V Predictions Mean           1520.5673
V Predictions Std            296.15204
V Predictions Max            1846.3064
V Predictions Min            52.15452
Log Pis Mean                 -0.27376795
Log Pis Std                  1.7763917
Log Pis Max                  5.8531504
Log Pis Min                  -4.762735
Policy mu Mean               -0.030063285
Policy mu Std                0.8540712
Policy mu Max                1.9797409
Policy mu Min                -2.3088224
Policy log std Mean          -0.4963688
Policy log std Std           0.19180404
Policy log std Max           0.0951944
Policy log std Min           -1.6901879
Z mean eval                  0.027738228
Z variance eval              0.004668467
total_rewards                [3404.98348255 3426.92133682 3420.99255385 3413.26558353  751.01005166
 3432.77649883 1671.65297428 3395.61994641 1635.12922634 2176.47383824]
total_rewards_mean           2672.8825492504575
total_rewards_std            966.0009405984158
total_rewards_max            3432.776498830819
total_rewards_min            751.010051655173
Number of train steps total  1400000
Number of env steps total    1587217
Number of rollouts total     0
Train Time (s)               143.2892342871055
(Previous) Eval Time (s)     24.950311245862395
Sample Time (s)              10.311083247419447
Epoch Time (s)               178.55062878038734
Total Train Time (s)         58573.719063145574
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:46:43.870702 UTC | [2020_01_11_02_30_29] Iteration #349 | Epoch Duration: 178.6371464729309
2020-01-11 18:46:43.870953 UTC | [2020_01_11_02_30_29] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027651304
Z variance train             0.0046670996
KL Divergence                11.019705
KL Loss                      1.1019706
QF Loss                      79.85057
VF Loss                      27.146894
Policy Loss                  -1499.3848
Q Predictions Mean           1497.758
Q Predictions Std            301.1396
Q Predictions Max            1805.9137
Q Predictions Min            232.02934
V Predictions Mean           1496.4324
V Predictions Std            299.07498
V Predictions Max            1799.0771
V Predictions Min            224.60933
Log Pis Mean                 -0.20444891
Log Pis Std                  1.8450918
Log Pis Max                  5.7906156
Log Pis Min                  -4.8640494
Policy mu Mean               -0.046151403
Policy mu Std                0.84756976
Policy mu Max                2.138533
Policy mu Min                -2.4077532
Policy log std Mean          -0.52637047
Policy log std Std           0.21310459
Policy log std Max           0.2222504
Policy log std Min           -1.511272
Z mean eval                  0.032556638
Z variance eval              0.004342119
total_rewards                [1119.73234817  815.82787629  921.64809921  608.06990711  851.90877106
  835.29984997 1087.42738827  774.23412431 1679.4875155   835.51023775]
total_rewards_mean           952.9146117651823
total_rewards_std            279.6898608322573
total_rewards_max            1679.48751550149
total_rewards_min            608.0699071091143
Number of train steps total  1404000
Number of env steps total    1593773
Number of rollouts total     0
Train Time (s)               143.98012155015022
(Previous) Eval Time (s)     9.663072945084423
Sample Time (s)              8.888331413269043
Epoch Time (s)               162.53152590850368
Total Train Time (s)         58736.33692114288
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:49:26.493239 UTC | [2020_01_11_02_30_29] Iteration #350 | Epoch Duration: 162.62211227416992
2020-01-11 18:49:26.493541 UTC | [2020_01_11_02_30_29] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03247638
Z variance train             0.004341581
KL Divergence                11.302925
KL Loss                      1.1302925
QF Loss                      32.27311
VF Loss                      20.442417
Policy Loss                  -1512.1003
Q Predictions Mean           1512.2891
Q Predictions Std            276.54367
Q Predictions Max            1825.5793
Q Predictions Min            180.99643
V Predictions Mean           1511.2286
V Predictions Std            274.02917
V Predictions Max            1822.9891
V Predictions Min            207.81557
Log Pis Mean                 -0.15339714
Log Pis Std                  1.9340875
Log Pis Max                  7.0579166
Log Pis Min                  -5.282936
Policy mu Mean               -0.053325776
Policy mu Std                0.8405538
Policy mu Max                2.3145137
Policy mu Min                -2.4598353
Policy log std Mean          -0.4782664
Policy log std Std           0.2094299
Policy log std Max           0.19748741
Policy log std Min           -1.2270678
Z mean eval                  0.024627017
Z variance eval              0.0037538572
total_rewards                [3429.29182777 1443.18015134 3394.07623989  910.15681104 3410.19160353
 3405.34866194  969.67515643 1261.83200196  989.14431682  903.96997561]
total_rewards_mean           2011.6866746323417
total_rewards_std            1152.2144744695001
total_rewards_max            3429.291827770921
total_rewards_min            903.9699756128496
Number of train steps total  1408000
Number of env steps total    1601081
Number of rollouts total     0
Train Time (s)               143.43993011908606
(Previous) Eval Time (s)     19.107173887081444
Sample Time (s)              10.038826537318528
Epoch Time (s)               172.58593054348603
Total Train Time (s)         58909.027212816756
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:52:19.186915 UTC | [2020_01_11_02_30_29] Iteration #351 | Epoch Duration: 172.693208694458
2020-01-11 18:52:19.187108 UTC | [2020_01_11_02_30_29] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024844822
Z variance train             0.0037540204
KL Divergence                11.556015
KL Loss                      1.1556015
QF Loss                      38.851936
VF Loss                      13.532889
Policy Loss                  -1487.6425
Q Predictions Mean           1487.9072
Q Predictions Std            278.63486
Q Predictions Max            1815.0696
Q Predictions Min            62.065063
V Predictions Mean           1488.7477
V Predictions Std            274.96085
V Predictions Max            1813.5634
V Predictions Min            111.24199
Log Pis Mean                 -0.06396586
Log Pis Std                  2.0524511
Log Pis Max                  7.2734227
Log Pis Min                  -5.2145743
Policy mu Mean               -0.079108484
Policy mu Std                0.8789264
Policy mu Max                2.182708
Policy mu Min                -2.3680966
Policy log std Mean          -0.5004769
Policy log std Std           0.20731433
Policy log std Max           0.028147697
Policy log std Min           -1.3316088
Z mean eval                  0.05232314
Z variance eval              0.0035034618
total_rewards                [1551.46135568 1411.9559702  2229.42033876 2043.93647496  821.92698406
 1222.05297096 2255.15663163 1641.27885611 2508.88357428 2440.61009431]
total_rewards_mean           1812.6683250945746
total_rewards_std            537.639131935412
total_rewards_max            2508.88357428092
total_rewards_min            821.9269840593137
Number of train steps total  1412000
Number of env steps total    1608116
Number of rollouts total     0
Train Time (s)               143.36056847823784
(Previous) Eval Time (s)     17.893173975404352
Sample Time (s)              9.797743500210345
Epoch Time (s)               171.05148595385253
Total Train Time (s)         59080.16441122396
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:55:10.328438 UTC | [2020_01_11_02_30_29] Iteration #352 | Epoch Duration: 171.14114546775818
2020-01-11 18:55:10.328660 UTC | [2020_01_11_02_30_29] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052179445
Z variance train             0.0035016797
KL Divergence                11.712033
KL Loss                      1.1712034
QF Loss                      22380.865
VF Loss                      41.00938
Policy Loss                  -1506.8898
Q Predictions Mean           1511.3458
Q Predictions Std            274.90536
Q Predictions Max            1811.0449
Q Predictions Min            243.50645
V Predictions Mean           1509.6713
V Predictions Std            270.60916
V Predictions Max            1804.9114
V Predictions Min            232.39438
Log Pis Mean                 -0.026119806
Log Pis Std                  2.1958232
Log Pis Max                  8.457305
Log Pis Min                  -4.8135853
Policy mu Mean               -0.20369108
Policy mu Std                0.8862434
Policy mu Max                2.0120175
Policy mu Min                -2.70146
Policy log std Mean          -0.51122016
Policy log std Std           0.21647827
Policy log std Max           0.2307893
Policy log std Min           -1.6448257
Z mean eval                  0.021583345
Z variance eval              0.0038220542
total_rewards                [3441.39153724 3415.26154446 3382.95371195  974.29917304  707.55089215
 1252.59586312  734.6131438  1814.42019183 1279.62558571  719.06692754]
total_rewards_mean           1772.1778570836836
total_rewards_std            1120.2936626066837
total_rewards_max            3441.391537240779
total_rewards_min            707.5508921469283
Number of train steps total  1416000
Number of env steps total    1614970
Number of rollouts total     0
Train Time (s)               143.46980987582356
(Previous) Eval Time (s)     17.524722160305828
Sample Time (s)              9.807159151881933
Epoch Time (s)               170.80169118801132
Total Train Time (s)         59251.05496477382
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:58:01.222268 UTC | [2020_01_11_02_30_29] Iteration #353 | Epoch Duration: 170.8934154510498
2020-01-11 18:58:01.222731 UTC | [2020_01_11_02_30_29] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02151946
Z variance train             0.0038258329
KL Divergence                11.459358
KL Loss                      1.1459359
QF Loss                      240.45772
VF Loss                      96.668274
Policy Loss                  -1544.275
Q Predictions Mean           1539.1992
Q Predictions Std            241.16803
Q Predictions Max            1829.3788
Q Predictions Min            122.12252
V Predictions Mean           1541.0483
V Predictions Std            239.82378
V Predictions Max            1822.1318
V Predictions Min            176.16087
Log Pis Mean                 -0.06557126
Log Pis Std                  2.0925944
Log Pis Max                  7.34931
Log Pis Min                  -5.31586
Policy mu Mean               -0.18074548
Policy mu Std                0.87810886
Policy mu Max                2.045631
Policy mu Min                -2.5032291
Policy log std Mean          -0.5306656
Policy log std Std           0.20851168
Policy log std Max           0.14238304
Policy log std Min           -1.4084494
Z mean eval                  0.039764114
Z variance eval              0.0037378415
total_rewards                [ 932.20561197 3406.80593901  788.7659372  1729.76951205 1800.15063549
  965.35774793 3410.90772807  747.15151017 2884.22166452  747.52357971]
total_rewards_mean           1741.2859866129984
total_rewards_std            1049.3488608978225
total_rewards_max            3410.907728073626
total_rewards_min            747.1515101658603
Number of train steps total  1420000
Number of env steps total    1622566
Number of rollouts total     0
Train Time (s)               143.9847476533614
(Previous) Eval Time (s)     14.74142783600837
Sample Time (s)              9.176101258955896
Epoch Time (s)               167.90227674832568
Total Train Time (s)         59419.042457481846
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:00:49.213649 UTC | [2020_01_11_02_30_29] Iteration #354 | Epoch Duration: 167.99073553085327
2020-01-11 19:00:49.213871 UTC | [2020_01_11_02_30_29] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039576054
Z variance train             0.0037386357
KL Divergence                11.547306
KL Loss                      1.1547307
QF Loss                      30.276527
VF Loss                      18.360615
Policy Loss                  -1514.2974
Q Predictions Mean           1513.53
Q Predictions Std            303.17975
Q Predictions Max            1836.2845
Q Predictions Min            111.4813
V Predictions Mean           1514.4303
V Predictions Std            303.68076
V Predictions Max            1839.47
V Predictions Min            108.27783
Log Pis Mean                 -0.42862946
Log Pis Std                  1.934642
Log Pis Max                  7.744627
Log Pis Min                  -5.8779254
Policy mu Mean               -0.1067575
Policy mu Std                0.8007294
Policy mu Max                1.6318691
Policy mu Min                -3.6376228
Policy log std Mean          -0.4996659
Policy log std Std           0.20055762
Policy log std Max           -0.026918858
Policy log std Min           -1.1401464
Z mean eval                  0.035571836
Z variance eval              0.0036917082
total_rewards                [1958.41688202  959.24634327  936.60561026  715.43748584  924.29054437
  891.96627283  965.3277019   921.58622008  961.79981589 1565.79346558]
total_rewards_mean           1080.04703420514
total_rewards_std            358.81454448162486
total_rewards_max            1958.416882022478
total_rewards_min            715.4374858448472
Number of train steps total  1424000
Number of env steps total    1629692
Number of rollouts total     0
Train Time (s)               144.9099001036957
(Previous) Eval Time (s)     10.528634270653129
Sample Time (s)              10.701287840958685
Epoch Time (s)               166.1398222153075
Total Train Time (s)         59585.36501115281
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:03:35.540394 UTC | [2020_01_11_02_30_29] Iteration #355 | Epoch Duration: 166.3262221813202
2020-01-11 19:03:35.540633 UTC | [2020_01_11_02_30_29] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035540488
Z variance train             0.0036875035
KL Divergence                11.562962
KL Loss                      1.1562961
QF Loss                      58.175686
VF Loss                      22.098658
Policy Loss                  -1517.2405
Q Predictions Mean           1516.3357
Q Predictions Std            329.8215
Q Predictions Max            1836.7549
Q Predictions Min            85.52352
V Predictions Mean           1515.1664
V Predictions Std            326.78278
V Predictions Max            1835.4005
V Predictions Min            78.247475
Log Pis Mean                 -0.31239802
Log Pis Std                  1.855382
Log Pis Max                  6.069094
Log Pis Min                  -6.8732524
Policy mu Mean               0.0035530876
Policy mu Std                0.84215015
Policy mu Max                2.7367709
Policy mu Min                -2.7375557
Policy log std Mean          -0.5122289
Policy log std Std           0.20371655
Policy log std Max           0.31206173
Policy log std Min           -1.8453774
Z mean eval                  0.03455379
Z variance eval              0.003918683
total_rewards                [1187.57853094  971.57272089 1197.22586695  993.53160673 1268.18383068
 2230.60759442 1203.11799139 1219.70654332  963.06540948 1135.86359948]
total_rewards_mean           1237.0453694288522
total_rewards_std            347.66322932118715
total_rewards_max            2230.6075944181644
total_rewards_min            963.0654094816604
Number of train steps total  1428000
Number of env steps total    1636730
Number of rollouts total     0
Train Time (s)               143.32855666521937
(Previous) Eval Time (s)     10.140247299801558
Sample Time (s)              10.262152978684753
Epoch Time (s)               163.73095694370568
Total Train Time (s)         59749.1873812112
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:06:19.366913 UTC | [2020_01_11_02_30_29] Iteration #356 | Epoch Duration: 163.82611274719238
2020-01-11 19:06:19.367158 UTC | [2020_01_11_02_30_29] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03451727
Z variance train             0.003920534
KL Divergence                11.436577
KL Loss                      1.1436577
QF Loss                      101.80914
VF Loss                      19.825474
Policy Loss                  -1469.0287
Q Predictions Mean           1468.489
Q Predictions Std            381.9813
Q Predictions Max            1838.8977
Q Predictions Min            72.99282
V Predictions Mean           1467.904
V Predictions Std            380.35202
V Predictions Max            1838.2155
V Predictions Min            72.42142
Log Pis Mean                 -0.2921681
Log Pis Std                  1.8742068
Log Pis Max                  6.803014
Log Pis Min                  -9.385268
Policy mu Mean               -0.027362844
Policy mu Std                0.83850354
Policy mu Max                2.3527343
Policy mu Min                -2.1569302
Policy log std Mean          -0.54635626
Policy log std Std           0.20229276
Policy log std Max           0.21584916
Policy log std Min           -1.5979668
Z mean eval                  0.028722484
Z variance eval              0.003952262
total_rewards                [ 949.40877099  938.39589803 3435.9426362  1395.9028902   920.33707884
 1739.88606714 3346.93026765  756.15747392  986.41937838 1886.18219442]
total_rewards_mean           1635.5562655761112
total_rewards_std            946.8059063561079
total_rewards_max            3435.9426362011122
total_rewards_min            756.1574739153258
Number of train steps total  1432000
Number of env steps total    1643603
Number of rollouts total     0
Train Time (s)               144.7589490772225
(Previous) Eval Time (s)     15.618026483338326
Sample Time (s)              10.03964778734371
Epoch Time (s)               170.41662334790453
Total Train Time (s)         59919.68841342069
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:09:09.872027 UTC | [2020_01_11_02_30_29] Iteration #357 | Epoch Duration: 170.50466585159302
2020-01-11 19:09:09.872268 UTC | [2020_01_11_02_30_29] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028900912
Z variance train             0.003952579
KL Divergence                11.390088
KL Loss                      1.1390089
QF Loss                      50.64588
VF Loss                      22.544127
Policy Loss                  -1513.4906
Q Predictions Mean           1514.7825
Q Predictions Std            324.3934
Q Predictions Max            1838.9971
Q Predictions Min            151.0942
V Predictions Mean           1513.6968
V Predictions Std            321.56873
V Predictions Max            1831.1218
V Predictions Min            170.62543
Log Pis Mean                 -0.11064469
Log Pis Std                  1.932561
Log Pis Max                  6.9713736
Log Pis Min                  -7.0622687
Policy mu Mean               -0.119060695
Policy mu Std                0.8512467
Policy mu Max                2.0126011
Policy mu Min                -2.2147048
Policy log std Mean          -0.51694685
Policy log std Std           0.20453838
Policy log std Max           0.21022362
Policy log std Min           -1.3158884
Z mean eval                  0.022238648
Z variance eval              0.004425122
total_rewards                [3051.28393123 2722.34477076 1043.58428048 3010.96775103 3401.08285578
  932.37790065 1132.10792592  854.07228953  983.17191385 3384.16121817]
total_rewards_mean           2051.5154837418495
total_rewards_std            1079.6437821678903
total_rewards_max            3401.082855783849
total_rewards_min            854.0722895278976
Number of train steps total  1436000
Number of env steps total    1650854
Number of rollouts total     0
Train Time (s)               143.74800201877952
(Previous) Eval Time (s)     19.008245397824794
Sample Time (s)              9.679303355515003
Epoch Time (s)               172.4355507721193
Total Train Time (s)         60092.20773871802
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:12:02.395050 UTC | [2020_01_11_02_30_29] Iteration #358 | Epoch Duration: 172.52262902259827
2020-01-11 19:12:02.395295 UTC | [2020_01_11_02_30_29] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022211244
Z variance train             0.004425481
KL Divergence                11.236122
KL Loss                      1.1236123
QF Loss                      107.20464
VF Loss                      75.948845
Policy Loss                  -1490.3887
Q Predictions Mean           1487.2417
Q Predictions Std            326.81857
Q Predictions Max            1838.4966
Q Predictions Min            145.66447
V Predictions Mean           1488.3462
V Predictions Std            317.1411
V Predictions Max            1840.6267
V Predictions Min            189.11427
Log Pis Mean                 -0.060684174
Log Pis Std                  1.9787654
Log Pis Max                  6.934452
Log Pis Min                  -3.9922304
Policy mu Mean               -0.10827143
Policy mu Std                0.9191178
Policy mu Max                3.8786626
Policy mu Min                -2.831276
Policy log std Mean          -0.5235715
Policy log std Std           0.18461497
Policy log std Max           0.021965861
Policy log std Min           -1.2873452
Z mean eval                  0.04631081
Z variance eval              0.0036412186
total_rewards                [ 976.76581124 1042.01893347 2942.64050487 3407.11146372 3457.98920589
 1006.12954985  671.45978115 3376.20324642  814.83968176 2748.0284479 ]
total_rewards_mean           2044.3186626275735
total_rewards_std            1164.0552094533168
total_rewards_max            3457.989205888152
total_rewards_min            671.4597811462253
Number of train steps total  1440000
Number of env steps total    1657881
Number of rollouts total     0
Train Time (s)               145.2596494909376
(Previous) Eval Time (s)     18.501787665765733
Sample Time (s)              10.229605941101909
Epoch Time (s)               173.99104309780523
Total Train Time (s)         60266.281712913886
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:14:56.473340 UTC | [2020_01_11_02_30_29] Iteration #359 | Epoch Duration: 174.07788801193237
2020-01-11 19:14:56.473566 UTC | [2020_01_11_02_30_29] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04609991
Z variance train             0.0036412224
KL Divergence                11.726725
KL Loss                      1.1726725
QF Loss                      84.00137
VF Loss                      52.89224
Policy Loss                  -1525.2074
Q Predictions Mean           1521.2972
Q Predictions Std            264.17163
Q Predictions Max            1814.3867
Q Predictions Min            99.636955
V Predictions Mean           1523.1387
V Predictions Std            252.76886
V Predictions Max            1810.6627
V Predictions Min            156.30334
Log Pis Mean                 0.12128979
Log Pis Std                  2.2666192
Log Pis Max                  8.354012
Log Pis Min                  -4.42727
Policy mu Mean               -0.15478225
Policy mu Std                0.92473686
Policy mu Max                2.1574497
Policy mu Min                -2.9498327
Policy log std Mean          -0.537873
Policy log std Std           0.19874279
Policy log std Max           0.020816386
Policy log std Min           -1.1301315
Z mean eval                  0.054217506
Z variance eval              0.004019993
total_rewards                [3360.99207485 1246.39463792 3347.86186047 3332.54304221 3328.45435823
 3347.2405111  3334.75056529 1162.51665666 3375.7993113  3320.94890622]
total_rewards_mean           2915.750192424937
total_rewards_std            855.9879690112205
total_rewards_max            3375.799311298052
total_rewards_min            1162.5166566607109
Number of train steps total  1444000
Number of env steps total    1665350
Number of rollouts total     0
Train Time (s)               154.7578462427482
(Previous) Eval Time (s)     29.675973284058273
Sample Time (s)              10.580907142255455
Epoch Time (s)               195.01472666906193
Total Train Time (s)         60461.397172458004
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:18:11.594116 UTC | [2020_01_11_02_30_29] Iteration #360 | Epoch Duration: 195.12037658691406
2020-01-11 19:18:11.594375 UTC | [2020_01_11_02_30_29] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056623816
Z variance train             0.00402374
KL Divergence                11.362194
KL Loss                      1.1362194
QF Loss                      84.672935
VF Loss                      116.48403
Policy Loss                  -1547.8811
Q Predictions Mean           1546.8894
Q Predictions Std            217.7193
Q Predictions Max            1809.5573
Q Predictions Min            141.53172
V Predictions Mean           1555.5847
V Predictions Std            213.17393
V Predictions Max            1819.4607
V Predictions Min            231.6918
Log Pis Mean                 -0.05856283
Log Pis Std                  2.2469954
Log Pis Max                  8.095661
Log Pis Min                  -4.1691356
Policy mu Mean               -0.12107345
Policy mu Std                0.90522516
Policy mu Max                2.4220622
Policy mu Min                -2.6191401
Policy log std Mean          -0.50684446
Policy log std Std           0.21072334
Policy log std Max           0.014652848
Policy log std Min           -1.3400912
Z mean eval                  0.017220944
Z variance eval              0.0036070202
total_rewards                [3441.4144168  2471.69324542  221.71656457  205.77628205 3479.39223113
  184.37048718  212.1199534   205.50511112  211.7625341  3396.49562688]
total_rewards_mean           1403.0246452638619
total_rewards_std            1488.8833790066365
total_rewards_max            3479.3922311271695
total_rewards_min            184.37048718194455
Number of train steps total  1448000
Number of env steps total    1672935
Number of rollouts total     0
Train Time (s)               153.1371997119859
(Previous) Eval Time (s)     14.277858139947057
Sample Time (s)              10.920718592125922
Epoch Time (s)               178.33577644405887
Total Train Time (s)         60639.820646443404
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:21:10.022185 UTC | [2020_01_11_02_30_29] Iteration #361 | Epoch Duration: 178.42761301994324
2020-01-11 19:21:10.022529 UTC | [2020_01_11_02_30_29] Iteration #361 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017418966
Z variance train             0.0036066833
KL Divergence                11.651689
KL Loss                      1.1651689
QF Loss                      188.79588
VF Loss                      33.94266
Policy Loss                  -1545.3004
Q Predictions Mean           1549.1453
Q Predictions Std            275.93005
Q Predictions Max            1823.7653
Q Predictions Min            1.2233514
V Predictions Mean           1547.0916
V Predictions Std            274.96713
V Predictions Max            1816.5223
V Predictions Min            -0.021598935
Log Pis Mean                 -0.1640459
Log Pis Std                  1.9789814
Log Pis Max                  7.1426787
Log Pis Min                  -4.862729
Policy mu Mean               -0.09281218
Policy mu Std                0.874767
Policy mu Max                2.0327983
Policy mu Min                -2.5635898
Policy log std Mean          -0.5256346
Policy log std Std           0.22357926
Policy log std Max           0.10805297
Policy log std Min           -1.2242591
Z mean eval                  0.008020829
Z variance eval              0.0039906125
total_rewards                [1695.08999443 1512.86890906 1488.02350464 2260.34417118 1465.5968411
 1514.53000382 1575.00259225  949.30254626 3057.82492125 1416.82080632]
total_rewards_mean           1693.54042903225
total_rewards_std            546.4374135636126
total_rewards_max            3057.824921252398
total_rewards_min            949.3025462621757
Number of train steps total  1452000
Number of env steps total    1680798
Number of rollouts total     0
Train Time (s)               152.69344639685005
(Previous) Eval Time (s)     16.164769382681698
Sample Time (s)              9.287440921645612
Epoch Time (s)               178.14565670117736
Total Train Time (s)         60818.05213137576
Epoch                        362
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:24:08.257343 UTC | [2020_01_11_02_30_29] Iteration #362 | Epoch Duration: 178.23460841178894
2020-01-11 19:24:08.257586 UTC | [2020_01_11_02_30_29] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008080036
Z variance train             0.0039876746
KL Divergence                11.46114
KL Loss                      1.146114
QF Loss                      46.370888
VF Loss                      47.718536
Policy Loss                  -1529.713
Q Predictions Mean           1531.9727
Q Predictions Std            326.6679
Q Predictions Max            1832.7367
Q Predictions Min            89.43157
V Predictions Mean           1532.8447
V Predictions Std            328.71292
V Predictions Max            1841.1125
V Predictions Min            86.114075
Log Pis Mean                 -0.24995987
Log Pis Std                  1.8383164
Log Pis Max                  7.144291
Log Pis Min                  -4.6106296
Policy mu Mean               -0.14361142
Policy mu Std                0.8694163
Policy mu Max                1.9191966
Policy mu Min                -2.682473
Policy log std Mean          -0.5391886
Policy log std Std           0.23567756
Policy log std Max           0.18569058
Policy log std Min           -1.3023654
Z mean eval                  0.025463467
Z variance eval              0.0040977164
total_rewards                [ 880.78539218 1868.06683631 1064.79366383  917.16373354 1375.54089119
 1947.57761088 1109.38188612 2648.66297663  961.03258638 1675.76988304]
total_rewards_mean           1444.8775460106253
total_rewards_std            550.1657570917863
total_rewards_max            2648.6629766348137
total_rewards_min            880.7853921799672
Number of train steps total  1456000
Number of env steps total    1688406
Number of rollouts total     0
Train Time (s)               153.27365893125534
(Previous) Eval Time (s)     13.917074589058757
Sample Time (s)              9.091782025061548
Epoch Time (s)               176.28251554537565
Total Train Time (s)         60994.422675379086
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:27:04.632041 UTC | [2020_01_11_02_30_29] Iteration #363 | Epoch Duration: 176.37429022789001
2020-01-11 19:27:04.632277 UTC | [2020_01_11_02_30_29] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025384342
Z variance train             0.0040994314
KL Divergence                11.346043
KL Loss                      1.1346043
QF Loss                      73.181595
VF Loss                      33.233887
Policy Loss                  -1520.2422
Q Predictions Mean           1522.5397
Q Predictions Std            311.18582
Q Predictions Max            1849.4576
Q Predictions Min            56.69322
V Predictions Mean           1521.8154
V Predictions Std            310.7922
V Predictions Max            1833.0627
V Predictions Min            44.388996
Log Pis Mean                 -0.08361621
Log Pis Std                  1.9654663
Log Pis Max                  5.618873
Log Pis Min                  -5.3279195
Policy mu Mean               -0.031797037
Policy mu Std                0.88909715
Policy mu Max                2.8692076
Policy mu Min                -2.3265295
Policy log std Mean          -0.52292496
Policy log std Std           0.20720676
Policy log std Max           0.11812627
Policy log std Min           -1.2235143
Z mean eval                  0.047226917
Z variance eval              0.0045521567
total_rewards                [1147.9681103  2193.63757779  670.85377467 2222.7033414  3393.14254051
 1460.43303594  903.4989354  3405.22526573 1004.36715356  845.29092078]
total_rewards_mean           1724.7120656086015
total_rewards_std            977.5190510941937
total_rewards_max            3405.225265733384
total_rewards_min            670.8537746745485
Number of train steps total  1460000
Number of env steps total    1696011
Number of rollouts total     0
Train Time (s)               149.0431953589432
(Previous) Eval Time (s)     16.44860840588808
Sample Time (s)              10.57700241683051
Epoch Time (s)               176.06880618166178
Total Train Time (s)         61170.839321777225
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:30:01.050975 UTC | [2020_01_11_02_30_29] Iteration #364 | Epoch Duration: 176.41855382919312
2020-01-11 19:30:01.051129 UTC | [2020_01_11_02_30_29] Iteration #364 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047126677
Z variance train             0.0045500523
KL Divergence                11.098555
KL Loss                      1.1098555
QF Loss                      68.60905
VF Loss                      37.72493
Policy Loss                  -1518.4159
Q Predictions Mean           1516.8948
Q Predictions Std            332.07358
Q Predictions Max            1849.4207
Q Predictions Min            103.79519
V Predictions Mean           1518.9718
V Predictions Std            328.98325
V Predictions Max            1849.7678
V Predictions Min            111.567085
Log Pis Mean                 -0.15575188
Log Pis Std                  1.8508427
Log Pis Max                  6.1386466
Log Pis Min                  -3.990182
Policy mu Mean               -0.09630934
Policy mu Std                0.85866475
Policy mu Max                2.2980165
Policy mu Min                -2.5463026
Policy log std Mean          -0.5169663
Policy log std Std           0.18362826
Policy log std Max           -0.036167383
Policy log std Min           -1.2881491
Z mean eval                  0.039697655
Z variance eval              0.0047441595
total_rewards                [ 675.05194192  901.51787935 1375.58782191  821.97829183 2157.2720338
 1976.86786563  673.59815955 1446.42376182  691.58875379  968.11093779]
total_rewards_mean           1168.7997447384846
total_rewards_std            519.4834457031983
total_rewards_max            2157.2720337980286
total_rewards_min            673.5981595466812
Number of train steps total  1464000
Number of env steps total    1703666
Number of rollouts total     0
Train Time (s)               144.52798183308914
(Previous) Eval Time (s)     11.538537752814591
Sample Time (s)              9.874269336927682
Epoch Time (s)               165.94078892283142
Total Train Time (s)         61336.890490407124
Epoch                        365
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:32:47.106418 UTC | [2020_01_11_02_30_29] Iteration #365 | Epoch Duration: 166.05516910552979
2020-01-11 19:32:47.106615 UTC | [2020_01_11_02_30_29] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039659347
Z variance train             0.004742471
KL Divergence                10.9956665
KL Loss                      1.0995667
QF Loss                      74.43979
VF Loss                      34.602814
Policy Loss                  -1541.37
Q Predictions Mean           1541.5239
Q Predictions Std            308.02322
Q Predictions Max            1845.0992
Q Predictions Min            28.43621
V Predictions Mean           1543.7883
V Predictions Std            305.22058
V Predictions Max            1850.0479
V Predictions Min            78.118546
Log Pis Mean                 -0.14117321
Log Pis Std                  1.8907186
Log Pis Max                  5.84556
Log Pis Min                  -4.984748
Policy mu Mean               -0.14849599
Policy mu Std                0.89008784
Policy mu Max                1.9642131
Policy mu Min                -2.4462924
Policy log std Mean          -0.5059014
Policy log std Std           0.18952742
Policy log std Max           0.051535547
Policy log std Min           -1.1027111
Z mean eval                  0.017389383
Z variance eval              0.0045180484
total_rewards                [ 864.40274658 2815.43543919 3455.87667686  647.5034822  1980.36188419
 1074.92533973 2479.8671216  3382.69863212 2635.66530536 3371.85475252]
total_rewards_mean           2270.859138034573
total_rewards_std            1022.4492978420905
total_rewards_max            3455.8766768602813
total_rewards_min            647.5034821967427
Number of train steps total  1468000
Number of env steps total    1711079
Number of rollouts total     0
Train Time (s)               144.82769707590342
(Previous) Eval Time (s)     20.269171992316842
Sample Time (s)              9.708823784254491
Epoch Time (s)               174.80569285247475
Total Train Time (s)         61511.7775312271
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:35:41.997480 UTC | [2020_01_11_02_30_29] Iteration #366 | Epoch Duration: 174.89070963859558
2020-01-11 19:35:41.997717 UTC | [2020_01_11_02_30_29] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017329043
Z variance train             0.004520012
KL Divergence                11.06773
KL Loss                      1.106773
QF Loss                      242.39734
VF Loss                      43.702103
Policy Loss                  -1535.6338
Q Predictions Mean           1535.0024
Q Predictions Std            270.1839
Q Predictions Max            1810.4058
Q Predictions Min            150.33078
V Predictions Mean           1538.6462
V Predictions Std            260.27966
V Predictions Max            1812.9102
V Predictions Min            318.6034
Log Pis Mean                 0.070970744
Log Pis Std                  2.3377562
Log Pis Max                  9.165303
Log Pis Min                  -6.7619104
Policy mu Mean               -0.17036708
Policy mu Std                0.92872995
Policy mu Max                2.660836
Policy mu Min                -2.7503676
Policy log std Mean          -0.51936847
Policy log std Std           0.18775411
Policy log std Max           0.11316115
Policy log std Min           -1.3650397
Z mean eval                  0.039226167
Z variance eval              0.0040865815
total_rewards                [1062.27937955 1822.12797123  858.62914639 1466.76834484  838.04341558
  744.94329532  931.14738594  720.28967679  793.52049544 1658.80012582]
total_rewards_mean           1089.6549236900569
total_rewards_std            385.7674521729245
total_rewards_max            1822.1279712271173
total_rewards_min            720.2896767949741
Number of train steps total  1472000
Number of env steps total    1718399
Number of rollouts total     0
Train Time (s)               144.0647220700048
(Previous) Eval Time (s)     9.259216315113008
Sample Time (s)              10.42906370665878
Epoch Time (s)               163.75300209177658
Total Train Time (s)         61675.63602314051
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:38:25.860476 UTC | [2020_01_11_02_30_29] Iteration #367 | Epoch Duration: 163.8625190258026
2020-01-11 19:38:25.860788 UTC | [2020_01_11_02_30_29] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038979355
Z variance train             0.004086611
KL Divergence                11.327888
KL Loss                      1.1327888
QF Loss                      106.25845
VF Loss                      26.345531
Policy Loss                  -1564.6144
Q Predictions Mean           1565.9938
Q Predictions Std            205.87175
Q Predictions Max            1819.723
Q Predictions Min            233.63132
V Predictions Mean           1562.6923
V Predictions Std            203.19414
V Predictions Max            1814.9698
V Predictions Min            289.4942
Log Pis Mean                 -0.21109992
Log Pis Std                  1.9727883
Log Pis Max                  6.6846695
Log Pis Min                  -5.570166
Policy mu Mean               -0.14652444
Policy mu Std                0.8700891
Policy mu Max                2.3405452
Policy mu Min                -2.4998055
Policy log std Mean          -0.50879735
Policy log std Std           0.20770428
Policy log std Max           0.09746337
Policy log std Min           -1.670358
Z mean eval                  0.028332874
Z variance eval              0.003640355
total_rewards                [1822.62663863 3373.11846452 1072.92719903  942.49216906 3017.37327478
  823.45827479  719.32679527  983.29598985 1017.22844843 1215.79423497]
total_rewards_mean           1498.7641489325551
total_rewards_std            897.5665407774646
total_rewards_max            3373.1184645244844
total_rewards_min            719.3267952732413
Number of train steps total  1476000
Number of env steps total    1725535
Number of rollouts total     0
Train Time (s)               143.963805234991
(Previous) Eval Time (s)     14.038388194981962
Sample Time (s)              9.81199309322983
Epoch Time (s)               167.8141865232028
Total Train Time (s)         61843.53479516134
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:41:13.768746 UTC | [2020_01_11_02_30_29] Iteration #368 | Epoch Duration: 167.90774273872375
2020-01-11 19:41:13.769112 UTC | [2020_01_11_02_30_29] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02813949
Z variance train             0.0036407087
KL Divergence                11.637556
KL Loss                      1.1637557
QF Loss                      89.329926
VF Loss                      77.82851
Policy Loss                  -1557.4926
Q Predictions Mean           1558.6532
Q Predictions Std            169.24112
Q Predictions Max            1805.4377
Q Predictions Min            583.593
V Predictions Mean           1555.9886
V Predictions Std            165.93724
V Predictions Max            1802.1298
V Predictions Min            655.0996
Log Pis Mean                 -0.12672442
Log Pis Std                  1.9614999
Log Pis Max                  7.577717
Log Pis Min                  -5.0258203
Policy mu Mean               -0.15825827
Policy mu Std                0.87788725
Policy mu Max                1.9938915
Policy mu Min                -2.6431093
Policy log std Mean          -0.51318556
Policy log std Std           0.21870449
Policy log std Max           0.19885379
Policy log std Min           -1.1808448
Z mean eval                  0.031025242
Z variance eval              0.0034638462
total_rewards                [1909.71363218 2944.24393409 3367.8427016  3382.51152067 3388.52679145
 2041.81695459 3139.9768873  2088.76994443 3398.80261949 2104.72935386]
total_rewards_mean           2776.6934339660083
total_rewards_std            620.8343429192611
total_rewards_max            3398.8026194854456
total_rewards_min            1909.7136321754463
Number of train steps total  1480000
Number of env steps total    1732983
Number of rollouts total     0
Train Time (s)               145.27284572366625
(Previous) Eval Time (s)     25.57462269999087
Sample Time (s)              10.18219963600859
Epoch Time (s)               181.0296680596657
Total Train Time (s)         62024.86100883689
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:44:15.093225 UTC | [2020_01_11_02_30_29] Iteration #369 | Epoch Duration: 181.32381319999695
2020-01-11 19:44:15.093456 UTC | [2020_01_11_02_30_29] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0308606
Z variance train             0.0034660813
KL Divergence                11.809025
KL Loss                      1.1809025
QF Loss                      132.97275
VF Loss                      101.70418
Policy Loss                  -1586.1484
Q Predictions Mean           1581.3848
Q Predictions Std            178.2244
Q Predictions Max            1885.987
Q Predictions Min            288.24728
V Predictions Mean           1580.179
V Predictions Std            173.66481
V Predictions Max            1886.2306
V Predictions Min            377.84595
Log Pis Mean                 -0.12810567
Log Pis Std                  2.1025543
Log Pis Max                  7.5976486
Log Pis Min                  -5.392824
Policy mu Mean               -0.13000731
Policy mu Std                0.8935256
Policy mu Max                2.2704308
Policy mu Min                -2.5954258
Policy log std Mean          -0.51520354
Policy log std Std           0.21440956
Policy log std Max           0.05734968
Policy log std Min           -1.7448602
Z mean eval                  0.010690136
Z variance eval              0.0039358223
total_rewards                [1301.26407075 1798.23709872  956.60755435 3386.55987252 1875.02797444
 1538.64298912 1875.43938574  656.5586799  1229.57642762 1841.15739637]
total_rewards_mean           1645.907144951128
total_rewards_std            703.8423418893677
total_rewards_max            3386.5598725174436
total_rewards_min            656.5586799038133
Number of train steps total  1484000
Number of env steps total    1740821
Number of rollouts total     0
Train Time (s)               144.0472670928575
(Previous) Eval Time (s)     16.20733569189906
Sample Time (s)              10.477212704718113
Epoch Time (s)               170.73181548947468
Total Train Time (s)         62195.67675337661
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:47:05.913413 UTC | [2020_01_11_02_30_29] Iteration #370 | Epoch Duration: 170.81978130340576
2020-01-11 19:47:05.913646 UTC | [2020_01_11_02_30_29] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010599331
Z variance train             0.0039365995
KL Divergence                11.464337
KL Loss                      1.1464337
QF Loss                      117.83287
VF Loss                      37.30865
Policy Loss                  -1594.3169
Q Predictions Mean           1595.545
Q Predictions Std            205.01112
Q Predictions Max            1959.5697
Q Predictions Min            311.63043
V Predictions Mean           1592.459
V Predictions Std            200.61662
V Predictions Max            1965.7225
V Predictions Min            356.3165
Log Pis Mean                 -0.009137765
Log Pis Std                  2.1352537
Log Pis Max                  11.076668
Log Pis Min                  -5.569058
Policy mu Mean               -0.173038
Policy mu Std                0.92486554
Policy mu Max                2.9747052
Policy mu Min                -2.9644213
Policy log std Mean          -0.53900605
Policy log std Std           0.24344613
Policy log std Max           0.16335636
Policy log std Min           -2.1270466
Z mean eval                  0.028310591
Z variance eval              0.004650005
total_rewards                [  98.19676006  429.39314006  331.56600502 1361.32632605  582.39788458
  101.146722    846.29250805  854.52263731  384.29873394 1555.20653467]
total_rewards_mean           654.4347251735521
total_rewards_std            472.91744982925957
total_rewards_max            1555.2065346690763
total_rewards_min            98.19676006171602
Number of train steps total  1488000
Number of env steps total    1748721
Number of rollouts total     0
Train Time (s)               144.5287062418647
(Previous) Eval Time (s)     7.042823371943086
Sample Time (s)              8.728456100914627
Epoch Time (s)               160.29998571472242
Total Train Time (s)         62356.07986210752
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:49:46.329368 UTC | [2020_01_11_02_30_29] Iteration #371 | Epoch Duration: 160.41555976867676
2020-01-11 19:49:46.329723 UTC | [2020_01_11_02_30_29] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028274003
Z variance train             0.0046517933
KL Divergence                11.094475
KL Loss                      1.1094475
QF Loss                      152.1372
VF Loss                      47.123535
Policy Loss                  -1614.6655
Q Predictions Mean           1615.5907
Q Predictions Std            225.70761
Q Predictions Max            2023.8881
Q Predictions Min            -36.327362
V Predictions Mean           1610.8301
V Predictions Std            223.87856
V Predictions Max            2035.0474
V Predictions Min            -67.20585
Log Pis Mean                 -0.26670238
Log Pis Std                  1.7889056
Log Pis Max                  7.2035537
Log Pis Min                  -4.913891
Policy mu Mean               -0.025027743
Policy mu Std                0.8495406
Policy mu Max                2.4835937
Policy mu Min                -2.6669748
Policy log std Mean          -0.51477236
Policy log std Std           0.20498492
Policy log std Max           0.072796464
Policy log std Min           -1.5765297
Z mean eval                  0.034373008
Z variance eval              0.0044391644
total_rewards                [ 578.0096466   664.88146677  707.05308237 1098.15157551 1133.84443802
  844.33484717  646.89900845  639.35829461 1083.51762753  787.45928045]
total_rewards_mean           818.3509267474085
total_rewards_std            201.222646522011
total_rewards_max            1133.8444380215703
total_rewards_min            578.0096466014218
Number of train steps total  1492000
Number of env steps total    1756124
Number of rollouts total     0
Train Time (s)               144.99701337283477
(Previous) Eval Time (s)     8.236315646208823
Sample Time (s)              10.223026862833649
Epoch Time (s)               163.45635588187724
Total Train Time (s)         62519.843288208824
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:52:30.088131 UTC | [2020_01_11_02_30_29] Iteration #372 | Epoch Duration: 163.7580976486206
2020-01-11 19:52:30.088339 UTC | [2020_01_11_02_30_29] Iteration #372 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034273062
Z variance train             0.0044368603
KL Divergence                11.187399
KL Loss                      1.11874
QF Loss                      108.26143
VF Loss                      28.626623
Policy Loss                  -1574.7334
Q Predictions Mean           1574.7351
Q Predictions Std            307.77765
Q Predictions Max            1986.2903
Q Predictions Min            64.5245
V Predictions Mean           1574.6238
V Predictions Std            304.94247
V Predictions Max            1981.2947
V Predictions Min            69.064545
Log Pis Mean                 -0.17503995
Log Pis Std                  1.9173734
Log Pis Max                  7.1441545
Log Pis Min                  -5.261402
Policy mu Mean               0.017616164
Policy mu Std                0.8636193
Policy mu Max                3.3099616
Policy mu Min                -2.5917995
Policy log std Mean          -0.512528
Policy log std Std           0.20258364
Policy log std Max           0.11402559
Policy log std Min           -1.1679285
Z mean eval                  0.055873133
Z variance eval              0.0043721283
total_rewards                [783.19815821 809.15743983 777.4330513  796.76208309 809.27980719
 706.30750196 712.49473377 866.98812507 835.9387206  733.09928995]
total_rewards_mean           783.065891096113
total_rewards_std            49.79412375042434
total_rewards_max            866.9881250657687
total_rewards_min            706.3075019600177
Number of train steps total  1496000
Number of env steps total    1763379
Number of rollouts total     0
Train Time (s)               144.36910047801211
(Previous) Eval Time (s)     7.891545530874282
Sample Time (s)              10.238119903486222
Epoch Time (s)               162.49876591237262
Total Train Time (s)         62682.43123023026
Epoch                        373
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:55:12.681340 UTC | [2020_01_11_02_30_29] Iteration #373 | Epoch Duration: 162.59282732009888
2020-01-11 19:55:12.681618 UTC | [2020_01_11_02_30_29] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055652834
Z variance train             0.0043742713
KL Divergence                11.260221
KL Loss                      1.1260221
QF Loss                      124.33031
VF Loss                      34.021
Policy Loss                  -1522.5431
Q Predictions Mean           1519.9291
Q Predictions Std            363.8376
Q Predictions Max            1878.1096
Q Predictions Min            -35.27801
V Predictions Mean           1523.3203
V Predictions Std            362.65726
V Predictions Max            1885.5344
V Predictions Min            -19.839636
Log Pis Mean                 -0.28835356
Log Pis Std                  1.9067984
Log Pis Max                  5.4791765
Log Pis Min                  -7.648148
Policy mu Mean               -0.09707576
Policy mu Std                0.8501976
Policy mu Max                2.3442883
Policy mu Min                -2.6257172
Policy log std Mean          -0.51605767
Policy log std Std           0.207585
Policy log std Max           0.09607208
Policy log std Min           -1.1929791
Z mean eval                  0.02386878
Z variance eval              0.004010026
total_rewards                [1164.77905975 2067.45461318 2915.37852188 1003.38421098  353.72162372
 1013.08435617  741.43026843  893.37447441 1594.8096137  1356.14130066]
total_rewards_mean           1310.3558042869263
total_rewards_std            696.3332480597223
total_rewards_max            2915.37852187571
total_rewards_min            353.7216237248782
Number of train steps total  1500000
Number of env steps total    1770931
Number of rollouts total     0
Train Time (s)               143.0945291868411
(Previous) Eval Time (s)     11.709693494718522
Sample Time (s)              9.381965590175241
Epoch Time (s)               164.18618827173486
Total Train Time (s)         62846.69715291727
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:57:56.951818 UTC | [2020_01_11_02_30_29] Iteration #374 | Epoch Duration: 164.26999497413635
2020-01-11 19:57:56.952090 UTC | [2020_01_11_02_30_29] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023496062
Z variance train             0.0040105255
KL Divergence                11.404023
KL Loss                      1.1404023
QF Loss                      508.48715
VF Loss                      115.27115
Policy Loss                  -1531.5529
Q Predictions Mean           1524.9346
Q Predictions Std            314.66235
Q Predictions Max            1852.9039
Q Predictions Min            92.47787
V Predictions Mean           1528.08
V Predictions Std            315.42838
V Predictions Max            1862.7922
V Predictions Min            82.42454
Log Pis Mean                 -0.23284581
Log Pis Std                  1.8782531
Log Pis Max                  7.103614
Log Pis Min                  -5.111614
Policy mu Mean               -0.14975433
Policy mu Std                0.87705624
Policy mu Max                2.362015
Policy mu Min                -2.6168141
Policy log std Mean          -0.49589387
Policy log std Std           0.20418704
Policy log std Max           0.16819376
Policy log std Min           -1.3598766
Z mean eval                  0.026358455
Z variance eval              0.0040525896
total_rewards                [1099.77831234  968.30707775  814.31328998 1349.13153367  766.69514574
  789.41986063  663.26481669  798.75337151  996.09314235  950.60208335]
total_rewards_mean           919.6358634019236
total_rewards_std            189.17450871621887
total_rewards_max            1349.131533666885
total_rewards_min            663.2648166886639
Number of train steps total  1504000
Number of env steps total    1778793
Number of rollouts total     0
Train Time (s)               143.27914693113416
(Previous) Eval Time (s)     8.505126242991537
Sample Time (s)              9.84679940668866
Epoch Time (s)               161.63107258081436
Total Train Time (s)         63008.42149264552
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:00:38.680371 UTC | [2020_01_11_02_30_29] Iteration #375 | Epoch Duration: 161.72809386253357
2020-01-11 20:00:38.680582 UTC | [2020_01_11_02_30_29] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026699802
Z variance train             0.004053612
KL Divergence                11.365195
KL Loss                      1.1365196
QF Loss                      98.36897
VF Loss                      39.636513
Policy Loss                  -1515.7278
Q Predictions Mean           1513.2407
Q Predictions Std            351.01154
Q Predictions Max            1843.6854
Q Predictions Min            99.48068
V Predictions Mean           1514.738
V Predictions Std            346.69864
V Predictions Max            1850.4994
V Predictions Min            117.688095
Log Pis Mean                 -0.10551947
Log Pis Std                  2.0574083
Log Pis Max                  8.097988
Log Pis Min                  -4.8244505
Policy mu Mean               -0.2746698
Policy mu Std                0.8572159
Policy mu Max                3.6532614
Policy mu Min                -2.7271132
Policy log std Mean          -0.49724165
Policy log std Std           0.19091332
Policy log std Max           0.0061192513
Policy log std Min           -1.1087581
Z mean eval                  0.032870192
Z variance eval              0.0041584475
total_rewards                [1008.70560168 1538.06841733  966.94854618 1075.64968509 1437.84556133
 2015.73140137 1382.90002084  903.14561001 1253.26820616 1710.29535002]
total_rewards_mean           1329.2558400018863
total_rewards_std            340.6451355265866
total_rewards_max            2015.731401373784
total_rewards_min            903.1456100098823
Number of train steps total  1508000
Number of env steps total    1786180
Number of rollouts total     0
Train Time (s)               145.5762842670083
(Previous) Eval Time (s)     11.920481668785214
Sample Time (s)              10.374874531291425
Epoch Time (s)               167.87164046708494
Total Train Time (s)         63176.37498112023
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:03:26.637794 UTC | [2020_01_11_02_30_29] Iteration #376 | Epoch Duration: 167.95706033706665
2020-01-11 20:03:26.638015 UTC | [2020_01_11_02_30_29] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032727934
Z variance train             0.0041577844
KL Divergence                11.340567
KL Loss                      1.1340567
QF Loss                      82.13411
VF Loss                      28.674429
Policy Loss                  -1518.2595
Q Predictions Mean           1518.7732
Q Predictions Std            328.87234
Q Predictions Max            1845.6941
Q Predictions Min            74.20077
V Predictions Mean           1517.0637
V Predictions Std            324.7354
V Predictions Max            1844.0681
V Predictions Min            96.71796
Log Pis Mean                 0.06341259
Log Pis Std                  2.1849134
Log Pis Max                  9.062701
Log Pis Min                  -6.7691264
Policy mu Mean               -0.15633775
Policy mu Std                0.9177828
Policy mu Max                2.1158996
Policy mu Min                -2.5269227
Policy log std Mean          -0.51513106
Policy log std Std           0.19787835
Policy log std Max           0.04545349
Policy log std Min           -1.2594357
Z mean eval                  0.034966197
Z variance eval              0.003958038
total_rewards                [ 976.99097965  664.27961092 1035.90417785  835.29778536  158.24303553
 1484.3871342  1560.82355864  675.28148614 2641.19860367  784.65491383]
total_rewards_mean           1081.7061285777177
total_rewards_std            646.3707784778686
total_rewards_max            2641.1986036702106
total_rewards_min            158.24303552571678
Number of train steps total  1512000
Number of env steps total    1793190
Number of rollouts total     0
Train Time (s)               143.50799469603226
(Previous) Eval Time (s)     10.8197829159908
Sample Time (s)              9.85651243198663
Epoch Time (s)               164.18429004400969
Total Train Time (s)         63340.63727106294
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:06:10.904365 UTC | [2020_01_11_02_30_29] Iteration #377 | Epoch Duration: 164.26620626449585
2020-01-11 20:06:10.904555 UTC | [2020_01_11_02_30_29] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035237618
Z variance train             0.0039557396
KL Divergence                11.501485
KL Loss                      1.1501485
QF Loss                      91.703415
VF Loss                      72.44594
Policy Loss                  -1563.159
Q Predictions Mean           1565.4957
Q Predictions Std            211.97002
Q Predictions Max            1863.3466
Q Predictions Min            383.36102
V Predictions Mean           1567.0955
V Predictions Std            210.68456
V Predictions Max            1860.1522
V Predictions Min            389.7802
Log Pis Mean                 -0.20868813
Log Pis Std                  1.9486799
Log Pis Max                  6.741287
Log Pis Min                  -6.0414085
Policy mu Mean               -0.16302048
Policy mu Std                0.87125903
Policy mu Max                2.4989715
Policy mu Min                -2.591101
Policy log std Mean          -0.48469257
Policy log std Std           0.19096267
Policy log std Max           0.34684724
Policy log std Min           -1.1613209
Z mean eval                  0.027001929
Z variance eval              0.0041607376
total_rewards                [1019.52217385 1435.50768155 1787.88276158 1295.63270424 1663.13081451
  931.34706973  893.98835525 1266.93301802  986.09891914  913.36333058]
total_rewards_mean           1219.3406828447226
total_rewards_std            308.50432828765526
total_rewards_max            1787.882761579688
total_rewards_min            893.9883552453092
Number of train steps total  1516000
Number of env steps total    1800605
Number of rollouts total     0
Train Time (s)               144.3009807257913
(Previous) Eval Time (s)     11.356315793003887
Sample Time (s)              10.340327624697238
Epoch Time (s)               165.99762414349243
Total Train Time (s)         63506.732236054726
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:08:57.003317 UTC | [2020_01_11_02_30_29] Iteration #378 | Epoch Duration: 166.09861993789673
2020-01-11 20:08:57.003511 UTC | [2020_01_11_02_30_29] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025397707
Z variance train             0.0041559013
KL Divergence                11.292965
KL Loss                      1.1292965
QF Loss                      147.17131
VF Loss                      269.11386
Policy Loss                  -1586.8649
Q Predictions Mean           1586.6013
Q Predictions Std            191.35318
Q Predictions Max            1854.3665
Q Predictions Min            537.3205
V Predictions Mean           1600.2024
V Predictions Std            187.49779
V Predictions Max            1864.6826
V Predictions Min            604.8852
Log Pis Mean                 0.08939305
Log Pis Std                  2.1226933
Log Pis Max                  8.628245
Log Pis Min                  -4.543785
Policy mu Mean               -0.23660587
Policy mu Std                0.8881925
Policy mu Max                1.8923783
Policy mu Min                -2.659809
Policy log std Mean          -0.50659317
Policy log std Std           0.20673841
Policy log std Max           0.060971737
Policy log std Min           -1.3462682
Z mean eval                  0.03570976
Z variance eval              0.004040647
total_rewards                [ 175.00385428  170.59293206  162.8638299   183.60134049 1824.94771426
  644.93632412  148.38597243 1372.65364563  190.05755262  143.30098529]
total_rewards_mean           501.6344151080625
total_rewards_std            575.5711952407879
total_rewards_max            1824.9477142630697
total_rewards_min            143.300985287089
Number of train steps total  1520000
Number of env steps total    1808072
Number of rollouts total     0
Train Time (s)               151.20424933405593
(Previous) Eval Time (s)     5.582009048201144
Sample Time (s)              9.989422148093581
Epoch Time (s)               166.77568053035066
Total Train Time (s)         63673.589481744915
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:11:43.866042 UTC | [2020_01_11_02_30_29] Iteration #379 | Epoch Duration: 166.8623559474945
2020-01-11 20:11:43.866335 UTC | [2020_01_11_02_30_29] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035573028
Z variance train             0.004040637
KL Divergence                11.3733225
KL Loss                      1.1373323
QF Loss                      161.32983
VF Loss                      148.4535
Policy Loss                  -1596.8987
Q Predictions Mean           1592.6238
Q Predictions Std            208.65607
Q Predictions Max            1854.6023
Q Predictions Min            348.64618
V Predictions Mean           1604.7894
V Predictions Std            195.63567
V Predictions Max            1864.3811
V Predictions Min            545.70166
Log Pis Mean                 -0.1340987
Log Pis Std                  2.106218
Log Pis Max                  10.008204
Log Pis Min                  -4.5083303
Policy mu Mean               -0.055690866
Policy mu Std                0.91361165
Policy mu Max                2.935974
Policy mu Min                -2.7472947
Policy log std Mean          -0.47362423
Policy log std Std           0.20447491
Policy log std Max           0.14595944
Policy log std Min           -1.5322285
Z mean eval                  0.056438882
Z variance eval              0.0046049813
total_rewards                [ 968.30532752 1260.09821791  737.42438538  900.41639055 1264.06109715
 1446.42304855  730.29120016 1047.94137323 1395.49894389 1147.74421288]
total_rewards_mean           1089.8204197235325
total_rewards_std            242.72457358858134
total_rewards_max            1446.4230485523349
total_rewards_min            730.2912001626752
Number of train steps total  1524000
Number of env steps total    1815463
Number of rollouts total     0
Train Time (s)               154.29267524695024
(Previous) Eval Time (s)     11.117770773824304
Sample Time (s)              11.24789439374581
Epoch Time (s)               176.65834041452035
Total Train Time (s)         63850.3270944627
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:14:40.608418 UTC | [2020_01_11_02_30_29] Iteration #380 | Epoch Duration: 176.74186778068542
2020-01-11 20:14:40.608747 UTC | [2020_01_11_02_30_29] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05665184
Z variance train             0.0046051266
KL Divergence                11.122606
KL Loss                      1.1122607
QF Loss                      61.738556
VF Loss                      20.428162
Policy Loss                  -1619.8569
Q Predictions Mean           1619.2401
Q Predictions Std            167.49191
Q Predictions Max            1866.0743
Q Predictions Min            626.9153
V Predictions Mean           1620.5516
V Predictions Std            161.35031
V Predictions Max            1865.6129
V Predictions Min            694.83044
Log Pis Mean                 -0.14529312
Log Pis Std                  1.8749768
Log Pis Max                  6.0000076
Log Pis Min                  -5.817197
Policy mu Mean               -0.20078592
Policy mu Std                0.875255
Policy mu Max                2.1792448
Policy mu Min                -2.5305803
Policy log std Mean          -0.48387313
Policy log std Std           0.21398996
Policy log std Max           0.10867447
Policy log std Min           -1.6417418
Z mean eval                  0.047369193
Z variance eval              0.0050798394
total_rewards                [ 536.33299479  742.11650832  734.41643021  741.10543834 1513.32994096
  814.0998097  1090.27701559  776.81601009  798.4908765  1025.30719851]
total_rewards_mean           877.2292223012104
total_rewards_std            257.99211191752823
total_rewards_max            1513.3299409570056
total_rewards_min            536.3329947880324
Number of train steps total  1528000
Number of env steps total    1822622
Number of rollouts total     0
Train Time (s)               153.55279947211966
(Previous) Eval Time (s)     9.039692186750472
Sample Time (s)              9.862789209466428
Epoch Time (s)               172.45528086833656
Total Train Time (s)         64022.86647675373
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:17:33.151437 UTC | [2020_01_11_02_30_29] Iteration #381 | Epoch Duration: 172.54251050949097
2020-01-11 20:17:33.151629 UTC | [2020_01_11_02_30_29] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047218
Z variance train             0.005079017
KL Divergence                10.992409
KL Loss                      1.0992409
QF Loss                      65.90436
VF Loss                      37.589203
Policy Loss                  -1598.4944
Q Predictions Mean           1597.8395
Q Predictions Std            257.32224
Q Predictions Max            1892.5658
Q Predictions Min            131.09409
V Predictions Mean           1597.2986
V Predictions Std            252.66507
V Predictions Max            1880.1581
V Predictions Min            87.49441
Log Pis Mean                 -0.086699106
Log Pis Std                  1.9828395
Log Pis Max                  8.693949
Log Pis Min                  -4.534441
Policy mu Mean               -0.1962155
Policy mu Std                0.8445291
Policy mu Max                3.7406018
Policy mu Min                -2.3654509
Policy log std Mean          -0.5276694
Policy log std Std           0.20863906
Policy log std Max           0.31860036
Policy log std Min           -1.4960601
Z mean eval                  0.062171828
Z variance eval              0.0055674464
total_rewards                [ 798.9769999   703.05973069  750.89109317  893.46415904  951.7608302
 1606.82304054 1110.41281421  933.74364254  686.15601229  747.26331356]
total_rewards_mean           918.2551636128501
total_rewards_std            261.6644255518038
total_rewards_max            1606.8230405384813
total_rewards_min            686.1560122856383
Number of train steps total  1532000
Number of env steps total    1830525
Number of rollouts total     0
Train Time (s)               153.16475254110992
(Previous) Eval Time (s)     9.586404381785542
Sample Time (s)              8.952393705956638
Epoch Time (s)               171.7035506288521
Total Train Time (s)         64194.68160290783
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:20:24.971145 UTC | [2020_01_11_02_30_29] Iteration #382 | Epoch Duration: 171.81936526298523
2020-01-11 20:20:24.971375 UTC | [2020_01_11_02_30_29] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062369395
Z variance train             0.0055669043
KL Divergence                10.875899
KL Loss                      1.08759
QF Loss                      68.355484
VF Loss                      29.754976
Policy Loss                  -1602.1753
Q Predictions Mean           1602.1145
Q Predictions Std            251.49939
Q Predictions Max            1866.0658
Q Predictions Min            51.31499
V Predictions Mean           1600.5587
V Predictions Std            248.46117
V Predictions Max            1861.7151
V Predictions Min            54.302868
Log Pis Mean                 -0.45540762
Log Pis Std                  1.7564077
Log Pis Max                  5.774034
Log Pis Min                  -5.9842157
Policy mu Mean               -0.107199766
Policy mu Std                0.8046676
Policy mu Max                2.9609027
Policy mu Min                -2.466176
Policy log std Mean          -0.4962813
Policy log std Std           0.1914222
Policy log std Max           0.045433223
Policy log std Min           -1.3862841
Z mean eval                  0.021534884
Z variance eval              0.0054974607
total_rewards                [ 818.04309885  737.69851078 1462.51923847  786.59021939  820.27919641
  829.7017522   815.20045363 1154.21318756  821.3017029  1427.87628606]
total_rewards_mean           967.3423646240395
total_rewards_std            261.7169829456959
total_rewards_max            1462.5192384684626
total_rewards_min            737.6985107787201
Number of train steps total  1536000
Number of env steps total    1838383
Number of rollouts total     0
Train Time (s)               152.5616051699035
(Previous) Eval Time (s)     9.512396055739373
Sample Time (s)              10.816117516718805
Epoch Time (s)               172.89011874236166
Total Train Time (s)         64367.66050654603
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:23:17.954118 UTC | [2020_01_11_02_30_29] Iteration #383 | Epoch Duration: 172.98259282112122
2020-01-11 20:23:17.954305 UTC | [2020_01_11_02_30_29] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021575546
Z variance train             0.005498192
KL Divergence                10.833176
KL Loss                      1.0833176
QF Loss                      46.90626
VF Loss                      40.913033
Policy Loss                  -1596.3132
Q Predictions Mean           1597.4459
Q Predictions Std            306.16376
Q Predictions Max            1865.3838
Q Predictions Min            35.59414
V Predictions Mean           1600.1995
V Predictions Std            306.9406
V Predictions Max            1872.0765
V Predictions Min            31.77197
Log Pis Mean                 -0.33163226
Log Pis Std                  1.9204818
Log Pis Max                  7.0207148
Log Pis Min                  -6.3406467
Policy mu Mean               -0.19078733
Policy mu Std                0.8409791
Policy mu Max                1.9064492
Policy mu Min                -2.751061
Policy log std Mean          -0.5005196
Policy log std Std           0.1911014
Policy log std Max           0.27929586
Policy log std Min           -1.2841457
Z mean eval                  0.037997246
Z variance eval              0.005197895
total_rewards                [ 939.99048339  740.26742415  987.14875176  770.12650628  685.90696952
  719.71505904  738.03657027 2070.8775297   745.5890871   765.11907533]
total_rewards_mean           916.2777456550281
total_rewards_std            395.7886475701423
total_rewards_max            2070.877529704762
total_rewards_min            685.9069695150986
Number of train steps total  1540000
Number of env steps total    1845639
Number of rollouts total     0
Train Time (s)               144.40763308294117
(Previous) Eval Time (s)     9.396642912644893
Sample Time (s)              10.18190158624202
Epoch Time (s)               163.9861775818281
Total Train Time (s)         64531.814268938266
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:26:02.112514 UTC | [2020_01_11_02_30_29] Iteration #384 | Epoch Duration: 164.15805983543396
2020-01-11 20:26:02.112722 UTC | [2020_01_11_02_30_29] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037936617
Z variance train             0.0051979525
KL Divergence                11.015188
KL Loss                      1.1015189
QF Loss                      61.731316
VF Loss                      56.951126
Policy Loss                  -1556.3019
Q Predictions Mean           1556.7205
Q Predictions Std            315.00958
Q Predictions Max            1860.3252
Q Predictions Min            42.321377
V Predictions Mean           1557.2114
V Predictions Std            318.4247
V Predictions Max            1868.367
V Predictions Min            12.8479805
Log Pis Mean                 -0.062839374
Log Pis Std                  1.9559208
Log Pis Max                  6.399577
Log Pis Min                  -5.670358
Policy mu Mean               -0.2311036
Policy mu Std                0.8703622
Policy mu Max                2.373769
Policy mu Min                -2.5166054
Policy log std Mean          -0.5160039
Policy log std Std           0.19551206
Policy log std Max           0.2028336
Policy log std Min           -1.2415054
Z mean eval                  0.041324418
Z variance eval              0.004644178
total_rewards                [1732.4736249   686.10061948  777.75415541  865.23230953  698.77260268
  820.96182912  985.51097097  749.75370883  772.16795112  932.62144807]
total_rewards_mean           902.1349220113883
total_rewards_std            291.3594523428463
total_rewards_max            1732.4736249041152
total_rewards_min            686.1006194773366
Number of train steps total  1544000
Number of env steps total    1853338
Number of rollouts total     0
Train Time (s)               144.33759243506938
(Previous) Eval Time (s)     8.629635718185455
Sample Time (s)              9.616250826977193
Epoch Time (s)               162.58347898023203
Total Train Time (s)         64694.4931435762
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:28:44.795176 UTC | [2020_01_11_02_30_29] Iteration #385 | Epoch Duration: 162.6823058128357
2020-01-11 20:28:44.795497 UTC | [2020_01_11_02_30_29] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04108865
Z variance train             0.0046448293
KL Divergence                11.262402
KL Loss                      1.1262401
QF Loss                      50.009804
VF Loss                      34.42232
Policy Loss                  -1556.1802
Q Predictions Mean           1556.499
Q Predictions Std            373.03708
Q Predictions Max            1877.9641
Q Predictions Min            11.75794
V Predictions Mean           1560.0408
V Predictions Std            372.61948
V Predictions Max            1885.8376
V Predictions Min            14.011246
Log Pis Mean                 -0.30949807
Log Pis Std                  1.873101
Log Pis Max                  6.301547
Log Pis Min                  -5.909069
Policy mu Mean               -0.17490196
Policy mu Std                0.81838536
Policy mu Max                1.8140074
Policy mu Min                -2.3924527
Policy log std Mean          -0.48907444
Policy log std Std           0.19028798
Policy log std Max           0.22636342
Policy log std Min           -1.2403667
Z mean eval                  0.024887402
Z variance eval              0.0052066864
total_rewards                [1515.0916627   882.90172704 1237.91799974  911.50024597  696.82801154
  735.04880101  696.75286873  722.76860616  957.53072225  728.43730085]
total_rewards_mean           908.4777945978725
total_rewards_std            258.1053789969969
total_rewards_max            1515.0916626988837
total_rewards_min            696.7528687262529
Number of train steps total  1548000
Number of env steps total    1861275
Number of rollouts total     0
Train Time (s)               143.75880784681067
(Previous) Eval Time (s)     7.391375715844333
Sample Time (s)              10.430413013789803
Epoch Time (s)               161.5805965764448
Total Train Time (s)         64856.151330010965
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:31:26.457711 UTC | [2020_01_11_02_30_29] Iteration #386 | Epoch Duration: 161.66205215454102
2020-01-11 20:31:26.457907 UTC | [2020_01_11_02_30_29] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024803838
Z variance train             0.005202924
KL Divergence                10.812527
KL Loss                      1.0812527
QF Loss                      51.047546
VF Loss                      37.658028
Policy Loss                  -1541.1691
Q Predictions Mean           1539.8057
Q Predictions Std            344.13687
Q Predictions Max            1857.8248
Q Predictions Min            58.47329
V Predictions Mean           1544.6833
V Predictions Std            339.88562
V Predictions Max            1867.0902
V Predictions Min            71.20856
Log Pis Mean                 -0.38292432
Log Pis Std                  1.8466775
Log Pis Max                  5.7020984
Log Pis Min                  -6.0821295
Policy mu Mean               -0.19350696
Policy mu Std                0.8393044
Policy mu Max                2.1073284
Policy mu Min                -2.435509
Policy log std Mean          -0.49657413
Policy log std Std           0.19732909
Policy log std Max           0.014136553
Policy log std Min           -1.4361348
Z mean eval                  0.02397705
Z variance eval              0.0054146806
total_rewards                [ 722.73708311  850.00152969  808.84721569 1451.29401509 1526.59977863
  702.32644137  721.32078393  639.47353325  708.11763647  901.64352329]
total_rewards_mean           903.2361540529362
total_rewards_std            302.3863664357227
total_rewards_max            1526.599778629606
total_rewards_min            639.4735332535982
Number of train steps total  1552000
Number of env steps total    1868382
Number of rollouts total     0
Train Time (s)               143.93408399214968
(Previous) Eval Time (s)     8.894338453188539
Sample Time (s)              10.971809001639485
Epoch Time (s)               163.8002314469777
Total Train Time (s)         65020.03513844218
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:34:10.345893 UTC | [2020_01_11_02_30_29] Iteration #387 | Epoch Duration: 163.88783717155457
2020-01-11 20:34:10.346096 UTC | [2020_01_11_02_30_29] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02401026
Z variance train             0.005414841
KL Divergence                10.810412
KL Loss                      1.0810412
QF Loss                      91.077866
VF Loss                      34.414875
Policy Loss                  -1591.781
Q Predictions Mean           1591.7146
Q Predictions Std            249.66122
Q Predictions Max            1843.7832
Q Predictions Min            203.16933
V Predictions Mean           1593.4248
V Predictions Std            246.48015
V Predictions Max            1844.692
V Predictions Min            255.5617
Log Pis Mean                 -0.39009345
Log Pis Std                  1.6909224
Log Pis Max                  6.4551506
Log Pis Min                  -4.99891
Policy mu Mean               -0.15944707
Policy mu Std                0.8188445
Policy mu Max                1.8914448
Policy mu Min                -2.669569
Policy log std Mean          -0.4662474
Policy log std Std           0.1977028
Policy log std Max           0.11419016
Policy log std Min           -1.263657
Z mean eval                  0.01941041
Z variance eval              0.0057002828
total_rewards                [ 948.62590898 1939.42684115  791.81505273 1607.52117371  965.03338817
  879.06699254 1946.52987014 1353.96025099 1085.3215632   745.9979908 ]
total_rewards_mean           1226.329903241387
total_rewards_std            435.2222059218513
total_rewards_max            1946.5298701412107
total_rewards_min            745.997990796929
Number of train steps total  1556000
Number of env steps total    1876191
Number of rollouts total     0
Train Time (s)               144.2295356541872
(Previous) Eval Time (s)     11.313734686002135
Sample Time (s)              10.50853167148307
Epoch Time (s)               166.0518020116724
Total Train Time (s)         65186.16642223764
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:36:56.481666 UTC | [2020_01_11_02_30_29] Iteration #388 | Epoch Duration: 166.13539576530457
2020-01-11 20:36:56.481877 UTC | [2020_01_11_02_30_29] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019436229
Z variance train             0.0057047936
KL Divergence                10.608794
KL Loss                      1.0608795
QF Loss                      89.01831
VF Loss                      134.1358
Policy Loss                  -1564.0946
Q Predictions Mean           1566.8972
Q Predictions Std            279.5468
Q Predictions Max            1849.9081
Q Predictions Min            212.4496
V Predictions Mean           1571.7429
V Predictions Std            277.2454
V Predictions Max            1859.0375
V Predictions Min            273.01447
Log Pis Mean                 -0.10609472
Log Pis Std                  2.1070528
Log Pis Max                  6.4432855
Log Pis Min                  -5.881933
Policy mu Mean               -0.19487746
Policy mu Std                0.85161316
Policy mu Max                1.7671288
Policy mu Min                -2.5653458
Policy log std Mean          -0.50417286
Policy log std Std           0.1927908
Policy log std Max           0.04585606
Policy log std Min           -1.5106766
Z mean eval                  0.053072464
Z variance eval              0.005065835
total_rewards                [2175.90013775 1215.39814368  779.26803487 2002.38878333 1992.48515762
 1634.90583349 1392.44414865  922.09580099  930.51422492  882.70752581]
total_rewards_mean           1392.8107791113325
total_rewards_std            500.6435621004829
total_rewards_max            2175.900137749212
total_rewards_min            779.2680348739885
Number of train steps total  1560000
Number of env steps total    1883589
Number of rollouts total     0
Train Time (s)               145.46040708990768
(Previous) Eval Time (s)     13.722719070035964
Sample Time (s)              10.469888977240771
Epoch Time (s)               169.6530151371844
Total Train Time (s)         65356.13862680085
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:39:46.457916 UTC | [2020_01_11_02_30_29] Iteration #389 | Epoch Duration: 169.97587871551514
2020-01-11 20:39:46.458155 UTC | [2020_01_11_02_30_29] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05248981
Z variance train             0.0050772903
KL Divergence                10.910198
KL Loss                      1.0910199
QF Loss                      144.1686
VF Loss                      169.55737
Policy Loss                  -1586.4308
Q Predictions Mean           1586.3157
Q Predictions Std            254.56628
Q Predictions Max            1869.4778
Q Predictions Min            165.86961
V Predictions Mean           1596.2305
V Predictions Std            242.65997
V Predictions Max            1876.8966
V Predictions Min            355.83063
Log Pis Mean                 -0.18177652
Log Pis Std                  1.9828705
Log Pis Max                  6.3777275
Log Pis Min                  -4.9647913
Policy mu Mean               -0.16258895
Policy mu Std                0.8786286
Policy mu Max                2.1959472
Policy mu Min                -2.486027
Policy log std Mean          -0.49608967
Policy log std Std           0.19716662
Policy log std Max           0.026228309
Policy log std Min           -1.1553059
Z mean eval                  0.035298146
Z variance eval              0.005187637
total_rewards                [ 928.68230174 1757.04391077  972.09715926  943.71286768 1465.41453488
  724.30699056 1990.8565532   908.32192326  788.33698642  873.48005379]
total_rewards_mean           1135.225328156403
total_rewards_std            417.48257982357984
total_rewards_max            1990.8565531969487
total_rewards_min            724.306990563802
Number of train steps total  1564000
Number of env steps total    1891273
Number of rollouts total     0
Train Time (s)               143.95091586885974
(Previous) Eval Time (s)     11.14852809580043
Sample Time (s)              8.871737367473543
Epoch Time (s)               163.9711813321337
Total Train Time (s)         65520.19238881767
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:42:30.516075 UTC | [2020_01_11_02_30_29] Iteration #390 | Epoch Duration: 164.0577712059021
2020-01-11 20:42:30.516269 UTC | [2020_01_11_02_30_29] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03537675
Z variance train             0.005187322
KL Divergence                10.717173
KL Loss                      1.0717173
QF Loss                      99.4946
VF Loss                      29.665564
Policy Loss                  -1601.4912
Q Predictions Mean           1601.4607
Q Predictions Std            230.87022
Q Predictions Max            1843.0626
Q Predictions Min            20.937113
V Predictions Mean           1602.2185
V Predictions Std            224.31773
V Predictions Max            1843.9333
V Predictions Min            94.392006
Log Pis Mean                 0.033955403
Log Pis Std                  1.9796135
Log Pis Max                  7.2140656
Log Pis Min                  -5.253369
Policy mu Mean               -0.29381368
Policy mu Std                0.9049238
Policy mu Max                2.4754958
Policy mu Min                -2.7904878
Policy log std Mean          -0.51934576
Policy log std Std           0.19329399
Policy log std Max           0.44693816
Policy log std Min           -1.3618393
Z mean eval                  0.03770203
Z variance eval              0.0044044266
total_rewards                [ 889.82238233 1114.88990002  510.11249231 1171.71228949 1489.20109661
 1276.07174072  770.70846737 1032.29032852 1765.27613189 1305.13172997]
total_rewards_mean           1132.5216559234136
total_rewards_std            341.62805887420063
total_rewards_max            1765.2761318896544
total_rewards_min            510.11249231048697
Number of train steps total  1568000
Number of env steps total    1898984
Number of rollouts total     0
Train Time (s)               143.36207736097276
(Previous) Eval Time (s)     10.489806428086013
Sample Time (s)              9.25172818871215
Epoch Time (s)               163.10361197777092
Total Train Time (s)         65683.3694198709
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:45:13.695437 UTC | [2020_01_11_02_30_29] Iteration #391 | Epoch Duration: 163.17898893356323
2020-01-11 20:45:13.695728 UTC | [2020_01_11_02_30_29] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037892565
Z variance train             0.004403679
KL Divergence                11.102765
KL Loss                      1.1102766
QF Loss                      38.33175
VF Loss                      24.566715
Policy Loss                  -1624.8683
Q Predictions Mean           1625.3054
Q Predictions Std            181.56671
Q Predictions Max            1840.5408
Q Predictions Min            629.486
V Predictions Mean           1622.4768
V Predictions Std            180.03412
V Predictions Max            1839.0167
V Predictions Min            655.6285
Log Pis Mean                 -0.2710441
Log Pis Std                  1.7939938
Log Pis Max                  6.62685
Log Pis Min                  -6.3140116
Policy mu Mean               -0.089469366
Policy mu Std                0.8629465
Policy mu Max                1.8578287
Policy mu Min                -2.3275425
Policy log std Mean          -0.49570203
Policy log std Std           0.18709606
Policy log std Max           0.24837768
Policy log std Min           -1.1526998
Z mean eval                  0.051640786
Z variance eval              0.0043769246
total_rewards                [1746.44885308 1129.35804337 1240.1358163  1891.11744744  872.47741848
 2835.78005999 1551.58705713 1840.07577777  970.30421124 1688.95279956]
total_rewards_mean           1576.6237484354465
total_rewards_std            545.2145694839207
total_rewards_max            2835.7800599879265
total_rewards_min            872.4774184801679
Number of train steps total  1572000
Number of env steps total    1906332
Number of rollouts total     0
Train Time (s)               145.56096697086468
(Previous) Eval Time (s)     15.593844150193036
Sample Time (s)              9.953464091289788
Epoch Time (s)               171.1082752123475
Total Train Time (s)         65854.56397272926
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:48:04.894756 UTC | [2020_01_11_02_30_29] Iteration #392 | Epoch Duration: 171.19880938529968
2020-01-11 20:48:04.895005 UTC | [2020_01_11_02_30_29] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05018706
Z variance train             0.004374629
KL Divergence                11.16121
KL Loss                      1.116121
QF Loss                      197.07913
VF Loss                      76.747406
Policy Loss                  -1583.2181
Q Predictions Mean           1587.2202
Q Predictions Std            258.56305
Q Predictions Max            1851.1486
Q Predictions Min            44.694065
V Predictions Mean           1580.4231
V Predictions Std            253.53642
V Predictions Max            1842.2382
V Predictions Min            92.82092
Log Pis Mean                 -0.31165957
Log Pis Std                  1.725816
Log Pis Max                  5.2634597
Log Pis Min                  -5.897869
Policy mu Mean               -0.09540302
Policy mu Std                0.83637846
Policy mu Max                2.0032346
Policy mu Min                -2.3118951
Policy log std Mean          -0.49455652
Policy log std Std           0.18409479
Policy log std Max           0.11238921
Policy log std Min           -1.2623498
Z mean eval                  0.050548803
Z variance eval              0.0055353027
total_rewards                [1739.28339198 1253.00777515  878.73572208 1111.38698135 1432.72804359
  853.44171761  961.16675532 3377.5986932  1278.0390981  3195.91705213]
total_rewards_mean           1608.1305230500861
total_rewards_std            877.6110481618566
total_rewards_max            3377.5986931962816
total_rewards_min            853.4417176125315
Number of train steps total  1576000
Number of env steps total    1914187
Number of rollouts total     0
Train Time (s)               143.11038306821138
(Previous) Eval Time (s)     15.953458055853844
Sample Time (s)              10.303044641390443
Epoch Time (s)               169.36688576545566
Total Train Time (s)         66024.01697467268
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:50:54.351919 UTC | [2020_01_11_02_30_29] Iteration #393 | Epoch Duration: 169.45675826072693
2020-01-11 20:50:54.352114 UTC | [2020_01_11_02_30_29] Iteration #393 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05036009
Z variance train             0.0055346373
KL Divergence                11.042313
KL Loss                      1.1042312
QF Loss                      31.837872
VF Loss                      38.543686
Policy Loss                  -1570.4547
Q Predictions Mean           1570.3699
Q Predictions Std            236.50333
Q Predictions Max            1861.0208
Q Predictions Min            224.74905
V Predictions Mean           1571.3846
V Predictions Std            238.31177
V Predictions Max            1859.389
V Predictions Min            219.56374
Log Pis Mean                 -0.030095093
Log Pis Std                  1.7636756
Log Pis Max                  5.0567036
Log Pis Min                  -4.9559183
Policy mu Mean               -0.16574813
Policy mu Std                0.87076634
Policy mu Max                2.010367
Policy mu Min                -2.344882
Policy log std Mean          -0.52432114
Policy log std Std           0.17753728
Policy log std Max           0.032702744
Policy log std Min           -1.1058924
Z mean eval                  0.049631387
Z variance eval              0.0041631786
total_rewards                [2725.76801517  940.34623839  955.75200643 1140.06581004 1419.211962
 1216.91590809 1987.52756739 1538.26218106  889.61007755 1442.62901706]
total_rewards_mean           1425.6088783184514
total_rewards_std            537.3839772827906
total_rewards_max            2725.768015170684
total_rewards_min            889.6100775538322
Number of train steps total  1580000
Number of env steps total    1923173
Number of rollouts total     0
Train Time (s)               144.22570946393535
(Previous) Eval Time (s)     13.09745897212997
Sample Time (s)              10.224145576357841
Epoch Time (s)               167.54731401242316
Total Train Time (s)         66191.64719120692
Epoch                        394
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:53:41.987645 UTC | [2020_01_11_02_30_29] Iteration #394 | Epoch Duration: 167.63540291786194
2020-01-11 20:53:41.987772 UTC | [2020_01_11_02_30_29] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049678486
Z variance train             0.0041634706
KL Divergence                11.459419
KL Loss                      1.145942
QF Loss                      41.63983
VF Loss                      17.478931
Policy Loss                  -1574.0782
Q Predictions Mean           1574.9482
Q Predictions Std            282.6668
Q Predictions Max            1844.2745
Q Predictions Min            49.358273
V Predictions Mean           1574.73
V Predictions Std            282.30045
V Predictions Max            1837.5436
V Predictions Min            50.2268
Log Pis Mean                 -0.12264507
Log Pis Std                  1.8392332
Log Pis Max                  7.419871
Log Pis Min                  -4.660076
Policy mu Mean               -0.09586829
Policy mu Std                0.88810515
Policy mu Max                2.0498967
Policy mu Min                -2.6687665
Policy log std Mean          -0.5227255
Policy log std Std           0.18008173
Policy log std Max           0.13612181
Policy log std Min           -1.1013023
Z mean eval                  0.018505657
Z variance eval              0.0036967066
total_rewards                [2182.03307366 3375.5602736  2032.20929069 1730.71632982 1071.68442225
 1927.9236239  1934.82552258 1094.53378374 2421.37544593 1366.22424148]
total_rewards_mean           1913.7086007637056
total_rewards_std            647.6651727181234
total_rewards_max            3375.560273597099
total_rewards_min            1071.6844222458815
Number of train steps total  1584000
Number of env steps total    1930845
Number of rollouts total     0
Train Time (s)               144.06763305002823
(Previous) Eval Time (s)     17.597888646647334
Sample Time (s)              9.617749409750104
Epoch Time (s)               171.28327110642567
Total Train Time (s)         66363.01687380485
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:56:33.360885 UTC | [2020_01_11_02_30_29] Iteration #395 | Epoch Duration: 171.37300395965576
2020-01-11 20:56:33.361075 UTC | [2020_01_11_02_30_29] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018490583
Z variance train             0.003697149
KL Divergence                11.589832
KL Loss                      1.1589832
QF Loss                      50.5471
VF Loss                      31.236526
Policy Loss                  -1528.4867
Q Predictions Mean           1527.2947
Q Predictions Std            359.7117
Q Predictions Max            1829.5752
Q Predictions Min            31.793716
V Predictions Mean           1528.9624
V Predictions Std            358.61722
V Predictions Max            1831.9756
V Predictions Min            32.314842
Log Pis Mean                 -0.3002972
Log Pis Std                  1.7389225
Log Pis Max                  5.1297007
Log Pis Min                  -6.530721
Policy mu Mean               -0.1725992
Policy mu Std                0.84560907
Policy mu Max                2.2003763
Policy mu Min                -2.571523
Policy log std Mean          -0.5273344
Policy log std Std           0.18429092
Policy log std Max           0.06357533
Policy log std Min           -1.0675457
Z mean eval                  0.05137738
Z variance eval              0.0039108857
total_rewards                [ 908.76894594  935.08617961  667.2590963   751.1854351  3381.41803887
  681.0273588  1385.51224672  936.35832065 1441.88116534  924.90366664]
total_rewards_mean           1201.340045397447
total_rewards_std            768.5211622427918
total_rewards_max            3381.418038865988
total_rewards_min            667.2590962981859
Number of train steps total  1588000
Number of env steps total    1938479
Number of rollouts total     0
Train Time (s)               145.19741578307003
(Previous) Eval Time (s)     11.546575311105698
Sample Time (s)              10.290766238234937
Epoch Time (s)               167.03475733241066
Total Train Time (s)         66530.13267217483
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:59:20.484361 UTC | [2020_01_11_02_30_29] Iteration #396 | Epoch Duration: 167.12313032150269
2020-01-11 20:59:20.484690 UTC | [2020_01_11_02_30_29] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05141697
Z variance train             0.003911919
KL Divergence                11.490735
KL Loss                      1.1490735
QF Loss                      29.93294
VF Loss                      18.18126
Policy Loss                  -1541.2471
Q Predictions Mean           1542.4543
Q Predictions Std            310.5298
Q Predictions Max            1842.9269
Q Predictions Min            121.73781
V Predictions Mean           1540.8181
V Predictions Std            309.95007
V Predictions Max            1837.3785
V Predictions Min            117.727905
Log Pis Mean                 -0.30831864
Log Pis Std                  1.7917153
Log Pis Max                  5.0007343
Log Pis Min                  -7.222082
Policy mu Mean               -0.156588
Policy mu Std                0.8076752
Policy mu Max                1.9578223
Policy mu Min                -2.2176945
Policy log std Mean          -0.4774723
Policy log std Std           0.178464
Policy log std Max           0.023649335
Policy log std Min           -1.0106518
Z mean eval                  0.036786865
Z variance eval              0.003837599
total_rewards                [1551.36582153 1225.94330407 1428.24031122  895.76098275 3022.87345968
 2359.35596415 1532.22096022  755.17754263 1008.67137168  959.95377563]
total_rewards_mean           1473.9563493559492
total_rewards_std            677.3260456960408
total_rewards_max            3022.8734596815034
total_rewards_min            755.1775426282688
Number of train steps total  1592000
Number of env steps total    1946394
Number of rollouts total     0
Train Time (s)               144.25023205718026
(Previous) Eval Time (s)     14.19594857422635
Sample Time (s)              10.213069478515536
Epoch Time (s)               168.65925010992214
Total Train Time (s)         66698.87706603296
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:02:09.229994 UTC | [2020_01_11_02_30_29] Iteration #397 | Epoch Duration: 168.7450156211853
2020-01-11 21:02:09.230255 UTC | [2020_01_11_02_30_29] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037154384
Z variance train             0.0038391068
KL Divergence                11.50791
KL Loss                      1.150791
QF Loss                      80.57851
VF Loss                      48.84384
Policy Loss                  -1546.4146
Q Predictions Mean           1545.7482
Q Predictions Std            302.78308
Q Predictions Max            1845.4519
Q Predictions Min            43.58554
V Predictions Mean           1542.4648
V Predictions Std            303.1059
V Predictions Max            1841.0957
V Predictions Min            46.067425
Log Pis Mean                 -0.21770462
Log Pis Std                  2.0506287
Log Pis Max                  10.592285
Log Pis Min                  -6.1948986
Policy mu Mean               -0.27246645
Policy mu Std                0.8316059
Policy mu Max                1.6178861
Policy mu Min                -3.3308723
Policy log std Mean          -0.47263256
Policy log std Std           0.18048625
Policy log std Max           0.17297155
Policy log std Min           -1.0413
Z mean eval                  0.03563174
Z variance eval              0.004472128
total_rewards                [2226.1951971  2413.12587333  975.11401944  922.71754461 2341.16590657
  898.72336178  930.63235128 1155.72517967 1693.53242884 3348.87253818]
total_rewards_mean           1690.580440079209
total_rewards_std            810.8201047170985
total_rewards_max            3348.872538180135
total_rewards_min            898.7233617756326
Number of train steps total  1596000
Number of env steps total    1954579
Number of rollouts total     0
Train Time (s)               144.96410090010613
(Previous) Eval Time (s)     16.91975409304723
Sample Time (s)              10.323801495600492
Epoch Time (s)               172.20765648875386
Total Train Time (s)         66871.16484234808
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:05:01.521947 UTC | [2020_01_11_02_30_29] Iteration #398 | Epoch Duration: 172.29152059555054
2020-01-11 21:05:01.522177 UTC | [2020_01_11_02_30_29] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035655145
Z variance train             0.004472494
KL Divergence                11.158319
KL Loss                      1.115832
QF Loss                      45.54487
VF Loss                      17.233482
Policy Loss                  -1498.1144
Q Predictions Mean           1497.7565
Q Predictions Std            335.59207
Q Predictions Max            1824.5864
Q Predictions Min            101.47035
V Predictions Mean           1497.1606
V Predictions Std            334.07935
V Predictions Max            1825.867
V Predictions Min            121.48068
Log Pis Mean                 -0.33388156
Log Pis Std                  1.7670578
Log Pis Max                  7.002775
Log Pis Min                  -5.284116
Policy mu Mean               -0.14192115
Policy mu Std                0.8528107
Policy mu Max                2.0447593
Policy mu Min                -2.401691
Policy log std Mean          -0.50474936
Policy log std Std           0.19085607
Policy log std Max           0.115852356
Policy log std Min           -1.3197436
Z mean eval                  0.042139415
Z variance eval              0.0038042248
total_rewards                [1139.94710922 1733.70301975 1178.38403575 1687.47398691  985.44709246
 1146.41275685 3045.32222477 2070.38251554 1252.50461512 3346.58395638]
total_rewards_mean           1758.616131273983
total_rewards_std            789.1949933547983
total_rewards_max            3346.5839563811924
total_rewards_min            985.4470924565198
Number of train steps total  1600000
Number of env steps total    1962407
Number of rollouts total     0
Train Time (s)               153.04225725121796
(Previous) Eval Time (s)     17.838963424786925
Sample Time (s)              10.350538408383727
Epoch Time (s)               181.2317590843886
Total Train Time (s)         67052.48746853694
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:08:02.849332 UTC | [2020_01_11_02_30_29] Iteration #399 | Epoch Duration: 181.3269965648651
2020-01-11 21:08:02.849543 UTC | [2020_01_11_02_30_29] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042137396
Z variance train             0.0038040676
KL Divergence                11.511965
KL Loss                      1.1511965
QF Loss                      76.505844
VF Loss                      13.532442
Policy Loss                  -1509.6716
Q Predictions Mean           1507.1862
Q Predictions Std            329.83325
Q Predictions Max            1818.3307
Q Predictions Min            26.480125
V Predictions Mean           1510.1456
V Predictions Std            330.17114
V Predictions Max            1825.4324
V Predictions Min            42.364265
Log Pis Mean                 -0.3865329
Log Pis Std                  1.7682961
Log Pis Max                  5.5423613
Log Pis Min                  -4.3968306
Policy mu Mean               -0.08283762
Policy mu Std                0.8097708
Policy mu Max                1.9217517
Policy mu Min                -2.4130492
Policy log std Mean          -0.50400496
Policy log std Std           0.18120494
Policy log std Max           -0.028451502
Policy log std Min           -1.1803114
Z mean eval                  0.03877373
Z variance eval              0.0039252257
total_rewards                [ 901.10604588 1776.24357694 1078.39476997 1956.9338773  1439.46126656
 2207.44183424 3345.14331408 1378.32745958 2045.51149834 2936.22293404]
total_rewards_mean           1906.4786576938186
total_rewards_std            738.4504779232694
total_rewards_max            3345.1433140776667
total_rewards_min            901.1060458810118
Number of train steps total  1604000
Number of env steps total    1970349
Number of rollouts total     0
Train Time (s)               153.45549780130386
(Previous) Eval Time (s)     19.037742911837995
Sample Time (s)              11.020078629720956
Epoch Time (s)               183.51331934286281
Total Train Time (s)         67236.08159240428
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:11:06.448169 UTC | [2020_01_11_02_30_29] Iteration #400 | Epoch Duration: 183.59843516349792
2020-01-11 21:11:06.448491 UTC | [2020_01_11_02_30_29] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03905086
Z variance train             0.0039259223
KL Divergence                11.492902
KL Loss                      1.1492902
QF Loss                      77.09818
VF Loss                      35.04065
Policy Loss                  -1525.3337
Q Predictions Mean           1524.1051
Q Predictions Std            313.58823
Q Predictions Max            1833.4335
Q Predictions Min            100.67762
V Predictions Mean           1528.5522
V Predictions Std            312.55264
V Predictions Max            1837.3767
V Predictions Min            134.33934
Log Pis Mean                 -0.16887204
Log Pis Std                  1.8365194
Log Pis Max                  6.238476
Log Pis Min                  -4.8889947
Policy mu Mean               -0.13407256
Policy mu Std                0.8933112
Policy mu Max                2.6779532
Policy mu Min                -2.4157069
Policy log std Mean          -0.5082961
Policy log std Std           0.177805
Policy log std Max           0.14776146
Policy log std Min           -1.0300732
Z mean eval                  0.051261075
Z variance eval              0.003558044
total_rewards                [2832.46088139  877.12670499 2275.48927566  907.93568729 3402.06696855
 1944.81438393 2065.55719357 1014.06976497 1393.84680992 3332.02713197]
total_rewards_mean           2004.5394802252754
total_rewards_std            911.5393393384995
total_rewards_max            3402.0669685547646
total_rewards_min            877.1267049927808
Number of train steps total  1608000
Number of env steps total    1980312
Number of rollouts total     0
Train Time (s)               154.11079310020432
(Previous) Eval Time (s)     17.404543459881097
Sample Time (s)              10.76503028953448
Epoch Time (s)               182.2803668496199
Total Train Time (s)         67418.45584577322
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:14:08.830792 UTC | [2020_01_11_02_30_29] Iteration #401 | Epoch Duration: 182.38198614120483
2020-01-11 21:14:08.831240 UTC | [2020_01_11_02_30_29] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050896645
Z variance train             0.0035546354
KL Divergence                11.688446
KL Loss                      1.1688446
QF Loss                      131.63936
VF Loss                      31.63544
Policy Loss                  -1536.8849
Q Predictions Mean           1533.842
Q Predictions Std            292.3554
Q Predictions Max            1832.6583
Q Predictions Min            48.67577
V Predictions Mean           1538.5488
V Predictions Std            289.18195
V Predictions Max            1835.9801
V Predictions Min            64.688065
Log Pis Mean                 -0.23034835
Log Pis Std                  1.9845091
Log Pis Max                  10.149005
Log Pis Min                  -4.4758615
Policy mu Mean               -0.081735596
Policy mu Std                0.8823902
Policy mu Max                3.193081
Policy mu Min                -2.508409
Policy log std Mean          -0.4736726
Policy log std Std           0.1989877
Policy log std Max           0.099374115
Policy log std Min           -1.0597633
Z mean eval                  0.037194747
Z variance eval              0.0035636374
total_rewards                [2461.54458273 3337.54139593  888.42160494 3327.5392947  3352.33771773
 2914.92119328 1274.41758109 2083.87256652 1352.96453358 1436.0310084 ]
total_rewards_mean           2242.959147890684
total_rewards_std            913.5553888314291
total_rewards_max            3352.337717727025
total_rewards_min            888.4216049430634
Number of train steps total  1612000
Number of env steps total    1989567
Number of rollouts total     0
Train Time (s)               155.73441233485937
(Previous) Eval Time (s)     20.33591200876981
Sample Time (s)              11.147668638266623
Epoch Time (s)               187.2179929818958
Total Train Time (s)         67605.75020095566
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:17:16.126938 UTC | [2020_01_11_02_30_29] Iteration #402 | Epoch Duration: 187.29544758796692
2020-01-11 21:17:16.127082 UTC | [2020_01_11_02_30_29] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03731657
Z variance train             0.0035638604
KL Divergence                11.661167
KL Loss                      1.1661167
QF Loss                      52.88353
VF Loss                      24.73712
Policy Loss                  -1560.7617
Q Predictions Mean           1559.034
Q Predictions Std            277.70917
Q Predictions Max            1837.3737
Q Predictions Min            203.64561
V Predictions Mean           1559.6775
V Predictions Std            273.34827
V Predictions Max            1832.544
V Predictions Min            243.6507
Log Pis Mean                 -0.43959466
Log Pis Std                  1.7745618
Log Pis Max                  5.6994767
Log Pis Min                  -5.411825
Policy mu Mean               -0.108330786
Policy mu Std                0.8150011
Policy mu Max                1.5853872
Policy mu Min                -2.5916245
Policy log std Mean          -0.4931219
Policy log std Std           0.18516567
Policy log std Max           0.08538878
Policy log std Min           -0.9783647
Z mean eval                  0.055326324
Z variance eval              0.0036645127
total_rewards                [1364.95622575 1730.70033497 3233.52694472 2830.28391324 2776.72454659
 1447.85467845 1523.40788295 2226.08819281 1956.53675928 2193.30339841]
total_rewards_mean           2128.338287716961
total_rewards_std            612.1872667157411
total_rewards_max            3233.5269447225924
total_rewards_min            1364.9562257487225
Number of train steps total  1616000
Number of env steps total    1999383
Number of rollouts total     0
Train Time (s)               149.90116706024855
(Previous) Eval Time (s)     20.863560025114566
Sample Time (s)              9.088933885097504
Epoch Time (s)               179.85366097046062
Total Train Time (s)         67785.69206726458
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:20:16.073522 UTC | [2020_01_11_02_30_29] Iteration #403 | Epoch Duration: 179.94631671905518
2020-01-11 21:20:16.073730 UTC | [2020_01_11_02_30_29] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05540214
Z variance train             0.003666611
KL Divergence                11.599261
KL Loss                      1.1599262
QF Loss                      67.15552
VF Loss                      22.907703
Policy Loss                  -1569.2142
Q Predictions Mean           1571.083
Q Predictions Std            256.74808
Q Predictions Max            1840.1035
Q Predictions Min            78.475685
V Predictions Mean           1569.1339
V Predictions Std            254.21553
V Predictions Max            1840.6246
V Predictions Min            167.58238
Log Pis Mean                 -0.35587692
Log Pis Std                  1.7599304
Log Pis Max                  7.4021516
Log Pis Min                  -5.431925
Policy mu Mean               -0.08605979
Policy mu Std                0.8203041
Policy mu Max                2.0655553
Policy mu Min                -2.6212747
Policy log std Mean          -0.5250144
Policy log std Std           0.2029048
Policy log std Max           0.024581462
Policy log std Min           -1.1847813
Z mean eval                  0.07130976
Z variance eval              0.0034309789
total_rewards                [3319.22050181 3324.00150138 1690.90322852 1758.33718461 2773.08438025
 1898.65028058 2409.6061385   845.22914842 1761.8487005  2559.10989162]
total_rewards_mean           2233.9990956182905
total_rewards_std            746.8756734801111
total_rewards_max            3324.0015013818625
total_rewards_min            845.229148417071
Number of train steps total  1620000
Number of env steps total    2007931
Number of rollouts total     0
Train Time (s)               145.5382890100591
(Previous) Eval Time (s)     21.569798848591745
Sample Time (s)              9.471872540656477
Epoch Time (s)               176.5799603993073
Total Train Time (s)         67962.56189521449
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:23:12.945905 UTC | [2020_01_11_02_30_29] Iteration #404 | Epoch Duration: 176.8720326423645
2020-01-11 21:23:12.946062 UTC | [2020_01_11_02_30_29] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.071276955
Z variance train             0.0034297924
KL Divergence                11.84003
KL Loss                      1.184003
QF Loss                      123.39708
VF Loss                      27.514656
Policy Loss                  -1559.4458
Q Predictions Mean           1557.8054
Q Predictions Std            282.42047
Q Predictions Max            1831.8685
Q Predictions Min            69.34836
V Predictions Mean           1560.093
V Predictions Std            280.4636
V Predictions Max            1840.5009
V Predictions Min            47.413197
Log Pis Mean                 -0.02819144
Log Pis Std                  2.1262581
Log Pis Max                  7.403325
Log Pis Min                  -4.319766
Policy mu Mean               -0.19722009
Policy mu Std                0.9056522
Policy mu Max                2.7195737
Policy mu Min                -2.5243652
Policy log std Mean          -0.518319
Policy log std Std           0.1984785
Policy log std Max           0.11703181
Policy log std Min           -1.1280241
Z mean eval                  0.02232671
Z variance eval              0.0035303645
total_rewards                [1422.94973837 3365.27134172 3318.96587008 1155.5193782  1945.79776739
 2265.33725036 1465.24100124 2548.64954786 2796.16337649 1475.56523538]
total_rewards_mean           2175.9460507084195
total_rewards_std            768.7284563730831
total_rewards_max            3365.271341717509
total_rewards_min            1155.5193781951843
Number of train steps total  1624000
Number of env steps total    2018520
Number of rollouts total     0
Train Time (s)               144.3840859378688
(Previous) Eval Time (s)     18.68457907391712
Sample Time (s)              9.285808796528727
Epoch Time (s)               172.35447380831465
Total Train Time (s)         68134.99405147042
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:26:05.381518 UTC | [2020_01_11_02_30_29] Iteration #405 | Epoch Duration: 172.435307264328
2020-01-11 21:26:05.381722 UTC | [2020_01_11_02_30_29] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022308184
Z variance train             0.003530623
KL Divergence                11.755613
KL Loss                      1.1755613
QF Loss                      96.33056
VF Loss                      19.402178
Policy Loss                  -1582.251
Q Predictions Mean           1582.9568
Q Predictions Std            249.52469
Q Predictions Max            1850.4639
Q Predictions Min            115.53549
V Predictions Mean           1584.4956
V Predictions Std            247.27992
V Predictions Max            1856.3054
V Predictions Min            104.68493
Log Pis Mean                 -0.27217832
Log Pis Std                  1.8206211
Log Pis Max                  5.8047037
Log Pis Min                  -5.631204
Policy mu Mean               -0.09251192
Policy mu Std                0.84698546
Policy mu Max                2.2671294
Policy mu Min                -2.679124
Policy log std Mean          -0.50777715
Policy log std Std           0.18429936
Policy log std Max           0.15213305
Policy log std Min           -1.2104347
Z mean eval                  0.024789754
Z variance eval              0.0041949796
total_rewards                [ 931.64424396 2226.89157634  965.88887175 3341.55551587 3317.11645282
 3332.1913404  3353.40693703 1753.36733287 3340.7874271   933.01459151]
total_rewards_mean           2349.5864289644064
total_rewards_std            1057.2677256711343
total_rewards_max            3353.406937029225
total_rewards_min            931.64424395742
Number of train steps total  1628000
Number of env steps total    2027594
Number of rollouts total     0
Train Time (s)               145.63913125684485
(Previous) Eval Time (s)     22.776482214219868
Sample Time (s)              9.847295055631548
Epoch Time (s)               178.26290852669626
Total Train Time (s)         68313.336901139
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:29:03.728771 UTC | [2020_01_11_02_30_29] Iteration #406 | Epoch Duration: 178.3468713760376
2020-01-11 21:29:03.728989 UTC | [2020_01_11_02_30_29] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025230423
Z variance train             0.0042008692
KL Divergence                11.3206415
KL Loss                      1.1320642
QF Loss                      91.2944
VF Loss                      124.793205
Policy Loss                  -1592.7145
Q Predictions Mean           1591.095
Q Predictions Std            233.91762
Q Predictions Max            1832.9288
Q Predictions Min            138.49171
V Predictions Mean           1590.7148
V Predictions Std            230.77875
V Predictions Max            1838.029
V Predictions Min            148.0492
Log Pis Mean                 -0.09990816
Log Pis Std                  1.6400359
Log Pis Max                  4.739855
Log Pis Min                  -4.7812424
Policy mu Mean               -0.1109255
Policy mu Std                0.85109097
Policy mu Max                2.0981042
Policy mu Min                -2.279216
Policy log std Mean          -0.5142048
Policy log std Std           0.197829
Policy log std Max           0.13250768
Policy log std Min           -1.0383725
Z mean eval                  0.048306208
Z variance eval              0.0033328156
total_rewards                [1193.27520244 1439.89820028 1766.06384647 1606.50651196  898.36817155
  931.61686855 1498.90967916 2066.66900943 1462.84424641 1127.5874582 ]
total_rewards_mean           1399.173919442627
total_rewards_std            349.9105310701633
total_rewards_max            2066.6690094256637
total_rewards_min            898.3681715451428
Number of train steps total  1632000
Number of env steps total    2036630
Number of rollouts total     0
Train Time (s)               145.09909711731598
(Previous) Eval Time (s)     13.673447654116899
Sample Time (s)              9.53203708678484
Epoch Time (s)               168.30458185821772
Total Train Time (s)         68481.72446297575
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:31:52.121435 UTC | [2020_01_11_02_30_29] Iteration #407 | Epoch Duration: 168.39222264289856
2020-01-11 21:31:52.121700 UTC | [2020_01_11_02_30_29] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048346065
Z variance train             0.0033323213
KL Divergence                11.972354
KL Loss                      1.1972355
QF Loss                      87.45734
VF Loss                      25.984665
Policy Loss                  -1543.8186
Q Predictions Mean           1543.397
Q Predictions Std            347.4597
Q Predictions Max            1823.1116
Q Predictions Min            26.950768
V Predictions Mean           1541.117
V Predictions Std            347.34235
V Predictions Max            1824.1017
V Predictions Min            28.314663
Log Pis Mean                 -0.305143
Log Pis Std                  1.6014647
Log Pis Max                  5.2327423
Log Pis Min                  -5.371164
Policy mu Mean               -0.12486094
Policy mu Std                0.8558541
Policy mu Max                2.0308583
Policy mu Min                -2.2761629
Policy log std Mean          -0.49894747
Policy log std Std           0.18890242
Policy log std Max           0.11910224
Policy log std Min           -0.9710578
Z mean eval                  0.031065408
Z variance eval              0.0034170211
total_rewards                [ 895.30415856 1775.32198672 3315.62871275 3324.87287511 1645.89986588
 1765.5739953   983.46300952  967.25510629 1233.73935278 3434.8073873 ]
total_rewards_mean           1934.1866450199923
total_rewards_std            981.823086055449
total_rewards_max            3434.8073872984774
total_rewards_min            895.3041585577114
Number of train steps total  1636000
Number of env steps total    2046934
Number of rollouts total     0
Train Time (s)               145.8581003351137
(Previous) Eval Time (s)     18.487364729866385
Sample Time (s)              9.526090130675584
Epoch Time (s)               173.87155519565567
Total Train Time (s)         68655.6755570909
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:34:46.076353 UTC | [2020_01_11_02_30_29] Iteration #408 | Epoch Duration: 173.95447826385498
2020-01-11 21:34:46.076548 UTC | [2020_01_11_02_30_29] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031120012
Z variance train             0.003416577
KL Divergence                11.855736
KL Loss                      1.1855736
QF Loss                      28.610537
VF Loss                      12.79352
Policy Loss                  -1580.2498
Q Predictions Mean           1579.8115
Q Predictions Std            270.05505
Q Predictions Max            1846.3153
Q Predictions Min            138.82275
V Predictions Mean           1581.7404
V Predictions Std            271.4264
V Predictions Max            1848.9059
V Predictions Min            148.04301
Log Pis Mean                 -0.15439048
Log Pis Std                  1.8726826
Log Pis Max                  9.492941
Log Pis Min                  -5.957585
Policy mu Mean               -0.03680375
Policy mu Std                0.8405901
Policy mu Max                2.0586321
Policy mu Min                -2.6513484
Policy log std Mean          -0.5003454
Policy log std Std           0.19658986
Policy log std Max           0.17053336
Policy log std Min           -1.0754542
Z mean eval                  0.025448937
Z variance eval              0.0040210867
total_rewards                [1184.02075779  943.70672462  950.30115256 2591.76901243  931.10443786
 3006.80385402 2489.93042673 1429.52055013 1995.79827222 1639.51044267]
total_rewards_mean           1716.246563101788
total_rewards_std            726.6440969723533
total_rewards_max            3006.803854015237
total_rewards_min            931.104437860674
Number of train steps total  1640000
Number of env steps total    2057735
Number of rollouts total     0
Train Time (s)               145.2420587297529
(Previous) Eval Time (s)     15.441365175880492
Sample Time (s)              10.600809659343213
Epoch Time (s)               171.2842335649766
Total Train Time (s)         68827.07386006135
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:37:37.479551 UTC | [2020_01_11_02_30_29] Iteration #409 | Epoch Duration: 171.40284609794617
2020-01-11 21:37:37.479762 UTC | [2020_01_11_02_30_29] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025415441
Z variance train             0.0040223943
KL Divergence                11.401349
KL Loss                      1.1401349
QF Loss                      79.57794
VF Loss                      25.38087
Policy Loss                  -1547.8188
Q Predictions Mean           1546.7158
Q Predictions Std            301.96622
Q Predictions Max            1822.3625
Q Predictions Min            193.02045
V Predictions Mean           1547.7421
V Predictions Std            302.90808
V Predictions Max            1832.084
V Predictions Min            186.74068
Log Pis Mean                 -0.041239113
Log Pis Std                  1.8395355
Log Pis Max                  5.021375
Log Pis Min                  -6.0062203
Policy mu Mean               -0.124162875
Policy mu Std                0.8817374
Policy mu Max                3.0987368
Policy mu Min                -2.321052
Policy log std Mean          -0.5129306
Policy log std Std           0.16897848
Policy log std Max           -0.059682608
Policy log std Min           -1.1409283
Z mean eval                  0.024135793
Z variance eval              0.0037409961
total_rewards                [ 671.37209237 3020.44940087 2960.63795808  896.25940178 3271.93027175
  831.54643378 3293.98965218 1933.98769126 2048.54959906 1962.45585916]
total_rewards_mean           2089.117836030414
total_rewards_std            976.4139300459076
total_rewards_max            3293.989652179186
total_rewards_min            671.372092372363
Number of train steps total  1644000
Number of env steps total    2066586
Number of rollouts total     0
Train Time (s)               145.230331429746
(Previous) Eval Time (s)     19.897545404732227
Sample Time (s)              10.10725980065763
Epoch Time (s)               175.23513663513586
Total Train Time (s)         69002.3865985251
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:40:32.796143 UTC | [2020_01_11_02_30_29] Iteration #410 | Epoch Duration: 175.3162305355072
2020-01-11 21:40:32.796326 UTC | [2020_01_11_02_30_29] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024054887
Z variance train             0.0037400045
KL Divergence                11.593262
KL Loss                      1.1593262
QF Loss                      118.67264
VF Loss                      66.16415
Policy Loss                  -1590.8505
Q Predictions Mean           1589.884
Q Predictions Std            256.36465
Q Predictions Max            1830.6818
Q Predictions Min            96.274826
V Predictions Mean           1584.6853
V Predictions Std            254.22711
V Predictions Max            1826.6265
V Predictions Min            135.64972
Log Pis Mean                 -0.0686536
Log Pis Std                  1.9544713
Log Pis Max                  11.01748
Log Pis Min                  -4.6654654
Policy mu Mean               0.085642815
Policy mu Std                0.89328706
Policy mu Max                3.170326
Policy mu Min                -2.4232805
Policy log std Mean          -0.5173113
Policy log std Std           0.16993251
Policy log std Max           0.12626588
Policy log std Min           -0.967598
Z mean eval                  0.08475277
Z variance eval              0.0035850443
total_rewards                [2316.25113101 2124.44557881 3323.00726222 2369.62225359 2031.09260488
  963.91952992 3314.20869889 1497.35282359 1434.46941538 3406.4465841 ]
total_rewards_mean           2278.081588239061
total_rewards_std            811.2534513854157
total_rewards_max            3406.4465840984903
total_rewards_min            963.9195299162852
Number of train steps total  1648000
Number of env steps total    2076001
Number of rollouts total     0
Train Time (s)               145.1284053917043
(Previous) Eval Time (s)     21.67841411801055
Sample Time (s)              10.344929849728942
Epoch Time (s)               177.15174935944378
Total Train Time (s)         69179.6197330947
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:43:30.034997 UTC | [2020_01_11_02_30_29] Iteration #411 | Epoch Duration: 177.23849892616272
2020-01-11 21:43:30.035365 UTC | [2020_01_11_02_30_29] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08471254
Z variance train             0.0035856615
KL Divergence                11.706615
KL Loss                      1.1706616
QF Loss                      44.739655
VF Loss                      21.989601
Policy Loss                  -1549.0237
Q Predictions Mean           1547.7578
Q Predictions Std            318.24478
Q Predictions Max            1828.7928
Q Predictions Min            30.78762
V Predictions Mean           1547.2349
V Predictions Std            317.7868
V Predictions Max            1825.726
V Predictions Min            12.430936
Log Pis Mean                 -0.1928857
Log Pis Std                  1.8578088
Log Pis Max                  6.1778574
Log Pis Min                  -5.4799023
Policy mu Mean               -0.0862283
Policy mu Std                0.8631938
Policy mu Max                2.2244236
Policy mu Min                -2.1209495
Policy log std Mean          -0.5006061
Policy log std Std           0.17793454
Policy log std Max           0.04081306
Policy log std Min           -0.9807035
Z mean eval                  0.0719138
Z variance eval              0.0032547873
total_rewards                [3324.25760466 1196.9541114  2018.07106227 2719.40497927 1269.67789702
 2201.05522464  914.80208689 2916.17634654 1995.33173183 3259.65880354]
total_rewards_mean           2181.5389848054565
total_rewards_std            822.4619286173188
total_rewards_max            3324.257604664094
total_rewards_min            914.8020868905544
Number of train steps total  1652000
Number of env steps total    2084176
Number of rollouts total     0
Train Time (s)               146.02076426008716
(Previous) Eval Time (s)     20.863491508178413
Sample Time (s)              9.89036727603525
Epoch Time (s)               176.77462304430082
Total Train Time (s)         69356.47438779008
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:46:26.893569 UTC | [2020_01_11_02_30_29] Iteration #412 | Epoch Duration: 176.85799050331116
2020-01-11 21:46:26.893769 UTC | [2020_01_11_02_30_29] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.071805775
Z variance train             0.0032548003
KL Divergence                11.916829
KL Loss                      1.1916829
QF Loss                      37.869576
VF Loss                      24.868843
Policy Loss                  -1543.0922
Q Predictions Mean           1542.105
Q Predictions Std            315.369
Q Predictions Max            1839.4515
Q Predictions Min            50.969086
V Predictions Mean           1541.5856
V Predictions Std            314.5013
V Predictions Max            1830.8147
V Predictions Min            43.7638
Log Pis Mean                 -0.09055985
Log Pis Std                  1.7768778
Log Pis Max                  6.054979
Log Pis Min                  -4.6146307
Policy mu Mean               -0.030553453
Policy mu Std                0.8793651
Policy mu Max                2.2526774
Policy mu Min                -2.5913668
Policy log std Mean          -0.5076647
Policy log std Std           0.18975504
Policy log std Max           0.07565269
Policy log std Min           -1.054255
Z mean eval                  0.011959305
Z variance eval              0.003730933
total_rewards                [ 991.80947143 2052.87143316 2266.56405322 1417.12541943  886.30280089
  968.17247    2721.6113351  1239.64793214 1698.53668987 1023.52467482]
total_rewards_mean           1526.6166280046327
total_rewards_std            603.1049999573718
total_rewards_max            2721.6113350992923
total_rewards_min            886.3028008903129
Number of train steps total  1656000
Number of env steps total    2092699
Number of rollouts total     0
Train Time (s)               145.82252693874761
(Previous) Eval Time (s)     13.946002227254212
Sample Time (s)              9.576644360087812
Epoch Time (s)               169.34517352608964
Total Train Time (s)         69525.8993993979
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:49:16.322889 UTC | [2020_01_11_02_30_29] Iteration #413 | Epoch Duration: 169.42897152900696
2020-01-11 21:49:16.323093 UTC | [2020_01_11_02_30_29] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011989156
Z variance train             0.0037298067
KL Divergence                11.597504
KL Loss                      1.1597503
QF Loss                      76.37971
VF Loss                      29.90606
Policy Loss                  -1557.8163
Q Predictions Mean           1554.0707
Q Predictions Std            298.00604
Q Predictions Max            1825.6088
Q Predictions Min            10.844578
V Predictions Mean           1560.8989
V Predictions Std            294.3326
V Predictions Max            1833.1458
V Predictions Min            50.10431
Log Pis Mean                 -0.35004407
Log Pis Std                  1.8468212
Log Pis Max                  10.848366
Log Pis Min                  -4.6188903
Policy mu Mean               0.02929031
Policy mu Std                0.86394423
Policy mu Max                2.8716958
Policy mu Min                -2.5254197
Policy log std Mean          -0.5022815
Policy log std Std           0.18430917
Policy log std Max           0.15121311
Policy log std Min           -1.0843291
Z mean eval                  0.012903241
Z variance eval              0.0034987393
total_rewards                [3250.31994089 1783.66647011 3370.91195035 3351.96307593  896.14238478
 3347.44095767 2274.13700902 2274.68124115 3034.98752672 1485.92401679]
total_rewards_mean           2507.0174573412414
total_rewards_std            852.4558530844693
total_rewards_max            3370.911950353377
total_rewards_min            896.1423847813537
Number of train steps total  1660000
Number of env steps total    2101315
Number of rollouts total     0
Train Time (s)               143.52154462691396
(Previous) Eval Time (s)     23.665184177923948
Sample Time (s)              9.651303470134735
Epoch Time (s)               176.83803227497265
Total Train Time (s)         69702.83608607063
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:52:13.264565 UTC | [2020_01_11_02_30_29] Iteration #414 | Epoch Duration: 176.94117212295532
2020-01-11 21:52:13.264821 UTC | [2020_01_11_02_30_29] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012868178
Z variance train             0.0034983954
KL Divergence                11.772912
KL Loss                      1.1772913
QF Loss                      81.93293
VF Loss                      21.448952
Policy Loss                  -1544.1924
Q Predictions Mean           1543.1865
Q Predictions Std            273.31323
Q Predictions Max            1829.2852
Q Predictions Min            154.84056
V Predictions Mean           1545.5107
V Predictions Std            272.389
V Predictions Max            1826.4708
V Predictions Min            202.39297
Log Pis Mean                 -0.3894391
Log Pis Std                  1.9168736
Log Pis Max                  9.414182
Log Pis Min                  -7.1945996
Policy mu Mean               -0.06643373
Policy mu Std                0.84016633
Policy mu Max                2.420434
Policy mu Min                -3.1377215
Policy log std Mean          -0.49294496
Policy log std Std           0.1777579
Policy log std Max           0.07780397
Policy log std Min           -1.0293567
Z mean eval                  0.05759257
Z variance eval              0.004050071
total_rewards                [2009.89355567 1462.30593011 1204.9943615  2665.96838139 1017.51377357
  958.35293013 1039.0939643  2016.9293004  2874.87275628 2207.77889789]
total_rewards_mean           1745.7703851222948
total_rewards_std            670.8906690907431
total_rewards_max            2874.872756281794
total_rewards_min            958.3529301319409
Number of train steps total  1664000
Number of env steps total    2110010
Number of rollouts total     0
Train Time (s)               145.29038145998493
(Previous) Eval Time (s)     15.791749803815037
Sample Time (s)              10.02838505199179
Epoch Time (s)               171.11051631579176
Total Train Time (s)         69874.04588348232
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:55:04.478543 UTC | [2020_01_11_02_30_29] Iteration #415 | Epoch Duration: 171.2135488986969
2020-01-11 21:55:04.478775 UTC | [2020_01_11_02_30_29] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057584643
Z variance train             0.004052361
KL Divergence                11.41119
KL Loss                      1.141119
QF Loss                      61.279156
VF Loss                      45.78395
Policy Loss                  -1566.1073
Q Predictions Mean           1566.9125
Q Predictions Std            285.16846
Q Predictions Max            1846.4266
Q Predictions Min            178.88908
V Predictions Mean           1566.3387
V Predictions Std            285.406
V Predictions Max            1837.9355
V Predictions Min            169.8622
Log Pis Mean                 -0.06824432
Log Pis Std                  2.0316174
Log Pis Max                  7.517749
Log Pis Min                  -4.477399
Policy mu Mean               -0.27363524
Policy mu Std                0.8572122
Policy mu Max                1.5905086
Policy mu Min                -3.3912685
Policy log std Mean          -0.51574427
Policy log std Std           0.19838554
Policy log std Max           0.098297596
Policy log std Min           -1.0995586
Z mean eval                  0.052057754
Z variance eval              0.004309642
total_rewards                [1866.97833645  935.37048264 3393.28820668 3406.53124808 3420.65484969
 1428.48493287 2539.10490837 1021.96081476 2036.87068851 3439.27125226]
total_rewards_mean           2348.851572030584
total_rewards_std            975.6374514687029
total_rewards_max            3439.271252263417
total_rewards_min            935.3704826422055
Number of train steps total  1668000
Number of env steps total    2117995
Number of rollouts total     0
Train Time (s)               144.76236874284223
(Previous) Eval Time (s)     21.90647978009656
Sample Time (s)              9.747409956064075
Epoch Time (s)               176.41625847900286
Total Train Time (s)         70050.61767868372
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:58:01.053013 UTC | [2020_01_11_02_30_29] Iteration #416 | Epoch Duration: 176.57409381866455
2020-01-11 21:58:01.053149 UTC | [2020_01_11_02_30_29] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05118967
Z variance train             0.0043125167
KL Divergence                11.251129
KL Loss                      1.1251129
QF Loss                      85.95031
VF Loss                      181.64006
Policy Loss                  -1517.154
Q Predictions Mean           1519.6228
Q Predictions Std            361.20074
Q Predictions Max            1826.388
Q Predictions Min            26.367111
V Predictions Mean           1529.1915
V Predictions Std            359.8485
V Predictions Max            1840.4385
V Predictions Min            45.564724
Log Pis Mean                 -0.17623314
Log Pis Std                  1.861992
Log Pis Max                  5.2635555
Log Pis Min                  -5.679
Policy mu Mean               -0.1074091
Policy mu Std                0.865853
Policy mu Max                2.4134042
Policy mu Min                -2.4203832
Policy log std Mean          -0.49842295
Policy log std Std           0.1817592
Policy log std Max           0.1615963
Policy log std Min           -0.9835026
Z mean eval                  0.026338574
Z variance eval              0.004352729
total_rewards                [2521.68631757 1537.51618095 2215.58003565 2262.91761826 1776.36323173
 3285.17652772 3329.2056231  1201.34784631 1752.69795277 2961.77760074]
total_rewards_mean           2284.4268934802108
total_rewards_std            698.9392794574723
total_rewards_max            3329.2056230988724
total_rewards_min            1201.3478463119911
Number of train steps total  1672000
Number of env steps total    2127633
Number of rollouts total     0
Train Time (s)               147.98533788323402
(Previous) Eval Time (s)     21.207940850872546
Sample Time (s)              9.820250245276839
Epoch Time (s)               179.0135289793834
Total Train Time (s)         70229.709258663
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:01:00.149360 UTC | [2020_01_11_02_30_29] Iteration #417 | Epoch Duration: 179.09609603881836
2020-01-11 22:01:00.149556 UTC | [2020_01_11_02_30_29] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026312202
Z variance train             0.0043565244
KL Divergence                11.15959
KL Loss                      1.115959
QF Loss                      53.528084
VF Loss                      49.15871
Policy Loss                  -1511.6359
Q Predictions Mean           1513.7086
Q Predictions Std            341.27817
Q Predictions Max            1835.7302
Q Predictions Min            16.487926
V Predictions Mean           1511.987
V Predictions Std            338.43134
V Predictions Max            1825.0145
V Predictions Min            -2.2226489
Log Pis Mean                 -0.45093435
Log Pis Std                  1.7459747
Log Pis Max                  6.083396
Log Pis Min                  -5.219372
Policy mu Mean               -0.12407606
Policy mu Std                0.80218035
Policy mu Max                2.3146064
Policy mu Min                -2.261292
Policy log std Mean          -0.5048445
Policy log std Std           0.18423435
Policy log std Max           0.24972141
Policy log std Min           -1.1069846
Z mean eval                  0.03727321
Z variance eval              0.00460117
total_rewards                [1233.34390765 1534.22486229 1416.27288238 1720.76601446 1238.53177263
 2804.76806572 1732.52916607 3012.54487382 1488.3417086  1565.19168562]
total_rewards_mean           1774.6514939227695
total_rewards_std            590.8234308371988
total_rewards_max            3012.5448738175974
total_rewards_min            1233.3439076508175
Number of train steps total  1676000
Number of env steps total    2138116
Number of rollouts total     0
Train Time (s)               154.68829650990665
(Previous) Eval Time (s)     18.01434919098392
Sample Time (s)              9.780748370103538
Epoch Time (s)               182.4833940709941
Total Train Time (s)         70412.28559752367
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:04:02.730182 UTC | [2020_01_11_02_30_29] Iteration #418 | Epoch Duration: 182.5804738998413
2020-01-11 22:04:02.730396 UTC | [2020_01_11_02_30_29] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037166618
Z variance train             0.004602167
KL Divergence                11.040532
KL Loss                      1.1040533
QF Loss                      35.15827
VF Loss                      11.738087
Policy Loss                  -1578.8154
Q Predictions Mean           1579.8232
Q Predictions Std            234.04813
Q Predictions Max            1836.4691
Q Predictions Min            277.01917
V Predictions Mean           1580.175
V Predictions Std            233.18237
V Predictions Max            1835.5084
V Predictions Min            302.1927
Log Pis Mean                 -0.40612134
Log Pis Std                  1.7051316
Log Pis Max                  5.6301
Log Pis Min                  -6.6908455
Policy mu Mean               -0.054907817
Policy mu Std                0.84739226
Policy mu Max                2.0336673
Policy mu Min                -2.4626007
Policy log std Mean          -0.49171725
Policy log std Std           0.19984014
Policy log std Max           0.14333057
Policy log std Min           -1.0854295
Z mean eval                  0.055834197
Z variance eval              0.003899394
total_rewards                [1858.0541834  3298.06484883 2940.01029204 1976.06246672 1126.43074952
 1118.62092338 2223.28224147 2299.46413327 1512.11985443 3325.65790718]
total_rewards_mean           2167.7767600242223
total_rewards_std            773.4794678010657
total_rewards_max            3325.657907182508
total_rewards_min            1118.6209233810334
Number of train steps total  1680000
Number of env steps total    2148478
Number of rollouts total     0
Train Time (s)               152.42546926811337
(Previous) Eval Time (s)     21.409581935964525
Sample Time (s)              10.657874829601496
Epoch Time (s)               184.4929260336794
Total Train Time (s)         70596.85393054783
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:07:07.302590 UTC | [2020_01_11_02_30_29] Iteration #419 | Epoch Duration: 184.5720410346985
2020-01-11 22:07:07.302768 UTC | [2020_01_11_02_30_29] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05583533
Z variance train             0.0038983696
KL Divergence                11.432126
KL Loss                      1.1432127
QF Loss                      1063.3894
VF Loss                      13.409798
Policy Loss                  -1559.031
Q Predictions Mean           1555.5459
Q Predictions Std            263.9893
Q Predictions Max            1827.5503
Q Predictions Min            317.78033
V Predictions Mean           1557.7758
V Predictions Std            261.73175
V Predictions Max            1826.6299
V Predictions Min            340.26498
Log Pis Mean                 -0.26767027
Log Pis Std                  1.7357777
Log Pis Max                  4.81971
Log Pis Min                  -5.4237275
Policy mu Mean               -0.10778487
Policy mu Std                0.8327572
Policy mu Max                1.8748224
Policy mu Min                -2.735132
Policy log std Mean          -0.49836826
Policy log std Std           0.18997777
Policy log std Max           0.33099127
Policy log std Min           -1.149833
Z mean eval                  0.07320891
Z variance eval              0.0032306067
total_rewards                [1165.80368586 3224.90452154 1511.15552142 2341.0396932  3317.40264416
 3058.20506529 3141.82501813 1415.54248768 3330.0421586  2692.73671709]
total_rewards_mean           2519.8657512990053
total_rewards_std            812.3143803905472
total_rewards_max            3330.0421586045995
total_rewards_min            1165.803685864612
Number of train steps total  1684000
Number of env steps total    2158503
Number of rollouts total     0
Train Time (s)               152.98332779668272
(Previous) Eval Time (s)     24.6563449180685
Sample Time (s)              10.819469444453716
Epoch Time (s)               188.45914215920493
Total Train Time (s)         70785.39884061506
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:10:15.852440 UTC | [2020_01_11_02_30_29] Iteration #420 | Epoch Duration: 188.54952096939087
2020-01-11 22:10:15.852661 UTC | [2020_01_11_02_30_29] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07309565
Z variance train             0.003229476
KL Divergence                11.901741
KL Loss                      1.1901741
QF Loss                      45.686367
VF Loss                      31.723629
Policy Loss                  -1557.4553
Q Predictions Mean           1559.4517
Q Predictions Std            276.52716
Q Predictions Max            1818.7668
Q Predictions Min            56.01803
V Predictions Mean           1559.3237
V Predictions Std            273.41232
V Predictions Max            1823.5098
V Predictions Min            120.85538
Log Pis Mean                 -0.28385854
Log Pis Std                  1.7108958
Log Pis Max                  5.1725736
Log Pis Min                  -4.9237375
Policy mu Mean               -0.027240122
Policy mu Std                0.85626
Policy mu Max                3.3112857
Policy mu Min                -2.5368774
Policy log std Mean          -0.5169094
Policy log std Std           0.18173294
Policy log std Max           0.07724762
Policy log std Min           -1.1153152
Z mean eval                  0.031483363
Z variance eval              0.0026879145
total_rewards                [1489.16663061  648.86744693 1481.4136858  1549.08828313 1707.1862249
 1509.43961412 1697.38870927 1531.19326386 1808.80347512  975.05007809]
total_rewards_mean           1439.7597411844513
total_rewards_std            338.3626419532608
total_rewards_max            1808.8034751239602
total_rewards_min            648.8674469346125
Number of train steps total  1688000
Number of env steps total    2166833
Number of rollouts total     0
Train Time (s)               155.18188013788313
(Previous) Eval Time (s)     14.080242461990565
Sample Time (s)              11.036785933189094
Epoch Time (s)               180.2989085330628
Total Train Time (s)         70965.91955740424
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:13:16.377919 UTC | [2020_01_11_02_30_29] Iteration #421 | Epoch Duration: 180.52509188652039
2020-01-11 22:13:16.378136 UTC | [2020_01_11_02_30_29] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03134518
Z variance train             0.0026881117
KL Divergence                12.337347
KL Loss                      1.2337347
QF Loss                      55.208866
VF Loss                      22.858578
Policy Loss                  -1592.8173
Q Predictions Mean           1591.1334
Q Predictions Std            254.45139
Q Predictions Max            1830.7904
Q Predictions Min            75.37736
V Predictions Mean           1593.494
V Predictions Std            245.60376
V Predictions Max            1830.1761
V Predictions Min            130.35991
Log Pis Mean                 -0.051670734
Log Pis Std                  1.9775817
Log Pis Max                  7.0649157
Log Pis Min                  -4.267826
Policy mu Mean               -0.12657249
Policy mu Std                0.8915172
Policy mu Max                2.151546
Policy mu Min                -2.8956134
Policy log std Mean          -0.49662152
Policy log std Std           0.1886383
Policy log std Max           -0.0014227629
Policy log std Min           -1.2763437
Z mean eval                  0.092522144
Z variance eval              0.0024361345
total_rewards                [ 664.63687091  729.62563396 1807.64626095  972.82419526  682.57246825
 2027.01738644 2279.52381637 2276.68959397 3015.77344465 3372.19546567]
total_rewards_mean           1782.8505136438157
total_rewards_std            939.3268248983005
total_rewards_max            3372.1954656717353
total_rewards_min            664.6368709141962
Number of train steps total  1692000
Number of env steps total    2176837
Number of rollouts total     0
Train Time (s)               150.7020246349275
(Previous) Eval Time (s)     16.15390634862706
Sample Time (s)              10.239125126507133
Epoch Time (s)               177.0950561100617
Total Train Time (s)         71143.09569998365
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:16:13.558661 UTC | [2020_01_11_02_30_29] Iteration #422 | Epoch Duration: 177.18035054206848
2020-01-11 22:16:13.558884 UTC | [2020_01_11_02_30_29] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09275078
Z variance train             0.0024352868
KL Divergence                12.630563
KL Loss                      1.2630563
QF Loss                      104.756676
VF Loss                      63.220016
Policy Loss                  -1596.9541
Q Predictions Mean           1594.8828
Q Predictions Std            250.10756
Q Predictions Max            1827.9114
Q Predictions Min            52.07874
V Predictions Mean           1593.7269
V Predictions Std            240.58563
V Predictions Max            1827.4374
V Predictions Min            108.73986
Log Pis Mean                 -0.3047037
Log Pis Std                  1.8426065
Log Pis Max                  7.3116865
Log Pis Min                  -5.794547
Policy mu Mean               -0.096317925
Policy mu Std                0.85120684
Policy mu Max                2.3307467
Policy mu Min                -2.6488583
Policy log std Mean          -0.4802103
Policy log std Std           0.19705752
Policy log std Max           0.1652093
Policy log std Min           -1.3829288
Z mean eval                  0.054658186
Z variance eval              0.0027558554
total_rewards                [2415.29374159 3468.1083652   973.48526097 1370.38664399 1916.95046131
 1725.88308479 1198.53811189 1502.18228554 1172.05878698 1683.95428554]
total_rewards_mean           1742.6841027801952
total_rewards_std            698.0984408753018
total_rewards_max            3468.1083652005404
total_rewards_min            973.4852609695934
Number of train steps total  1696000
Number of env steps total    2184884
Number of rollouts total     0
Train Time (s)               145.0727906562388
(Previous) Eval Time (s)     16.21017111139372
Sample Time (s)              10.46652314811945
Epoch Time (s)               171.74948491575196
Total Train Time (s)         71314.93325163005
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:19:05.401538 UTC | [2020_01_11_02_30_29] Iteration #423 | Epoch Duration: 171.84247183799744
2020-01-11 22:19:05.401821 UTC | [2020_01_11_02_30_29] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054545544
Z variance train             0.002755924
KL Divergence                12.423346
KL Loss                      1.2423346
QF Loss                      74.522
VF Loss                      22.979446
Policy Loss                  -1569.7415
Q Predictions Mean           1567.4604
Q Predictions Std            277.99902
Q Predictions Max            1830.7682
Q Predictions Min            42.97899
V Predictions Mean           1569.9763
V Predictions Std            269.60043
V Predictions Max            1828.2335
V Predictions Min            7.6817408
Log Pis Mean                 -0.07532441
Log Pis Std                  1.8860067
Log Pis Max                  6.1612363
Log Pis Min                  -5.1162853
Policy mu Mean               -0.11031029
Policy mu Std                0.8900743
Policy mu Max                1.979943
Policy mu Min                -2.8989737
Policy log std Mean          -0.49652115
Policy log std Std           0.19293949
Policy log std Max           0.1677779
Policy log std Min           -1.2459872
Z mean eval                  0.025215019
Z variance eval              0.0033456285
total_rewards                [1388.89606414 1447.96918857 1142.5041935  1951.54507321 3034.88780041
 1888.79263852 1968.74100637  938.40303589 2390.35195623 2962.58495513]
total_rewards_mean           1911.4675911967624
total_rewards_std            680.2736671623019
total_rewards_max            3034.8878004101775
total_rewards_min            938.4030358894887
Number of train steps total  1700000
Number of env steps total    2194982
Number of rollouts total     0
Train Time (s)               145.4401674028486
(Previous) Eval Time (s)     18.90423267893493
Sample Time (s)              9.970887454226613
Epoch Time (s)               174.31528753601015
Total Train Time (s)         71489.33229095535
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:21:59.804749 UTC | [2020_01_11_02_30_29] Iteration #424 | Epoch Duration: 174.40274739265442
2020-01-11 22:21:59.804994 UTC | [2020_01_11_02_30_29] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02520923
Z variance train             0.0033466313
KL Divergence                11.932185
KL Loss                      1.1932186
QF Loss                      33.948456
VF Loss                      12.4343605
Policy Loss                  -1594.1068
Q Predictions Mean           1593.5979
Q Predictions Std            211.49686
Q Predictions Max            1816.9358
Q Predictions Min            332.0019
V Predictions Mean           1594.0203
V Predictions Std            208.70811
V Predictions Max            1817.1095
V Predictions Min            362.93814
Log Pis Mean                 -0.5486826
Log Pis Std                  1.7989798
Log Pis Max                  4.812812
Log Pis Min                  -5.6549616
Policy mu Mean               -0.07689033
Policy mu Std                0.77958757
Policy mu Max                1.7700515
Policy mu Min                -2.410671
Policy log std Mean          -0.46202564
Policy log std Std           0.19861752
Policy log std Max           0.15101254
Policy log std Min           -1.2465599
Z mean eval                  0.045352362
Z variance eval              0.0040888023
total_rewards                [2669.91280838 3396.40116295 1429.05096583 1765.22674362 2197.00186333
 1943.4532492  1668.59890619 3392.81445278 1147.33030703  907.14206385]
total_rewards_mean           2051.693252316761
total_rewards_std            822.5721162826026
total_rewards_max            3396.4011629531133
total_rewards_min            907.1420638526971
Number of train steps total  1704000
Number of env steps total    2204910
Number of rollouts total     0
Train Time (s)               145.44688328681514
(Previous) Eval Time (s)     19.62478107213974
Sample Time (s)              10.552828499581665
Epoch Time (s)               175.62449285853654
Total Train Time (s)         71665.03061949695
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:24:55.505176 UTC | [2020_01_11_02_30_29] Iteration #425 | Epoch Duration: 175.7000436782837
2020-01-11 22:24:55.505312 UTC | [2020_01_11_02_30_29] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04539051
Z variance train             0.004088506
KL Divergence                11.571171
KL Loss                      1.1571171
QF Loss                      23620.3
VF Loss                      56.95862
Policy Loss                  -1607.5492
Q Predictions Mean           1611.8798
Q Predictions Std            237.93925
Q Predictions Max            1824.3739
Q Predictions Min            322.96182
V Predictions Mean           1613.2201
V Predictions Std            234.00398
V Predictions Max            1823.3639
V Predictions Min            386.82114
Log Pis Mean                 -0.23442572
Log Pis Std                  1.8465998
Log Pis Max                  5.5545883
Log Pis Min                  -4.0531497
Policy mu Mean               -0.14641863
Policy mu Std                0.81900126
Policy mu Max                1.7546334
Policy mu Min                -2.402538
Policy log std Mean          -0.47579232
Policy log std Std           0.18645559
Policy log std Max           0.20001817
Policy log std Min           -1.387439
Z mean eval                  0.04718264
Z variance eval              0.0037476
total_rewards                [ 870.07792282 1187.09433978 1000.61217872 2482.31471035 1761.37026841
 1279.94062006 1276.6588881  1182.91911557  976.65634289 1520.84156193]
total_rewards_mean           1353.848594863779
total_rewards_std            451.3230407457719
total_rewards_max            2482.3147103520487
total_rewards_min            870.0779228203365
Number of train steps total  1708000
Number of env steps total    2212939
Number of rollouts total     0
Train Time (s)               146.84977554902434
(Previous) Eval Time (s)     12.473271209280938
Sample Time (s)              8.707916392944753
Epoch Time (s)               168.03096315125003
Total Train Time (s)         71833.14717492927
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:27:43.626710 UTC | [2020_01_11_02_30_29] Iteration #426 | Epoch Duration: 168.12128567695618
2020-01-11 22:27:43.626907 UTC | [2020_01_11_02_30_29] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04816691
Z variance train             0.0037530295
KL Divergence                11.576835
KL Loss                      1.1576835
QF Loss                      179.7492
VF Loss                      41.47176
Policy Loss                  -1595.0986
Q Predictions Mean           1592.9318
Q Predictions Std            260.70114
Q Predictions Max            1835.477
Q Predictions Min            144.73271
V Predictions Mean           1598.8307
V Predictions Std            250.8141
V Predictions Max            1828.7949
V Predictions Min            222.40442
Log Pis Mean                 -0.23577645
Log Pis Std                  1.9594247
Log Pis Max                  8.102582
Log Pis Min                  -9.067857
Policy mu Mean               -0.10515652
Policy mu Std                0.8560051
Policy mu Max                2.4917104
Policy mu Min                -2.5701108
Policy log std Mean          -0.46583924
Policy log std Std           0.19329265
Policy log std Max           0.092336535
Policy log std Min           -1.2055416
Z mean eval                  0.03802774
Z variance eval              0.00444619
total_rewards                [1776.60959958 2305.1423966  1465.06071413 1168.40836878  913.86992005
 3517.17193774 1205.20917501  973.61132598 1227.78557423 1409.24924407]
total_rewards_mean           1596.2118256154486
total_rewards_std            748.4803214546527
total_rewards_max            3517.1719377394147
total_rewards_min            913.8699200463121
Number of train steps total  1712000
Number of env steps total    2222400
Number of rollouts total     0
Train Time (s)               145.49385322676972
(Previous) Eval Time (s)     15.405880356673151
Sample Time (s)              8.770311157684773
Epoch Time (s)               169.67004474112764
Total Train Time (s)         72002.90157149173
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:30:33.391480 UTC | [2020_01_11_02_30_29] Iteration #427 | Epoch Duration: 169.76441526412964
2020-01-11 22:30:33.391794 UTC | [2020_01_11_02_30_29] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0378728
Z variance train             0.0044469363
KL Divergence                11.229172
KL Loss                      1.1229172
QF Loss                      52.049145
VF Loss                      25.883686
Policy Loss                  -1624.1228
Q Predictions Mean           1626.0073
Q Predictions Std            196.50403
Q Predictions Max            1823.2952
Q Predictions Min            229.67604
V Predictions Mean           1625.4891
V Predictions Std            194.43562
V Predictions Max            1824.0084
V Predictions Min            251.11781
Log Pis Mean                 -0.57003653
Log Pis Std                  1.7575288
Log Pis Max                  6.3445773
Log Pis Min                  -6.6527386
Policy mu Mean               -0.02089714
Policy mu Std                0.7739678
Policy mu Max                2.3816447
Policy mu Min                -2.7171144
Policy log std Mean          -0.4743271
Policy log std Std           0.19142525
Policy log std Max           0.051382214
Policy log std Min           -1.0234754
Z mean eval                  0.021834556
Z variance eval              0.0056913393
total_rewards                [ 955.76884641 2112.50162551 1894.05626607 1210.34112908  976.54258625
 1182.45353578  978.8364888   918.38660661 2203.68125395 1695.5000522 ]
total_rewards_mean           1412.8068390661142
total_rewards_std            485.03798431483096
total_rewards_max            2203.681253947055
total_rewards_min            918.3866066094347
Number of train steps total  1716000
Number of env steps total    2230977
Number of rollouts total     0
Train Time (s)               146.44559308886528
(Previous) Eval Time (s)     13.240221541840583
Sample Time (s)              9.307875096797943
Epoch Time (s)               168.9936897275038
Total Train Time (s)         72172.30274914159
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:33:22.792218 UTC | [2020_01_11_02_30_29] Iteration #428 | Epoch Duration: 169.40013456344604
2020-01-11 22:33:22.792460 UTC | [2020_01_11_02_30_29] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02177791
Z variance train             0.0056926725
KL Divergence                10.7301235
KL Loss                      1.0730124
QF Loss                      54.934875
VF Loss                      24.561092
Policy Loss                  -1601.002
Q Predictions Mean           1599.9613
Q Predictions Std            242.69125
Q Predictions Max            1811.6757
Q Predictions Min            111.65636
V Predictions Mean           1603.8828
V Predictions Std            237.60034
V Predictions Max            1817.5027
V Predictions Min            192.52847
Log Pis Mean                 -0.27673876
Log Pis Std                  1.7400501
Log Pis Max                  7.607849
Log Pis Min                  -3.6704578
Policy mu Mean               -0.13435982
Policy mu Std                0.81277466
Policy mu Max                1.7648326
Policy mu Min                -2.526511
Policy log std Mean          -0.51041484
Policy log std Std           0.18805437
Policy log std Max           0.13813111
Policy log std Min           -1.0008247
Z mean eval                  0.021230323
Z variance eval              0.0049243704
total_rewards                [ 649.05318949 1495.72327671 1430.44391356  905.46591122 1148.84023296
 1017.50494144 1478.09616625  936.87922276 1471.16438527 1691.73486072]
total_rewards_mean           1222.4906100369146
total_rewards_std            319.9400228328154
total_rewards_max            1691.7348607178085
total_rewards_min            649.0531894861157
Number of train steps total  1720000
Number of env steps total    2240430
Number of rollouts total     0
Train Time (s)               143.72105422988534
(Previous) Eval Time (s)     11.2177523849532
Sample Time (s)              9.015826407354325
Epoch Time (s)               163.95463302219287
Total Train Time (s)         72336.33814810496
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:36:06.831961 UTC | [2020_01_11_02_30_29] Iteration #429 | Epoch Duration: 164.0393238067627
2020-01-11 22:36:06.832143 UTC | [2020_01_11_02_30_29] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021088315
Z variance train             0.0049240016
KL Divergence                10.902807
KL Loss                      1.0902808
QF Loss                      137.03789
VF Loss                      103.38634
Policy Loss                  -1584.6245
Q Predictions Mean           1583.5322
Q Predictions Std            267.14502
Q Predictions Max            1830.1975
Q Predictions Min            55.532578
V Predictions Mean           1592.8901
V Predictions Std            259.43463
V Predictions Max            1832.6459
V Predictions Min            200.68185
Log Pis Mean                 -0.5224613
Log Pis Std                  1.6985766
Log Pis Max                  6.0612345
Log Pis Min                  -5.1116886
Policy mu Mean               -0.16279685
Policy mu Std                0.8126079
Policy mu Max                1.5241555
Policy mu Min                -2.6335166
Policy log std Mean          -0.46872452
Policy log std Std           0.19754802
Policy log std Max           0.097480625
Policy log std Min           -1.0061576
Z mean eval                  0.015031954
Z variance eval              0.006070446
total_rewards                [1428.49092999  653.34924896 1530.333389   2715.78287663 2208.76067526
  904.73898167 1536.54251058 1380.25800432  966.6544651  1174.59056219]
total_rewards_mean           1449.9501643709496
total_rewards_std            586.3982380272315
total_rewards_max            2715.7828766332914
total_rewards_min            653.3492489637612
Number of train steps total  1724000
Number of env steps total    2248736
Number of rollouts total     0
Train Time (s)               144.6579408980906
(Previous) Eval Time (s)     13.909200113266706
Sample Time (s)              9.182155702263117
Epoch Time (s)               167.74929671362042
Total Train Time (s)         72504.2121994379
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:38:54.711284 UTC | [2020_01_11_02_30_29] Iteration #430 | Epoch Duration: 167.87897872924805
2020-01-11 22:38:54.711525 UTC | [2020_01_11_02_30_29] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0151182655
Z variance train             0.006071698
KL Divergence                10.4202385
KL Loss                      1.0420239
QF Loss                      57.4493
VF Loss                      13.000289
Policy Loss                  -1618.3997
Q Predictions Mean           1619.4557
Q Predictions Std            235.7056
Q Predictions Max            1825.3738
Q Predictions Min            127.888016
V Predictions Mean           1618.3713
V Predictions Std            230.88121
V Predictions Max            1828.3969
V Predictions Min            161.02559
Log Pis Mean                 -0.36942846
Log Pis Std                  1.8748852
Log Pis Max                  10.508462
Log Pis Min                  -5.8203406
Policy mu Mean               -0.13119254
Policy mu Std                0.8268228
Policy mu Max                2.7446198
Policy mu Min                -2.790617
Policy log std Mean          -0.4828539
Policy log std Std           0.19726177
Policy log std Max           0.12707493
Policy log std Min           -1.4906931
Z mean eval                  0.03184069
Z variance eval              0.0054964246
total_rewards                [ 899.14229151 1656.51486476 1151.42607465 2513.52336637  926.01977316
  651.58320431 1506.27546231  896.0853924  1100.19831418 1172.59768596]
total_rewards_mean           1247.3366429611665
total_rewards_std            507.63400421909853
total_rewards_max            2513.5233663738404
total_rewards_min            651.5832043117484
Number of train steps total  1728000
Number of env steps total    2258646
Number of rollouts total     0
Train Time (s)               145.7332012518309
(Previous) Eval Time (s)     11.827073562890291
Sample Time (s)              10.061026539187878
Epoch Time (s)               167.62130135390908
Total Train Time (s)         72671.92387052067
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:41:42.427053 UTC | [2020_01_11_02_30_29] Iteration #431 | Epoch Duration: 167.71533966064453
2020-01-11 22:41:42.427283 UTC | [2020_01_11_02_30_29] Iteration #431 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031343482
Z variance train             0.0055012996
KL Divergence                10.645517
KL Loss                      1.0645517
QF Loss                      177.26257
VF Loss                      95.80316
Policy Loss                  -1590.4753
Q Predictions Mean           1584.4539
Q Predictions Std            235.96973
Q Predictions Max            1832.5162
Q Predictions Min            338.22028
V Predictions Mean           1582.9714
V Predictions Std            232.99254
V Predictions Max            1830.6833
V Predictions Min            362.1799
Log Pis Mean                 -0.31073982
Log Pis Std                  2.0334158
Log Pis Max                  10.261633
Log Pis Min                  -6.1595016
Policy mu Mean               -0.049606174
Policy mu Std                0.83954096
Policy mu Max                3.2153075
Policy mu Min                -2.5450869
Policy log std Mean          -0.49737248
Policy log std Std           0.18576656
Policy log std Max           0.09317893
Policy log std Min           -1.1505617
Z mean eval                  0.034688912
Z variance eval              0.005613624
total_rewards                [ 650.30454191 1378.76753822 1362.15354328 1752.75921545  931.9268534
 1480.00450548  912.24165501  651.19128248 1187.14040021  908.0045415 ]
total_rewards_mean           1121.449407693137
total_rewards_std            349.84937063824873
total_rewards_max            1752.7592154514573
total_rewards_min            650.3045419093734
Number of train steps total  1732000
Number of env steps total    2268449
Number of rollouts total     0
Train Time (s)               145.13393668364733
(Previous) Eval Time (s)     10.326788616832346
Sample Time (s)              9.834632130805403
Epoch Time (s)               165.29535743128508
Total Train Time (s)         72837.3075756398
Epoch                        432
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:44:27.815391 UTC | [2020_01_11_02_30_29] Iteration #432 | Epoch Duration: 165.38795804977417
2020-01-11 22:44:27.815582 UTC | [2020_01_11_02_30_29] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034547605
Z variance train             0.0056151147
KL Divergence                10.5209255
KL Loss                      1.0520926
QF Loss                      171.09128
VF Loss                      153.74086
Policy Loss                  -1607.6962
Q Predictions Mean           1605.8966
Q Predictions Std            263.8867
Q Predictions Max            1823.2938
Q Predictions Min            -8.991357
V Predictions Mean           1606.6713
V Predictions Std            252.78609
V Predictions Max            1831.2211
V Predictions Min            23.712492
Log Pis Mean                 -0.34187856
Log Pis Std                  1.8231919
Log Pis Max                  5.370123
Log Pis Min                  -4.683716
Policy mu Mean               -0.12743051
Policy mu Std                0.81670475
Policy mu Max                2.2214136
Policy mu Min                -2.8452444
Policy log std Mean          -0.5065057
Policy log std Std           0.19907574
Policy log std Max           0.06866437
Policy log std Min           -1.3298278
Z mean eval                  0.032032155
Z variance eval              0.004566988
total_rewards                [1803.43104786 1599.03192644 1062.03958463 1233.19000966 1261.5128695
 1195.14014491 1005.52974513 1752.38566977 1209.61241331 1487.07891615]
total_rewards_mean           1360.8952327356649
total_rewards_std            267.18535957573096
total_rewards_max            1803.4310478617722
total_rewards_min            1005.5297451272542
Number of train steps total  1736000
Number of env steps total    2277546
Number of rollouts total     0
Train Time (s)               145.32625381136313
(Previous) Eval Time (s)     11.481821694876999
Sample Time (s)              10.483312228694558
Epoch Time (s)               167.2913877349347
Total Train Time (s)         73004.68087990256
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:47:15.193088 UTC | [2020_01_11_02_30_29] Iteration #433 | Epoch Duration: 167.3773696422577
2020-01-11 22:47:15.193264 UTC | [2020_01_11_02_30_29] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032107502
Z variance train             0.0045661787
KL Divergence                11.109901
KL Loss                      1.1109902
QF Loss                      69.45619
VF Loss                      36.2464
Policy Loss                  -1622.8223
Q Predictions Mean           1619.9583
Q Predictions Std            212.85071
Q Predictions Max            1829.808
Q Predictions Min            72.66273
V Predictions Mean           1618.7969
V Predictions Std            206.69832
V Predictions Max            1830.4104
V Predictions Min            186.15694
Log Pis Mean                 -0.28597027
Log Pis Std                  1.644782
Log Pis Max                  5.4048667
Log Pis Min                  -5.2488723
Policy mu Mean               -0.1206707
Policy mu Std                0.82354814
Policy mu Max                1.6179827
Policy mu Min                -2.5926774
Policy log std Mean          -0.4910636
Policy log std Std           0.19230585
Policy log std Max           0.020619273
Policy log std Min           -1.3068413
Z mean eval                  0.03767377
Z variance eval              0.0048455996
total_rewards                [1002.19464557 1389.26424269  675.0618294  1078.61631467 1057.18790266
 1255.75623309 1711.38231014 3096.39011188  670.39588772 3028.3207661 ]
total_rewards_mean           1496.4570243928786
total_rewards_std            836.1173982431287
total_rewards_max            3096.390111884799
total_rewards_min            670.3958877159017
Number of train steps total  1740000
Number of env steps total    2286150
Number of rollouts total     0
Train Time (s)               146.02790120476857
(Previous) Eval Time (s)     14.625922562088817
Sample Time (s)              10.238807881250978
Epoch Time (s)               170.89263164810836
Total Train Time (s)         73175.6573116756
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:50:06.174301 UTC | [2020_01_11_02_30_29] Iteration #434 | Epoch Duration: 170.98089361190796
2020-01-11 22:50:06.174510 UTC | [2020_01_11_02_30_29] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03770376
Z variance train             0.004845704
KL Divergence                10.919172
KL Loss                      1.0919173
QF Loss                      58.832176
VF Loss                      25.801907
Policy Loss                  -1638.9916
Q Predictions Mean           1636.2925
Q Predictions Std            197.04701
Q Predictions Max            1836.8833
Q Predictions Min            452.6108
V Predictions Mean           1636.343
V Predictions Std            191.06505
V Predictions Max            1846.5674
V Predictions Min            542.91254
Log Pis Mean                 -0.3849573
Log Pis Std                  1.9080988
Log Pis Max                  7.131674
Log Pis Min                  -6.7810035
Policy mu Mean               -0.061634194
Policy mu Std                0.8204845
Policy mu Max                2.174514
Policy mu Min                -2.799547
Policy log std Mean          -0.49302268
Policy log std Std           0.1969636
Policy log std Max           0.16029456
Policy log std Min           -1.4761912
Z mean eval                  0.013819225
Z variance eval              0.0053898664
total_rewards                [1523.50941207 2019.37154432 1203.63155328 1247.13861371 1825.63169368
 1127.42402633 2242.56660881 3438.59815196  993.59103569 1591.0022509 ]
total_rewards_mean           1721.2464890743759
total_rewards_std            689.3272669277857
total_rewards_max            3438.598151957598
total_rewards_min            993.5910356898529
Number of train steps total  1744000
Number of env steps total    2293720
Number of rollouts total     0
Train Time (s)               145.48485757410526
(Previous) Eval Time (s)     15.627306761685759
Sample Time (s)              9.257447575218976
Epoch Time (s)               170.36961191101
Total Train Time (s)         73346.39788569557
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:52:56.919451 UTC | [2020_01_11_02_30_29] Iteration #435 | Epoch Duration: 170.74478721618652
2020-01-11 22:52:56.919658 UTC | [2020_01_11_02_30_29] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013345179
Z variance train             0.0053806654
KL Divergence                10.701175
KL Loss                      1.0701175
QF Loss                      95.81107
VF Loss                      97.50232
Policy Loss                  -1646.3848
Q Predictions Mean           1642.3346
Q Predictions Std            159.74088
Q Predictions Max            1837.9519
Q Predictions Min            915.96594
V Predictions Mean           1638.4132
V Predictions Std            158.43228
V Predictions Max            1836.3481
V Predictions Min            934.7813
Log Pis Mean                 -0.5774151
Log Pis Std                  1.811359
Log Pis Max                  5.3165073
Log Pis Min                  -4.640628
Policy mu Mean               -0.19437027
Policy mu Std                0.7821233
Policy mu Max                2.098184
Policy mu Min                -2.707932
Policy log std Mean          -0.4967545
Policy log std Std           0.19295225
Policy log std Max           0.26104927
Policy log std Min           -1.1717207
Z mean eval                  0.026247736
Z variance eval              0.0050649205
total_rewards                [1205.40261812 1190.48120627  947.76394522 1051.70211827 1144.64598226
 2275.30284137  937.9883904  1105.81114233 1349.56996823 1723.25022155]
total_rewards_mean           1293.191843403928
total_rewards_std            391.396442264087
total_rewards_max            2275.3028413718907
total_rewards_min            937.9883903990178
Number of train steps total  1748000
Number of env steps total    2302653
Number of rollouts total     0
Train Time (s)               145.11328213196248
(Previous) Eval Time (s)     12.386786974966526
Sample Time (s)              8.652335771359503
Epoch Time (s)               166.1524048782885
Total Train Time (s)         73512.6328755673
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:55:43.158950 UTC | [2020_01_11_02_30_29] Iteration #436 | Epoch Duration: 166.23913478851318
2020-01-11 22:55:43.159153 UTC | [2020_01_11_02_30_29] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026288267
Z variance train             0.005065225
KL Divergence                11.055647
KL Loss                      1.1055647
QF Loss                      68.81064
VF Loss                      61.51286
Policy Loss                  -1658.0914
Q Predictions Mean           1656.4125
Q Predictions Std            148.44997
Q Predictions Max            1842.736
Q Predictions Min            952.2247
V Predictions Mean           1652.5343
V Predictions Std            145.99431
V Predictions Max            1842.6293
V Predictions Min            966.48926
Log Pis Mean                 -0.45940265
Log Pis Std                  1.5849427
Log Pis Max                  7.2698135
Log Pis Min                  -4.285037
Policy mu Mean               -0.1094599
Policy mu Std                0.79859585
Policy mu Max                2.4512415
Policy mu Min                -2.2971592
Policy log std Mean          -0.49383846
Policy log std Std           0.17870389
Policy log std Max           0.0833419
Policy log std Min           -1.1553364
Z mean eval                  0.024013871
Z variance eval              0.0058910884
total_rewards                [1229.93147564 1675.23054407 1500.53391798 1227.99929445  678.1238849
 1139.88211512 1017.06929752 1727.76490932 1685.73559233 1163.97343954]
total_rewards_mean           1304.6244470863571
total_rewards_std            321.4944898497035
total_rewards_max            1727.764909318006
total_rewards_min            678.1238849012054
Number of train steps total  1752000
Number of env steps total    2311866
Number of rollouts total     0
Train Time (s)               153.32338736392558
(Previous) Eval Time (s)     12.489797020331025
Sample Time (s)              10.510496693197638
Epoch Time (s)               176.32368107745424
Total Train Time (s)         73689.12550177891
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:58:39.656349 UTC | [2020_01_11_02_30_29] Iteration #437 | Epoch Duration: 176.4967782497406
2020-01-11 22:58:39.656566 UTC | [2020_01_11_02_30_29] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023593258
Z variance train             0.0058910428
KL Divergence                10.651629
KL Loss                      1.065163
QF Loss                      149.43404
VF Loss                      90.944244
Policy Loss                  -1631.726
Q Predictions Mean           1630.024
Q Predictions Std            194.53844
Q Predictions Max            1816.5723
Q Predictions Min            448.85324
V Predictions Mean           1636.4902
V Predictions Std            193.93805
V Predictions Max            1825.4508
V Predictions Min            487.8303
Log Pis Mean                 -0.5350245
Log Pis Std                  1.7545505
Log Pis Max                  8.344082
Log Pis Min                  -5.2167454
Policy mu Mean               0.07830775
Policy mu Std                0.76738375
Policy mu Max                2.4204168
Policy mu Min                -2.2394888
Policy log std Mean          -0.46734843
Policy log std Std           0.19278154
Policy log std Max           0.112531364
Policy log std Min           -1.404331
Z mean eval                  0.031009797
Z variance eval              0.006440535
total_rewards                [ 996.08915401  910.05886099 1209.22928458 1218.07567543  973.58900161
 1001.52294019 1465.64321882 1234.66643978 1113.13718571 1696.73609488]
total_rewards_mean           1181.874785600364
total_rewards_std            232.26864503276624
total_rewards_max            1696.7360948836201
total_rewards_min            910.058860989933
Number of train steps total  1756000
Number of env steps total    2321143
Number of rollouts total     0
Train Time (s)               155.01468884013593
(Previous) Eval Time (s)     11.400189041160047
Sample Time (s)              10.797418186906725
Epoch Time (s)               177.2122960682027
Total Train Time (s)         73866.4205868463
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:01:36.959978 UTC | [2020_01_11_02_30_29] Iteration #438 | Epoch Duration: 177.30326771736145
2020-01-11 23:01:36.960119 UTC | [2020_01_11_02_30_29] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030866772
Z variance train             0.006446121
KL Divergence                10.382054
KL Loss                      1.0382055
QF Loss                      40.32469
VF Loss                      13.473814
Policy Loss                  -1650.156
Q Predictions Mean           1645.9458
Q Predictions Std            236.94983
Q Predictions Max            1839.9342
Q Predictions Min            78.04969
V Predictions Mean           1648.415
V Predictions Std            230.61217
V Predictions Max            1845.4015
V Predictions Min            121.387085
Log Pis Mean                 -0.57518077
Log Pis Std                  1.6798201
Log Pis Max                  4.942343
Log Pis Min                  -5.256032
Policy mu Mean               0.05610004
Policy mu Std                0.8003762
Policy mu Max                2.0347137
Policy mu Min                -2.5076573
Policy log std Mean          -0.4884851
Policy log std Std           0.19554788
Policy log std Max           0.27819696
Policy log std Min           -1.4617252
Z mean eval                  0.052357875
Z variance eval              0.0066925883
total_rewards                [ 954.65507087  984.10207393 1048.82125506 1012.0173419  1549.81245817
 1516.50119118  960.18952621 1269.526092    941.98428447 1005.74309494]
total_rewards_mean           1124.3352388710125
total_rewards_std            222.9214067728139
total_rewards_max            1549.8124581665131
total_rewards_min            941.9842844661442
Number of train steps total  1760000
Number of env steps total    2330954
Number of rollouts total     0
Train Time (s)               156.43929859204218
(Previous) Eval Time (s)     10.591390925925225
Sample Time (s)              9.426403327379376
Epoch Time (s)               176.45709284534678
Total Train Time (s)         74042.95775438193
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:04:33.502001 UTC | [2020_01_11_02_30_29] Iteration #439 | Epoch Duration: 176.54175734519958
2020-01-11 23:04:33.502231 UTC | [2020_01_11_02_30_29] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05236743
Z variance train             0.0066953884
KL Divergence                10.412422
KL Loss                      1.0412422
QF Loss                      38.473465
VF Loss                      32.341385
Policy Loss                  -1680.0964
Q Predictions Mean           1680.0089
Q Predictions Std            173.40903
Q Predictions Max            1855.8068
Q Predictions Min            602.05334
V Predictions Mean           1678.8275
V Predictions Std            167.75284
V Predictions Max            1850.4589
V Predictions Min            615.2545
Log Pis Mean                 -0.44925568
Log Pis Std                  1.8812405
Log Pis Max                  7.193244
Log Pis Min                  -4.311493
Policy mu Mean               0.0025507982
Policy mu Std                0.81340957
Policy mu Max                2.862893
Policy mu Min                -2.5867443
Policy log std Mean          -0.4451903
Policy log std Std           0.20743345
Policy log std Max           0.08101982
Policy log std Min           -1.2994808
Z mean eval                  0.03173584
Z variance eval              0.0075728036
total_rewards                [1239.02264353 1344.79044846 1376.14936368 1172.52366364 1062.60184325
 1490.87633686  955.53947016 1623.19895433 1689.78855538  914.82598686]
total_rewards_mean           1286.9317266156045
total_rewards_std            253.42888278761967
total_rewards_max            1689.7885553847743
total_rewards_min            914.8259868608666
Number of train steps total  1764000
Number of env steps total    2338591
Number of rollouts total     0
Train Time (s)               157.6287330170162
(Previous) Eval Time (s)     12.31460442300886
Sample Time (s)              10.466164703015238
Epoch Time (s)               180.4095021430403
Total Train Time (s)         74223.46012556553
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:07:34.009417 UTC | [2020_01_11_02_30_29] Iteration #440 | Epoch Duration: 180.5070095062256
2020-01-11 23:07:34.009644 UTC | [2020_01_11_02_30_29] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03252242
Z variance train             0.0075680157
KL Divergence                10.03647
KL Loss                      1.0036471
QF Loss                      91.01268
VF Loss                      167.25333
Policy Loss                  -1663.8134
Q Predictions Mean           1662.7778
Q Predictions Std            203.81015
Q Predictions Max            1842.3088
Q Predictions Min            57.802525
V Predictions Mean           1655.6855
V Predictions Std            199.14821
V Predictions Max            1831.3872
V Predictions Min            78.35711
Log Pis Mean                 -0.60625684
Log Pis Std                  1.7107966
Log Pis Max                  7.899639
Log Pis Min                  -5.2362156
Policy mu Mean               -0.055423666
Policy mu Std                0.80350995
Policy mu Max                2.6062346
Policy mu Min                -2.6286442
Policy log std Mean          -0.4480697
Policy log std Std           0.18929681
Policy log std Max           0.047617733
Policy log std Min           -1.4500808
Z mean eval                  0.03196473
Z variance eval              0.006600027
total_rewards                [1068.42198794 1649.14995996 1315.7703927  2100.46984862  826.60964204
  952.51990449 1175.04681114  899.01601959 1112.50242897 1244.42141281]
total_rewards_mean           1234.3928408255863
total_rewards_std            365.09976430024005
total_rewards_max            2100.469848616835
total_rewards_min            826.6096420411395
Number of train steps total  1768000
Number of env steps total    2347485
Number of rollouts total     0
Train Time (s)               154.31000988790765
(Previous) Eval Time (s)     10.859608069062233
Sample Time (s)              10.288854393176734
Epoch Time (s)               175.45847235014662
Total Train Time (s)         74398.99979066942
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:10:29.553803 UTC | [2020_01_11_02_30_29] Iteration #441 | Epoch Duration: 175.5439977645874
2020-01-11 23:10:29.554013 UTC | [2020_01_11_02_30_29] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03190837
Z variance train             0.0065996125
KL Divergence                10.365902
KL Loss                      1.0365902
QF Loss                      51.25471
VF Loss                      45.13452
Policy Loss                  -1652.7411
Q Predictions Mean           1652.4796
Q Predictions Std            254.09846
Q Predictions Max            1855.2388
Q Predictions Min            78.33149
V Predictions Mean           1656.1956
V Predictions Std            247.70483
V Predictions Max            1859.6047
V Predictions Min            79.624886
Log Pis Mean                 -0.500947
Log Pis Std                  1.7341515
Log Pis Max                  7.534747
Log Pis Min                  -4.578021
Policy mu Mean               -0.019063434
Policy mu Std                0.8011401
Policy mu Max                3.1342425
Policy mu Min                -3.1796439
Policy log std Mean          -0.50716907
Policy log std Std           0.20452431
Policy log std Max           0.025315404
Policy log std Min           -1.2962945
Z mean eval                  0.030541757
Z variance eval              0.0068552434
total_rewards                [ 956.20174297  830.27662927  869.23891399 1801.26784612  750.11387246
 1699.54316046  849.92351131  949.58174994  765.04195238  869.91658727]
total_rewards_mean           1034.1105966162518
total_rewards_std            364.3093802807558
total_rewards_max            1801.2678461229364
total_rewards_min            750.1138724557644
Number of train steps total  1772000
Number of env steps total    2356071
Number of rollouts total     0
Train Time (s)               144.51456544920802
(Previous) Eval Time (s)     9.321714061778039
Sample Time (s)              9.973511497024447
Epoch Time (s)               163.8097910080105
Total Train Time (s)         74562.89173767762
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:13:13.450198 UTC | [2020_01_11_02_30_29] Iteration #442 | Epoch Duration: 163.89603567123413
2020-01-11 23:13:13.450389 UTC | [2020_01_11_02_30_29] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03019695
Z variance train             0.0068599596
KL Divergence                10.156874
KL Loss                      1.0156873
QF Loss                      57.91278
VF Loss                      94.20319
Policy Loss                  -1678.6971
Q Predictions Mean           1678.8203
Q Predictions Std            160.7252
Q Predictions Max            1845.6357
Q Predictions Min            552.52673
V Predictions Mean           1670.0503
V Predictions Std            156.99477
V Predictions Max            1836.476
V Predictions Min            609.83276
Log Pis Mean                 -0.6385534
Log Pis Std                  1.706096
Log Pis Max                  5.98547
Log Pis Min                  -5.082594
Policy mu Mean               -0.0916073
Policy mu Std                0.798208
Policy mu Max                2.611955
Policy mu Min                -2.485142
Policy log std Mean          -0.46445027
Policy log std Std           0.18550925
Policy log std Max           0.15548015
Policy log std Min           -1.4579982
Z mean eval                  0.029377233
Z variance eval              0.0072568655
total_rewards                [ 947.84163811 1547.7842487  1252.94855517 1486.08584993  957.47774421
  916.60261178  951.67959093  924.97042248 1887.67054935  986.34187274]
total_rewards_mean           1185.9403083398952
total_rewards_std            325.91189528832194
total_rewards_max            1887.6705493468335
total_rewards_min            916.6026117845173
Number of train steps total  1776000
Number of env steps total    2365431
Number of rollouts total     0
Train Time (s)               144.47868760023266
(Previous) Eval Time (s)     10.696115238126367
Sample Time (s)              10.272634264081717
Epoch Time (s)               165.44743710244074
Total Train Time (s)         74728.42163804127
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:15:58.985603 UTC | [2020_01_11_02_30_29] Iteration #443 | Epoch Duration: 165.53506112098694
2020-01-11 23:15:58.985834 UTC | [2020_01_11_02_30_29] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029368227
Z variance train             0.00725054
KL Divergence                9.992315
KL Loss                      0.9992315
QF Loss                      52.195114
VF Loss                      26.510445
Policy Loss                  -1643.8481
Q Predictions Mean           1642.5133
Q Predictions Std            244.2144
Q Predictions Max            1832.1453
Q Predictions Min            11.385406
V Predictions Mean           1642.4918
V Predictions Std            242.21481
V Predictions Max            1839.2615
V Predictions Min            -12.304272
Log Pis Mean                 -0.29999685
Log Pis Std                  1.8780233
Log Pis Max                  8.551842
Log Pis Min                  -6.0054374
Policy mu Mean               0.017058024
Policy mu Std                0.82028186
Policy mu Max                2.460079
Policy mu Min                -3.004053
Policy log std Mean          -0.47298685
Policy log std Std           0.1877533
Policy log std Max           0.29545367
Policy log std Min           -1.4362667
Z mean eval                  0.028079573
Z variance eval              0.0075167217
total_rewards                [1496.59266772  982.48364912 1752.04882437 1190.30875217 2048.3211452
  293.29143712  893.58711199 1759.17742785 2148.29712199  989.03866679]
total_rewards_mean           1355.3146804309545
total_rewards_std            555.9690145559155
total_rewards_max            2148.297121986059
total_rewards_min            293.2914371207993
Number of train steps total  1780000
Number of env steps total    2374765
Number of rollouts total     0
Train Time (s)               144.5918173370883
(Previous) Eval Time (s)     12.019304993096739
Sample Time (s)              10.323219272308052
Epoch Time (s)               166.93434160249308
Total Train Time (s)         74895.45939520234
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:18:46.027887 UTC | [2020_01_11_02_30_29] Iteration #444 | Epoch Duration: 167.0418565273285
2020-01-11 23:18:46.028131 UTC | [2020_01_11_02_30_29] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02790763
Z variance train             0.007513343
KL Divergence                9.771786
KL Loss                      0.9771786
QF Loss                      67.27047
VF Loss                      28.628506
Policy Loss                  -1665.016
Q Predictions Mean           1666.207
Q Predictions Std            180.22676
Q Predictions Max            1843.9442
Q Predictions Min            511.0289
V Predictions Mean           1665.7948
V Predictions Std            178.03165
V Predictions Max            1850.9048
V Predictions Min            518.5305
Log Pis Mean                 -0.45307028
Log Pis Std                  1.9144346
Log Pis Max                  7.0243254
Log Pis Min                  -7.23262
Policy mu Mean               0.018704029
Policy mu Std                0.78987
Policy mu Max                1.802803
Policy mu Min                -2.741536
Policy log std Mean          -0.46947932
Policy log std Std           0.18754947
Policy log std Max           0.19126165
Policy log std Min           -1.5916047
Z mean eval                  0.027488898
Z variance eval              0.007070709
total_rewards                [ 839.85206382  969.12802154 1117.80808599  840.7651133   758.89150241
  956.59941488  984.61903147  974.37539098 1161.95831989  996.73171691]
total_rewards_mean           960.0728661187019
total_rewards_std            117.06599285022914
total_rewards_max            1161.9583198877951
total_rewards_min            758.8915024072569
Number of train steps total  1784000
Number of env steps total    2382965
Number of rollouts total     0
Train Time (s)               145.25066455174237
(Previous) Eval Time (s)     9.094739341177046
Sample Time (s)              9.546167692169547
Epoch Time (s)               163.89157158508897
Total Train Time (s)         75059.43165368307
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:21:30.004963 UTC | [2020_01_11_02_30_29] Iteration #445 | Epoch Duration: 163.97664999961853
2020-01-11 23:21:30.005195 UTC | [2020_01_11_02_30_29] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027432885
Z variance train             0.0070675984
KL Divergence                9.947963
KL Loss                      0.9947963
QF Loss                      50.500534
VF Loss                      87.336784
Policy Loss                  -1653.9979
Q Predictions Mean           1651.7169
Q Predictions Std            220.62614
Q Predictions Max            1838.9469
Q Predictions Min            208.27138
V Predictions Mean           1646.6462
V Predictions Std            217.97725
V Predictions Max            1835.1774
V Predictions Min            261.99292
Log Pis Mean                 -0.3171949
Log Pis Std                  1.8946023
Log Pis Max                  13.506227
Log Pis Min                  -4.5645223
Policy mu Mean               -0.09242525
Policy mu Std                0.8278984
Policy mu Max                2.9283724
Policy mu Min                -3.0925283
Policy log std Mean          -0.47901344
Policy log std Std           0.18508202
Policy log std Max           0.1811049
Policy log std Min           -1.2230935
Z mean eval                  0.04532632
Z variance eval              0.0071943714
total_rewards                [ 975.34796181 1091.45116208  728.08451181 1207.46225148  986.63844722
  853.4096304   947.58175935 1378.66498994  985.89342952  975.24900141]
total_rewards_mean           1012.9783145019268
total_rewards_std            171.13708290126445
total_rewards_max            1378.664989942754
total_rewards_min            728.0845118080542
Number of train steps total  1788000
Number of env steps total    2393168
Number of rollouts total     0
Train Time (s)               146.2100054291077
(Previous) Eval Time (s)     10.017934703733772
Sample Time (s)              8.690366419497877
Epoch Time (s)               164.91830655233935
Total Train Time (s)         75224.42996051302
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:24:15.007298 UTC | [2020_01_11_02_30_29] Iteration #446 | Epoch Duration: 165.00194120407104
2020-01-11 23:24:15.007505 UTC | [2020_01_11_02_30_29] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0453421
Z variance train             0.0071943947
KL Divergence                9.943614
KL Loss                      0.9943614
QF Loss                      25.279457
VF Loss                      11.457214
Policy Loss                  -1668.2579
Q Predictions Mean           1667.1893
Q Predictions Std            186.76093
Q Predictions Max            1843.7278
Q Predictions Min            92.21394
V Predictions Mean           1669.0199
V Predictions Std            186.57785
V Predictions Max            1851.5494
V Predictions Min            72.361855
Log Pis Mean                 -0.47768518
Log Pis Std                  1.6951658
Log Pis Max                  8.350453
Log Pis Min                  -5.1586094
Policy mu Mean               0.021480812
Policy mu Std                0.78998303
Policy mu Max                2.3037941
Policy mu Min                -2.2831368
Policy log std Mean          -0.45688644
Policy log std Std           0.1798004
Policy log std Max           0.096459776
Policy log std Min           -1.0228906
Z mean eval                  0.023590105
Z variance eval              0.0065029524
total_rewards                [ 924.46631604  889.98863333 1092.28357313 1490.6545996   961.93463041
 1122.10282212  902.82569241 1160.79507948 1021.75213957  766.70693974]
total_rewards_mean           1033.3510425826446
total_rewards_std            190.39377471066342
total_rewards_max            1490.654599598702
total_rewards_min            766.7069397375774
Number of train steps total  1792000
Number of env steps total    2402800
Number of rollouts total     0
Train Time (s)               145.11254848586395
(Previous) Eval Time (s)     9.81335895974189
Sample Time (s)              9.825054068118334
Epoch Time (s)               164.75096151372418
Total Train Time (s)         75389.25758810481
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:26:59.837877 UTC | [2020_01_11_02_30_29] Iteration #447 | Epoch Duration: 164.83023715019226
2020-01-11 23:26:59.838015 UTC | [2020_01_11_02_30_29] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023718413
Z variance train             0.006498441
KL Divergence                10.29529
KL Loss                      1.029529
QF Loss                      58.48888
VF Loss                      43.791023
Policy Loss                  -1666.8942
Q Predictions Mean           1664.2178
Q Predictions Std            200.39284
Q Predictions Max            1843.4891
Q Predictions Min            233.0011
V Predictions Mean           1669.7949
V Predictions Std            196.18192
V Predictions Max            1852.2362
V Predictions Min            363.6525
Log Pis Mean                 -0.4743235
Log Pis Std                  1.5484593
Log Pis Max                  7.3745995
Log Pis Min                  -4.983348
Policy mu Mean               -0.103207804
Policy mu Std                0.768086
Policy mu Max                1.8685923
Policy mu Min                -2.502703
Policy log std Mean          -0.45242748
Policy log std Std           0.1801414
Policy log std Max           0.15230313
Policy log std Min           -1.301723
Z mean eval                  0.024809431
Z variance eval              0.0069270195
total_rewards                [ 912.68290344 2125.76929925  834.69053612  999.43932164 1067.24306329
  900.17218777  691.19414785  770.78714403  855.69616556  930.18395768]
total_rewards_mean           1008.7858726634395
total_rewards_std            385.9560977397404
total_rewards_max            2125.7692992493953
total_rewards_min            691.1941478527206
Number of train steps total  1796000
Number of env steps total    2411770
Number of rollouts total     0
Train Time (s)               145.25089887017384
(Previous) Eval Time (s)     8.363783897832036
Sample Time (s)              10.031905256677419
Epoch Time (s)               163.6465880246833
Total Train Time (s)         75553.00192057714
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:29:43.587025 UTC | [2020_01_11_02_30_29] Iteration #448 | Epoch Duration: 163.74888110160828
2020-01-11 23:29:43.587251 UTC | [2020_01_11_02_30_29] Iteration #448 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024660816
Z variance train             0.0069302483
KL Divergence                10.064877
KL Loss                      1.0064877
QF Loss                      16578.652
VF Loss                      49.933083
Policy Loss                  -1628.4072
Q Predictions Mean           1631.0779
Q Predictions Std            241.09578
Q Predictions Max            1859.8499
Q Predictions Min            139.04611
V Predictions Mean           1631.1423
V Predictions Std            238.39587
V Predictions Max            1852.8081
V Predictions Min            118.637115
Log Pis Mean                 -0.37693423
Log Pis Std                  1.7967876
Log Pis Max                  7.6419983
Log Pis Min                  -6.3658643
Policy mu Mean               0.013679464
Policy mu Std                0.82345456
Policy mu Max                1.9455705
Policy mu Min                -2.931855
Policy log std Mean          -0.46343353
Policy log std Std           0.17415684
Policy log std Max           0.18818295
Policy log std Min           -1.0915079
Z mean eval                  0.031587876
Z variance eval              0.0074043684
total_rewards                [ 906.81158051 1005.26263402  858.33929764  948.80247021  974.682943
 1041.49041237  965.25520929 1215.41011989  836.70182298 1005.3191005 ]
total_rewards_mean           975.8075590413767
total_rewards_std            101.10078727226193
total_rewards_max            1215.4101198862427
total_rewards_min            836.7018229762318
Number of train steps total  1800000
Number of env steps total    2420173
Number of rollouts total     0
Train Time (s)               145.73731860797852
(Previous) Eval Time (s)     9.527337872888893
Sample Time (s)              8.903939954005182
Epoch Time (s)               164.1685964348726
Total Train Time (s)         75717.24877095036
Epoch                        449
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:32:27.838418 UTC | [2020_01_11_02_30_29] Iteration #449 | Epoch Duration: 164.2510232925415
2020-01-11 23:32:27.838601 UTC | [2020_01_11_02_30_29] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031617142
Z variance train             0.0074077146
KL Divergence                9.87994
KL Loss                      0.987994
QF Loss                      52.169823
VF Loss                      23.66923
Policy Loss                  -1680.3855
Q Predictions Mean           1678.4578
Q Predictions Std            182.30792
Q Predictions Max            1847.4409
Q Predictions Min            26.923267
V Predictions Mean           1678.9263
V Predictions Std            176.48317
V Predictions Max            1844.3516
V Predictions Min            134.10846
Log Pis Mean                 -0.7174999
Log Pis Std                  1.5662144
Log Pis Max                  4.814829
Log Pis Min                  -4.181454
Policy mu Mean               -0.060836177
Policy mu Std                0.722742
Policy mu Max                2.0581858
Policy mu Min                -2.8817756
Policy log std Mean          -0.45227504
Policy log std Std           0.20752776
Policy log std Max           0.22554219
Policy log std Min           -1.4188273
Z mean eval                  0.021138346
Z variance eval              0.007893204
total_rewards                [1481.52902871 1406.3483199  1187.37666506 1200.03969037 1178.24991424
 1001.76140268 1157.44893346 1119.91718266 1054.1622341  1036.75912965]
total_rewards_mean           1182.3592500842005
total_rewards_std            146.55964895577486
total_rewards_max            1481.5290287100745
total_rewards_min            1001.7614026817379
Number of train steps total  1804000
Number of env steps total    2428279
Number of rollouts total     0
Train Time (s)               146.4300534389913
(Previous) Eval Time (s)     10.995386256836355
Sample Time (s)              9.078075476922095
Epoch Time (s)               166.50351517274976
Total Train Time (s)         75883.8286655792
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:35:14.422993 UTC | [2020_01_11_02_30_29] Iteration #450 | Epoch Duration: 166.58424305915833
2020-01-11 23:35:14.423271 UTC | [2020_01_11_02_30_29] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02072489
Z variance train             0.007896947
KL Divergence                9.865271
KL Loss                      0.9865271
QF Loss                      23918.656
VF Loss                      39.819412
Policy Loss                  -1666.5654
Q Predictions Mean           1665.6316
Q Predictions Std            182.57904
Q Predictions Max            1870.0077
Q Predictions Min            481.16708
V Predictions Mean           1668.8516
V Predictions Std            176.80293
V Predictions Max            1872.2852
V Predictions Min            569.11163
Log Pis Mean                 -0.52551025
Log Pis Std                  1.67214
Log Pis Max                  7.012718
Log Pis Min                  -4.1054173
Policy mu Mean               -0.01251521
Policy mu Std                0.77522665
Policy mu Max                1.7555724
Policy mu Min                -2.6203396
Policy log std Mean          -0.45742512
Policy log std Std           0.20263527
Policy log std Max           0.0659672
Policy log std Min           -1.1681311
Z mean eval                  0.020805959
Z variance eval              0.007034219
total_rewards                [ 979.98084535  860.94728296  798.28848299  821.10217876 1100.16018738
  980.1110773  1076.6077007   957.33696386 1009.61125411  939.58668679]
total_rewards_mean           952.373266018566
total_rewards_std            95.70997062490035
total_rewards_max            1100.1601873785849
total_rewards_min            798.2884829946644
Number of train steps total  1808000
Number of env steps total    2437055
Number of rollouts total     0
Train Time (s)               144.01954467594624
(Previous) Eval Time (s)     8.754906914196908
Sample Time (s)              10.44245409918949
Epoch Time (s)               163.21690568933263
Total Train Time (s)         76047.12776708696
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:37:57.726683 UTC | [2020_01_11_02_30_29] Iteration #451 | Epoch Duration: 163.30324697494507
2020-01-11 23:37:57.726896 UTC | [2020_01_11_02_30_29] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020786252
Z variance train             0.0070300535
KL Divergence                10.184925
KL Loss                      1.0184926
QF Loss                      57.794758
VF Loss                      37.491745
Policy Loss                  -1675.8119
Q Predictions Mean           1675.4595
Q Predictions Std            181.6985
Q Predictions Max            1863.4872
Q Predictions Min            510.84363
V Predictions Mean           1673.8826
V Predictions Std            180.33556
V Predictions Max            1865.8292
V Predictions Min            646.0372
Log Pis Mean                 -0.35699365
Log Pis Std                  1.7107706
Log Pis Max                  5.8315434
Log Pis Min                  -7.053578
Policy mu Mean               -0.090037845
Policy mu Std                0.80730903
Policy mu Max                2.3661726
Policy mu Min                -2.5787597
Policy log std Mean          -0.44533142
Policy log std Std           0.20719871
Policy log std Max           0.40770215
Policy log std Min           -1.0483904
Z mean eval                  0.039458465
Z variance eval              0.006654228
total_rewards                [ 928.6214322  1548.18521719  928.03551645  882.34836583 1894.67698405
  890.92023911  905.6026672  1005.71325631  967.67709819  975.0886139 ]
total_rewards_mean           1092.6869390433114
total_rewards_std            325.83250059030826
total_rewards_max            1894.6769840491922
total_rewards_min            882.3483658260451
Number of train steps total  1812000
Number of env steps total    2445678
Number of rollouts total     0
Train Time (s)               145.72522388026118
(Previous) Eval Time (s)     9.94231081707403
Sample Time (s)              9.086027222685516
Epoch Time (s)               164.75356192002073
Total Train Time (s)         76211.95447239699
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:40:42.555864 UTC | [2020_01_11_02_30_29] Iteration #452 | Epoch Duration: 164.82882285118103
2020-01-11 23:40:42.556006 UTC | [2020_01_11_02_30_29] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03953518
Z variance train             0.0066559375
KL Divergence                10.138354
KL Loss                      1.0138354
QF Loss                      108.33949
VF Loss                      21.09712
Policy Loss                  -1660.0131
Q Predictions Mean           1657.6306
Q Predictions Std            196.43207
Q Predictions Max            1846.3688
Q Predictions Min            15.204994
V Predictions Mean           1659.1895
V Predictions Std            197.17332
V Predictions Max            1846.6252
V Predictions Min            -2.6457386
Log Pis Mean                 -0.4946733
Log Pis Std                  1.556278
Log Pis Max                  6.4862795
Log Pis Min                  -4.7413716
Policy mu Mean               -0.1334552
Policy mu Std                0.77724296
Policy mu Max                1.5720161
Policy mu Min                -2.96889
Policy log std Mean          -0.461508
Policy log std Std           0.1871033
Policy log std Max           0.12587628
Policy log std Min           -1.06952
Z mean eval                  0.023970284
Z variance eval              0.007709055
total_rewards                [ 946.86749429  946.98878489  919.79262426 1247.88615179 1184.29828042
  920.63827189  983.16389718 1001.05982521  943.28547877 1402.60689701]
total_rewards_mean           1049.658770569534
total_rewards_std            159.596883615053
total_rewards_max            1402.606897009433
total_rewards_min            919.7926242612041
Number of train steps total  1816000
Number of env steps total    2453025
Number of rollouts total     0
Train Time (s)               145.75563332391903
(Previous) Eval Time (s)     10.243108700029552
Sample Time (s)              9.62736029876396
Epoch Time (s)               165.62610232271254
Total Train Time (s)         76377.71837198595
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:43:28.324944 UTC | [2020_01_11_02_30_29] Iteration #453 | Epoch Duration: 165.76881384849548
2020-01-11 23:43:28.325145 UTC | [2020_01_11_02_30_29] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025184745
Z variance train             0.0077056875
KL Divergence                9.818384
KL Loss                      0.9818384
QF Loss                      159.61047
VF Loss                      164.02208
Policy Loss                  -1660.456
Q Predictions Mean           1663.0974
Q Predictions Std            247.27815
Q Predictions Max            1862.6614
Q Predictions Min            62.73043
V Predictions Mean           1657.2208
V Predictions Std            244.2794
V Predictions Max            1852.3744
V Predictions Min            93.416916
Log Pis Mean                 -0.55263233
Log Pis Std                  1.6563998
Log Pis Max                  5.9338613
Log Pis Min                  -4.2557163
Policy mu Mean               -0.11805984
Policy mu Std                0.7662627
Policy mu Max                2.203459
Policy mu Min                -2.4754832
Policy log std Mean          -0.45318493
Policy log std Std           0.19750601
Policy log std Max           0.22645703
Policy log std Min           -1.155932
Z mean eval                  0.061044257
Z variance eval              0.008529684
total_rewards                [1051.8557255   986.28396728 1013.03668878 1101.56051903  941.74116207
 1039.46965638 1004.72104883  957.93012245 1424.09114494 1069.15390298]
total_rewards_mean           1058.9843938243196
total_rewards_std            130.36476645795628
total_rewards_max            1424.0911449385492
total_rewards_min            941.7411620744987
Number of train steps total  1820000
Number of env steps total    2462072
Number of rollouts total     0
Train Time (s)               145.58512231800705
(Previous) Eval Time (s)     10.311500973068178
Sample Time (s)              10.211840906180441
Epoch Time (s)               166.10846419725567
Total Train Time (s)         76543.90647826856
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:46:14.519518 UTC | [2020_01_11_02_30_29] Iteration #454 | Epoch Duration: 166.19393229484558
2020-01-11 23:46:14.519784 UTC | [2020_01_11_02_30_29] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060507607
Z variance train             0.008531174
KL Divergence                9.769383
KL Loss                      0.97693837
QF Loss                      92.17326
VF Loss                      74.3425
Policy Loss                  -1669.2213
Q Predictions Mean           1672.0803
Q Predictions Std            246.58893
Q Predictions Max            1855.523
Q Predictions Min            292.2186
V Predictions Mean           1670.9225
V Predictions Std            245.73656
V Predictions Max            1861.9336
V Predictions Min            282.62137
Log Pis Mean                 -0.6755638
Log Pis Std                  1.8492275
Log Pis Max                  6.469712
Log Pis Min                  -7.112268
Policy mu Mean               -0.09647945
Policy mu Std                0.7991591
Policy mu Max                2.089805
Policy mu Min                -2.976871
Policy log std Mean          -0.42515984
Policy log std Std           0.19724883
Policy log std Max           0.1957173
Policy log std Min           -1.1550956
Z mean eval                  0.037192978
Z variance eval              0.008503225
total_rewards                [1402.23208138  949.06088019  788.22897497 1173.917993   1000.71386306
 2714.11093896 1485.18963298 1431.29256051 1470.46757197 1385.46532803]
total_rewards_mean           1380.0679825064783
total_rewards_std            502.44258299264857
total_rewards_max            2714.1109389577905
total_rewards_min            788.2289749738233
Number of train steps total  1824000
Number of env steps total    2470558
Number of rollouts total     0
Train Time (s)               146.1805590391159
(Previous) Eval Time (s)     12.245448611676693
Sample Time (s)              8.627145166508853
Epoch Time (s)               167.05315281730145
Total Train Time (s)         76711.04599686945
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:49:01.664209 UTC | [2020_01_11_02_30_29] Iteration #455 | Epoch Duration: 167.1442642211914
2020-01-11 23:49:01.664421 UTC | [2020_01_11_02_30_29] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037222173
Z variance train             0.008507227
KL Divergence                9.597558
KL Loss                      0.95975584
QF Loss                      125.97892
VF Loss                      62.150986
Policy Loss                  -1659.1555
Q Predictions Mean           1659.1936
Q Predictions Std            284.64395
Q Predictions Max            1874.1744
Q Predictions Min            28.047998
V Predictions Mean           1655.1681
V Predictions Std            279.5345
V Predictions Max            1870.7838
V Predictions Min            16.634922
Log Pis Mean                 -0.20570454
Log Pis Std                  2.0303545
Log Pis Max                  8.024129
Log Pis Min                  -5.103383
Policy mu Mean               -0.056097597
Policy mu Std                0.8636747
Policy mu Max                2.066444
Policy mu Min                -2.7432823
Policy log std Mean          -0.46109596
Policy log std Std           0.18476906
Policy log std Max           0.13354766
Policy log std Min           -1.0328581
Z mean eval                  0.06900757
Z variance eval              0.0066372952
total_rewards                [1692.29614315 1317.74112324 1407.47062573 1171.22705384 1219.98135253
 1655.50035275  957.39591584  904.07959427  855.66454713  979.52123324]
total_rewards_mean           1216.0877941730776
total_rewards_std            286.1792237549151
total_rewards_max            1692.2961431481174
total_rewards_min            855.6645471340331
Number of train steps total  1828000
Number of env steps total    2480272
Number of rollouts total     0
Train Time (s)               148.02064009010792
(Previous) Eval Time (s)     11.700193291995674
Sample Time (s)              10.267738840542734
Epoch Time (s)               169.98857222264633
Total Train Time (s)         76881.11601912929
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:51:51.739017 UTC | [2020_01_11_02_30_29] Iteration #456 | Epoch Duration: 170.07444262504578
2020-01-11 23:51:51.739223 UTC | [2020_01_11_02_30_29] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.069157615
Z variance train             0.0066389805
KL Divergence                10.221327
KL Loss                      1.0221328
QF Loss                      27.283121
VF Loss                      14.26634
Policy Loss                  -1683.3674
Q Predictions Mean           1680.4639
Q Predictions Std            219.97871
Q Predictions Max            1868.5277
Q Predictions Min            353.50784
V Predictions Mean           1683.7534
V Predictions Std            219.45346
V Predictions Max            1872.3165
V Predictions Min            346.21024
Log Pis Mean                 -0.3991318
Log Pis Std                  1.9169612
Log Pis Max                  7.317913
Log Pis Min                  -6.6443768
Policy mu Mean               -0.129037
Policy mu Std                0.8035427
Policy mu Max                2.4252894
Policy mu Min                -2.462694
Policy log std Mean          -0.47112095
Policy log std Std           0.18960367
Policy log std Max           0.08451569
Policy log std Min           -1.5732708
Z mean eval                  0.040609766
Z variance eval              0.006872052
total_rewards                [ 976.93814874 1808.24721421  946.51079479  763.68079565  857.92144398
  941.9080691  1467.92516476  787.25690307  995.09435559 1005.68463553]
total_rewards_mean           1055.116752542447
total_rewards_std            311.44111154786003
total_rewards_max            1808.2472142066733
total_rewards_min            763.6807956473721
Number of train steps total  1832000
Number of env steps total    2489008
Number of rollouts total     0
Train Time (s)               156.41855997405946
(Previous) Eval Time (s)     9.751851951237768
Sample Time (s)              10.23907081829384
Epoch Time (s)               176.40948274359107
Total Train Time (s)         77057.61287269974
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:54:48.241142 UTC | [2020_01_11_02_30_29] Iteration #457 | Epoch Duration: 176.50173497200012
2020-01-11 23:54:48.241385 UTC | [2020_01_11_02_30_29] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040359028
Z variance train             0.0068790256
KL Divergence                10.281139
KL Loss                      1.028114
QF Loss                      35.3485
VF Loss                      44.331074
Policy Loss                  -1652.382
Q Predictions Mean           1652.7462
Q Predictions Std            233.3185
Q Predictions Max            1845.4231
Q Predictions Min            201.67343
V Predictions Mean           1649.0183
V Predictions Std            231.31645
V Predictions Max            1844.5117
V Predictions Min            174.0491
Log Pis Mean                 -0.5781525
Log Pis Std                  1.696891
Log Pis Max                  9.491859
Log Pis Min                  -4.761633
Policy mu Mean               -0.0967342
Policy mu Std                0.8012632
Policy mu Max                1.6197214
Policy mu Min                -3.0727024
Policy log std Mean          -0.47107872
Policy log std Std           0.17541367
Policy log std Max           0.1373474
Policy log std Min           -0.9892998
Z mean eval                  0.034781806
Z variance eval              0.0072326525
total_rewards                [ 932.97328732 1702.72274265 1434.5442738  1986.42552153 1185.90838645
 1581.28918862 1447.58174273 1377.17964032 1209.5806186   963.26359157]
total_rewards_mean           1382.1468993597803
total_rewards_std            309.86124114316146
total_rewards_max            1986.4255215314156
total_rewards_min            932.9732873197942
Number of train steps total  1836000
Number of env steps total    2497295
Number of rollouts total     0
Train Time (s)               154.79312995867804
(Previous) Eval Time (s)     13.979592280928046
Sample Time (s)              10.743458989541978
Epoch Time (s)               179.51618122914806
Total Train Time (s)         77237.20770362904
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:57:47.841007 UTC | [2020_01_11_02_30_29] Iteration #458 | Epoch Duration: 179.59945464134216
2020-01-11 23:57:47.841244 UTC | [2020_01_11_02_30_29] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034962602
Z variance train             0.0072271316
KL Divergence                10.227373
KL Loss                      1.0227374
QF Loss                      41.354073
VF Loss                      34.29726
Policy Loss                  -1667.8732
Q Predictions Mean           1666.9373
Q Predictions Std            168.14366
Q Predictions Max            1852.8073
Q Predictions Min            632.5396
V Predictions Mean           1664.4412
V Predictions Std            165.66513
V Predictions Max            1851.3378
V Predictions Min            714.1633
Log Pis Mean                 -0.18829028
Log Pis Std                  1.7099957
Log Pis Max                  4.75534
Log Pis Min                  -4.798257
Policy mu Mean               -0.06675086
Policy mu Std                0.8455164
Policy mu Max                2.0390027
Policy mu Min                -2.049537
Policy log std Mean          -0.4966818
Policy log std Std           0.18020384
Policy log std Max           0.12164256
Policy log std Min           -1.1416186
Z mean eval                  0.054028966
Z variance eval              0.006195125
total_rewards                [ 956.87121448 1921.78514784  958.00206958  974.95912337  906.54883843
 1332.66269667 1168.56487191 1193.34761435  984.54503338  889.84556823]
total_rewards_mean           1128.713217824266
total_rewards_std            297.6299310136897
total_rewards_max            1921.7851478395858
total_rewards_min            889.8455682339978
Number of train steps total  1840000
Number of env steps total    2504473
Number of rollouts total     0
Train Time (s)               153.7742230850272
(Previous) Eval Time (s)     10.8994648065418
Sample Time (s)              10.504087373614311
Epoch Time (s)               175.1777752651833
Total Train Time (s)         77412.46972342301
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:00:43.109135 UTC | [2020_01_11_02_30_29] Iteration #459 | Epoch Duration: 175.26768589019775
2020-01-12 00:00:43.109573 UTC | [2020_01_11_02_30_29] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053837597
Z variance train             0.0061907633
KL Divergence                10.561137
KL Loss                      1.0561137
QF Loss                      72.60542
VF Loss                      100.58535
Policy Loss                  -1651.1853
Q Predictions Mean           1647.9055
Q Predictions Std            210.48982
Q Predictions Max            1854.783
Q Predictions Min            450.53333
V Predictions Mean           1644.2756
V Predictions Std            205.09796
V Predictions Max            1849.3291
V Predictions Min            550.3186
Log Pis Mean                 -0.39437973
Log Pis Std                  1.852232
Log Pis Max                  5.364472
Log Pis Min                  -4.5228343
Policy mu Mean               -0.12901376
Policy mu Std                0.8234077
Policy mu Max                2.0377145
Policy mu Min                -2.6009994
Policy log std Mean          -0.49743286
Policy log std Std           0.17906204
Policy log std Max           0.13531649
Policy log std Min           -1.2101743
Z mean eval                  0.047990542
Z variance eval              0.005606831
total_rewards                [ 668.32621093 1444.25106241  915.37529001  998.79953535 1441.07374123
 1628.52584615  937.96875851 1726.85111682  815.96213954 1066.57978478]
total_rewards_mean           1164.3713485710023
total_rewards_std            347.04522708185044
total_rewards_max            1726.8511168190323
total_rewards_min            668.3262109253118
Number of train steps total  1844000
Number of env steps total    2513277
Number of rollouts total     0
Train Time (s)               157.25423528673127
(Previous) Eval Time (s)     11.485911975614727
Sample Time (s)              10.824152645189315
Epoch Time (s)               179.56429990753531
Total Train Time (s)         77592.11551720882
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:03:42.759161 UTC | [2020_01_11_02_30_29] Iteration #460 | Epoch Duration: 179.6493637561798
2020-01-12 00:03:42.759434 UTC | [2020_01_11_02_30_29] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04798966
Z variance train             0.0056057875
KL Divergence                10.814671
KL Loss                      1.081467
QF Loss                      37.066463
VF Loss                      24.762514
Policy Loss                  -1692.4978
Q Predictions Mean           1692.4509
Q Predictions Std            149.32178
Q Predictions Max            1856.4849
Q Predictions Min            923.00885
V Predictions Mean           1694.3458
V Predictions Std            150.42534
V Predictions Max            1859.198
V Predictions Min            906.0122
Log Pis Mean                 -0.38393387
Log Pis Std                  1.6766661
Log Pis Max                  4.11628
Log Pis Min                  -5.4408855
Policy mu Mean               -0.09907183
Policy mu Std                0.85106313
Policy mu Max                2.4203768
Policy mu Min                -2.2453098
Policy log std Mean          -0.48790887
Policy log std Std           0.1749638
Policy log std Max           0.06319612
Policy log std Min           -1.049742
Z mean eval                  0.028107803
Z variance eval              0.0055103595
total_rewards                [1328.1821958   996.47424834  972.31409179 1043.64090871 1011.83690596
  952.13662512  918.56334    1102.09429654  956.07172306  887.93705709]
total_rewards_mean           1016.9251392406692
total_rewards_std            118.95226196789172
total_rewards_max            1328.1821957990858
total_rewards_min            887.9370570853798
Number of train steps total  1848000
Number of env steps total    2521700
Number of rollouts total     0
Train Time (s)               151.59305458469316
(Previous) Eval Time (s)     9.52024687686935
Sample Time (s)              9.950778936501592
Epoch Time (s)               171.0640803980641
Total Train Time (s)         77763.34591811895
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:06:33.993969 UTC | [2020_01_11_02_30_29] Iteration #461 | Epoch Duration: 171.23438620567322
2020-01-12 00:06:33.994161 UTC | [2020_01_11_02_30_29] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028361935
Z variance train             0.0055104634
KL Divergence                10.744717
KL Loss                      1.0744717
QF Loss                      48.267002
VF Loss                      21.745247
Policy Loss                  -1670.5488
Q Predictions Mean           1666.7998
Q Predictions Std            191.39728
Q Predictions Max            1846.2843
Q Predictions Min            140.93709
V Predictions Mean           1669.4702
V Predictions Std            184.60097
V Predictions Max            1855.0931
V Predictions Min            278.00967
Log Pis Mean                 -0.117522456
Log Pis Std                  1.6939478
Log Pis Max                  5.7911773
Log Pis Min                  -3.6710575
Policy mu Mean               -0.070067845
Policy mu Std                0.8595783
Policy mu Max                2.1101298
Policy mu Min                -2.5757759
Policy log std Mean          -0.4973649
Policy log std Std           0.20008811
Policy log std Max           0.04506436
Policy log std Min           -1.1761022
Z mean eval                  0.052367937
Z variance eval              0.0056173485
total_rewards                [1006.43743222  976.19444589 1176.5020771   821.19727839  982.29292598
 1549.33139807  897.78306916  691.72991464 1083.41192725 1493.58340138]
total_rewards_mean           1067.8463870071819
total_rewards_std            259.96915484270005
total_rewards_max            1549.3313980697094
total_rewards_min            691.72991464076
Number of train steps total  1852000
Number of env steps total    2530925
Number of rollouts total     0
Train Time (s)               145.14973961003125
(Previous) Eval Time (s)     10.071396676823497
Sample Time (s)              10.195017294492573
Epoch Time (s)               165.41615358134732
Total Train Time (s)         77928.84680660488
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:09:19.499718 UTC | [2020_01_11_02_30_29] Iteration #462 | Epoch Duration: 165.5054202079773
2020-01-12 00:09:19.499895 UTC | [2020_01_11_02_30_29] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052140784
Z variance train             0.005616036
KL Divergence                10.6362915
KL Loss                      1.0636292
QF Loss                      149.93132
VF Loss                      34.384785
Policy Loss                  -1671.5978
Q Predictions Mean           1670.3494
Q Predictions Std            197.28564
Q Predictions Max            1850.984
Q Predictions Min            277.53537
V Predictions Mean           1672.6334
V Predictions Std            181.0773
V Predictions Max            1851.7476
V Predictions Min            283.69714
Log Pis Mean                 -0.04707124
Log Pis Std                  2.0205576
Log Pis Max                  7.3141522
Log Pis Min                  -7.1584406
Policy mu Mean               -0.12844245
Policy mu Std                0.8754074
Policy mu Max                2.132329
Policy mu Min                -3.062337
Policy log std Mean          -0.504976
Policy log std Std           0.19613259
Policy log std Max           0.014622688
Policy log std Min           -1.135575
Z mean eval                  0.018021803
Z variance eval              0.0056540444
total_rewards                [1598.19590452 1206.24464732 1139.76769295  864.64745812  830.72638701
 1210.33716248  875.3406941  1435.28744955 1309.89154789 1094.93141784]
total_rewards_mean           1156.537036177253
total_rewards_std            240.03066599430963
total_rewards_max            1598.1959045237106
total_rewards_min            830.7263870088384
Number of train steps total  1856000
Number of env steps total    2539067
Number of rollouts total     0
Train Time (s)               146.5147549849935
(Previous) Eval Time (s)     11.138783460017294
Sample Time (s)              9.928652410861105
Epoch Time (s)               167.5821908558719
Total Train Time (s)         78096.51032214472
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:12:07.168263 UTC | [2020_01_11_02_30_29] Iteration #463 | Epoch Duration: 167.66821813583374
2020-01-12 00:12:07.168453 UTC | [2020_01_11_02_30_29] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018105235
Z variance train             0.0056531797
KL Divergence                10.580597
KL Loss                      1.0580597
QF Loss                      55.99428
VF Loss                      21.879238
Policy Loss                  -1687.2563
Q Predictions Mean           1685.778
Q Predictions Std            151.1362
Q Predictions Max            1860.7788
Q Predictions Min            380.33173
V Predictions Mean           1686.2235
V Predictions Std            137.09789
V Predictions Max            1855.6692
V Predictions Min            759.3881
Log Pis Mean                 -0.34199578
Log Pis Std                  1.7297083
Log Pis Max                  9.004013
Log Pis Min                  -5.4833665
Policy mu Mean               -0.15664119
Policy mu Std                0.8354347
Policy mu Max                1.764804
Policy mu Min                -3.0788982
Policy log std Mean          -0.49283805
Policy log std Std           0.20659931
Policy log std Max           0.28963366
Policy log std Min           -1.3583319
Z mean eval                  0.042826183
Z variance eval              0.0048921807
total_rewards                [ 537.4363061   919.00168951  625.92996006  859.2246627   731.80077984
 1167.15345551 1684.09470946 1176.04499066 1992.73567906  258.59888543]
total_rewards_mean           995.2021118329576
total_rewards_std            501.40702438930197
total_rewards_max            1992.7356790595036
total_rewards_min            258.59888543183456
Number of train steps total  1860000
Number of env steps total    2547590
Number of rollouts total     0
Train Time (s)               145.31489846576005
(Previous) Eval Time (s)     9.912447928916663
Sample Time (s)              9.971895328722894
Epoch Time (s)               165.1992417233996
Total Train Time (s)         78261.78863528231
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:14:52.451686 UTC | [2020_01_11_02_30_29] Iteration #464 | Epoch Duration: 165.28308129310608
2020-01-12 00:14:52.451866 UTC | [2020_01_11_02_30_29] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042970847
Z variance train             0.0048914077
KL Divergence                10.893782
KL Loss                      1.0893782
QF Loss                      373.05948
VF Loss                      26.876844
Policy Loss                  -1696.3721
Q Predictions Mean           1692.6531
Q Predictions Std            172.98749
Q Predictions Max            2048.0925
Q Predictions Min            203.09894
V Predictions Mean           1697.0948
V Predictions Std            160.67235
V Predictions Max            2019.4244
V Predictions Min            597.96277
Log Pis Mean                 -0.30624336
Log Pis Std                  1.9277315
Log Pis Max                  8.431129
Log Pis Min                  -7.323102
Policy mu Mean               0.019953286
Policy mu Std                0.85155857
Policy mu Max                3.2424104
Policy mu Min                -3.2667725
Policy log std Mean          -0.4641889
Policy log std Std           0.21368343
Policy log std Max           0.3243028
Policy log std Min           -1.2991059
Z mean eval                  0.02905802
Z variance eval              0.0048751226
total_rewards                [ 954.71442304  971.40557833  747.58039573  713.40678311 1434.93021536
  835.15486349  743.94520096  740.59525028  959.65493747  545.91522577]
total_rewards_mean           864.7302873530637
total_rewards_std            228.63827396883624
total_rewards_max            1434.9302153563717
total_rewards_min            545.9152257688768
Number of train steps total  1864000
Number of env steps total    2557985
Number of rollouts total     0
Train Time (s)               145.54435320105404
(Previous) Eval Time (s)     8.501789464149624
Sample Time (s)              10.057472862768918
Epoch Time (s)               164.10361552797258
Total Train Time (s)         78425.97150034318
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:17:36.645341 UTC | [2020_01_11_02_30_29] Iteration #465 | Epoch Duration: 164.19332838058472
2020-01-12 00:17:36.645680 UTC | [2020_01_11_02_30_29] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02924122
Z variance train             0.0048810337
KL Divergence                10.930515
KL Loss                      1.0930516
QF Loss                      140.42471
VF Loss                      34.966263
Policy Loss                  -1700.7964
Q Predictions Mean           1698.692
Q Predictions Std            183.02888
Q Predictions Max            1926.9971
Q Predictions Min            158.54204
V Predictions Mean           1698.7434
V Predictions Std            179.79527
V Predictions Max            1942.3615
V Predictions Min            165.09743
Log Pis Mean                 -0.4997627
Log Pis Std                  1.7662389
Log Pis Max                  10.308693
Log Pis Min                  -4.6419296
Policy mu Mean               0.034084428
Policy mu Std                0.81709194
Policy mu Max                2.0180614
Policy mu Min                -2.929909
Policy log std Mean          -0.46810117
Policy log std Std           0.21993951
Policy log std Max           0.32651457
Policy log std Min           -1.4390883
Z mean eval                  0.03925862
Z variance eval              0.00497058
total_rewards                [ 691.76198585  687.4712253   777.5190071   848.07948976  886.73127953
 1169.93363429 1148.73828826  668.30830071 1039.84912781  846.39908863]
total_rewards_mean           876.4791427245578
total_rewards_std            176.55577533116204
total_rewards_max            1169.9336342916845
total_rewards_min            668.3083007128625
Number of train steps total  1868000
Number of env steps total    2567369
Number of rollouts total     0
Train Time (s)               146.22166972607374
(Previous) Eval Time (s)     8.86885116295889
Sample Time (s)              10.127073540352285
Epoch Time (s)               165.21759442938492
Total Train Time (s)         78591.28308814485
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:20:21.955939 UTC | [2020_01_11_02_30_29] Iteration #466 | Epoch Duration: 165.30995965003967
2020-01-12 00:20:21.956149 UTC | [2020_01_11_02_30_29] Iteration #466 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040342994
Z variance train             0.0049723503
KL Divergence                10.95219
KL Loss                      1.095219
QF Loss                      115.654366
VF Loss                      75.56697
Policy Loss                  -1638.9523
Q Predictions Mean           1637.2021
Q Predictions Std            265.80862
Q Predictions Max            1883.8517
Q Predictions Min            202.03683
V Predictions Mean           1644.6538
V Predictions Std            256.05545
V Predictions Max            1878.2839
V Predictions Min            275.85764
Log Pis Mean                 -0.036957912
Log Pis Std                  2.028021
Log Pis Max                  7.332236
Log Pis Min                  -5.4481916
Policy mu Mean               -0.0021282844
Policy mu Std                0.89167774
Policy mu Max                3.446895
Policy mu Min                -2.3767462
Policy log std Mean          -0.4959241
Policy log std Std           0.20981507
Policy log std Max           0.21404567
Policy log std Min           -1.3288536
Z mean eval                  0.026338467
Z variance eval              0.004715395
total_rewards                [637.76113902 623.01165623 400.94263865 615.84140467 647.53146831
 878.91850292 643.08407416 625.57646018 880.6812824  628.42736669]
total_rewards_mean           658.177599323546
total_rewards_std            130.43740050275872
total_rewards_max            880.6812824003879
total_rewards_min            400.94263865496134
Number of train steps total  1872000
Number of env steps total    2576647
Number of rollouts total     0
Train Time (s)               147.16106307972223
(Previous) Eval Time (s)     6.359367785975337
Sample Time (s)              10.188393503893167
Epoch Time (s)               163.70882436959073
Total Train Time (s)         78755.08386179246
Epoch                        467
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:23:05.762332 UTC | [2020_01_11_02_30_29] Iteration #467 | Epoch Duration: 163.8060245513916
2020-01-12 00:23:05.762531 UTC | [2020_01_11_02_30_29] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026229078
Z variance train             0.004716076
KL Divergence                11.005645
KL Loss                      1.1005645
QF Loss                      86.613495
VF Loss                      97.96507
Policy Loss                  -1678.4313
Q Predictions Mean           1677.6702
Q Predictions Std            256.40463
Q Predictions Max            1878.0703
Q Predictions Min            74.38573
V Predictions Mean           1671.6973
V Predictions Std            254.92238
V Predictions Max            1866.063
V Predictions Min            82.74879
Log Pis Mean                 -0.30387422
Log Pis Std                  1.7612244
Log Pis Max                  6.829813
Log Pis Min                  -5.736412
Policy mu Mean               0.033239316
Policy mu Std                0.85066676
Policy mu Max                2.7054965
Policy mu Min                -2.6772614
Policy log std Mean          -0.5122367
Policy log std Std           0.18794301
Policy log std Max           0.062499464
Policy log std Min           -1.218993
Z mean eval                  0.028275201
Z variance eval              0.005524337
total_rewards                [1071.43999063 1238.61574008 1005.49861125 1016.74390353  881.8472975
  947.58692121  931.74748119 1217.83616205 1018.16612709  892.5026858 ]
total_rewards_mean           1022.1984920344046
total_rewards_std            117.52781743687059
total_rewards_max            1238.6157400838429
total_rewards_min            881.8472974951875
Number of train steps total  1876000
Number of env steps total    2585691
Number of rollouts total     0
Train Time (s)               146.6458351649344
(Previous) Eval Time (s)     9.602309618610889
Sample Time (s)              13.28095278935507
Epoch Time (s)               169.52909757290035
Total Train Time (s)         78924.69627315365
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:25:55.379457 UTC | [2020_01_11_02_30_29] Iteration #468 | Epoch Duration: 169.61676478385925
2020-01-12 00:25:55.379704 UTC | [2020_01_11_02_30_29] Iteration #468 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028128212
Z variance train             0.0055221445
KL Divergence                10.635553
KL Loss                      1.0635554
QF Loss                      84.779144
VF Loss                      52.6773
Policy Loss                  -1686.7173
Q Predictions Mean           1684.7607
Q Predictions Std            206.1782
Q Predictions Max            1880.7083
Q Predictions Min            498.45798
V Predictions Mean           1681.7533
V Predictions Std            205.42294
V Predictions Max            1873.1791
V Predictions Min            514.7574
Log Pis Mean                 -0.22389527
Log Pis Std                  1.810577
Log Pis Max                  9.288092
Log Pis Min                  -5.2392244
Policy mu Mean               -0.08693171
Policy mu Std                0.8398503
Policy mu Max                1.8956969
Policy mu Min                -3.3908465
Policy log std Mean          -0.4746804
Policy log std Std           0.196448
Policy log std Max           0.108955055
Policy log std Min           -1.1371702
Z mean eval                  0.05019877
Z variance eval              0.005384594
total_rewards                [907.32393652 822.87896828 774.56225564 881.11124936 913.54945398
 707.18222608 725.88944295 733.37951508 682.19874389 976.1241667 ]
total_rewards_mean           812.4199958482884
total_rewards_std            96.98534144526515
total_rewards_max            976.124166701836
total_rewards_min            682.1987438864271
Number of train steps total  1880000
Number of env steps total    2595896
Number of rollouts total     0
Train Time (s)               149.91417605010793
(Previous) Eval Time (s)     7.574906490277499
Sample Time (s)              9.153030363377184
Epoch Time (s)               166.6421129037626
Total Train Time (s)         79091.4234395898
Epoch                        469
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:28:42.111009 UTC | [2020_01_11_02_30_29] Iteration #469 | Epoch Duration: 166.7311236858368
2020-01-12 00:28:42.111349 UTC | [2020_01_11_02_30_29] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048856467
Z variance train             0.0053825667
KL Divergence                10.7387295
KL Loss                      1.0738729
QF Loss                      66.35754
VF Loss                      162.60269
Policy Loss                  -1661.7101
Q Predictions Mean           1662.6798
Q Predictions Std            213.6951
Q Predictions Max            1871.5718
Q Predictions Min            601.76086
V Predictions Mean           1672.9
V Predictions Std            214.4792
V Predictions Max            1876.7646
V Predictions Min            598.33966
Log Pis Mean                 -0.4179178
Log Pis Std                  1.9295789
Log Pis Max                  9.499714
Log Pis Min                  -5.2764854
Policy mu Mean               -0.1741751
Policy mu Std                0.8316081
Policy mu Max                2.499599
Policy mu Min                -2.6822264
Policy log std Mean          -0.46064615
Policy log std Std           0.19692336
Policy log std Max           0.33176646
Policy log std Min           -1.3273964
Z mean eval                  0.037439268
Z variance eval              0.0057265023
total_rewards                [ 805.57699193 1034.06808214  811.73870928 1003.76798075  898.24960018
  969.72845023  970.71837404  719.93186274 1105.10180627  687.29991879]
total_rewards_mean           900.618177636132
total_rewards_std            132.30374203659616
total_rewards_max            1105.1018062682442
total_rewards_min            687.2999187921945
Number of train steps total  1884000
Number of env steps total    2604481
Number of rollouts total     0
Train Time (s)               151.18364213826135
(Previous) Eval Time (s)     8.198879037983716
Sample Time (s)              10.72365642990917
Epoch Time (s)               170.10617760615423
Total Train Time (s)         79261.62011909578
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:31:32.312990 UTC | [2020_01_11_02_30_29] Iteration #470 | Epoch Duration: 170.20147967338562
2020-01-12 00:31:32.313208 UTC | [2020_01_11_02_30_29] Iteration #470 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03754637
Z variance train             0.005726372
KL Divergence                10.715021
KL Loss                      1.0715021
QF Loss                      24744.156
VF Loss                      28.195799
Policy Loss                  -1690.3147
Q Predictions Mean           1692.0502
Q Predictions Std            184.632
Q Predictions Max            1867.0568
Q Predictions Min            381.5842
V Predictions Mean           1688.4381
V Predictions Std            179.0108
V Predictions Max            1861.6523
V Predictions Min            507.9883
Log Pis Mean                 -0.3184625
Log Pis Std                  1.7681016
Log Pis Max                  7.2191777
Log Pis Min                  -4.967407
Policy mu Mean               0.07549186
Policy mu Std                0.85379964
Policy mu Max                2.2194033
Policy mu Min                -2.2578626
Policy log std Mean          -0.48721066
Policy log std Std           0.24709938
Policy log std Max           0.25473464
Policy log std Min           -1.4976708
Z mean eval                  0.02138444
Z variance eval              0.006335476
total_rewards                [874.36202754 910.69978785 861.20395986 974.82784816 927.91774491
 914.11022491 854.31038185 892.74203061 723.43845684 892.5141837 ]
total_rewards_mean           882.6126646229204
total_rewards_std            62.611237483527766
total_rewards_max            974.8278481600348
total_rewards_min            723.4384568370907
Number of train steps total  1888000
Number of env steps total    2614204
Number of rollouts total     0
Train Time (s)               156.26914877491072
(Previous) Eval Time (s)     8.517889204900712
Sample Time (s)              10.393404092639685
Epoch Time (s)               175.18044207245111
Total Train Time (s)         79436.88083971292
Epoch                        471
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:34:27.578550 UTC | [2020_01_11_02_30_29] Iteration #471 | Epoch Duration: 175.26518440246582
2020-01-12 00:34:27.578785 UTC | [2020_01_11_02_30_29] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021271909
Z variance train             0.0063306056
KL Divergence                10.551935
KL Loss                      1.0551935
QF Loss                      30.958559
VF Loss                      28.948832
Policy Loss                  -1690.6223
Q Predictions Mean           1691.2139
Q Predictions Std            185.02696
Q Predictions Max            1875.5822
Q Predictions Min            712.5863
V Predictions Mean           1693.4377
V Predictions Std            185.58409
V Predictions Max            1873.3711
V Predictions Min            708.7521
Log Pis Mean                 -0.29445976
Log Pis Std                  1.6663158
Log Pis Max                  6.0516143
Log Pis Min                  -5.323529
Policy mu Mean               -0.00025031343
Policy mu Std                0.8110057
Policy mu Max                2.385664
Policy mu Min                -2.477036
Policy log std Mean          -0.5061876
Policy log std Std           0.19197533
Policy log std Max           0.16933912
Policy log std Min           -1.24071
Z mean eval                  0.024240818
Z variance eval              0.006217138
total_rewards                [1146.44663106  960.98970834 1099.34497286 1280.3561306   310.84686363
  307.17863972  582.5987252  1530.91853834  303.40834199 1324.99359354]
total_rewards_mean           884.7082145286319
total_rewards_std            445.01775462104877
total_rewards_max            1530.9185383415597
total_rewards_min            303.408341990185
Number of train steps total  1892000
Number of env steps total    2623371
Number of rollouts total     0
Train Time (s)               155.9477054271847
(Previous) Eval Time (s)     9.021912340074778
Sample Time (s)              10.032588826026767
Epoch Time (s)               175.00220659328625
Total Train Time (s)         79611.96045193635
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:37:22.663586 UTC | [2020_01_11_02_30_29] Iteration #472 | Epoch Duration: 175.08461952209473
2020-01-12 00:37:22.663939 UTC | [2020_01_11_02_30_29] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024394926
Z variance train             0.006206004
KL Divergence                10.409618
KL Loss                      1.0409619
QF Loss                      94.57852
VF Loss                      100.03698
Policy Loss                  -1654.0857
Q Predictions Mean           1650.6707
Q Predictions Std            222.69643
Q Predictions Max            1852.4202
Q Predictions Min            364.52786
V Predictions Mean           1658.102
V Predictions Std            220.41458
V Predictions Max            1862.125
V Predictions Min            346.13297
Log Pis Mean                 -0.23959225
Log Pis Std                  1.9020565
Log Pis Max                  8.511062
Log Pis Min                  -5.1669006
Policy mu Mean               -0.20772094
Policy mu Std                0.81310374
Policy mu Max                3.4267387
Policy mu Min                -2.294044
Policy log std Mean          -0.49082625
Policy log std Std           0.20788921
Policy log std Max           0.19644958
Policy log std Min           -1.2228515
Z mean eval                  0.058263876
Z variance eval              0.0065490366
total_rewards                [1003.0917139   994.45146814 1130.68980772  871.60293232  959.87359316
 1763.18618701  965.76812697 1001.7668707  1172.44803743 1057.47252425]
total_rewards_mean           1092.0351261609271
total_rewards_std            238.15561665536438
total_rewards_max            1763.1861870088076
total_rewards_min            871.6029323199004
Number of train steps total  1896000
Number of env steps total    2632501
Number of rollouts total     0
Train Time (s)               155.58603273658082
(Previous) Eval Time (s)     10.748722345102578
Sample Time (s)              10.384262167848647
Epoch Time (s)               176.71901724953204
Total Train Time (s)         79788.7691194308
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:40:19.484732 UTC | [2020_01_11_02_30_29] Iteration #473 | Epoch Duration: 176.82055926322937
2020-01-12 00:40:19.485368 UTC | [2020_01_11_02_30_29] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058620073
Z variance train             0.0065463446
KL Divergence                10.408178
KL Loss                      1.0408179
QF Loss                      47.910595
VF Loss                      23.946753
Policy Loss                  -1657.4532
Q Predictions Mean           1655.3049
Q Predictions Std            241.27473
Q Predictions Max            1871.7205
Q Predictions Min            483.52792
V Predictions Mean           1657.783
V Predictions Std            237.17206
V Predictions Max            1871.2361
V Predictions Min            540.4401
Log Pis Mean                 -0.38104174
Log Pis Std                  1.7332581
Log Pis Max                  6.75521
Log Pis Min                  -3.7675126
Policy mu Mean               0.040351886
Policy mu Std                0.82875794
Policy mu Max                2.7055657
Policy mu Min                -2.3401234
Policy log std Mean          -0.4891713
Policy log std Std           0.18901365
Policy log std Max           0.11474866
Policy log std Min           -1.2355167
Z mean eval                  0.017179243
Z variance eval              0.0059801256
total_rewards                [ 960.6462194  1057.76808761  877.66166287  848.20848461  985.41202354
  859.03629967  962.03527553  976.97033421  947.91534137  850.24891456]
total_rewards_mean           932.5902643380589
total_rewards_std            66.81761682503274
total_rewards_max            1057.7680876122552
total_rewards_min            848.2084846081151
Number of train steps total  1900000
Number of env steps total    2643432
Number of rollouts total     0
Train Time (s)               156.51596922101453
(Previous) Eval Time (s)     9.020894182380289
Sample Time (s)              10.362281661480665
Epoch Time (s)               175.89914506487548
Total Train Time (s)         79964.78329673316
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:43:15.496806 UTC | [2020_01_11_02_30_29] Iteration #474 | Epoch Duration: 176.01092195510864
2020-01-12 00:43:15.497026 UTC | [2020_01_11_02_30_29] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017180767
Z variance train             0.0059785824
KL Divergence                10.703598
KL Loss                      1.0703598
QF Loss                      51.857155
VF Loss                      34.995903
Policy Loss                  -1653.3876
Q Predictions Mean           1652.2131
Q Predictions Std            251.44003
Q Predictions Max            1874.8374
Q Predictions Min            219.47409
V Predictions Mean           1654.102
V Predictions Std            245.65796
V Predictions Max            1882.302
V Predictions Min            303.9344
Log Pis Mean                 -0.10800908
Log Pis Std                  1.9150652
Log Pis Max                  7.2126384
Log Pis Min                  -6.8731594
Policy mu Mean               0.072628655
Policy mu Std                0.85999846
Policy mu Max                2.2663515
Policy mu Min                -2.5952785
Policy log std Mean          -0.5583224
Policy log std Std           0.2029156
Policy log std Max           0.12660965
Policy log std Min           -1.4618714
Z mean eval                  0.026788548
Z variance eval              0.0058930973
total_rewards                [1130.90349248  939.13915071  947.57246842  876.87823248 1095.73646683
  926.71737776 1026.58993751  918.51747539  668.65597262  947.03392527]
total_rewards_mean           947.7744499466337
total_rewards_std            120.80927621413366
total_rewards_max            1130.9034924790446
total_rewards_min            668.6559726159223
Number of train steps total  1904000
Number of env steps total    2652341
Number of rollouts total     0
Train Time (s)               150.2605107477866
(Previous) Eval Time (s)     8.884010918904096
Sample Time (s)              9.152411853894591
Epoch Time (s)               168.2969335205853
Total Train Time (s)         80133.16619040305
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:46:03.884823 UTC | [2020_01_11_02_30_29] Iteration #475 | Epoch Duration: 168.38763737678528
2020-01-12 00:46:03.885043 UTC | [2020_01_11_02_30_29] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02678718
Z variance train             0.005890584
KL Divergence                10.598713
KL Loss                      1.0598713
QF Loss                      41.9642
VF Loss                      14.264829
Policy Loss                  -1673.4858
Q Predictions Mean           1673.0613
Q Predictions Std            210.01613
Q Predictions Max            1873.9451
Q Predictions Min            606.4641
V Predictions Mean           1671.9404
V Predictions Std            207.53137
V Predictions Max            1883.8193
V Predictions Min            638.15497
Log Pis Mean                 -0.40444627
Log Pis Std                  1.6116922
Log Pis Max                  5.7620864
Log Pis Min                  -5.278159
Policy mu Mean               0.061719
Policy mu Std                0.80857897
Policy mu Max                1.672584
Policy mu Min                -2.2840028
Policy log std Mean          -0.55289316
Policy log std Std           0.20763941
Policy log std Max           0.1184617
Policy log std Min           -1.3250968
Z mean eval                  0.021904994
Z variance eval              0.006171594
total_rewards                [ 781.77212349  941.14414193  652.60015667  887.0148042   954.99032468
  904.16991674  652.28399139 1182.81905312  899.47612799  890.87495121]
total_rewards_mean           874.7145591414521
total_rewards_std            146.67212976310813
total_rewards_max            1182.8190531162913
total_rewards_min            652.2839913871833
Number of train steps total  1908000
Number of env steps total    2661763
Number of rollouts total     0
Train Time (s)               147.62254628771916
(Previous) Eval Time (s)     8.206944188568741
Sample Time (s)              10.122511748690158
Epoch Time (s)               165.95200222497806
Total Train Time (s)         80299.20211791387
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:48:49.925687 UTC | [2020_01_11_02_30_29] Iteration #476 | Epoch Duration: 166.0404872894287
2020-01-12 00:48:49.925898 UTC | [2020_01_11_02_30_29] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022071706
Z variance train             0.006165312
KL Divergence                10.424456
KL Loss                      1.0424455
QF Loss                      131.43411
VF Loss                      61.74018
Policy Loss                  -1651.3927
Q Predictions Mean           1652.759
Q Predictions Std            240.89395
Q Predictions Max            1877.286
Q Predictions Min            303.06314
V Predictions Mean           1649.0099
V Predictions Std            236.36751
V Predictions Max            1867.5013
V Predictions Min            354.4529
Log Pis Mean                 -0.040777236
Log Pis Std                  1.730558
Log Pis Max                  6.8452163
Log Pis Min                  -5.016097
Policy mu Mean               0.14720316
Policy mu Std                0.8556896
Policy mu Max                2.742643
Policy mu Min                -2.8652308
Policy log std Mean          -0.54582256
Policy log std Std           0.19879152
Policy log std Max           0.09026483
Policy log std Min           -1.324441
Z mean eval                  0.054814488
Z variance eval              0.0055342754
total_rewards                [1190.88388372  953.7167595  1271.7557383   967.94968217 1018.56990872
 1189.64129018  888.59629383  900.37427644  980.91962942 1148.63823565]
total_rewards_mean           1051.1045697929121
total_rewards_std            129.78541739395098
total_rewards_max            1271.7557383005499
total_rewards_min            888.596293828308
Number of train steps total  1912000
Number of env steps total    2671835
Number of rollouts total     0
Train Time (s)               147.4792672903277
(Previous) Eval Time (s)     10.02564515126869
Sample Time (s)              11.090957558248192
Epoch Time (s)               168.59586999984458
Total Train Time (s)         80467.87824924616
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:51:38.606483 UTC | [2020_01_11_02_30_29] Iteration #477 | Epoch Duration: 168.68043065071106
2020-01-12 00:51:38.606679 UTC | [2020_01_11_02_30_29] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054354917
Z variance train             0.0055331364
KL Divergence                10.778657
KL Loss                      1.0778657
QF Loss                      38.669075
VF Loss                      23.430935
Policy Loss                  -1672.0857
Q Predictions Mean           1672.6101
Q Predictions Std            190.85275
Q Predictions Max            1871.4302
Q Predictions Min            828.17944
V Predictions Mean           1671.7963
V Predictions Std            190.68706
V Predictions Max            1871.8118
V Predictions Min            847.00006
Log Pis Mean                 -0.28198218
Log Pis Std                  1.6629939
Log Pis Max                  5.307063
Log Pis Min                  -5.1365237
Policy mu Mean               0.10131093
Policy mu Std                0.8337546
Policy mu Max                2.450009
Policy mu Min                -2.2274194
Policy log std Mean          -0.5392974
Policy log std Std           0.19765125
Policy log std Max           0.10245845
Policy log std Min           -1.2330551
Z mean eval                  0.034066673
Z variance eval              0.0059266454
total_rewards                [ 899.32271884  964.37140304  962.69394     962.1576697  1914.58902303
  883.81092174 1062.65233082  785.76267595  802.39706732  941.95834239]
total_rewards_mean           1017.9716092825669
total_rewards_std            308.7411521132762
total_rewards_max            1914.5890230292193
total_rewards_min            785.7626759513478
Number of train steps total  1916000
Number of env steps total    2681852
Number of rollouts total     0
Train Time (s)               157.98548714490607
(Previous) Eval Time (s)     9.071586517151445
Sample Time (s)              9.946856651920825
Epoch Time (s)               177.00393031397834
Total Train Time (s)         80644.97716202354
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:54:35.711106 UTC | [2020_01_11_02_30_29] Iteration #478 | Epoch Duration: 177.10424375534058
2020-01-12 00:54:35.711534 UTC | [2020_01_11_02_30_29] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032370884
Z variance train             0.0059273792
KL Divergence                10.727272
KL Loss                      1.0727272
QF Loss                      6512.325
VF Loss                      252.30748
Policy Loss                  -1648.3649
Q Predictions Mean           1650.7468
Q Predictions Std            224.37572
Q Predictions Max            1866.406
Q Predictions Min            530.83105
V Predictions Mean           1663.2743
V Predictions Std            226.89336
V Predictions Max            1879.1489
V Predictions Min            536.9052
Log Pis Mean                 -0.21054126
Log Pis Std                  1.7173802
Log Pis Max                  6.079402
Log Pis Min                  -5.7530437
Policy mu Mean               0.044516224
Policy mu Std                0.83376235
Policy mu Max                1.8353046
Policy mu Min                -2.278377
Policy log std Mean          -0.54831785
Policy log std Std           0.19194229
Policy log std Max           0.09082204
Policy log std Min           -1.2859228
Z mean eval                  0.028055737
Z variance eval              0.007407678
total_rewards                [ 363.71895655 1450.89903444  899.73178506  958.78781472  950.87482654
  814.23001884 1084.50148749 1840.30043219  830.69106999  803.11950694]
total_rewards_mean           999.6854932743188
total_rewards_std            379.14524975779085
total_rewards_max            1840.3004321931603
total_rewards_min            363.7189565496978
Number of train steps total  1920000
Number of env steps total    2691466
Number of rollouts total     0
Train Time (s)               154.21982765430585
(Previous) Eval Time (s)     10.521140380762517
Sample Time (s)              10.77970671467483
Epoch Time (s)               175.5206747497432
Total Train Time (s)         80820.58703681314
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:57:31.326170 UTC | [2020_01_11_02_30_29] Iteration #479 | Epoch Duration: 175.61434745788574
2020-01-12 00:57:31.326416 UTC | [2020_01_11_02_30_29] Iteration #479 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029120946
Z variance train             0.007407792
KL Divergence                10.071519
KL Loss                      1.007152
QF Loss                      5051.6885
VF Loss                      62.587967
Policy Loss                  -1644.4269
Q Predictions Mean           1642.8062
Q Predictions Std            261.01276
Q Predictions Max            1871.5421
Q Predictions Min            217.60123
V Predictions Mean           1638.7478
V Predictions Std            260.2628
V Predictions Max            1869.402
V Predictions Min            249.01126
Log Pis Mean                 -0.077919155
Log Pis Std                  2.0284286
Log Pis Max                  8.284931
Log Pis Min                  -5.19416
Policy mu Mean               -0.07370762
Policy mu Std                0.86485136
Policy mu Max                2.3519251
Policy mu Min                -2.6108274
Policy log std Mean          -0.570935
Policy log std Std           0.20564881
Policy log std Max           0.09081763
Policy log std Min           -1.3108776
Z mean eval                  0.01706731
Z variance eval              0.007295522
total_rewards                [840.08717025 935.63656889 820.1701437  963.7685319  965.34010868
 830.02256508 819.19157831 957.87171466 774.13153156 830.62579898]
total_rewards_mean           873.6845712017217
total_rewards_std            69.33591031181595
total_rewards_max            965.3401086767738
total_rewards_min            774.131531560081
Number of train steps total  1924000
Number of env steps total    2702379
Number of rollouts total     0
Train Time (s)               154.45642855996266
(Previous) Eval Time (s)     7.6994490078650415
Sample Time (s)              10.655491777230054
Epoch Time (s)               172.81136934505776
Total Train Time (s)         80993.48403509706
Epoch                        480
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:00:24.228948 UTC | [2020_01_11_02_30_29] Iteration #480 | Epoch Duration: 172.90235137939453
2020-01-12 01:00:24.229214 UTC | [2020_01_11_02_30_29] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016850945
Z variance train             0.007292462
KL Divergence                10.135994
KL Loss                      1.0135994
QF Loss                      102.90653
VF Loss                      206.55075
Policy Loss                  -1640.7292
Q Predictions Mean           1639.995
Q Predictions Std            273.72318
Q Predictions Max            1872.034
Q Predictions Min            42.376354
V Predictions Mean           1654.0149
V Predictions Std            277.2976
V Predictions Max            1884.0
V Predictions Min            49.78746
Log Pis Mean                 -0.022675108
Log Pis Std                  1.9444466
Log Pis Max                  7.075731
Log Pis Min                  -5.5459414
Policy mu Mean               0.087906875
Policy mu Std                0.90412414
Policy mu Max                2.7737498
Policy mu Min                -2.8659644
Policy log std Mean          -0.5196754
Policy log std Std           0.20675641
Policy log std Max           0.27179664
Policy log std Min           -1.2758262
Z mean eval                  0.063570835
Z variance eval              0.0063827904
total_rewards                [ 273.10177571  814.09969472  255.74199773  838.73933954  958.75503457
  768.93674468  158.2012966  1208.92571563  992.04661995 1432.02162703]
total_rewards_mean           770.0569846145174
total_rewards_std            401.023609356408
total_rewards_max            1432.0216270300612
total_rewards_min            158.20129659941017
Number of train steps total  1928000
Number of env steps total    2712816
Number of rollouts total     0
Train Time (s)               156.8714716960676
(Previous) Eval Time (s)     7.160469048190862
Sample Time (s)              10.251087612938136
Epoch Time (s)               174.2830283571966
Total Train Time (s)         81167.84703212185
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:03:18.597923 UTC | [2020_01_11_02_30_29] Iteration #481 | Epoch Duration: 174.36849117279053
2020-01-12 01:03:18.598243 UTC | [2020_01_11_02_30_29] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06358583
Z variance train             0.0063800244
KL Divergence                10.644445
KL Loss                      1.0644445
QF Loss                      125.165665
VF Loss                      76.84798
Policy Loss                  -1644.7081
Q Predictions Mean           1647.7446
Q Predictions Std            263.7626
Q Predictions Max            1869.8401
Q Predictions Min            96.3789
V Predictions Mean           1638.3707
V Predictions Std            260.37375
V Predictions Max            1857.2085
V Predictions Min            204.39394
Log Pis Mean                 0.13653873
Log Pis Std                  2.122648
Log Pis Max                  8.4780245
Log Pis Min                  -6.1105804
Policy mu Mean               0.05282044
Policy mu Std                0.9466727
Policy mu Max                2.8964539
Policy mu Min                -2.6544166
Policy log std Mean          -0.5099506
Policy log std Std           0.2301288
Policy log std Max           0.15907335
Policy log std Min           -1.2420633
Z mean eval                  0.01565069
Z variance eval              0.0064130435
total_rewards                [1406.1263115   886.18668407 1147.28134475 1178.54366101 1064.59632628
 1054.09944713  935.13859026 1165.62685062  813.7715862   830.63968513]
total_rewards_mean           1048.2010486958031
total_rewards_std            176.1621140446769
total_rewards_max            1406.1263115029467
total_rewards_min            813.771586203604
Number of train steps total  1932000
Number of env steps total    2722347
Number of rollouts total     0
Train Time (s)               152.81135845417157
(Previous) Eval Time (s)     9.815644159913063
Sample Time (s)              11.427018599584699
Epoch Time (s)               174.05402121366933
Total Train Time (s)         81341.98778303154
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:06:12.744195 UTC | [2020_01_11_02_30_29] Iteration #482 | Epoch Duration: 174.1457691192627
2020-01-12 01:06:12.744324 UTC | [2020_01_11_02_30_29] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015639199
Z variance train             0.006413173
KL Divergence                10.61366
KL Loss                      1.061366
QF Loss                      43.94766
VF Loss                      19.339699
Policy Loss                  -1621.346
Q Predictions Mean           1621.233
Q Predictions Std            295.66043
Q Predictions Max            1868.3488
Q Predictions Min            -20.071802
V Predictions Mean           1622.1958
V Predictions Std            292.87073
V Predictions Max            1868.9431
V Predictions Min            60.06933
Log Pis Mean                 -0.14494482
Log Pis Std                  1.9787866
Log Pis Max                  8.162575
Log Pis Min                  -6.5331507
Policy mu Mean               -0.05099078
Policy mu Std                0.8842142
Policy mu Max                1.8335037
Policy mu Min                -2.7097988
Policy log std Mean          -0.55607
Policy log std Std           0.20750909
Policy log std Max           0.104252905
Policy log std Min           -1.3440924
Z mean eval                  0.045005776
Z variance eval              0.0060900217
total_rewards                [1235.54546675 1044.19553422 1665.7734596  1114.22267164 1103.12017924
 1313.17228118 1319.455283   1126.3713804  1834.93790064 1072.09661914]
total_rewards_mean           1282.8890775799675
total_rewards_std            253.48076876605535
total_rewards_max            1834.9379006448733
total_rewards_min            1044.1955342174385
Number of train steps total  1936000
Number of env steps total    2732482
Number of rollouts total     0
Train Time (s)               146.82583791809157
(Previous) Eval Time (s)     11.900948419235647
Sample Time (s)              9.626023834105581
Epoch Time (s)               168.3528101714328
Total Train Time (s)         81510.43385897903
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:09:01.196292 UTC | [2020_01_11_02_30_29] Iteration #483 | Epoch Duration: 168.4518437385559
2020-01-12 01:09:01.196531 UTC | [2020_01_11_02_30_29] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044974394
Z variance train             0.006088487
KL Divergence                10.620843
KL Loss                      1.0620843
QF Loss                      64.05439
VF Loss                      58.12765
Policy Loss                  -1642.0958
Q Predictions Mean           1642.0688
Q Predictions Std            238.43065
Q Predictions Max            1868.4645
Q Predictions Min            329.17972
V Predictions Mean           1646.9237
V Predictions Std            233.60924
V Predictions Max            1871.8854
V Predictions Min            415.70682
Log Pis Mean                 -0.0881083
Log Pis Std                  1.8403641
Log Pis Max                  7.054698
Log Pis Min                  -4.4093204
Policy mu Mean               -0.019771107
Policy mu Std                0.8578882
Policy mu Max                2.8301504
Policy mu Min                -2.7656324
Policy log std Mean          -0.5427627
Policy log std Std           0.20401841
Policy log std Max           0.11216664
Policy log std Min           -1.3281674
Z mean eval                  0.060739398
Z variance eval              0.0072430456
total_rewards                [ 802.90915369  793.18803023 1023.03681589  763.83459239  797.79347443
  850.93098647 1087.71640145  771.33348626 1063.05959302 1297.61212885]
total_rewards_mean           925.1414662681118
total_rewards_std            172.48880234106676
total_rewards_max            1297.612128850073
total_rewards_min            763.8345923934809
Number of train steps total  1940000
Number of env steps total    2743077
Number of rollouts total     0
Train Time (s)               148.23286341503263
(Previous) Eval Time (s)     9.358605039305985
Sample Time (s)              10.18055999232456
Epoch Time (s)               167.77202844666317
Total Train Time (s)         81678.28857850656
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:11:49.056323 UTC | [2020_01_11_02_30_29] Iteration #484 | Epoch Duration: 167.85961079597473
2020-01-12 01:11:49.056602 UTC | [2020_01_11_02_30_29] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06167826
Z variance train             0.0072534317
KL Divergence                10.110786
KL Loss                      1.0110787
QF Loss                      198.65825
VF Loss                      66.95634
Policy Loss                  -1655.7781
Q Predictions Mean           1658.115
Q Predictions Std            231.06326
Q Predictions Max            1889.3057
Q Predictions Min            244.93088
V Predictions Mean           1654.3113
V Predictions Std            230.85175
V Predictions Max            1894.7449
V Predictions Min            334.64993
Log Pis Mean                 0.033682376
Log Pis Std                  1.8152598
Log Pis Max                  5.7814136
Log Pis Min                  -4.6440344
Policy mu Mean               -0.014193025
Policy mu Std                0.9210202
Policy mu Max                2.714379
Policy mu Min                -2.3583972
Policy log std Mean          -0.5260212
Policy log std Std           0.20579888
Policy log std Max           0.13465601
Policy log std Min           -1.1983359
Z mean eval                  0.034347337
Z variance eval              0.008350235
total_rewards                [1426.97209007  808.73267235 1621.34111967  732.24994074  942.66354134
 1008.39795675  821.84204963 1318.77550851 1163.55133885  759.6313041 ]
total_rewards_mean           1060.4157522002856
total_rewards_std            293.49358291062657
total_rewards_max            1621.3411196695333
total_rewards_min            732.2499407426624
Number of train steps total  1944000
Number of env steps total    2752768
Number of rollouts total     0
Train Time (s)               154.65764953009784
(Previous) Eval Time (s)     10.530245253350586
Sample Time (s)              9.310685997828841
Epoch Time (s)               174.49858078127727
Total Train Time (s)         81852.87976599205
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:14:43.653134 UTC | [2020_01_11_02_30_29] Iteration #485 | Epoch Duration: 174.59631037712097
2020-01-12 01:14:43.653472 UTC | [2020_01_11_02_30_29] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03420984
Z variance train             0.00834503
KL Divergence                10.069857
KL Loss                      1.0069857
QF Loss                      66.626785
VF Loss                      21.579132
Policy Loss                  -1615.325
Q Predictions Mean           1615.2233
Q Predictions Std            280.02164
Q Predictions Max            1882.9861
Q Predictions Min            186.19023
V Predictions Mean           1617.6306
V Predictions Std            276.43103
V Predictions Max            1887.5275
V Predictions Min            308.36874
Log Pis Mean                 0.01842396
Log Pis Std                  1.8267397
Log Pis Max                  5.9819217
Log Pis Min                  -3.7767644
Policy mu Mean               -0.044920623
Policy mu Std                0.8948633
Policy mu Max                2.1128023
Policy mu Min                -2.530188
Policy log std Mean          -0.54037803
Policy log std Std           0.21536507
Policy log std Max           0.2521601
Policy log std Min           -1.20472
Z mean eval                  0.030926306
Z variance eval              0.00860187
total_rewards                [1907.91192397 1194.24768863 1321.60011993 1658.76978898  866.14817301
 1317.75329756 1438.67149871  889.71360915 1143.79217511  899.93025555]
total_rewards_mean           1263.8538530592791
total_rewards_std            325.1801539686713
total_rewards_max            1907.9119239694853
total_rewards_min            866.148173014639
Number of train steps total  1948000
Number of env steps total    2762722
Number of rollouts total     0
Train Time (s)               156.53174514090642
(Previous) Eval Time (s)     11.952321738004684
Sample Time (s)              11.201749420259148
Epoch Time (s)               179.68581629917026
Total Train Time (s)         82032.65440067416
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:17:43.433698 UTC | [2020_01_11_02_30_29] Iteration #486 | Epoch Duration: 179.78000378608704
2020-01-12 01:17:43.434037 UTC | [2020_01_11_02_30_29] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030924797
Z variance train             0.008598335
KL Divergence                10.177689
KL Loss                      1.0177689
QF Loss                      40.165443
VF Loss                      12.5929985
Policy Loss                  -1627.458
Q Predictions Mean           1626.526
Q Predictions Std            266.51974
Q Predictions Max            1875.7509
Q Predictions Min            264.59036
V Predictions Mean           1627.0056
V Predictions Std            265.02014
V Predictions Max            1872.2527
V Predictions Min            287.74393
Log Pis Mean                 -0.032161824
Log Pis Std                  1.8490195
Log Pis Max                  6.0860534
Log Pis Min                  -5.147327
Policy mu Mean               0.033558864
Policy mu Std                0.9183138
Policy mu Max                2.2996979
Policy mu Min                -2.7573683
Policy log std Mean          -0.5492119
Policy log std Std           0.1859117
Policy log std Max           0.10541773
Policy log std Min           -1.5500085
Z mean eval                  0.01926648
Z variance eval              0.0088238595
total_rewards                [ 718.39955884 1096.84023761 1092.09338284 1460.41938058 2124.59722348
 1069.19567625  787.96617034 1265.48673885 1501.92160157  863.54109248]
total_rewards_mean           1198.0461062853897
total_rewards_std            396.53704401744346
total_rewards_max            2124.597223483041
total_rewards_min            718.3995588426492
Number of train steps total  1952000
Number of env steps total    2772674
Number of rollouts total     0
Train Time (s)               156.0620301500894
(Previous) Eval Time (s)     12.256213136017323
Sample Time (s)              10.379408627282828
Epoch Time (s)               178.69765191338956
Total Train Time (s)         82211.43142331252
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:20:42.216438 UTC | [2020_01_11_02_30_29] Iteration #487 | Epoch Duration: 178.7821135520935
2020-01-12 01:20:42.216722 UTC | [2020_01_11_02_30_29] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018524481
Z variance train             0.008814096
KL Divergence                9.984008
KL Loss                      0.9984008
QF Loss                      138.6572
VF Loss                      112.64192
Policy Loss                  -1629.883
Q Predictions Mean           1627.9368
Q Predictions Std            259.95505
Q Predictions Max            1857.201
Q Predictions Min            19.828995
V Predictions Mean           1637.7134
V Predictions Std            261.29202
V Predictions Max            1865.0504
V Predictions Min            57.992344
Log Pis Mean                 -0.115031965
Log Pis Std                  1.925809
Log Pis Max                  6.9839664
Log Pis Min                  -5.3666887
Policy mu Mean               0.0077361646
Policy mu Std                0.8874344
Policy mu Max                2.224451
Policy mu Min                -2.9279015
Policy log std Mean          -0.5468455
Policy log std Std           0.19790548
Policy log std Max           0.1147961
Policy log std Min           -1.1450554
Z mean eval                  0.0325403
Z variance eval              0.009607603
total_rewards                [1316.24742066 1871.88679323 1070.12540079  821.6568957  1562.99400917
  698.22281944 1288.78124979  940.71796257 1336.59859376  771.84048012]
total_rewards_mean           1167.9071625213703
total_rewards_std            357.11213432330334
total_rewards_max            1871.8867932328171
total_rewards_min            698.2228194365978
Number of train steps total  1956000
Number of env steps total    2781826
Number of rollouts total     0
Train Time (s)               156.97785316826776
(Previous) Eval Time (s)     10.554774453863502
Sample Time (s)              9.765138640534133
Epoch Time (s)               177.2977662626654
Total Train Time (s)         82388.8233247078
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:23:39.613346 UTC | [2020_01_11_02_30_29] Iteration #488 | Epoch Duration: 177.39643931388855
2020-01-12 01:23:39.613566 UTC | [2020_01_11_02_30_29] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0323208
Z variance train             0.009613749
KL Divergence                9.538782
KL Loss                      0.9538782
QF Loss                      37.2701
VF Loss                      12.136687
Policy Loss                  -1684.0189
Q Predictions Mean           1683.8407
Q Predictions Std            195.11713
Q Predictions Max            1868.3586
Q Predictions Min            472.7332
V Predictions Mean           1682.8604
V Predictions Std            195.07175
V Predictions Max            1865.0864
V Predictions Min            490.86777
Log Pis Mean                 -0.19856018
Log Pis Std                  1.6935264
Log Pis Max                  5.8748026
Log Pis Min                  -4.9803147
Policy mu Mean               0.107884645
Policy mu Std                0.882154
Policy mu Max                1.7973492
Policy mu Min                -2.1768575
Policy log std Mean          -0.5022747
Policy log std Std           0.2095002
Policy log std Max           0.42873225
Policy log std Min           -1.146569
Z mean eval                  0.0383129
Z variance eval              0.009558451
total_rewards                [1027.6768548  1600.49186982 1380.78459653 1280.9658295   915.32330258
  477.9403521   657.79577664  806.36716143  948.09468216  725.78571506]
total_rewards_mean           982.1226140624236
total_rewards_std            330.80215428856013
total_rewards_max            1600.491869819101
total_rewards_min            477.94035210342554
Number of train steps total  1960000
Number of env steps total    2791667
Number of rollouts total     0
Train Time (s)               154.7412190870382
(Previous) Eval Time (s)     9.86577994003892
Sample Time (s)              10.592993396800011
Epoch Time (s)               175.19999242387712
Total Train Time (s)         82564.10302711651
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:26:34.898785 UTC | [2020_01_11_02_30_29] Iteration #489 | Epoch Duration: 175.28497982025146
2020-01-12 01:26:34.899078 UTC | [2020_01_11_02_30_29] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03841085
Z variance train             0.009560101
KL Divergence                9.33816
KL Loss                      0.93381596
QF Loss                      100.158356
VF Loss                      133.80986
Policy Loss                  -1667.2084
Q Predictions Mean           1668.2644
Q Predictions Std            231.14825
Q Predictions Max            1878.294
Q Predictions Min            367.93356
V Predictions Mean           1657.2261
V Predictions Std            228.96902
V Predictions Max            1867.5348
V Predictions Min            372.5501
Log Pis Mean                 0.02049844
Log Pis Std                  1.8990076
Log Pis Max                  5.3993287
Log Pis Min                  -5.7919807
Policy mu Mean               0.10508417
Policy mu Std                0.93641055
Policy mu Max                1.9173342
Policy mu Min                -2.1869476
Policy log std Mean          -0.5612915
Policy log std Std           0.20114893
Policy log std Max           0.46854293
Policy log std Min           -1.3562555
Z mean eval                  0.024439167
Z variance eval              0.009100453
total_rewards                [ 880.56861945  885.18374649  784.06794696 1141.4689004   756.09453645
  741.19101237 1631.05767366 1286.15342822  953.38401112 1486.22036336]
total_rewards_mean           1054.539023848361
total_rewards_std            301.5815823587049
total_rewards_max            1631.0576736625094
total_rewards_min            741.1910123710652
Number of train steps total  1964000
Number of env steps total    2801025
Number of rollouts total     0
Train Time (s)               146.6616545850411
(Previous) Eval Time (s)     10.157447547186166
Sample Time (s)              10.839917317032814
Epoch Time (s)               167.6590194492601
Total Train Time (s)         82731.8434489835
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:29:22.643888 UTC | [2020_01_11_02_30_29] Iteration #490 | Epoch Duration: 167.74459218978882
2020-01-12 01:29:22.644110 UTC | [2020_01_11_02_30_29] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024399135
Z variance train             0.009094966
KL Divergence                9.497736
KL Loss                      0.9497736
QF Loss                      140.53491
VF Loss                      20.287884
Policy Loss                  -1629.5533
Q Predictions Mean           1629.517
Q Predictions Std            267.78796
Q Predictions Max            1876.2755
Q Predictions Min            20.517319
V Predictions Mean           1629.2987
V Predictions Std            262.67343
V Predictions Max            1871.5686
V Predictions Min            39.80956
Log Pis Mean                 -0.06425598
Log Pis Std                  1.7875502
Log Pis Max                  4.982111
Log Pis Min                  -4.2025843
Policy mu Mean               0.12114354
Policy mu Std                0.8561932
Policy mu Max                1.9522818
Policy mu Min                -2.3367498
Policy log std Mean          -0.55949336
Policy log std Std           0.20517209
Policy log std Max           0.15310156
Policy log std Min           -1.3375506
Z mean eval                  0.027094414
Z variance eval              0.009475117
total_rewards                [1059.97037964  831.74373555 1024.43178962 1107.82837119 3342.68257301
 1445.39031797 1664.15828048  833.23375356 1050.91826109 3300.508375  ]
total_rewards_mean           1566.0865837112224
total_rewards_std            910.4928946918592
total_rewards_max            3342.6825730096343
total_rewards_min            831.7437355548869
Number of train steps total  1968000
Number of env steps total    2810273
Number of rollouts total     0
Train Time (s)               146.84692520089447
(Previous) Eval Time (s)     14.849568346049637
Sample Time (s)              10.017464737407863
Epoch Time (s)               171.71395828435197
Total Train Time (s)         82903.63391573913
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:32:14.439380 UTC | [2020_01_11_02_30_29] Iteration #491 | Epoch Duration: 171.79511547088623
2020-01-12 01:32:14.439593 UTC | [2020_01_11_02_30_29] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027181014
Z variance train             0.009484949
KL Divergence                9.398953
KL Loss                      0.93989533
QF Loss                      54.745422
VF Loss                      31.685333
Policy Loss                  -1648.2438
Q Predictions Mean           1646.9156
Q Predictions Std            219.37616
Q Predictions Max            1878.0873
Q Predictions Min            497.98032
V Predictions Mean           1650.2751
V Predictions Std            219.2734
V Predictions Max            1879.1471
V Predictions Min            501.357
Log Pis Mean                 -0.12226638
Log Pis Std                  1.73357
Log Pis Max                  7.0710735
Log Pis Min                  -4.658599
Policy mu Mean               -0.004341898
Policy mu Std                0.8476495
Policy mu Max                1.7159156
Policy mu Min                -3.2483234
Policy log std Mean          -0.55763614
Policy log std Std           0.21792686
Policy log std Max           0.08914584
Policy log std Min           -1.6438837
Z mean eval                  0.027301928
Z variance eval              0.008718568
total_rewards                [ 879.24387922 2945.15770773  855.85263591 1169.65760908 1136.80510344
 1450.40756376 1201.94396917 2222.11077679 1778.48550506 1233.19236795]
total_rewards_mean           1487.2857118088564
total_rewards_std            623.6702779120171
total_rewards_max            2945.1577077303605
total_rewards_min            855.8526359050409
Number of train steps total  1972000
Number of env steps total    2820529
Number of rollouts total     0
Train Time (s)               152.7420407361351
(Previous) Eval Time (s)     15.076240336056799
Sample Time (s)              9.921930072363466
Epoch Time (s)               177.74021114455536
Total Train Time (s)         83081.4556196765
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:35:12.272349 UTC | [2020_01_11_02_30_29] Iteration #492 | Epoch Duration: 177.8325479030609
2020-01-12 01:35:12.272819 UTC | [2020_01_11_02_30_29] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027581355
Z variance train             0.008715329
KL Divergence                9.603987
KL Loss                      0.9603987
QF Loss                      82.08234
VF Loss                      45.406464
Policy Loss                  -1645.142
Q Predictions Mean           1646.657
Q Predictions Std            241.18523
Q Predictions Max            1866.1786
Q Predictions Min            238.70967
V Predictions Mean           1640.6721
V Predictions Std            240.56114
V Predictions Max            1862.8267
V Predictions Min            250.71295
Log Pis Mean                 -0.29892606
Log Pis Std                  1.823398
Log Pis Max                  6.2464285
Log Pis Min                  -6.4263015
Policy mu Mean               -0.09224201
Policy mu Std                0.86716276
Policy mu Max                2.286672
Policy mu Min                -2.5592873
Policy log std Mean          -0.520887
Policy log std Std           0.19559328
Policy log std Max           0.1562885
Policy log std Min           -1.4529245
Z mean eval                  0.032277618
Z variance eval              0.00829391
total_rewards                [1069.56778515 2907.68599367 2153.67875101 1410.75490957  866.69937431
  633.5948347  2153.92697872  901.4260518  1924.82745249  847.37238298]
total_rewards_mean           1486.9534514398529
total_rewards_std            717.2482309880941
total_rewards_max            2907.6859936665223
total_rewards_min            633.594834698187
Number of train steps total  1976000
Number of env steps total    2830364
Number of rollouts total     0
Train Time (s)               155.04034695401788
(Previous) Eval Time (s)     15.370873149950057
Sample Time (s)              9.670428417157382
Epoch Time (s)               180.08164852112532
Total Train Time (s)         83261.62283312669
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:38:12.438439 UTC | [2020_01_11_02_30_29] Iteration #493 | Epoch Duration: 180.16528749465942
2020-01-12 01:38:12.438645 UTC | [2020_01_11_02_30_29] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03287545
Z variance train             0.008290089
KL Divergence                9.724369
KL Loss                      0.9724369
QF Loss                      52.087585
VF Loss                      20.845543
Policy Loss                  -1653.5992
Q Predictions Mean           1653.4729
Q Predictions Std            221.09381
Q Predictions Max            1878.1686
Q Predictions Min            570.13336
V Predictions Mean           1652.0398
V Predictions Std            219.88081
V Predictions Max            1868.713
V Predictions Min            586.0787
Log Pis Mean                 -0.053451627
Log Pis Std                  1.7401974
Log Pis Max                  5.1520996
Log Pis Min                  -4.8547196
Policy mu Mean               0.07331929
Policy mu Std                0.8774272
Policy mu Max                1.8074776
Policy mu Min                -2.2317047
Policy log std Mean          -0.5460722
Policy log std Std           0.19333182
Policy log std Max           0.077048
Policy log std Min           -1.3255773
Z mean eval                  0.03801923
Z variance eval              0.008721515
total_rewards                [2959.84570474 1621.91063968 2945.03068821  951.29054715  934.07822505
 1571.03208029 1247.77571078 1814.10688064  846.93950893  872.57824613]
total_rewards_mean           1576.4588231628466
total_rewards_std            760.5581648618776
total_rewards_max            2959.8457047385227
total_rewards_min            846.9395089344159
Number of train steps total  1980000
Number of env steps total    2841311
Number of rollouts total     0
Train Time (s)               157.19142590044066
(Previous) Eval Time (s)     15.88557345373556
Sample Time (s)              10.628370092716068
Epoch Time (s)               183.7053694468923
Total Train Time (s)         83445.44522939157
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:41:16.266185 UTC | [2020_01_11_02_30_29] Iteration #494 | Epoch Duration: 183.82736778259277
2020-01-12 01:41:16.266457 UTC | [2020_01_11_02_30_29] Iteration #494 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03805686
Z variance train             0.008725976
KL Divergence                9.651915
KL Loss                      0.9651915
QF Loss                      61.940125
VF Loss                      110.53574
Policy Loss                  -1653.2777
Q Predictions Mean           1653.0503
Q Predictions Std            230.91495
Q Predictions Max            1859.6765
Q Predictions Min            278.9993
V Predictions Mean           1645.0137
V Predictions Std            229.96053
V Predictions Max            1850.7854
V Predictions Min            325.20422
Log Pis Mean                 -0.090469815
Log Pis Std                  1.6152748
Log Pis Max                  6.1554127
Log Pis Min                  -4.1073384
Policy mu Mean               0.0673191
Policy mu Std                0.8767976
Policy mu Max                1.8066875
Policy mu Min                -2.5257003
Policy log std Mean          -0.5561443
Policy log std Std           0.20461956
Policy log std Max           -0.020629942
Policy log std Min           -1.4192016
Z mean eval                  0.022991998
Z variance eval              0.009772271
total_rewards                [1461.89958315 2896.64540501 1690.34260505 1385.44124525 1874.1638911
 1163.32022792 1612.23952292 1754.22408915 1256.62924173 2086.90682137]
total_rewards_mean           1718.1812632658875
total_rewards_std            475.35900491860804
total_rewards_max            2896.6454050089055
total_rewards_min            1163.3202279181478
Number of train steps total  1984000
Number of env steps total    2851029
Number of rollouts total     0
Train Time (s)               156.78174202190712
(Previous) Eval Time (s)     16.416138213593513
Sample Time (s)              9.932117685675621
Epoch Time (s)               183.12999792117625
Total Train Time (s)         83628.82516038418
Epoch                        495
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:44:19.650883 UTC | [2020_01_11_02_30_29] Iteration #495 | Epoch Duration: 183.38425946235657
2020-01-12 01:44:19.651095 UTC | [2020_01_11_02_30_29] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022879887
Z variance train             0.009786154
KL Divergence                9.340158
KL Loss                      0.93401587
QF Loss                      64.385574
VF Loss                      27.331146
Policy Loss                  -1657.786
Q Predictions Mean           1659.9204
Q Predictions Std            200.8293
Q Predictions Max            1881.2186
Q Predictions Min            467.7197
V Predictions Mean           1658.1273
V Predictions Std            202.22374
V Predictions Max            1881.6849
V Predictions Min            452.7716
Log Pis Mean                 -0.22116384
Log Pis Std                  1.7406652
Log Pis Max                  3.9661818
Log Pis Min                  -5.333684
Policy mu Mean               -0.018498909
Policy mu Std                0.8719603
Policy mu Max                1.81808
Policy mu Min                -2.4668307
Policy log std Mean          -0.5510834
Policy log std Std           0.20180409
Policy log std Max           0.27402267
Policy log std Min           -1.3765419
Z mean eval                  0.028398577
Z variance eval              0.009631887
total_rewards                [ 899.36495726  811.2563687  1633.98669759 1019.05704398 1085.64905697
 1128.11254145 1704.43723137  881.09326512 1338.31076629  875.74899041]
total_rewards_mean           1137.7016919149414
total_rewards_std            303.7182923415078
total_rewards_max            1704.4372313732688
total_rewards_min            811.2563686986188
Number of train steps total  1988000
Number of env steps total    2861794
Number of rollouts total     0
Train Time (s)               155.06842489214614
(Previous) Eval Time (s)     10.549746323842555
Sample Time (s)              10.286121146287769
Epoch Time (s)               175.90429236227646
Total Train Time (s)         83804.81193217775
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:47:15.643097 UTC | [2020_01_11_02_30_29] Iteration #496 | Epoch Duration: 175.99181652069092
2020-01-12 01:47:15.643375 UTC | [2020_01_11_02_30_29] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028622579
Z variance train             0.009626591
KL Divergence                9.497741
KL Loss                      0.9497741
QF Loss                      75.311356
VF Loss                      21.228445
Policy Loss                  -1666.82
Q Predictions Mean           1665.7823
Q Predictions Std            192.70186
Q Predictions Max            1874.9194
Q Predictions Min            222.45656
V Predictions Mean           1665.186
V Predictions Std            190.9292
V Predictions Max            1870.2937
V Predictions Min            305.42374
Log Pis Mean                 -0.17047621
Log Pis Std                  1.854473
Log Pis Max                  6.4622884
Log Pis Min                  -6.1933975
Policy mu Mean               0.05988422
Policy mu Std                0.8638011
Policy mu Max                1.6143254
Policy mu Min                -2.320675
Policy log std Mean          -0.53014356
Policy log std Std           0.19261129
Policy log std Max           0.096879125
Policy log std Min           -1.1813943
Z mean eval                  0.03497135
Z variance eval              0.008765882
total_rewards                [ 945.09881781 1316.5117607   645.90141594  748.83588882 2206.35592785
 1523.88772242  889.58976581  732.48613003 1048.51893129 1578.22819602]
total_rewards_mean           1163.5414556688697
total_rewards_std            466.3061193465386
total_rewards_max            2206.355927851223
total_rewards_min            645.9014159360958
Number of train steps total  1992000
Number of env steps total    2871363
Number of rollouts total     0
Train Time (s)               148.8411692720838
(Previous) Eval Time (s)     11.011906140949577
Sample Time (s)              10.146518339868635
Epoch Time (s)               169.999593752902
Total Train Time (s)         83974.95992023451
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:50:05.797495 UTC | [2020_01_11_02_30_29] Iteration #497 | Epoch Duration: 170.15394163131714
2020-01-12 01:50:05.797799 UTC | [2020_01_11_02_30_29] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03511675
Z variance train             0.008763861
KL Divergence                9.743526
KL Loss                      0.97435266
QF Loss                      200.36879
VF Loss                      57.348495
Policy Loss                  -1655.2891
Q Predictions Mean           1654.3506
Q Predictions Std            250.56613
Q Predictions Max            1877.4131
Q Predictions Min            297.0169
V Predictions Mean           1659.3088
V Predictions Std            247.11179
V Predictions Max            1877.3752
V Predictions Min            294.74927
Log Pis Mean                 0.06998469
Log Pis Std                  1.9077948
Log Pis Max                  7.472787
Log Pis Min                  -4.565638
Policy mu Mean               0.16882606
Policy mu Std                0.91385823
Policy mu Max                2.5109806
Policy mu Min                -2.904004
Policy log std Mean          -0.5183087
Policy log std Std           0.20972067
Policy log std Max           0.10213444
Policy log std Min           -1.5918609
Z mean eval                  0.022916393
Z variance eval              0.008478502
total_rewards                [ 857.35620167 3242.49448066 1369.57250977  202.42940538  455.55071114
 2067.77040516 2235.46611851  758.29098869 2447.37858571 2644.47513472]
total_rewards_mean           1628.078454142287
total_rewards_std            984.7622900113106
total_rewards_max            3242.494480657042
total_rewards_min            202.42940538216888
Number of train steps total  1996000
Number of env steps total    2881934
Number of rollouts total     0
Train Time (s)               149.22940658172593
(Previous) Eval Time (s)     15.848869870882481
Sample Time (s)              9.741891605313867
Epoch Time (s)               174.82016805792227
Total Train Time (s)         84149.8584985151
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:53:00.702084 UTC | [2020_01_11_02_30_29] Iteration #498 | Epoch Duration: 174.90402817726135
2020-01-12 01:53:00.702407 UTC | [2020_01_11_02_30_29] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02301227
Z variance train             0.008477438
KL Divergence                9.854557
KL Loss                      0.9854557
QF Loss                      185.64288
VF Loss                      116.37947
Policy Loss                  -1657.6742
Q Predictions Mean           1657.6632
Q Predictions Std            210.02876
Q Predictions Max            1869.9662
Q Predictions Min            496.55334
V Predictions Mean           1655.598
V Predictions Std            206.56512
V Predictions Max            1860.2437
V Predictions Min            510.80334
Log Pis Mean                 -0.22454748
Log Pis Std                  1.7632681
Log Pis Max                  4.6277776
Log Pis Min                  -5.9263883
Policy mu Mean               -0.08387095
Policy mu Std                0.8827148
Policy mu Max                2.0532458
Policy mu Min                -2.4192445
Policy log std Mean          -0.53661704
Policy log std Std           0.20563298
Policy log std Max           0.14584714
Policy log std Min           -1.3237797
Z mean eval                  0.02651013
Z variance eval              0.008400967
total_rewards                [1544.51329959 1715.69919164  916.64331879  465.55755247 1032.55394902
  193.60227485 1964.99847194  906.56890901 1019.962884    220.04960108]
total_rewards_mean           998.0149452393431
total_rewards_std            574.5665618341797
total_rewards_max            1964.9984719420509
total_rewards_min            193.60227484697566
Number of train steps total  2000000
Number of env steps total    2891857
Number of rollouts total     0
Train Time (s)               151.12673365790397
(Previous) Eval Time (s)     9.558442696928978
Sample Time (s)              10.202586678788066
Epoch Time (s)               170.887763033621
Total Train Time (s)         84320.82831833418
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:55:51.676353 UTC | [2020_01_11_02_30_29] Iteration #499 | Epoch Duration: 170.97374892234802
2020-01-12 01:55:51.676558 UTC | [2020_01_11_02_30_29] Iteration #499 | Started Training: True
2020-01-12 01:55:52.234409 UTC | [2020_01_11_02_30_29] Variant:
2020-01-12 01:55:52.234991 UTC | [2020_01_11_02_30_29] {
  "env_name": "Ant-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20_seed56",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020739615
Z variance train             0.6925828
KL Divergence                0.14979754
KL Loss                      0.014979755
QF Loss                      170.93364
VF Loss                      28.43916
Policy Loss                  -5.2961206
Q Predictions Mean           0.00031675867
Q Predictions Std            0.001953969
Q Predictions Max            0.004820696
Q Predictions Min            -0.006647126
V Predictions Mean           0.0006681929
V Predictions Std            0.001489744
V Predictions Max            0.006949477
V Predictions Min            -0.0035818887
Log Pis Mean                 -5.3144464
Log Pis Std                  0.63060546
Log Pis Max                  -3.633874
Log Pis Min                  -7.648528
Policy mu Mean               0.00019556031
Policy mu Std                0.0018260028
Policy mu Max                0.005162905
Policy mu Min                -0.003271655
Policy log std Mean          0.000110227906
Policy log std Std           0.0018035872
Policy log std Max           0.0047096843
Policy log std Min           -0.0044151316
Z mean eval                  1.0544976
Z variance eval              0.0024129825
total_rewards                [ 13.13736166  -7.38926891  93.17613454 -20.71727439 165.7598549
  64.50569213  71.79475596  11.20247275  94.82248633   9.99270943]
total_rewards_mean           49.62849244052059
total_rewards_std            55.422712674363645
total_rewards_max            165.75985490347642
total_rewards_min            -20.717274385917413
Number of train steps total  4000
Number of env steps total    5816
Number of rollouts total     0
Train Time (s)               149.23043684707955
(Previous) Eval Time (s)     0
Sample Time (s)              21.58799327770248
Epoch Time (s)               170.81843012478203
Total Train Time (s)         200.9515971839428
Epoch                        0
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:59:13.283674 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #0 | Epoch Duration: 200.95620822906494
2020-01-12 01:59:13.284049 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0566139
Z variance train             0.002407066
KL Divergence                21.542606
KL Loss                      2.1542606
QF Loss                      181.38506
VF Loss                      31.826447
Policy Loss                  -89.68265
Q Predictions Mean           79.707436
Q Predictions Std            22.603193
Q Predictions Max            136.58455
Q Predictions Min            -20.208584
V Predictions Mean           89.10989
V Predictions Std            18.345472
V Predictions Max            138.96791
V Predictions Min            10.631987
Log Pis Mean                 -2.4285212
Log Pis Std                  1.8314219
Log Pis Max                  2.5941508
Log Pis Min                  -8.114782
Policy mu Mean               0.044504944
Policy mu Std                0.40066025
Policy mu Max                1.6059942
Policy mu Min                -1.1674106
Policy log std Mean          -0.81093395
Policy log std Std           0.11363833
Policy log std Max           -0.21670234
Policy log std Min           -1.150845
Z mean eval                  1.1397088
Z variance eval              0.005028114
total_rewards                [-175.58266771   35.645596    -46.37078067   10.06083892  -77.63924695
   31.37982564  -14.79590003  -53.50795412   10.32066599    6.17485603]
total_rewards_mean           -27.43147669183299
total_rewards_std            60.88160911848864
total_rewards_max            35.645596000592676
total_rewards_min            -175.58266770743697
Number of train steps total  8000
Number of env steps total    9872
Number of rollouts total     0
Train Time (s)               147.62579732807353
(Previous) Eval Time (s)     22.58427954511717
Sample Time (s)              13.87459096359089
Epoch Time (s)               184.0846678367816
Total Train Time (s)         385.12779380986467
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:02:17.460392 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #1 | Epoch Duration: 184.17612552642822
2020-01-12 02:02:17.460607 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1409552
Z variance train             0.00505676
KL Divergence                21.630806
KL Loss                      2.1630807
QF Loss                      377.52515
VF Loss                      60.044106
Policy Loss                  -169.96007
Q Predictions Mean           162.6568
Q Predictions Std            32.16505
Q Predictions Max            240.86234
Q Predictions Min            -60.781742
V Predictions Mean           173.03932
V Predictions Std            27.815828
V Predictions Max            246.92134
V Predictions Min            -26.464302
Log Pis Mean                 -1.2564224
Log Pis Std                  2.1493669
Log Pis Max                  5.755768
Log Pis Min                  -7.87923
Policy mu Mean               -0.011179952
Policy mu Std                0.5407934
Policy mu Max                1.6659592
Policy mu Min                -1.8308569
Policy log std Mean          -0.8368506
Policy log std Std           0.13767964
Policy log std Max           -0.26710713
Policy log std Min           -1.2649587
Z mean eval                  1.1919354
Z variance eval              0.008486282
total_rewards                [-42.91850687 -74.90735296  14.04386229   2.98243962 -70.38657656
   5.64582132  17.9697845    3.87189681  41.17354515 -32.1296302 ]
total_rewards_mean           -13.465471688001376
total_rewards_std            37.27957839181186
total_rewards_max            41.173545152492096
total_rewards_min            -74.90735295916778
Number of train steps total  12000
Number of env steps total    12769
Number of rollouts total     0
Train Time (s)               148.50378854526207
(Previous) Eval Time (s)     13.598402393981814
Sample Time (s)              13.458345065359026
Epoch Time (s)               175.5605360046029
Total Train Time (s)         560.7780516389757
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:05:13.112567 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #2 | Epoch Duration: 175.65174055099487
2020-01-12 02:05:13.112853 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1879838
Z variance train             0.008594788
KL Divergence                22.08867
KL Loss                      2.208867
QF Loss                      215.13931
VF Loss                      72.14874
Policy Loss                  -218.62689
Q Predictions Mean           210.3663
Q Predictions Std            33.547077
Q Predictions Max            306.7834
Q Predictions Min            17.93596
V Predictions Mean           223.07822
V Predictions Std            28.865833
V Predictions Max            306.87415
V Predictions Min            85.75181
Log Pis Mean                 -1.7050557
Log Pis Std                  2.3909745
Log Pis Max                  7.495367
Log Pis Min                  -11.297843
Policy mu Mean               0.022688957
Policy mu Std                0.54718035
Policy mu Max                1.6941465
Policy mu Min                -1.6956433
Policy log std Mean          -0.78675675
Policy log std Std           0.132799
Policy log std Max           -0.1904356
Policy log std Min           -1.2419926
Z mean eval                  1.1943372
Z variance eval              0.005781381
total_rewards                [ 30.15888466 -22.44192132 -77.61071976  12.06497705  13.74167552
   4.14600521 -27.83406982  40.28186251  15.56433745  12.01679654]
total_rewards_mean           0.008782803868975541
total_rewards_std            32.51495620932859
total_rewards_max            40.2818625140113
total_rewards_min            -77.61071975920818
Number of train steps total  16000
Number of env steps total    16241
Number of rollouts total     0
Train Time (s)               147.22107549197972
(Previous) Eval Time (s)     23.85515489289537
Sample Time (s)              10.137045213021338
Epoch Time (s)               181.21327559789643
Total Train Time (s)         742.082006814424
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:08:14.417327 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #3 | Epoch Duration: 181.30430579185486
2020-01-12 02:08:14.417549 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1932265
Z variance train             0.0057705874
KL Divergence                22.737156
KL Loss                      2.2737157
QF Loss                      184.514
VF Loss                      38.644375
Policy Loss                  -237.90352
Q Predictions Mean           228.2254
Q Predictions Std            32.8014
Q Predictions Max            309.87054
Q Predictions Min            52.324368
V Predictions Mean           239.50693
V Predictions Std            25.89154
V Predictions Max            303.99063
V Predictions Min            154.73488
Log Pis Mean                 -2.2389333
Log Pis Std                  2.0019736
Log Pis Max                  4.044941
Log Pis Min                  -9.031786
Policy mu Mean               0.04706185
Policy mu Std                0.49314916
Policy mu Max                1.8001937
Policy mu Min                -1.7522733
Policy log std Mean          -0.7510754
Policy log std Std           0.13919504
Policy log std Max           -0.24323589
Policy log std Min           -1.3386207
Z mean eval                  1.1989933
Z variance eval              0.018279966
total_rewards                [   1.79700124  100.52926589   74.90109721   44.31445363  -13.45702129
    3.13507543   69.75661542   52.40010326   87.46440898 -183.61403938]
total_rewards_mean           23.7226960404253
total_rewards_std            78.24478208510145
total_rewards_max            100.52926589268236
total_rewards_min            -183.61403937607616
Number of train steps total  20000
Number of env steps total    19211
Number of rollouts total     0
Train Time (s)               139.12519570579752
(Previous) Eval Time (s)     24.04441267065704
Sample Time (s)              12.801806816831231
Epoch Time (s)               175.9714151932858
Total Train Time (s)         918.175864352379
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:11:10.512400 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #4 | Epoch Duration: 176.0946545600891
2020-01-12 02:11:10.512656 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2023884
Z variance train             0.01827148
KL Divergence                20.219389
KL Loss                      2.021939
QF Loss                      149.64822
VF Loss                      40.489525
Policy Loss                  -253.6789
Q Predictions Mean           245.13567
Q Predictions Std            38.532124
Q Predictions Max            310.1511
Q Predictions Min            -1.4830879
V Predictions Mean           251.53381
V Predictions Std            27.833733
V Predictions Max            309.03003
V Predictions Min            91.52096
Log Pis Mean                 -2.294933
Log Pis Std                  2.140958
Log Pis Max                  5.796008
Log Pis Min                  -7.7982855
Policy mu Mean               0.07315215
Policy mu Std                0.47515523
Policy mu Max                1.8719985
Policy mu Min                -1.7857602
Policy log std Mean          -0.77948684
Policy log std Std           0.12778723
Policy log std Max           -0.23453316
Policy log std Min           -1.2556396
Z mean eval                  1.1930134
Z variance eval              0.023904419
total_rewards                [ 45.86202237  72.18432998  98.28852272  59.03729154  43.60269925
   0.50486024  76.54100898  30.42095658 109.95001052  32.26137118]
total_rewards_mean           56.86530733653363
total_rewards_std            31.525415303866687
total_rewards_max            109.95001051960334
total_rewards_min            0.5048602427953264
Number of train steps total  24000
Number of env steps total    21930
Number of rollouts total     0
Train Time (s)               139.7234011492692
(Previous) Eval Time (s)     18.080513229127973
Sample Time (s)              11.888500816654414
Epoch Time (s)               169.69241519505158
Total Train Time (s)         1087.9597620079294
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:14:00.298528 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #5 | Epoch Duration: 169.78568935394287
2020-01-12 02:14:00.298811 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1967143
Z variance train             0.02406312
KL Divergence                20.824501
KL Loss                      2.0824502
QF Loss                      174.54517
VF Loss                      51.8351
Policy Loss                  -262.74182
Q Predictions Mean           254.66632
Q Predictions Std            36.797855
Q Predictions Max            337.63483
Q Predictions Min            6.0210023
V Predictions Mean           261.12518
V Predictions Std            29.941679
V Predictions Max            331.5363
V Predictions Min            156.21469
Log Pis Mean                 -2.385511
Log Pis Std                  2.034444
Log Pis Max                  4.1186814
Log Pis Min                  -7.879507
Policy mu Mean               0.040288623
Policy mu Std                0.4650556
Policy mu Max                1.6404253
Policy mu Min                -1.6847428
Policy log std Mean          -0.76992494
Policy log std Std           0.13140169
Policy log std Max           -0.3685484
Policy log std Min           -1.4375504
Z mean eval                  1.2106545
Z variance eval              0.033559225
total_rewards                [189.44157556 -13.04177735  65.48229684  99.8429142   43.07504756
 130.83152411  74.85454433 -12.09748668  22.13074185  68.01931214]
total_rewards_mean           66.85386925676625
total_rewards_std            59.54715346072747
total_rewards_max            189.44157556419432
total_rewards_min            -13.041777347867098
Number of train steps total  28000
Number of env steps total    24810
Number of rollouts total     0
Train Time (s)               143.47519650263712
(Previous) Eval Time (s)     20.624541501980275
Sample Time (s)              11.501424953807145
Epoch Time (s)               175.60116295842454
Total Train Time (s)         1263.7011395408772
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:16:56.040433 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #6 | Epoch Duration: 175.7414288520813
2020-01-12 02:16:56.040641 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2109798
Z variance train             0.033454277
KL Divergence                19.556278
KL Loss                      1.9556278
QF Loss                      339.74396
VF Loss                      42.103012
Policy Loss                  -266.46643
Q Predictions Mean           259.89056
Q Predictions Std            43.714977
Q Predictions Max            358.9482
Q Predictions Min            -35.12441
V Predictions Mean           265.07794
V Predictions Std            35.791107
V Predictions Max            360.5921
V Predictions Min            104.01368
Log Pis Mean                 -2.10249
Log Pis Std                  2.2231493
Log Pis Max                  9.603794
Log Pis Min                  -11.786749
Policy mu Mean               -0.045119744
Policy mu Std                0.4672354
Policy mu Max                1.8865727
Policy mu Min                -1.9127703
Policy log std Mean          -0.77882326
Policy log std Std           0.1370102
Policy log std Max           -0.38219434
Policy log std Min           -1.4392236
Z mean eval                  1.202303
Z variance eval              0.043017887
total_rewards                [ 12.53530024  83.81564848 102.0384848   94.44207371  83.53771296
  52.75458098  38.16175431  15.39794268 120.23954684 113.64425999]
total_rewards_mean           71.65673050030651
total_rewards_std            37.40863800840924
total_rewards_max            120.23954684477692
total_rewards_min            12.535300244037598
Number of train steps total  32000
Number of env steps total    27386
Number of rollouts total     0
Train Time (s)               148.08252565283328
(Previous) Eval Time (s)     22.578466564882547
Sample Time (s)              11.88409938942641
Epoch Time (s)               182.54509160714224
Total Train Time (s)         1446.3417553049512
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:19:58.682281 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #7 | Epoch Duration: 182.64148235321045
2020-01-12 02:19:58.682487 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #7 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1904852
Z variance train             0.043340877
KL Divergence                18.82072
KL Loss                      1.8820721
QF Loss                      185.9778
VF Loss                      83.38835
Policy Loss                  -268.1443
Q Predictions Mean           261.56787
Q Predictions Std            48.679165
Q Predictions Max            349.79916
Q Predictions Min            -47.374332
V Predictions Mean           273.82928
V Predictions Std            39.01479
V Predictions Max            358.99786
V Predictions Min            114.07263
Log Pis Mean                 -2.1378436
Log Pis Std                  2.3774507
Log Pis Max                  12.852284
Log Pis Min                  -8.142151
Policy mu Mean               0.010908625
Policy mu Std                0.45623094
Policy mu Max                1.5814681
Policy mu Min                -1.918077
Policy log std Mean          -0.788309
Policy log std Std           0.1301334
Policy log std Max           -0.34202665
Policy log std Min           -1.3360637
Z mean eval                  1.1826317
Z variance eval              0.032373484
total_rewards                [174.68346117  13.81022273  35.14565656 282.62152498 112.2579168
  22.74153156  84.89907807  65.76126897  33.34109932 129.10987527]
total_rewards_mean           95.43716354334795
total_rewards_std            79.47644900013061
total_rewards_max            282.62152498341214
total_rewards_min            13.810222731764307
Number of train steps total  36000
Number of env steps total    30489
Number of rollouts total     0
Train Time (s)               147.86339179286733
(Previous) Eval Time (s)     16.56301433267072
Sample Time (s)              13.406490257475525
Epoch Time (s)               177.83289638301358
Total Train Time (s)         1624.266385812778
Epoch                        8
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:22:56.608691 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #8 | Epoch Duration: 177.92603063583374
2020-01-12 02:22:56.608957 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1831156
Z variance train             0.032782827
KL Divergence                19.726295
KL Loss                      1.9726295
QF Loss                      170.5463
VF Loss                      50.460587
Policy Loss                  -279.77487
Q Predictions Mean           269.84418
Q Predictions Std            51.123604
Q Predictions Max            383.9404
Q Predictions Min            -49.57015
V Predictions Mean           275.6012
V Predictions Std            41.425274
V Predictions Max            359.97632
V Predictions Min            93.99472
Log Pis Mean                 -2.0414886
Log Pis Std                  2.1673114
Log Pis Max                  6.227373
Log Pis Min                  -9.221298
Policy mu Mean               0.023522282
Policy mu Std                0.47694138
Policy mu Max                2.3797014
Policy mu Min                -1.7713151
Policy log std Mean          -0.78533894
Policy log std Std           0.12057825
Policy log std Max           -0.3977667
Policy log std Min           -1.3716631
Z mean eval                  1.2297322
Z variance eval              0.03827124
total_rewards                [ 99.76966784 157.41863125 121.77692956  35.9408373   79.34231696
 170.70299875 193.40897804 -46.76904863  21.59205282 182.70847524]
total_rewards_mean           101.5891839119103
total_rewards_std            75.18646884477378
total_rewards_max            193.4089780364869
total_rewards_min            -46.76904863423529
Number of train steps total  40000
Number of env steps total    34452
Number of rollouts total     0
Train Time (s)               148.7874742182903
(Previous) Eval Time (s)     25.374113861005753
Sample Time (s)              13.398263896349818
Epoch Time (s)               187.55985197564587
Total Train Time (s)         1811.9278211891651
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:26:04.271139 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #9 | Epoch Duration: 187.6620135307312
2020-01-12 02:26:04.271400 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2274735
Z variance train             0.038308285
KL Divergence                18.002083
KL Loss                      1.8002083
QF Loss                      126.11586
VF Loss                      28.29443
Policy Loss                  -288.66373
Q Predictions Mean           283.0558
Q Predictions Std            43.406525
Q Predictions Max            363.29944
Q Predictions Min            151.45932
V Predictions Mean           288.83984
V Predictions Std            40.980305
V Predictions Max            367.20013
V Predictions Min            185.00253
Log Pis Mean                 -2.2751222
Log Pis Std                  2.0265315
Log Pis Max                  9.057115
Log Pis Min                  -6.827588
Policy mu Mean               0.052466005
Policy mu Std                0.4324439
Policy mu Max                1.9591362
Policy mu Min                -1.8456533
Policy log std Mean          -0.7911769
Policy log std Std           0.121360414
Policy log std Max           -0.4418358
Policy log std Min           -1.4471177
Z mean eval                  1.2214562
Z variance eval              0.025867525
total_rewards                [348.81735834 203.01935006 140.81434318 113.55816152  95.60670708
 119.82186532  55.64308113  98.41051993  84.98843302 203.72783937]
total_rewards_mean           146.44076589523047
total_rewards_std            81.34637862318061
total_rewards_max            348.8173583372145
total_rewards_min            55.643081127025894
Number of train steps total  44000
Number of env steps total    37087
Number of rollouts total     0
Train Time (s)               148.9485857221298
(Previous) Eval Time (s)     29.100419081747532
Sample Time (s)              12.292741999961436
Epoch Time (s)               190.34174680383876
Total Train Time (s)         2002.3579883407801
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:29:14.702480 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #10 | Epoch Duration: 190.43092131614685
2020-01-12 02:29:14.702686 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #10 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2192675
Z variance train             0.025713857
KL Divergence                20.632374
KL Loss                      2.0632374
QF Loss                      149.43771
VF Loss                      55.76693
Policy Loss                  -288.57684
Q Predictions Mean           281.99014
Q Predictions Std            46.089664
Q Predictions Max            362.74335
Q Predictions Min            2.2964547
V Predictions Mean           291.4533
V Predictions Std            40.524372
V Predictions Max            370.45752
V Predictions Min            164.72441
Log Pis Mean                 -2.4438188
Log Pis Std                  2.099212
Log Pis Max                  6.022685
Log Pis Min                  -10.154972
Policy mu Mean               -0.016710188
Policy mu Std                0.44859642
Policy mu Max                1.4980482
Policy mu Min                -2.0078502
Policy log std Mean          -0.7745251
Policy log std Std           0.11876177
Policy log std Max           -0.27775234
Policy log std Min           -1.3061647
Z mean eval                  1.2236964
Z variance eval              0.058170937
total_rewards                [1.90974293e-01 7.18347402e+01 1.38768716e+02 9.96244795e+01
 1.91566389e+02 1.74852194e+02 4.47635446e+01 3.37166397e+01
 1.99138226e+02 3.01270009e+01]
total_rewards_mean           98.4582903582479
total_rewards_std            69.55353139334467
total_rewards_max            199.13822617738208
total_rewards_min            0.19097429275632694
Number of train steps total  48000
Number of env steps total    40838
Number of rollouts total     0
Train Time (s)               139.78361962363124
(Previous) Eval Time (s)     13.366811597719789
Sample Time (s)              12.692046544980258
Epoch Time (s)               165.84247776633129
Total Train Time (s)         2168.2869748091325
Epoch                        11
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:32:00.635577 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #11 | Epoch Duration: 165.93265867233276
2020-01-12 02:32:00.635909 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #11 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2240851
Z variance train             0.05720359
KL Divergence                18.3719
KL Loss                      1.83719
QF Loss                      195.5611
VF Loss                      46.754936
Policy Loss                  -307.42294
Q Predictions Mean           300.0487
Q Predictions Std            44.07146
Q Predictions Max            404.26382
Q Predictions Min            155.57442
V Predictions Mean           310.79285
V Predictions Std            39.51498
V Predictions Max            417.6064
V Predictions Min            199.60724
Log Pis Mean                 -2.2067251
Log Pis Std                  1.9792665
Log Pis Max                  10.257411
Log Pis Min                  -7.328621
Policy mu Mean               0.0103253005
Policy mu Std                0.4170177
Policy mu Max                1.6089126
Policy mu Min                -2.4236948
Policy log std Mean          -0.79141736
Policy log std Std           0.10235588
Policy log std Max           -0.47264588
Policy log std Min           -1.4746072
Z mean eval                  1.2620189
Z variance eval              0.047366537
total_rewards                [ -6.48397032 146.3312163  127.70477719  73.1033857  254.9754479
 282.83055629 255.69433913  18.48408757  11.28834583 347.96666723]
total_rewards_mean           151.1894852820649
total_rewards_std            121.02064479604506
total_rewards_max            347.9666672318244
total_rewards_min            -6.483970318780404
Number of train steps total  52000
Number of env steps total    44561
Number of rollouts total     0
Train Time (s)               140.26895567728207
(Previous) Eval Time (s)     17.30699310125783
Sample Time (s)              12.374353378079832
Epoch Time (s)               169.95030215661973
Total Train Time (s)         2338.3323191390373
Epoch                        12
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:34:50.679895 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #12 | Epoch Duration: 170.04374957084656
2020-01-12 02:34:50.680143 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2640232
Z variance train             0.04749287
KL Divergence                17.926754
KL Loss                      1.7926754
QF Loss                      142.35239
VF Loss                      54.431145
Policy Loss                  -311.0602
Q Predictions Mean           304.83682
Q Predictions Std            44.15947
Q Predictions Max            400.09412
Q Predictions Min            186.08719
V Predictions Mean           307.21906
V Predictions Std            42.836246
V Predictions Max            399.6843
V Predictions Min            188.79398
Log Pis Mean                 -2.4538088
Log Pis Std                  1.8693794
Log Pis Max                  3.6067736
Log Pis Min                  -8.396633
Policy mu Mean               0.031835176
Policy mu Std                0.4097006
Policy mu Max                1.4979184
Policy mu Min                -1.6177193
Policy log std Mean          -0.807139
Policy log std Std           0.10598414
Policy log std Max           -0.41943175
Policy log std Min           -1.3117325
Z mean eval                  1.2469945
Z variance eval              0.04247927
total_rewards                [ 84.11101734 191.28805254 153.49834452 226.74520973  95.85979475
 250.75919209 166.6386214  124.76757141 269.80564278 246.93944822]
total_rewards_mean           181.04128947797503
total_rewards_std            63.29317094075637
total_rewards_max            269.805642782332
total_rewards_min            84.11101733970159
Number of train steps total  56000
Number of env steps total    47137
Number of rollouts total     0
Train Time (s)               145.97927669575438
(Previous) Eval Time (s)     26.936512622982264
Sample Time (s)              11.46517939073965
Epoch Time (s)               184.3809687094763
Total Train Time (s)         2522.802729835268
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:37:55.151393 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #13 | Epoch Duration: 184.4710726737976
2020-01-12 02:37:55.151599 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2486366
Z variance train             0.04192553
KL Divergence                18.255875
KL Loss                      1.8255875
QF Loss                      155.13763
VF Loss                      73.169754
Policy Loss                  -305.47336
Q Predictions Mean           299.0765
Q Predictions Std            54.66857
Q Predictions Max            405.58984
Q Predictions Min            -60.620445
V Predictions Mean           309.98828
V Predictions Std            46.062653
V Predictions Max            413.61603
V Predictions Min            204.74008
Log Pis Mean                 -2.44344
Log Pis Std                  1.8572764
Log Pis Max                  4.751592
Log Pis Min                  -9.2038965
Policy mu Mean               0.021306409
Policy mu Std                0.42294756
Policy mu Max                1.9531257
Policy mu Min                -1.7261555
Policy log std Mean          -0.7945157
Policy log std Std           0.10424785
Policy log std Max           -0.34312725
Policy log std Min           -1.3588175
Z mean eval                  1.2704548
Z variance eval              0.036360122
total_rewards                [ 76.20858793 186.45120059  26.54064404  91.40161829 281.03484728
 262.75476956 158.8299596  111.13604239  55.36473865 402.3438192 ]
total_rewards_mean           165.20662275396893
total_rewards_std            112.8019557032434
total_rewards_max            402.3438192046944
total_rewards_min            26.54064404406762
Number of train steps total  60000
Number of env steps total    49664
Number of rollouts total     0
Train Time (s)               151.39915075525641
(Previous) Eval Time (s)     17.027381965890527
Sample Time (s)              10.141902423929423
Epoch Time (s)               178.56843514507636
Total Train Time (s)         2701.459562496282
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:40:53.809713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #14 | Epoch Duration: 178.65795135498047
2020-01-12 02:40:53.809920 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2757199
Z variance train             0.03641496
KL Divergence                18.764221
KL Loss                      1.8764222
QF Loss                      188.61285
VF Loss                      34.35664
Policy Loss                  -323.09882
Q Predictions Mean           315.23187
Q Predictions Std            54.34933
Q Predictions Max            414.38748
Q Predictions Min            -92.97176
V Predictions Mean           321.25763
V Predictions Std            46.173664
V Predictions Max            423.6205
V Predictions Min            86.017006
Log Pis Mean                 -2.2558029
Log Pis Std                  2.1778464
Log Pis Max                  13.8381195
Log Pis Min                  -8.532529
Policy mu Mean               0.009249026
Policy mu Std                0.43944675
Policy mu Max                2.2206273
Policy mu Min                -1.8399125
Policy log std Mean          -0.7981715
Policy log std Std           0.10566142
Policy log std Max           -0.47572726
Policy log std Min           -1.447911
Z mean eval                  1.303474
Z variance eval              0.034887612
total_rewards                [195.05687977 137.93887795 277.9471638  164.94660751 168.90507111
 295.76610441 254.32917343 466.8927822  592.13462483  91.34091444]
total_rewards_mean           264.5258199453228
total_rewards_std            148.13592476989174
total_rewards_max            592.1346248266684
total_rewards_min            91.34091444345785
Number of train steps total  64000
Number of env steps total    52700
Number of rollouts total     0
Train Time (s)               148.25464148120955
(Previous) Eval Time (s)     34.777983378153294
Sample Time (s)              13.211725275963545
Epoch Time (s)               196.24435013532639
Total Train Time (s)         2897.7883442379534
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:44:10.139365 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #15 | Epoch Duration: 196.32929754257202
2020-01-12 02:44:10.139552 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3063362
Z variance train             0.03484661
KL Divergence                19.208904
KL Loss                      1.9208905
QF Loss                      184.11522
VF Loss                      36.78253
Policy Loss                  -331.59973
Q Predictions Mean           322.12103
Q Predictions Std            51.049385
Q Predictions Max            426.9307
Q Predictions Min            58.86532
V Predictions Mean           330.80005
V Predictions Std            44.85094
V Predictions Max            439.66458
V Predictions Min            199.1062
Log Pis Mean                 -2.5377214
Log Pis Std                  1.9466329
Log Pis Max                  5.3180423
Log Pis Min                  -9.330341
Policy mu Mean               0.040640373
Policy mu Std                0.41549695
Policy mu Max                1.6091115
Policy mu Min                -2.0949423
Policy log std Mean          -0.7846751
Policy log std Std           0.10022927
Policy log std Max           -0.3209231
Policy log std Min           -1.3073584
Z mean eval                  1.3294942
Z variance eval              0.04074596
total_rewards                [184.64822765 265.35430516 181.25977289 145.97689856 320.75916349
 187.23252271   7.80901971 183.11779006 311.74237195  87.65409654]
total_rewards_mean           187.55541687134138
total_rewards_std            91.27102656453631
total_rewards_max            320.75916349164885
total_rewards_min            7.809019711971092
Number of train steps total  68000
Number of env steps total    56192
Number of rollouts total     0
Train Time (s)               151.30775674106553
(Previous) Eval Time (s)     28.45471150521189
Sample Time (s)              11.793275048956275
Epoch Time (s)               191.5557432952337
Total Train Time (s)         3089.4362739026546
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:47:21.788922 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #16 | Epoch Duration: 191.6492099761963
2020-01-12 02:47:21.789166 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #16 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3237432
Z variance train             0.040714182
KL Divergence                19.772324
KL Loss                      1.9772323
QF Loss                      158.1973
VF Loss                      41.14605
Policy Loss                  -328.8086
Q Predictions Mean           321.50266
Q Predictions Std            54.517982
Q Predictions Max            410.27863
Q Predictions Min            -18.132355
V Predictions Mean           330.66406
V Predictions Std            48.23886
V Predictions Max            413.96408
V Predictions Min            74.59718
Log Pis Mean                 -2.4556446
Log Pis Std                  2.5660677
Log Pis Max                  21.902065
Log Pis Min                  -8.379854
Policy mu Mean               0.03059306
Policy mu Std                0.42073667
Policy mu Max                3.0792487
Policy mu Min                -3.396662
Policy log std Mean          -0.80039823
Policy log std Std           0.102675095
Policy log std Max           -0.5026946
Policy log std Min           -1.266088
Z mean eval                  1.4828961
Z variance eval              0.3755185
total_rewards                [304.8658626  338.18743483 291.10481077   7.84608071 525.8450893
 487.40894002  20.09316662 210.51739328 312.16863542 282.40192813]
total_rewards_mean           278.04393416826736
total_rewards_std            159.69820310094735
total_rewards_max            525.8450893030268
total_rewards_min            7.8460807123094725
Number of train steps total  72000
Number of env steps total    59855
Number of rollouts total     0
Train Time (s)               148.4855574159883
(Previous) Eval Time (s)     27.416539925150573
Sample Time (s)              12.058784551918507
Epoch Time (s)               187.96088189305738
Total Train Time (s)         3277.482942267321
Epoch                        17
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:50:29.838692 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #17 | Epoch Duration: 188.04933834075928
2020-01-12 02:50:29.838973 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4858599
Z variance train             0.3751647
KL Divergence                16.323696
KL Loss                      1.6323696
QF Loss                      182.93225
VF Loss                      57.646034
Policy Loss                  -341.3095
Q Predictions Mean           331.05008
Q Predictions Std            66.03375
Q Predictions Max            448.1032
Q Predictions Min            -78.02628
V Predictions Mean           341.86923
V Predictions Std            52.389297
V Predictions Max            440.20917
V Predictions Min            167.1121
Log Pis Mean                 -2.5073783
Log Pis Std                  2.1113281
Log Pis Max                  9.134172
Log Pis Min                  -9.419468
Policy mu Mean               0.034670852
Policy mu Std                0.39561084
Policy mu Max                2.516118
Policy mu Min                -2.496137
Policy log std Mean          -0.798236
Policy log std Std           0.0920228
Policy log std Max           -0.45037144
Policy log std Min           -1.3393693
Z mean eval                  1.4210136
Z variance eval              0.057326168
total_rewards                [535.15331672 314.84739974 270.34055575 461.27773744 124.54470295
  64.90408064 138.01823042  68.14646406 497.10660008 302.83745984]
total_rewards_mean           277.7176547658345
total_rewards_std            168.03290187375546
total_rewards_max            535.153316722492
total_rewards_min            64.9040806403029
Number of train steps total  76000
Number of env steps total    63369
Number of rollouts total     0
Train Time (s)               136.91146493609995
(Previous) Eval Time (s)     22.498874149285257
Sample Time (s)              11.911144590936601
Epoch Time (s)               171.3214836763218
Total Train Time (s)         3448.8943955912255
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:53:21.252294 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #18 | Epoch Duration: 171.41300415992737
2020-01-12 02:53:21.252707 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4244914
Z variance train             0.057714313
KL Divergence                20.22934
KL Loss                      2.022934
QF Loss                      125.477615
VF Loss                      35.897766
Policy Loss                  -349.8206
Q Predictions Mean           339.9798
Q Predictions Std            56.913456
Q Predictions Max            472.38773
Q Predictions Min            216.2889
V Predictions Mean           347.63483
V Predictions Std            54.466732
V Predictions Max            472.4532
V Predictions Min            233.71465
Log Pis Mean                 -2.3473458
Log Pis Std                  1.8495461
Log Pis Max                  3.47024
Log Pis Min                  -9.865513
Policy mu Mean               0.006614738
Policy mu Std                0.38176084
Policy mu Max                1.5022734
Policy mu Min                -1.6681468
Policy log std Mean          -0.8112436
Policy log std Std           0.09603042
Policy log std Max           -0.5191695
Policy log std Min           -1.2920827
Z mean eval                  1.4022312
Z variance eval              0.0421261
total_rewards                [811.09796853 458.9515687  767.7370265  884.52342273  87.93569222
  92.34273914 294.04093172 332.27573331 406.66255356 368.65949918]
total_rewards_mean           450.4227135596132
total_rewards_std            269.4296631771421
total_rewards_max            884.5234227301944
total_rewards_min            87.93569222427982
Number of train steps total  80000
Number of env steps total    67114
Number of rollouts total     0
Train Time (s)               137.96470968518406
(Previous) Eval Time (s)     26.9362335591577
Sample Time (s)              12.359632932115346
Epoch Time (s)               177.2605761764571
Total Train Time (s)         3626.2477945126593
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:56:18.605507 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #19 | Epoch Duration: 177.35253596305847
2020-01-12 02:56:18.605711 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4003032
Z variance train             0.041811295
KL Divergence                21.030094
KL Loss                      2.1030095
QF Loss                      180.47649
VF Loss                      41.305855
Policy Loss                  -347.62097
Q Predictions Mean           337.4585
Q Predictions Std            68.267105
Q Predictions Max            482.63702
Q Predictions Min            -47.182274
V Predictions Mean           348.58292
V Predictions Std            55.599094
V Predictions Max            497.3725
V Predictions Min            59.703423
Log Pis Mean                 -2.37856
Log Pis Std                  2.3020163
Log Pis Max                  12.412126
Log Pis Min                  -9.090819
Policy mu Mean               0.019498628
Policy mu Std                0.4176955
Policy mu Max                2.1429677
Policy mu Min                -2.216785
Policy log std Mean          -0.8047863
Policy log std Std           0.09982979
Policy log std Max           -0.48774385
Policy log std Min           -1.5518197
Z mean eval                  1.3987427
Z variance eval              0.049248952
total_rewards                [ 11.06835484  94.0599027  155.37264937 323.89939119 239.82868274
  87.10290009 497.20806323 276.87390371 442.84356349 119.0453643 ]
total_rewards_mean           224.73027756652013
total_rewards_std            152.3962671670747
total_rewards_max            497.208063232042
total_rewards_min            11.068354843661416
Number of train steps total  84000
Number of env steps total    69621
Number of rollouts total     0
Train Time (s)               142.5562929310836
(Previous) Eval Time (s)     18.772278748918325
Sample Time (s)              10.502183090429753
Epoch Time (s)               171.83075477043167
Total Train Time (s)         3798.168584979605
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:59:10.528804 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #20 | Epoch Duration: 171.92283940315247
2020-01-12 02:59:10.529157 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3995701
Z variance train             0.048856314
KL Divergence                20.03452
KL Loss                      2.003452
QF Loss                      244.84671
VF Loss                      27.02066
Policy Loss                  -362.95642
Q Predictions Mean           353.2582
Q Predictions Std            75.41545
Q Predictions Max            491.32452
Q Predictions Min            -92.74903
V Predictions Mean           362.8625
V Predictions Std            59.268497
V Predictions Max            477.35696
V Predictions Min            68.13546
Log Pis Mean                 -2.321042
Log Pis Std                  2.3980908
Log Pis Max                  12.666454
Log Pis Min                  -8.6352005
Policy mu Mean               0.031222949
Policy mu Std                0.42650926
Policy mu Max                2.7344012
Policy mu Min                -2.5338068
Policy log std Mean          -0.8112147
Policy log std Std           0.10402053
Policy log std Max           -0.48549283
Policy log std Min           -1.5373068
Z mean eval                  1.3130854
Z variance eval              0.07937112
total_rewards                [171.20400881 154.53784001 351.8654592  362.16522525  86.41582651
 184.2886704  490.75217553 245.98119051 519.36662709 470.7795888 ]
total_rewards_mean           303.7356612106461
total_rewards_std            148.24363629547526
total_rewards_max            519.366627090738
total_rewards_min            86.41582650764498
Number of train steps total  88000
Number of env steps total    72257
Number of rollouts total     0
Train Time (s)               147.27454910008237
(Previous) Eval Time (s)     21.675254868343472
Sample Time (s)              12.135653132107109
Epoch Time (s)               181.08545710053295
Total Train Time (s)         3979.346457324922
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:02:11.707330 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #21 | Epoch Duration: 181.1779580116272
2020-01-12 03:02:11.707586 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3182023
Z variance train             0.0792858
KL Divergence                16.366688
KL Loss                      1.6366688
QF Loss                      154.13914
VF Loss                      42.72235
Policy Loss                  -376.57123
Q Predictions Mean           366.88132
Q Predictions Std            60.175167
Q Predictions Max            494.76544
Q Predictions Min            210.85594
V Predictions Mean           376.66635
V Predictions Std            56.375095
V Predictions Max            494.16318
V Predictions Min            234.20027
Log Pis Mean                 -2.3602989
Log Pis Std                  1.9613153
Log Pis Max                  4.029257
Log Pis Min                  -9.674251
Policy mu Mean               0.030863091
Policy mu Std                0.39871535
Policy mu Max                1.6214503
Policy mu Min                -2.167438
Policy log std Mean          -0.8204947
Policy log std Std           0.093330525
Policy log std Max           -0.4475934
Policy log std Min           -1.2983797
Z mean eval                  1.3477523
Z variance eval              0.06495686
total_rewards                [333.5829457   -2.48063959 354.49329771  94.16219532 295.08248459
 485.45692756 461.04481152 208.96084629  64.27924902 168.29644263]
total_rewards_mean           246.28785607387
total_rewards_std            158.3234793326504
total_rewards_max            485.4569275601168
total_rewards_min            -2.480639588324076
Number of train steps total  92000
Number of env steps total    76083
Number of rollouts total     0
Train Time (s)               146.52307974081486
(Previous) Eval Time (s)     17.257477768231183
Sample Time (s)              12.267700236290693
Epoch Time (s)               176.04825774533674
Total Train Time (s)         4155.479520534165
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:05:07.841474 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #22 | Epoch Duration: 176.13373017311096
2020-01-12 03:05:07.841649 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3438189
Z variance train             0.06467514
KL Divergence                19.075075
KL Loss                      1.9075075
QF Loss                      154.93454
VF Loss                      52.139046
Policy Loss                  -368.02237
Q Predictions Mean           361.42148
Q Predictions Std            59.569458
Q Predictions Max            481.8993
Q Predictions Min            203.5424
V Predictions Mean           370.26855
V Predictions Std            57.381023
V Predictions Max            496.56067
V Predictions Min            245.5625
Log Pis Mean                 -2.3555503
Log Pis Std                  2.018947
Log Pis Max                  5.7502327
Log Pis Min                  -9.9517565
Policy mu Mean               -0.005768822
Policy mu Std                0.40182257
Policy mu Max                1.7918863
Policy mu Min                -1.9746653
Policy log std Mean          -0.8226555
Policy log std Std           0.09060623
Policy log std Max           -0.49038047
Policy log std Min           -1.2909606
Z mean eval                  2.4416935
Z variance eval              0.15058038
total_rewards                [290.35770343 297.95989987  49.21040347 231.60117555 274.73895028
 294.47166665  57.45377998 461.87422465 287.21605981 963.43386158]
total_rewards_mean           320.8317725264958
total_rewards_std            242.7632310950705
total_rewards_max            963.4338615821122
total_rewards_min            49.21040346681495
Number of train steps total  96000
Number of env steps total    78912
Number of rollouts total     0
Train Time (s)               147.4154945272021
(Previous) Eval Time (s)     27.749587316066027
Sample Time (s)              12.348867329303175
Epoch Time (s)               187.5139491725713
Total Train Time (s)         4343.110650794581
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:08:15.474024 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #23 | Epoch Duration: 187.63221955299377
2020-01-12 03:08:15.474222 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4417686
Z variance train             0.15157226
KL Divergence                27.499987
KL Loss                      2.7499988
QF Loss                      227.53139
VF Loss                      50.570732
Policy Loss                  -365.34372
Q Predictions Mean           355.3521
Q Predictions Std            83.52966
Q Predictions Max            478.18652
Q Predictions Min            -29.2401
V Predictions Mean           365.7395
V Predictions Std            68.36756
V Predictions Max            485.02655
V Predictions Min            -22.208204
Log Pis Mean                 -2.2682145
Log Pis Std                  2.4198747
Log Pis Max                  13.000246
Log Pis Min                  -8.456212
Policy mu Mean               0.020821333
Policy mu Std                0.42755505
Policy mu Max                2.0605674
Policy mu Min                -2.543626
Policy log std Mean          -0.8214097
Policy log std Std           0.09645924
Policy log std Max           -0.40116188
Policy log std Min           -1.3974726
Z mean eval                  1.854546
Z variance eval              0.07860614
total_rewards                [815.24697519  79.97065291 309.55615363 141.57383328 654.49212313
  12.54923024 430.17649747  11.76948952 802.90156926 334.82241989]
total_rewards_mean           359.305894451262
total_rewards_std            294.3380005344088
total_rewards_max            815.2469751908708
total_rewards_min            11.769489518625662
Number of train steps total  100000
Number of env steps total    82460
Number of rollouts total     0
Train Time (s)               146.662843960803
(Previous) Eval Time (s)     23.13341499119997
Sample Time (s)              10.492659726180136
Epoch Time (s)               180.2889186781831
Total Train Time (s)         4523.491182946134
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:11:15.855803 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #24 | Epoch Duration: 180.38142657279968
2020-01-12 03:11:15.856006 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8627037
Z variance train             0.07746436
KL Divergence                25.92554
KL Loss                      2.592554
QF Loss                      221.19415
VF Loss                      41.43488
Policy Loss                  -368.38867
Q Predictions Mean           359.17923
Q Predictions Std            63.737587
Q Predictions Max            480.06235
Q Predictions Min            22.692797
V Predictions Mean           369.78192
V Predictions Std            58.696167
V Predictions Max            480.6085
V Predictions Min            147.9251
Log Pis Mean                 -2.1573215
Log Pis Std                  2.4183059
Log Pis Max                  15.322132
Log Pis Min                  -8.215649
Policy mu Mean               -0.022378454
Policy mu Std                0.42429537
Policy mu Max                2.2049677
Policy mu Min                -2.7483659
Policy log std Mean          -0.8401432
Policy log std Std           0.09414792
Policy log std Max           -0.53383636
Policy log std Min           -1.273047
Z mean eval                  1.631383
Z variance eval              0.111878
total_rewards                [486.81425075  17.89421816 401.53992424 295.74227505 278.88080094
 364.55104412 341.9814913  200.53985843 374.75955168 670.23918802]
total_rewards_mean           343.2942602687023
total_rewards_std            162.78865479370816
total_rewards_max            670.2391880178311
total_rewards_min            17.894218162010358
Number of train steps total  104000
Number of env steps total    86176
Number of rollouts total     0
Train Time (s)               137.4365718793124
(Previous) Eval Time (s)     27.168549482244998
Sample Time (s)              12.18144562235102
Epoch Time (s)               176.78656698390841
Total Train Time (s)         4700.36376320431
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:14:12.730294 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #25 | Epoch Duration: 176.87410736083984
2020-01-12 03:14:12.730571 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6347357
Z variance train             0.11245316
KL Divergence                23.996008
KL Loss                      2.3996007
QF Loss                      271.51102
VF Loss                      99.042114
Policy Loss                  -373.2381
Q Predictions Mean           364.20837
Q Predictions Std            83.50437
Q Predictions Max            494.3102
Q Predictions Min            -81.99213
V Predictions Mean           373.0412
V Predictions Std            68.51606
V Predictions Max            491.56018
V Predictions Min            1.5513592
Log Pis Mean                 -1.8529725
Log Pis Std                  2.8296227
Log Pis Max                  18.762947
Log Pis Min                  -6.9047403
Policy mu Mean               -0.025435336
Policy mu Std                0.46465966
Policy mu Max                2.6323216
Policy mu Min                -2.924293
Policy log std Mean          -0.82553506
Policy log std Std           0.107514046
Policy log std Max           -0.48349053
Policy log std Min           -1.4485087
Z mean eval                  1.4134004
Z variance eval              0.13116701
total_rewards                [1055.14520692  234.48677266   57.42980762  976.86709406  450.53464548
  329.08865297 1103.09022335  357.42399778  911.48347099  773.69487888]
total_rewards_mean           624.9244750718883
total_rewards_std            361.36181423798627
total_rewards_max            1103.0902233523398
total_rewards_min            57.42980762183191
Number of train steps total  108000
Number of env steps total    90906
Number of rollouts total     0
Train Time (s)               137.4804749172181
(Previous) Eval Time (s)     26.611884457990527
Sample Time (s)              12.899966748431325
Epoch Time (s)               176.99232612363994
Total Train Time (s)         4877.443429686595
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:17:09.811065 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #26 | Epoch Duration: 177.08031463623047
2020-01-12 03:17:09.811288 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #26 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4111258
Z variance train             0.13101816
KL Divergence                23.045288
KL Loss                      2.304529
QF Loss                      222.0751
VF Loss                      37.27869
Policy Loss                  -361.40402
Q Predictions Mean           351.7398
Q Predictions Std            76.761734
Q Predictions Max            489.82117
Q Predictions Min            13.6778755
V Predictions Mean           362.74197
V Predictions Std            66.16595
V Predictions Max            494.4371
V Predictions Min            213.09512
Log Pis Mean                 -2.158417
Log Pis Std                  2.187752
Log Pis Max                  7.5586033
Log Pis Min                  -8.207475
Policy mu Mean               -0.008376284
Policy mu Std                0.42011878
Policy mu Max                1.750129
Policy mu Min                -1.7666602
Policy log std Mean          -0.8281004
Policy log std Std           0.10285406
Policy log std Max           -0.48455453
Policy log std Min           -1.2793605
Z mean eval                  1.2446897
Z variance eval              0.843377
total_rewards                [260.51082116 948.64149902 158.89347471 710.08922118 769.7173429
 634.04669463 271.08089179 313.33148039 477.55338576 388.41555595]
total_rewards_mean           493.22803674828094
total_rewards_std            246.8981173241929
total_rewards_max            948.6414990244448
total_rewards_min            158.89347470943147
Number of train steps total  112000
Number of env steps total    93406
Number of rollouts total     0
Train Time (s)               142.4879337460734
(Previous) Eval Time (s)     25.278495298698545
Sample Time (s)              11.450237339828163
Epoch Time (s)               179.2166663846001
Total Train Time (s)         5056.745911771432
Epoch                        27
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:20:09.114655 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #27 | Epoch Duration: 179.3032157421112
2020-01-12 03:20:09.114841 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2416253
Z variance train             0.84292746
KL Divergence                18.197878
KL Loss                      1.8197879
QF Loss                      243.58125
VF Loss                      87.10949
Policy Loss                  -373.35828
Q Predictions Mean           366.0035
Q Predictions Std            74.79334
Q Predictions Max            517.86804
Q Predictions Min            -25.730188
V Predictions Mean           367.75125
V Predictions Std            66.94416
V Predictions Max            512.1696
V Predictions Min            211.16031
Log Pis Mean                 -2.597168
Log Pis Std                  1.9798702
Log Pis Max                  7.0057774
Log Pis Min                  -9.202297
Policy mu Mean               0.02604071
Policy mu Std                0.378956
Policy mu Max                1.8595932
Policy mu Min                -2.2845535
Policy log std Mean          -0.79413617
Policy log std Std           0.10050629
Policy log std Max           -0.43599516
Policy log std Min           -1.1500654
Z mean eval                  1.4356389
Z variance eval              0.07287562
total_rewards                [369.89490597 632.28718247 132.46653401 579.97710664 822.73918926
 413.05585358 837.27028043 469.51711728 125.59874485 794.06519386]
total_rewards_mean           517.6872108365417
total_rewards_std            250.1653455716603
total_rewards_max            837.2702804260814
total_rewards_min            125.5987448538993
Number of train steps total  116000
Number of env steps total    98686
Number of rollouts total     0
Train Time (s)               147.89368030428886
(Previous) Eval Time (s)     25.755507335998118
Sample Time (s)              11.059172335080802
Epoch Time (s)               184.70835997536778
Total Train Time (s)         5241.553789314348
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:23:13.924302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #28 | Epoch Duration: 184.8093032836914
2020-01-12 03:23:13.924541 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4319819
Z variance train             0.07385673
KL Divergence                23.7532
KL Loss                      2.3753202
QF Loss                      262.5862
VF Loss                      101.181145
Policy Loss                  -356.39288
Q Predictions Mean           344.1233
Q Predictions Std            82.16987
Q Predictions Max            489.15222
Q Predictions Min            -94.52217
V Predictions Mean           349.9946
V Predictions Std            72.18406
V Predictions Max            486.97125
V Predictions Min            46.012783
Log Pis Mean                 -2.011149
Log Pis Std                  2.874235
Log Pis Max                  25.531586
Log Pis Min                  -7.738886
Policy mu Mean               0.0017506649
Policy mu Std                0.4307712
Policy mu Max                3.9783254
Policy mu Min                -4.1726265
Policy log std Mean          -0.8331101
Policy log std Std           0.10811155
Policy log std Max           -0.37104166
Policy log std Min           -1.5073147
Z mean eval                  1.2933996
Z variance eval              0.08145963
total_rewards                [265.00636092 186.81269914 470.63668123  12.71739145 525.10890636
 144.47095413 864.8448121  136.00301165 405.08107948 300.45934276]
total_rewards_mean           331.1141239230446
total_rewards_std            234.06269010045636
total_rewards_max            864.8448121020633
total_rewards_min            12.717391454527954
Number of train steps total  120000
Number of env steps total    101647
Number of rollouts total     0
Train Time (s)               147.27348717628047
(Previous) Eval Time (s)     19.248615962918848
Sample Time (s)              12.308090801350772
Epoch Time (s)               178.8301939405501
Total Train Time (s)         5420.774091814645
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:26:13.145749 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #29 | Epoch Duration: 179.2210512161255
2020-01-12 03:26:13.145941 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2910507
Z variance train             0.081003785
KL Divergence                23.149887
KL Loss                      2.3149889
QF Loss                      180.01497
VF Loss                      55.51188
Policy Loss                  -377.4206
Q Predictions Mean           371.13132
Q Predictions Std            78.24858
Q Predictions Max            498.89792
Q Predictions Min            -37.35169
V Predictions Mean           378.22748
V Predictions Std            71.76893
V Predictions Max            512.6933
V Predictions Min            150.10062
Log Pis Mean                 -2.2848296
Log Pis Std                  2.1342714
Log Pis Max                  13.095684
Log Pis Min                  -9.858968
Policy mu Mean               -0.0022894219
Policy mu Std                0.41405228
Policy mu Max                2.482556
Policy mu Min                -2.425794
Policy log std Mean          -0.82575434
Policy log std Std           0.10072149
Policy log std Max           -0.39987442
Policy log std Min           -1.4960033
Z mean eval                  1.2519033
Z variance eval              0.08317338
total_rewards                [ 452.86353882  342.61711785 1088.40619335  389.80423212  698.14111444
  708.77957602  557.82831784   51.12180601  536.18790685  528.79014868]
total_rewards_mean           535.4539951978094
total_rewards_std            257.4119874203093
total_rewards_max            1088.406193345198
total_rewards_min            51.121806014710806
Number of train steps total  124000
Number of env steps total    105513
Number of rollouts total     0
Train Time (s)               147.96308364486322
(Previous) Eval Time (s)     30.807130305096507
Sample Time (s)              12.324702647514641
Epoch Time (s)               191.09491659747437
Total Train Time (s)         5611.955492649227
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:29:24.328515 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #30 | Epoch Duration: 191.1824288368225
2020-01-12 03:29:24.328698 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2545388
Z variance train             0.08338394
KL Divergence                22.710417
KL Loss                      2.2710416
QF Loss                      211.57205
VF Loss                      55.683693
Policy Loss                  -382.42926
Q Predictions Mean           373.2529
Q Predictions Std            84.78854
Q Predictions Max            569.25836
Q Predictions Min            211.3968
V Predictions Mean           382.77863
V Predictions Std            79.22591
V Predictions Max            539.30493
V Predictions Min            222.81812
Log Pis Mean                 -2.2149904
Log Pis Std                  2.4665349
Log Pis Max                  11.475931
Log Pis Min                  -10.5176525
Policy mu Mean               0.025362875
Policy mu Std                0.42864892
Policy mu Max                3.7684503
Policy mu Min                -2.3512673
Policy log std Mean          -0.83543
Policy log std Std           0.110755764
Policy log std Max           -0.4269026
Policy log std Min           -1.3611552
Z mean eval                  1.242022
Z variance eval              0.0828768
total_rewards                [ 708.3128325   487.54916521  533.95019586 1011.9766648   529.58503019
  266.79091234  304.97818739   65.13845575  833.60262766  158.48472433]
total_rewards_mean           490.0368796021095
total_rewards_std            285.68383962445614
total_rewards_max            1011.9766647982142
total_rewards_min            65.13845575255617
Number of train steps total  128000
Number of env steps total    109411
Number of rollouts total     0
Train Time (s)               145.8466008347459
(Previous) Eval Time (s)     27.222115635871887
Sample Time (s)              12.22536780172959
Epoch Time (s)               185.2940842723474
Total Train Time (s)         5797.336746307556
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:32:29.711394 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #31 | Epoch Duration: 185.3825500011444
2020-01-12 03:32:29.711617 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #31 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2341808
Z variance train             0.08410156
KL Divergence                22.97426
KL Loss                      2.297426
QF Loss                      275.87735
VF Loss                      116.41944
Policy Loss                  -396.74643
Q Predictions Mean           387.83228
Q Predictions Std            89.76276
Q Predictions Max            533.05585
Q Predictions Min            -86.537056
V Predictions Mean           404.61652
V Predictions Std            79.99831
V Predictions Max            532.46906
V Predictions Min            259.06445
Log Pis Mean                 -2.0763698
Log Pis Std                  1.9937294
Log Pis Max                  4.277859
Log Pis Min                  -7.441659
Policy mu Mean               0.0039936923
Policy mu Std                0.4235562
Policy mu Max                1.9051383
Policy mu Min                -2.2474594
Policy log std Mean          -0.83588076
Policy log std Std           0.10023836
Policy log std Max           -0.48033068
Policy log std Min           -1.3251216
Z mean eval                  1.2276967
Z variance eval              0.10615094
total_rewards                [ 508.70626681  364.99788192 1359.82036935  765.49659988  329.0419821
  201.56134202  350.24318011  583.04689665  270.03993602  362.20057422]
total_rewards_mean           509.5155029078467
total_rewards_std            323.5215474251397
total_rewards_max            1359.8203693469316
total_rewards_min            201.56134202330077
Number of train steps total  132000
Number of env steps total    112184
Number of rollouts total     0
Train Time (s)               136.79603163478896
(Previous) Eval Time (s)     23.420009560883045
Sample Time (s)              12.081146222073585
Epoch Time (s)               172.2971874177456
Total Train Time (s)         5969.943884020206
Epoch                        32
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:35:22.319872 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #32 | Epoch Duration: 172.6080904006958
2020-01-12 03:35:22.320073 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.230427
Z variance train             0.10612655
KL Divergence                23.337112
KL Loss                      2.3337114
QF Loss                      276.4198
VF Loss                      77.22198
Policy Loss                  -407.6648
Q Predictions Mean           397.43744
Q Predictions Std            97.11773
Q Predictions Max            574.55005
Q Predictions Min            -8.465256
V Predictions Mean           405.0525
V Predictions Std            86.8653
V Predictions Max            570.71936
V Predictions Min            102.65841
Log Pis Mean                 -1.9315767
Log Pis Std                  2.5245788
Log Pis Max                  18.22468
Log Pis Min                  -7.476952
Policy mu Mean               0.009225704
Policy mu Std                0.42453137
Policy mu Max                2.7991061
Policy mu Min                -2.468052
Policy log std Mean          -0.8478766
Policy log std Std           0.10882125
Policy log std Max           -0.5075305
Policy log std Min           -1.5888816
Z mean eval                  1.2441
Z variance eval              0.053728797
total_rewards                [ 624.17371937  172.5501404  1017.54075111  586.65185391  376.60128229
  621.58311431  262.80474418  547.6392329   125.08469621  719.96787651]
total_rewards_mean           505.459741117542
total_rewards_std            259.84409615563834
total_rewards_max            1017.5407511070458
total_rewards_min            125.08469620568872
Number of train steps total  136000
Number of env steps total    115856
Number of rollouts total     0
Train Time (s)               137.32994719827548
(Previous) Eval Time (s)     21.980516669806093
Sample Time (s)              11.942347057629377
Epoch Time (s)               171.25281092571095
Total Train Time (s)         6141.30370481126
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:38:13.681329 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #33 | Epoch Duration: 171.36110758781433
2020-01-12 03:38:13.681531 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2449663
Z variance train             0.05329875
KL Divergence                24.208057
KL Loss                      2.4208057
QF Loss                      270.3619
VF Loss                      61.19486
Policy Loss                  -408.55664
Q Predictions Mean           401.28772
Q Predictions Std            89.90232
Q Predictions Max            565.9746
Q Predictions Min            -11.340281
V Predictions Mean           410.2051
V Predictions Std            85.799835
V Predictions Max            560.44763
V Predictions Min            176.60512
Log Pis Mean                 -2.047928
Log Pis Std                  2.3617904
Log Pis Max                  10.518747
Log Pis Min                  -10.681833
Policy mu Mean               0.0092147235
Policy mu Std                0.42541832
Policy mu Max                2.0804396
Policy mu Min                -2.9901614
Policy log std Mean          -0.8565544
Policy log std Std           0.107845984
Policy log std Max           -0.4942652
Policy log std Min           -1.3467865
Z mean eval                  1.1818198
Z variance eval              0.13552985
total_rewards                [  75.32466119 1223.47014053   42.08579436  317.95901744  294.18376781
  935.94318184  360.23096797  214.43817892  365.39202722  625.58738997]
total_rewards_mean           445.46151272390705
total_rewards_std            358.3597738021824
total_rewards_max            1223.470140525189
total_rewards_min            42.08579435840661
Number of train steps total  140000
Number of env steps total    119023
Number of rollouts total     0
Train Time (s)               143.03574838489294
(Previous) Eval Time (s)     22.836166366003454
Sample Time (s)              12.850327883381397
Epoch Time (s)               178.7222426342778
Total Train Time (s)         6320.114073945675
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:41:12.492901 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #34 | Epoch Duration: 178.8112096786499
2020-01-12 03:41:12.493091 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1842782
Z variance train             0.1343342
KL Divergence                20.330378
KL Loss                      2.033038
QF Loss                      420.12634
VF Loss                      61.288177
Policy Loss                  -409.45508
Q Predictions Mean           399.63257
Q Predictions Std            101.3196
Q Predictions Max            570.0996
Q Predictions Min            -46.845562
V Predictions Mean           413.01788
V Predictions Std            91.026695
V Predictions Max            569.32684
V Predictions Min            227.56801
Log Pis Mean                 -1.9538134
Log Pis Std                  2.4600708
Log Pis Max                  20.238546
Log Pis Min                  -7.2855425
Policy mu Mean               0.0368219
Policy mu Std                0.43413827
Policy mu Max                3.172846
Policy mu Min                -2.2948778
Policy log std Mean          -0.8508703
Policy log std Std           0.11160407
Policy log std Max           -0.40657908
Policy log std Min           -1.5404634
Z mean eval                  1.2123549
Z variance eval              0.061017044
total_rewards                [513.29199407 626.42256385 393.34009072 138.70316846 778.51507143
 390.43030643 178.39440944 396.98929192  85.41604877 214.25579386]
total_rewards_mean           371.5758738947628
total_rewards_std            212.20052907794866
total_rewards_max            778.5150714327397
total_rewards_min            85.4160487665855
Number of train steps total  144000
Number of env steps total    122938
Number of rollouts total     0
Train Time (s)               147.84591631684452
(Previous) Eval Time (s)     21.380710987839848
Sample Time (s)              14.05007255030796
Epoch Time (s)               183.27669985499233
Total Train Time (s)         6503.484969448298
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:44:15.865461 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #35 | Epoch Duration: 183.37221503257751
2020-01-12 03:44:15.865678 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2147377
Z variance train             0.06126503
KL Divergence                23.290117
KL Loss                      2.3290117
QF Loss                      521.4937
VF Loss                      83.57216
Policy Loss                  -421.04462
Q Predictions Mean           408.01224
Q Predictions Std            104.32154
Q Predictions Max            579.135
Q Predictions Min            -83.173836
V Predictions Mean           418.4619
V Predictions Std            89.25148
V Predictions Max            572.07623
V Predictions Min            214.61356
Log Pis Mean                 -1.7931573
Log Pis Std                  2.4557843
Log Pis Max                  15.08411
Log Pis Min                  -8.243905
Policy mu Mean               0.000494868
Policy mu Std                0.46321195
Policy mu Max                3.8279853
Policy mu Min                -2.6406288
Policy log std Mean          -0.85929155
Policy log std Std           0.117584504
Policy log std Max           -0.47884172
Policy log std Min           -1.3929155
Z mean eval                  1.228146
Z variance eval              0.04279983
total_rewards                [122.05634401 224.17780294 599.47982307 341.28747907 666.43497747
 918.18730457 342.92889139 228.65758316 429.14037735 312.3248004 ]
total_rewards_mean           418.4675383420322
total_rewards_std            229.92435677469857
total_rewards_max            918.1873045689211
total_rewards_min            122.05634400741054
Number of train steps total  148000
Number of env steps total    126435
Number of rollouts total     0
Train Time (s)               146.6581414011307
(Previous) Eval Time (s)     17.738923993892968
Sample Time (s)              12.259325466584414
Epoch Time (s)               176.6563908616081
Total Train Time (s)         6680.234447576106
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:47:12.616373 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #36 | Epoch Duration: 176.75053787231445
2020-01-12 03:47:12.616569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2315543
Z variance train             0.0430632
KL Divergence                24.375122
KL Loss                      2.4375122
QF Loss                      321.71722
VF Loss                      68.45612
Policy Loss                  -430.15826
Q Predictions Mean           418.753
Q Predictions Std            105.57263
Q Predictions Max            593.2129
Q Predictions Min            -67.09137
V Predictions Mean           429.13324
V Predictions Std            93.57491
V Predictions Max            594.50726
V Predictions Min            186.58704
Log Pis Mean                 -2.0770297
Log Pis Std                  2.7015824
Log Pis Max                  22.269547
Log Pis Min                  -9.573923
Policy mu Mean               0.0055271806
Policy mu Std                0.4414161
Policy mu Max                2.6798885
Policy mu Min                -3.1223574
Policy log std Mean          -0.850611
Policy log std Std           0.11143233
Policy log std Max           -0.5009024
Policy log std Min           -1.403096
Z mean eval                  1.233886
Z variance eval              0.12835881
total_rewards                [ 360.7302594   250.34622301  285.05382499  165.718102    151.95427651
 1247.37262142  513.28232208 1093.50024116  373.80705301 1455.10855726]
total_rewards_mean           589.6873480833501
total_rewards_std            460.38122721096073
total_rewards_max            1455.1085572555774
total_rewards_min            151.95427650611234
Number of train steps total  152000
Number of env steps total    130173
Number of rollouts total     0
Train Time (s)               146.7173011326231
(Previous) Eval Time (s)     25.38676411798224
Sample Time (s)              11.638207549694926
Epoch Time (s)               183.74227280030027
Total Train Time (s)         6864.0651716827415
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:50:16.448595 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #37 | Epoch Duration: 183.831866979599
2020-01-12 03:50:16.448788 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #37 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2272556
Z variance train             0.12717529
KL Divergence                20.938173
KL Loss                      2.0938175
QF Loss                      244.22638
VF Loss                      48.026535
Policy Loss                  -431.74835
Q Predictions Mean           425.63828
Q Predictions Std            105.99351
Q Predictions Max            640.18835
Q Predictions Min            231.97914
V Predictions Mean           434.02728
V Predictions Std            101.63648
V Predictions Max            637.68646
V Predictions Min            246.29454
Log Pis Mean                 -1.9944232
Log Pis Std                  2.1890583
Log Pis Max                  12.57444
Log Pis Min                  -8.346413
Policy mu Mean               -0.012878883
Policy mu Std                0.42546162
Policy mu Max                2.3290744
Policy mu Min                -2.6749845
Policy log std Mean          -0.84352297
Policy log std Std           0.110565275
Policy log std Max           -0.52294827
Policy log std Min           -1.3537383
Z mean eval                  1.2508271
Z variance eval              0.09177275
total_rewards                [1145.18461743  539.62591339  736.25660764  975.66309308  665.2788844
  273.53915531 1140.18746248   14.46303549  296.35987728  797.59360272]
total_rewards_mean           658.4152249216535
total_rewards_std            360.994617449557
total_rewards_max            1145.1846174321302
total_rewards_min            14.463035491410558
Number of train steps total  156000
Number of env steps total    134268
Number of rollouts total     0
Train Time (s)               146.8674243800342
(Previous) Eval Time (s)     24.402628127951175
Sample Time (s)              10.397451331838965
Epoch Time (s)               181.66750383982435
Total Train Time (s)         7045.829056310467
Epoch                        38
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:53:18.214000 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #38 | Epoch Duration: 181.76507258415222
2020-01-12 03:53:18.214165 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2558541
Z variance train             0.091140315
KL Divergence                23.612827
KL Loss                      2.3612828
QF Loss                      306.87054
VF Loss                      54.175533
Policy Loss                  -444.54263
Q Predictions Mean           436.15686
Q Predictions Std            108.98154
Q Predictions Max            636.9404
Q Predictions Min            112.336754
V Predictions Mean           443.9854
V Predictions Std            103.48403
V Predictions Max            634.2162
V Predictions Min            138.12984
Log Pis Mean                 -1.9307938
Log Pis Std                  2.4214344
Log Pis Max                  18.13476
Log Pis Min                  -7.450885
Policy mu Mean               -0.0091282595
Policy mu Std                0.42433587
Policy mu Max                2.6531627
Policy mu Min                -2.3297603
Policy log std Mean          -0.87138903
Policy log std Std           0.1183744
Policy log std Max           -0.45914227
Policy log std Min           -1.5713661
Z mean eval                  1.2558223
Z variance eval              0.097483665
total_rewards                [ 234.94737431 1043.85540969  632.6431424   189.44936664  303.21336462
   68.19844464  357.90857225   38.50567933  822.39806689  497.46456449]
total_rewards_mean           418.8583985264336
total_rewards_std            312.4931026655759
total_rewards_max            1043.855409688479
total_rewards_min            38.505679329613876
Number of train steps total  160000
Number of env steps total    137563
Number of rollouts total     0
Train Time (s)               137.32688621385023
(Previous) Eval Time (s)     14.191549732815474
Sample Time (s)              12.147085970733315
Epoch Time (s)               163.66552191739902
Total Train Time (s)         7209.593499202281
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:56:01.980569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #39 | Epoch Duration: 163.76626467704773
2020-01-12 03:56:01.980763 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2552546
Z variance train             0.09884886
KL Divergence                22.844162
KL Loss                      2.2844162
QF Loss                      264.75113
VF Loss                      76.0322
Policy Loss                  -439.3036
Q Predictions Mean           428.557
Q Predictions Std            115.30579
Q Predictions Max            615.79926
Q Predictions Min            -4.692653
V Predictions Mean           438.7974
V Predictions Std            108.37769
V Predictions Max            614.27155
V Predictions Min            199.75798
Log Pis Mean                 -1.8335543
Log Pis Std                  1.9904225
Log Pis Max                  9.368203
Log Pis Min                  -7.9603934
Policy mu Mean               0.01008664
Policy mu Std                0.45058462
Policy mu Max                2.0818737
Policy mu Min                -2.9053943
Policy log std Mean          -0.86003494
Policy log std Std           0.118784055
Policy log std Max           -0.49968925
Policy log std Min           -1.4115033
Z mean eval                  1.2010624
Z variance eval              0.07718854
total_rewards                [409.46641573 216.70371505 148.09577627 536.98851863 694.88251751
 415.53137863 703.7409511  324.92655401 373.08934181 428.73494425]
total_rewards_mean           425.2160112978765
total_rewards_std            172.1021940836672
total_rewards_max            703.7409510986606
total_rewards_min            148.09577627108547
Number of train steps total  164000
Number of env steps total    141131
Number of rollouts total     0
Train Time (s)               137.83365571312606
(Previous) Eval Time (s)     23.188826739788055
Sample Time (s)              12.223345687612891
Epoch Time (s)               173.245828140527
Total Train Time (s)         7382.929752966389
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:58:55.318066 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #40 | Epoch Duration: 173.3371570110321
2020-01-12 03:58:55.318260 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2096307
Z variance train             0.07750615
KL Divergence                23.520124
KL Loss                      2.3520124
QF Loss                      231.21742
VF Loss                      64.72943
Policy Loss                  -438.77185
Q Predictions Mean           427.57285
Q Predictions Std            123.40449
Q Predictions Max            630.0761
Q Predictions Min            10.467874
V Predictions Mean           434.60733
V Predictions Std            116.39537
V Predictions Max            632.0898
V Predictions Min            191.78413
Log Pis Mean                 -1.7046142
Log Pis Std                  2.4891121
Log Pis Max                  14.351462
Log Pis Min                  -7.1538286
Policy mu Mean               0.025925085
Policy mu Std                0.46497294
Policy mu Max                2.251936
Policy mu Min                -2.7912295
Policy log std Mean          -0.8609885
Policy log std Std           0.11609984
Policy log std Max           -0.4487365
Policy log std Min           -1.4890814
Z mean eval                  1.3402524
Z variance eval              0.13702269
total_rewards                [ 729.6977294   299.34517064  591.29670498  285.5207319   414.48341919
   17.77115692  107.14508338   91.51844536 1049.13793347  397.98112102]
total_rewards_mean           398.3897496264375
total_rewards_std            302.8404947738087
total_rewards_max            1049.1379334705027
total_rewards_min            17.77115691514923
Number of train steps total  168000
Number of env steps total    144506
Number of rollouts total     0
Train Time (s)               142.89744039298967
(Previous) Eval Time (s)     22.419586569070816
Sample Time (s)              12.091365320142359
Epoch Time (s)               177.40839228220284
Total Train Time (s)         7560.4251651261
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:01:52.815619 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #41 | Epoch Duration: 177.4971899986267
2020-01-12 04:01:52.815882 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3382146
Z variance train             0.13661066
KL Divergence                20.855986
KL Loss                      2.0855987
QF Loss                      350.4218
VF Loss                      51.59214
Policy Loss                  -457.36383
Q Predictions Mean           452.08514
Q Predictions Std            117.22523
Q Predictions Max            647.61884
Q Predictions Min            219.98795
V Predictions Mean           457.81848
V Predictions Std            114.262276
V Predictions Max            657.44183
V Predictions Min            227.3154
Log Pis Mean                 -1.6583703
Log Pis Std                  2.43065
Log Pis Max                  14.569891
Log Pis Min                  -7.271239
Policy mu Mean               0.022845954
Policy mu Std                0.43481103
Policy mu Max                2.734498
Policy mu Min                -2.6899548
Policy log std Mean          -0.8855032
Policy log std Std           0.115013815
Policy log std Max           -0.48819238
Policy log std Min           -1.3204658
Z mean eval                  1.232033
Z variance eval              0.15184201
total_rewards                [1013.37030635  461.05282262  204.13401004  934.09791627  727.77414842
  289.07376288  222.30930187  165.9932526   188.69088481  268.3865404 ]
total_rewards_mean           447.48829462626253
total_rewards_std            308.0698911258676
total_rewards_max            1013.3703063540528
total_rewards_min            165.99325260376315
Number of train steps total  172000
Number of env steps total    147418
Number of rollouts total     0
Train Time (s)               148.31132341176271
(Previous) Eval Time (s)     20.015792863909155
Sample Time (s)              12.907880731392652
Epoch Time (s)               181.23499700706452
Total Train Time (s)         7741.745443343651
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:04:54.137162 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #42 | Epoch Duration: 181.32110118865967
2020-01-12 04:04:54.137401 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2311018
Z variance train             0.15120687
KL Divergence                22.23259
KL Loss                      2.223259
QF Loss                      283.9657
VF Loss                      159.62627
Policy Loss                  -434.2844
Q Predictions Mean           426.38837
Q Predictions Std            134.11417
Q Predictions Max            655.92163
Q Predictions Min            -32.493225
V Predictions Mean           431.7701
V Predictions Std            126.16781
V Predictions Max            669.30615
V Predictions Min            118.76023
Log Pis Mean                 -2.0866716
Log Pis Std                  2.3347404
Log Pis Max                  16.00346
Log Pis Min                  -8.267352
Policy mu Mean               0.018477885
Policy mu Std                0.43901306
Policy mu Max                3.0994518
Policy mu Min                -2.6796224
Policy log std Mean          -0.8506526
Policy log std Std           0.12245891
Policy log std Max           -0.28845316
Policy log std Min           -1.4456552
Z mean eval                  1.2475224
Z variance eval              0.29348296
total_rewards                [702.5872511   79.70175631  66.72054403 119.52362727 465.32699486
 281.37688994 230.21605923 250.37130448 356.87138251 154.69945147]
total_rewards_mean           270.73952612125714
total_rewards_std            186.65377791842988
total_rewards_max            702.5872510989228
total_rewards_min            66.72054402817619
Number of train steps total  176000
Number of env steps total    151276
Number of rollouts total     0
Train Time (s)               147.4065041579306
(Previous) Eval Time (s)     14.00532168103382
Sample Time (s)              13.190061547793448
Epoch Time (s)               174.60188738675788
Total Train Time (s)         7916.450868962333
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:07:48.843577 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #43 | Epoch Duration: 174.70599341392517
2020-01-12 04:07:48.843762 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2388017
Z variance train             0.29658067
KL Divergence                22.317724
KL Loss                      2.2317724
QF Loss                      264.9743
VF Loss                      71.62639
Policy Loss                  -459.5808
Q Predictions Mean           454.78677
Q Predictions Std            129.61928
Q Predictions Max            644.7849
Q Predictions Min            -6.782153
V Predictions Mean           461.75458
V Predictions Std            122.07543
V Predictions Max            647.9986
V Predictions Min            218.75317
Log Pis Mean                 -2.1155078
Log Pis Std                  2.1698341
Log Pis Max                  9.156916
Log Pis Min                  -8.786783
Policy mu Mean               0.016518723
Policy mu Std                0.4127955
Policy mu Max                2.0263462
Policy mu Min                -2.0197198
Policy log std Mean          -0.8532768
Policy log std Std           0.126691
Policy log std Max           -0.5237187
Policy log std Min           -1.5045621
Z mean eval                  1.2958134
Z variance eval              0.12128502
total_rewards                [ 401.00815477 1116.88046629  529.35176586 1142.94769475  176.40954848
  247.79343084  363.03418495  268.16104561   78.10293489  477.48648164]
total_rewards_mean           480.1175708088181
total_rewards_std            349.27967457523704
total_rewards_max            1142.947694754525
total_rewards_min            78.10293489173213
Number of train steps total  180000
Number of env steps total    154034
Number of rollouts total     0
Train Time (s)               147.3820583350025
(Previous) Eval Time (s)     17.44131771568209
Sample Time (s)              12.51278875861317
Epoch Time (s)               177.33616480929777
Total Train Time (s)         8093.876634099521
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:10:46.271908 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #44 | Epoch Duration: 177.42796802520752
2020-01-12 04:10:46.272250 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2971385
Z variance train             0.122125685
KL Divergence                23.63276
KL Loss                      2.363276
QF Loss                      305.13013
VF Loss                      54.03945
Policy Loss                  -462.37457
Q Predictions Mean           455.2082
Q Predictions Std            145.77364
Q Predictions Max            697.63007
Q Predictions Min            -46.186893
V Predictions Mean           458.68256
V Predictions Std            139.16866
V Predictions Max            674.5557
V Predictions Min            228.67285
Log Pis Mean                 -1.7141333
Log Pis Std                  2.4080477
Log Pis Max                  15.518396
Log Pis Min                  -7.7807193
Policy mu Mean               0.04056447
Policy mu Std                0.4304948
Policy mu Max                4.055021
Policy mu Min                -2.744232
Policy log std Mean          -0.84043694
Policy log std Std           0.122782715
Policy log std Max           -0.39485577
Policy log std Min           -1.3600953
Z mean eval                  1.2300246
Z variance eval              0.19252568
total_rewards                [1251.08293132  310.85224902  419.32240114 1797.1339858   397.11977824
  629.48338898 1260.54188476  113.87110197  804.02452561 1263.23669458]
total_rewards_mean           824.666894143221
total_rewards_std            516.2085730137626
total_rewards_max            1797.133985802424
total_rewards_min            113.87110197305242
Number of train steps total  184000
Number of env steps total    157561
Number of rollouts total     0
Train Time (s)               145.82688875636086
(Previous) Eval Time (s)     32.62500093784183
Sample Time (s)              11.750085738487542
Epoch Time (s)               190.20197543269023
Total Train Time (s)         8284.184513654094
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:13:56.581977 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #45 | Epoch Duration: 190.3095099925995
2020-01-12 04:13:56.582255 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.229794
Z variance train             0.19171211
KL Divergence                24.049564
KL Loss                      2.4049566
QF Loss                      278.84558
VF Loss                      58.430077
Policy Loss                  -481.22662
Q Predictions Mean           473.41287
Q Predictions Std            142.03723
Q Predictions Max            723.60016
Q Predictions Min            -38.4843
V Predictions Mean           478.20514
V Predictions Std            136.43758
V Predictions Max            708.5791
V Predictions Min            58.084415
Log Pis Mean                 -1.8423477
Log Pis Std                  2.4969366
Log Pis Max                  15.606122
Log Pis Min                  -7.3119707
Policy mu Mean               0.018475913
Policy mu Std                0.46185747
Policy mu Max                2.6057794
Policy mu Min                -2.4600103
Policy log std Mean          -0.8628892
Policy log std Std           0.12901554
Policy log std Max           -0.45499712
Policy log std Min           -1.6124119
Z mean eval                  1.2116776
Z variance eval              0.091130204
total_rewards                [ 310.93712274  575.5522962    53.43679434  606.03986828  909.47288213
 1067.8251348  1240.63543151   78.9473534   603.694917    305.53647191]
total_rewards_mean           575.2078272296767
total_rewards_std            382.1049851363626
total_rewards_max            1240.635431509341
total_rewards_min            53.43679433637311
Number of train steps total  188000
Number of env steps total    161294
Number of rollouts total     0
Train Time (s)               138.37399923009798
(Previous) Eval Time (s)     18.809058513026685
Sample Time (s)              11.674628556706011
Epoch Time (s)               168.85768629983068
Total Train Time (s)         8453.138722718693
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:16:45.536990 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #46 | Epoch Duration: 168.9545760154724
2020-01-12 04:16:45.537227 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2140434
Z variance train             0.091273874
KL Divergence                22.490002
KL Loss                      2.2490003
QF Loss                      340.58575
VF Loss                      48.247658
Policy Loss                  -474.67047
Q Predictions Mean           463.88223
Q Predictions Std            142.09018
Q Predictions Max            678.55676
Q Predictions Min            33.055126
V Predictions Mean           472.23456
V Predictions Std            134.61752
V Predictions Max            669.40784
V Predictions Min            237.51688
Log Pis Mean                 -1.818277
Log Pis Std                  2.543006
Log Pis Max                  10.459493
Log Pis Min                  -9.114943
Policy mu Mean               -0.001679632
Policy mu Std                0.45993006
Policy mu Max                2.0685272
Policy mu Min                -3.0337954
Policy log std Mean          -0.86504585
Policy log std Std           0.13255401
Policy log std Max           -0.55782294
Policy log std Min           -1.5190516
Z mean eval                  1.2742655
Z variance eval              0.20035645
total_rewards                [ 428.37574324 1441.78180792  232.46260572  430.06916383 1015.61771371
  646.15846661  675.47796482   56.96186656  733.14524181    7.68084737]
total_rewards_mean           566.7731421595519
total_rewards_std            416.53296887968975
total_rewards_max            1441.781807923952
total_rewards_min            7.680847373185587
Number of train steps total  192000
Number of env steps total    163989
Number of rollouts total     0
Train Time (s)               138.63976535294205
(Previous) Eval Time (s)     17.991697994992137
Sample Time (s)              11.227001695893705
Epoch Time (s)               167.8584650438279
Total Train Time (s)         8621.085541756358
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:19:33.485206 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #47 | Epoch Duration: 167.94779658317566
2020-01-12 04:19:33.485416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2743227
Z variance train             0.20154019
KL Divergence                22.014723
KL Loss                      2.2014723
QF Loss                      330.39032
VF Loss                      44.543934
Policy Loss                  -471.46167
Q Predictions Mean           462.47537
Q Predictions Std            142.96706
Q Predictions Max            692.60443
Q Predictions Min            90.69713
V Predictions Mean           472.12506
V Predictions Std            139.80084
V Predictions Max            689.95526
V Predictions Min            225.15964
Log Pis Mean                 -1.9231427
Log Pis Std                  2.2264323
Log Pis Max                  4.9446726
Log Pis Min                  -8.339248
Policy mu Mean               -0.015020458
Policy mu Std                0.44308874
Policy mu Max                2.286957
Policy mu Min                -2.2427294
Policy log std Mean          -0.8730795
Policy log std Std           0.13793842
Policy log std Max           -0.4350726
Policy log std Min           -1.4057231
Z mean eval                  1.2547609
Z variance eval              0.13760224
total_rewards                [ 528.0768843   154.58536503  446.25136308  501.58441465  311.08595021
 1554.15238235  486.5749311   947.5874942  1463.48803901  349.89738854]
total_rewards_mean           674.328421246267
total_rewards_std            460.1486259258905
total_rewards_max            1554.1523823460943
total_rewards_min            154.58536503248857
Number of train steps total  196000
Number of env steps total    168387
Number of rollouts total     0
Train Time (s)               141.6619714642875
(Previous) Eval Time (s)     27.804616685025394
Sample Time (s)              11.049760788679123
Epoch Time (s)               180.516348937992
Total Train Time (s)         8801.697772740386
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:22:34.098883 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #48 | Epoch Duration: 180.61331605911255
2020-01-12 04:22:34.099075 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2545882
Z variance train             0.138432
KL Divergence                21.909979
KL Loss                      2.1909978
QF Loss                      309.99872
VF Loss                      128.57907
Policy Loss                  -463.52344
Q Predictions Mean           456.16623
Q Predictions Std            149.78801
Q Predictions Max            707.53436
Q Predictions Min            -0.8948022
V Predictions Mean           467.30746
V Predictions Std            146.20108
V Predictions Max            710.2632
V Predictions Min            16.060158
Log Pis Mean                 -1.3315375
Log Pis Std                  2.5228262
Log Pis Max                  9.728036
Log Pis Min                  -7.449027
Policy mu Mean               0.035897117
Policy mu Std                0.47714403
Policy mu Max                2.5802903
Policy mu Min                -3.5061255
Policy log std Mean          -0.8946482
Policy log std Std           0.13984227
Policy log std Max           -0.4850659
Policy log std Min           -1.497888
Z mean eval                  1.223211
Z variance eval              0.05669571
total_rewards                [480.91388808 243.39205785 445.86562301 945.86830794 349.26202708
 601.93809299 263.36979736 470.4459431  378.80863147 379.30922047]
total_rewards_mean           455.9173589361079
total_rewards_std            191.76611286617376
total_rewards_max            945.8683079381191
total_rewards_min            243.3920578455674
Number of train steps total  200000
Number of env steps total    170965
Number of rollouts total     0
Train Time (s)               148.5697961281985
(Previous) Eval Time (s)     21.649560380727053
Sample Time (s)              11.517228670418262
Epoch Time (s)               181.73658517934382
Total Train Time (s)         8983.845231623389
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:25:36.249267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #49 | Epoch Duration: 182.15002036094666
2020-01-12 04:25:36.249539 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2303915
Z variance train             0.056813687
KL Divergence                24.026123
KL Loss                      2.4026124
QF Loss                      328.20685
VF Loss                      67.48815
Policy Loss                  -488.6024
Q Predictions Mean           478.21863
Q Predictions Std            159.32626
Q Predictions Max            726.8261
Q Predictions Min            -52.15594
V Predictions Mean           485.82892
V Predictions Std            150.33162
V Predictions Max            718.3913
V Predictions Min            113.8488
Log Pis Mean                 -1.737493
Log Pis Std                  2.3090365
Log Pis Max                  9.796396
Log Pis Min                  -6.6498294
Policy mu Mean               -0.012972526
Policy mu Std                0.4743517
Policy mu Max                2.7988706
Policy mu Min                -3.371007
Policy log std Mean          -0.8691325
Policy log std Std           0.1306145
Policy log std Max           -0.3377648
Policy log std Min           -1.4609315
Z mean eval                  1.2432511
Z variance eval              0.15519641
total_rewards                [ 142.43047864  711.6291995   251.72931267  248.3225644   235.98544463
  475.39008835   86.23433856  563.06974739  531.81312807 1651.10237643]
total_rewards_mean           489.77066786368886
total_rewards_std            432.2168736937881
total_rewards_max            1651.1023764267738
total_rewards_min            86.23433856394767
Number of train steps total  204000
Number of env steps total    173636
Number of rollouts total     0
Train Time (s)               147.9484878797084
(Previous) Eval Time (s)     12.455973474308848
Sample Time (s)              13.488744386471808
Epoch Time (s)               173.89320574048907
Total Train Time (s)         9157.828106146306
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:28:30.234508 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #50 | Epoch Duration: 173.98477125167847
2020-01-12 04:28:30.234862 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2424184
Z variance train             0.15295917
KL Divergence                22.636452
KL Loss                      2.2636452
QF Loss                      387.3344
VF Loss                      77.49318
Policy Loss                  -493.03293
Q Predictions Mean           483.89673
Q Predictions Std            153.82729
Q Predictions Max            720.9813
Q Predictions Min            -20.320597
V Predictions Mean           489.57376
V Predictions Std            147.1962
V Predictions Max            718.98303
V Predictions Min            -3.0128677
Log Pis Mean                 -1.8890765
Log Pis Std                  2.2086964
Log Pis Max                  7.5068145
Log Pis Min                  -9.622714
Policy mu Mean               0.00011536735
Policy mu Std                0.41915384
Policy mu Max                2.1956403
Policy mu Min                -2.24649
Policy log std Mean          -0.873003
Policy log std Std           0.13717416
Policy log std Max           -0.5144026
Policy log std Min           -1.4836934
Z mean eval                  1.2714319
Z variance eval              0.24052458
total_rewards                [ 269.46465395 1091.85892173 1020.89837155  832.56749906  967.39036278
  555.25425539  867.22827745  826.9118526   755.25140904  365.79118545]
total_rewards_mean           755.2616788995331
total_rewards_std            260.80540170381687
total_rewards_max            1091.8589217267215
total_rewards_min            269.4646539546545
Number of train steps total  208000
Number of env steps total    177384
Number of rollouts total     0
Train Time (s)               146.90489235008135
(Previous) Eval Time (s)     23.491262735798955
Sample Time (s)              12.334968205075711
Epoch Time (s)               182.73112329095602
Total Train Time (s)         9340.77634849213
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:31:33.184211 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #51 | Epoch Duration: 182.94906163215637
2020-01-12 04:31:33.184511 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2699062
Z variance train             0.24111101
KL Divergence                19.474792
KL Loss                      1.9474792
QF Loss                      464.5599
VF Loss                      58.093437
Policy Loss                  -467.3666
Q Predictions Mean           457.12454
Q Predictions Std            153.06287
Q Predictions Max            692.3394
Q Predictions Min            105.2889
V Predictions Mean           466.6054
V Predictions Std            146.8479
V Predictions Max            685.6372
V Predictions Min            212.0709
Log Pis Mean                 -2.0165334
Log Pis Std                  2.4768364
Log Pis Max                  17.97253
Log Pis Min                  -7.1637335
Policy mu Mean               0.041555036
Policy mu Std                0.42129752
Policy mu Max                2.2686343
Policy mu Min                -2.7140503
Policy log std Mean          -0.86463296
Policy log std Std           0.13129269
Policy log std Max           -0.28924844
Policy log std Min           -1.447636
Z mean eval                  1.2640986
Z variance eval              0.12067584
total_rewards                [1114.82563092  248.72053293  403.13228621  618.21307387  118.72041749
  271.45717721  347.19246473  348.74512818 1571.00786746  784.52353714]
total_rewards_mean           582.6538116157077
total_rewards_std            432.2081330094472
total_rewards_max            1571.0078674640267
total_rewards_min            118.7204174929351
Number of train steps total  212000
Number of env steps total    179951
Number of rollouts total     0
Train Time (s)               145.89766291715205
(Previous) Eval Time (s)     21.606778481043875
Sample Time (s)              11.691472841892391
Epoch Time (s)               179.1959142400883
Total Train Time (s)         9520.069196533412
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:34:32.477550 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #52 | Epoch Duration: 179.29282212257385
2020-01-12 04:34:32.477768 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2659352
Z variance train             0.12111982
KL Divergence                22.91446
KL Loss                      2.291446
QF Loss                      170.42616
VF Loss                      62.998478
Policy Loss                  -483.6882
Q Predictions Mean           475.37354
Q Predictions Std            160.85565
Q Predictions Max            712.1578
Q Predictions Min            -32.730885
V Predictions Mean           483.9826
V Predictions Std            154.05106
V Predictions Max            718.11945
V Predictions Min            208.48433
Log Pis Mean                 -1.9247084
Log Pis Std                  2.6145701
Log Pis Max                  17.789053
Log Pis Min                  -9.971968
Policy mu Mean               -0.024191018
Policy mu Std                0.43838796
Policy mu Max                2.21016
Policy mu Min                -3.1018384
Policy log std Mean          -0.8655976
Policy log std Std           0.13400176
Policy log std Max           -0.4377275
Policy log std Min           -1.3965855
Z mean eval                  1.282463
Z variance eval              0.087110616
total_rewards                [ 335.1472156   300.22691973  464.21803523  324.71471868  168.55018862
  231.82934199  907.7783864   575.09470737  802.78157795 1099.30921401]
total_rewards_mean           520.9650305594106
total_rewards_std            299.8734404082666
total_rewards_max            1099.3092140059514
total_rewards_min            168.55018862443296
Number of train steps total  216000
Number of env steps total    183564
Number of rollouts total     0
Train Time (s)               140.25718973390758
(Previous) Eval Time (s)     21.005938163027167
Sample Time (s)              12.044518634211272
Epoch Time (s)               173.30764653114602
Total Train Time (s)         9693.46469461592
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:37:25.874718 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #53 | Epoch Duration: 173.39681029319763
2020-01-12 04:37:25.874935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2821558
Z variance train             0.08670609
KL Divergence                23.394505
KL Loss                      2.3394506
QF Loss                      269.5158
VF Loss                      105.38522
Policy Loss                  -506.779
Q Predictions Mean           500.5236
Q Predictions Std            167.60153
Q Predictions Max            753.50415
Q Predictions Min            183.3591
V Predictions Mean           511.82245
V Predictions Std            164.39003
V Predictions Max            758.8951
V Predictions Min            205.47139
Log Pis Mean                 -1.888561
Log Pis Std                  2.716828
Log Pis Max                  15.24073
Log Pis Min                  -8.205389
Policy mu Mean               0.059434555
Policy mu Std                0.4385613
Policy mu Max                2.7587218
Policy mu Min                -2.8717222
Policy log std Mean          -0.86171675
Policy log std Std           0.13930853
Policy log std Max           -0.43853444
Policy log std Min           -1.801749
Z mean eval                  1.2716575
Z variance eval              0.17023952
total_rewards                [ 552.44466918  602.6490666   560.8047685   249.5888453   601.16632022
  990.1621036   624.41675939  535.25688096 1203.12814368    5.47566056]
total_rewards_mean           592.5093217995543
total_rewards_std            316.2704685590072
total_rewards_max            1203.128143675559
total_rewards_min            5.475660560062215
Number of train steps total  220000
Number of env steps total    187087
Number of rollouts total     0
Train Time (s)               138.84996404964477
(Previous) Eval Time (s)     22.889463612809777
Sample Time (s)              11.669867840595543
Epoch Time (s)               173.4092955030501
Total Train Time (s)         9867.010012998711
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:40:19.422280 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #54 | Epoch Duration: 173.54713201522827
2020-01-12 04:40:19.422580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2689155
Z variance train             0.16870499
KL Divergence                22.900928
KL Loss                      2.290093
QF Loss                      323.76242
VF Loss                      58.08722
Policy Loss                  -491.9149
Q Predictions Mean           485.00275
Q Predictions Std            164.81328
Q Predictions Max            747.8525
Q Predictions Min            -31.624819
V Predictions Mean           491.5777
V Predictions Std            156.47876
V Predictions Max            728.00305
V Predictions Min            234.88298
Log Pis Mean                 -1.8299117
Log Pis Std                  2.4304302
Log Pis Max                  11.806103
Log Pis Min                  -8.36261
Policy mu Mean               -0.014025364
Policy mu Std                0.43215278
Policy mu Max                2.041173
Policy mu Min                -2.7315931
Policy log std Mean          -0.8818973
Policy log std Std           0.1355408
Policy log std Max           -0.48219448
Policy log std Min           -1.5494518
Z mean eval                  1.2762692
Z variance eval              0.15631437
total_rewards                [ 207.17891274  544.60288119  755.27974494  545.59743523  793.68367911
 1603.99473623  530.76788417  547.87893599  430.53966511  827.63167096]
total_rewards_mean           678.7155545666976
total_rewards_std            354.40778379345926
total_rewards_max            1603.9947362275539
total_rewards_min            207.17891274024976
Number of train steps total  224000
Number of env steps total    189819
Number of rollouts total     0
Train Time (s)               140.8692221599631
(Previous) Eval Time (s)     26.520766034256667
Sample Time (s)              12.300806649029255
Epoch Time (s)               179.69079484324902
Total Train Time (s)         10046.791865248233
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:43:19.205228 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #55 | Epoch Duration: 179.78246593475342
2020-01-12 04:43:19.205439 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2756559
Z variance train             0.15659295
KL Divergence                21.41196
KL Loss                      2.141196
QF Loss                      255.42058
VF Loss                      57.377033
Policy Loss                  -533.4002
Q Predictions Mean           524.5112
Q Predictions Std            168.82617
Q Predictions Max            784.0808
Q Predictions Min            -28.5265
V Predictions Mean           531.15063
V Predictions Std            162.10005
V Predictions Max            773.5649
V Predictions Min            239.22897
Log Pis Mean                 -1.6060188
Log Pis Std                  2.4962478
Log Pis Max                  15.984402
Log Pis Min                  -6.7277565
Policy mu Mean               0.03815617
Policy mu Std                0.45053917
Policy mu Max                3.052901
Policy mu Min                -3.3630054
Policy log std Mean          -0.8796371
Policy log std Std           0.12561382
Policy log std Max           -0.5535204
Policy log std Min           -1.4323574
Z mean eval                  1.2396321
Z variance eval              0.11045573
total_rewards                [ 505.11176533 1113.58973148  191.37678717 1391.71548133  696.98128661
 1111.44580082  677.14255269 1297.12317757  282.74179446  780.36329354]
total_rewards_mean           804.7591671005082
total_rewards_std            392.86116117558583
total_rewards_max            1391.7154813300895
total_rewards_min            191.37678716920993
Number of train steps total  228000
Number of env steps total    193274
Number of rollouts total     0
Train Time (s)               149.48991259234026
(Previous) Eval Time (s)     24.085978002287447
Sample Time (s)              11.410999331623316
Epoch Time (s)               184.98688992625102
Total Train Time (s)         10231.869508202188
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:46:24.290478 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #56 | Epoch Duration: 185.08486366271973
2020-01-12 04:46:24.290871 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2380142
Z variance train             0.1102291
KL Divergence                22.292664
KL Loss                      2.2292664
QF Loss                      472.2771
VF Loss                      94.98532
Policy Loss                  -497.45547
Q Predictions Mean           487.45966
Q Predictions Std            173.87129
Q Predictions Max            765.78394
Q Predictions Min            -89.286316
V Predictions Mean           494.28638
V Predictions Std            166.10526
V Predictions Max            774.5809
V Predictions Min            57.36389
Log Pis Mean                 -1.7080569
Log Pis Std                  2.7810786
Log Pis Max                  17.308243
Log Pis Min                  -8.06298
Policy mu Mean               0.03033424
Policy mu Std                0.4588198
Policy mu Max                2.533805
Policy mu Min                -3.2787352
Policy log std Mean          -0.8739206
Policy log std Std           0.14901048
Policy log std Max           -0.45544562
Policy log std Min           -1.6621246
Z mean eval                  1.2292262
Z variance eval              0.04099272
total_rewards                [1846.3653747   121.78449078  692.78707609  687.2557219   289.82082755
 1632.41789683  703.76209354  701.481916    502.08566959 1450.03260029]
total_rewards_mean           862.7793667273505
total_rewards_std            549.8286450271623
total_rewards_max            1846.3653747005021
total_rewards_min            121.78449077632598
Number of train steps total  232000
Number of env steps total    198830
Number of rollouts total     0
Train Time (s)               147.6378724416718
(Previous) Eval Time (s)     24.53674687212333
Sample Time (s)              13.005708694923669
Epoch Time (s)               185.1803280087188
Total Train Time (s)         10417.149703877512
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:49:29.566336 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #57 | Epoch Duration: 185.27513813972473
2020-01-12 04:49:29.566534 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2295605
Z variance train             0.04120399
KL Divergence                24.386703
KL Loss                      2.4386704
QF Loss                      303.4914
VF Loss                      125.93894
Policy Loss                  -525.3101
Q Predictions Mean           517.93677
Q Predictions Std            163.9726
Q Predictions Max            741.5029
Q Predictions Min            21.190485
V Predictions Mean           531.51227
V Predictions Std            159.18419
V Predictions Max            749.2716
V Predictions Min            232.09889
Log Pis Mean                 -1.5876341
Log Pis Std                  2.5672116
Log Pis Max                  10.492174
Log Pis Min                  -8.522718
Policy mu Mean               -0.03052894
Policy mu Std                0.4483542
Policy mu Max                2.47825
Policy mu Min                -2.7673573
Policy log std Mean          -0.8975401
Policy log std Std           0.15080483
Policy log std Max           -0.42852902
Policy log std Min           -1.5662587
Z mean eval                  1.1708483
Z variance eval              0.048855178
total_rewards                [ 330.87619338  153.31861505  387.72553926  403.79182401  693.75349824
  474.5030148  1020.43960867   74.60977147 1099.34389645  870.0956735 ]
total_rewards_mean           550.8457634825612
total_rewards_std            336.30167358306153
total_rewards_max            1099.3438964473473
total_rewards_min            74.60977146847435
Number of train steps total  236000
Number of env steps total    201269
Number of rollouts total     0
Train Time (s)               146.5572842741385
(Previous) Eval Time (s)     19.651416276115924
Sample Time (s)              12.416493157390505
Epoch Time (s)               178.62519370764494
Total Train Time (s)         10595.860166958999
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:52:28.278518 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #58 | Epoch Duration: 178.71183466911316
2020-01-12 04:52:28.278724 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.16906
Z variance train             0.04905943
KL Divergence                22.78566
KL Loss                      2.2785661
QF Loss                      353.83813
VF Loss                      118.95221
Policy Loss                  -525.19446
Q Predictions Mean           517.3554
Q Predictions Std            176.32478
Q Predictions Max            761.4449
Q Predictions Min            -23.226524
V Predictions Mean           531.5229
V Predictions Std            172.96237
V Predictions Max            765.8841
V Predictions Min            20.343052
Log Pis Mean                 -1.6125641
Log Pis Std                  2.6723588
Log Pis Max                  11.743497
Log Pis Min                  -7.72048
Policy mu Mean               0.029699573
Policy mu Std                0.4594171
Policy mu Max                3.078553
Policy mu Min                -2.1955345
Policy log std Mean          -0.8874093
Policy log std Std           0.15311028
Policy log std Max           -0.49929544
Policy log std Min           -1.6173501
Z mean eval                  1.2004033
Z variance eval              0.026744362
total_rewards                [1313.7609408   565.30388327   73.62487841  652.11764265  201.62203299
  433.43481225  554.64299348  514.66574521 1780.7376016   409.25553204]
total_rewards_mean           649.9166062696402
total_rewards_std            489.0645906174561
total_rewards_max            1780.7376016002397
total_rewards_min            73.62487841179059
Number of train steps total  240000
Number of env steps total    204804
Number of rollouts total     0
Train Time (s)               147.51188009930775
(Previous) Eval Time (s)     19.500629162881523
Sample Time (s)              12.084445777814835
Epoch Time (s)               179.0969550400041
Total Train Time (s)         10775.043225100264
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:55:27.463004 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #59 | Epoch Duration: 179.18413376808167
2020-01-12 04:55:27.463203 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.199556
Z variance train             0.02679183
KL Divergence                25.262669
KL Loss                      2.5262668
QF Loss                      312.3936
VF Loss                      81.86003
Policy Loss                  -518.08044
Q Predictions Mean           511.8073
Q Predictions Std            177.65143
Q Predictions Max            761.6616
Q Predictions Min            70.66105
V Predictions Mean           513.86365
V Predictions Std            170.94153
V Predictions Max            753.8749
V Predictions Min            161.45432
Log Pis Mean                 -1.7976946
Log Pis Std                  2.5777617
Log Pis Max                  9.83292
Log Pis Min                  -8.924756
Policy mu Mean               0.0034425892
Policy mu Std                0.44759825
Policy mu Max                2.1745458
Policy mu Min                -3.8728619
Policy log std Mean          -0.86726904
Policy log std Std           0.13695711
Policy log std Max           -0.40784258
Policy log std Min           -1.6866719
Z mean eval                  1.2677829
Z variance eval              0.0495149
total_rewards                [ 460.90775781  538.22824574  602.8091478   411.50941715   85.26293941
   30.31214429  474.85640566 1180.17245382  131.52990159  151.34990411]
total_rewards_mean           406.69383173835257
total_rewards_std            323.6567436690532
total_rewards_max            1180.172453819287
total_rewards_min            30.31214429328052
Number of train steps total  244000
Number of env steps total    207460
Number of rollouts total     0
Train Time (s)               141.47448216425255
(Previous) Eval Time (s)     19.091336596757174
Sample Time (s)              12.49863045103848
Epoch Time (s)               173.0644492120482
Total Train Time (s)         10948.197300711647
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:58:20.618935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #60 | Epoch Duration: 173.15558004379272
2020-01-12 04:58:20.619121 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2679762
Z variance train             0.04945088
KL Divergence                23.863976
KL Loss                      2.3863976
QF Loss                      352.0481
VF Loss                      72.69202
Policy Loss                  -545.4673
Q Predictions Mean           536.8648
Q Predictions Std            180.27481
Q Predictions Max            766.48157
Q Predictions Min            24.755102
V Predictions Mean           544.1172
V Predictions Std            168.44223
V Predictions Max            761.44763
V Predictions Min            122.563934
Log Pis Mean                 -1.4886029
Log Pis Std                  3.2072008
Log Pis Max                  22.682034
Log Pis Min                  -10.6395035
Policy mu Mean               0.016420633
Policy mu Std                0.49776608
Policy mu Max                3.1569626
Policy mu Min                -3.2662563
Policy log std Mean          -0.8956853
Policy log std Std           0.14499189
Policy log std Max           -0.51544726
Policy log std Min           -1.6594629
Z mean eval                  1.2598982
Z variance eval              0.044816058
total_rewards                [1862.67402264  661.62755412  489.09211699  527.77991265   93.17727579
  888.40440006  464.9255334    89.26522838   94.97299857 2033.67593753]
total_rewards_mean           720.5594980117477
total_rewards_std            663.320018771521
total_rewards_max            2033.675937527155
total_rewards_min            89.26522838259515
Number of train steps total  248000
Number of env steps total    211065
Number of rollouts total     0
Train Time (s)               138.6859473171644
(Previous) Eval Time (s)     20.58487522089854
Sample Time (s)              11.695157585199922
Epoch Time (s)               170.96598012326285
Total Train Time (s)         11119.251452136785
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:01:11.674995 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #61 | Epoch Duration: 171.05569624900818
2020-01-12 05:01:11.675308 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2592368
Z variance train             0.04488253
KL Divergence                23.924288
KL Loss                      2.3924289
QF Loss                      367.42148
VF Loss                      104.08624
Policy Loss                  -529.90784
Q Predictions Mean           518.1002
Q Predictions Std            189.83017
Q Predictions Max            820.3933
Q Predictions Min            18.070126
V Predictions Mean           526.6172
V Predictions Std            179.25388
V Predictions Max            810.4969
V Predictions Min            157.5843
Log Pis Mean                 -1.5362548
Log Pis Std                  2.7658083
Log Pis Max                  14.687092
Log Pis Min                  -9.0883875
Policy mu Mean               -0.009033308
Policy mu Std                0.46030837
Policy mu Max                2.8313363
Policy mu Min                -2.6653666
Policy log std Mean          -0.8987133
Policy log std Std           0.16187952
Policy log std Max           -0.50071377
Policy log std Min           -1.8582991
Z mean eval                  1.2614192
Z variance eval              0.06974458
total_rewards                [1751.23309188  149.99570696  424.07666317  905.45032607  650.77672419
  685.1106415   467.56401893 1154.97285555  599.40694767  510.86748564]
total_rewards_mean           729.9454461556817
total_rewards_std            427.3796253093407
total_rewards_max            1751.2330918848795
total_rewards_min            149.9957069609966
Number of train steps total  252000
Number of env steps total    214466
Number of rollouts total     0
Train Time (s)               140.30033798282966
(Previous) Eval Time (s)     29.71482932008803
Sample Time (s)              11.096128396689892
Epoch Time (s)               181.11129569960758
Total Train Time (s)         11300.473074077629
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:04:12.898051 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #62 | Epoch Duration: 181.22255659103394
2020-01-12 05:04:12.898266 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.256694
Z variance train             0.069033876
KL Divergence                23.33343
KL Loss                      2.333343
QF Loss                      392.6551
VF Loss                      64.37436
Policy Loss                  -537.49286
Q Predictions Mean           524.58386
Q Predictions Std            183.05519
Q Predictions Max            797.2562
Q Predictions Min            7.67154
V Predictions Mean           540.1504
V Predictions Std            175.24887
V Predictions Max            798.17554
V Predictions Min            235.60239
Log Pis Mean                 -1.5041163
Log Pis Std                  2.7302704
Log Pis Max                  13.011522
Log Pis Min                  -8.525068
Policy mu Mean               0.03408063
Policy mu Std                0.48614448
Policy mu Max                2.36796
Policy mu Min                -2.386825
Policy log std Mean          -0.89823663
Policy log std Std           0.15228546
Policy log std Max           -0.12330127
Policy log std Min           -1.5200877
Z mean eval                  1.2698524
Z variance eval              0.11552031
total_rewards                [1456.15319606  425.9694332    94.48602971 1486.79254141 1267.60780423
  572.48443949 2106.43731241 1049.98293334  169.93617744  652.47711009]
total_rewards_mean           928.2326977378832
total_rewards_std            619.182309317349
total_rewards_max            2106.437312406498
total_rewards_min            94.48602971062016
Number of train steps total  256000
Number of env steps total    217355
Number of rollouts total     0
Train Time (s)               149.33218231564388
(Previous) Eval Time (s)     26.917298623360693
Sample Time (s)              13.333034125622362
Epoch Time (s)               189.58251506462693
Total Train Time (s)         11490.14495961275
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:07:22.571795 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #63 | Epoch Duration: 189.67337036132812
2020-01-12 05:07:22.571996 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2723532
Z variance train             0.11513184
KL Divergence                20.934092
KL Loss                      2.0934093
QF Loss                      499.9095
VF Loss                      110.3989
Policy Loss                  -543.85034
Q Predictions Mean           532.70984
Q Predictions Std            181.27232
Q Predictions Max            787.2185
Q Predictions Min            -61.298256
V Predictions Mean           546.66376
V Predictions Std            173.96062
V Predictions Max            791.7869
V Predictions Min            249.78912
Log Pis Mean                 -1.4274061
Log Pis Std                  2.4936354
Log Pis Max                  9.293995
Log Pis Min                  -7.383942
Policy mu Mean               0.038323656
Policy mu Std                0.46407136
Policy mu Max                2.1820707
Policy mu Min                -2.056312
Policy log std Mean          -0.90945613
Policy log std Std           0.1579208
Policy log std Max           -0.28307647
Policy log std Min           -1.719687
Z mean eval                  1.2290437
Z variance eval              0.045619734
total_rewards                [ 385.64883638  484.35566128  511.26568844  485.05155469  629.76727054
 1064.11212526  245.4272939   429.51886538  191.68684814 1497.12870669]
total_rewards_mean           592.3962850701583
total_rewards_std            377.15515580087265
total_rewards_max            1497.1287066897985
total_rewards_min            191.68684814218733
Number of train steps total  260000
Number of env steps total    221128
Number of rollouts total     0
Train Time (s)               147.77221189578995
(Previous) Eval Time (s)     25.1343494951725
Sample Time (s)              11.916188419796526
Epoch Time (s)               184.82274981075898
Total Train Time (s)         11675.055635738187
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:10:27.483938 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #64 | Epoch Duration: 184.91179609298706
2020-01-12 05:10:27.484129 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2277946
Z variance train             0.046155803
KL Divergence                23.96076
KL Loss                      2.396076
QF Loss                      445.59637
VF Loss                      154.1987
Policy Loss                  -547.6479
Q Predictions Mean           540.15356
Q Predictions Std            188.12155
Q Predictions Max            812.9769
Q Predictions Min            53.317554
V Predictions Mean           555.3153
V Predictions Std            187.23528
V Predictions Max            832.4102
V Predictions Min            145.8058
Log Pis Mean                 -1.5666208
Log Pis Std                  2.7834222
Log Pis Max                  14.808512
Log Pis Min                  -7.7653685
Policy mu Mean               -0.005925411
Policy mu Std                0.46323612
Policy mu Max                2.920718
Policy mu Min                -2.6937206
Policy log std Mean          -0.90222883
Policy log std Std           0.14726932
Policy log std Max           -0.541241
Policy log std Min           -1.5715383
Z mean eval                  1.2333007
Z variance eval              0.08634976
total_rewards                [1001.91737963  904.70469582   73.37759326  755.76271238 1983.82062612
 1145.65215115  682.45228078 1811.2739109   518.00256361 1053.68186436]
total_rewards_mean           993.0645777991351
total_rewards_std            539.4633968224124
total_rewards_max            1983.8206261150044
total_rewards_min            73.37759326155515
Number of train steps total  264000
Number of env steps total    224155
Number of rollouts total     0
Train Time (s)               146.93255919311196
(Previous) Eval Time (s)     22.25600208202377
Sample Time (s)              12.657073920127004
Epoch Time (s)               181.84563519526273
Total Train Time (s)         11856.990663953125
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:13:29.420577 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #65 | Epoch Duration: 181.93630456924438
2020-01-12 05:13:29.420767 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2270544
Z variance train             0.08564535
KL Divergence                22.216633
KL Loss                      2.2216632
QF Loss                      459.71716
VF Loss                      113.05988
Policy Loss                  -565.7088
Q Predictions Mean           555.2212
Q Predictions Std            182.79292
Q Predictions Max            820.4519
Q Predictions Min            -31.87717
V Predictions Mean           560.34766
V Predictions Std            174.53255
V Predictions Max            797.2983
V Predictions Min            45.42442
Log Pis Mean                 -1.6906457
Log Pis Std                  2.7290797
Log Pis Max                  12.084948
Log Pis Min                  -7.7650204
Policy mu Mean               0.030858524
Policy mu Std                0.48191705
Policy mu Max                3.3643124
Policy mu Min                -2.8375118
Policy log std Mean          -0.8868466
Policy log std Std           0.15210792
Policy log std Max           -0.49733293
Policy log std Min           -1.7164567
Z mean eval                  1.2324258
Z variance eval              0.059794534
total_rewards                [  86.91075743  612.66743507 1075.34705615  313.67651067  991.29951578
 1106.80758513  732.33337998 1360.44140426  470.51050432  690.65803397]
total_rewards_mean           744.0652182756479
total_rewards_std            373.4364776900268
total_rewards_max            1360.4414042576686
total_rewards_min            86.91075742866546
Number of train steps total  268000
Number of env steps total    227766
Number of rollouts total     0
Train Time (s)               147.23263476602733
(Previous) Eval Time (s)     17.506334602367133
Sample Time (s)              12.89196260459721
Epoch Time (s)               177.63093197299168
Total Train Time (s)         12034.718619927298
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:16:27.151490 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #66 | Epoch Duration: 177.73054552078247
2020-01-12 05:16:27.151868 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.224322
Z variance train             0.059877753
KL Divergence                23.735527
KL Loss                      2.3735528
QF Loss                      506.01544
VF Loss                      95.144394
Policy Loss                  -550.45355
Q Predictions Mean           540.3662
Q Predictions Std            188.13501
Q Predictions Max            813.85986
Q Predictions Min            18.178967
V Predictions Mean           553.883
V Predictions Std            181.09918
V Predictions Max            817.353
V Predictions Min            227.71126
Log Pis Mean                 -1.0864646
Log Pis Std                  3.2096853
Log Pis Max                  16.203264
Log Pis Min                  -7.5923367
Policy mu Mean               0.045391925
Policy mu Std                0.531334
Policy mu Max                3.1688056
Policy mu Min                -2.7491472
Policy log std Mean          -0.9090982
Policy log std Std           0.15542628
Policy log std Max           -0.3588159
Policy log std Min           -1.8577583
Z mean eval                  1.3041334
Z variance eval              0.11535152
total_rewards                [ 383.10087997 1139.46625201  493.35485986  413.31759605 1808.09010648
  818.78475645  370.31675173 1228.23164314  551.86079683  365.30258161]
total_rewards_mean           757.1826224118591
total_rewards_std            463.616968131429
total_rewards_max            1808.0901064769064
total_rewards_min            365.3025816085194
Number of train steps total  272000
Number of env steps total    230742
Number of rollouts total     0
Train Time (s)               140.3466214807704
(Previous) Eval Time (s)     27.05418691597879
Sample Time (s)              13.552830620668828
Epoch Time (s)               180.95363901741803
Total Train Time (s)         12215.910000167787
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:19:28.343384 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #67 | Epoch Duration: 181.1912498474121
2020-01-12 05:19:28.343580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3126023
Z variance train             0.11573736
KL Divergence                21.654814
KL Loss                      2.1654813
QF Loss                      620.46265
VF Loss                      112.14311
Policy Loss                  -558.1892
Q Predictions Mean           547.3266
Q Predictions Std            196.44633
Q Predictions Max            834.0842
Q Predictions Min            -43.235508
V Predictions Mean           558.96484
V Predictions Std            190.00046
V Predictions Max            829.9671
V Predictions Min            186.0825
Log Pis Mean                 -1.3861411
Log Pis Std                  3.2005534
Log Pis Max                  17.72455
Log Pis Min                  -6.798415
Policy mu Mean               0.009275682
Policy mu Std                0.49632585
Policy mu Max                3.4393208
Policy mu Min                -3.14548
Policy log std Mean          -0.90976524
Policy log std Std           0.16115554
Policy log std Max           -0.3704023
Policy log std Min           -1.6682754
Z mean eval                  1.2800118
Z variance eval              0.047176324
total_rewards                [ 409.55649818 1043.76323122  413.64969454  948.21752069  581.24733403
 1417.41956299  806.83892969 1595.63781652  556.41998967   67.10618744]
total_rewards_mean           783.9856764969339
total_rewards_std            451.5692151811207
total_rewards_max            1595.6378165237877
total_rewards_min            67.10618744086514
Number of train steps total  276000
Number of env steps total    233330
Number of rollouts total     0
Train Time (s)               138.98940745415166
(Previous) Eval Time (s)     24.403349785134196
Sample Time (s)              11.913210224360228
Epoch Time (s)               175.30596746364608
Total Train Time (s)         12391.304618903436
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:22:23.740181 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #68 | Epoch Duration: 175.39644026756287
2020-01-12 05:22:23.740451 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2898102
Z variance train             0.04700438
KL Divergence                23.639414
KL Loss                      2.3639414
QF Loss                      331.24585
VF Loss                      97.25301
Policy Loss                  -584.55176
Q Predictions Mean           577.48083
Q Predictions Std            184.0657
Q Predictions Max            821.68866
Q Predictions Min            124.826836
V Predictions Mean           590.9036
V Predictions Std            181.83803
V Predictions Max            818.881
V Predictions Min            181.95459
Log Pis Mean                 -1.1187155
Log Pis Std                  2.7437541
Log Pis Max                  16.438416
Log Pis Min                  -6.8059006
Policy mu Mean               0.00943275
Policy mu Std                0.5022091
Policy mu Max                2.3888009
Policy mu Min                -3.7585168
Policy log std Mean          -0.904801
Policy log std Std           0.15769856
Policy log std Max           -0.44246355
Policy log std Min           -1.897852
Z mean eval                  1.25126
Z variance eval              0.07835587
total_rewards                [1820.41266403  661.06207377 1484.57060723 2302.10983223 1917.21654345
  904.28466494 2057.12371384 2142.12890064 1032.72318529  203.61723266]
total_rewards_mean           1452.524941807535
total_rewards_std            676.6224368230351
total_rewards_max            2302.1098322340363
total_rewards_min            203.61723265686174
Number of train steps total  280000
Number of env steps total    236065
Number of rollouts total     0
Train Time (s)               140.9226110642776
(Previous) Eval Time (s)     32.441000408958644
Sample Time (s)              11.530011938419193
Epoch Time (s)               184.89362341165543
Total Train Time (s)         12576.306069901213
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:25:28.743159 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #69 | Epoch Duration: 185.00251126289368
2020-01-12 05:25:28.743441 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2490485
Z variance train             0.07847874
KL Divergence                23.267143
KL Loss                      2.3267143
QF Loss                      488.5445
VF Loss                      113.658806
Policy Loss                  -556.4982
Q Predictions Mean           546.845
Q Predictions Std            180.49207
Q Predictions Max            810.236
Q Predictions Min            239.45627
V Predictions Mean           560.0356
V Predictions Std            175.02597
V Predictions Max            805.7862
V Predictions Min            262.977
Log Pis Mean                 -1.2476385
Log Pis Std                  2.4285367
Log Pis Max                  9.910967
Log Pis Min                  -6.2479258
Policy mu Mean               0.008172556
Policy mu Std                0.47143668
Policy mu Max                3.05046
Policy mu Min                -2.1914113
Policy log std Mean          -0.9156583
Policy log std Std           0.16095205
Policy log std Max           -0.2860858
Policy log std Min           -1.7074231
Z mean eval                  1.1742238
Z variance eval              0.026874816
total_rewards                [1723.61329471  752.09620828 2047.53175998 2145.85183618  166.35735328
 2116.36931153  133.13400276 2003.18881941 2039.96542637  280.00610483]
total_rewards_mean           1340.8114117319624
total_rewards_std            844.5621225850142
total_rewards_max            2145.8518361774127
total_rewards_min            133.1340027562243
Number of train steps total  284000
Number of env steps total    238564
Number of rollouts total     0
Train Time (s)               149.80336778610945
(Previous) Eval Time (s)     24.59285812312737
Sample Time (s)              10.048514929134399
Epoch Time (s)               184.44474083837122
Total Train Time (s)         12760.844211871736
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:28:33.283965 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #70 | Epoch Duration: 184.54035830497742
2020-01-12 05:28:33.284208 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #70 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1773279
Z variance train             0.026713774
KL Divergence                24.729404
KL Loss                      2.4729404
QF Loss                      1159.017
VF Loss                      119.386795
Policy Loss                  -588.1197
Q Predictions Mean           578.9889
Q Predictions Std            189.788
Q Predictions Max            830.4326
Q Predictions Min            116.56523
V Predictions Mean           583.72815
V Predictions Std            183.07687
V Predictions Max            820.4359
V Predictions Min            228.54002
Log Pis Mean                 -1.0223165
Log Pis Std                  2.7569609
Log Pis Max                  10.194109
Log Pis Min                  -8.611057
Policy mu Mean               0.0045745345
Policy mu Std                0.4897675
Policy mu Max                2.1243699
Policy mu Min                -2.5010548
Policy log std Mean          -0.9386706
Policy log std Std           0.17027824
Policy log std Max           -0.5382459
Policy log std Min           -1.8104124
Z mean eval                  1.248297
Z variance eval              0.09523897
total_rewards                [1943.25105629 1162.2021681   450.16791124  102.70692563  548.5101968
  855.60051806  409.31931847 2543.51976417 1547.21786663  187.98472567]
total_rewards_mean           975.0480451066453
total_rewards_std            770.2028088207153
total_rewards_max            2543.519764172765
total_rewards_min            102.70692562861936
Number of train steps total  288000
Number of env steps total    241318
Number of rollouts total     0
Train Time (s)               148.87825225992128
(Previous) Eval Time (s)     30.336005054879934
Sample Time (s)              13.01375881768763
Epoch Time (s)               192.22801613248885
Total Train Time (s)         12953.161749814637
Epoch                        71
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:31:45.602964 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #71 | Epoch Duration: 192.31857919692993
2020-01-12 05:31:45.603219 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2506803
Z variance train             0.09505904
KL Divergence                21.683872
KL Loss                      2.1683872
QF Loss                      375.61908
VF Loss                      71.71071
Policy Loss                  -588.6643
Q Predictions Mean           577.5829
Q Predictions Std            201.08815
Q Predictions Max            850.9185
Q Predictions Min            -8.681563
V Predictions Mean           584.48083
V Predictions Std            192.106
V Predictions Max            845.33154
V Predictions Min            222.39658
Log Pis Mean                 -1.179746
Log Pis Std                  2.7192743
Log Pis Max                  12.832163
Log Pis Min                  -5.4797974
Policy mu Mean               0.013027266
Policy mu Std                0.47664195
Policy mu Max                2.3759735
Policy mu Min                -2.4894867
Policy log std Mean          -0.9251949
Policy log std Std           0.17509551
Policy log std Max           -0.48348895
Policy log std Min           -1.6529154
Z mean eval                  1.1960326
Z variance eval              0.039345313
total_rewards                [2288.62936059  878.86213584 2446.67001767 2061.02317314  465.27680466
  373.90896481 1885.8584448   405.35258682  937.05144485  597.84202329]
total_rewards_mean           1234.0474956484145
total_rewards_std            795.4901125678495
total_rewards_max            2446.6700176699833
total_rewards_min            373.9089648125763
Number of train steps total  292000
Number of env steps total    244160
Number of rollouts total     0
Train Time (s)               147.94762062001973
(Previous) Eval Time (s)     24.611397127155215
Sample Time (s)              12.02430998859927
Epoch Time (s)               184.58332773577422
Total Train Time (s)         13137.849230694119
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:34:50.292613 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #72 | Epoch Duration: 184.6890571117401
2020-01-12 05:34:50.292907 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1976717
Z variance train             0.039259452
KL Divergence                23.70444
KL Loss                      2.370444
QF Loss                      376.42426
VF Loss                      134.21564
Policy Loss                  -600.9004
Q Predictions Mean           589.8196
Q Predictions Std            200.27902
Q Predictions Max            869.2813
Q Predictions Min            -10.2653475
V Predictions Mean           600.2448
V Predictions Std            191.61494
V Predictions Max            865.10815
V Predictions Min            250.9682
Log Pis Mean                 -1.1039809
Log Pis Std                  2.9736223
Log Pis Max                  18.015945
Log Pis Min                  -9.343112
Policy mu Mean               0.009828339
Policy mu Std                0.5109297
Policy mu Max                4.6180167
Policy mu Min                -3.1798604
Policy log std Mean          -0.91250676
Policy log std Std           0.16670997
Policy log std Max           -0.31219453
Policy log std Min           -1.6152575
Z mean eval                  1.2035974
Z variance eval              0.043243572
total_rewards                [ 321.58674223  199.16263918  573.60787598  242.85634523  587.47495819
  697.62164203  911.43629488 1437.65934175  435.21219201  720.81409852]
total_rewards_mean           612.7432130007479
total_rewards_std            348.5559409652589
total_rewards_max            1437.6593417519396
total_rewards_min            199.16263918024805
Number of train steps total  296000
Number of env steps total    246912
Number of rollouts total     0
Train Time (s)               146.568622474093
(Previous) Eval Time (s)     20.765681040938944
Sample Time (s)              14.094809784553945
Epoch Time (s)               181.42911329958588
Total Train Time (s)         13319.372338231653
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:37:51.817329 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #73 | Epoch Duration: 181.52423620224
2020-01-12 05:37:51.817533 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1988184
Z variance train             0.043480627
KL Divergence                23.809956
KL Loss                      2.3809955
QF Loss                      484.66998
VF Loss                      115.65809
Policy Loss                  -573.9017
Q Predictions Mean           563.9961
Q Predictions Std            203.6686
Q Predictions Max            845.3786
Q Predictions Min            -75.510635
V Predictions Mean           579.76013
V Predictions Std            196.7911
V Predictions Max            853.67957
V Predictions Min            226.1463
Log Pis Mean                 -1.4783676
Log Pis Std                  2.5819228
Log Pis Max                  8.992903
Log Pis Min                  -7.981624
Policy mu Mean               0.00092960475
Policy mu Std                0.47378373
Policy mu Max                1.8112519
Policy mu Min                -2.494443
Policy log std Mean          -0.8990526
Policy log std Std           0.16131058
Policy log std Max           -0.3478551
Policy log std Min           -1.5319942
Z mean eval                  1.2570488
Z variance eval              0.046418834
total_rewards                [ 464.50211207  641.8169995   333.26839833 2181.29906009  423.33291692
 2175.1662566   805.64179061   83.83917966 1339.47250189  910.57592281]
total_rewards_mean           935.8915138490742
total_rewards_std            701.9884066457968
total_rewards_max            2181.2990600854173
total_rewards_min            83.83917966360144
Number of train steps total  300000
Number of env steps total    249955
Number of rollouts total     0
Train Time (s)               140.6947680078447
(Previous) Eval Time (s)     30.07866667304188
Sample Time (s)              14.584345690906048
Epoch Time (s)               185.35778037179261
Total Train Time (s)         13504.816404552665
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:40:57.263283 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #74 | Epoch Duration: 185.44559907913208
2020-01-12 05:40:57.263481 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2538159
Z variance train             0.046216365
KL Divergence                22.88174
KL Loss                      2.2881742
QF Loss                      519.7311
VF Loss                      77.20994
Policy Loss                  -603.7061
Q Predictions Mean           594.0915
Q Predictions Std            210.60606
Q Predictions Max            898.6832
Q Predictions Min            18.018232
V Predictions Mean           603.8493
V Predictions Std            202.30731
V Predictions Max            892.91
V Predictions Min            219.1924
Log Pis Mean                 -1.1214149
Log Pis Std                  3.1372185
Log Pis Max                  13.439519
Log Pis Min                  -7.693735
Policy mu Mean               0.0042658956
Policy mu Std                0.5292446
Policy mu Max                2.6725824
Policy mu Min                -2.9909267
Policy log std Mean          -0.9250158
Policy log std Std           0.17024341
Policy log std Max           -0.3819771
Policy log std Min           -1.7618365
Z mean eval                  1.2687428
Z variance eval              0.03800621
total_rewards                [ 405.74306521  580.51283821  553.31960845  731.70994212 1761.23193983
 1067.95626563 1966.48375071 2198.69625777 2387.32325776 2270.35141398]
total_rewards_mean           1392.332833968735
total_rewards_std            758.6090824856149
total_rewards_max            2387.3232577649605
total_rewards_min            405.7430652100753
Number of train steps total  304000
Number of env steps total    252986
Number of rollouts total     0
Train Time (s)               139.17408319190145
(Previous) Eval Time (s)     27.82165684690699
Sample Time (s)              12.938561735674739
Epoch Time (s)               179.93430177448317
Total Train Time (s)         13684.841469957028
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:43:57.292272 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #75 | Epoch Duration: 180.02860522270203
2020-01-12 05:43:57.292552 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.269149
Z variance train             0.037926055
KL Divergence                23.414541
KL Loss                      2.3414543
QF Loss                      456.57843
VF Loss                      117.195755
Policy Loss                  -600.51263
Q Predictions Mean           595.08167
Q Predictions Std            213.5937
Q Predictions Max            895.3767
Q Predictions Min            -18.922646
V Predictions Mean           599.8314
V Predictions Std            207.36089
V Predictions Max            894.48413
V Predictions Min            91.76229
Log Pis Mean                 -1.3309507
Log Pis Std                  2.627734
Log Pis Max                  11.056293
Log Pis Min                  -10.098885
Policy mu Mean               0.018922359
Policy mu Std                0.44282135
Policy mu Max                2.3944714
Policy mu Min                -3.0442927
Policy log std Mean          -0.9341626
Policy log std Std           0.17787856
Policy log std Max           -0.51558864
Policy log std Min           -1.9428282
Z mean eval                  1.1964266
Z variance eval              0.035620816
total_rewards                [2056.10757858  568.87963095 1093.80595705 1034.50947419  521.30508913
 2530.30009779  907.99196262 2373.72252263  458.49000685 2372.52758165]
total_rewards_mean           1391.7639901439825
total_rewards_std            801.251489981947
total_rewards_max            2530.3000977886986
total_rewards_min            458.49000685182114
Number of train steps total  308000
Number of env steps total    255368
Number of rollouts total     0
Train Time (s)               142.26606324594468
(Previous) Eval Time (s)     33.26637479988858
Sample Time (s)              11.523689358495176
Epoch Time (s)               187.05612740432844
Total Train Time (s)         13871.999023062177
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:47:04.451055 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #76 | Epoch Duration: 187.15827417373657
2020-01-12 05:47:04.451463 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1994783
Z variance train             0.035697028
KL Divergence                23.927505
KL Loss                      2.3927505
QF Loss                      615.14856
VF Loss                      104.2118
Policy Loss                  -607.6762
Q Predictions Mean           598.2045
Q Predictions Std            209.67445
Q Predictions Max            878.6144
Q Predictions Min            12.159829
V Predictions Mean           606.18274
V Predictions Std            202.56113
V Predictions Max            878.23004
V Predictions Min            131.49506
Log Pis Mean                 -0.9511509
Log Pis Std                  3.0248575
Log Pis Max                  16.710274
Log Pis Min                  -8.266005
Policy mu Mean               -0.013653804
Policy mu Std                0.5423959
Policy mu Max                3.205374
Policy mu Min                -3.751624
Policy log std Mean          -0.91887516
Policy log std Std           0.16848947
Policy log std Max           -0.27353007
Policy log std Min           -1.7209955
Z mean eval                  1.2096304
Z variance eval              0.04733301
total_rewards                [2250.46130483 1638.76348537 2284.65348626  145.9600619  2138.38642014
 2129.84226686  861.77408012 2213.73795795  628.70964958 1901.68309083]
total_rewards_mean           1619.3971803841619
total_rewards_std            743.6722890988275
total_rewards_max            2284.653486262042
total_rewards_min            145.96006189703863
Number of train steps total  312000
Number of env steps total    258799
Number of rollouts total     0
Train Time (s)               149.15541056217626
(Previous) Eval Time (s)     32.61582437576726
Sample Time (s)              11.376494188793004
Epoch Time (s)               193.14772912673652
Total Train Time (s)         14065.245722566731
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:50:17.699757 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #77 | Epoch Duration: 193.24796795845032
2020-01-12 05:50:17.700075 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2122569
Z variance train             0.04760154
KL Divergence                23.18921
KL Loss                      2.318921
QF Loss                      641.8063
VF Loss                      102.399956
Policy Loss                  -625.39465
Q Predictions Mean           616.4185
Q Predictions Std            212.90648
Q Predictions Max            886.4989
Q Predictions Min            37.691227
V Predictions Mean           623.7706
V Predictions Std            209.46413
V Predictions Max            877.5752
V Predictions Min            63.102013
Log Pis Mean                 -0.9977274
Log Pis Std                  3.7147386
Log Pis Max                  39.11149
Log Pis Min                  -8.719757
Policy mu Mean               0.029160157
Policy mu Std                0.5340366
Policy mu Max                6.0613594
Policy mu Min                -5.968633
Policy log std Mean          -0.93863213
Policy log std Std           0.18178345
Policy log std Max           -0.42766148
Policy log std Min           -2.3170896
Z mean eval                  1.2309209
Z variance eval              0.08058432
total_rewards                [1939.03909439 2148.10279654  931.61390403  528.15953595 1746.73745069
  108.78727548  633.41151969  719.696429   1022.66150243 1488.72705927]
total_rewards_mean           1126.6936567473253
total_rewards_std            638.0386771835869
total_rewards_max            2148.102796542768
total_rewards_min            108.7872754847943
Number of train steps total  316000
Number of env steps total    261327
Number of rollouts total     0
Train Time (s)               148.39885390596464
(Previous) Eval Time (s)     23.22514209104702
Sample Time (s)              10.798184433020651
Epoch Time (s)               182.4221804300323
Total Train Time (s)         14247.760292895604
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:53:20.214995 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #78 | Epoch Duration: 182.514732837677
2020-01-12 05:53:20.215200 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.234289
Z variance train             0.08020606
KL Divergence                21.855827
KL Loss                      2.1855829
QF Loss                      366.9513
VF Loss                      86.71423
Policy Loss                  -599.61224
Q Predictions Mean           595.0891
Q Predictions Std            201.45686
Q Predictions Max            870.7309
Q Predictions Min            -14.665744
V Predictions Mean           599.1012
V Predictions Std            200.21259
V Predictions Max            870.62213
V Predictions Min            -103.72915
Log Pis Mean                 -1.2000022
Log Pis Std                  2.9776459
Log Pis Max                  18.890558
Log Pis Min                  -7.9635406
Policy mu Mean               0.0060583376
Policy mu Std                0.5152874
Policy mu Max                2.7795622
Policy mu Min                -3.7493093
Policy log std Mean          -0.92652076
Policy log std Std           0.16817816
Policy log std Max           -0.36984533
Policy log std Min           -1.680601
Z mean eval                  1.218229
Z variance eval              0.031646237
total_rewards                [ 627.94837096 1363.14727142 2304.89924564  953.23752602  936.86771442
 1113.45319504 1263.60223374 1754.87611515 1625.28285283 2273.27909473]
total_rewards_mean           1421.6593619957991
total_rewards_std            535.3205253854505
total_rewards_max            2304.899245638278
total_rewards_min            627.9483709631922
Number of train steps total  320000
Number of env steps total    265926
Number of rollouts total     0
Train Time (s)               148.57618387509137
(Previous) Eval Time (s)     31.377890820149332
Sample Time (s)              12.39290611911565
Epoch Time (s)               192.34698081435636
Total Train Time (s)         14440.192522552796
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:56:32.649045 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #79 | Epoch Duration: 192.4336953163147
2020-01-12 05:56:32.649231 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2166336
Z variance train             0.03168813
KL Divergence                23.307735
KL Loss                      2.3307736
QF Loss                      701.36676
VF Loss                      109.07089
Policy Loss                  -636.338
Q Predictions Mean           622.9304
Q Predictions Std            219.0491
Q Predictions Max            904.8521
Q Predictions Min            -126.30424
V Predictions Mean           638.1478
V Predictions Std            208.59291
V Predictions Max            914.7554
V Predictions Min            242.39738
Log Pis Mean                 -1.1569616
Log Pis Std                  3.0296414
Log Pis Max                  15.789
Log Pis Min                  -7.499511
Policy mu Mean               -0.0077126594
Policy mu Std                0.52954036
Policy mu Max                3.18182
Policy mu Min                -2.6346743
Policy log std Mean          -0.9291992
Policy log std Std           0.18090689
Policy log std Max           -0.35659993
Policy log std Min           -1.6996753
Z mean eval                  1.2532191
Z variance eval              0.038257435
total_rewards                [1503.46042405   71.05925443 2478.8021578   540.40427509 1553.72482437
  573.86190092  616.71623578  208.73688418  450.94608956 1665.75971829]
total_rewards_mean           966.3471764472794
total_rewards_std            742.2308977908936
total_rewards_max            2478.8021577995937
total_rewards_min            71.05925442715834
Number of train steps total  324000
Number of env steps total    269297
Number of rollouts total     0
Train Time (s)               146.2137281219475
(Previous) Eval Time (s)     23.862419149838388
Sample Time (s)              11.435252607800066
Epoch Time (s)               181.51139987958595
Total Train Time (s)         14621.792243693955
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:59:34.251064 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #80 | Epoch Duration: 181.60168170928955
2020-01-12 05:59:34.251295 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2554252
Z variance train             0.03878186
KL Divergence                24.013597
KL Loss                      2.4013598
QF Loss                      385.4354
VF Loss                      125.56702
Policy Loss                  -636.4267
Q Predictions Mean           626.76355
Q Predictions Std            215.7322
Q Predictions Max            902.4769
Q Predictions Min            -10.743888
V Predictions Mean           642.4813
V Predictions Std            206.25563
V Predictions Max            908.72864
V Predictions Min            262.51675
Log Pis Mean                 -0.8993196
Log Pis Std                  3.0615969
Log Pis Max                  16.220394
Log Pis Min                  -7.9268665
Policy mu Mean               -0.032624558
Policy mu Std                0.5163588
Policy mu Max                2.2806475
Policy mu Min                -2.9678645
Policy log std Mean          -0.9310522
Policy log std Std           0.17594805
Policy log std Max           -0.36906862
Policy log std Min           -1.6780524
Z mean eval                  1.2169945
Z variance eval              0.02723369
total_rewards                [1057.38642021  993.69045537 1376.36204571  224.33471121 2476.42672009
 1110.8487246  2364.01247942 2573.49850194 1094.74015807 1202.28986159]
total_rewards_mean           1447.359007821118
total_rewards_std            729.6427199186396
total_rewards_max            2573.4985019400183
total_rewards_min            224.33471120791455
Number of train steps total  328000
Number of env steps total    271562
Number of rollouts total     0
Train Time (s)               140.59267473500222
(Previous) Eval Time (s)     27.285299717914313
Sample Time (s)              11.468012926634401
Epoch Time (s)               179.34598737955093
Total Train Time (s)         14801.226131179836
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:02:33.686597 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #81 | Epoch Duration: 179.43513894081116
2020-01-12 06:02:33.686807 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2188269
Z variance train             0.027119273
KL Divergence                24.794596
KL Loss                      2.4794595
QF Loss                      451.74496
VF Loss                      92.98673
Policy Loss                  -628.8228
Q Predictions Mean           619.3598
Q Predictions Std            239.56903
Q Predictions Max            930.79486
Q Predictions Min            -46.380783
V Predictions Mean           626.4489
V Predictions Std            226.48741
V Predictions Max            924.37823
V Predictions Min            94.36305
Log Pis Mean                 -0.7550207
Log Pis Std                  3.3424838
Log Pis Max                  18.066177
Log Pis Min                  -7.585187
Policy mu Mean               -0.0034181941
Policy mu Std                0.54315966
Policy mu Max                2.7756183
Policy mu Min                -2.819823
Policy log std Mean          -0.9509504
Policy log std Std           0.19480214
Policy log std Max           -0.4084561
Policy log std Min           -1.8873235
Z mean eval                  1.2250931
Z variance eval              0.03320954
total_rewards                [  53.92525545 1701.15068113 1091.71987066  910.55055461  695.41094236
  459.18922824  434.18448323  139.94235307 2073.931126    972.29928113]
total_rewards_mean           853.2303775876632
total_rewards_std            615.3749060881325
total_rewards_max            2073.9311259984925
total_rewards_min            53.925255445646314
Number of train steps total  332000
Number of env steps total    273995
Number of rollouts total     0
Train Time (s)               138.79913592431694
(Previous) Eval Time (s)     23.13055334193632
Sample Time (s)              11.011978768743575
Epoch Time (s)               172.94166803499684
Total Train Time (s)         14974.254534138832
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:05:26.716927 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #82 | Epoch Duration: 173.029967546463
2020-01-12 06:05:26.717132 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2156487
Z variance train             0.033338193
KL Divergence                23.169771
KL Loss                      2.3169773
QF Loss                      574.81226
VF Loss                      112.96126
Policy Loss                  -670.0603
Q Predictions Mean           662.7807
Q Predictions Std            209.5088
Q Predictions Max            911.3387
Q Predictions Min            6.1042128
V Predictions Mean           671.5763
V Predictions Std            203.89833
V Predictions Max            915.31525
V Predictions Min            173.15019
Log Pis Mean                 -0.9107009
Log Pis Std                  3.1097615
Log Pis Max                  20.76285
Log Pis Min                  -6.6926246
Policy mu Mean               0.037366748
Policy mu Std                0.5197586
Policy mu Max                3.1639407
Policy mu Min                -3.6582968
Policy log std Mean          -0.954213
Policy log std Std           0.18030907
Policy log std Max           -0.5279105
Policy log std Min           -2.1963046
Z mean eval                  1.16903
Z variance eval              0.020085972
total_rewards                [ 797.00231861 1274.34526559  733.90822458  402.69265205 1639.59661547
  646.5597314   835.33637092  661.42985137  137.37182644  411.44608568]
total_rewards_mean           753.9688942112768
total_rewards_std            412.91791197167663
total_rewards_max            1639.5966154724892
total_rewards_min            137.3718264354556
Number of train steps total  336000
Number of env steps total    276569
Number of rollouts total     0
Train Time (s)               143.35320040490478
(Previous) Eval Time (s)     25.013746864162385
Sample Time (s)              11.392708516214043
Epoch Time (s)               179.7596557852812
Total Train Time (s)         15154.10193358967
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:08:26.565858 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #83 | Epoch Duration: 179.84857773780823
2020-01-12 06:08:26.566044 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1706269
Z variance train             0.019950282
KL Divergence                25.161291
KL Loss                      2.5161293
QF Loss                      360.93634
VF Loss                      130.5082
Policy Loss                  -641.4356
Q Predictions Mean           632.7911
Q Predictions Std            222.41582
Q Predictions Max            915.39014
Q Predictions Min            38.607815
V Predictions Mean           636.084
V Predictions Std            216.10931
V Predictions Max            904.88885
V Predictions Min            153.29407
Log Pis Mean                 -1.1382004
Log Pis Std                  2.8720286
Log Pis Max                  13.098215
Log Pis Min                  -11.429075
Policy mu Mean               0.005325539
Policy mu Std                0.5041966
Policy mu Max                2.8853068
Policy mu Min                -2.6133313
Policy log std Mean          -0.9131365
Policy log std Std           0.1649485
Policy log std Max           -0.3491059
Policy log std Min           -1.7873266
Z mean eval                  1.1753063
Z variance eval              0.039203696
total_rewards                [ 822.56630103  797.585145    989.97097419 1931.66544644 1781.64335295
 2512.5271074   742.98686165 1051.28007435 1952.99835731 1242.21916769]
total_rewards_mean           1382.544278801633
total_rewards_std            584.0736511315941
total_rewards_max            2512.5271074029383
total_rewards_min            742.9868616453916
Number of train steps total  340000
Number of env steps total    279120
Number of rollouts total     0
Train Time (s)               149.71424422692508
(Previous) Eval Time (s)     25.464921046048403
Sample Time (s)              12.379470378160477
Epoch Time (s)               187.55863565113395
Total Train Time (s)         15341.750344645232
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:11:34.214700 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #84 | Epoch Duration: 187.6485104560852
2020-01-12 06:11:34.214832 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1700993
Z variance train             0.03916826
KL Divergence                22.546705
KL Loss                      2.2546706
QF Loss                      498.1946
VF Loss                      83.75441
Policy Loss                  -651.63416
Q Predictions Mean           645.0315
Q Predictions Std            223.00726
Q Predictions Max            935.8363
Q Predictions Min            -18.80354
V Predictions Mean           653.68823
V Predictions Std            217.48587
V Predictions Max            927.05444
V Predictions Min            140.24844
Log Pis Mean                 -0.67722875
Log Pis Std                  2.7964444
Log Pis Max                  12.0827465
Log Pis Min                  -7.8666515
Policy mu Mean               -0.0032165307
Policy mu Std                0.51209456
Policy mu Max                2.6914966
Policy mu Min                -2.1244645
Policy log std Mean          -0.9575105
Policy log std Std           0.18893561
Policy log std Max           -0.5294476
Policy log std Min           -1.9296643
Z mean eval                  1.1979563
Z variance eval              0.028928483
total_rewards                [2608.14409732  569.02269043 2291.37509411 1693.50502666  304.51390583
   54.49391489 2254.82661103 1036.88874521 1182.41119729 1681.00673568]
total_rewards_mean           1367.6188018446528
total_rewards_std            837.8370477887995
total_rewards_max            2608.144097316611
total_rewards_min            54.49391489067982
Number of train steps total  344000
Number of env steps total    281533
Number of rollouts total     0
Train Time (s)               148.9949807948433
(Previous) Eval Time (s)     22.752141813281924
Sample Time (s)              11.50751081109047
Epoch Time (s)               183.25463341921568
Total Train Time (s)         15525.092606601771
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:14:37.564350 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #85 | Epoch Duration: 183.34941339492798
2020-01-12 06:14:37.564502 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2009137
Z variance train             0.02867887
KL Divergence                23.711088
KL Loss                      2.3711088
QF Loss                      391.70972
VF Loss                      107.778366
Policy Loss                  -659.16174
Q Predictions Mean           650.0903
Q Predictions Std            229.61896
Q Predictions Max            956.75586
Q Predictions Min            -40.493477
V Predictions Mean           659.9033
V Predictions Std            223.26768
V Predictions Max            954.89404
V Predictions Min            54.2499
Log Pis Mean                 -1.0327806
Log Pis Std                  3.3737257
Log Pis Max                  16.390398
Log Pis Min                  -8.509881
Policy mu Mean               -0.01790228
Policy mu Std                0.55465174
Policy mu Max                2.9992392
Policy mu Min                -4.752341
Policy log std Mean          -0.9175953
Policy log std Std           0.17162998
Policy log std Max           -0.3536448
Policy log std Min           -1.7263203
Z mean eval                  1.2555901
Z variance eval              0.02865633
total_rewards                [ 762.40194942  866.16482631 2157.37781393  911.7982612  1065.00649668
 2396.95769473 2562.25219887 2637.72158681  203.09799918  457.21037046]
total_rewards_mean           1401.9989197566513
total_rewards_std            883.9564626432452
total_rewards_max            2637.7215868064263
total_rewards_min            203.0979991765421
Number of train steps total  348000
Number of env steps total    285025
Number of rollouts total     0
Train Time (s)               149.27486234810203
(Previous) Eval Time (s)     27.787161422893405
Sample Time (s)              10.43576089385897
Epoch Time (s)               187.4977846648544
Total Train Time (s)         15712.838177558966
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:17:45.311387 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #86 | Epoch Duration: 187.74675726890564
2020-01-12 06:17:45.311587 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2574497
Z variance train             0.028501328
KL Divergence                23.150303
KL Loss                      2.3150303
QF Loss                      531.7721
VF Loss                      118.773544
Policy Loss                  -651.287
Q Predictions Mean           643.4686
Q Predictions Std            251.8469
Q Predictions Max            964.7
Q Predictions Min            49.426144
V Predictions Mean           650.2446
V Predictions Std            242.56291
V Predictions Max            961.04333
V Predictions Min            28.517784
Log Pis Mean                 -0.4707138
Log Pis Std                  3.232638
Log Pis Max                  12.647596
Log Pis Min                  -8.717959
Policy mu Mean               0.016787149
Policy mu Std                0.5487041
Policy mu Max                2.7912962
Policy mu Min                -3.216904
Policy log std Mean          -0.9452671
Policy log std Std           0.18905474
Policy log std Max           -0.31719232
Policy log std Min           -2.032273
Z mean eval                  1.1933038
Z variance eval              0.02534916
total_rewards                [2533.64892863 1857.28581938  324.27236694  810.90641237  173.43925535
 2417.66486724  366.33350087 1210.68725528 2341.71025077 1947.35446569]
total_rewards_mean           1398.330312251786
total_rewards_std            884.8320421145021
total_rewards_max            2533.648928632255
total_rewards_min            173.43925535267044
Number of train steps total  352000
Number of env steps total    287434
Number of rollouts total     0
Train Time (s)               147.71621628012508
(Previous) Eval Time (s)     25.765496281906962
Sample Time (s)              11.532107449602336
Epoch Time (s)               185.01382001163438
Total Train Time (s)         15897.942377127241
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:20:50.417223 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #87 | Epoch Duration: 185.1054916381836
2020-01-12 06:20:50.417408 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1919205
Z variance train             0.025367131
KL Divergence                22.595901
KL Loss                      2.2595901
QF Loss                      406.58426
VF Loss                      75.909904
Policy Loss                  -630.109
Q Predictions Mean           621.62146
Q Predictions Std            243.30646
Q Predictions Max            956.1316
Q Predictions Min            -6.3817058
V Predictions Mean           631.7838
V Predictions Std            236.87462
V Predictions Max            973.14886
V Predictions Min            52.52514
Log Pis Mean                 -0.89480096
Log Pis Std                  3.3483245
Log Pis Max                  17.37203
Log Pis Min                  -8.224986
Policy mu Mean               0.030512743
Policy mu Std                0.54902756
Policy mu Max                2.6526477
Policy mu Min                -3.9003603
Policy log std Mean          -0.9321716
Policy log std Std           0.17970532
Policy log std Max           -0.2656755
Policy log std Min           -1.9388661
Z mean eval                  1.1476127
Z variance eval              0.02292895
total_rewards                [2592.39690044  132.10529465 1014.41840954 1666.41464431 2476.53960781
  202.29085408   74.79105278  531.25747464  541.98715293 2556.1508476 ]
total_rewards_mean           1178.835223878978
total_rewards_std            996.8493656696365
total_rewards_max            2592.396900442329
total_rewards_min            74.79105278464723
Number of train steps total  356000
Number of env steps total    291953
Number of rollouts total     0
Train Time (s)               139.01898105069995
(Previous) Eval Time (s)     18.238343393895775
Sample Time (s)              10.12595839612186
Epoch Time (s)               167.38328284071758
Total Train Time (s)         16065.412812877446
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:23:37.890262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #88 | Epoch Duration: 167.4727041721344
2020-01-12 06:23:37.890492 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1448221
Z variance train             0.02283452
KL Divergence                23.356968
KL Loss                      2.335697
QF Loss                      488.17664
VF Loss                      230.66539
Policy Loss                  -684.84344
Q Predictions Mean           672.4157
Q Predictions Std            240.34409
Q Predictions Max            966.1811
Q Predictions Min            -48.577976
V Predictions Mean           689.605
V Predictions Std            232.08821
V Predictions Max            974.0711
V Predictions Min            -55.22654
Log Pis Mean                 -0.6276761
Log Pis Std                  3.213871
Log Pis Max                  24.37101
Log Pis Min                  -9.824659
Policy mu Mean               -0.02234854
Policy mu Std                0.5471166
Policy mu Max                3.2463582
Policy mu Min                -3.1276276
Policy log std Mean          -0.9673732
Policy log std Std           0.19086874
Policy log std Max           -0.465652
Policy log std Min           -1.79807
Z mean eval                  1.2047087
Z variance eval              0.047398448
total_rewards                [1428.5347378  2582.2768202   330.7520131  1825.85503151 1381.25274818
 2508.37941466  310.39136253  730.57519198  407.66310055 1258.78652452]
total_rewards_mean           1276.4466945016277
total_rewards_std            802.4642667198683
total_rewards_max            2582.2768202043253
total_rewards_min            310.39136252523383
Number of train steps total  360000
Number of env steps total    294381
Number of rollouts total     0
Train Time (s)               139.17070903722197
(Previous) Eval Time (s)     21.757069239392877
Sample Time (s)              11.1207689139992
Epoch Time (s)               172.04854719061404
Total Train Time (s)         16237.557006278541
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:26:30.036036 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #89 | Epoch Duration: 172.14535856246948
2020-01-12 06:26:30.036245 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2003437
Z variance train             0.04718084
KL Divergence                22.581547
KL Loss                      2.2581546
QF Loss                      408.64053
VF Loss                      92.31023
Policy Loss                  -689.47424
Q Predictions Mean           680.8055
Q Predictions Std            241.5346
Q Predictions Max            994.63214
Q Predictions Min            -38.44844
V Predictions Mean           688.7739
V Predictions Std            234.55101
V Predictions Max            994.29016
V Predictions Min            263.95886
Log Pis Mean                 -1.1015483
Log Pis Std                  2.7718318
Log Pis Max                  17.022345
Log Pis Min                  -7.618719
Policy mu Mean               0.025560157
Policy mu Std                0.52272683
Policy mu Max                3.138613
Policy mu Min                -3.7139118
Policy log std Mean          -0.9508126
Policy log std Std           0.17795783
Policy log std Max           -0.44104177
Policy log std Min           -1.6695013
Z mean eval                  1.1874223
Z variance eval              0.084575854
total_rewards                [ 818.91255808 1115.09795493 1356.01906716  343.97288078 2433.22985542
  822.96698589  114.91359282  652.09009677 1381.6995485    66.34419007]
total_rewards_mean           910.5246730395374
total_rewards_std            673.0838349769548
total_rewards_max            2433.229855415489
total_rewards_min            66.34419006702781
Number of train steps total  364000
Number of env steps total    297197
Number of rollouts total     0
Train Time (s)               142.7363701891154
(Previous) Eval Time (s)     20.07053046580404
Sample Time (s)              10.698087928351015
Epoch Time (s)               173.50498858327046
Total Train Time (s)         16411.15207260009
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:29:23.633160 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #90 | Epoch Duration: 173.596755027771
2020-01-12 06:29:23.633409 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1880497
Z variance train             0.08332236
KL Divergence                21.393791
KL Loss                      2.1393793
QF Loss                      445.12112
VF Loss                      208.15698
Policy Loss                  -673.4366
Q Predictions Mean           662.9707
Q Predictions Std            242.30661
Q Predictions Max            952.4997
Q Predictions Min            32.836906
V Predictions Mean           673.56445
V Predictions Std            238.22221
V Predictions Max            967.87994
V Predictions Min            93.65132
Log Pis Mean                 -1.1098332
Log Pis Std                  2.874198
Log Pis Max                  12.677047
Log Pis Min                  -7.18493
Policy mu Mean               0.0039720484
Policy mu Std                0.50807697
Policy mu Max                2.8588095
Policy mu Min                -3.5936587
Policy log std Mean          -0.9247241
Policy log std Std           0.1725116
Policy log std Max           -0.33340183
Policy log std Min           -1.6797452
Z mean eval                  1.234973
Z variance eval              0.03050841
total_rewards                [ 362.49971123  871.78819516  709.89777007 1454.3502866   539.44111884
 1267.95609825 2266.82117524 1380.89531855  589.59053678  402.77791984]
total_rewards_mean           984.6018130553905
total_rewards_std            571.8399739517938
total_rewards_max            2266.821175243238
total_rewards_min            362.4997112300458
Number of train steps total  368000
Number of env steps total    300366
Number of rollouts total     0
Train Time (s)               149.74878827203065
(Previous) Eval Time (s)     25.48033235874027
Sample Time (s)              13.41522840410471
Epoch Time (s)               188.64434903487563
Total Train Time (s)         16599.889000396244
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:32:32.371596 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #91 | Epoch Duration: 188.73803901672363
2020-01-12 06:32:32.371799 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.235505
Z variance train             0.030487454
KL Divergence                24.99808
KL Loss                      2.499808
QF Loss                      751.15247
VF Loss                      133.05278
Policy Loss                  -706.05585
Q Predictions Mean           694.6696
Q Predictions Std            244.16373
Q Predictions Max            989.132
Q Predictions Min            -60.29544
V Predictions Mean           709.3718
V Predictions Std            230.15465
V Predictions Max            987.97565
V Predictions Min            54.654816
Log Pis Mean                 -1.0057867
Log Pis Std                  3.209762
Log Pis Max                  14.72183
Log Pis Min                  -6.928317
Policy mu Mean               0.03630165
Policy mu Std                0.5391352
Policy mu Max                3.7545874
Policy mu Min                -2.4181561
Policy log std Mean          -0.93333185
Policy log std Std           0.17860714
Policy log std Max           -0.3476653
Policy log std Min           -1.8470552
Z mean eval                  1.1962261
Z variance eval              0.06054887
total_rewards                [  82.26423032 1309.16388056  317.73582345  851.77105252   79.95898993
   54.53783655 1389.97053456  619.80516263  126.68389638  335.21863326]
total_rewards_mean           516.7110040165732
total_rewards_std            482.82600555471
total_rewards_max            1389.9705345620068
total_rewards_min            54.537836551410905
Number of train steps total  372000
Number of env steps total    302842
Number of rollouts total     0
Train Time (s)               148.81009068526328
(Previous) Eval Time (s)     11.083523836918175
Sample Time (s)              11.630320203490555
Epoch Time (s)               171.523934725672
Total Train Time (s)         16771.517793381587
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:35:24.002767 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #92 | Epoch Duration: 171.63082242012024
2020-01-12 06:35:24.002964 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1923995
Z variance train             0.061139643
KL Divergence                24.204062
KL Loss                      2.420406
QF Loss                      793.83716
VF Loss                      143.4344
Policy Loss                  -680.03235
Q Predictions Mean           670.54553
Q Predictions Std            254.89995
Q Predictions Max            1023.2843
Q Predictions Min            42.877514
V Predictions Mean           682.17596
V Predictions Std            243.05876
V Predictions Max            1018.6321
V Predictions Min            241.73999
Log Pis Mean                 -1.1684391
Log Pis Std                  3.073365
Log Pis Max                  15.493124
Log Pis Min                  -8.933916
Policy mu Mean               -0.0071155652
Policy mu Std                0.51564217
Policy mu Max                2.508322
Policy mu Min                -3.050954
Policy log std Mean          -0.92680794
Policy log std Std           0.18978256
Policy log std Max           -0.35319665
Policy log std Min           -1.978929
Z mean eval                  1.1856841
Z variance eval              0.66064906
total_rewards                [1305.40073055 1454.08526646 2569.01860624  207.30556809  462.71122242
 1583.21427801  580.10251423  832.15842825  296.61974191   72.36353761]
total_rewards_mean           936.2979893766117
total_rewards_std            744.1520968970583
total_rewards_max            2569.018606240665
total_rewards_min            72.36353760956361
Number of train steps total  376000
Number of env steps total    305346
Number of rollouts total     0
Train Time (s)               147.6685678982176
(Previous) Eval Time (s)     16.13161423522979
Sample Time (s)              10.760169543325901
Epoch Time (s)               174.56035167677328
Total Train Time (s)         16946.181398151442
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:38:18.668136 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #93 | Epoch Duration: 174.6650218963623
2020-01-12 06:38:18.668349 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1699241
Z variance train             0.6536137
KL Divergence                20.405287
KL Loss                      2.0405288
QF Loss                      599.34326
VF Loss                      308.26935
Policy Loss                  -656.7255
Q Predictions Mean           652.09814
Q Predictions Std            255.32324
Q Predictions Max            989.92914
Q Predictions Min            64.57406
V Predictions Mean           658.47046
V Predictions Std            251.41638
V Predictions Max            987.9746
V Predictions Min            205.36296
Log Pis Mean                 -1.1932873
Log Pis Std                  2.9063413
Log Pis Max                  17.512894
Log Pis Min                  -8.273182
Policy mu Mean               0.034382455
Policy mu Std                0.5053118
Policy mu Max                3.9122071
Policy mu Min                -2.3325608
Policy log std Mean          -0.9514301
Policy log std Std           0.18332513
Policy log std Max           -0.2784801
Policy log std Min           -1.6057897
Z mean eval                  1.2639997
Z variance eval              0.015404969
total_rewards                [ 117.92201174  213.37886947 1281.94851929 2533.23189612 2590.39565797
  637.11346277  819.28874589 1305.0682978  2559.87984992  677.35906202]
total_rewards_mean           1273.5586372987761
total_rewards_std            916.6720595335402
total_rewards_max            2590.3956579671535
total_rewards_min            117.92201174418865
Number of train steps total  380000
Number of env steps total    308136
Number of rollouts total     0
Train Time (s)               147.5582202631049
(Previous) Eval Time (s)     24.68548820959404
Sample Time (s)              13.580032332800329
Epoch Time (s)               185.82374080549926
Total Train Time (s)         17132.095563327894
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:41:24.583962 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #94 | Epoch Duration: 185.91547060012817
2020-01-12 06:41:24.584143 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2667053
Z variance train             0.015330279
KL Divergence                25.928364
KL Loss                      2.5928364
QF Loss                      482.98724
VF Loss                      148.91621
Policy Loss                  -676.2685
Q Predictions Mean           669.2849
Q Predictions Std            255.9257
Q Predictions Max            1014.3653
Q Predictions Min            254.02249
V Predictions Mean           676.052
V Predictions Std            252.08888
V Predictions Max            1012.9043
V Predictions Min            233.3552
Log Pis Mean                 -1.2221296
Log Pis Std                  3.009971
Log Pis Max                  12.776218
Log Pis Min                  -9.707181
Policy mu Mean               -0.00927273
Policy mu Std                0.50666004
Policy mu Max                2.2866228
Policy mu Min                -2.6629224
Policy log std Mean          -0.9240497
Policy log std Std           0.18291092
Policy log std Max           -0.45637557
Policy log std Min           -1.6958327
Z mean eval                  1.2163854
Z variance eval              0.007557492
total_rewards                [1050.94330785  268.93927521 1563.87160619 1288.78499957 2042.08875265
  934.52627551 2638.86803586  143.02015271  476.54981432 2198.27699376]
total_rewards_mean           1260.586921364122
total_rewards_std            804.9685743938104
total_rewards_max            2638.86803586365
total_rewards_min            143.0201527135088
Number of train steps total  384000
Number of env steps total    311510
Number of rollouts total     0
Train Time (s)               141.61789701879025
(Previous) Eval Time (s)     21.93826209101826
Sample Time (s)              12.18146083317697
Epoch Time (s)               175.73761994298548
Total Train Time (s)         17307.92288214527
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:44:20.413704 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #95 | Epoch Duration: 175.82940196990967
2020-01-12 06:44:20.413947 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2197584
Z variance train             0.007523513
KL Divergence                26.727045
KL Loss                      2.6727045
QF Loss                      628.37933
VF Loss                      87.51657
Policy Loss                  -685.7674
Q Predictions Mean           676.74426
Q Predictions Std            252.86653
Q Predictions Max            1008.7613
Q Predictions Min            189.94412
V Predictions Mean           685.68677
V Predictions Std            247.12605
V Predictions Max            999.0443
V Predictions Min            282.09518
Log Pis Mean                 -1.0783896
Log Pis Std                  3.075821
Log Pis Max                  17.265766
Log Pis Min                  -9.898644
Policy mu Mean               0.003993692
Policy mu Std                0.5106444
Policy mu Max                3.1673808
Policy mu Min                -2.7711024
Policy log std Mean          -0.9252516
Policy log std Std           0.1791585
Policy log std Max           -0.43254465
Policy log std Min           -1.7615234
Z mean eval                  1.2026384
Z variance eval              0.02261879
total_rewards                [1305.55969977  986.18730301 1224.23241503 2191.05388767 1841.32470723
  832.05920341 1137.46163424 2476.69191388  831.18150632  218.465129  ]
total_rewards_mean           1304.4217399556164
total_rewards_std            648.8885593361658
total_rewards_max            2476.6919138755256
total_rewards_min            218.46512900141266
Number of train steps total  388000
Number of env steps total    314075
Number of rollouts total     0
Train Time (s)               140.31122437305748
(Previous) Eval Time (s)     24.55841604201123
Sample Time (s)              11.958357217721641
Epoch Time (s)               176.82799763279036
Total Train Time (s)         17484.840908899903
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:47:17.333324 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #96 | Epoch Duration: 176.9192087650299
2020-01-12 06:47:17.333578 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2015945
Z variance train             0.022426423
KL Divergence                23.823906
KL Loss                      2.3823907
QF Loss                      849.0974
VF Loss                      205.34795
Policy Loss                  -693.9183
Q Predictions Mean           682.7672
Q Predictions Std            259.47363
Q Predictions Max            1011.147
Q Predictions Min            -73.90362
V Predictions Mean           699.18945
V Predictions Std            246.30801
V Predictions Max            1011.4557
V Predictions Min            289.51468
Log Pis Mean                 -0.72654843
Log Pis Std                  3.6097398
Log Pis Max                  25.196428
Log Pis Min                  -7.1322474
Policy mu Mean               0.014805223
Policy mu Std                0.564737
Policy mu Max                4.1665077
Policy mu Min                -3.3849964
Policy log std Mean          -0.93727773
Policy log std Std           0.19471763
Policy log std Max           -0.34526062
Policy log std Min           -2.109959
Z mean eval                  1.1619077
Z variance eval              0.01427076
total_rewards                [1695.5513457   301.10650968 2673.46396385 1865.9269206  1964.61775986
 2772.84679337   17.34147245  310.98650661  351.77950332  152.9863408 ]
total_rewards_mean           1210.660711624517
total_rewards_std            1035.8681385038144
total_rewards_max            2772.846793374126
total_rewards_min            17.341472451308487
Number of train steps total  392000
Number of env steps total    316511
Number of rollouts total     0
Train Time (s)               142.17509068688378
(Previous) Eval Time (s)     20.892190949991345
Sample Time (s)              9.945095363538712
Epoch Time (s)               173.01237700041384
Total Train Time (s)         17657.96375869913
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:50:10.459404 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #97 | Epoch Duration: 173.12564325332642
2020-01-12 06:50:10.459665 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1656531
Z variance train             0.014277269
KL Divergence                25.955269
KL Loss                      2.595527
QF Loss                      694.4749
VF Loss                      135.01128
Policy Loss                  -683.8685
Q Predictions Mean           673.76
Q Predictions Std            261.34576
Q Predictions Max            1005.11066
Q Predictions Min            -58.52443
V Predictions Mean           682.062
V Predictions Std            254.21156
V Predictions Max            992.56683
V Predictions Min            83.3444
Log Pis Mean                 -0.898636
Log Pis Std                  2.9396951
Log Pis Max                  11.287434
Log Pis Min                  -9.723343
Policy mu Mean               -0.01987862
Policy mu Std                0.52384436
Policy mu Max                2.313381
Policy mu Min                -3.0903382
Policy log std Mean          -0.9422256
Policy log std Std           0.19293942
Policy log std Max           -0.3795081
Policy log std Min           -1.6927099
Z mean eval                  1.1643229
Z variance eval              0.013449127
total_rewards                [ 707.71298854  698.37630926 2648.2265651  1815.61393777 2292.12518808
  101.1887771  1041.50128668 1288.98289048 1669.90650436  430.40093164]
total_rewards_mean           1269.4035379008978
total_rewards_std            785.3918256561865
total_rewards_max            2648.2265651021594
total_rewards_min            101.18877709818337
Number of train steps total  396000
Number of env steps total    319086
Number of rollouts total     0
Train Time (s)               150.70688715716824
(Previous) Eval Time (s)     22.773365651722997
Sample Time (s)              12.588260620366782
Epoch Time (s)               186.06851342925802
Total Train Time (s)         17844.13222554326
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:53:16.629864 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #98 | Epoch Duration: 186.16997814178467
2020-01-12 06:53:16.630207 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1670195
Z variance train             0.013423249
KL Divergence                26.004799
KL Loss                      2.6004798
QF Loss                      450.21045
VF Loss                      165.82974
Policy Loss                  -709.1284
Q Predictions Mean           699.3596
Q Predictions Std            254.808
Q Predictions Max            1013.0004
Q Predictions Min            -73.04902
V Predictions Mean           711.374
V Predictions Std            245.94002
V Predictions Max            1003.19324
V Predictions Min            162.15494
Log Pis Mean                 -1.0176861
Log Pis Std                  3.0025523
Log Pis Max                  17.737122
Log Pis Min                  -8.505827
Policy mu Mean               -0.0030320135
Policy mu Std                0.53570646
Policy mu Max                3.180166
Policy mu Min                -3.0630846
Policy log std Mean          -0.94528776
Policy log std Std           0.18845743
Policy log std Max           -0.36966443
Policy log std Min           -1.7112688
Z mean eval                  1.4045141
Z variance eval              0.7563896
total_rewards                [2646.18319344  142.24564608  700.35381948 2522.07861034 1738.69496897
 1686.0092828  2609.94543116 2652.17711404 2360.08540198  411.92476798]
total_rewards_mean           1746.9698236266318
total_rewards_std            938.4077404558742
total_rewards_max            2652.1771140438013
total_rewards_min            142.2456460750306
Number of train steps total  400000
Number of env steps total    323170
Number of rollouts total     0
Train Time (s)               149.08501272182912
(Previous) Eval Time (s)     32.34722223691642
Sample Time (s)              13.263445565011352
Epoch Time (s)               194.6956805237569
Total Train Time (s)         18038.915907923132
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:56:31.415334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #99 | Epoch Duration: 194.78494143486023
2020-01-12 06:56:31.415521 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4059044
Z variance train             0.76517904
KL Divergence                22.504662
KL Loss                      2.250466
QF Loss                      849.4148
VF Loss                      270.9757
Policy Loss                  -630.32367
Q Predictions Mean           619.81604
Q Predictions Std            229.34232
Q Predictions Max            945.61224
Q Predictions Min            226.46065
V Predictions Mean           637.35425
V Predictions Std            227.43494
V Predictions Max            947.25476
V Predictions Min            243.71887
Log Pis Mean                 -0.8751
Log Pis Std                  3.2434585
Log Pis Max                  14.252442
Log Pis Min                  -8.381999
Policy mu Mean               0.026237804
Policy mu Std                0.5397209
Policy mu Max                3.7250288
Policy mu Min                -2.8840988
Policy log std Mean          -0.936098
Policy log std Std           0.19527143
Policy log std Max           -0.3714035
Policy log std Min           -1.824247
Z mean eval                  1.1881845
Z variance eval              0.026068568
total_rewards                [1739.18802385 1499.60852218 1538.61808211 1338.99531122 1406.79531699
  824.67391204 2521.11097736 1673.50479907 2117.99836945  163.19356973]
total_rewards_mean           1482.3686883993162
total_rewards_std            615.4684148401653
total_rewards_max            2521.110977363279
total_rewards_min            163.19356972896855
Number of train steps total  404000
Number of env steps total    325880
Number of rollouts total     0
Train Time (s)               149.10885492898524
(Previous) Eval Time (s)     31.579057666938752
Sample Time (s)              12.684067995287478
Epoch Time (s)               193.37198059121147
Total Train Time (s)         18232.381225489546
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:59:44.882721 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #100 | Epoch Duration: 193.46707105636597
2020-01-12 06:59:44.882915 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1856425
Z variance train             0.026010718
KL Divergence                23.534014
KL Loss                      2.3534014
QF Loss                      1212.2544
VF Loss                      160.64812
Policy Loss                  -697.7452
Q Predictions Mean           686.6853
Q Predictions Std            262.9664
Q Predictions Max            1027.658
Q Predictions Min            -12.898292
V Predictions Mean           703.06165
V Predictions Std            252.9054
V Predictions Max            1028.903
V Predictions Min            203.22842
Log Pis Mean                 -0.762094
Log Pis Std                  2.985682
Log Pis Max                  19.212181
Log Pis Min                  -6.462441
Policy mu Mean               -0.00056344504
Policy mu Std                0.53550655
Policy mu Max                2.629422
Policy mu Min                -3.173739
Policy log std Mean          -0.94255036
Policy log std Std           0.18340257
Policy log std Max           -0.42639345
Policy log std Min           -1.654099
Z mean eval                  1.1828663
Z variance eval              0.018161625
total_rewards                [ 179.74253211   75.55053992  742.17762579  396.37624377  937.09955318
  609.14761337 1001.94595705  636.2775699   491.3845811  2891.1363014 ]
total_rewards_mean           796.0838517604019
total_rewards_std            752.7649819520079
total_rewards_max            2891.1363014015033
total_rewards_min            75.55053992104845
Number of train steps total  408000
Number of env steps total    328573
Number of rollouts total     0
Train Time (s)               147.46990070398897
(Previous) Eval Time (s)     13.275358238257468
Sample Time (s)              12.115352084860206
Epoch Time (s)               172.86061102710664
Total Train Time (s)         18405.3396295188
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:02:37.843956 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #101 | Epoch Duration: 172.96087384223938
2020-01-12 07:02:37.844269 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.19462
Z variance train             0.017929439
KL Divergence                24.075367
KL Loss                      2.4075367
QF Loss                      404.22012
VF Loss                      122.19728
Policy Loss                  -716.20056
Q Predictions Mean           709.41846
Q Predictions Std            256.3584
Q Predictions Max            1025.7234
Q Predictions Min            -4.6772227
V Predictions Mean           713.36383
V Predictions Std            249.3921
V Predictions Max            999.1626
V Predictions Min            -20.465141
Log Pis Mean                 -0.94734436
Log Pis Std                  3.1572886
Log Pis Max                  18.045141
Log Pis Min                  -7.6790385
Policy mu Mean               0.00813631
Policy mu Std                0.5317549
Policy mu Max                3.5621057
Policy mu Min                -2.5343897
Policy log std Mean          -0.9434482
Policy log std Std           0.19731906
Policy log std Max           0.10577309
Policy log std Min           -1.8038874
Z mean eval                  1.2310461
Z variance eval              0.028850514
total_rewards                [ 866.08485432 1322.22265271  486.81168046  488.37276099 2636.51834946
  583.30263114  149.08703194 1870.39273733  148.82090766 1457.95519965]
total_rewards_mean           1000.9568805655703
total_rewards_std            769.0624451126928
total_rewards_max            2636.51834946131
total_rewards_min            148.82090766238616
Number of train steps total  412000
Number of env steps total    330969
Number of rollouts total     0
Train Time (s)               141.5538318771869
(Previous) Eval Time (s)     15.580198287963867
Sample Time (s)              11.846151850186288
Epoch Time (s)               168.98018201533705
Total Train Time (s)         18574.416989658028
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:05:26.923493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #102 | Epoch Duration: 169.07904624938965
2020-01-12 07:05:26.923756 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.23227
Z variance train             0.028811509
KL Divergence                23.010277
KL Loss                      2.3010278
QF Loss                      496.72375
VF Loss                      102.21991
Policy Loss                  -707.7411
Q Predictions Mean           697.45544
Q Predictions Std            269.3069
Q Predictions Max            1066.7131
Q Predictions Min            -22.761993
V Predictions Mean           704.23
V Predictions Std            263.23495
V Predictions Max            1046.2473
V Predictions Min            -10.073982
Log Pis Mean                 -0.7619128
Log Pis Std                  3.1796958
Log Pis Max                  16.480515
Log Pis Min                  -7.670928
Policy mu Mean               -0.01928762
Policy mu Std                0.5488704
Policy mu Max                3.0578592
Policy mu Min                -2.6635995
Policy log std Mean          -0.95350075
Policy log std Std           0.19010301
Policy log std Max           -0.18445164
Policy log std Min           -1.75857
Z mean eval                  1.1893642
Z variance eval              0.02558664
total_rewards                [ 699.96143016   44.00636564  772.7121605  1161.52560368 2397.23021424
  358.95975036   68.75547497  110.87883732 1021.48562547 2142.8997528 ]
total_rewards_mean           877.8415215154934
total_rewards_std            791.207272078459
total_rewards_max            2397.230214236981
total_rewards_min            44.00636564050856
Number of train steps total  416000
Number of env steps total    333724
Number of rollouts total     0
Train Time (s)               139.7117033773102
(Previous) Eval Time (s)     15.013571675401181
Sample Time (s)              11.393602922558784
Epoch Time (s)               166.11887797527015
Total Train Time (s)         18740.644320558757
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:08:13.152305 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #103 | Epoch Duration: 166.22837257385254
2020-01-12 07:08:13.152493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1844479
Z variance train             0.025486344
KL Divergence                23.21185
KL Loss                      2.3211849
QF Loss                      554.6378
VF Loss                      83.84252
Policy Loss                  -690.8
Q Predictions Mean           684.0313
Q Predictions Std            264.1507
Q Predictions Max            1027.625
Q Predictions Min            114.46675
V Predictions Mean           693.5632
V Predictions Std            258.5362
V Predictions Max            1030.8623
V Predictions Min            236.52548
Log Pis Mean                 -0.96016747
Log Pis Std                  2.908558
Log Pis Max                  16.182533
Log Pis Min                  -8.2673645
Policy mu Mean               0.019711828
Policy mu Std                0.50842047
Policy mu Max                2.3523364
Policy mu Min                -3.240733
Policy log std Mean          -0.93622696
Policy log std Std           0.18774635
Policy log std Max           -0.41915312
Policy log std Min           -1.7480972
Z mean eval                  1.18499
Z variance eval              0.083912276
total_rewards                [1620.34392375  913.25137752 1764.26746312 2768.93658335 1134.22614906
 1297.88192845 1210.14348907 1035.71241272 2742.29094692 1524.84560851]
total_rewards_mean           1601.1899882453488
total_rewards_std            628.8502126855664
total_rewards_max            2768.936583345872
total_rewards_min            913.2513775188597
Number of train steps total  420000
Number of env steps total    337492
Number of rollouts total     0
Train Time (s)               141.91873142682016
(Previous) Eval Time (s)     27.952119497116655
Sample Time (s)              11.67117317719385
Epoch Time (s)               181.54202410113066
Total Train Time (s)         18922.277907255106
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:11:14.788355 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #104 | Epoch Duration: 181.63570189476013
2020-01-12 07:11:14.788598 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1780264
Z variance train             0.082795724
KL Divergence                21.746748
KL Loss                      2.1746747
QF Loss                      648.4034
VF Loss                      148.46786
Policy Loss                  -704.0943
Q Predictions Mean           696.82324
Q Predictions Std            252.92471
Q Predictions Max            1038.6277
Q Predictions Min            -21.728788
V Predictions Mean           703.7053
V Predictions Std            247.66217
V Predictions Max            1040.9454
V Predictions Min            97.25739
Log Pis Mean                 -0.81949806
Log Pis Std                  3.261674
Log Pis Max                  23.688099
Log Pis Min                  -9.882176
Policy mu Mean               0.015001046
Policy mu Std                0.51556414
Policy mu Max                5.049064
Policy mu Min                -3.5040257
Policy log std Mean          -0.9562771
Policy log std Std           0.1913668
Policy log std Max           -0.2645886
Policy log std Min           -2.0391693
Z mean eval                  1.1786091
Z variance eval              0.022414032
total_rewards                [1988.2803805   538.36707929  718.8180298  2816.95266399 1068.93982935
 2590.17466603 1307.9277752   394.64576308  967.54454623 1908.24756483]
total_rewards_mean           1429.9898298311496
total_rewards_std            808.821317776031
total_rewards_max            2816.952663993755
total_rewards_min            394.645763082915
Number of train steps total  424000
Number of env steps total    340066
Number of rollouts total     0
Train Time (s)               150.5902577857487
(Previous) Eval Time (s)     26.686062366236
Sample Time (s)              11.314607525244355
Epoch Time (s)               188.59092767722905
Total Train Time (s)         19110.95905977767
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:14:23.470962 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #105 | Epoch Duration: 188.68220710754395
2020-01-12 07:14:23.471150 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1784738
Z variance train             0.022320902
KL Divergence                23.409782
KL Loss                      2.3409784
QF Loss                      565.25757
VF Loss                      103.27989
Policy Loss                  -697.07935
Q Predictions Mean           682.8908
Q Predictions Std            271.25946
Q Predictions Max            1040.8523
Q Predictions Min            78.36752
V Predictions Mean           698.29974
V Predictions Std            260.05048
V Predictions Max            1033.4651
V Predictions Min            231.62895
Log Pis Mean                 -0.74852633
Log Pis Std                  3.022689
Log Pis Max                  11.06682
Log Pis Min                  -6.774143
Policy mu Mean               0.0034270268
Policy mu Std                0.51976687
Policy mu Max                2.9239204
Policy mu Min                -2.6387255
Policy log std Mean          -0.95389056
Policy log std Std           0.18480453
Policy log std Max           -0.45996222
Policy log std Min           -1.638652
Z mean eval                  1.2020425
Z variance eval              0.029679656
total_rewards                [1757.56040281 2783.85429889  215.87649426 1364.15548138 1664.51719555
  741.96340853 1411.71769521 1368.93896142 1707.08015757  497.98361834]
total_rewards_mean           1351.3647713965124
total_rewards_std            695.3198533660773
total_rewards_max            2783.8542988867607
total_rewards_min            215.8764942636296
Number of train steps total  428000
Number of env steps total    343301
Number of rollouts total     0
Train Time (s)               150.3141428050585
(Previous) Eval Time (s)     32.811168246902525
Sample Time (s)              13.647091919090599
Epoch Time (s)               196.77240297105163
Total Train Time (s)         19307.833082031924
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:17:40.347268 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #106 | Epoch Duration: 196.87591886520386
2020-01-12 07:17:40.347472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.199724
Z variance train             0.029697295
KL Divergence                21.876318
KL Loss                      2.1876318
QF Loss                      1238.4348
VF Loss                      173.95712
Policy Loss                  -721.0546
Q Predictions Mean           711.021
Q Predictions Std            266.23642
Q Predictions Max            1029.3474
Q Predictions Min            179.40784
V Predictions Mean           724.3807
V Predictions Std            259.8167
V Predictions Max            1036.0559
V Predictions Min            197.77713
Log Pis Mean                 -0.80532527
Log Pis Std                  2.812141
Log Pis Max                  12.935959
Log Pis Min                  -7.327595
Policy mu Mean               -0.008082256
Policy mu Std                0.50991833
Policy mu Max                2.2702177
Policy mu Min                -2.869358
Policy log std Mean          -0.9676838
Policy log std Std           0.20965084
Policy log std Max           -0.23798883
Policy log std Min           -1.957107
Z mean eval                  1.2084926
Z variance eval              0.025618225
total_rewards                [ 604.72479335 2058.26777815  418.76534205  700.83225247  604.29359482
  369.09026674  947.94129621 2728.93425982 2782.6969662   871.99971553]
total_rewards_mean           1208.7546265349836
total_rewards_std            894.9117435378826
total_rewards_max            2782.6969662022475
total_rewards_min            369.0902667408525
Number of train steps total  432000
Number of env steps total    345862
Number of rollouts total     0
Train Time (s)               148.13354269461706
(Previous) Eval Time (s)     31.29202124942094
Sample Time (s)              11.97624830249697
Epoch Time (s)               191.40181224653497
Total Train Time (s)         19499.333084776532
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:20:51.849270 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #107 | Epoch Duration: 191.50163388252258
2020-01-12 07:20:51.849504 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1997672
Z variance train             0.025811207
KL Divergence                22.271435
KL Loss                      2.2271435
QF Loss                      569.19543
VF Loss                      111.519325
Policy Loss                  -731.47705
Q Predictions Mean           727.2247
Q Predictions Std            264.1154
Q Predictions Max            1034.2383
Q Predictions Min            -55.06044
V Predictions Mean           736.81836
V Predictions Std            261.37872
V Predictions Max            1032.6869
V Predictions Min            -15.613311
Log Pis Mean                 -0.9156616
Log Pis Std                  2.7314281
Log Pis Max                  7.623104
Log Pis Min                  -8.147697
Policy mu Mean               -0.008053245
Policy mu Std                0.49055606
Policy mu Max                2.3917818
Policy mu Min                -1.8552834
Policy log std Mean          -0.96677274
Policy log std Std           0.19318603
Policy log std Max           -0.37119138
Policy log std Min           -1.7349277
Z mean eval                  1.1291425
Z variance eval              0.023874087
total_rewards                [ 431.37604721  746.23988679  315.90296976 2512.41642014  294.91640843
 1267.00836626 1528.12656387  346.1537417   435.06572812  441.98414168]
total_rewards_mean           831.9190273983606
total_rewards_std            690.3628612052871
total_rewards_max            2512.416420143054
total_rewards_min            294.9164084303184
Number of train steps total  436000
Number of env steps total    349701
Number of rollouts total     0
Train Time (s)               147.4319291007705
(Previous) Eval Time (s)     15.101437343750149
Sample Time (s)              13.926837523467839
Epoch Time (s)               176.4602039679885
Total Train Time (s)         19675.894028866664
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:23:48.414811 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #108 | Epoch Duration: 176.56512117385864
2020-01-12 07:23:48.415119 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1241577
Z variance train             0.024169818
KL Divergence                23.132668
KL Loss                      2.3132668
QF Loss                      582.4058
VF Loss                      195.00264
Policy Loss                  -740.38464
Q Predictions Mean           725.5387
Q Predictions Std            268.5148
Q Predictions Max            1046.2181
Q Predictions Min            -113.166916
V Predictions Mean           733.79144
V Predictions Std            256.28745
V Predictions Max            1041.3759
V Predictions Min            -5.196641
Log Pis Mean                 -0.9112082
Log Pis Std                  3.1255755
Log Pis Max                  19.892836
Log Pis Min                  -9.354276
Policy mu Mean               0.0077122394
Policy mu Std                0.54291236
Policy mu Max                2.6458502
Policy mu Min                -3.0237277
Policy log std Mean          -0.9327481
Policy log std Std           0.18000269
Policy log std Max           -0.39342538
Policy log std Min           -1.7541506
Z mean eval                  1.2241414
Z variance eval              0.052397262
total_rewards                [ 814.82419841 1716.79264967 2443.61519419 2722.25373905 2889.05210913
  413.72768934  667.25414145  930.61013963 1018.2765354  1924.33729141]
total_rewards_mean           1554.0743687685808
total_rewards_std            860.8589781048922
total_rewards_max            2889.0521091344017
total_rewards_min            413.72768933798375
Number of train steps total  440000
Number of env steps total    352737
Number of rollouts total     0
Train Time (s)               140.17942601582035
(Previous) Eval Time (s)     30.96659741969779
Sample Time (s)              12.796581287868321
Epoch Time (s)               183.94260472338647
Total Train Time (s)         19859.923370459583
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:26:52.444625 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #109 | Epoch Duration: 184.02926182746887
2020-01-12 07:26:52.444808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2192131
Z variance train             0.051845025
KL Divergence                22.955036
KL Loss                      2.2955036
QF Loss                      528.5102
VF Loss                      127.622406
Policy Loss                  -739.5193
Q Predictions Mean           726.5459
Q Predictions Std            263.00082
Q Predictions Max            1021.0811
Q Predictions Min            63.73113
V Predictions Mean           735.48267
V Predictions Std            256.10358
V Predictions Max            1017.3048
V Predictions Min            87.656044
Log Pis Mean                 -0.5615777
Log Pis Std                  3.1787753
Log Pis Max                  18.178495
Log Pis Min                  -7.153151
Policy mu Mean               -0.028303921
Policy mu Std                0.54824406
Policy mu Max                2.9601283
Policy mu Min                -3.538616
Policy log std Mean          -0.988547
Policy log std Std           0.19629581
Policy log std Max           -0.51228535
Policy log std Min           -1.7078714
Z mean eval                  1.2440431
Z variance eval              0.045507304
total_rewards                [1659.07219587 2032.22854269  742.02070801  483.98322179 1810.62914891
  599.3035962   623.44857032 1222.15021258  806.16195165   75.0942532 ]
total_rewards_mean           1005.4092401211013
total_rewards_std            611.0849945855352
total_rewards_max            2032.2285426854235
total_rewards_min            75.09425320337905
Number of train steps total  444000
Number of env steps total    355581
Number of rollouts total     0
Train Time (s)               140.5376154370606
(Previous) Eval Time (s)     19.66283907974139
Sample Time (s)              12.424919695593417
Epoch Time (s)               172.6253742123954
Total Train Time (s)         20032.64284069417
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:29:45.166216 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #110 | Epoch Duration: 172.72127079963684
2020-01-12 07:29:45.166405 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2466434
Z variance train             0.045709614
KL Divergence                21.269304
KL Loss                      2.1269305
QF Loss                      401.81458
VF Loss                      110.24299
Policy Loss                  -747.3299
Q Predictions Mean           740.8229
Q Predictions Std            281.55185
Q Predictions Max            1112.6361
Q Predictions Min            -15.266952
V Predictions Mean           741.6024
V Predictions Std            275.73114
V Predictions Max            1098.8588
V Predictions Min            121.95724
Log Pis Mean                 -1.0608926
Log Pis Std                  2.741603
Log Pis Max                  9.648836
Log Pis Min                  -7.808818
Policy mu Mean               -0.013530593
Policy mu Std                0.49788705
Policy mu Max                2.572291
Policy mu Min                -3.4500067
Policy log std Mean          -0.94055367
Policy log std Std           0.17808428
Policy log std Max           -0.3917677
Policy log std Min           -2.1718655
Z mean eval                  1.1692455
Z variance eval              0.025938269
total_rewards                [ 641.09699224  338.79711868 1679.077023    926.3753358  1400.13077359
  112.44538511 1349.14142464 2948.14575942 2071.59581747 1134.2516779 ]
total_rewards_mean           1260.1057307844162
total_rewards_std            799.2113284663274
total_rewards_max            2948.1457594208987
total_rewards_min            112.44538510962633
Number of train steps total  448000
Number of env steps total    358130
Number of rollouts total     0
Train Time (s)               144.39525908092037
(Previous) Eval Time (s)     17.537349462974817
Sample Time (s)              12.113536758348346
Epoch Time (s)               174.04614530224353
Total Train Time (s)         20206.79023698205
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:32:39.315862 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #111 | Epoch Duration: 174.14930272102356
2020-01-12 07:32:39.316091 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1713603
Z variance train             0.026357811
KL Divergence                22.780106
KL Loss                      2.2780106
QF Loss                      674.5043
VF Loss                      177.05167
Policy Loss                  -738.8785
Q Predictions Mean           731.32385
Q Predictions Std            276.6838
Q Predictions Max            1083.653
Q Predictions Min            -23.981901
V Predictions Mean           738.595
V Predictions Std            269.33728
V Predictions Max            1083.604
V Predictions Min            -19.899296
Log Pis Mean                 -0.5094827
Log Pis Std                  3.6475441
Log Pis Max                  24.362461
Log Pis Min                  -7.780703
Policy mu Mean               -0.013209449
Policy mu Std                0.56307507
Policy mu Max                3.904347
Policy mu Min                -4.251239
Policy log std Mean          -0.9683077
Policy log std Std           0.20060329
Policy log std Max           -0.48378557
Policy log std Min           -2.0558243
Z mean eval                  1.2568767
Z variance eval              0.016016085
total_rewards                [1266.08942578 2650.61022634 2721.69243857 1003.08342342 2557.10958569
 2548.27562806 2579.51586597 2978.45007467 2675.75840588 2835.85057419]
total_rewards_mean           2381.643564857847
total_rewards_std            638.7142534796212
total_rewards_max            2978.4500746741733
total_rewards_min            1003.0834234170475
Number of train steps total  452000
Number of env steps total    360747
Number of rollouts total     0
Train Time (s)               150.8552286918275
(Previous) Eval Time (s)     33.77392952190712
Sample Time (s)              12.07982274191454
Epoch Time (s)               196.70898095564917
Total Train Time (s)         20403.597408267204
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:35:56.125780 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #112 | Epoch Duration: 196.80953741073608
2020-01-12 07:35:56.126003 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2609813
Z variance train             0.016032819
KL Divergence                23.336248
KL Loss                      2.3336248
QF Loss                      617.11035
VF Loss                      172.41931
Policy Loss                  -728.08344
Q Predictions Mean           721.6946
Q Predictions Std            291.4688
Q Predictions Max            1071.8235
Q Predictions Min            -9.420805
V Predictions Mean           725.3163
V Predictions Std            287.82007
V Predictions Max            1056.8982
V Predictions Min            -22.516733
Log Pis Mean                 -0.6551963
Log Pis Std                  3.7298946
Log Pis Max                  35.090363
Log Pis Min                  -7.094599
Policy mu Mean               -0.004371766
Policy mu Std                0.57500744
Policy mu Max                3.2538865
Policy mu Min                -3.6857424
Policy log std Mean          -0.93919975
Policy log std Std           0.1999095
Policy log std Max           -0.42103627
Policy log std Min           -1.7413638
Z mean eval                  1.1868583
Z variance eval              0.018665303
total_rewards                [ 841.83563121 1707.74573728 2686.1984459    52.61663347  432.68513385
 2757.5790415  2869.7420662  1448.16300349 1199.69763602 2646.38978557]
total_rewards_mean           1664.2653114502457
total_rewards_std            985.5166455487896
total_rewards_max            2869.742066198073
total_rewards_min            52.61663347437205
Number of train steps total  456000
Number of env steps total    363366
Number of rollouts total     0
Train Time (s)               149.59832997899503
(Previous) Eval Time (s)     22.316159031819552
Sample Time (s)              11.465562609490007
Epoch Time (s)               183.38005162030458
Total Train Time (s)         20587.0748666008
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:38:59.605036 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #113 | Epoch Duration: 183.47888255119324
2020-01-12 07:38:59.605234 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1869998
Z variance train             0.018682227
KL Divergence                22.537476
KL Loss                      2.2537477
QF Loss                      535.88684
VF Loss                      88.85633
Policy Loss                  -712.68256
Q Predictions Mean           707.191
Q Predictions Std            279.67505
Q Predictions Max            1061.3085
Q Predictions Min            3.0145183
V Predictions Mean           715.9048
V Predictions Std            275.30353
V Predictions Max            1063.4574
V Predictions Min            151.8456
Log Pis Mean                 -1.0065362
Log Pis Std                  2.7486317
Log Pis Max                  12.23478
Log Pis Min                  -8.1629505
Policy mu Mean               -0.004092385
Policy mu Std                0.50975114
Policy mu Max                3.441691
Policy mu Min                -3.70509
Policy log std Mean          -0.93502307
Policy log std Std           0.18522097
Policy log std Max           -0.15008134
Policy log std Min           -1.6152222
Z mean eval                  1.1983097
Z variance eval              0.01760152
total_rewards                [1070.03579321  956.1676483  1325.1268431   902.56143262 1744.26296185
  799.35891707 1335.09772057 1822.47055222  336.61283456 3011.21583242]
total_rewards_mean           1330.291053591733
total_rewards_std            699.9364523348146
total_rewards_max            3011.215832423239
total_rewards_min            336.61283456105014
Number of train steps total  460000
Number of env steps total    366670
Number of rollouts total     0
Train Time (s)               150.3957328191027
(Previous) Eval Time (s)     24.45816924981773
Sample Time (s)              11.531442787498236
Epoch Time (s)               186.38534485641867
Total Train Time (s)         20773.56439588964
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:42:06.097817 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #114 | Epoch Duration: 186.49240612983704
2020-01-12 07:42:06.098133 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1981562
Z variance train             0.017667264
KL Divergence                23.490536
KL Loss                      2.3490536
QF Loss                      653.845
VF Loss                      159.14651
Policy Loss                  -751.23615
Q Predictions Mean           743.2565
Q Predictions Std            284.1407
Q Predictions Max            1084.7335
Q Predictions Min            19.607851
V Predictions Mean           755.3655
V Predictions Std            273.8338
V Predictions Max            1086.0898
V Predictions Min            131.29306
Log Pis Mean                 -0.56989753
Log Pis Std                  3.6724217
Log Pis Max                  24.759424
Log Pis Min                  -7.742811
Policy mu Mean               -0.0131042
Policy mu Std                0.57632995
Policy mu Max                3.612392
Policy mu Min                -3.511208
Policy log std Mean          -0.9507531
Policy log std Std           0.20208374
Policy log std Max           -0.44472122
Policy log std Min           -1.9679241
Z mean eval                  1.1794614
Z variance eval              0.014909816
total_rewards                [2144.14234745 1399.98755936  362.44880516 1849.15226068  665.31435533
  102.96514499 2852.60688677 2845.75469754  808.70310001 1547.65933001]
total_rewards_mean           1457.873448729582
total_rewards_std            926.9452968857389
total_rewards_max            2852.606886771931
total_rewards_min            102.96514498619877
Number of train steps total  464000
Number of env steps total    369128
Number of rollouts total     0
Train Time (s)               148.93439111905172
(Previous) Eval Time (s)     26.91524377092719
Sample Time (s)              11.679001712240279
Epoch Time (s)               187.5286366022192
Total Train Time (s)         20961.193675473332
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:45:13.730727 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #115 | Epoch Duration: 187.63234901428223
2020-01-12 07:45:13.731309 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1794183
Z variance train             0.0147040505
KL Divergence                23.36792
KL Loss                      2.336792
QF Loss                      991.2019
VF Loss                      135.84424
Policy Loss                  -742.76636
Q Predictions Mean           742.61707
Q Predictions Std            281.03473
Q Predictions Max            1075.4535
Q Predictions Min            249.65416
V Predictions Mean           747.8445
V Predictions Std            279.8377
V Predictions Max            1073.7322
V Predictions Min            251.60597
Log Pis Mean                 -0.8049051
Log Pis Std                  2.7261596
Log Pis Max                  12.328889
Log Pis Min                  -6.4361506
Policy mu Mean               -0.02287642
Policy mu Std                0.50456494
Policy mu Max                2.341614
Policy mu Min                -2.334914
Policy log std Mean          -0.9631993
Policy log std Std           0.19460113
Policy log std Max           -0.5582044
Policy log std Min           -2.1786747
Z mean eval                  1.11424
Z variance eval              0.013523626
total_rewards                [ 299.55317632 1468.40450983 2816.89349309 1325.77768443 2882.56706212
  484.18178376 1510.40171038 2806.85255172 1905.18995851  212.12950832]
total_rewards_mean           1571.19514384775
total_rewards_std            981.3299484273974
total_rewards_max            2882.5670621150684
total_rewards_min            212.12950831618122
Number of train steps total  468000
Number of env steps total    372395
Number of rollouts total     0
Train Time (s)               140.42744745174423
(Previous) Eval Time (s)     22.113817093893886
Sample Time (s)              11.178434839472175
Epoch Time (s)               173.7196993851103
Total Train Time (s)         21135.004313215613
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:48:07.542584 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #116 | Epoch Duration: 173.81096386909485
2020-01-12 07:48:07.542921 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1166724
Z variance train             0.01361047
KL Divergence                22.953213
KL Loss                      2.2953212
QF Loss                      825.42706
VF Loss                      213.89532
Policy Loss                  -774.0851
Q Predictions Mean           765.22876
Q Predictions Std            259.1822
Q Predictions Max            1077.4713
Q Predictions Min            6.683446
V Predictions Mean           769.1414
V Predictions Std            252.374
V Predictions Max            1077.9125
V Predictions Min            -19.144754
Log Pis Mean                 -0.38448292
Log Pis Std                  3.0846794
Log Pis Max                  20.605793
Log Pis Min                  -7.63621
Policy mu Mean               -0.029548422
Policy mu Std                0.5650733
Policy mu Max                4.098235
Policy mu Min                -3.1899736
Policy log std Mean          -0.9853367
Policy log std Std           0.20245197
Policy log std Max           0.23256779
Policy log std Min           -1.7879891
Z mean eval                  1.1204503
Z variance eval              0.012819904
total_rewards                [2744.51599694  822.98421779  312.80538656  657.55622102  528.86622948
 2639.90205041  641.7314385  1855.85675547  921.78573565 2844.26373106]
total_rewards_mean           1397.026776287327
total_rewards_std            962.6729097624138
total_rewards_max            2844.263731062358
total_rewards_min            312.8053865564277
Number of train steps total  472000
Number of env steps total    375983
Number of rollouts total     0
Train Time (s)               140.62084043910727
(Previous) Eval Time (s)     24.458904735744
Sample Time (s)              11.831009136978537
Epoch Time (s)               176.9107543118298
Total Train Time (s)         21312.018754696473
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:51:04.557061 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #117 | Epoch Duration: 177.01392483711243
2020-01-12 07:51:04.557189 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1231796
Z variance train             0.012811559
KL Divergence                23.355318
KL Loss                      2.335532
QF Loss                      571.0654
VF Loss                      166.9462
Policy Loss                  -723.30414
Q Predictions Mean           714.4071
Q Predictions Std            294.45886
Q Predictions Max            1111.9608
Q Predictions Min            -38.27729
V Predictions Mean           728.27966
V Predictions Std            285.6832
V Predictions Max            1111.2638
V Predictions Min            125.61362
Log Pis Mean                 -1.0217962
Log Pis Std                  2.9056268
Log Pis Max                  8.714205
Log Pis Min                  -9.921772
Policy mu Mean               -0.0123044485
Policy mu Std                0.5128706
Policy mu Max                2.6254694
Policy mu Min                -2.9351265
Policy log std Mean          -0.9487059
Policy log std Std           0.19589001
Policy log std Max           -0.36464268
Policy log std Min           -1.9640305
Z mean eval                  1.2063249
Z variance eval              0.012312335
total_rewards                [ 597.200229    284.34179841 3051.63437916 1534.94085842 2870.63281254
 2767.11982671 2856.07318006 2880.40125908 2620.21269796  903.89910746]
total_rewards_mean           2036.645614880099
total_rewards_std            1032.5046765331117
total_rewards_max            3051.634379155291
total_rewards_min            284.3417984103032
Number of train steps total  476000
Number of env steps total    378568
Number of rollouts total     0
Train Time (s)               144.46397626120597
(Previous) Eval Time (s)     25.0167925930582
Sample Time (s)              9.96308746933937
Epoch Time (s)               179.44385632360354
Total Train Time (s)         21491.545970292762
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:54:04.085352 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #118 | Epoch Duration: 179.528071641922
2020-01-12 07:54:04.085473 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2078397
Z variance train             0.012216947
KL Divergence                23.442036
KL Loss                      2.3442037
QF Loss                      419.6413
VF Loss                      171.22318
Policy Loss                  -760.79895
Q Predictions Mean           754.4415
Q Predictions Std            292.20218
Q Predictions Max            1098.5768
Q Predictions Min            -8.344828
V Predictions Mean           760.5404
V Predictions Std            284.42548
V Predictions Max            1103.4491
V Predictions Min            25.475971
Log Pis Mean                 -0.80802596
Log Pis Std                  2.9598312
Log Pis Max                  13.320987
Log Pis Min                  -8.464307
Policy mu Mean               -0.004784617
Policy mu Std                0.5331027
Policy mu Max                3.238746
Policy mu Min                -3.5093694
Policy log std Mean          -0.96271384
Policy log std Std           0.19890799
Policy log std Max           -0.35773683
Policy log std Min           -2.025497
Z mean eval                  1.186559
Z variance eval              0.014499009
total_rewards                [1884.79827721 3025.5498914  1341.85049542 1863.37825496 2855.55020434
  963.87968776 3018.91780633 1757.36479763 1696.95398281 1594.52082138]
total_rewards_mean           2000.2764219257756
total_rewards_std            683.7891903272961
total_rewards_max            3025.5498914005093
total_rewards_min            963.8796877625564
Number of train steps total  480000
Number of env steps total    380959
Number of rollouts total     0
Train Time (s)               150.5444938247092
(Previous) Eval Time (s)     32.262655295897275
Sample Time (s)              10.892680305521935
Epoch Time (s)               193.69982942612842
Total Train Time (s)         21685.34272231674
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:57:17.885541 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #119 | Epoch Duration: 193.79994010925293
2020-01-12 07:57:17.885808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1873422
Z variance train             0.014543986
KL Divergence                22.772318
KL Loss                      2.277232
QF Loss                      628.01465
VF Loss                      143.7021
Policy Loss                  -762.187
Q Predictions Mean           756.5292
Q Predictions Std            282.07733
Q Predictions Max            1107.477
Q Predictions Min            -9.158906
V Predictions Mean           763.202
V Predictions Std            280.625
V Predictions Max            1096.698
V Predictions Min            7.6715517
Log Pis Mean                 -0.8939019
Log Pis Std                  2.9178884
Log Pis Max                  14.5699215
Log Pis Min                  -9.082886
Policy mu Mean               0.0036713742
Policy mu Std                0.5227865
Policy mu Max                2.3347538
Policy mu Min                -2.693841
Policy log std Mean          -0.95980114
Policy log std Std           0.21033283
Policy log std Max           -0.4188942
Policy log std Min           -2.054077
Z mean eval                  1.1792688
Z variance eval              0.00892377
total_rewards                [1273.64681657 1662.67274602 2919.30751122 2702.23028437  740.09099433
  758.59192301  856.31863115 2870.43089451 3101.22019656  640.89887323]
total_rewards_mean           1752.5408870972715
total_rewards_std            980.8789780646864
total_rewards_max            3101.2201965578433
total_rewards_min            640.8988732343362
Number of train steps total  484000
Number of env steps total    384850
Number of rollouts total     0
Train Time (s)               149.49381318408996
(Previous) Eval Time (s)     37.47662839572877
Sample Time (s)              11.844850849360228
Epoch Time (s)               198.81529242917895
Total Train Time (s)         21884.248824388254
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:00:36.793758 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #120 | Epoch Duration: 198.9077503681183
2020-01-12 08:00:36.794026 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1720598
Z variance train             0.008936721
KL Divergence                23.829826
KL Loss                      2.3829827
QF Loss                      665.7984
VF Loss                      139.53708
Policy Loss                  -818.2946
Q Predictions Mean           813.22034
Q Predictions Std            245.28125
Q Predictions Max            1141.7891
Q Predictions Min            125.278275
V Predictions Mean           821.12366
V Predictions Std            239.31467
V Predictions Max            1113.6293
V Predictions Min            250.91399
Log Pis Mean                 -0.45409578
Log Pis Std                  3.0468414
Log Pis Max                  12.136347
Log Pis Min                  -8.285576
Policy mu Mean               -0.0006897814
Policy mu Std                0.5653476
Policy mu Max                2.4925296
Policy mu Min                -3.1051881
Policy log std Mean          -0.98610723
Policy log std Std           0.19695272
Policy log std Max           -0.36832
Policy log std Min           -1.867834
Z mean eval                  1.1612804
Z variance eval              0.011145163
total_rewards                [2848.80542056  559.52136509 2569.43138561  275.69636683  503.20770092
 3109.20541191 2850.59851905  799.44811053 1294.92939647 2950.80990593]
total_rewards_mean           1776.165358290053
total_rewards_std            1123.7720204346379
total_rewards_max            3109.2054119137274
total_rewards_min            275.6963668259198
Number of train steps total  488000
Number of env steps total    387524
Number of rollouts total     0
Train Time (s)               151.49058814765885
(Previous) Eval Time (s)     30.74880336318165
Sample Time (s)              11.672630154527724
Epoch Time (s)               193.91202166536823
Total Train Time (s)         22078.24624991184
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:03:50.793807 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #121 | Epoch Duration: 193.99960446357727
2020-01-12 08:03:50.794026 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1640316
Z variance train             0.011263423
KL Divergence                23.538973
KL Loss                      2.3538973
QF Loss                      432.3108
VF Loss                      141.15634
Policy Loss                  -792.0803
Q Predictions Mean           781.9409
Q Predictions Std            280.73608
Q Predictions Max            1128.5721
Q Predictions Min            1.2735441
V Predictions Mean           786.9536
V Predictions Std            273.18588
V Predictions Max            1126.1804
V Predictions Min            -16.273178
Log Pis Mean                 -0.8484798
Log Pis Std                  2.9197567
Log Pis Max                  10.543903
Log Pis Min                  -9.91643
Policy mu Mean               0.031716675
Policy mu Std                0.52878857
Policy mu Max                2.880226
Policy mu Min                -2.0272212
Policy log std Mean          -0.95742434
Policy log std Std           0.19732535
Policy log std Max           -0.4337026
Policy log std Min           -1.9285322
Z mean eval                  1.1712496
Z variance eval              0.019514972
total_rewards                [2815.87871906  599.66174057  549.7898018  1618.0215273  2840.56226182
 1948.77679548 1836.98016751  880.37461056 2936.66301354 2901.06088458]
total_rewards_mean           1892.7769522235496
total_rewards_std            918.6516318855655
total_rewards_max            2936.6630135431096
total_rewards_min            549.7898018045818
Number of train steps total  492000
Number of env steps total    391298
Number of rollouts total     0
Train Time (s)               149.36278107389808
(Previous) Eval Time (s)     27.227180724032223
Sample Time (s)              11.448110319208354
Epoch Time (s)               188.03807211713865
Total Train Time (s)         22266.456021012273
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:06:59.004785 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #122 | Epoch Duration: 188.21058893203735
2020-01-12 08:06:59.004979 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1700119
Z variance train             0.019505776
KL Divergence                20.987007
KL Loss                      2.0987008
QF Loss                      968.9841
VF Loss                      219.41904
Policy Loss                  -759.4806
Q Predictions Mean           751.5384
Q Predictions Std            277.07233
Q Predictions Max            1098.345
Q Predictions Min            183.26567
V Predictions Mean           761.6185
V Predictions Std            271.7443
V Predictions Max            1097.0347
V Predictions Min            99.46009
Log Pis Mean                 -0.34346023
Log Pis Std                  3.4711552
Log Pis Max                  14.29633
Log Pis Min                  -7.962785
Policy mu Mean               -0.0053412556
Policy mu Std                0.57549435
Policy mu Max                2.4225266
Policy mu Min                -2.6897168
Policy log std Mean          -0.9800773
Policy log std Std           0.2027248
Policy log std Max           -0.46812034
Policy log std Min           -2.154329
Z mean eval                  1.1503068
Z variance eval              0.027142882
total_rewards                [ 242.48284515 1796.97560431  222.3674866  2753.7469958  1007.34821304
 1921.83888223   98.39788849 2122.05186453  146.64257274 2289.2960562 ]
total_rewards_mean           1260.1148409107425
total_rewards_std            975.9598759532796
total_rewards_max            2753.7469958028037
total_rewards_min            98.39788849486104
Number of train steps total  496000
Number of env steps total    394160
Number of rollouts total     0
Train Time (s)               140.06021972186863
(Previous) Eval Time (s)     18.27461751597002
Sample Time (s)              10.926793847233057
Epoch Time (s)               169.2616310850717
Total Train Time (s)         22435.80960387923
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:09:48.360511 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #123 | Epoch Duration: 169.35539388656616
2020-01-12 08:09:48.360689 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1522881
Z variance train             0.027246708
KL Divergence                21.487074
KL Loss                      2.1487074
QF Loss                      447.71655
VF Loss                      100.50954
Policy Loss                  -779.3018
Q Predictions Mean           769.4165
Q Predictions Std            285.47388
Q Predictions Max            1135.9706
Q Predictions Min            -14.822797
V Predictions Mean           779.7927
V Predictions Std            275.00836
V Predictions Max            1118.1937
V Predictions Min            -9.149947
Log Pis Mean                 -0.48241773
Log Pis Std                  3.1608095
Log Pis Max                  12.839839
Log Pis Min                  -7.6355433
Policy mu Mean               -0.0026376713
Policy mu Std                0.5659814
Policy mu Max                3.4212976
Policy mu Min                -2.9489377
Policy log std Mean          -0.97365904
Policy log std Std           0.20164257
Policy log std Max           -0.35707092
Policy log std Min           -1.8823364
Z mean eval                  1.1195335
Z variance eval              0.0113448715
total_rewards                [ 687.30755923  886.75396767 2681.23379    2982.19112021  418.50871207
 3037.80270103 1803.04184621  206.41022801 2519.31350205 2888.87873336]
total_rewards_mean           1811.1442159836818
total_rewards_std            1092.1671032799388
total_rewards_max            3037.802701030734
total_rewards_min            206.41022800519056
Number of train steps total  500000
Number of env steps total    397525
Number of rollouts total     0
Train Time (s)               140.4370355317369
(Previous) Eval Time (s)     24.443831162992865
Sample Time (s)              10.934117577504367
Epoch Time (s)               175.81498427223414
Total Train Time (s)         22611.720773576293
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:12:44.274181 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #124 | Epoch Duration: 175.91334128379822
2020-01-12 08:12:44.274395 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1131226
Z variance train             0.011344416
KL Divergence                22.983644
KL Loss                      2.2983644
QF Loss                      517.72217
VF Loss                      94.585106
Policy Loss                  -824.15375
Q Predictions Mean           817.9223
Q Predictions Std            284.04062
Q Predictions Max            1129.8013
Q Predictions Min            11.685181
V Predictions Mean           823.61426
V Predictions Std            278.20428
V Predictions Max            1130.4525
V Predictions Min            44.825893
Log Pis Mean                 -0.6191057
Log Pis Std                  3.0068185
Log Pis Max                  11.802323
Log Pis Min                  -10.9113035
Policy mu Mean               -0.026299104
Policy mu Std                0.5736685
Policy mu Max                4.1981697
Policy mu Min                -3.1608222
Policy log std Mean          -0.9768865
Policy log std Std           0.19225241
Policy log std Max           0.03991449
Policy log std Min           -1.9523828
Z mean eval                  1.1332335
Z variance eval              0.0114903245
total_rewards                [2866.38872434 2076.10564251  600.25179769 2932.82721346 2964.70648693
  127.77576986  602.15197136  597.08637778 3031.57930638 3231.83089209]
total_rewards_mean           1903.070418240257
total_rewards_std            1201.312649598304
total_rewards_max            3231.8308920933173
total_rewards_min            127.77576986220973
Number of train steps total  504000
Number of env steps total    402469
Number of rollouts total     0
Train Time (s)               145.77745071286336
(Previous) Eval Time (s)     25.233150132000446
Sample Time (s)              10.577118886634707
Epoch Time (s)               181.5877197314985
Total Train Time (s)         22793.406179464422
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:15:45.962004 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #125 | Epoch Duration: 181.6874349117279
2020-01-12 08:15:45.962245 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1381603
Z variance train             0.011506712
KL Divergence                22.646515
KL Loss                      2.2646515
QF Loss                      517.04175
VF Loss                      158.70564
Policy Loss                  -807.904
Q Predictions Mean           801.4813
Q Predictions Std            283.52686
Q Predictions Max            1117.013
Q Predictions Min            -3.1770456
V Predictions Mean           806.2134
V Predictions Std            282.26337
V Predictions Max            1123.7858
V Predictions Min            -9.081616
Log Pis Mean                 -0.5076507
Log Pis Std                  2.6960764
Log Pis Max                  12.347558
Log Pis Min                  -7.176537
Policy mu Mean               -0.008803956
Policy mu Std                0.5025406
Policy mu Max                3.135456
Policy mu Min                -1.7622532
Policy log std Mean          -0.9946493
Policy log std Std           0.2053684
Policy log std Max           -0.3482101
Policy log std Min           -2.1789553
Z mean eval                  1.159205
Z variance eval              0.015541822
total_rewards                [ 404.34719528 2889.91895311 1364.10431554 1592.22052662  289.74735559
  459.0474363  2416.40382942 2660.49754678 1165.56170723 2938.12447719]
total_rewards_mean           1617.9973343041727
total_rewards_std            996.7428725426875
total_rewards_max            2938.1244771870224
total_rewards_min            289.7473555869103
Number of train steps total  508000
Number of env steps total    406017
Number of rollouts total     0
Train Time (s)               150.7575328652747
(Previous) Eval Time (s)     24.812071609310806
Sample Time (s)              12.484296469017863
Epoch Time (s)               188.05390094360337
Total Train Time (s)         22981.731161049567
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:18:54.289752 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #126 | Epoch Duration: 188.32731342315674
2020-01-12 08:18:54.290072 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.157521
Z variance train             0.01541495
KL Divergence                22.250525
KL Loss                      2.2250526
QF Loss                      519.36975
VF Loss                      225.66037
Policy Loss                  -804.39655
Q Predictions Mean           795.5064
Q Predictions Std            293.3754
Q Predictions Max            1112.5254
Q Predictions Min            -21.443
V Predictions Mean           812.03296
V Predictions Std            284.8915
V Predictions Max            1121.769
V Predictions Min            71.39479
Log Pis Mean                 -0.41640753
Log Pis Std                  2.8125606
Log Pis Max                  11.773989
Log Pis Min                  -8.2122555
Policy mu Mean               -0.001779808
Policy mu Std                0.54893786
Policy mu Max                2.5483963
Policy mu Min                -2.8134825
Policy log std Mean          -0.9774939
Policy log std Std           0.19674905
Policy log std Max           -0.065297544
Policy log std Min           -1.9522874
Z mean eval                  1.2003047
Z variance eval              0.008175116
total_rewards                [2782.99088545  280.56243603 3019.52915092  823.8904327  2126.21439853
  761.50926467 1367.35599311  708.39384206 2595.22278145 1557.29984875]
total_rewards_mean           1602.2969033656682
total_rewards_std            926.2334480185307
total_rewards_max            3019.5291509162594
total_rewards_min            280.56243602894983
Number of train steps total  512000
Number of env steps total    409031
Number of rollouts total     0
Train Time (s)               150.9224638720043
(Previous) Eval Time (s)     28.286595177836716
Sample Time (s)              12.375379799399525
Epoch Time (s)               191.58443884924054
Total Train Time (s)         23173.446108032018
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:22:06.007456 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #127 | Epoch Duration: 191.71717238426208
2020-01-12 08:22:06.007743 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2071818
Z variance train             0.008193837
KL Divergence                23.403765
KL Loss                      2.3403766
QF Loss                      1014.6944
VF Loss                      241.38724
Policy Loss                  -795.46185
Q Predictions Mean           788.6599
Q Predictions Std            294.9337
Q Predictions Max            1118.5267
Q Predictions Min            226.59619
V Predictions Mean           795.2191
V Predictions Std            291.81125
V Predictions Max            1128.1348
V Predictions Min            220.07843
Log Pis Mean                 -0.66540635
Log Pis Std                  3.118186
Log Pis Max                  22.978985
Log Pis Min                  -7.357247
Policy mu Mean               0.008649841
Policy mu Std                0.52467585
Policy mu Max                2.9844315
Policy mu Min                -3.987068
Policy log std Mean          -0.98285544
Policy log std Std           0.20479491
Policy log std Max           -0.31672585
Policy log std Min           -1.8172469
Z mean eval                  1.1540805
Z variance eval              0.01608259
total_rewards                [2963.64730331 3067.73557776 3139.44269976  749.19181933  184.03364572
  979.38863266  584.07047912 2273.47144033  657.15926006 2276.5383842 ]
total_rewards_mean           1687.467924225553
total_rewards_std            1106.9544844637287
total_rewards_max            3139.4426997564933
total_rewards_min            184.03364571853382
Number of train steps total  516000
Number of env steps total    411827
Number of rollouts total     0
Train Time (s)               151.360485218931
(Previous) Eval Time (s)     32.1967323217541
Sample Time (s)              10.74459178885445
Epoch Time (s)               194.30180932953954
Total Train Time (s)         23367.851199313533
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:25:20.414615 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #128 | Epoch Duration: 194.40669679641724
2020-01-12 08:25:20.414828 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1472328
Z variance train             0.015836507
KL Divergence                22.127733
KL Loss                      2.2127733
QF Loss                      678.364
VF Loss                      104.59293
Policy Loss                  -797.8026
Q Predictions Mean           793.4234
Q Predictions Std            296.7691
Q Predictions Max            1122.8052
Q Predictions Min            232.74776
V Predictions Mean           798.16437
V Predictions Std            293.4541
V Predictions Max            1126.1248
V Predictions Min            243.68437
Log Pis Mean                 -0.90891546
Log Pis Std                  3.0042756
Log Pis Max                  17.701506
Log Pis Min                  -9.133039
Policy mu Mean               -0.027527591
Policy mu Std                0.5198928
Policy mu Max                4.2899094
Policy mu Min                -2.9806836
Policy log std Mean          -0.9608575
Policy log std Std           0.18993533
Policy log std Max           -0.53044295
Policy log std Min           -1.7634139
Z mean eval                  1.1798004
Z variance eval              0.016319988
total_rewards                [2676.62400972 2860.02458636 2998.95340306 2791.69266177 2801.52405873
 1041.25092786 1541.55029644 1214.69408264  799.72796158 2868.53799009]
total_rewards_mean           2159.457997826756
total_rewards_std            845.6602333195184
total_rewards_max            2998.953403063352
total_rewards_min            799.7279615802479
Number of train steps total  520000
Number of env steps total    415834
Number of rollouts total     0
Train Time (s)               149.40381304593757
(Previous) Eval Time (s)     31.463661228772253
Sample Time (s)              10.995336323510855
Epoch Time (s)               191.86281059822068
Total Train Time (s)         23559.890665100887
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:28:32.456410 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #129 | Epoch Duration: 192.04141283035278
2020-01-12 08:28:32.456615 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1754469
Z variance train             0.016221512
KL Divergence                22.205484
KL Loss                      2.2205484
QF Loss                      456.9549
VF Loss                      134.05334
Policy Loss                  -770.8285
Q Predictions Mean           761.25385
Q Predictions Std            304.68765
Q Predictions Max            1142.4808
Q Predictions Min            -36.300125
V Predictions Mean           771.4895
V Predictions Std            294.63956
V Predictions Max            1140.99
V Predictions Min            234.78499
Log Pis Mean                 -0.8208468
Log Pis Std                  3.041088
Log Pis Max                  13.763378
Log Pis Min                  -7.3649683
Policy mu Mean               0.02856187
Policy mu Std                0.5206006
Policy mu Max                2.748495
Policy mu Min                -2.5861168
Policy log std Mean          -0.95716804
Policy log std Std           0.19315475
Policy log std Max           -0.44630408
Policy log std Min           -1.9152651
Z mean eval                  1.136006
Z variance eval              0.012043485
total_rewards                [ 267.40395928 1201.44240862 2114.05231281 1502.28492807  612.81418917
 3241.29034142  643.07189173  989.28632167  133.63775352  373.96272389]
total_rewards_mean           1107.9246830190914
total_rewards_std            916.3795748874625
total_rewards_max            3241.2903414199727
total_rewards_min            133.6377535229826
Number of train steps total  524000
Number of env steps total    420826
Number of rollouts total     0
Train Time (s)               141.51108359592035
(Previous) Eval Time (s)     18.886877048760653
Sample Time (s)              12.118564091157168
Epoch Time (s)               172.51652473583817
Total Train Time (s)         23732.579690715764
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:31:25.149182 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #130 | Epoch Duration: 172.692316532135
2020-01-12 08:31:25.149562 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1379647
Z variance train             0.012055379
KL Divergence                22.613792
KL Loss                      2.2613792
QF Loss                      851.17725
VF Loss                      363.28326
Policy Loss                  -794.41907
Q Predictions Mean           789.1105
Q Predictions Std            308.08524
Q Predictions Max            1162.6123
Q Predictions Min            -13.662639
V Predictions Mean           790.53394
V Predictions Std            303.55252
V Predictions Max            1152.238
V Predictions Min            -47.07801
Log Pis Mean                 -0.76049125
Log Pis Std                  3.0405347
Log Pis Max                  13.789253
Log Pis Min                  -7.1293645
Policy mu Mean               -0.0060057053
Policy mu Std                0.5444901
Policy mu Max                2.349132
Policy mu Min                -3.6518223
Policy log std Mean          -0.9584182
Policy log std Std           0.20483094
Policy log std Max           -0.23491395
Policy log std Min           -2.0865912
Z mean eval                  1.1323943
Z variance eval              0.019206308
total_rewards                [ 229.51717127 2919.35078076 3075.94138907  771.11087604  669.14878294
 1996.2339589   460.14691487   63.47513136  486.12672784 1774.38751192]
total_rewards_mean           1244.5439244958366
total_rewards_std            1057.1501005570342
total_rewards_max            3075.9413890671444
total_rewards_min            63.4751313604094
Number of train steps total  528000
Number of env steps total    423886
Number of rollouts total     0
Train Time (s)               140.1161742308177
(Previous) Eval Time (s)     29.487742260098457
Sample Time (s)              11.654356906656176
Epoch Time (s)               181.25827339757234
Total Train Time (s)         23913.928373775445
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:34:26.500083 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #131 | Epoch Duration: 181.3502504825592
2020-01-12 08:34:26.500386 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1300871
Z variance train             0.019206729
KL Divergence                22.108631
KL Loss                      2.210863
QF Loss                      535.5329
VF Loss                      112.869675
Policy Loss                  -803.36975
Q Predictions Mean           799.56946
Q Predictions Std            307.43793
Q Predictions Max            1156.6437
Q Predictions Min            -1.7550247
V Predictions Mean           805.3238
V Predictions Std            301.77353
V Predictions Max            1166.4141
V Predictions Min            -6.589736
Log Pis Mean                 -0.7086941
Log Pis Std                  2.8517022
Log Pis Max                  10.343235
Log Pis Min                  -8.5767565
Policy mu Mean               0.020504959
Policy mu Std                0.5275519
Policy mu Max                3.1801872
Policy mu Min                -3.8326576
Policy log std Mean          -0.96520865
Policy log std Std           0.19248754
Policy log std Max           -0.4787029
Policy log std Min           -1.8162177
Z mean eval                  1.1689425
Z variance eval              0.021129062
total_rewards                [2894.9772858  3130.2953384  3030.4592362  2979.48614251 2792.14550738
 2949.56592849 2790.00591312  956.19004191 2963.59487235 2154.73745235]
total_rewards_mean           2664.1457718493957
total_rewards_std            623.231294000347
total_rewards_max            3130.2953383997483
total_rewards_min            956.1900419130156
Number of train steps total  532000
Number of env steps total    428248
Number of rollouts total     0
Train Time (s)               148.6310190721415
(Previous) Eval Time (s)     36.227011180948466
Sample Time (s)              13.03630743874237
Epoch Time (s)               197.89433769183233
Total Train Time (s)         24111.9241979355
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:37:44.498472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #132 | Epoch Duration: 197.9978802204132
2020-01-12 08:37:44.498858 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1494167
Z variance train             0.021687398
KL Divergence                21.735476
KL Loss                      2.1735475
QF Loss                      943.2372
VF Loss                      176.215
Policy Loss                  -808.3084
Q Predictions Mean           793.0406
Q Predictions Std            307.74588
Q Predictions Max            1163.3091
Q Predictions Min            -12.24826
V Predictions Mean           814.20764
V Predictions Std            297.2175
V Predictions Max            1165.7405
V Predictions Min            61.48768
Log Pis Mean                 -0.20525576
Log Pis Std                  3.50321
Log Pis Max                  13.883884
Log Pis Min                  -9.156412
Policy mu Mean               -0.020641908
Policy mu Std                0.5835216
Policy mu Max                2.7308922
Policy mu Min                -3.4414296
Policy log std Mean          -0.974729
Policy log std Std           0.20867214
Policy log std Max           -0.3793857
Policy log std Min           -2.2680635
Z mean eval                  1.1155064
Z variance eval              0.018303502
total_rewards                [1261.26922593 1871.28911543  819.16617011 1904.73437964 3031.43208137
  232.95770546  994.68399948  963.62120864 3196.55641531 2239.45900838]
total_rewards_mean           1651.516930973797
total_rewards_std            922.5751442353268
total_rewards_max            3196.5564153073174
total_rewards_min            232.95770545999258
Number of train steps total  536000
Number of env steps total    431265
Number of rollouts total     0
Train Time (s)               150.14553236868232
(Previous) Eval Time (s)     23.191895036958158
Sample Time (s)              12.115264009218663
Epoch Time (s)               185.45269141485915
Total Train Time (s)         24297.590394282248
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:40:50.166897 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #133 | Epoch Duration: 185.6677360534668
2020-01-12 08:40:50.167110 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.108626
Z variance train             0.018262634
KL Divergence                21.999865
KL Loss                      2.1999865
QF Loss                      1575.0378
VF Loss                      110.11543
Policy Loss                  -827.99976
Q Predictions Mean           822.7911
Q Predictions Std            301.9371
Q Predictions Max            1155.6792
Q Predictions Min            240.95477
V Predictions Mean           828.3568
V Predictions Std            298.6718
V Predictions Max            1151.9249
V Predictions Min            246.10599
Log Pis Mean                 -0.49305204
Log Pis Std                  3.3328097
Log Pis Max                  18.880268
Log Pis Min                  -7.6880374
Policy mu Mean               -0.03845985
Policy mu Std                0.5532388
Policy mu Max                2.8150997
Policy mu Min                -2.7925537
Policy log std Mean          -0.98276937
Policy log std Std           0.21013929
Policy log std Max           -0.44818836
Policy log std Min           -1.8479745
Z mean eval                  1.1886739
Z variance eval              0.097212695
total_rewards                [3116.48420538 2432.78869507  897.326104   3132.91265559 3105.04015168
 3025.97090227 3177.11038797 1041.72274638 3018.91492219  803.0329621 ]
total_rewards_mean           2375.130373264411
total_rewards_std            978.4951594162503
total_rewards_max            3177.1103879679904
total_rewards_min            803.0329620976069
Number of train steps total  540000
Number of env steps total    435658
Number of rollouts total     0
Train Time (s)               149.26954628201202
(Previous) Eval Time (s)     29.434264719020575
Sample Time (s)              11.983525950461626
Epoch Time (s)               190.68733695149422
Total Train Time (s)         24488.36219384987
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:44:00.941609 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #134 | Epoch Duration: 190.77429699897766
2020-01-12 08:44:00.941837 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1897588
Z variance train             0.095842615
KL Divergence                20.080713
KL Loss                      2.0080714
QF Loss                      2442.5415
VF Loss                      342.55255
Policy Loss                  -935.6498
Q Predictions Mean           926.9678
Q Predictions Std            358.78455
Q Predictions Max            1335.7747
Q Predictions Min            -4.8801203
V Predictions Mean           942.56104
V Predictions Std            348.2708
V Predictions Max            1331.1667
V Predictions Min            287.00015
Log Pis Mean                 -0.68408316
Log Pis Std                  2.7511084
Log Pis Max                  10.878915
Log Pis Min                  -9.704649
Policy mu Mean               -0.007837145
Policy mu Std                0.51315355
Policy mu Max                1.814133
Policy mu Min                -3.1996303
Policy log std Mean          -0.97824836
Policy log std Std           0.1889748
Policy log std Max           -0.51741296
Policy log std Min           -1.816759
Z mean eval                  1.1106185
Z variance eval              0.01919492
total_rewards                [ 575.56852147  384.30652406 1437.4806241   743.80145243  773.98761717
 1160.3575503   864.94972857 1381.08469373  242.00908989 3117.75358951]
total_rewards_mean           1068.1299391241005
total_rewards_std            779.0713310674583
total_rewards_max            3117.753589511665
total_rewards_min            242.00908988647512
Number of train steps total  544000
Number of env steps total    439998
Number of rollouts total     0
Train Time (s)               150.92698129313067
(Previous) Eval Time (s)     24.47994481679052
Sample Time (s)              12.211497021373361
Epoch Time (s)               187.61842313129455
Total Train Time (s)         24676.090822271537
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:47:08.673253 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #135 | Epoch Duration: 187.73121762275696
2020-01-12 08:47:08.673565 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1140976
Z variance train             0.019193422
KL Divergence                21.07768
KL Loss                      2.107768
QF Loss                      1000.97705
VF Loss                      161.00502
Policy Loss                  -799.2025
Q Predictions Mean           794.2645
Q Predictions Std            315.5651
Q Predictions Max            1174.2944
Q Predictions Min            -57.059544
V Predictions Mean           801.38245
V Predictions Std            312.0046
V Predictions Max            1164.2726
V Predictions Min            -101.27235
Log Pis Mean                 -0.7511773
Log Pis Std                  3.0895846
Log Pis Max                  14.954445
Log Pis Min                  -7.9873424
Policy mu Mean               -0.004074069
Policy mu Std                0.5440567
Policy mu Max                2.4423409
Policy mu Min                -4.049431
Policy log std Mean          -0.94508266
Policy log std Std           0.19640276
Policy log std Max           -0.40690917
Policy log std Min           -1.8682249
Z mean eval                  1.1541405
Z variance eval              0.012345409
total_rewards                [1415.29035372 1686.6326817  3022.16161049 2532.40066571  531.72178719
  601.05456177  562.31143008 2410.71941784 1542.37032172 1619.73692744]
total_rewards_mean           1592.4399757658484
total_rewards_std            825.218188138079
total_rewards_max            3022.161610493456
total_rewards_min            531.721787185409
Number of train steps total  548000
Number of env steps total    444025
Number of rollouts total     0
Train Time (s)               146.79086795076728
(Previous) Eval Time (s)     31.96400768030435
Sample Time (s)              13.08893961366266
Epoch Time (s)               191.8438152447343
Total Train Time (s)         24868.02926694369
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:50:20.614890 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #136 | Epoch Duration: 191.94105768203735
2020-01-12 08:50:20.615216 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1535109
Z variance train             0.012364624
KL Divergence                22.500793
KL Loss                      2.2500794
QF Loss                      1076.5126
VF Loss                      151.47427
Policy Loss                  -785.4324
Q Predictions Mean           775.96906
Q Predictions Std            322.5999
Q Predictions Max            1163.4064
Q Predictions Min            16.888008
V Predictions Mean           793.2715
V Predictions Std            317.1318
V Predictions Max            1164.6562
V Predictions Min            -14.615841
Log Pis Mean                 -0.7960111
Log Pis Std                  2.9322267
Log Pis Max                  10.005274
Log Pis Min                  -9.841108
Policy mu Mean               -0.0035965024
Policy mu Std                0.5398001
Policy mu Max                2.115481
Policy mu Min                -2.791304
Policy log std Mean          -0.9587743
Policy log std Std           0.20354865
Policy log std Max           0.70075715
Policy log std Min           -1.8122736
Z mean eval                  1.0844262
Z variance eval              0.036952756
total_rewards                [2815.09637602 1156.53746894 1413.36811332 2317.86293066 1997.42538161
 1147.79726489 1763.082102    430.59860158  198.9273321  2597.14866943]
total_rewards_mean           1583.7844240562895
total_rewards_std            832.7356818747885
total_rewards_max            2815.0963760239933
total_rewards_min            198.92733210160128
Number of train steps total  552000
Number of env steps total    446593
Number of rollouts total     0
Train Time (s)               140.9595053838566
(Previous) Eval Time (s)     29.28898077318445
Sample Time (s)              11.082686421927065
Epoch Time (s)               181.3311725789681
Total Train Time (s)         25049.449545506854
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:53:22.036571 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #137 | Epoch Duration: 181.42116498947144
2020-01-12 08:53:22.036764 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0922556
Z variance train             0.03695803
KL Divergence                19.842129
KL Loss                      1.9842129
QF Loss                      696.9278
VF Loss                      210.30443
Policy Loss                  -840.2899
Q Predictions Mean           830.9193
Q Predictions Std            294.04462
Q Predictions Max            1206.5132
Q Predictions Min            103.00679
V Predictions Mean           834.0034
V Predictions Std            290.70108
V Predictions Max            1193.883
V Predictions Min            55.895287
Log Pis Mean                 -0.3754276
Log Pis Std                  3.232267
Log Pis Max                  17.934101
Log Pis Min                  -7.9585757
Policy mu Mean               0.007880107
Policy mu Std                0.5833146
Policy mu Max                3.1826737
Policy mu Min                -3.7880523
Policy log std Mean          -0.98396635
Policy log std Std           0.19558522
Policy log std Max           -0.42833212
Policy log std Min           -1.9586699
Z mean eval                  1.1238563
Z variance eval              0.02378468
total_rewards                [1374.39885684 1285.38887848  990.02529302 1519.80371331  323.49763175
  611.0973856  3101.62702626 3187.2650521   436.66106989  272.94732901]
total_rewards_mean           1310.2712236264938
total_rewards_std            1009.2103838634595
total_rewards_max            3187.2650521033142
total_rewards_min            272.947329012727
Number of train steps total  556000
Number of env steps total    449870
Number of rollouts total     0
Train Time (s)               141.83020592899993
(Previous) Eval Time (s)     18.92425133101642
Sample Time (s)              10.946388009004295
Epoch Time (s)               171.70084526902065
Total Train Time (s)         25221.23668784136
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:56:13.826358 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #138 | Epoch Duration: 171.78944039344788
2020-01-12 08:56:13.826578 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1282138
Z variance train             0.02370273
KL Divergence                20.563107
KL Loss                      2.0563107
QF Loss                      517.2103
VF Loss                      125.72542
Policy Loss                  -845.2224
Q Predictions Mean           840.3905
Q Predictions Std            305.18484
Q Predictions Max            1192.9292
Q Predictions Min            -17.053843
V Predictions Mean           842.9129
V Predictions Std            300.66666
V Predictions Max            1169.2592
V Predictions Min            -8.595264
Log Pis Mean                 -0.5517562
Log Pis Std                  3.3972385
Log Pis Max                  18.441818
Log Pis Min                  -10.686348
Policy mu Mean               -0.030317338
Policy mu Std                0.553773
Policy mu Max                3.4446082
Policy mu Min                -2.768784
Policy log std Mean          -0.9839664
Policy log std Std           0.20594423
Policy log std Max           -0.34775764
Policy log std Min           -1.9409759
Z mean eval                  1.1524079
Z variance eval              0.045854993
total_rewards                [ 778.53368185  477.11129034  541.93561293 1232.87720722  962.71514798
 1362.00092128 1751.39473208 2977.89833263 2971.77151366  193.90195029]
total_rewards_mean           1325.01403902549
total_rewards_std            931.5020722518215
total_rewards_max            2977.8983326276393
total_rewards_min            193.9019502901105
Number of train steps total  560000
Number of env steps total    452879
Number of rollouts total     0
Train Time (s)               150.84003834798932
(Previous) Eval Time (s)     25.417807477992028
Sample Time (s)              12.186558766290545
Epoch Time (s)               188.4444045922719
Total Train Time (s)         25409.76347162109
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:59:22.353629 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #139 | Epoch Duration: 188.5269079208374
2020-01-12 08:59:22.353764 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1550763
Z variance train             0.04655949
KL Divergence                21.461197
KL Loss                      2.1461198
QF Loss                      608.4531
VF Loss                      120.12602
Policy Loss                  -781.20386
Q Predictions Mean           775.94226
Q Predictions Std            327.74332
Q Predictions Max            1166.495
Q Predictions Min            158.71005
V Predictions Mean           775.4794
V Predictions Std            322.32355
V Predictions Max            1159.0048
V Predictions Min            214.12154
Log Pis Mean                 -0.8823159
Log Pis Std                  3.048787
Log Pis Max                  14.595524
Log Pis Min                  -8.362165
Policy mu Mean               0.015576084
Policy mu Std                0.53319234
Policy mu Max                2.6767778
Policy mu Min                -2.0897894
Policy log std Mean          -0.9489963
Policy log std Std           0.19242129
Policy log std Max           -0.3625077
Policy log std Min           -1.8766582
Z mean eval                  1.0636761
Z variance eval              0.012624422
total_rewards                [ 178.35606726 2932.87002978 1493.25079522 3083.58114198 2990.07039081
 2921.73979024 2986.73563328 2266.44952397 3106.35494603  481.10127928]
total_rewards_mean           2244.0509597856712
total_rewards_std            1069.0897070448186
total_rewards_max            3106.3549460314525
total_rewards_min            178.35606726488288
Number of train steps total  564000
Number of env steps total    459099
Number of rollouts total     0
Train Time (s)               149.128359306138
(Previous) Eval Time (s)     29.010198508854955
Sample Time (s)              10.703752880450338
Epoch Time (s)               188.8423106954433
Total Train Time (s)         25598.69653815264
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:02:31.290820 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #140 | Epoch Duration: 188.9368932247162
2020-01-12 09:02:31.291176 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0622013
Z variance train             0.012526113
KL Divergence                21.743702
KL Loss                      2.1743703
QF Loss                      599.6224
VF Loss                      159.46771
Policy Loss                  -790.957
Q Predictions Mean           784.2783
Q Predictions Std            316.4772
Q Predictions Max            1144.0304
Q Predictions Min            -40.3251
V Predictions Mean           785.66846
V Predictions Std            308.72134
V Predictions Max            1130.6831
V Predictions Min            -23.256811
Log Pis Mean                 -0.32815176
Log Pis Std                  3.784165
Log Pis Max                  36.50052
Log Pis Min                  -8.589142
Policy mu Mean               0.008051759
Policy mu Std                0.5957002
Policy mu Max                3.1587925
Policy mu Min                -4.625629
Policy log std Mean          -0.97829384
Policy log std Std           0.20250544
Policy log std Max           -0.416907
Policy log std Min           -1.7451425
Z mean eval                  1.1200234
Z variance eval              0.008886995
total_rewards                [1849.72206572 1102.12830814  772.67732977 2170.60336852 1957.12299851
 1448.63101285 2863.12161396 3055.51344331  734.49489609 2061.04528671]
total_rewards_mean           1801.5060323587136
total_rewards_std            757.6508673956938
total_rewards_max            3055.513443310487
total_rewards_min            734.4948960940977
Number of train steps total  568000
Number of env steps total    464943
Number of rollouts total     0
Train Time (s)               149.546079732012
(Previous) Eval Time (s)     33.29286831011996
Sample Time (s)              13.07467354182154
Epoch Time (s)               195.9136215839535
Total Train Time (s)         25794.71223042207
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:05:47.308115 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #141 | Epoch Duration: 196.01668000221252
2020-01-12 09:05:47.308359 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1192671
Z variance train             0.008911034
KL Divergence                22.790346
KL Loss                      2.2790346
QF Loss                      795.0762
VF Loss                      140.40048
Policy Loss                  -778.5842
Q Predictions Mean           768.1957
Q Predictions Std            327.0422
Q Predictions Max            1136.674
Q Predictions Min            -24.124054
V Predictions Mean           780.3253
V Predictions Std            318.92923
V Predictions Max            1141.4285
V Predictions Min            226.91124
Log Pis Mean                 -0.41503498
Log Pis Std                  3.6763756
Log Pis Max                  19.35255
Log Pis Min                  -10.135122
Policy mu Mean               -0.0045266724
Policy mu Std                0.5799572
Policy mu Max                3.1038015
Policy mu Min                -2.9682744
Policy log std Mean          -0.9643199
Policy log std Std           0.21767938
Policy log std Max           -0.3884356
Policy log std Min           -2.3215952
Z mean eval                  1.0953192
Z variance eval              0.012029624
total_rewards                [3111.72536619 3056.64657639 3128.84542337 3174.36004517 2942.02530757
  243.68118867  406.62421243  600.06866729 2925.8334551  1622.92011611]
total_rewards_mean           2121.2730358271933
total_rewards_std            1197.0319836937733
total_rewards_max            3174.36004516672
total_rewards_min            243.68118867492024
Number of train steps total  572000
Number of env steps total    470785
Number of rollouts total     0
Train Time (s)               150.9877929938957
(Previous) Eval Time (s)     31.496887968387455
Sample Time (s)              12.86758984066546
Epoch Time (s)               195.35227080294862
Total Train Time (s)         25990.164374717977
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:09:02.767232 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #142 | Epoch Duration: 195.45869207382202
2020-01-12 09:09:02.767473 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0951575
Z variance train             0.011869522
KL Divergence                23.318142
KL Loss                      2.3318143
QF Loss                      521.7688
VF Loss                      226.32181
Policy Loss                  -808.47217
Q Predictions Mean           800.93384
Q Predictions Std            312.6693
Q Predictions Max            1160.1329
Q Predictions Min            -31.039968
V Predictions Mean           806.0513
V Predictions Std            307.3151
V Predictions Max            1142.5331
V Predictions Min            -40.688328
Log Pis Mean                 -0.2648408
Log Pis Std                  3.144712
Log Pis Max                  19.039444
Log Pis Min                  -8.851328
Policy mu Mean               -0.0065696244
Policy mu Std                0.57554585
Policy mu Max                3.342
Policy mu Min                -3.0199916
Policy log std Mean          -0.98377484
Policy log std Std           0.20248438
Policy log std Max           -0.2958001
Policy log std Min           -1.8969436
Z mean eval                  1.0975692
Z variance eval              0.04621325
total_rewards                [ 847.54842483 3012.44678417 2970.90171272 2824.78078903   33.05075378
 2338.34820472 2426.44289643 1126.35803119  259.50944083  629.73586703]
total_rewards_mean           1646.9122904734875
total_rewards_std            1120.928238669707
total_rewards_max            3012.446784171737
total_rewards_min            33.05075378391746
Number of train steps total  576000
Number of env steps total    474162
Number of rollouts total     0
Train Time (s)               144.49681778391823
(Previous) Eval Time (s)     22.679570795968175
Sample Time (s)              10.696582513861358
Epoch Time (s)               177.87297109374776
Total Train Time (s)         26168.126962595154
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:12:00.728430 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #143 | Epoch Duration: 177.9607858657837
2020-01-12 09:12:00.728619 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #143 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1022254
Z variance train             0.047211174
KL Divergence                20.886496
KL Loss                      2.0886495
QF Loss                      545.3043
VF Loss                      159.26193
Policy Loss                  -819.4302
Q Predictions Mean           810.9342
Q Predictions Std            337.5754
Q Predictions Max            1165.1019
Q Predictions Min            -53.239635
V Predictions Mean           817.7344
V Predictions Std            328.9631
V Predictions Max            1156.4667
V Predictions Min            2.4170187
Log Pis Mean                 -0.27392378
Log Pis Std                  4.0498514
Log Pis Max                  38.09146
Log Pis Min                  -9.298425
Policy mu Mean               -0.015500631
Policy mu Std                0.5732662
Policy mu Max                6.7049336
Policy mu Min                -3.844523
Policy log std Mean          -0.9904864
Policy log std Std           0.21290064
Policy log std Max           -0.41719025
Policy log std Min           -2.145568
Z mean eval                  1.0925434
Z variance eval              0.018344225
total_rewards                [2006.19552815 3055.47022544 3021.1040436  2280.7261043  1100.1404189
 1739.78611736 3014.62809421  822.62207514  244.7300828  2960.04983661]
total_rewards_mean           2024.545252650758
total_rewards_std            975.9768106609887
total_rewards_max            3055.4702254367835
total_rewards_min            244.73008280099657
Number of train steps total  580000
Number of env steps total    478508
Number of rollouts total     0
Train Time (s)               140.65358586609364
(Previous) Eval Time (s)     26.60274443682283
Sample Time (s)              11.896811519283801
Epoch Time (s)               179.15314182220027
Total Train Time (s)         26347.367379079573
Epoch                        144
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:14:59.970925 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #144 | Epoch Duration: 179.2421624660492
2020-01-12 09:14:59.971121 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0963638
Z variance train             0.018556338
KL Divergence                21.899473
KL Loss                      2.1899474
QF Loss                      571.41565
VF Loss                      113.78238
Policy Loss                  -834.2527
Q Predictions Mean           827.6948
Q Predictions Std            307.09415
Q Predictions Max            1151.8503
Q Predictions Min            24.878103
V Predictions Mean           831.72205
V Predictions Std            300.09402
V Predictions Max            1145.7494
V Predictions Min            143.73819
Log Pis Mean                 -0.47751743
Log Pis Std                  3.4755855
Log Pis Max                  25.271412
Log Pis Min                  -7.1980724
Policy mu Mean               -0.014938122
Policy mu Std                0.56951344
Policy mu Max                4.0106826
Policy mu Min                -3.1619558
Policy log std Mean          -0.9759395
Policy log std Std           0.21072702
Policy log std Max           -0.29176193
Policy log std Min           -2.5414245
Z mean eval                  1.12167
Z variance eval              0.01623021
total_rewards                [2326.48041329 2906.69558945   91.5914996  1491.41888872  518.96017609
 3069.29935769  676.16647092 1131.33777805  182.10947237  346.68309569]
total_rewards_mean           1274.074274186527
total_rewards_std            1069.6660511957216
total_rewards_max            3069.299357690136
total_rewards_min            91.59149960172596
Number of train steps total  584000
Number of env steps total    483914
Number of rollouts total     0
Train Time (s)               144.21510497899726
(Previous) Eval Time (s)     21.93153397878632
Sample Time (s)              11.159276112914085
Epoch Time (s)               177.30591507069767
Total Train Time (s)         26524.769065634813
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:17:57.375175 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #145 | Epoch Duration: 177.40383172035217
2020-01-12 09:17:57.375416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1127989
Z variance train             0.01634385
KL Divergence                20.709522
KL Loss                      2.0709522
QF Loss                      706.03674
VF Loss                      162.11699
Policy Loss                  -825.64667
Q Predictions Mean           816.5969
Q Predictions Std            306.78302
Q Predictions Max            1157.2412
Q Predictions Min            86.51262
V Predictions Mean           825.33264
V Predictions Std            298.86533
V Predictions Max            1165.2845
V Predictions Min            259.41776
Log Pis Mean                 -0.5396162
Log Pis Std                  3.388762
Log Pis Max                  17.173859
Log Pis Min                  -8.384055
Policy mu Mean               0.025708094
Policy mu Std                0.55873424
Policy mu Max                3.209954
Policy mu Min                -3.0231347
Policy log std Mean          -0.9773483
Policy log std Std           0.2057191
Policy log std Max           -0.45537803
Policy log std Min           -1.8037899
Z mean eval                  1.0850643
Z variance eval              0.02304301
total_rewards                [2624.99807152 2851.70992549 1367.96782248 3059.62928014  181.84223251
 3271.46638282  330.34606405  735.23837086  727.03504242 1314.75843163]
total_rewards_mean           1646.4991623930832
total_rewards_std            1130.8567245323875
total_rewards_max            3271.4663828232997
total_rewards_min            181.8422325095344
Number of train steps total  588000
Number of env steps total    489893
Number of rollouts total     0
Train Time (s)               151.8546595298685
(Previous) Eval Time (s)     23.960674681235105
Sample Time (s)              12.552792903967202
Epoch Time (s)               188.36812711507082
Total Train Time (s)         26713.23298370419
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:21:05.841332 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #146 | Epoch Duration: 188.46574568748474
2020-01-12 09:21:05.841520 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #146 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0906498
Z variance train             0.023238951
KL Divergence                20.77428
KL Loss                      2.077428
QF Loss                      467.3661
VF Loss                      102.85697
Policy Loss                  -812.9388
Q Predictions Mean           803.78735
Q Predictions Std            319.54645
Q Predictions Max            1226.1251
Q Predictions Min            -28.919592
V Predictions Mean           809.8135
V Predictions Std            315.52423
V Predictions Max            1223.5035
V Predictions Min            -8.809769
Log Pis Mean                 -0.53353083
Log Pis Std                  3.470574
Log Pis Max                  20.564262
Log Pis Min                  -9.026816
Policy mu Mean               0.0011343947
Policy mu Std                0.54602116
Policy mu Max                3.8181112
Policy mu Min                -2.8884487
Policy log std Mean          -0.97258
Policy log std Std           0.20316826
Policy log std Max           -0.41078335
Policy log std Min           -2.0143995
Z mean eval                  1.1387205
Z variance eval              0.015769357
total_rewards                [1649.85237063  353.80833154  354.22087972 1061.14381105 2882.8344013
  914.80896668 3000.29488713 3178.77974549 2088.76762419 2625.88451805]
total_rewards_mean           1811.0395535783089
total_rewards_std            1039.8215498040604
total_rewards_max            3178.7797454943143
total_rewards_min            353.80833154393997
Number of train steps total  592000
Number of env steps total    495178
Number of rollouts total     0
Train Time (s)               150.5665367678739
(Previous) Eval Time (s)     21.78669408010319
Sample Time (s)              14.30035947682336
Epoch Time (s)               186.65359032480046
Total Train Time (s)         26899.97435578378
Epoch                        147
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:24:12.585052 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #147 | Epoch Duration: 186.74339294433594
2020-01-12 09:24:12.585252 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1381313
Z variance train             0.015808243
KL Divergence                21.414383
KL Loss                      2.1414382
QF Loss                      686.729
VF Loss                      141.30167
Policy Loss                  -841.4122
Q Predictions Mean           836.8757
Q Predictions Std            323.2514
Q Predictions Max            1208.8185
Q Predictions Min            228.0478
V Predictions Mean           838.5365
V Predictions Std            318.40744
V Predictions Max            1199.5935
V Predictions Min            263.11188
Log Pis Mean                 -0.39401424
Log Pis Std                  3.0157645
Log Pis Max                  14.661232
Log Pis Min                  -12.127345
Policy mu Mean               -0.002836275
Policy mu Std                0.56745225
Policy mu Max                2.604429
Policy mu Min                -2.897207
Policy log std Mean          -0.97013116
Policy log std Std           0.20627686
Policy log std Max           -0.40462792
Policy log std Min           -2.1673255
Z mean eval                  1.0305564
Z variance eval              0.07379665
total_rewards                [2991.37353908 3228.95537256 1076.39417582 3128.19238989  798.08950757
  509.65773778 3193.51661668 1216.72000355 3092.24707364 1830.63691047]
total_rewards_mean           2106.5783327031586
total_rewards_std            1069.1508341786039
total_rewards_max            3228.955372556613
total_rewards_min            509.657737776531
Number of train steps total  596000
Number of env steps total    499815
Number of rollouts total     0
Train Time (s)               149.365127899684
(Previous) Eval Time (s)     34.81489566620439
Sample Time (s)              11.278405047953129
Epoch Time (s)               195.45842861384153
Total Train Time (s)         27095.533868120983
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:27:28.147785 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #148 | Epoch Duration: 195.56235527992249
2020-01-12 09:27:28.148088 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0372077
Z variance train             0.07714553
KL Divergence                20.58651
KL Loss                      2.058651
QF Loss                      636.4254
VF Loss                      211.19891
Policy Loss                  -813.3568
Q Predictions Mean           803.1444
Q Predictions Std            319.30087
Q Predictions Max            1179.372
Q Predictions Min            186.9203
V Predictions Mean           811.64966
V Predictions Std            313.71158
V Predictions Max            1184.2683
V Predictions Min            235.81537
Log Pis Mean                 -0.43368328
Log Pis Std                  3.3410707
Log Pis Max                  19.548256
Log Pis Min                  -7.0095196
Policy mu Mean               0.019383725
Policy mu Std                0.5568333
Policy mu Max                3.2911427
Policy mu Min                -2.9379609
Policy log std Mean          -1.0061707
Policy log std Std           0.21970008
Policy log std Max           -0.29548812
Policy log std Min           -2.1380074
Z mean eval                  1.0869353
Z variance eval              0.016234841
total_rewards                [2690.27818993 1424.22763339  391.08157948  491.84758775 3113.29204103
 3173.42566125 3248.79486379 3125.29160813 2706.2740878  3087.2304316 ]
total_rewards_mean           2345.174368415659
total_rewards_std            1077.1581313241816
total_rewards_max            3248.79486379487
total_rewards_min            391.0815794774846
Number of train steps total  600000
Number of env steps total    502709
Number of rollouts total     0
Train Time (s)               149.81933481059968
(Previous) Eval Time (s)     29.758851577993482
Sample Time (s)              12.803685913328081
Epoch Time (s)               192.38187230192125
Total Train Time (s)         27288.045374027453
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:30:40.661620 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #149 | Epoch Duration: 192.51331281661987
2020-01-12 09:30:40.661935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0885696
Z variance train             0.016141992
KL Divergence                21.4181
KL Loss                      2.1418102
QF Loss                      1178.1318
VF Loss                      115.565796
Policy Loss                  -809.6543
Q Predictions Mean           805.2071
Q Predictions Std            327.6558
Q Predictions Max            1194.7733
Q Predictions Min            -6.030516
V Predictions Mean           810.53485
V Predictions Std            324.77225
V Predictions Max            1198.1775
V Predictions Min            -6.1733084
Log Pis Mean                 -0.75367963
Log Pis Std                  2.7551835
Log Pis Max                  13.548402
Log Pis Min                  -8.895459
Policy mu Mean               0.034682058
Policy mu Std                0.5082423
Policy mu Max                3.154815
Policy mu Min                -3.278677
Policy log std Mean          -0.97758573
Policy log std Std           0.19526237
Policy log std Max           -0.36681336
Policy log std Min           -1.7468157
Z mean eval                  1.1076264
Z variance eval              0.031619765
total_rewards                [2995.79822737 3284.86394682 3063.92281823  546.89129477 3103.42957283
  348.60939275 3304.85454957 3192.01333406   98.0595012  2657.29055026]
total_rewards_mean           2259.573318787423
total_rewards_std            1277.8795145882802
total_rewards_max            3304.8545495733115
total_rewards_min            98.05950119835005
Number of train steps total  604000
Number of env steps total    508381
Number of rollouts total     0
Train Time (s)               142.56352926790714
(Previous) Eval Time (s)     28.393539142794907
Sample Time (s)              11.993733201175928
Epoch Time (s)               182.95080161187798
Total Train Time (s)         27471.08420283813
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:33:43.702654 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #150 | Epoch Duration: 183.04054069519043
2020-01-12 09:33:43.702881 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1022667
Z variance train             0.031788938
KL Divergence                19.736862
KL Loss                      1.9736862
QF Loss                      585.7568
VF Loss                      66.534195
Policy Loss                  -867.5685
Q Predictions Mean           864.2206
Q Predictions Std            309.8301
Q Predictions Max            1234.2468
Q Predictions Min            244.58911
V Predictions Mean           867.8115
V Predictions Std            306.74496
V Predictions Max            1212.917
V Predictions Min            260.6172
Log Pis Mean                 -0.49894857
Log Pis Std                  2.7478886
Log Pis Max                  7.8421154
Log Pis Min                  -10.263928
Policy mu Mean               -0.021964245
Policy mu Std                0.5201063
Policy mu Max                2.1461864
Policy mu Min                -2.026312
Policy log std Mean          -0.9958545
Policy log std Std           0.19380216
Policy log std Max           -0.42153424
Policy log std Min           -1.6961617
Z mean eval                  1.1097174
Z variance eval              0.0151467
total_rewards                [3001.48262664  774.29738532  498.86358749 3071.28033299 2991.20968966
 3169.104381   2904.64466644 1748.89137829 3055.66963747 1692.42481446]
total_rewards_mean           2290.786849977138
total_rewards_std            974.709013191155
total_rewards_max            3169.1043810040137
total_rewards_min            498.863587487605
Number of train steps total  608000
Number of env steps total    512833
Number of rollouts total     0
Train Time (s)               140.52427451778203
(Previous) Eval Time (s)     31.803151628933847
Sample Time (s)              11.103977801278234
Epoch Time (s)               183.4314039479941
Total Train Time (s)         27654.600804613903
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:36:47.221961 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #151 | Epoch Duration: 183.51888728141785
2020-01-12 09:36:47.222277 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1103508
Z variance train             0.015191148
KL Divergence                21.493902
KL Loss                      2.1493902
QF Loss                      613.4691
VF Loss                      178.71297
Policy Loss                  -820.3936
Q Predictions Mean           813.1757
Q Predictions Std            326.22708
Q Predictions Max            1209.6261
Q Predictions Min            120.71027
V Predictions Mean           822.7885
V Predictions Std            322.35672
V Predictions Max            1209.039
V Predictions Min            244.49744
Log Pis Mean                 -0.3128577
Log Pis Std                  3.0670257
Log Pis Max                  16.47339
Log Pis Min                  -7.6424465
Policy mu Mean               -0.00867017
Policy mu Std                0.5643791
Policy mu Max                2.9207258
Policy mu Min                -2.7287498
Policy log std Mean          -0.9810543
Policy log std Std           0.20640981
Policy log std Max           -0.25562185
Policy log std Min           -1.9527323
Z mean eval                  1.0977685
Z variance eval              0.05536903
total_rewards                [2204.9237574   910.61640094 2988.27858541 3099.85527563 3084.15513843
 3236.7534772  3248.05422818  543.15367081 1993.88144122 1854.62747747]
total_rewards_mean           2316.429945267859
total_rewards_std            939.1490923855142
total_rewards_max            3248.0542281792937
total_rewards_min            543.1536708090445
Number of train steps total  612000
Number of env steps total    517969
Number of rollouts total     0
Train Time (s)               144.8578137550503
(Previous) Eval Time (s)     26.61128841387108
Sample Time (s)              10.985820278059691
Epoch Time (s)               182.45492244698107
Total Train Time (s)         27837.145044021774
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:39:49.768233 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #152 | Epoch Duration: 182.54572772979736
2020-01-12 09:39:49.768430 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #152 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0970407
Z variance train             0.056693204
KL Divergence                18.93815
KL Loss                      1.893815
QF Loss                      581.7053
VF Loss                      636.86237
Policy Loss                  -817.17975
Q Predictions Mean           807.93097
Q Predictions Std            314.27417
Q Predictions Max            1199.8816
Q Predictions Min            -25.621967
V Predictions Mean           819.676
V Predictions Std            303.4738
V Predictions Max            1205.9513
V Predictions Min            226.02487
Log Pis Mean                 -0.18407772
Log Pis Std                  3.3992486
Log Pis Max                  18.943733
Log Pis Min                  -7.5042224
Policy mu Mean               0.019488143
Policy mu Std                0.5961057
Policy mu Max                2.8734581
Policy mu Min                -4.890771
Policy log std Mean          -0.9785911
Policy log std Std           0.2186312
Policy log std Max           -0.2580222
Policy log std Min           -2.0128367
Z mean eval                  1.1437774
Z variance eval              0.039775647
total_rewards                [3232.3421667  3144.95061078 3105.67602716 3090.88602642  310.8092016
 3086.87441861  590.90501549 2893.40990172 3148.74714188 3084.26860625]
total_rewards_mean           2568.886911661656
total_rewards_std            1063.9293972633923
total_rewards_max            3232.342166704636
total_rewards_min            310.8092015972415
Number of train steps total  616000
Number of env steps total    524074
Number of rollouts total     0
Train Time (s)               151.76234086416662
(Previous) Eval Time (s)     30.977872570976615
Sample Time (s)              10.117179282940924
Epoch Time (s)               192.85739271808416
Total Train Time (s)         28030.090344609227
Epoch                        153
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:43:02.715672 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #153 | Epoch Duration: 192.94708371162415
2020-01-12 09:43:02.715860 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1546345
Z variance train             0.040162154
KL Divergence                20.541094
KL Loss                      2.0541093
QF Loss                      987.17126
VF Loss                      211.32243
Policy Loss                  -833.63
Q Predictions Mean           831.2672
Q Predictions Std            336.06186
Q Predictions Max            1233.8744
Q Predictions Min            -50.610424
V Predictions Mean           828.7732
V Predictions Std            327.96402
V Predictions Max            1191.8372
V Predictions Min            -15.396679
Log Pis Mean                 -0.43919307
Log Pis Std                  2.9702802
Log Pis Max                  15.264405
Log Pis Min                  -7.5339637
Policy mu Mean               -0.009713763
Policy mu Std                0.53702295
Policy mu Max                3.1014457
Policy mu Min                -2.6420813
Policy log std Mean          -0.9876889
Policy log std Std           0.21858376
Policy log std Max           -0.17114496
Policy log std Min           -2.039353
Z mean eval                  1.0731735
Z variance eval              0.020829577
total_rewards                [3138.56503155 3216.48676364 1919.9333794   504.8523145  1597.70680274
 3056.32033337 1750.29873848 2008.59534294 3149.63026049 3050.96769317]
total_rewards_mean           2339.33566602677
total_rewards_std            873.6601508069787
total_rewards_max            3216.4867636378603
total_rewards_min            504.8523145027101
Number of train steps total  620000
Number of env steps total    529680
Number of rollouts total     0
Train Time (s)               151.17848840728402
(Previous) Eval Time (s)     26.960822796914726
Sample Time (s)              10.7711676126346
Epoch Time (s)               188.91047881683335
Total Train Time (s)         28219.102668492123
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:46:11.730271 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #154 | Epoch Duration: 189.01426434516907
2020-01-12 09:46:11.730454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0771053
Z variance train             0.020958502
KL Divergence                21.704453
KL Loss                      2.1704452
QF Loss                      653.468
VF Loss                      66.957466
Policy Loss                  -829.731
Q Predictions Mean           821.1423
Q Predictions Std            323.15982
Q Predictions Max            1190.1776
Q Predictions Min            241.33383
V Predictions Mean           831.6151
V Predictions Std            319.06955
V Predictions Max            1188.1615
V Predictions Min            241.61499
Log Pis Mean                 -0.7592758
Log Pis Std                  3.1354187
Log Pis Max                  11.165052
Log Pis Min                  -8.552811
Policy mu Mean               0.002649175
Policy mu Std                0.5180781
Policy mu Max                2.3641517
Policy mu Min                -2.2986362
Policy log std Mean          -0.9877397
Policy log std Std           0.22280636
Policy log std Max           -0.39531916
Policy log std Min           -1.8685378
Z mean eval                  1.1358559
Z variance eval              0.01110859
total_rewards                [3227.16565778  168.55087702 2020.95731418 3165.26276184 3107.71659891
 3056.05151517  366.24423799 2957.56113914 2193.19024736 3071.26984107]
total_rewards_mean           2333.397019046
total_rewards_std            1105.4494953216795
total_rewards_max            3227.1656577794156
total_rewards_min            168.55087702289438
Number of train steps total  624000
Number of env steps total    535376
Number of rollouts total     0
Train Time (s)               151.40658697625622
(Previous) Eval Time (s)     31.562810211908072
Sample Time (s)              11.715915687382221
Epoch Time (s)               194.68531287554651
Total Train Time (s)         28413.875176389236
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:49:26.505545 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #155 | Epoch Duration: 194.77493906021118
2020-01-12 09:49:26.507357 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #155 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1375511
Z variance train             0.010989001
KL Divergence                23.025513
KL Loss                      2.3025513
QF Loss                      764.98474
VF Loss                      231.70508
Policy Loss                  -843.30115
Q Predictions Mean           835.7981
Q Predictions Std            321.90588
Q Predictions Max            1203.2814
Q Predictions Min            -4.111983
V Predictions Mean           843.30286
V Predictions Std            316.64273
V Predictions Max            1198.7347
V Predictions Min            188.61644
Log Pis Mean                 -0.39630762
Log Pis Std                  3.2343285
Log Pis Max                  24.54745
Log Pis Min                  -7.2498198
Policy mu Mean               0.011985674
Policy mu Std                0.5521013
Policy mu Max                3.5951304
Policy mu Min                -2.5365598
Policy log std Mean          -0.9848338
Policy log std Std           0.2123308
Policy log std Max           -0.39525908
Policy log std Min           -2.0655513
Z mean eval                  1.1113024
Z variance eval              0.0065387907
total_rewards                [ 816.64422497 3309.97173534 1637.28174465 2042.94515552 3069.0623166
 2523.68576032  170.27897041 3140.14850686 2372.28168612 1346.41056476]
total_rewards_mean           2042.87106655659
total_rewards_std            993.0819630431885
total_rewards_max            3309.9717353443534
total_rewards_min            170.27897041306682
Number of train steps total  628000
Number of env steps total    540474
Number of rollouts total     0
Train Time (s)               150.73696007905528
(Previous) Eval Time (s)     22.77338460739702
Sample Time (s)              12.326258129440248
Epoch Time (s)               185.83660281589255
Total Train Time (s)         28599.79977180669
Epoch                        156
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:52:32.433619 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #156 | Epoch Duration: 185.92591786384583
2020-01-12 09:52:32.433937 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1147865
Z variance train             0.0065463544
KL Divergence                23.567495
KL Loss                      2.3567495
QF Loss                      616.6174
VF Loss                      99.23217
Policy Loss                  -836.41986
Q Predictions Mean           833.69507
Q Predictions Std            320.06436
Q Predictions Max            1222.866
Q Predictions Min            23.422276
V Predictions Mean           837.4178
V Predictions Std            317.88312
V Predictions Max            1199.826
V Predictions Min            185.14784
Log Pis Mean                 -0.67057925
Log Pis Std                  3.30801
Log Pis Max                  11.971031
Log Pis Min                  -11.651594
Policy mu Mean               -0.0093498
Policy mu Std                0.53797156
Policy mu Max                2.372169
Policy mu Min                -2.710981
Policy log std Mean          -1.0108142
Policy log std Std           0.20907743
Policy log std Max           -0.51317626
Policy log std Min           -2.08232
Z mean eval                  1.0689704
Z variance eval              0.0426067
total_rewards                [ 773.37061072 2763.94700122  604.16810964 1941.07357964  690.08025606
 1362.88049438 1356.73879162  624.75440991 1502.74305065  536.08430657]
total_rewards_mean           1215.5840610411683
total_rewards_std            685.87025463609
total_rewards_max            2763.9470012169677
total_rewards_min            536.0843065727096
Number of train steps total  632000
Number of env steps total    546467
Number of rollouts total     0
Train Time (s)               141.81943471403793
(Previous) Eval Time (s)     23.12898707203567
Sample Time (s)              11.12319016829133
Epoch Time (s)               176.07161195436493
Total Train Time (s)         28775.961638795678
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:55:28.597047 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #157 | Epoch Duration: 176.16291785240173
2020-01-12 09:55:28.597252 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0677396
Z variance train             0.042750306
KL Divergence                19.427773
KL Loss                      1.9427773
QF Loss                      787.30743
VF Loss                      148.77092
Policy Loss                  -849.4911
Q Predictions Mean           846.63983
Q Predictions Std            306.0845
Q Predictions Max            1203.2124
Q Predictions Min            -35.75168
V Predictions Mean           850.6041
V Predictions Std            301.19662
V Predictions Max            1181.1699
V Predictions Min            -7.356078
Log Pis Mean                 -0.35442653
Log Pis Std                  3.0228202
Log Pis Max                  14.838769
Log Pis Min                  -7.209152
Policy mu Mean               -0.018383607
Policy mu Std                0.5570893
Policy mu Max                2.2742558
Policy mu Min                -2.552504
Policy log std Mean          -0.9888567
Policy log std Std           0.2050471
Policy log std Max           -0.28049082
Policy log std Min           -1.9649624
Z mean eval                  1.1298846
Z variance eval              0.009703668
total_rewards                [1678.06186861 1632.45279852  664.78972082  634.39192421  140.11802471
 1387.73400674 3113.89670831 1876.16874676 1132.05374024  764.71431924]
total_rewards_mean           1302.4381858162967
total_rewards_std            799.3668903239712
total_rewards_max            3113.896708306212
total_rewards_min            140.11802471181306
Number of train steps total  636000
Number of env steps total    549977
Number of rollouts total     0
Train Time (s)               141.57576686842367
(Previous) Eval Time (s)     24.972805961035192
Sample Time (s)              12.390757335815579
Epoch Time (s)               178.93933016527444
Total Train Time (s)         28954.98708834499
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:58:27.625403 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #158 | Epoch Duration: 179.02794194221497
2020-01-12 09:58:27.625658 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1336854
Z variance train             0.009700157
KL Divergence                22.026062
KL Loss                      2.2026062
QF Loss                      680.4155
VF Loss                      99.51518
Policy Loss                  -818.7432
Q Predictions Mean           809.08405
Q Predictions Std            338.02118
Q Predictions Max            1209.8364
Q Predictions Min            49.55529
V Predictions Mean           816.78973
V Predictions Std            330.74377
V Predictions Max            1196.7927
V Predictions Min            215.80502
Log Pis Mean                 -0.79783446
Log Pis Std                  3.1054242
Log Pis Max                  18.773335
Log Pis Min                  -9.231824
Policy mu Mean               -0.015057372
Policy mu Std                0.5350823
Policy mu Max                3.1919394
Policy mu Min                -3.1823347
Policy log std Mean          -0.9746157
Policy log std Std           0.20123754
Policy log std Max           -0.26804334
Policy log std Min           -1.8613657
Z mean eval                  1.0696326
Z variance eval              0.012413253
total_rewards                [3159.822988    471.91691571 1284.95835373 1844.27176242 3112.65508916
 3178.95348013 1868.73423697 1186.08177837 2590.61686819  147.64139701]
total_rewards_mean           1884.5652869687797
total_rewards_std            1056.8915882434032
total_rewards_max            3178.9534801303334
total_rewards_min            147.64139700932128
Number of train steps total  640000
Number of env steps total    554335
Number of rollouts total     0
Train Time (s)               146.7981078820303
(Previous) Eval Time (s)     31.605165938846767
Sample Time (s)              11.42635775078088
Epoch Time (s)               189.82963157165796
Total Train Time (s)         29144.92365772184
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:01:37.564840 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #159 | Epoch Duration: 189.93900656700134
2020-01-12 10:01:37.565063 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #159 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0681272
Z variance train             0.01253475
KL Divergence                21.331919
KL Loss                      2.1331918
QF Loss                      801.4905
VF Loss                      268.94708
Policy Loss                  -840.0173
Q Predictions Mean           833.5857
Q Predictions Std            327.33295
Q Predictions Max            1220.6106
Q Predictions Min            189.59453
V Predictions Mean           842.93555
V Predictions Std            320.6647
V Predictions Max            1223.5452
V Predictions Min            267.0891
Log Pis Mean                 -0.5285949
Log Pis Std                  3.0469427
Log Pis Max                  13.038717
Log Pis Min                  -7.9049234
Policy mu Mean               0.008187764
Policy mu Std                0.56042606
Policy mu Max                2.5043597
Policy mu Min                -3.0934799
Policy log std Mean          -0.9749569
Policy log std Std           0.21482675
Policy log std Max           -0.39687395
Policy log std Min           -1.9577093
Z mean eval                  1.1561692
Z variance eval              0.009112755
total_rewards                [3129.39004017  540.69297734 2769.12276882 2820.83489467  828.5183936
 3103.78588564  457.59631713 3009.4464275   514.02255569 3079.4949304 ]
total_rewards_mean           2025.2905190961276
total_rewards_std            1184.3210890469436
total_rewards_max            3129.3900401675414
total_rewards_min            457.59631713349063
Number of train steps total  644000
Number of env steps total    559096
Number of rollouts total     0
Train Time (s)               150.69106105994433
(Previous) Eval Time (s)     36.48718186188489
Sample Time (s)              11.72628459893167
Epoch Time (s)               198.9045275207609
Total Train Time (s)         29343.917699753307
Epoch                        160
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:04:56.561239 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #160 | Epoch Duration: 198.99601697921753
2020-01-12 10:04:56.561430 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1612742
Z variance train             0.009118113
KL Divergence                22.02735
KL Loss                      2.202735
QF Loss                      571.9667
VF Loss                      104.87035
Policy Loss                  -813.14844
Q Predictions Mean           807.39856
Q Predictions Std            336.37427
Q Predictions Max            1236.3289
Q Predictions Min            162.28706
V Predictions Mean           812.6382
V Predictions Std            332.38443
V Predictions Max            1239.298
V Predictions Min            221.4952
Log Pis Mean                 -0.4120309
Log Pis Std                  3.5740018
Log Pis Max                  18.473076
Log Pis Min                  -8.134787
Policy mu Mean               -0.0062699486
Policy mu Std                0.56536245
Policy mu Max                2.9038298
Policy mu Min                -3.1835182
Policy log std Mean          -0.97363925
Policy log std Std           0.22905514
Policy log std Max           -0.4125588
Policy log std Min           -2.1886764
Z mean eval                  1.1284025
Z variance eval              0.030519009
total_rewards                [1736.23478651   97.47613016 3199.71853291 3349.50974555 3146.13434871
 2190.73109804 2755.72885625 1024.32559766 3363.42136158 2498.21964816]
total_rewards_mean           2336.1500105523924
total_rewards_std            1039.2262288052286
total_rewards_max            3363.4213615776084
total_rewards_min            97.4761301622105
Number of train steps total  648000
Number of env steps total    564995
Number of rollouts total     0
Train Time (s)               150.49444757588208
(Previous) Eval Time (s)     25.869229645933956
Sample Time (s)              11.552600335329771
Epoch Time (s)               187.9162775571458
Total Train Time (s)         29531.922289494425
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:08:04.568282 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #161 | Epoch Duration: 188.00669193267822
2020-01-12 10:08:04.568539 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1313031
Z variance train             0.030616503
KL Divergence                19.51987
KL Loss                      1.9519871
QF Loss                      773.2929
VF Loss                      136.05164
Policy Loss                  -828.271
Q Predictions Mean           821.9607
Q Predictions Std            332.4065
Q Predictions Max            1215.1847
Q Predictions Min            253.87248
V Predictions Mean           828.5929
V Predictions Std            330.61075
V Predictions Max            1216.9783
V Predictions Min            262.918
Log Pis Mean                 -0.67424434
Log Pis Std                  3.0722635
Log Pis Max                  13.588464
Log Pis Min                  -6.344305
Policy mu Mean               0.012633206
Policy mu Std                0.53363794
Policy mu Max                2.8068247
Policy mu Min                -2.4380655
Policy log std Mean          -0.96530616
Policy log std Std           0.2130126
Policy log std Max           -0.27016854
Policy log std Min           -2.0244966
Z mean eval                  1.0868454
Z variance eval              0.018592287
total_rewards                [2915.55014846 1665.6457911   822.23493128 1077.76217669  317.04641308
 1385.3714524   493.77400218 3364.07386259 2419.40124735 1445.42639229]
total_rewards_mean           1590.6286417418519
total_rewards_std            966.1673488885951
total_rewards_max            3364.0738625912654
total_rewards_min            317.04641308118624
Number of train steps total  652000
Number of env steps total    571806
Number of rollouts total     0
Train Time (s)               151.40847667399794
(Previous) Eval Time (s)     26.21135544916615
Sample Time (s)              11.523203015327454
Epoch Time (s)               189.14303513849154
Total Train Time (s)         29721.150899169967
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:11:13.798896 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #162 | Epoch Duration: 189.23019886016846
2020-01-12 10:11:13.799087 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0807571
Z variance train             0.01844692
KL Divergence                20.270462
KL Loss                      2.0270462
QF Loss                      621.38184
VF Loss                      137.83551
Policy Loss                  -831.8614
Q Predictions Mean           825.7564
Q Predictions Std            342.1145
Q Predictions Max            1217.1437
Q Predictions Min            -5.5167108
V Predictions Mean           833.7927
V Predictions Std            338.0368
V Predictions Max            1221.866
V Predictions Min            69.24776
Log Pis Mean                 -0.6536863
Log Pis Std                  2.864786
Log Pis Max                  11.0231495
Log Pis Min                  -6.593418
Policy mu Mean               -0.023990812
Policy mu Std                0.53184134
Policy mu Max                2.7622066
Policy mu Min                -2.8790617
Policy log std Mean          -0.97100127
Policy log std Std           0.21205187
Policy log std Max           -0.4588325
Policy log std Min           -1.7637911
Z mean eval                  1.0450404
Z variance eval              0.023326958
total_rewards                [1799.36739192  433.58009778 1728.64459008 3183.34615865 3103.12048197
  988.49119485 3181.08314159 3088.39066483 1538.8763459  1562.35180515]
total_rewards_mean           2060.7251872738825
total_rewards_std            956.803982725173
total_rewards_max            3183.3461586506037
total_rewards_min            433.58009778056254
Number of train steps total  656000
Number of env steps total    578178
Number of rollouts total     0
Train Time (s)               149.46066272072494
(Previous) Eval Time (s)     27.889274589717388
Sample Time (s)              11.681494558695704
Epoch Time (s)               189.03143186913803
Total Train Time (s)         29910.298349244054
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:14:22.948935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #163 | Epoch Duration: 189.14970111846924
2020-01-12 10:14:22.949156 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0485306
Z variance train             0.023708984
KL Divergence                19.69799
KL Loss                      1.969799
QF Loss                      463.08713
VF Loss                      156.57904
Policy Loss                  -863.31537
Q Predictions Mean           854.0432
Q Predictions Std            336.85178
Q Predictions Max            1224.2333
Q Predictions Min            -30.150822
V Predictions Mean           854.62915
V Predictions Std            327.27603
V Predictions Max            1218.9775
V Predictions Min            193.74078
Log Pis Mean                 -0.524288
Log Pis Std                  2.6715991
Log Pis Max                  13.198981
Log Pis Min                  -8.48695
Policy mu Mean               -0.021293074
Policy mu Std                0.538356
Policy mu Max                2.261596
Policy mu Min                -3.4197412
Policy log std Mean          -0.97083485
Policy log std Std           0.19079849
Policy log std Max           -0.39685225
Policy log std Min           -2.0134563
Z mean eval                  1.1157272
Z variance eval              0.010067264
total_rewards                [3249.35927626 1094.83983999 1360.82258709 2160.58659068  449.52732896
 3221.45038762 3273.6583308   109.66847259 3315.23962399 1191.55325904]
total_rewards_mean           1942.6705697023767
total_rewards_std            1194.0096097016203
total_rewards_max            3315.2396239853333
total_rewards_min            109.66847259265812
Number of train steps total  660000
Number of env steps total    585071
Number of rollouts total     0
Train Time (s)               141.2832118878141
(Previous) Eval Time (s)     26.978307457175106
Sample Time (s)              10.966658955905586
Epoch Time (s)               179.2281783008948
Total Train Time (s)         30089.613556326833
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:17:22.269646 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #164 | Epoch Duration: 179.32030606269836
2020-01-12 10:17:22.270020 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1206919
Z variance train             0.009956064
KL Divergence                21.109818
KL Loss                      2.1109817
QF Loss                      639.657
VF Loss                      234.18825
Policy Loss                  -855.40076
Q Predictions Mean           847.501
Q Predictions Std            333.94
Q Predictions Max            1232.1722
Q Predictions Min            264.43637
V Predictions Mean           859.06946
V Predictions Std            329.56296
V Predictions Max            1232.5149
V Predictions Min            274.037
Log Pis Mean                 -0.17267887
Log Pis Std                  3.869449
Log Pis Max                  24.316465
Log Pis Min                  -7.549432
Policy mu Mean               -0.030397065
Policy mu Std                0.60399723
Policy mu Max                2.8839822
Policy mu Min                -3.3724422
Policy log std Mean          -0.9707145
Policy log std Std           0.22042817
Policy log std Max           -0.19677639
Policy log std Min           -2.235439
Z mean eval                  1.0039771
Z variance eval              0.011816181
total_rewards                [2190.95902125 3138.1538631  3080.55404569 1458.12264018 1481.89631655
 1056.63291211  646.31220079 3135.06143062 2100.57035285  527.91936495]
total_rewards_mean           1881.6182148083542
total_rewards_std            954.425953242522
total_rewards_max            3138.153863096385
total_rewards_min            527.9193649541207
Number of train steps total  664000
Number of env steps total    590878
Number of rollouts total     0
Train Time (s)               140.9251157050021
(Previous) Eval Time (s)     31.223386588972062
Sample Time (s)              11.42608178826049
Epoch Time (s)               183.57458408223465
Total Train Time (s)         30273.2904650867
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:20:25.949002 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #165 | Epoch Duration: 183.6787030696869
2020-01-12 10:20:25.949270 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0081378
Z variance train             0.011767386
KL Divergence                21.692959
KL Loss                      2.169296
QF Loss                      507.34888
VF Loss                      110.20311
Policy Loss                  -860.1677
Q Predictions Mean           855.51135
Q Predictions Std            346.71338
Q Predictions Max            1242.8986
Q Predictions Min            59.001896
V Predictions Mean           857.13586
V Predictions Std            342.54056
V Predictions Max            1240.4752
V Predictions Min            188.37236
Log Pis Mean                 -0.6857536
Log Pis Std                  2.718555
Log Pis Max                  13.267487
Log Pis Min                  -7.5137296
Policy mu Mean               -0.0214655
Policy mu Std                0.5157225
Policy mu Max                3.6262865
Policy mu Min                -2.5953057
Policy log std Mean          -0.9679173
Policy log std Std           0.20581281
Policy log std Max           -0.42590654
Policy log std Min           -2.2138648
Z mean eval                  1.1933308
Z variance eval              0.008205074
total_rewards                [3243.66079469 3241.26214484  729.09423356 1170.73229453  786.61194704
  710.5231778  2824.89394475 1831.97411698 1646.63872315 1064.78502582]
total_rewards_mean           1725.0176403152868
total_rewards_std            973.5189929842749
total_rewards_max            3243.6607946875406
total_rewards_min            710.5231778010634
Number of train steps total  668000
Number of env steps total    596238
Number of rollouts total     0
Train Time (s)               149.20020028809085
(Previous) Eval Time (s)     26.506604885682464
Sample Time (s)              12.406692368909717
Epoch Time (s)               188.11349754268304
Total Train Time (s)         30461.4974890789
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:23:34.159285 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #166 | Epoch Duration: 188.2097749710083
2020-01-12 10:23:34.159660 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1901915
Z variance train             0.008311338
KL Divergence                22.913174
KL Loss                      2.2913175
QF Loss                      693.63074
VF Loss                      438.60233
Policy Loss                  -864.2876
Q Predictions Mean           856.3766
Q Predictions Std            334.9778
Q Predictions Max            1218.6604
Q Predictions Min            0.35322618
V Predictions Mean           862.3068
V Predictions Std            324.22403
V Predictions Max            1213.1986
V Predictions Min            -3.9135752
Log Pis Mean                 -0.3091572
Log Pis Std                  3.8134375
Log Pis Max                  26.146805
Log Pis Min                  -8.316294
Policy mu Mean               0.033889808
Policy mu Std                0.58491987
Policy mu Max                4.03586
Policy mu Min                -3.8129888
Policy log std Mean          -0.9763348
Policy log std Std           0.21694656
Policy log std Max           -0.30653417
Policy log std Min           -2.2018147
Z mean eval                  1.0188122
Z variance eval              0.034967773
total_rewards                [2879.46001935 2539.42191508  524.86496593 1951.93538873 3117.55377267
 2001.25290771 1500.47520699 3110.49543849 2985.15500622 3120.79850187]
total_rewards_mean           2373.141312303499
total_rewards_std            825.1537992797864
total_rewards_max            3120.7985018732516
total_rewards_min            524.864965925244
Number of train steps total  672000
Number of env steps total    604517
Number of rollouts total     0
Train Time (s)               150.32516769925132
(Previous) Eval Time (s)     32.30423727212474
Sample Time (s)              12.64185668155551
Epoch Time (s)               195.27126165293157
Total Train Time (s)         30656.86080244137
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:26:49.522733 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #167 | Epoch Duration: 195.36287379264832
2020-01-12 10:26:49.522877 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0197318
Z variance train             0.035113804
KL Divergence                19.138233
KL Loss                      1.9138234
QF Loss                      544.46765
VF Loss                      96.4263
Policy Loss                  -793.7903
Q Predictions Mean           788.5166
Q Predictions Std            354.9894
Q Predictions Max            1228.1234
Q Predictions Min            5.814343
V Predictions Mean           790.83545
V Predictions Std            352.60754
V Predictions Max            1223.8717
V Predictions Min            215.32574
Log Pis Mean                 -0.9442637
Log Pis Std                  2.7870293
Log Pis Max                  9.510321
Log Pis Min                  -7.7970066
Policy mu Mean               -0.040286876
Policy mu Std                0.51842403
Policy mu Max                2.4060276
Policy mu Min                -2.1729894
Policy log std Mean          -0.9447422
Policy log std Std           0.20818081
Policy log std Max           -0.3807006
Policy log std Min           -1.8511456
Z mean eval                  1.0705808
Z variance eval              0.010738514
total_rewards                [1411.36044212 3149.45238403 1347.54454339 2980.487101    379.75413122
 3100.2362281  1173.30930195  468.19778312  449.27578894  998.99012634]
total_rewards_mean           1545.8607830221365
total_rewards_std            1061.3521765715336
total_rewards_max            3149.452384033857
total_rewards_min            379.75413121551196
Number of train steps total  676000
Number of env steps total    609451
Number of rollouts total     0
Train Time (s)               149.8417543657124
(Previous) Eval Time (s)     31.808534920215607
Sample Time (s)              12.655200301669538
Epoch Time (s)               194.30548958759755
Total Train Time (s)         30851.261859737337
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:30:03.928176 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #168 | Epoch Duration: 194.40512990951538
2020-01-12 10:30:03.928518 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0739768
Z variance train             0.010734566
KL Divergence                21.40255
KL Loss                      2.140255
QF Loss                      2073.234
VF Loss                      234.93797
Policy Loss                  -876.58954
Q Predictions Mean           866.74475
Q Predictions Std            311.86658
Q Predictions Max            1227.6455
Q Predictions Min            208.17056
V Predictions Mean           878.9895
V Predictions Std            308.4489
V Predictions Max            1238.5486
V Predictions Min            204.71356
Log Pis Mean                 -0.21698211
Log Pis Std                  3.3724601
Log Pis Max                  20.276882
Log Pis Min                  -7.864152
Policy mu Mean               0.008769847
Policy mu Std                0.58496
Policy mu Max                3.1578186
Policy mu Min                -3.0131507
Policy log std Mean          -0.9840089
Policy log std Std           0.22057553
Policy log std Max           -0.2699737
Policy log std Min           -2.361929
Z mean eval                  1.0639586
Z variance eval              0.014552765
total_rewards                [1668.99533198 3147.84903968  594.9231167   940.88096143 1108.14244179
 3198.92047369 3112.76429109 3033.37276768  219.87624554 3142.48382197]
total_rewards_mean           2016.8208491557002
total_rewards_std            1163.3271250960022
total_rewards_max            3198.920473688152
total_rewards_min            219.87624554359604
Number of train steps total  680000
Number of env steps total    617320
Number of rollouts total     0
Train Time (s)               150.44002749305218
(Previous) Eval Time (s)     23.680578334257007
Sample Time (s)              12.131611990742385
Epoch Time (s)               186.25221781805158
Total Train Time (s)         31037.606232952792
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:33:10.274538 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #169 | Epoch Duration: 186.34583449363708
2020-01-12 10:33:10.274724 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0584087
Z variance train             0.014606744
KL Divergence                20.516466
KL Loss                      2.0516467
QF Loss                      635.1787
VF Loss                      126.94581
Policy Loss                  -867.17993
Q Predictions Mean           860.73834
Q Predictions Std            323.41986
Q Predictions Max            1246.0426
Q Predictions Min            38.1873
V Predictions Mean           864.70325
V Predictions Std            318.53885
V Predictions Max            1246.6377
V Predictions Min            -41.95686
Log Pis Mean                 -0.44382828
Log Pis Std                  3.196976
Log Pis Max                  18.316883
Log Pis Min                  -8.031166
Policy mu Mean               0.013124916
Policy mu Std                0.56310856
Policy mu Max                2.6844583
Policy mu Min                -4.0848455
Policy log std Mean          -0.9764823
Policy log std Std           0.21331821
Policy log std Max           -0.3849144
Policy log std Min           -2.1694584
Z mean eval                  1.1891725
Z variance eval              0.013773998
total_rewards                [2017.70727624 1203.08459371 2961.62560508 3186.04683284 1131.14763243
 3118.23805144 2981.3208353  3129.51556773 2845.36009954  716.4919643 ]
total_rewards_mean           2329.053845860713
total_rewards_std            921.4248544047623
total_rewards_max            3186.046832836536
total_rewards_min            716.4919643025471
Number of train steps total  684000
Number of env steps total    624091
Number of rollouts total     0
Train Time (s)               146.46746766380966
(Previous) Eval Time (s)     29.71187987923622
Sample Time (s)              11.639588795602322
Epoch Time (s)               187.8189363386482
Total Train Time (s)         31225.518743570894
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:36:18.189603 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #170 | Epoch Duration: 187.9147288799286
2020-01-12 10:36:18.189806 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.182092
Z variance train             0.013929208
KL Divergence                21.263794
KL Loss                      2.1263795
QF Loss                      1665.3105
VF Loss                      648.1735
Policy Loss                  -868.6311
Q Predictions Mean           859.13367
Q Predictions Std            332.1978
Q Predictions Max            1248.6201
Q Predictions Min            33.89097
V Predictions Mean           878.3622
V Predictions Std            323.67822
V Predictions Max            1251.154
V Predictions Min            56.52217
Log Pis Mean                 -0.14405403
Log Pis Std                  3.1862898
Log Pis Max                  14.54081
Log Pis Min                  -9.431418
Policy mu Mean               -0.029182516
Policy mu Std                0.57848054
Policy mu Max                3.6892412
Policy mu Min                -3.4689333
Policy log std Mean          -1.0077553
Policy log std Std           0.23528402
Policy log std Max           -0.35550314
Policy log std Min           -2.3649485
Z mean eval                  1.2306563
Z variance eval              0.017827822
total_rewards                [2798.40642434 1670.86706801  746.44640241 2298.79721153 3038.42177972
  434.74249842 3264.78877811 2622.77732507  365.13288791  206.94924235]
total_rewards_mean           1744.7329617860246
total_rewards_std            1147.1076529854956
total_rewards_max            3264.78877810766
total_rewards_min            206.94924235406714
Number of train steps total  688000
Number of env steps total    628620
Number of rollouts total     0
Train Time (s)               141.23819863284007
(Previous) Eval Time (s)     28.65375276422128
Sample Time (s)              10.651243435684592
Epoch Time (s)               180.54319483274594
Total Train Time (s)         31406.160399211105
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:39:18.833582 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #171 | Epoch Duration: 180.64361882209778
2020-01-12 10:39:18.833790 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2244904
Z variance train             0.018072924
KL Divergence                21.12846
KL Loss                      2.1128461
QF Loss                      1030.5815
VF Loss                      427.50967
Policy Loss                  -885.0974
Q Predictions Mean           876.839
Q Predictions Std            321.7414
Q Predictions Max            1279.3007
Q Predictions Min            -28.452911
V Predictions Mean           888.8749
V Predictions Std            320.72064
V Predictions Max            1293.0472
V Predictions Min            -28.368002
Log Pis Mean                 -0.2349211
Log Pis Std                  3.1134207
Log Pis Max                  21.549072
Log Pis Min                  -6.527759
Policy mu Mean               -0.0010456576
Policy mu Std                0.576468
Policy mu Max                3.78729
Policy mu Min                -2.637654
Policy log std Mean          -0.983235
Policy log std Std           0.22170618
Policy log std Max           -0.26431787
Policy log std Min           -1.9535471
Z mean eval                  1.1459744
Z variance eval              0.016265824
total_rewards                [3083.17125539 3122.90192628 3132.34727899   43.90282414 3028.04568696
 3167.71211401 3144.28522148  389.90056851 2014.62643971 3040.19529752]
total_rewards_mean           2416.7088613002315
total_rewards_std            1149.37770241744
total_rewards_max            3167.7121140127974
total_rewards_min            43.90282414055348
Number of train steps total  692000
Number of env steps total    633287
Number of rollouts total     0
Train Time (s)               142.11648711701855
(Previous) Eval Time (s)     27.585085663944483
Sample Time (s)              11.731971809174865
Epoch Time (s)               181.4335445901379
Total Train Time (s)         31587.68758200109
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:42:20.364026 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #172 | Epoch Duration: 181.53008151054382
2020-01-12 10:42:20.364272 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.149934
Z variance train             0.016545707
KL Divergence                20.902311
KL Loss                      2.0902312
QF Loss                      1145.1045
VF Loss                      100.23943
Policy Loss                  -843.8185
Q Predictions Mean           838.76135
Q Predictions Std            357.46033
Q Predictions Max            1225.429
Q Predictions Min            -28.960846
V Predictions Mean           843.5614
V Predictions Std            353.5442
V Predictions Max            1222.6403
V Predictions Min            -15.726723
Log Pis Mean                 -0.6033193
Log Pis Std                  3.0557394
Log Pis Max                  17.295734
Log Pis Min                  -8.160171
Policy mu Mean               -0.040364895
Policy mu Std                0.5545871
Policy mu Max                5.65138
Policy mu Min                -2.385737
Policy log std Mean          -0.9781021
Policy log std Std           0.21094674
Policy log std Max           -0.24751073
Policy log std Min           -1.91827
Z mean eval                  1.1076978
Z variance eval              0.0132840155
total_rewards                [1980.76166206 1004.99427407  432.11809628 1238.98810786  436.36248465
 3131.73720973  859.69129582 1463.1670116  2319.29879555  632.6016119 ]
total_rewards_mean           1349.9720549533527
total_rewards_std            841.929393774178
total_rewards_max            3131.737209732679
total_rewards_min            432.1180962782002
Number of train steps total  696000
Number of env steps total    641849
Number of rollouts total     0
Train Time (s)               150.3959006536752
(Previous) Eval Time (s)     26.81308984803036
Sample Time (s)              11.289082132745534
Epoch Time (s)               188.4980726344511
Total Train Time (s)         31776.29148914758
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:45:28.971401 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #173 | Epoch Duration: 188.60692238807678
2020-01-12 10:45:28.971760 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1117532
Z variance train             0.013243651
KL Divergence                21.096811
KL Loss                      2.1096811
QF Loss                      492.19223
VF Loss                      93.83022
Policy Loss                  -906.7041
Q Predictions Mean           900.3528
Q Predictions Std            329.99606
Q Predictions Max            1260.568
Q Predictions Min            236.245
V Predictions Mean           905.5935
V Predictions Std            322.3853
V Predictions Max            1264.0614
V Predictions Min            208.34033
Log Pis Mean                 -0.34977055
Log Pis Std                  3.0637434
Log Pis Max                  13.565114
Log Pis Min                  -11.652405
Policy mu Mean               0.020874519
Policy mu Std                0.56581753
Policy mu Max                2.8193712
Policy mu Min                -2.5663452
Policy log std Mean          -0.9837785
Policy log std Std           0.20718509
Policy log std Max           -0.41577095
Policy log std Min           -2.2492626
Z mean eval                  1.0836707
Z variance eval              0.011168128
total_rewards                [ 894.55911137  631.23295834  704.83099572 2110.23307028 2714.34299221
  234.79193916  590.90487721  713.78518544 3235.29574405 1170.29498557]
total_rewards_mean           1300.0271859356785
total_rewards_std            967.7823338329156
total_rewards_max            3235.2957440493055
total_rewards_min            234.79193916118058
Number of train steps total  700000
Number of env steps total    646716
Number of rollouts total     0
Train Time (s)               150.01592706004158
(Previous) Eval Time (s)     20.92790629575029
Sample Time (s)              12.2879733950831
Epoch Time (s)               183.23180675087497
Total Train Time (s)         31959.611453760415
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:48:32.293525 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #174 | Epoch Duration: 183.3214979171753
2020-01-12 10:48:32.293715 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0810246
Z variance train             0.011113601
KL Divergence                21.830664
KL Loss                      2.1830664
QF Loss                      893.6666
VF Loss                      164.38077
Policy Loss                  -883.5959
Q Predictions Mean           873.44037
Q Predictions Std            330.17627
Q Predictions Max            1259.9131
Q Predictions Min            -9.974417
V Predictions Mean           884.0073
V Predictions Std            319.29114
V Predictions Max            1256.1935
V Predictions Min            64.04076
Log Pis Mean                 -0.28226164
Log Pis Std                  3.8377361
Log Pis Max                  21.023355
Log Pis Min                  -7.2332997
Policy mu Mean               0.010995356
Policy mu Std                0.60421884
Policy mu Max                3.020705
Policy mu Min                -4.4942036
Policy log std Mean          -0.9827899
Policy log std Std           0.24315377
Policy log std Max           -0.36881846
Policy log std Min           -2.6152782
Z mean eval                  1.0753219
Z variance eval              0.023360632
total_rewards                [3207.18777999 3203.42367602  903.8534446  3068.69322828 3196.41236971
  352.1721258  2547.44474639 3189.25967023 3346.06337933 2959.4650102 ]
total_rewards_mean           2597.39754305551
total_rewards_std            1013.5861297742745
total_rewards_max            3346.0633793314923
total_rewards_min            352.1721257997492
Number of train steps total  704000
Number of env steps total    652338
Number of rollouts total     0
Train Time (s)               148.82587977405638
(Previous) Eval Time (s)     33.66441651294008
Sample Time (s)              11.71252993028611
Epoch Time (s)               194.20282621728256
Total Train Time (s)         32153.898388961796
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:51:46.581532 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #175 | Epoch Duration: 194.28768396377563
2020-01-12 10:51:46.581681 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0740931
Z variance train             0.023331543
KL Divergence                20.0569
KL Loss                      2.00569
QF Loss                      569.8011
VF Loss                      272.8021
Policy Loss                  -887.366
Q Predictions Mean           884.14923
Q Predictions Std            348.87387
Q Predictions Max            1253.802
Q Predictions Min            -16.952015
V Predictions Mean           882.1757
V Predictions Std            343.8642
V Predictions Max            1240.0902
V Predictions Min            -24.656721
Log Pis Mean                 -0.15496877
Log Pis Std                  3.2914736
Log Pis Max                  15.970392
Log Pis Min                  -6.6665864
Policy mu Mean               0.0135281235
Policy mu Std                0.56659764
Policy mu Max                2.9621084
Policy mu Min                -3.3189213
Policy log std Mean          -0.98862636
Policy log std Std           0.23570055
Policy log std Max           -0.42615473
Policy log std Min           -2.176118
Z mean eval                  1.1557825
Z variance eval              0.006564413
total_rewards                [ 121.31326226 1046.04724578 1348.05188257  779.26486981  716.36885158
 2886.4740009  3263.53862212  321.54813399 3067.5572477   149.38975378]
total_rewards_mean           1369.9553870490781
total_rewards_std            1174.600806008545
total_rewards_max            3263.5386221230483
total_rewards_min            121.31326226278267
Number of train steps total  708000
Number of env steps total    656823
Number of rollouts total     0
Train Time (s)               150.2069992031902
(Previous) Eval Time (s)     20.464693679939955
Sample Time (s)              12.201441495679319
Epoch Time (s)               182.87313437880948
Total Train Time (s)         32337.022504931316
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:54:49.708767 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #176 | Epoch Duration: 183.12696933746338
2020-01-12 10:54:49.708975 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.156656
Z variance train             0.0065314085
KL Divergence                23.477964
KL Loss                      2.3477964
QF Loss                      855.6699
VF Loss                      164.22601
Policy Loss                  -876.25726
Q Predictions Mean           866.7373
Q Predictions Std            342.23322
Q Predictions Max            1259.6962
Q Predictions Min            -49.58784
V Predictions Mean           874.3875
V Predictions Std            333.03363
V Predictions Max            1255.2506
V Predictions Min            278.87656
Log Pis Mean                 -0.14931644
Log Pis Std                  3.4900851
Log Pis Max                  17.30114
Log Pis Min                  -7.949586
Policy mu Mean               0.04957475
Policy mu Std                0.60165256
Policy mu Max                2.4351466
Policy mu Min                -2.7527876
Policy log std Mean          -0.98010874
Policy log std Std           0.22884102
Policy log std Max           -0.40329295
Policy log std Min           -2.2606595
Z mean eval                  1.1003226
Z variance eval              0.020869222
total_rewards                [2156.06264235 1285.15312561  127.31137382  150.78902216 3124.90508547
 1801.83534618  733.99738136  671.85617278  754.87248311 3117.32339126]
total_rewards_mean           1392.4106024095408
total_rewards_std            1060.2084796977645
total_rewards_max            3124.9050854683046
total_rewards_min            127.31137382352146
Number of train steps total  712000
Number of env steps total    662693
Number of rollouts total     0
Train Time (s)               144.80082961916924
(Previous) Eval Time (s)     19.66176605504006
Sample Time (s)              12.70110370637849
Epoch Time (s)               177.1636993805878
Total Train Time (s)         32514.2725039972
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:57:46.961604 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #177 | Epoch Duration: 177.25248551368713
2020-01-12 10:57:46.961792 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1065614
Z variance train             0.020997778
KL Divergence                19.911562
KL Loss                      1.9911562
QF Loss                      881.5096
VF Loss                      183.66081
Policy Loss                  -848.88654
Q Predictions Mean           838.58685
Q Predictions Std            342.87485
Q Predictions Max            1224.2439
Q Predictions Min            -42.109108
V Predictions Mean           843.6168
V Predictions Std            334.88412
V Predictions Max            1222.0608
V Predictions Min            -13.633079
Log Pis Mean                 -0.32489938
Log Pis Std                  3.2811735
Log Pis Max                  15.5006485
Log Pis Min                  -8.33583
Policy mu Mean               -0.018590854
Policy mu Std                0.56258625
Policy mu Max                2.5505831
Policy mu Min                -3.1236577
Policy log std Mean          -0.9961879
Policy log std Std           0.23048896
Policy log std Max           -0.1256926
Policy log std Min           -2.0917156
Z mean eval                  1.1254618
Z variance eval              0.016560113
total_rewards                [3301.43719184 1679.20932595  786.36166472 3416.32519134 2130.63770258
 1574.05415758  784.79673704  541.59666857 1153.0673476  2222.68797307]
total_rewards_mean           1759.017396029568
total_rewards_std            962.4891943118282
total_rewards_max            3416.325191339355
total_rewards_min            541.5966685715193
Number of train steps total  716000
Number of env steps total    668574
Number of rollouts total     0
Train Time (s)               141.80258687818423
(Previous) Eval Time (s)     27.79942943993956
Sample Time (s)              11.277997652068734
Epoch Time (s)               180.88001397019252
Total Train Time (s)         32695.27693916997
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:00:47.968396 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #178 | Epoch Duration: 181.0064549446106
2020-01-12 11:00:47.968618 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1178993
Z variance train             0.016649133
KL Divergence                20.792507
KL Loss                      2.0792508
QF Loss                      1171.154
VF Loss                      295.891
Policy Loss                  -872.36237
Q Predictions Mean           866.6904
Q Predictions Std            348.10046
Q Predictions Max            1291.4938
Q Predictions Min            161.6137
V Predictions Mean           880.6813
V Predictions Std            343.85675
V Predictions Max            1283.8444
V Predictions Min            276.88525
Log Pis Mean                 -0.75903213
Log Pis Std                  2.717814
Log Pis Max                  8.173167
Log Pis Min                  -7.7576017
Policy mu Mean               -0.0054660887
Policy mu Std                0.54391545
Policy mu Max                3.182597
Policy mu Min                -2.3313153
Policy log std Mean          -0.9523893
Policy log std Std           0.20071618
Policy log std Max           -0.19304222
Policy log std Min           -1.948184
Z mean eval                  1.0352858
Z variance eval              0.009912437
total_rewards                [ 892.3586693   506.15708618 1692.0939083  2486.88192305  779.19411472
 1620.09350584  570.76858111 1549.34983105 1833.25747381 1693.74113761]
total_rewards_mean           1362.3896230975229
total_rewards_std            610.4840495683985
total_rewards_max            2486.8819230525282
total_rewards_min            506.15708618399646
Number of train steps total  720000
Number of env steps total    674832
Number of rollouts total     0
Train Time (s)               143.03084935201332
(Previous) Eval Time (s)     28.73566688876599
Sample Time (s)              11.205805457662791
Epoch Time (s)               182.9723216984421
Total Train Time (s)         32878.3373118774
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:03:51.030920 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #179 | Epoch Duration: 183.06215572357178
2020-01-12 11:03:51.031100 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.034478
Z variance train             0.009879303
KL Divergence                20.945217
KL Loss                      2.0945218
QF Loss                      818.0625
VF Loss                      182.74355
Policy Loss                  -844.0697
Q Predictions Mean           836.027
Q Predictions Std            356.75998
Q Predictions Max            1267.5111
Q Predictions Min            91.90061
V Predictions Mean           841.8938
V Predictions Std            350.98297
V Predictions Max            1265.697
V Predictions Min            226.95685
Log Pis Mean                 -0.5371656
Log Pis Std                  3.0662057
Log Pis Max                  16.331238
Log Pis Min                  -8.117907
Policy mu Mean               0.007646811
Policy mu Std                0.55553037
Policy mu Max                3.2038407
Policy mu Min                -3.0257623
Policy log std Mean          -0.9696951
Policy log std Std           0.21837033
Policy log std Max           -0.30620974
Policy log std Min           -2.092452
Z mean eval                  1.0871649
Z variance eval              0.013879505
total_rewards                [1347.61384849 1990.70362256  242.32256925 3468.25621811   27.63736483
 3314.947053   1016.97216708 2483.67908252 3521.31274835 3238.72677983]
total_rewards_mean           2065.217145402789
total_rewards_std            1276.5889483567316
total_rewards_max            3521.31274834766
total_rewards_min            27.637364833258665
Number of train steps total  724000
Number of env steps total    681938
Number of rollouts total     0
Train Time (s)               151.94988083234057
(Previous) Eval Time (s)     29.489654507953674
Sample Time (s)              11.865444473456591
Epoch Time (s)               193.30497981375083
Total Train Time (s)         33071.73290324723
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:07:04.429613 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #180 | Epoch Duration: 193.39829778671265
2020-01-12 11:07:04.429830 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0836985
Z variance train             0.014093539
KL Divergence                22.046886
KL Loss                      2.2046888
QF Loss                      982.2501
VF Loss                      130.938
Policy Loss                  -865.68994
Q Predictions Mean           861.32324
Q Predictions Std            345.0726
Q Predictions Max            1249.8287
Q Predictions Min            251.52708
V Predictions Mean           862.09753
V Predictions Std            346.84525
V Predictions Max            1252.4363
V Predictions Min            277.0223
Log Pis Mean                 -0.32145712
Log Pis Std                  3.0339923
Log Pis Max                  12.574976
Log Pis Min                  -8.007811
Policy mu Mean               -0.021391079
Policy mu Std                0.5727838
Policy mu Max                2.7581341
Policy mu Min                -2.0936387
Policy log std Mean          -0.9624467
Policy log std Std           0.22628358
Policy log std Max           -0.35511225
Policy log std Min           -2.0891702
Z mean eval                  1.3253672
Z variance eval              0.0104210535
total_rewards                [3285.05256091 1968.65381609 3145.2083661  2715.69702383 3167.44081254
 1302.7529279  1949.2474948   110.58852522 2973.68210675 1412.48070334]
total_rewards_mean           2203.080433747353
total_rewards_std            988.8583978820466
total_rewards_max            3285.0525609060655
total_rewards_min            110.58852522455169
Number of train steps total  728000
Number of env steps total    688361
Number of rollouts total     0
Train Time (s)               151.2604408399202
(Previous) Eval Time (s)     27.915462971199304
Sample Time (s)              11.794410509057343
Epoch Time (s)               190.97031432017684
Total Train Time (s)         33262.79363320256
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:10:15.492992 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #181 | Epoch Duration: 191.0630009174347
2020-01-12 11:10:15.493228 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3224427
Z variance train             0.010610446
KL Divergence                22.736523
KL Loss                      2.2736523
QF Loss                      1079.3087
VF Loss                      307.86444
Policy Loss                  -879.8668
Q Predictions Mean           870.2113
Q Predictions Std            342.76984
Q Predictions Max            1245.8895
Q Predictions Min            8.323293
V Predictions Mean           867.79724
V Predictions Std            334.85327
V Predictions Max            1222.3765
V Predictions Min            11.660019
Log Pis Mean                 -0.16006762
Log Pis Std                  3.4814856
Log Pis Max                  11.617233
Log Pis Min                  -7.2958117
Policy mu Mean               0.007647534
Policy mu Std                0.5820906
Policy mu Max                3.3278947
Policy mu Min                -3.4301963
Policy log std Mean          -1.0088269
Policy log std Std           0.24917522
Policy log std Max           -0.39717197
Policy log std Min           -2.2015643
Z mean eval                  1.1505777
Z variance eval              0.008253239
total_rewards                [3279.86875396 3258.03529568 3495.12926853 3218.2319563   590.14631142
 2637.8249801  3279.34175393  340.66574672 3310.38887522 3421.31139225]
total_rewards_mean           2683.094433409927
total_rewards_std            1131.189467148677
total_rewards_max            3495.1292685275525
total_rewards_min            340.66574672108334
Number of train steps total  732000
Number of env steps total    694012
Number of rollouts total     0
Train Time (s)               151.11385653121397
(Previous) Eval Time (s)     33.879407851956785
Sample Time (s)              11.789575174450874
Epoch Time (s)               196.78283955762163
Total Train Time (s)         33459.67566028237
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:13:32.378116 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #182 | Epoch Duration: 196.8847143650055
2020-01-12 11:13:32.378392 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1537083
Z variance train             0.008273237
KL Divergence                24.142979
KL Loss                      2.4142978
QF Loss                      553.08655
VF Loss                      234.19829
Policy Loss                  -824.1093
Q Predictions Mean           817.5619
Q Predictions Std            370.22562
Q Predictions Max            1292.1243
Q Predictions Min            -36.03129
V Predictions Mean           822.1719
V Predictions Std            364.45776
V Predictions Max            1271.1406
V Predictions Min            23.762627
Log Pis Mean                 -0.45834276
Log Pis Std                  3.1615162
Log Pis Max                  20.182983
Log Pis Min                  -7.3472238
Policy mu Mean               -0.0043458785
Policy mu Std                0.5632023
Policy mu Max                3.39564
Policy mu Min                -4.164534
Policy log std Mean          -0.9592327
Policy log std Std           0.21141334
Policy log std Max           -0.30507302
Policy log std Min           -1.9460762
Z mean eval                  1.0860054
Z variance eval              0.011330461
total_rewards                [1672.34593923  530.62922926  810.37859927  856.38256675 2017.89564645
 1213.37314876 1637.66235183 3289.25086395   58.02825247  549.86686495]
total_rewards_mean           1263.5813462916517
total_rewards_std            886.1739116651893
total_rewards_max            3289.250863950011
total_rewards_min            58.02825247477902
Number of train steps total  736000
Number of env steps total    700084
Number of rollouts total     0
Train Time (s)               150.383162365295
(Previous) Eval Time (s)     24.537167890928686
Sample Time (s)              10.842543374281377
Epoch Time (s)               185.76287363050506
Total Train Time (s)         33645.526710845996
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:16:38.231854 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #183 | Epoch Duration: 185.853280544281
2020-01-12 11:16:38.232123 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0813439
Z variance train             0.011395188
KL Divergence                22.868717
KL Loss                      2.2868717
QF Loss                      700.7653
VF Loss                      187.0997
Policy Loss                  -864.7077
Q Predictions Mean           861.2545
Q Predictions Std            349.08725
Q Predictions Max            1243.6376
Q Predictions Min            -15.606261
V Predictions Mean           868.36597
V Predictions Std            347.2581
V Predictions Max            1247.679
V Predictions Min            96.63404
Log Pis Mean                 -0.596467
Log Pis Std                  2.9987178
Log Pis Max                  14.67665
Log Pis Min                  -9.391786
Policy mu Mean               -0.018923134
Policy mu Std                0.5538228
Policy mu Max                2.8235724
Policy mu Min                -2.8393872
Policy log std Mean          -0.9548174
Policy log std Std           0.19518784
Policy log std Max           -0.3429153
Policy log std Min           -1.978448
Z mean eval                  1.1912628
Z variance eval              0.0065843402
total_rewards                [2070.68034425 3287.51848766 1694.63454668 3095.66686523 3395.33533718
 3076.05206995 3233.35471905 3293.791093    724.35482278 3383.20914639]
total_rewards_mean           2725.459743216598
total_rewards_std            867.9839453040104
total_rewards_max            3395.3353371804324
total_rewards_min            724.3548227835726
Number of train steps total  740000
Number of env steps total    707433
Number of rollouts total     0
Train Time (s)               142.1887872312218
(Previous) Eval Time (s)     36.45491302991286
Sample Time (s)              10.846237654797733
Epoch Time (s)               189.4899379159324
Total Train Time (s)         33835.10795861343
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:19:47.813496 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #184 | Epoch Duration: 189.58122396469116
2020-01-12 11:19:47.813637 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #184 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1953757
Z variance train             0.006587325
KL Divergence                22.122295
KL Loss                      2.2122295
QF Loss                      1002.3098
VF Loss                      152.9399
Policy Loss                  -863.4439
Q Predictions Mean           854.24243
Q Predictions Std            356.51263
Q Predictions Max            1275.157
Q Predictions Min            93.897385
V Predictions Mean           861.4787
V Predictions Std            354.19107
V Predictions Max            1274.1069
V Predictions Min            -10.714715
Log Pis Mean                 -0.5280184
Log Pis Std                  3.354779
Log Pis Max                  22.00865
Log Pis Min                  -6.311781
Policy mu Mean               0.004649676
Policy mu Std                0.56711406
Policy mu Max                3.9008589
Policy mu Min                -3.3396122
Policy log std Mean          -0.97442085
Policy log std Std           0.22838862
Policy log std Max           -0.30230802
Policy log std Min           -2.199801
Z mean eval                  1.2222726
Z variance eval              0.008128271
total_rewards                [3391.69996661 3174.40131077 1565.40350651 3114.96556276 3333.0673902
 1989.87547282 1130.14993271 1979.703284    401.38678056 3273.88313092]
total_rewards_mean           2335.453633785405
total_rewards_std            1016.6288838906833
total_rewards_max            3391.6999666120896
total_rewards_min            401.38678055651104
Number of train steps total  744000
Number of env steps total    713314
Number of rollouts total     0
Train Time (s)               141.80431928113103
(Previous) Eval Time (s)     28.156042288057506
Sample Time (s)              10.355266250204295
Epoch Time (s)               180.31562781939283
Total Train Time (s)         34015.53370776726
Epoch                        185
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:22:48.242610 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #185 | Epoch Duration: 180.4288456439972
2020-01-12 11:22:48.242815 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #185 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.210881
Z variance train             0.008141441
KL Divergence                21.7928
KL Loss                      2.17928
QF Loss                      782.07544
VF Loss                      141.19745
Policy Loss                  -903.7664
Q Predictions Mean           897.43677
Q Predictions Std            335.0181
Q Predictions Max            1273.9972
Q Predictions Min            -17.802744
V Predictions Mean           910.5481
V Predictions Std            327.46002
V Predictions Max            1271.1616
V Predictions Min            231.68024
Log Pis Mean                 -0.29027262
Log Pis Std                  3.0955245
Log Pis Max                  13.899207
Log Pis Min                  -8.516551
Policy mu Mean               -0.00827725
Policy mu Std                0.5791747
Policy mu Max                3.7431672
Policy mu Min                -2.7881355
Policy log std Mean          -1.0007974
Policy log std Std           0.20997995
Policy log std Max           -0.49853554
Policy log std Min           -2.0417829
Z mean eval                  1.0977356
Z variance eval              0.009962166
total_rewards                [1277.93429251  528.98990169  124.60188424 1885.90345657  277.4188844
 2381.03367094  343.57711756 1994.94255475   26.62362259 1483.28192777]
total_rewards_mean           1032.4307312994777
total_rewards_std            828.9106952108929
total_rewards_max            2381.0336709438684
total_rewards_min            26.623622585875115
Number of train steps total  748000
Number of env steps total    717533
Number of rollouts total     0
Train Time (s)               146.52207550173625
(Previous) Eval Time (s)     13.590126519091427
Sample Time (s)              11.865294713992625
Epoch Time (s)               171.9774967348203
Total Train Time (s)         34187.60594679415
Epoch                        186
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:25:40.319466 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #186 | Epoch Duration: 172.07645535469055
2020-01-12 11:25:40.319877 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1082534
Z variance train             0.009927759
KL Divergence                21.069847
KL Loss                      2.1069849
QF Loss                      620.1838
VF Loss                      251.35977
Policy Loss                  -821.5682
Q Predictions Mean           815.4731
Q Predictions Std            365.7501
Q Predictions Max            1254.4595
Q Predictions Min            -101.83784
V Predictions Mean           814.66455
V Predictions Std            359.85593
V Predictions Max            1243.1754
V Predictions Min            34.19482
Log Pis Mean                 -0.63691044
Log Pis Std                  3.7087424
Log Pis Max                  22.765776
Log Pis Min                  -8.051193
Policy mu Mean               0.019326877
Policy mu Std                0.57727104
Policy mu Max                3.2130613
Policy mu Min                -3.2229977
Policy log std Mean          -0.9621674
Policy log std Std           0.21590094
Policy log std Max           -0.27918947
Policy log std Min           -1.9934186
Z mean eval                  1.1174257
Z variance eval              0.0060321353
total_rewards                [ 602.22334642  991.4059209   805.67258381  179.3279537  3384.07988143
 3150.88358632 3437.47610721  866.62151355 3375.49618445  832.13737443]
total_rewards_mean           1762.532445221005
total_rewards_std            1303.6635009311578
total_rewards_max            3437.4761072073466
total_rewards_min            179.32795369640743
Number of train steps total  752000
Number of env steps total    722990
Number of rollouts total     0
Train Time (s)               152.444268676918
(Previous) Eval Time (s)     22.134009561035782
Sample Time (s)              13.087863401975483
Epoch Time (s)               187.66614163992926
Total Train Time (s)         34375.36611807998
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:28:48.081059 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #187 | Epoch Duration: 187.76091599464417
2020-01-12 11:28:48.081276 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1173315
Z variance train             0.0060534
KL Divergence                23.090916
KL Loss                      2.3090916
QF Loss                      888.3511
VF Loss                      165.58163
Policy Loss                  -900.0864
Q Predictions Mean           890.05255
Q Predictions Std            347.95776
Q Predictions Max            1297.3551
Q Predictions Min            104.8108
V Predictions Mean           901.8938
V Predictions Std            341.25668
V Predictions Max            1305.0558
V Predictions Min            199.401
Log Pis Mean                 -0.20650855
Log Pis Std                  3.3483748
Log Pis Max                  17.82299
Log Pis Min                  -9.369988
Policy mu Mean               -8.358387e-06
Policy mu Std                0.57404107
Policy mu Max                2.8937395
Policy mu Min                -2.6505308
Policy log std Mean          -0.9892845
Policy log std Std           0.2059049
Policy log std Max           -0.3175751
Policy log std Min           -2.1993656
Z mean eval                  1.0892996
Z variance eval              0.009873608
total_rewards                [2293.94672318 2344.78535286  629.16040487 1227.79627763 2109.71295489
  928.78590254 3329.12961946 1410.28716111 1962.46411813 2334.83581616]
total_rewards_mean           1857.0904330852804
total_rewards_std            765.7647991280945
total_rewards_max            3329.1296194643346
total_rewards_min            629.1604048720054
Number of train steps total  756000
Number of env steps total    730762
Number of rollouts total     0
Train Time (s)               151.69031224306673
(Previous) Eval Time (s)     21.00969175901264
Sample Time (s)              12.208362989127636
Epoch Time (s)               184.908366991207
Total Train Time (s)         34560.362699450925
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:31:53.080136 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #188 | Epoch Duration: 184.99871373176575
2020-01-12 11:31:53.080325 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #188 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0917172
Z variance train             0.009865301
KL Divergence                21.652168
KL Loss                      2.165217
QF Loss                      1216.6204
VF Loss                      256.97882
Policy Loss                  -869.3175
Q Predictions Mean           860.7187
Q Predictions Std            359.3523
Q Predictions Max            1269.3019
Q Predictions Min            226.31567
V Predictions Mean           863.88074
V Predictions Std            353.8787
V Predictions Max            1265.6836
V Predictions Min            256.42026
Log Pis Mean                 -0.6285397
Log Pis Std                  2.8926878
Log Pis Max                  13.369419
Log Pis Min                  -10.036106
Policy mu Mean               -0.009293106
Policy mu Std                0.5528805
Policy mu Max                2.3120935
Policy mu Min                -2.5954053
Policy log std Mean          -0.9614657
Policy log std Std           0.20918329
Policy log std Max           -0.35383224
Policy log std Min           -1.8955541
Z mean eval                  1.0797776
Z variance eval              0.008015996
total_rewards                [1414.52277852 1174.98083546 3170.3769988  3283.42018954 3232.5143603
 1025.20031436 3011.94860404 3410.94376736 1151.2257599  3183.93590632]
total_rewards_mean           2405.9069514594717
total_rewards_std            999.951782677132
total_rewards_max            3410.9437673578905
total_rewards_min            1025.200314363733
Number of train steps total  760000
Number of env steps total    736102
Number of rollouts total     0
Train Time (s)               151.81704868981615
(Previous) Eval Time (s)     36.118081491906196
Sample Time (s)              10.742676356807351
Epoch Time (s)               198.6778065385297
Total Train Time (s)         34759.14346957719
Epoch                        189
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:35:11.863610 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #189 | Epoch Duration: 198.78314018249512
2020-01-12 11:35:11.863829 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.081322
Z variance train             0.007987061
KL Divergence                23.15178
KL Loss                      2.315178
QF Loss                      653.3334
VF Loss                      187.20297
Policy Loss                  -878.22144
Q Predictions Mean           871.9376
Q Predictions Std            348.60803
Q Predictions Max            1282.0393
Q Predictions Min            -76.47644
V Predictions Mean           878.5508
V Predictions Std            341.5162
V Predictions Max            1290.7362
V Predictions Min            278.13306
Log Pis Mean                 -0.46141905
Log Pis Std                  3.0266776
Log Pis Max                  15.13836
Log Pis Min                  -7.2218637
Policy mu Mean               0.015194897
Policy mu Std                0.56505406
Policy mu Max                3.5807328
Policy mu Min                -3.2369406
Policy log std Mean          -0.9602599
Policy log std Std           0.20684017
Policy log std Max           -0.18894118
Policy log std Min           -1.9522371
Z mean eval                  1.0117203
Z variance eval              0.0094366735
total_rewards                [3129.68740753 3500.67130502 1387.6205897  1524.97517513 2752.72140327
 1463.04418372 3174.81686801 1207.85956662 3248.36476947 2476.05053417]
total_rewards_mean           2386.581180265167
total_rewards_std            853.3490463682897
total_rewards_max            3500.671305019934
total_rewards_min            1207.8595666217732
Number of train steps total  764000
Number of env steps total    745768
Number of rollouts total     0
Train Time (s)               151.44936726195738
(Previous) Eval Time (s)     26.325090452097356
Sample Time (s)              12.059164772275835
Epoch Time (s)               189.83362248633057
Total Train Time (s)         34949.082793288864
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:38:21.806038 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #190 | Epoch Duration: 189.94204688072205
2020-01-12 11:38:21.806270 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0165513
Z variance train             0.009364283
KL Divergence                20.967575
KL Loss                      2.0967577
QF Loss                      560.148
VF Loss                      137.87675
Policy Loss                  -879.5269
Q Predictions Mean           874.59625
Q Predictions Std            342.21307
Q Predictions Max            1282.2913
Q Predictions Min            241.55396
V Predictions Mean           877.34204
V Predictions Std            342.15292
V Predictions Max            1274.1001
V Predictions Min            230.95335
Log Pis Mean                 -0.42421332
Log Pis Std                  2.971557
Log Pis Max                  9.43477
Log Pis Min                  -10.85659
Policy mu Mean               0.011120932
Policy mu Std                0.5483615
Policy mu Max                2.1822715
Policy mu Min                -2.4337752
Policy log std Mean          -0.96969616
Policy log std Std           0.22439261
Policy log std Max           -0.30574167
Policy log std Min           -2.183377
Z mean eval                  1.0902178
Z variance eval              0.017609742
total_rewards                [1467.69848285 1128.07818852 3375.80649726 3491.69282225 3434.40447694
   85.27755221  871.77918388  141.26077895 1942.54734474 2124.02389341]
total_rewards_mean           1806.256922100584
total_rewards_std            1235.1669698105704
total_rewards_max            3491.6928222522697
total_rewards_min            85.27755220686764
Number of train steps total  768000
Number of env steps total    750861
Number of rollouts total     0
Train Time (s)               142.16148529900238
(Previous) Eval Time (s)     21.66134360106662
Sample Time (s)              11.123320020269603
Epoch Time (s)               174.9461489203386
Total Train Time (s)         35124.115473868325
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:41:16.841001 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #191 | Epoch Duration: 175.03457736968994
2020-01-12 11:41:16.841188 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0906979
Z variance train             0.017649977
KL Divergence                20.330982
KL Loss                      2.0330982
QF Loss                      820.7438
VF Loss                      119.05687
Policy Loss                  -863.59863
Q Predictions Mean           858.579
Q Predictions Std            354.9025
Q Predictions Max            1271.3539
Q Predictions Min            -54.924347
V Predictions Mean           866.3235
V Predictions Std            351.8614
V Predictions Max            1283.8258
V Predictions Min            -37.21148
Log Pis Mean                 -0.7751923
Log Pis Std                  3.0990183
Log Pis Max                  12.334565
Log Pis Min                  -7.502907
Policy mu Mean               0.02569215
Policy mu Std                0.5615399
Policy mu Max                3.9957707
Policy mu Min                -2.411466
Policy log std Mean          -0.9629464
Policy log std Std           0.20725784
Policy log std Max           -0.45665407
Policy log std Min           -1.9891393
Z mean eval                  1.0508301
Z variance eval              0.012199258
total_rewards                [3321.31990775 1029.8289473  3252.44598632 2021.16312739  432.50955866
 1803.17927962  548.78838091  607.74380129 1565.14435577 1837.98580919]
total_rewards_mean           1642.0109154204165
total_rewards_std            986.4142306949441
total_rewards_max            3321.319907753666
total_rewards_min            432.50955865873755
Number of train steps total  772000
Number of env steps total    757439
Number of rollouts total     0
Train Time (s)               142.12829228676856
(Previous) Eval Time (s)     24.345157032832503
Sample Time (s)              11.247187841683626
Epoch Time (s)               177.72063716128469
Total Train Time (s)         35301.92524700146
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:44:14.653637 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #192 | Epoch Duration: 177.81230878829956
2020-01-12 11:44:14.653836 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0579592
Z variance train             0.012261875
KL Divergence                21.39128
KL Loss                      2.139128
QF Loss                      562.3188
VF Loss                      179.72395
Policy Loss                  -896.3641
Q Predictions Mean           893.2206
Q Predictions Std            342.79294
Q Predictions Max            1285.1656
Q Predictions Min            246.00255
V Predictions Mean           891.7421
V Predictions Std            338.763
V Predictions Max            1264.7985
V Predictions Min            245.06694
Log Pis Mean                 -0.73245317
Log Pis Std                  3.138662
Log Pis Max                  12.613906
Log Pis Min                  -8.362744
Policy mu Mean               -0.014810802
Policy mu Std                0.5444565
Policy mu Max                2.6515257
Policy mu Min                -3.5879807
Policy log std Mean          -0.9623882
Policy log std Std           0.23227896
Policy log std Max           -0.20547777
Policy log std Min           -2.272778
Z mean eval                  1.0919312
Z variance eval              0.012527826
total_rewards                [3383.35787612 3434.16048039  628.57585242 1188.52539261 1310.62549265
 1590.5125126   547.45456767 3502.70448852  314.00429763 3316.31396175]
total_rewards_mean           1921.6234922351027
total_rewards_std            1266.2761128230788
total_rewards_max            3502.7044885210466
total_rewards_min            314.00429763012573
Number of train steps total  776000
Number of env steps total    762203
Number of rollouts total     0
Train Time (s)               147.14015239709988
(Previous) Eval Time (s)     21.222222382202744
Sample Time (s)              11.087307342793792
Epoch Time (s)               179.44968212209642
Total Train Time (s)         35481.462309216615
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:47:14.193189 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #193 | Epoch Duration: 179.5391981601715
2020-01-12 11:47:14.193383 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #193 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0987284
Z variance train             0.0126182465
KL Divergence                21.63637
KL Loss                      2.163637
QF Loss                      746.4238
VF Loss                      299.53973
Policy Loss                  -853.0224
Q Predictions Mean           846.1881
Q Predictions Std            350.03262
Q Predictions Max            1304.6503
Q Predictions Min            27.55241
V Predictions Mean           853.9894
V Predictions Std            344.84744
V Predictions Max            1283.4441
V Predictions Min            153.5735
Log Pis Mean                 -0.8226207
Log Pis Std                  3.2016342
Log Pis Max                  18.168783
Log Pis Min                  -11.703276
Policy mu Mean               -0.0004957542
Policy mu Std                0.569558
Policy mu Max                3.503994
Policy mu Min                -3.0104682
Policy log std Mean          -0.9561528
Policy log std Std           0.20502853
Policy log std Max           -0.06804299
Policy log std Min           -1.9230014
Z mean eval                  1.1016161
Z variance eval              0.016095882
total_rewards                [3283.56990947 3537.24024762 1533.27056484 1568.19084133  353.0371697
 3213.58109735 3340.25350637 3303.70538275 3371.54215147 3333.46444181]
total_rewards_mean           2683.7855312715883
total_rewards_std            1052.6051681529777
total_rewards_max            3537.240247622984
total_rewards_min            353.03716969620507
Number of train steps total  780000
Number of env steps total    767973
Number of rollouts total     0
Train Time (s)               153.11191471712664
(Previous) Eval Time (s)     30.108005065005273
Sample Time (s)              12.66098963888362
Epoch Time (s)               195.88090942101553
Total Train Time (s)         35677.437690145336
Epoch                        194
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:50:30.171160 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #194 | Epoch Duration: 195.97763109207153
2020-01-12 11:50:30.171443 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1182112
Z variance train             0.016587103
KL Divergence                20.76865
KL Loss                      2.076865
QF Loss                      834.1061
VF Loss                      429.61072
Policy Loss                  -831.7376
Q Predictions Mean           816.7574
Q Predictions Std            366.0534
Q Predictions Max            1275.8545
Q Predictions Min            37.73117
V Predictions Mean           819.1117
V Predictions Std            356.88693
V Predictions Max            1266.4104
V Predictions Min            148.58719
Log Pis Mean                 -0.7678799
Log Pis Std                  3.0116336
Log Pis Max                  12.436422
Log Pis Min                  -8.484849
Policy mu Mean               -0.0014596921
Policy mu Std                0.540866
Policy mu Max                1.8818138
Policy mu Min                -2.411131
Policy log std Mean          -0.95996684
Policy log std Std           0.21053459
Policy log std Max           -0.45389986
Policy log std Min           -1.8571434
Z mean eval                  1.0244181
Z variance eval              0.0074942955
total_rewards                [2315.54407708  303.02383516 3236.2150154    46.57576132 2076.73746424
 3136.40587958  586.38427277  489.0827515   265.21469017  275.92122512]
total_rewards_mean           1273.1104972340413
total_rewards_std            1208.3096253738242
total_rewards_max            3236.2150154014917
total_rewards_min            46.575761320237746
Number of train steps total  784000
Number of env steps total    772827
Number of rollouts total     0
Train Time (s)               151.59753649914637
(Previous) Eval Time (s)     15.701583862304688
Sample Time (s)              11.797971048392355
Epoch Time (s)               179.09709140984342
Total Train Time (s)         35856.62126999209
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:53:29.357701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #195 | Epoch Duration: 179.1861035823822
2020-01-12 11:53:29.357911 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0232586
Z variance train             0.007403561
KL Divergence                22.495552
KL Loss                      2.2495553
QF Loss                      417.94598
VF Loss                      119.93836
Policy Loss                  -871.9908
Q Predictions Mean           864.2619
Q Predictions Std            360.58447
Q Predictions Max            1304.4948
Q Predictions Min            -54.829826
V Predictions Mean           867.9458
V Predictions Std            356.0455
V Predictions Max            1309.6888
V Predictions Min            -29.524794
Log Pis Mean                 -0.58836555
Log Pis Std                  2.8478997
Log Pis Max                  13.896923
Log Pis Min                  -6.27643
Policy mu Mean               0.014466416
Policy mu Std                0.55503
Policy mu Max                2.6165402
Policy mu Min                -2.4882588
Policy log std Mean          -0.95707965
Policy log std Std           0.2097776
Policy log std Max           -0.36707532
Policy log std Min           -2.1053765
Z mean eval                  1.1493685
Z variance eval              0.013833824
total_rewards                [ 957.39274558  116.67582392 1822.46014161 3339.23451552 1253.00876536
 2411.73174398  551.32894926 1944.95497166 1608.97783204 3365.27082153]
total_rewards_mean           1737.1036310453521
total_rewards_std            1030.23899042486
total_rewards_max            3365.2708215277216
total_rewards_min            116.67582392455535
Number of train steps total  788000
Number of env steps total    779681
Number of rollouts total     0
Train Time (s)               152.62843635072932
(Previous) Eval Time (s)     24.506486226804554
Sample Time (s)              11.742517571896315
Epoch Time (s)               188.87744014943019
Total Train Time (s)         36045.59151741117
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:56:38.331640 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #196 | Epoch Duration: 188.973530292511
2020-01-12 11:56:38.332012 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.148143
Z variance train             0.013758679
KL Divergence                22.580612
KL Loss                      2.2580612
QF Loss                      812.7106
VF Loss                      184.19008
Policy Loss                  -865.91125
Q Predictions Mean           860.71326
Q Predictions Std            356.61115
Q Predictions Max            1297.5474
Q Predictions Min            260.23972
V Predictions Mean           865.13727
V Predictions Std            354.80762
V Predictions Max            1281.5426
V Predictions Min            278.29407
Log Pis Mean                 -0.7082487
Log Pis Std                  2.8033116
Log Pis Max                  15.440068
Log Pis Min                  -7.349331
Policy mu Mean               0.007386043
Policy mu Std                0.54057086
Policy mu Max                2.431421
Policy mu Min                -2.1386628
Policy log std Mean          -0.96045864
Policy log std Std           0.2117728
Policy log std Max           -0.4592605
Policy log std Min           -2.3008451
Z mean eval                  1.2567686
Z variance eval              0.007923073
total_rewards                [3288.80867693  476.38452867 2437.84451299 3210.52772775 3503.33696008
 3406.05444734 3175.67075349 3300.45015938 3547.46291172 3161.88952674]
total_rewards_mean           2950.8430205091363
total_rewards_std            874.843117848453
total_rewards_max            3547.4629117243567
total_rewards_min            476.3845286713917
Number of train steps total  792000
Number of env steps total    788449
Number of rollouts total     0
Train Time (s)               151.06196016306058
(Previous) Eval Time (s)     34.56239088391885
Sample Time (s)              11.549260355066508
Epoch Time (s)               197.17361140204594
Total Train Time (s)         36242.8767894716
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:59:55.618524 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #197 | Epoch Duration: 197.28625774383545
2020-01-12 11:59:55.618712 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2542745
Z variance train             0.007963385
KL Divergence                22.392204
KL Loss                      2.2392204
QF Loss                      576.18274
VF Loss                      179.18413
Policy Loss                  -882.4584
Q Predictions Mean           875.38525
Q Predictions Std            352.17206
Q Predictions Max            1303.0988
Q Predictions Min            14.211243
V Predictions Mean           882.4614
V Predictions Std            343.7221
V Predictions Max            1290.8188
V Predictions Min            205.22868
Log Pis Mean                 -0.22196388
Log Pis Std                  3.093995
Log Pis Max                  16.848587
Log Pis Min                  -9.115799
Policy mu Mean               -0.05773955
Policy mu Std                0.5421369
Policy mu Max                2.7846658
Policy mu Min                -2.7338974
Policy log std Mean          -0.99785614
Policy log std Std           0.24291357
Policy log std Max           -0.34722036
Policy log std Min           -2.2054782
Z mean eval                  1.200367
Z variance eval              0.016596556
total_rewards                [2608.45226384 1116.46255198 3342.73636116 3335.53811488 2321.73288308
 3226.31847006 2995.46981399 3158.27310235 3233.91059384 3355.59538463]
total_rewards_mean           2869.4489539811852
total_rewards_std            669.1891140912591
total_rewards_max            3355.5953846324705
total_rewards_min            1116.462551984296
Number of train steps total  796000
Number of env steps total    794000
Number of rollouts total     0
Train Time (s)               142.3258315557614
(Previous) Eval Time (s)     30.698361871298403
Sample Time (s)              11.821899946779013
Epoch Time (s)               184.8460933738388
Total Train Time (s)         36427.81354079023
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:03:00.558152 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #198 | Epoch Duration: 184.93930196762085
2020-01-12 12:03:00.558344 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1963637
Z variance train             0.016607122
KL Divergence                20.28001
KL Loss                      2.028001
QF Loss                      641.2472
VF Loss                      120.30177
Policy Loss                  -882.3903
Q Predictions Mean           877.95874
Q Predictions Std            361.84183
Q Predictions Max            1317.094
Q Predictions Min            243.97021
V Predictions Mean           886.4883
V Predictions Std            360.9491
V Predictions Max            1310.0684
V Predictions Min            262.76062
Log Pis Mean                 -0.6599668
Log Pis Std                  2.9354875
Log Pis Max                  14.563263
Log Pis Min                  -7.694032
Policy mu Mean               -0.021984955
Policy mu Std                0.5401513
Policy mu Max                2.6687424
Policy mu Min                -2.6542988
Policy log std Mean          -0.9737183
Policy log std Std           0.21428397
Policy log std Max           -0.39807087
Policy log std Min           -2.2078142
Z mean eval                  1.2475947
Z variance eval              0.022600394
total_rewards                [2770.16944396 3190.43719936 3191.71507903 3381.5759862  3260.25291264
 3159.1111713  3176.90353962 3275.70921027 3211.23213655 3298.1792742 ]
total_rewards_mean           3191.5285953134926
total_rewards_std            154.43430879734072
total_rewards_max            3381.575986204682
total_rewards_min            2770.1694439644034
Number of train steps total  800000
Number of env steps total    799478
Number of rollouts total     0
Train Time (s)               142.5965895028785
(Previous) Eval Time (s)     35.949669987894595
Sample Time (s)              11.377347184345126
Epoch Time (s)               189.9236066751182
Total Train Time (s)         36617.837709525134
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:06:10.585015 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #199 | Epoch Duration: 190.02652645111084
2020-01-12 12:06:10.585211 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2545973
Z variance train             0.022545576
KL Divergence                20.185287
KL Loss                      2.0185287
QF Loss                      871.3984
VF Loss                      243.84908
Policy Loss                  -849.9526
Q Predictions Mean           845.05334
Q Predictions Std            358.4217
Q Predictions Max            1297.8197
Q Predictions Min            -31.499073
V Predictions Mean           851.0877
V Predictions Std            354.3711
V Predictions Max            1296.058
V Predictions Min            -24.704525
Log Pis Mean                 -0.5777588
Log Pis Std                  3.1342556
Log Pis Max                  18.217255
Log Pis Min                  -7.2817965
Policy mu Mean               -0.008006973
Policy mu Std                0.5567779
Policy mu Max                2.7435336
Policy mu Min                -3.9871874
Policy log std Mean          -0.94849265
Policy log std Std           0.21593605
Policy log std Max           -0.41542184
Policy log std Min           -2.085845
Z mean eval                  1.2574105
Z variance eval              0.024075495
total_rewards                [1114.87852994 2365.36980401 3289.79903713 3089.20634971 3365.93880734
 3301.31556128 3338.64246274 1533.75633304 2662.79207082 3179.64416855]
total_rewards_mean           2724.1343124564237
total_rewards_std            769.583889065185
total_rewards_max            3365.9388073394994
total_rewards_min            1114.878529942811
Number of train steps total  804000
Number of env steps total    809391
Number of rollouts total     0
Train Time (s)               150.56739003770053
(Previous) Eval Time (s)     33.451935733202845
Sample Time (s)              11.348698354326189
Epoch Time (s)               195.36802412522957
Total Train Time (s)         36813.30844069831
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:09:26.060403 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #200 | Epoch Duration: 195.47501468658447
2020-01-12 12:09:26.060751 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2627361
Z variance train             0.023587767
KL Divergence                20.23888
KL Loss                      2.023888
QF Loss                      1266.5969
VF Loss                      121.859726
Policy Loss                  -847.975
Q Predictions Mean           840.5812
Q Predictions Std            395.72446
Q Predictions Max            1329.1072
Q Predictions Min            -30.674116
V Predictions Mean           843.2561
V Predictions Std            387.68823
V Predictions Max            1338.9683
V Predictions Min            23.293861
Log Pis Mean                 -0.5689157
Log Pis Std                  3.3144042
Log Pis Max                  17.153522
Log Pis Min                  -10.133438
Policy mu Mean               0.010243613
Policy mu Std                0.5428011
Policy mu Max                2.4832819
Policy mu Min                -3.1335018
Policy log std Mean          -0.9751673
Policy log std Std           0.23501168
Policy log std Max           -0.45370358
Policy log std Min           -2.5029607
Z mean eval                  1.0603654
Z variance eval              0.008870824
total_rewards                [1461.66865465 2571.48333137 3385.08463238 3301.8875033   632.56889888
 1012.94365215  420.82585761  306.13732121 2788.33563938 3307.26492223]
total_rewards_mean           1918.8200413147338
total_rewards_std            1212.4927604964375
total_rewards_max            3385.0846323779633
total_rewards_min            306.1373212062983
Number of train steps total  808000
Number of env steps total    818126
Number of rollouts total     0
Train Time (s)               149.9772669430822
(Previous) Eval Time (s)     25.417903451249003
Sample Time (s)              11.648883884772658
Epoch Time (s)               187.04405427910388
Total Train Time (s)         37000.449054921046
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:12:33.202463 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #201 | Epoch Duration: 187.14145469665527
2020-01-12 12:12:33.202675 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0605063
Z variance train             0.008876034
KL Divergence                21.38842
KL Loss                      2.138842
QF Loss                      662.41235
VF Loss                      243.79448
Policy Loss                  -876.69836
Q Predictions Mean           874.12
Q Predictions Std            345.50726
Q Predictions Max            1323.0575
Q Predictions Min            227.8527
V Predictions Mean           877.7764
V Predictions Std            345.9959
V Predictions Max            1302.5193
V Predictions Min            209.96288
Log Pis Mean                 -0.89899707
Log Pis Std                  3.22205
Log Pis Max                  24.600307
Log Pis Min                  -8.682854
Policy mu Mean               -0.00622373
Policy mu Std                0.5605573
Policy mu Max                4.912643
Policy mu Min                -2.94623
Policy log std Mean          -0.9600072
Policy log std Std           0.20981881
Policy log std Max           -0.35419947
Policy log std Min           -2.1808937
Z mean eval                  1.066681
Z variance eval              0.011017968
total_rewards                [1839.62655481 3476.71625534  515.72663379 1404.14632503 3319.16860098
 3319.80869093  514.09905797 3324.66406393 3355.59065063 3128.75526657]
total_rewards_mean           2419.8302099982734
total_rewards_std            1164.4053095975353
total_rewards_max            3476.7162553419707
total_rewards_min            514.0990579717364
Number of train steps total  812000
Number of env steps total    825954
Number of rollouts total     0
Train Time (s)               151.00324597023427
(Previous) Eval Time (s)     32.64906819490716
Sample Time (s)              11.962139033712447
Epoch Time (s)               195.61445319885388
Total Train Time (s)         37196.16502945591
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:15:48.922966 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #202 | Epoch Duration: 195.72006726264954
2020-01-12 12:15:48.923419 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0637052
Z variance train             0.01095601
KL Divergence                20.975256
KL Loss                      2.0975256
QF Loss                      6805.5684
VF Loss                      190.0015
Policy Loss                  -887.79114
Q Predictions Mean           880.43054
Q Predictions Std            355.18985
Q Predictions Max            1309.5122
Q Predictions Min            99.262276
V Predictions Mean           894.29
V Predictions Std            348.97476
V Predictions Max            1300.1418
V Predictions Min            288.83734
Log Pis Mean                 -0.16789806
Log Pis Std                  3.5507445
Log Pis Max                  27.672321
Log Pis Min                  -7.6659513
Policy mu Mean               -0.022146117
Policy mu Std                0.5982073
Policy mu Max                3.4185236
Policy mu Min                -4.135024
Policy log std Mean          -0.97037315
Policy log std Std           0.22013868
Policy log std Max           -0.46438986
Policy log std Min           -2.0989158
Z mean eval                  1.1108055
Z variance eval              0.013374518
total_rewards                [3125.37771002 3532.71352893 3307.11413811 3318.07229792 3223.54462302
 1940.4024925  1455.4857968  3276.93121646 3346.60251947 3173.82184603]
total_rewards_mean           2970.006616924939
total_rewards_std            653.55013303416
total_rewards_max            3532.7135289256094
total_rewards_min            1455.4857968044598
Number of train steps total  816000
Number of env steps total    833878
Number of rollouts total     0
Train Time (s)               151.91537989722565
(Previous) Eval Time (s)     32.72178626572713
Sample Time (s)              11.546876915730536
Epoch Time (s)               196.18404307868332
Total Train Time (s)         37392.44392884942
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:19:05.203359 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #203 | Epoch Duration: 196.27965116500854
2020-01-12 12:19:05.203550 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.10977
Z variance train             0.013448593
KL Divergence                22.376991
KL Loss                      2.2376993
QF Loss                      757.66254
VF Loss                      588.847
Policy Loss                  -894.19556
Q Predictions Mean           889.1191
Q Predictions Std            341.78217
Q Predictions Max            1322.821
Q Predictions Min            113.4357
V Predictions Mean           902.1692
V Predictions Std            337.76132
V Predictions Max            1329.2255
V Predictions Min            187.30447
Log Pis Mean                 -0.18188776
Log Pis Std                  3.25812
Log Pis Max                  23.747822
Log Pis Min                  -6.5075555
Policy mu Mean               -0.0070919213
Policy mu Std                0.58408874
Policy mu Max                3.134442
Policy mu Min                -3.3070347
Policy log std Mean          -0.9889552
Policy log std Std           0.23282146
Policy log std Max           -0.43677968
Policy log std Min           -2.145699
Z mean eval                  1.1859083
Z variance eval              0.018923039
total_rewards                [3553.28145657 3214.9654348  2944.22803488 3294.93456199 1044.34028072
 3409.15635625 1668.58347387 3391.11664464  987.53430664 3087.59703582]
total_rewards_mean           2659.573758618014
total_rewards_std            962.2304621533839
total_rewards_max            3553.281456572768
total_rewards_min            987.5343066408183
Number of train steps total  820000
Number of env steps total    840051
Number of rollouts total     0
Train Time (s)               146.61147156590596
(Previous) Eval Time (s)     31.67374645266682
Sample Time (s)              11.47987951990217
Epoch Time (s)               189.76509753847495
Total Train Time (s)         37582.295146625955
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:22:15.057835 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #204 | Epoch Duration: 189.8541305065155
2020-01-12 12:22:15.058084 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1833379
Z variance train             0.018992659
KL Divergence                22.066113
KL Loss                      2.2066114
QF Loss                      1375.7201
VF Loss                      222.08755
Policy Loss                  -911.455
Q Predictions Mean           901.4801
Q Predictions Std            351.1591
Q Predictions Max            1341.2383
Q Predictions Min            -65.001015
V Predictions Mean           910.55505
V Predictions Std            339.3427
V Predictions Max            1361.4645
V Predictions Min            222.62628
Log Pis Mean                 -0.20364884
Log Pis Std                  3.0889568
Log Pis Max                  20.331776
Log Pis Min                  -7.299629
Policy mu Mean               0.0026609027
Policy mu Std                0.5922112
Policy mu Max                3.659874
Policy mu Min                -3.349841
Policy log std Mean          -0.9877089
Policy log std Std           0.2336042
Policy log std Max           -0.053274155
Policy log std Min           -2.2828875
Z mean eval                  1.068969
Z variance eval              0.0071388804
total_rewards                [3270.49566321 2495.12792964  425.56227729  258.70276025 3403.55022865
 3250.33775165 3017.08743282 1776.54820155 3313.72638703 1197.81908578]
total_rewards_mean           2240.895771786943
total_rewards_std            1173.7563596005862
total_rewards_max            3403.550228648973
total_rewards_min            258.7027602519612
Number of train steps total  824000
Number of env steps total    848281
Number of rollouts total     0
Train Time (s)               142.6253861989826
(Previous) Eval Time (s)     26.770942497998476
Sample Time (s)              10.38052123459056
Epoch Time (s)               179.77684993157163
Total Train Time (s)         37762.165458441246
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:25:14.931686 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #205 | Epoch Duration: 179.8734269142151
2020-01-12 12:25:14.931930 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0687308
Z variance train             0.007132406
KL Divergence                21.618635
KL Loss                      2.1618636
QF Loss                      629.1248
VF Loss                      261.28796
Policy Loss                  -854.9578
Q Predictions Mean           849.5249
Q Predictions Std            378.6171
Q Predictions Max            1294.8754
Q Predictions Min            34.014515
V Predictions Mean           855.94916
V Predictions Std            373.12766
V Predictions Max            1288.3679
V Predictions Min            -9.82722
Log Pis Mean                 -0.3105123
Log Pis Std                  3.2654073
Log Pis Max                  15.366173
Log Pis Min                  -8.014648
Policy mu Mean               0.025269771
Policy mu Std                0.5825386
Policy mu Max                3.1006653
Policy mu Min                -3.6586893
Policy log std Mean          -0.9569912
Policy log std Std           0.21735857
Policy log std Max           -0.3152458
Policy log std Min           -2.0950284
Z mean eval                  1.0667249
Z variance eval              0.01787998
total_rewards                [3380.32793708 1070.99383984  717.01099908 3350.38518968 3279.06084148
 3585.44493666   94.88370741   84.36924885 1364.72281109 3438.85354315]
total_rewards_mean           2036.6053054315119
total_rewards_std            1419.4075272616935
total_rewards_max            3585.4449366633576
total_rewards_min            84.36924884988935
Number of train steps total  828000
Number of env steps total    857807
Number of rollouts total     0
Train Time (s)               143.87253092508763
(Previous) Eval Time (s)     27.450084377080202
Sample Time (s)              12.168814918026328
Epoch Time (s)               183.49143022019416
Total Train Time (s)         37945.75102526136
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:28:18.518999 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #206 | Epoch Duration: 183.58691000938416
2020-01-12 12:28:18.519226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0619661
Z variance train             0.017869314
KL Divergence                20.42047
KL Loss                      2.042047
QF Loss                      472.88086
VF Loss                      261.00616
Policy Loss                  -860.54736
Q Predictions Mean           857.87976
Q Predictions Std            381.37155
Q Predictions Max            1345.7504
Q Predictions Min            -18.271948
V Predictions Mean           859.22577
V Predictions Std            377.92084
V Predictions Max            1323.0541
V Predictions Min            129.94371
Log Pis Mean                 -0.9195683
Log Pis Std                  3.219554
Log Pis Max                  18.269924
Log Pis Min                  -8.783073
Policy mu Mean               -0.007246768
Policy mu Std                0.5570064
Policy mu Max                3.1908834
Policy mu Min                -4.029795
Policy log std Mean          -0.9183283
Policy log std Std           0.20117374
Policy log std Max           -0.29239458
Policy log std Min           -2.1531372
Z mean eval                  1.1149743
Z variance eval              0.010899885
total_rewards                [1294.6743693  1964.3303668  3180.27661954 3324.26800508 2152.10477305
 3094.95311128 3460.69122542 3126.2238016  2681.54930033  434.88252987]
total_rewards_mean           2471.395410226173
total_rewards_std            946.6529521119878
total_rewards_max            3460.6912254152257
total_rewards_min            434.8825298671023
Number of train steps total  832000
Number of env steps total    866301
Number of rollouts total     0
Train Time (s)               151.917247178033
(Previous) Eval Time (s)     33.71495279390365
Sample Time (s)              11.696172663010657
Epoch Time (s)               197.3283726349473
Total Train Time (s)         38143.22156784404
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:31:35.993474 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #207 | Epoch Duration: 197.47408413887024
2020-01-12 12:31:35.993721 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1199119
Z variance train             0.011174075
KL Divergence                21.474941
KL Loss                      2.147494
QF Loss                      599.4226
VF Loss                      357.92847
Policy Loss                  -907.2473
Q Predictions Mean           901.85376
Q Predictions Std            352.6629
Q Predictions Max            1338.0205
Q Predictions Min            -35.425278
V Predictions Mean           910.8409
V Predictions Std            342.5877
V Predictions Max            1330.8531
V Predictions Min            253.82028
Log Pis Mean                 -0.5777549
Log Pis Std                  2.9898372
Log Pis Max                  11.150745
Log Pis Min                  -10.577001
Policy mu Mean               -0.0025753865
Policy mu Std                0.57333165
Policy mu Max                2.7184968
Policy mu Min                -2.6841094
Policy log std Mean          -0.958821
Policy log std Std           0.2096689
Policy log std Max           -0.36742496
Policy log std Min           -2.051177
Z mean eval                  1.0619074
Z variance eval              0.032780886
total_rewards                [3462.83467646 2476.12201784  747.99098111 1679.18013936  491.29044408
 2341.311669   3486.70117689 2015.02489942   34.08741816  148.20918923]
total_rewards_mean           1688.2752611562205
total_rewards_std            1223.2110246208645
total_rewards_max            3486.7011768853527
total_rewards_min            34.087418164184164
Number of train steps total  836000
Number of env steps total    875197
Number of rollouts total     0
Train Time (s)               151.37322304071859
(Previous) Eval Time (s)     18.042531209997833
Sample Time (s)              11.643390640616417
Epoch Time (s)               181.05914489133283
Total Train Time (s)         38324.37198525481
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:34:37.145852 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #208 | Epoch Duration: 181.151957988739
2020-01-12 12:34:37.146048 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0611192
Z variance train             0.03285894
KL Divergence                19.278133
KL Loss                      1.9278134
QF Loss                      774.84033
VF Loss                      165.82819
Policy Loss                  -886.8715
Q Predictions Mean           878.4562
Q Predictions Std            384.2045
Q Predictions Max            1331.2441
Q Predictions Min            28.892866
V Predictions Mean           885.14087
V Predictions Std            377.00403
V Predictions Max            1331.78
V Predictions Min            0.86734366
Log Pis Mean                 -0.4339121
Log Pis Std                  3.1985106
Log Pis Max                  15.544581
Log Pis Min                  -8.7196455
Policy mu Mean               0.013305761
Policy mu Std                0.56495744
Policy mu Max                3.2395246
Policy mu Min                -3.479515
Policy log std Mean          -0.9644822
Policy log std Std           0.23097254
Policy log std Max           -0.31948453
Policy log std Min           -2.005786
Z mean eval                  1.1167257
Z variance eval              0.013757654
total_rewards                [3352.51473919   94.76526946  445.50426047 1378.92768203 1129.03198287
 3387.56871406 1139.46003865 2345.57136698 3377.17887001 1046.73893802]
total_rewards_mean           1769.7261861739848
total_rewards_std            1186.606596279883
total_rewards_max            3387.5687140584423
total_rewards_min            94.76526946065285
Number of train steps total  840000
Number of env steps total    883992
Number of rollouts total     0
Train Time (s)               150.73425698187202
(Previous) Eval Time (s)     23.122218403033912
Sample Time (s)              11.293435307219625
Epoch Time (s)               185.14991069212556
Total Train Time (s)         38509.62368882308
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:37:42.401160 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #209 | Epoch Duration: 185.25492572784424
2020-01-12 12:37:42.401637 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1120417
Z variance train             0.01388031
KL Divergence                19.908928
KL Loss                      1.9908928
QF Loss                      476.93475
VF Loss                      243.05788
Policy Loss                  -922.7266
Q Predictions Mean           917.0113
Q Predictions Std            358.56473
Q Predictions Max            1347.4514
Q Predictions Min            -14.690786
V Predictions Mean           927.3876
V Predictions Std            354.6424
V Predictions Max            1352.9048
V Predictions Min            155.44275
Log Pis Mean                 -0.48037446
Log Pis Std                  3.090248
Log Pis Max                  20.294544
Log Pis Min                  -6.875155
Policy mu Mean               0.049124792
Policy mu Std                0.5746789
Policy mu Max                2.4257526
Policy mu Min                -3.3667808
Policy log std Mean          -0.9643295
Policy log std Std           0.22626796
Policy log std Max           -0.40594703
Policy log std Min           -2.0735512
Z mean eval                  1.1327933
Z variance eval              0.016408091
total_rewards                [2449.73159198 3294.95329821 3388.4508766  2779.77111811 3310.80283082
 3220.05665081 2858.54869525 3221.93961795  823.21191077 3624.79377545]
total_rewards_mean           2897.226036595946
total_rewards_std            763.3233508478942
total_rewards_max            3624.7937754527643
total_rewards_min            823.2119107717043
Number of train steps total  844000
Number of env steps total    890127
Number of rollouts total     0
Train Time (s)               151.70643581310287
(Previous) Eval Time (s)     32.835095453076065
Sample Time (s)              12.858797084074467
Epoch Time (s)               197.4003283502534
Total Train Time (s)         38707.11775763286
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:40:59.897469 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #210 | Epoch Duration: 197.49558973312378
2020-01-12 12:40:59.897673 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1405798
Z variance train             0.016769554
KL Divergence                21.989029
KL Loss                      2.1989028
QF Loss                      565.5111
VF Loss                      86.851295
Policy Loss                  -894.0703
Q Predictions Mean           886.6139
Q Predictions Std            354.8102
Q Predictions Max            1309.7827
Q Predictions Min            242.2655
V Predictions Mean           895.38306
V Predictions Std            356.57303
V Predictions Max            1305.3508
V Predictions Min            261.0526
Log Pis Mean                 -0.5402913
Log Pis Std                  3.0038252
Log Pis Max                  15.107037
Log Pis Min                  -7.800265
Policy mu Mean               -0.008738605
Policy mu Std                0.5286982
Policy mu Max                2.867859
Policy mu Min                -3.275409
Policy log std Mean          -0.9927452
Policy log std Std           0.22589527
Policy log std Max           -0.42724496
Policy log std Min           -2.052899
Z mean eval                  1.0697862
Z variance eval              0.0047577834
total_rewards                [3388.01586568 3255.00151056 3288.0531259  3117.82608401 1457.81283371
 3197.44089664 3411.9047441  3390.28277313 3335.85462472 1159.14618242]
total_rewards_mean           2900.1338640873696
total_rewards_std            803.3404416679173
total_rewards_max            3411.9047440960603
total_rewards_min            1159.1461824184203
Number of train steps total  848000
Number of env steps total    896233
Number of rollouts total     0
Train Time (s)               145.17228948278353
(Previous) Eval Time (s)     34.035147415008396
Sample Time (s)              12.803192927967757
Epoch Time (s)               192.01062982575968
Total Train Time (s)         38899.215457088314
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:44:11.998170 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #211 | Epoch Duration: 192.10033798217773
2020-01-12 12:44:11.998390 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0707283
Z variance train             0.004853587
KL Divergence                25.223244
KL Loss                      2.5223243
QF Loss                      1176.434
VF Loss                      411.5146
Policy Loss                  -889.6698
Q Predictions Mean           883.4794
Q Predictions Std            375.35626
Q Predictions Max            1361.1201
Q Predictions Min            11.507847
V Predictions Mean           886.25836
V Predictions Std            370.6699
V Predictions Max            1363.3984
V Predictions Min            -7.9093084
Log Pis Mean                 -0.8040234
Log Pis Std                  3.7875042
Log Pis Max                  26.298052
Log Pis Min                  -10.346233
Policy mu Mean               0.005764407
Policy mu Std                0.56335205
Policy mu Max                3.643193
Policy mu Min                -4.667454
Policy log std Mean          -0.9755217
Policy log std Std           0.24567197
Policy log std Max           -0.4532655
Policy log std Min           -2.4016943
Z mean eval                  1.1123946
Z variance eval              0.0050544837
total_rewards                [3465.64690758 1194.3064028  3331.81659141 3376.14522668 1759.05685342
 2980.06862841 1503.53589815 3305.34784836 1247.96944201 2918.55668663]
total_rewards_mean           2508.245048544829
total_rewards_std            908.8420064713266
total_rewards_max            3465.6469075767527
total_rewards_min            1194.306402802315
Number of train steps total  852000
Number of env steps total    904604
Number of rollouts total     0
Train Time (s)               142.7812729589641
(Previous) Eval Time (s)     26.93916559126228
Sample Time (s)              11.24278125911951
Epoch Time (s)               180.9632198093459
Total Train Time (s)         39080.27097678976
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:47:13.056882 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #212 | Epoch Duration: 181.0583200454712
2020-01-12 12:47:13.057132 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1066127
Z variance train             0.005027391
KL Divergence                24.868397
KL Loss                      2.4868398
QF Loss                      627.7401
VF Loss                      206.05414
Policy Loss                  -886.86725
Q Predictions Mean           880.5602
Q Predictions Std            363.3885
Q Predictions Max            1329.2773
Q Predictions Min            -37.425735
V Predictions Mean           894.6438
V Predictions Std            359.35077
V Predictions Max            1341.0597
V Predictions Min            176.48204
Log Pis Mean                 -0.44011107
Log Pis Std                  3.1148913
Log Pis Max                  20.0303
Log Pis Min                  -6.8997455
Policy mu Mean               0.002269877
Policy mu Std                0.55888474
Policy mu Max                2.8680174
Policy mu Min                -2.8583732
Policy log std Mean          -0.9598422
Policy log std Std           0.21555121
Policy log std Max           -0.30210406
Policy log std Min           -2.0066714
Z mean eval                  1.0585306
Z variance eval              0.013631429
total_rewards                [2226.25186205 2937.44993383 3005.00233369 3509.93290938 3342.47154715
 1854.2507408  3546.27834002 1339.14511805 1459.08581475 3408.287634  ]
total_rewards_mean           2662.8156233716954
total_rewards_std            821.8104803652772
total_rewards_max            3546.2783400156723
total_rewards_min            1339.1451180506963
Number of train steps total  856000
Number of env steps total    911509
Number of rollouts total     0
Train Time (s)               146.24448462296277
(Previous) Eval Time (s)     31.513316587079316
Sample Time (s)              11.03538103075698
Epoch Time (s)               188.79318224079907
Total Train Time (s)         39269.1556261424
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:50:21.945686 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #213 | Epoch Duration: 188.88838911056519
2020-01-12 12:50:21.945874 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #213 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0595896
Z variance train             0.013660179
KL Divergence                20.71642
KL Loss                      2.071642
QF Loss                      804.08356
VF Loss                      124.49773
Policy Loss                  -908.02563
Q Predictions Mean           897.4498
Q Predictions Std            363.4985
Q Predictions Max            1342.7671
Q Predictions Min            -41.577415
V Predictions Mean           904.8799
V Predictions Std            355.04303
V Predictions Max            1344.9437
V Predictions Min            287.4726
Log Pis Mean                 -0.30273664
Log Pis Std                  3.1405184
Log Pis Max                  14.213736
Log Pis Min                  -8.934364
Policy mu Mean               0.01795525
Policy mu Std                0.6023179
Policy mu Max                2.4688587
Policy mu Min                -2.7591007
Policy log std Mean          -0.9664091
Policy log std Std           0.23228358
Policy log std Max           -0.37376523
Policy log std Min           -1.9977748
Z mean eval                  1.0533936
Z variance eval              0.009705989
total_rewards                [3446.72979267 3482.13674101 3510.98666667  808.58296215 3505.1409649
 1471.58569289 3420.91961499  474.78613911 3246.19461033 3228.61261181]
total_rewards_mean           2659.5675796532405
total_rewards_std            1165.9531976139242
total_rewards_max            3510.986666669063
total_rewards_min            474.78613911404375
Number of train steps total  860000
Number of env steps total    919509
Number of rollouts total     0
Train Time (s)               153.17816523695365
(Previous) Eval Time (s)     31.648490220773965
Sample Time (s)              11.152932598721236
Epoch Time (s)               195.97958805644885
Total Train Time (s)         39465.230606240686
Epoch                        214
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:53:38.024626 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #214 | Epoch Duration: 196.07856464385986
2020-01-12 12:53:38.024983 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0520691
Z variance train             0.00970504
KL Divergence                20.88248
KL Loss                      2.088248
QF Loss                      940.49524
VF Loss                      513.9438
Policy Loss                  -887.16876
Q Predictions Mean           884.6302
Q Predictions Std            383.9508
Q Predictions Max            1344.9052
Q Predictions Min            -39.068974
V Predictions Mean           883.8685
V Predictions Std            378.3601
V Predictions Max            1348.8994
V Predictions Min            -15.54138
Log Pis Mean                 -0.6711627
Log Pis Std                  2.9683008
Log Pis Max                  16.142033
Log Pis Min                  -7.433329
Policy mu Mean               0.008360857
Policy mu Std                0.54641414
Policy mu Max                3.0662796
Policy mu Min                -1.8935554
Policy log std Mean          -0.9530932
Policy log std Std           0.21716149
Policy log std Max           -0.36470175
Policy log std Min           -2.2556303
Z mean eval                  1.2571627
Z variance eval              0.01858793
total_rewards                [ 359.98269294 3405.01078687  304.90227167 2163.20773547 1884.40015289
 3074.87473821 1231.20674678 2162.88892796 1270.10342193 3320.83987142]
total_rewards_mean           1917.741734613613
total_rewards_std            1075.160583685056
total_rewards_max            3405.0107868702444
total_rewards_min            304.90227166853725
Number of train steps total  864000
Number of env steps total    925553
Number of rollouts total     0
Train Time (s)               152.23874430498108
(Previous) Eval Time (s)     22.813901566900313
Sample Time (s)              11.83336024126038
Epoch Time (s)               186.88600611314178
Total Train Time (s)         39652.21526749665
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:56:45.012431 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #215 | Epoch Duration: 186.9872009754181
2020-01-12 12:56:45.012680 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2618476
Z variance train             0.018630624
KL Divergence                19.896626
KL Loss                      1.9896625
QF Loss                      749.7224
VF Loss                      86.79006
Policy Loss                  -901.6723
Q Predictions Mean           895.9202
Q Predictions Std            352.869
Q Predictions Max            1388.7954
Q Predictions Min            267.6648
V Predictions Mean           903.7409
V Predictions Std            353.92535
V Predictions Max            1378.905
V Predictions Min            269.33224
Log Pis Mean                 -0.6754687
Log Pis Std                  3.0850675
Log Pis Max                  15.0997925
Log Pis Min                  -7.5623055
Policy mu Mean               0.021798844
Policy mu Std                0.5660567
Policy mu Max                4.2474527
Policy mu Min                -3.115043
Policy log std Mean          -0.9410199
Policy log std Std           0.2163366
Policy log std Max           -0.2251668
Policy log std Min           -2.2043052
Z mean eval                  1.0339466
Z variance eval              0.010987368
total_rewards                [3501.98225652 1502.46116777  695.070499   2267.94492589  954.01673448
  256.48177253  276.45380352 2033.20746376 2643.91785838  514.51843259]
total_rewards_mean           1464.6054914453002
total_rewards_std            1055.395423536985
total_rewards_max            3501.9822565211207
total_rewards_min            256.48177253438143
Number of train steps total  868000
Number of env steps total    932996
Number of rollouts total     0
Train Time (s)               152.8662296710536
(Previous) Eval Time (s)     21.443103343248367
Sample Time (s)              11.691148414742202
Epoch Time (s)               186.00048142904416
Total Train Time (s)         39838.3052353668
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:59:51.105427 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #216 | Epoch Duration: 186.0925636291504
2020-01-12 12:59:51.105731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0369211
Z variance train             0.010922072
KL Divergence                21.144821
KL Loss                      2.1144822
QF Loss                      710.2988
VF Loss                      502.7683
Policy Loss                  -895.2052
Q Predictions Mean           888.1302
Q Predictions Std            373.80707
Q Predictions Max            1340.2723
Q Predictions Min            -30.564705
V Predictions Mean           887.57153
V Predictions Std            368.0322
V Predictions Max            1319.7715
V Predictions Min            -27.739586
Log Pis Mean                 -0.3748311
Log Pis Std                  3.9057455
Log Pis Max                  29.79597
Log Pis Min                  -9.912023
Policy mu Mean               -0.014532551
Policy mu Std                0.5855598
Policy mu Max                3.3737993
Policy mu Min                -4.544677
Policy log std Mean          -0.96728265
Policy log std Std           0.24341579
Policy log std Max           -0.35854262
Policy log std Min           -2.5176845
Z mean eval                  1.0862513
Z variance eval              0.006170531
total_rewards                [ 900.7220203  3451.77448926 1007.02251907 3393.84325873 2763.42090114
 3500.14773945 3430.61580828 1623.8895088  3639.60450833 3621.96830988]
total_rewards_mean           2733.300906325104
total_rewards_std            1058.6794560518754
total_rewards_max            3639.6045083340687
total_rewards_min            900.7220203018705
Number of train steps total  872000
Number of env steps total    941451
Number of rollouts total     0
Train Time (s)               152.22731381375343
(Previous) Eval Time (s)     30.741844782605767
Sample Time (s)              12.26102087739855
Epoch Time (s)               195.23017947375774
Total Train Time (s)         40033.62483820552
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:03:06.427897 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #217 | Epoch Duration: 195.32198023796082
2020-01-12 13:03:06.428125 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0905297
Z variance train             0.006161225
KL Divergence                23.302212
KL Loss                      2.3302212
QF Loss                      694.7346
VF Loss                      205.04457
Policy Loss                  -901.0982
Q Predictions Mean           892.8197
Q Predictions Std            363.27267
Q Predictions Max            1360.2156
Q Predictions Min            -78.37477
V Predictions Mean           901.9614
V Predictions Std            359.4029
V Predictions Max            1361.6077
V Predictions Min            234.05603
Log Pis Mean                 -0.41285503
Log Pis Std                  2.9915266
Log Pis Max                  14.429856
Log Pis Min                  -9.4182205
Policy mu Mean               0.044989284
Policy mu Std                0.531157
Policy mu Max                2.526271
Policy mu Min                -2.1523848
Policy log std Mean          -0.9812096
Policy log std Std           0.2348779
Policy log std Max           -0.23174232
Policy log std Min           -2.3065958
Z mean eval                  1.1456001
Z variance eval              0.0064252107
total_rewards                [ 630.90459809 2111.83589336 3394.43055002  751.32032516 3614.63839419
 3427.75605282 3489.49178472 2091.20938345 3508.46979746 3472.24318014]
total_rewards_mean           2649.229995941335
total_rewards_std            1117.6314969395023
total_rewards_max            3614.6383941861313
total_rewards_min            630.9045980873758
Number of train steps total  876000
Number of env steps total    947617
Number of rollouts total     0
Train Time (s)               142.75870225206017
(Previous) Eval Time (s)     31.047897251322865
Sample Time (s)              10.918971291277558
Epoch Time (s)               184.7255707946606
Total Train Time (s)         40218.436047584284
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:06:11.241139 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #218 | Epoch Duration: 184.81287097930908
2020-01-12 13:06:11.241314 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1425617
Z variance train             0.0064301416
KL Divergence                23.5196
KL Loss                      2.35196
QF Loss                      534.1946
VF Loss                      97.61308
Policy Loss                  -891.7483
Q Predictions Mean           888.23
Q Predictions Std            358.47522
Q Predictions Max            1305.0496
Q Predictions Min            238.71294
V Predictions Mean           895.1884
V Predictions Std            356.1423
V Predictions Max            1299.7476
V Predictions Min            238.13322
Log Pis Mean                 -0.49401292
Log Pis Std                  3.2896905
Log Pis Max                  17.218636
Log Pis Min                  -9.881902
Policy mu Mean               0.009349431
Policy mu Std                0.5852878
Policy mu Max                2.8721154
Policy mu Min                -5.2544494
Policy log std Mean          -0.9609106
Policy log std Std           0.1967777
Policy log std Max           -0.2738843
Policy log std Min           -2.0012667
Z mean eval                  1.1117778
Z variance eval              0.020970404
total_rewards                [1506.90626109  627.28750767   79.57604274 2156.47968481  723.33298251
  144.76667086 3482.62412055  424.46818728 3608.86925043 1848.01509081]
total_rewards_mean           1460.2325798762072
total_rewards_std            1236.5399404574102
total_rewards_max            3608.869250429254
total_rewards_min            79.5760427441585
Number of train steps total  880000
Number of env steps total    954162
Number of rollouts total     0
Train Time (s)               142.85363600729033
(Previous) Eval Time (s)     19.713828315027058
Sample Time (s)              11.227911747992039
Epoch Time (s)               173.79537607030943
Total Train Time (s)         40392.31700220611
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:09:05.125040 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #219 | Epoch Duration: 173.8835883140564
2020-01-12 13:09:05.125217 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1087917
Z variance train             0.020998131
KL Divergence                19.050858
KL Loss                      1.9050858
QF Loss                      712.7364
VF Loss                      142.02356
Policy Loss                  -945.1904
Q Predictions Mean           938.33264
Q Predictions Std            349.01086
Q Predictions Max            1346.8586
Q Predictions Min            -73.603516
V Predictions Mean           944.7093
V Predictions Std            347.19742
V Predictions Max            1343.8185
V Predictions Min            1.2079456
Log Pis Mean                 -0.19685076
Log Pis Std                  2.9039598
Log Pis Max                  13.953887
Log Pis Min                  -7.5140276
Policy mu Mean               0.028094571
Policy mu Std                0.5529997
Policy mu Max                4.029097
Policy mu Min                -2.9685848
Policy log std Mean          -0.9894315
Policy log std Std           0.21609317
Policy log std Max           -0.3944052
Policy log std Min           -2.132679
Z mean eval                  1.1108825
Z variance eval              0.009215349
total_rewards                [3358.16453333 3336.56120004 3463.2242379  1244.37703864  939.28629956
 2058.86413991 3382.64330128 3366.29259271 3621.7170833  2631.97751598]
total_rewards_mean           2740.3107942658858
total_rewards_std            938.0189559825859
total_rewards_max            3621.7170833041764
total_rewards_min            939.286299555184
Number of train steps total  884000
Number of env steps total    963151
Number of rollouts total     0
Train Time (s)               149.528456246946
(Previous) Eval Time (s)     32.1980996709317
Sample Time (s)              11.342490293551236
Epoch Time (s)               193.06904621142894
Total Train Time (s)         40585.511425500736
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:12:18.322605 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #220 | Epoch Duration: 193.19724106788635
2020-01-12 13:12:18.322822 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1014066
Z variance train             0.009251902
KL Divergence                21.704035
KL Loss                      2.1704035
QF Loss                      867.5927
VF Loss                      128.97476
Policy Loss                  -876.47986
Q Predictions Mean           872.13086
Q Predictions Std            384.49704
Q Predictions Max            1349.5562
Q Predictions Min            266.944
V Predictions Mean           878.8003
V Predictions Std            380.783
V Predictions Max            1346.7499
V Predictions Min            263.08133
Log Pis Mean                 -0.6353954
Log Pis Std                  2.8627539
Log Pis Max                  7.8040743
Log Pis Min                  -8.558731
Policy mu Mean               0.020720461
Policy mu Std                0.5339548
Policy mu Max                2.5840986
Policy mu Min                -2.3793557
Policy log std Mean          -0.95409346
Policy log std Std           0.20982286
Policy log std Max           -0.41899276
Policy log std Min           -1.7982469
Z mean eval                  1.0894177
Z variance eval              0.0106304865
total_rewards                [3367.97975829 3042.08414844 1708.23324165 3377.61010812  131.69527761
  391.07619302 1819.10541145 3125.69440151  674.59743275  801.44388858]
total_rewards_mean           1843.9519861416215
total_rewards_std            1235.6809225725356
total_rewards_max            3377.6101081164416
total_rewards_min            131.69527761280477
Number of train steps total  888000
Number of env steps total    971544
Number of rollouts total     0
Train Time (s)               153.0391508191824
(Previous) Eval Time (s)     22.767821945250034
Sample Time (s)              12.89212818769738
Epoch Time (s)               188.6991009521298
Total Train Time (s)         40774.30350813642
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:15:27.117675 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #221 | Epoch Duration: 188.7946903705597
2020-01-12 13:15:27.117886 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0861099
Z variance train             0.01054958
KL Divergence                20.39949
KL Loss                      2.0399492
QF Loss                      1549.8374
VF Loss                      210.58345
Policy Loss                  -903.3842
Q Predictions Mean           896.3767
Q Predictions Std            361.78116
Q Predictions Max            1320.1488
Q Predictions Min            140.17133
V Predictions Mean           904.57886
V Predictions Std            356.41507
V Predictions Max            1326.6567
V Predictions Min            143.51457
Log Pis Mean                 -0.6266073
Log Pis Std                  2.9338453
Log Pis Max                  13.356194
Log Pis Min                  -7.658085
Policy mu Mean               0.002356824
Policy mu Std                0.5616844
Policy mu Max                3.9638104
Policy mu Min                -2.633087
Policy log std Mean          -0.9486705
Policy log std Std           0.21807466
Policy log std Max           -0.40341777
Policy log std Min           -1.920791
Z mean eval                  1.1334115
Z variance eval              0.00906706
total_rewards                [3449.12629845  276.02830821 2794.87495478 3108.34782455  884.95319823
 3243.84073468 3561.61923235 2998.66886676 3231.12472677 2363.82467654]
total_rewards_mean           2591.240882132609
total_rewards_std            1063.5388320890693
total_rewards_max            3561.619232348402
total_rewards_min            276.02830821104925
Number of train steps total  892000
Number of env steps total    981247
Number of rollouts total     0
Train Time (s)               151.51406367728487
(Previous) Eval Time (s)     29.330424583051354
Sample Time (s)              12.133256665430963
Epoch Time (s)               192.97774492576718
Total Train Time (s)         40967.37685357593
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:18:40.193808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #222 | Epoch Duration: 193.07577228546143
2020-01-12 13:18:40.194011 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1348085
Z variance train             0.009117676
KL Divergence                22.131548
KL Loss                      2.2131548
QF Loss                      771.0454
VF Loss                      164.19342
Policy Loss                  -933.3517
Q Predictions Mean           929.4752
Q Predictions Std            367.3683
Q Predictions Max            1350.232
Q Predictions Min            -43.39413
V Predictions Mean           937.42413
V Predictions Std            365.52475
V Predictions Max            1360.964
V Predictions Min            10.8334875
Log Pis Mean                 -0.39348286
Log Pis Std                  3.5574522
Log Pis Max                  23.345644
Log Pis Min                  -7.8422613
Policy mu Mean               0.029243862
Policy mu Std                0.60211134
Policy mu Max                3.1952276
Policy mu Min                -4.801361
Policy log std Mean          -0.97254777
Policy log std Std           0.22915174
Policy log std Max           -0.30097246
Policy log std Min           -2.3281367
Z mean eval                  1.1273339
Z variance eval              0.008206891
total_rewards                [1159.3657228  3054.86553368 1423.0244002  3050.3839375  3023.99852132
 1151.63202315 2946.87759522 1518.72182013 2638.0905912  3202.86140007]
total_rewards_mean           2316.982154526934
total_rewards_std            836.7424867379684
total_rewards_max            3202.861400073753
total_rewards_min            1151.6320231472678
Number of train steps total  896000
Number of env steps total    991341
Number of rollouts total     0
Train Time (s)               153.3740158630535
(Previous) Eval Time (s)     31.85820882022381
Sample Time (s)              13.493303225375712
Epoch Time (s)               198.72552790865302
Total Train Time (s)         41166.219809986185
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:21:59.042404 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #223 | Epoch Duration: 198.8482151031494
2020-01-12 13:21:59.042699 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1293156
Z variance train             0.0082023395
KL Divergence                22.015776
KL Loss                      2.2015777
QF Loss                      786.6825
VF Loss                      141.12097
Policy Loss                  -905.252
Q Predictions Mean           896.77783
Q Predictions Std            365.6717
Q Predictions Max            1341.0485
Q Predictions Min            229.19896
V Predictions Mean           901.59143
V Predictions Std            362.03226
V Predictions Max            1361.193
V Predictions Min            234.01492
Log Pis Mean                 -0.31257653
Log Pis Std                  3.4618628
Log Pis Max                  17.841286
Log Pis Min                  -10.996071
Policy mu Mean               0.027841572
Policy mu Std                0.5800564
Policy mu Max                2.4154863
Policy mu Min                -2.9792593
Policy log std Mean          -0.9792067
Policy log std Std           0.23558569
Policy log std Max           -0.393196
Policy log std Min           -2.1647792
Z mean eval                  1.0839096
Z variance eval              0.008636532
total_rewards                [ 416.71694138 3368.59052759 3479.63575492 3108.17144975 3307.98952922
 3089.30553203 3282.21144638 3173.27345958  286.56798108 3346.05081284]
total_rewards_mean           2685.851343476461
total_rewards_std            1172.9890272609257
total_rewards_max            3479.635754920965
total_rewards_min            286.56798108035457
Number of train steps total  900000
Number of env steps total    1001342
Number of rollouts total     0
Train Time (s)               150.47462534811348
(Previous) Eval Time (s)     28.747707074973732
Sample Time (s)              12.061193058732897
Epoch Time (s)               191.2835254818201
Total Train Time (s)         41357.600110953674
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:25:10.424541 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #224 | Epoch Duration: 191.38165378570557
2020-01-12 13:25:10.424750 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #224 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0889461
Z variance train             0.008616801
KL Divergence                20.687473
KL Loss                      2.0687473
QF Loss                      688.0986
VF Loss                      171.6298
Policy Loss                  -919.3247
Q Predictions Mean           913.50977
Q Predictions Std            356.75903
Q Predictions Max            1316.9731
Q Predictions Min            258.7308
V Predictions Mean           925.6764
V Predictions Std            354.8003
V Predictions Max            1321.6447
V Predictions Min            281.79953
Log Pis Mean                 -0.13802496
Log Pis Std                  3.0298092
Log Pis Max                  19.350962
Log Pis Min                  -8.112691
Policy mu Mean               0.035153627
Policy mu Std                0.5812242
Policy mu Max                2.3597114
Policy mu Min                -2.1063461
Policy log std Mean          -0.9735175
Policy log std Std           0.21946363
Policy log std Max           -0.4751015
Policy log std Min           -2.013599
Z mean eval                  0.9798425
Z variance eval              0.011370969
total_rewards                [3361.02511447 3380.13424609 3346.2095713  3112.89807161 2859.2411793
 3356.01484682 1667.30699777 1752.31465424 3339.9526948  1238.9536347 ]
total_rewards_mean           2741.405101111394
total_rewards_std            802.1805354939836
total_rewards_max            3380.1342460877277
total_rewards_min            1238.953634699528
Number of train steps total  904000
Number of env steps total    1010307
Number of rollouts total     0
Train Time (s)               142.39840598218143
(Previous) Eval Time (s)     29.50606978079304
Sample Time (s)              11.350968895945698
Epoch Time (s)               183.25544465892017
Total Train Time (s)         41540.94145125337
Epoch                        225
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:28:13.768638 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #225 | Epoch Duration: 183.34372639656067
2020-01-12 13:28:13.768845 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9822014
Z variance train             0.011426857
KL Divergence                20.632097
KL Loss                      2.0632098
QF Loss                      404.17603
VF Loss                      116.90861
Policy Loss                  -881.8271
Q Predictions Mean           875.98816
Q Predictions Std            367.80133
Q Predictions Max            1339.8917
Q Predictions Min            253.44058
V Predictions Mean           885.13684
V Predictions Std            364.47095
V Predictions Max            1332.358
V Predictions Min            255.34418
Log Pis Mean                 -0.79298985
Log Pis Std                  2.8765407
Log Pis Max                  10.524383
Log Pis Min                  -13.116009
Policy mu Mean               0.024093118
Policy mu Std                0.5266647
Policy mu Max                1.9104835
Policy mu Min                -2.0595422
Policy log std Mean          -0.9637495
Policy log std Std           0.21775016
Policy log std Max           -0.39382035
Policy log std Min           -2.0161989
Z mean eval                  1.0029427
Z variance eval              0.008404545
total_rewards                [3137.48323026 3211.44157989 3522.81278292 3469.19161473 3345.98493848
  465.56663109 3400.7860716   250.66701624 1371.27151996 3425.09119443]
total_rewards_mean           2560.0296579594647
total_rewards_std            1253.6874624088398
total_rewards_max            3522.8127829179857
total_rewards_min            250.6670162403882
Number of train steps total  908000
Number of env steps total    1020239
Number of rollouts total     0
Train Time (s)               142.841070080176
(Previous) Eval Time (s)     27.386314434930682
Sample Time (s)              11.034292434342206
Epoch Time (s)               181.26167694944888
Total Train Time (s)         41722.295519151725
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:31:15.125701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #226 | Epoch Duration: 181.3567008972168
2020-01-12 13:31:15.125913 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0021131
Z variance train             0.008411325
KL Divergence                20.792067
KL Loss                      2.0792067
QF Loss                      587.3385
VF Loss                      204.66016
Policy Loss                  -919.7437
Q Predictions Mean           912.93695
Q Predictions Std            362.8558
Q Predictions Max            1354.6044
Q Predictions Min            -9.553106
V Predictions Mean           919.8507
V Predictions Std            354.83148
V Predictions Max            1350.613
V Predictions Min            106.0408
Log Pis Mean                 -0.20002341
Log Pis Std                  3.796005
Log Pis Max                  25.389488
Log Pis Min                  -8.072117
Policy mu Mean               0.02522787
Policy mu Std                0.63477343
Policy mu Max                4.459966
Policy mu Min                -4.6702604
Policy log std Mean          -0.9590362
Policy log std Std           0.23329076
Policy log std Max           0.1305685
Policy log std Min           -2.5214872
Z mean eval                  1.0436821
Z variance eval              0.011383456
total_rewards                [3186.48062    1490.21820685 3274.34947225 1874.47575254 2505.25617008
  425.06078474 2211.205476   1110.21486003 3370.29392068  329.69633281]
total_rewards_mean           1977.7251595981684
total_rewards_std            1074.3387461383172
total_rewards_max            3370.2939206822757
total_rewards_min            329.6963328076648
Number of train steps total  912000
Number of env steps total    1030018
Number of rollouts total     0
Train Time (s)               152.3609280041419
(Previous) Eval Time (s)     29.2587446346879
Sample Time (s)              11.45753941917792
Epoch Time (s)               193.07721205800772
Total Train Time (s)         41915.458814802114
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:34:28.292013 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #227 | Epoch Duration: 193.16595005989075
2020-01-12 13:34:28.292201 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #227 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0432187
Z variance train             0.011330978
KL Divergence                20.999586
KL Loss                      2.0999587
QF Loss                      1446.1147
VF Loss                      158.80916
Policy Loss                  -892.5854
Q Predictions Mean           884.0792
Q Predictions Std            383.27017
Q Predictions Max            1341.6573
Q Predictions Min            46.42083
V Predictions Mean           896.36475
V Predictions Std            378.905
V Predictions Max            1335.3392
V Predictions Min            78.34902
Log Pis Mean                 -0.46192825
Log Pis Std                  3.1882281
Log Pis Max                  16.9756
Log Pis Min                  -7.9009323
Policy mu Mean               0.04845103
Policy mu Std                0.5812822
Policy mu Max                2.5234375
Policy mu Min                -3.412922
Policy log std Mean          -0.9514599
Policy log std Std           0.21682806
Policy log std Max           -0.45971876
Policy log std Min           -2.082944
Z mean eval                  1.1623867
Z variance eval              0.008388213
total_rewards                [ 552.65987941 3398.27166176 3412.44884385 2003.2067246  3362.2777772
 1177.73686127 3381.82074455  490.53265126 3308.57078429 1484.64980824]
total_rewards_mean           2257.217573643192
total_rewards_std            1186.6402680925423
total_rewards_max            3412.4488438452827
total_rewards_min            490.53265125779035
Number of train steps total  916000
Number of env steps total    1036995
Number of rollouts total     0
Train Time (s)               151.94644141197205
(Previous) Eval Time (s)     27.851295885629952
Sample Time (s)              11.969364290125668
Epoch Time (s)               191.76710158772767
Total Train Time (s)         42107.321071711835
Epoch                        228
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:37:40.157363 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #228 | Epoch Duration: 191.86501026153564
2020-01-12 13:37:40.157569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.152477
Z variance train             0.008380844
KL Divergence                21.740688
KL Loss                      2.174069
QF Loss                      602.27246
VF Loss                      230.59587
Policy Loss                  -930.5867
Q Predictions Mean           925.7979
Q Predictions Std            370.06793
Q Predictions Max            1378.8336
Q Predictions Min            -2.3324075
V Predictions Mean           927.9612
V Predictions Std            364.3485
V Predictions Max            1364.7401
V Predictions Min            171.46774
Log Pis Mean                 -0.61790675
Log Pis Std                  2.7266095
Log Pis Max                  10.983053
Log Pis Min                  -9.456513
Policy mu Mean               0.003665031
Policy mu Std                0.5393888
Policy mu Max                2.74459
Policy mu Min                -2.36298
Policy log std Mean          -0.95089304
Policy log std Std           0.21177667
Policy log std Max           -0.36441702
Policy log std Min           -2.3102617
Z mean eval                  1.055562
Z variance eval              0.048506822
total_rewards                [ 405.3348635  2603.19716672 1976.98159463  437.85532191  640.46660573
   72.21252218 3035.30855173   11.98832453  238.28162706 1337.83404117]
total_rewards_mean           1075.9460619164931
total_rewards_std            1045.932023048141
total_rewards_max            3035.3085517347527
total_rewards_min            11.98832453425825
Number of train steps total  920000
Number of env steps total    1048046
Number of rollouts total     0
Train Time (s)               151.39502540510148
(Previous) Eval Time (s)     12.694666124880314
Sample Time (s)              11.739715456031263
Epoch Time (s)               175.82940698601305
Total Train Time (s)         42283.239797668066
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:40:36.083245 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #229 | Epoch Duration: 175.9254972934723
2020-01-12 13:40:36.083502 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0581326
Z variance train             0.04878763
KL Divergence                19.701496
KL Loss                      1.9701496
QF Loss                      922.94104
VF Loss                      136.47707
Policy Loss                  -954.48505
Q Predictions Mean           946.93475
Q Predictions Std            341.9736
Q Predictions Max            1377.8597
Q Predictions Min            138.54591
V Predictions Mean           954.8389
V Predictions Std            336.63916
V Predictions Max            1379.5991
V Predictions Min            248.00287
Log Pis Mean                 -0.2550932
Log Pis Std                  3.4233375
Log Pis Max                  25.383125
Log Pis Min                  -7.27303
Policy mu Mean               0.03917828
Policy mu Std                0.5996841
Policy mu Max                3.0748322
Policy mu Min                -3.9349911
Policy log std Mean          -0.9702296
Policy log std Std           0.21184908
Policy log std Max           -0.38020062
Policy log std Min           -1.9162459
Z mean eval                  1.159076
Z variance eval              0.033362452
total_rewards                [1945.40980548 3184.61534187 2988.485479   1546.07305462  880.75004512
 1702.63792492 1103.09121287 2679.43573073 3481.0385839   552.4359755 ]
total_rewards_mean           2006.3973154003954
total_rewards_std            973.9187541511008
total_rewards_max            3481.0385839012724
total_rewards_min            552.4359754953351
Number of train steps total  924000
Number of env steps total    1055181
Number of rollouts total     0
Train Time (s)               152.90710812201723
(Previous) Eval Time (s)     24.183250745758414
Sample Time (s)              11.475939242634922
Epoch Time (s)               188.56629811041057
Total Train Time (s)         42471.90110553941
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:43:44.747860 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #230 | Epoch Duration: 188.66416144371033
2020-01-12 13:43:44.748086 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.154204
Z variance train             0.033008832
KL Divergence                19.877327
KL Loss                      1.9877328
QF Loss                      478.17407
VF Loss                      216.14874
Policy Loss                  -930.15607
Q Predictions Mean           921.6034
Q Predictions Std            376.23508
Q Predictions Max            1355.416
Q Predictions Min            -21.463543
V Predictions Mean           928.0955
V Predictions Std            364.98196
V Predictions Max            1350.2684
V Predictions Min            0.29812956
Log Pis Mean                 -0.31408072
Log Pis Std                  3.290569
Log Pis Max                  19.555176
Log Pis Min                  -8.203912
Policy mu Mean               0.03353916
Policy mu Std                0.5865805
Policy mu Max                4.35701
Policy mu Min                -3.7668362
Policy log std Mean          -0.97675854
Policy log std Std           0.22663137
Policy log std Max           -0.054548264
Policy log std Min           -2.1482813
Z mean eval                  1.2365501
Z variance eval              0.04482454
total_rewards                [2456.5429326  3547.1496093  1751.75395694  682.34137036 1105.77181872
 1321.68972009  303.68860736 3202.24985889 1326.02415285  845.28002578]
total_rewards_mean           1654.2492052887815
total_rewards_std            1028.3367739236792
total_rewards_max            3547.1496093002643
total_rewards_min            303.6886073602167
Number of train steps total  928000
Number of env steps total    1065072
Number of rollouts total     0
Train Time (s)               148.98108132788911
(Previous) Eval Time (s)     25.17146109882742
Sample Time (s)              11.872250916901976
Epoch Time (s)               186.0247933436185
Total Train Time (s)         42658.019441580866
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:46:50.869066 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #231 | Epoch Duration: 186.1208052635193
2020-01-12 13:46:50.869289 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #231 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2430469
Z variance train             0.04488218
KL Divergence                19.52415
KL Loss                      1.9524151
QF Loss                      1581.2502
VF Loss                      240.68105
Policy Loss                  -911.23975
Q Predictions Mean           905.24805
Q Predictions Std            368.15463
Q Predictions Max            1342.8097
Q Predictions Min            49.39763
V Predictions Mean           911.22595
V Predictions Std            368.61264
V Predictions Max            1338.8676
V Predictions Min            31.931149
Log Pis Mean                 -0.27782792
Log Pis Std                  2.8552756
Log Pis Max                  16.824053
Log Pis Min                  -7.2803864
Policy mu Mean               0.026317045
Policy mu Std                0.55757153
Policy mu Max                2.8298187
Policy mu Min                -2.950369
Policy log std Mean          -0.95057154
Policy log std Std           0.21504804
Policy log std Max           -0.47138405
Policy log std Min           -2.1825151
Z mean eval                  1.0923171
Z variance eval              0.02225418
total_rewards                [3458.43705114 3388.23318387  806.62027355 3432.80928397 1007.8170545
   30.46855685 3533.782279    999.47158011 3674.92762671  401.03415205]
total_rewards_mean           2073.360104177331
total_rewards_std            1451.0896323360203
total_rewards_max            3674.9276267118403
total_rewards_min            30.468556854224122
Number of train steps total  932000
Number of env steps total    1073410
Number of rollouts total     0
Train Time (s)               142.72506200475618
(Previous) Eval Time (s)     21.765310898888856
Sample Time (s)              8.690001456998289
Epoch Time (s)               173.18037436064333
Total Train Time (s)         42831.550703004
Epoch                        232
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:49:44.403108 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #232 | Epoch Duration: 173.5336730480194
2020-01-12 13:49:44.403312 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0926995
Z variance train             0.022811044
KL Divergence                21.544535
KL Loss                      2.1544535
QF Loss                      1264.7405
VF Loss                      104.81219
Policy Loss                  -913.714
Q Predictions Mean           910.43854
Q Predictions Std            385.95258
Q Predictions Max            1392.1045
Q Predictions Min            49.649525
V Predictions Mean           918.7176
V Predictions Std            380.88754
V Predictions Max            1382.3185
V Predictions Min            285.77725
Log Pis Mean                 -0.5357073
Log Pis Std                  3.0260916
Log Pis Max                  11.865629
Log Pis Min                  -7.203336
Policy mu Mean               -0.030382391
Policy mu Std                0.55613065
Policy mu Max                2.0001624
Policy mu Min                -2.6705072
Policy log std Mean          -0.96633923
Policy log std Std           0.23321998
Policy log std Max           -0.18254793
Policy log std Min           -2.0862262
Z mean eval                  1.0420574
Z variance eval              0.0293452
total_rewards                [3721.60286308 3423.12588313 3504.81379757 3643.84351325 1321.31560125
 3466.39302257 3400.90130627 3457.49199421 3579.76108976  592.94906874]
total_rewards_mean           3011.2198139847033
total_rewards_std            1044.193490384928
total_rewards_max            3721.602863077159
total_rewards_min            592.9490687432183
Number of train steps total  936000
Number of env steps total    1082231
Number of rollouts total     0
Train Time (s)               143.93105149595067
(Previous) Eval Time (s)     31.770420981105417
Sample Time (s)              11.44264671439305
Epoch Time (s)               187.14411919144914
Total Train Time (s)         43018.79010802088
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:52:51.645355 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #233 | Epoch Duration: 187.24189400672913
2020-01-12 13:52:51.645582 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0415903
Z variance train             0.030642167
KL Divergence                20.002022
KL Loss                      2.0002022
QF Loss                      936.56824
VF Loss                      403.7328
Policy Loss                  -874.0947
Q Predictions Mean           871.1139
Q Predictions Std            358.20483
Q Predictions Max            1282.432
Q Predictions Min            18.68047
V Predictions Mean           868.03314
V Predictions Std            359.96436
V Predictions Max            1284.3285
V Predictions Min            -20.19348
Log Pis Mean                 -0.58608884
Log Pis Std                  2.91507
Log Pis Max                  11.354082
Log Pis Min                  -7.343309
Policy mu Mean               -0.0070300205
Policy mu Std                0.5461407
Policy mu Max                2.0300229
Policy mu Min                -3.675143
Policy log std Mean          -0.9639807
Policy log std Std           0.23092197
Policy log std Max           -0.36541128
Policy log std Min           -2.1076198
Z mean eval                  1.1240591
Z variance eval              0.05254973
total_rewards                [2022.06481066   15.09976082  541.18043446 3019.16088886 3473.63641003
 3298.90555519 1843.12351911  468.00698149 3462.3998618   224.72394579]
total_rewards_mean           1836.8302168211326
total_rewards_std            1355.0463700492946
total_rewards_max            3473.6364100304145
total_rewards_min            15.099760824940084
Number of train steps total  940000
Number of env steps total    1092553
Number of rollouts total     0
Train Time (s)               153.32133066980168
(Previous) Eval Time (s)     23.070256853010505
Sample Time (s)              10.424064503517002
Epoch Time (s)               186.8156520263292
Total Train Time (s)         43205.69263430871
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:55:58.552064 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #234 | Epoch Duration: 186.90627455711365
2020-01-12 13:55:58.552509 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1224697
Z variance train             0.05474638
KL Divergence                17.184523
KL Loss                      1.7184523
QF Loss                      2051.2568
VF Loss                      607.27783
Policy Loss                  -959.38544
Q Predictions Mean           952.2831
Q Predictions Std            367.0647
Q Predictions Max            1369.4739
Q Predictions Min            4.8446045
V Predictions Mean           957.938
V Predictions Std            363.31696
V Predictions Max            1353.9651
V Predictions Min            61.65128
Log Pis Mean                 -0.44457513
Log Pis Std                  3.4860406
Log Pis Max                  19.51731
Log Pis Min                  -6.6931963
Policy mu Mean               0.03936018
Policy mu Std                0.61035347
Policy mu Max                5.5363812
Policy mu Min                -2.704654
Policy log std Mean          -0.93639266
Policy log std Std           0.22684969
Policy log std Max           -0.3332585
Policy log std Min           -2.3969905
Z mean eval                  1.1349107
Z variance eval              0.020363268
total_rewards                [2457.34221128 1532.13173199 2956.4618496  3337.3681571  3190.38401007
 3407.87458612 3454.61131043 2790.83821497 1849.31163861 2078.18110955]
total_rewards_mean           2705.450481971604
total_rewards_std            657.5785126640658
total_rewards_max            3454.611310425644
total_rewards_min            1532.1317319917503
Number of train steps total  944000
Number of env steps total    1100788
Number of rollouts total     0
Train Time (s)               151.72795113222674
(Previous) Eval Time (s)     32.01938941795379
Sample Time (s)              13.10589276952669
Epoch Time (s)               196.85323331970721
Total Train Time (s)         43402.635143416
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:59:15.496825 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #235 | Epoch Duration: 196.94403338432312
2020-01-12 13:59:15.497016 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1355871
Z variance train             0.020280955
KL Divergence                19.198975
KL Loss                      1.9198974
QF Loss                      728.157
VF Loss                      106.12516
Policy Loss                  -935.0047
Q Predictions Mean           927.65125
Q Predictions Std            347.15445
Q Predictions Max            1320.6426
Q Predictions Min            -53.561653
V Predictions Mean           936.2538
V Predictions Std            338.72818
V Predictions Max            1323.9185
V Predictions Min            267.8594
Log Pis Mean                 -0.6497662
Log Pis Std                  3.2435586
Log Pis Max                  21.421875
Log Pis Min                  -10.047176
Policy mu Mean               0.021627808
Policy mu Std                0.5582959
Policy mu Max                3.2569945
Policy mu Min                -3.8628843
Policy log std Mean          -0.9665386
Policy log std Std           0.22460397
Policy log std Max           -0.3865549
Policy log std Min           -2.0917306
Z mean eval                  1.0284746
Z variance eval              0.012884798
total_rewards                [1220.7168114  2577.88307071  313.86981874 3349.57539416 3646.40977673
 2574.79451298  733.14697029  480.91345815 3391.51072238 3171.78032349]
total_rewards_mean           2146.0600859027395
total_rewards_std            1251.2094149162083
total_rewards_max            3646.4097767309204
total_rewards_min            313.86981874435304
Number of train steps total  948000
Number of env steps total    1108027
Number of rollouts total     0
Train Time (s)               152.13047480909154
(Previous) Eval Time (s)     26.19838339043781
Sample Time (s)              11.827008934225887
Epoch Time (s)               190.15586713375524
Total Train Time (s)         43592.88321714243
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:02:25.753167 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #236 | Epoch Duration: 190.25596261024475
2020-01-12 14:02:25.753495 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0323293
Z variance train             0.012827684
KL Divergence                20.427492
KL Loss                      2.0427492
QF Loss                      1231.4478
VF Loss                      237.85504
Policy Loss                  -963.49884
Q Predictions Mean           961.1222
Q Predictions Std            346.80524
Q Predictions Max            1377.6156
Q Predictions Min            -32.38489
V Predictions Mean           966.54346
V Predictions Std            346.40314
V Predictions Max            1372.6925
V Predictions Min            -26.935558
Log Pis Mean                 -0.27036715
Log Pis Std                  3.339405
Log Pis Max                  25.264408
Log Pis Min                  -6.271396
Policy mu Mean               -0.004623328
Policy mu Std                0.5898372
Policy mu Max                4.239464
Policy mu Min                -4.6021867
Policy log std Mean          -0.95923907
Policy log std Std           0.21080579
Policy log std Max           0.26792336
Policy log std Min           -2.5879254
Z mean eval                  1.1418412
Z variance eval              0.007841455
total_rewards                [2504.1045265   650.47586504 3238.65792562  939.40260986  558.83217179
  825.86295956  326.76832695 1088.43572717 2173.79778879 3530.4821734 ]
total_rewards_mean           1583.6820074679351
total_rewards_std            1116.2467399532466
total_rewards_max            3530.482173399275
total_rewards_min            326.76832695151705
Number of train steps total  952000
Number of env steps total    1115632
Number of rollouts total     0
Train Time (s)               152.23667739797384
(Previous) Eval Time (s)     23.86213499866426
Sample Time (s)              12.204515722114593
Epoch Time (s)               188.3033281187527
Total Train Time (s)         43781.28326462954
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:05:34.153648 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #237 | Epoch Duration: 188.3999330997467
2020-01-12 14:05:34.153991 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1389719
Z variance train             0.007860223
KL Divergence                22.78633
KL Loss                      2.2786329
QF Loss                      643.96985
VF Loss                      265.23596
Policy Loss                  -943.8849
Q Predictions Mean           941.03296
Q Predictions Std            355.41406
Q Predictions Max            1377.0594
Q Predictions Min            29.833637
V Predictions Mean           942.92554
V Predictions Std            357.54416
V Predictions Max            1363.1077
V Predictions Min            -11.231587
Log Pis Mean                 -0.47781518
Log Pis Std                  3.269095
Log Pis Max                  14.74946
Log Pis Min                  -9.020661
Policy mu Mean               0.05057237
Policy mu Std                0.57571805
Policy mu Max                3.2190335
Policy mu Min                -2.385942
Policy log std Mean          -0.9823581
Policy log std Std           0.23013704
Policy log std Max           -0.3508188
Policy log std Min           -2.6553397
Z mean eval                  1.0112462
Z variance eval              0.017583352
total_rewards                [3500.3485688  3334.95689623 3373.46480607 3275.86526607 3280.77644412
 3558.01745802 3471.78398805 3469.18548996 3468.9117071  3215.25843694]
total_rewards_mean           3394.8569061377375
total_rewards_std            108.6973274403017
total_rewards_max            3558.0174580248977
total_rewards_min            3215.258436935823
Number of train steps total  956000
Number of env steps total    1122946
Number of rollouts total     0
Train Time (s)               146.03535106312484
(Previous) Eval Time (s)     36.39892614912242
Sample Time (s)              11.635161973070353
Epoch Time (s)               194.0694391853176
Total Train Time (s)         43975.43907234259
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:08:48.312467 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #238 | Epoch Duration: 194.158296585083
2020-01-12 14:08:48.312666 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0183742
Z variance train             0.01750674
KL Divergence                18.418667
KL Loss                      1.8418667
QF Loss                      921.9597
VF Loss                      240.72984
Policy Loss                  -957.0018
Q Predictions Mean           951.98267
Q Predictions Std            341.25452
Q Predictions Max            1383.4286
Q Predictions Min            278.18088
V Predictions Mean           950.4068
V Predictions Std            337.6648
V Predictions Max            1341.5471
V Predictions Min            270.72498
Log Pis Mean                 0.053841017
Log Pis Std                  3.095274
Log Pis Max                  10.163962
Log Pis Min                  -10.137326
Policy mu Mean               0.030767372
Policy mu Std                0.60512507
Policy mu Max                2.3146112
Policy mu Min                -2.1811714
Policy log std Mean          -0.999194
Policy log std Std           0.24138096
Policy log std Max           -0.45769626
Policy log std Min           -2.2467048
Z mean eval                  1.0909203
Z variance eval              0.004908925
total_rewards                [3471.20376504 3468.5435007   394.77321274 3424.61673574  302.94017446
 3343.97091543 2577.72803001   56.64233447 3574.13823601 2440.53915138]
total_rewards_mean           2305.5096055983986
total_rewards_std            1395.0860087706867
total_rewards_max            3574.1382360106477
total_rewards_min            56.64233446922654
Number of train steps total  960000
Number of env steps total    1133814
Number of rollouts total     0
Train Time (s)               143.27745526097715
(Previous) Eval Time (s)     28.178314078133553
Sample Time (s)              11.105176826938987
Epoch Time (s)               182.5609461660497
Total Train Time (s)         44158.08968552807
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:11:50.965865 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #239 | Epoch Duration: 182.6530385017395
2020-01-12 14:11:50.966060 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0966747
Z variance train             0.0049033603
KL Divergence                22.139328
KL Loss                      2.2139328
QF Loss                      732.6404
VF Loss                      214.33682
Policy Loss                  -936.79724
Q Predictions Mean           928.71497
Q Predictions Std            351.72958
Q Predictions Max            1371.805
Q Predictions Min            268.12387
V Predictions Mean           934.66486
V Predictions Std            347.0353
V Predictions Max            1380.125
V Predictions Min            278.68857
Log Pis Mean                 -0.32038838
Log Pis Std                  3.2584763
Log Pis Max                  15.685337
Log Pis Min                  -7.2559924
Policy mu Mean               0.041270945
Policy mu Std                0.5808669
Policy mu Max                2.8650699
Policy mu Min                -3.4927053
Policy log std Mean          -0.9754087
Policy log std Std           0.23892702
Policy log std Max           -0.35654336
Policy log std Min           -2.4043834
Z mean eval                  1.0910223
Z variance eval              0.010666641
total_rewards                [1732.53932841 3338.90017691 3431.36954518 3509.7657659  3546.75046671
 3615.43562521  949.72546892 1064.40789246 3381.60237436 3435.14435893]
total_rewards_mean           2800.564100298482
total_rewards_std            1035.9688436477195
total_rewards_max            3615.4356252119974
total_rewards_min            949.7254689154508
Number of train steps total  964000
Number of env steps total    1143617
Number of rollouts total     0
Train Time (s)               147.0860477676615
(Previous) Eval Time (s)     30.143505103420466
Sample Time (s)              11.946330766193569
Epoch Time (s)               189.17588363727555
Total Train Time (s)         44347.35312539479
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:15:00.232465 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #240 | Epoch Duration: 189.26625967025757
2020-01-12 14:15:00.232667 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0799986
Z variance train             0.010603447
KL Divergence                20.637787
KL Loss                      2.0637786
QF Loss                      852.12714
VF Loss                      190.85847
Policy Loss                  -976.7627
Q Predictions Mean           971.22015
Q Predictions Std            342.80377
Q Predictions Max            1352.8551
Q Predictions Min            274.21228
V Predictions Mean           985.56555
V Predictions Std            342.68274
V Predictions Max            1366.8505
V Predictions Min            285.61185
Log Pis Mean                 -0.4818326
Log Pis Std                  2.8365195
Log Pis Max                  13.784443
Log Pis Min                  -7.6231966
Policy mu Mean               -0.01716477
Policy mu Std                0.55577344
Policy mu Max                2.4261878
Policy mu Min                -2.5970654
Policy log std Mean          -0.99491477
Policy log std Std           0.21731931
Policy log std Max           -0.4398899
Policy log std Min           -2.2077103
Z mean eval                  1.1033597
Z variance eval              0.014336077
total_rewards                [3107.22353037  511.99038493  946.71557282  636.00507315 1626.08179832
 3534.02706292 1058.40232366 1220.79164305 2712.04037333 1352.90784114]
total_rewards_mean           1670.6185603701244
total_rewards_std            1011.8122816160117
total_rewards_max            3534.027062922103
total_rewards_min            511.99038492898757
Number of train steps total  968000
Number of env steps total    1153481
Number of rollouts total     0
Train Time (s)               153.99764177994803
(Previous) Eval Time (s)     24.42372405389324
Sample Time (s)              10.584663328249007
Epoch Time (s)               189.00602916209027
Total Train Time (s)         44536.590056455694
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:18:09.472470 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #241 | Epoch Duration: 189.2396411895752
2020-01-12 14:18:09.472664 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0980827
Z variance train             0.014359942
KL Divergence                21.053238
KL Loss                      2.1053238
QF Loss                      753.55444
VF Loss                      167.55893
Policy Loss                  -928.3153
Q Predictions Mean           924.03394
Q Predictions Std            375.6601
Q Predictions Max            1358.7634
Q Predictions Min            20.751486
V Predictions Mean           929.1072
V Predictions Std            375.06955
V Predictions Max            1363.6344
V Predictions Min            14.454056
Log Pis Mean                 -0.537146
Log Pis Std                  3.392461
Log Pis Max                  24.289402
Log Pis Min                  -7.463187
Policy mu Mean               -0.012463575
Policy mu Std                0.5591422
Policy mu Max                3.5481687
Policy mu Min                -3.2725172
Policy log std Mean          -0.9475882
Policy log std Std           0.23941275
Policy log std Max           -0.0077391863
Policy log std Min           -2.1998038
Z mean eval                  0.98866737
Z variance eval              0.009433041
total_rewards                [3170.71792639 3456.15305715 3215.64873086 3223.25920004 3265.64487758
 3176.34617181 3381.10340057 3281.21477379 3214.29563687 3134.17454195]
total_rewards_mean           3251.855831700673
total_rewards_std            94.42871372314657
total_rewards_max            3456.1530571529975
total_rewards_min            3134.174541954344
Number of train steps total  972000
Number of env steps total    1163124
Number of rollouts total     0
Train Time (s)               152.87371760513633
(Previous) Eval Time (s)     35.98774336185306
Sample Time (s)              12.036249792668968
Epoch Time (s)               200.89771075965837
Total Train Time (s)         44737.57543276902
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:21:30.461050 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #242 | Epoch Duration: 200.98823714256287
2020-01-12 14:21:30.461245 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98645717
Z variance train             0.009483966
KL Divergence                21.980423
KL Loss                      2.1980424
QF Loss                      567.77625
VF Loss                      118.92252
Policy Loss                  -972.92834
Q Predictions Mean           969.00055
Q Predictions Std            359.17203
Q Predictions Max            1406.8164
Q Predictions Min            16.012321
V Predictions Mean           969.7638
V Predictions Std            359.1605
V Predictions Max            1399.5865
V Predictions Min            -68.30901
Log Pis Mean                 -0.48280013
Log Pis Std                  3.043638
Log Pis Max                  17.808495
Log Pis Min                  -6.0620804
Policy mu Mean               -0.021263644
Policy mu Std                0.5686338
Policy mu Max                3.3553221
Policy mu Min                -3.0019555
Policy log std Mean          -0.98453414
Policy log std Std           0.23721573
Policy log std Max           -0.3808025
Policy log std Min           -2.3144999
Z mean eval                  1.0811441
Z variance eval              0.033635385
total_rewards                [2132.76234447   26.57860261 1792.90858694 1514.72602846 1304.35883387
 1308.79325182 3378.18379802  502.75399887   88.99774363 2285.60229669]
total_rewards_mean           1433.566548536448
total_rewards_std            990.8705691838314
total_rewards_max            3378.1837980204755
total_rewards_min            26.578602613023083
Number of train steps total  976000
Number of env steps total    1171525
Number of rollouts total     0
Train Time (s)               154.46223454689607
(Previous) Eval Time (s)     18.79815675225109
Sample Time (s)              11.535108881536871
Epoch Time (s)               184.79550018068403
Total Train Time (s)         44922.47752701817
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:24:35.366964 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #243 | Epoch Duration: 184.90556383132935
2020-01-12 14:24:35.367212 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0653392
Z variance train             0.033519845
KL Divergence                19.955135
KL Loss                      1.9955136
QF Loss                      513.64795
VF Loss                      83.74453
Policy Loss                  -1051.2931
Q Predictions Mean           1047.776
Q Predictions Std            363.12875
Q Predictions Max            1435.36
Q Predictions Min            1.2844015
V Predictions Mean           1049.4932
V Predictions Std            361.80133
V Predictions Max            1432.7745
V Predictions Min            52.389896
Log Pis Mean                 -0.39650434
Log Pis Std                  2.4733012
Log Pis Max                  9.411968
Log Pis Min                  -7.313451
Policy mu Mean               0.016515322
Policy mu Std                0.5831845
Policy mu Max                3.5771825
Policy mu Min                -2.491882
Policy log std Mean          -0.9537176
Policy log std Std           0.21007775
Policy log std Max           -0.19586301
Policy log std Min           -1.8442247
Z mean eval                  1.0450838
Z variance eval              0.009899815
total_rewards                [3419.19260935 2768.306713   3302.83524683 1462.27394941 3444.90236114
 3522.41473289 3575.50812026 3554.90988063 3728.77342919 3277.92624594]
total_rewards_mean           3205.704328864479
total_rewards_std            630.9449780060189
total_rewards_max            3728.7734291863176
total_rewards_min            1462.2739494081052
Number of train steps total  980000
Number of env steps total    1180962
Number of rollouts total     0
Train Time (s)               152.26411103317514
(Previous) Eval Time (s)     33.75765220541507
Sample Time (s)              13.300572354346514
Epoch Time (s)               199.32233559293672
Total Train Time (s)         45121.88888255786
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:27:54.781802 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #244 | Epoch Duration: 199.41443133354187
2020-01-12 14:27:54.782008 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0401889
Z variance train             0.009877134
KL Divergence                20.938587
KL Loss                      2.0938587
QF Loss                      1537.2041
VF Loss                      138.0235
Policy Loss                  -976.0951
Q Predictions Mean           973.41833
Q Predictions Std            339.61536
Q Predictions Max            1360.6051
Q Predictions Min            173.7182
V Predictions Mean           977.49963
V Predictions Std            338.72177
V Predictions Max            1372.9089
V Predictions Min            257.79504
Log Pis Mean                 -0.8458695
Log Pis Std                  2.8435938
Log Pis Max                  13.244349
Log Pis Min                  -8.465018
Policy mu Mean               0.032301657
Policy mu Std                0.5577022
Policy mu Max                2.3438642
Policy mu Min                -2.7425728
Policy log std Mean          -0.934566
Policy log std Std           0.2400015
Policy log std Max           -0.26262355
Policy log std Min           -2.0416784
Z mean eval                  0.9928296
Z variance eval              0.013220479
total_rewards                [1182.98183648 3567.51059194 3307.12308029 3508.32213992  508.45347975
  393.71385466 2655.85407411 3600.36598882 1864.35897998  834.90336655]
total_rewards_mean           2142.3587392499016
total_rewards_std            1267.97417847736
total_rewards_max            3600.3659888169423
total_rewards_min            393.71385466028266
Number of train steps total  984000
Number of env steps total    1190960
Number of rollouts total     0
Train Time (s)               143.41525864508003
(Previous) Eval Time (s)     20.247795462142676
Sample Time (s)              10.456232178490609
Epoch Time (s)               174.11928628571332
Total Train Time (s)         45296.10381228058
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:30:48.999628 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #245 | Epoch Duration: 174.2174665927887
2020-01-12 14:30:48.999838 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99204075
Z variance train             0.0132360635
KL Divergence                21.348145
KL Loss                      2.1348145
QF Loss                      635.919
VF Loss                      71.78102
Policy Loss                  -951.60583
Q Predictions Mean           947.61707
Q Predictions Std            348.84268
Q Predictions Max            1363.8163
Q Predictions Min            106.42636
V Predictions Mean           951.3652
V Predictions Std            349.34988
V Predictions Max            1367.6273
V Predictions Min            119.01993
Log Pis Mean                 -0.59652025
Log Pis Std                  2.9696908
Log Pis Max                  15.434259
Log Pis Min                  -7.2448053
Policy mu Mean               0.013049705
Policy mu Std                0.5385621
Policy mu Max                2.307432
Policy mu Min                -2.3393593
Policy log std Mean          -0.94727325
Policy log std Std           0.24370693
Policy log std Max           -0.39109713
Policy log std Min           -2.1670346
Z mean eval                  1.0493863
Z variance eval              0.030276168
total_rewards                [1385.76740783 1188.13976632  716.21235349  174.02255203 3667.04339537
 2252.43963252 2694.32720661  146.21769604 1033.62759277  960.61885502]
total_rewards_mean           1421.8416457992612
total_rewards_std            1070.1205351377553
total_rewards_max            3667.043395366002
total_rewards_min            146.21769603978507
Number of train steps total  988000
Number of env steps total    1201733
Number of rollouts total     0
Train Time (s)               143.6013448331505
(Previous) Eval Time (s)     14.153801708016545
Sample Time (s)              11.785528672393411
Epoch Time (s)               169.54067521356046
Total Train Time (s)         45465.73286121292
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:33:38.631314 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #246 | Epoch Duration: 169.63133144378662
2020-01-12 14:33:38.631491 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0476573
Z variance train             0.03013878
KL Divergence                19.396948
KL Loss                      1.9396948
QF Loss                      631.98035
VF Loss                      375.16525
Policy Loss                  -964.10767
Q Predictions Mean           959.2672
Q Predictions Std            371.37192
Q Predictions Max            1410.7396
Q Predictions Min            216.16676
V Predictions Mean           956.59015
V Predictions Std            367.2883
V Predictions Max            1386.1093
V Predictions Min            288.39395
Log Pis Mean                 -0.36819762
Log Pis Std                  3.397614
Log Pis Max                  22.99379
Log Pis Min                  -8.414314
Policy mu Mean               -0.00698448
Policy mu Std                0.572363
Policy mu Max                2.3152518
Policy mu Min                -3.744757
Policy log std Mean          -0.95708394
Policy log std Std           0.27393937
Policy log std Max           -0.25835758
Policy log std Min           -2.8646374
Z mean eval                  1.1999711
Z variance eval              0.010388443
total_rewards                [3478.30792888  383.88783771  249.83496729 1594.75519045 1190.07197547
 2435.77866019 2155.10463979 1425.31843425 3425.81289456 3644.17883822]
total_rewards_mean           1998.30513668114
total_rewards_std            1181.56482618227
total_rewards_max            3644.178838221572
total_rewards_min            249.83496729216262
Number of train steps total  992000
Number of env steps total    1212127
Number of rollouts total     0
Train Time (s)               149.5087153748609
(Previous) Eval Time (s)     26.193310072645545
Sample Time (s)              11.965480098966509
Epoch Time (s)               187.66750554647297
Total Train Time (s)         45653.487407962326
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:36:46.388936 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #247 | Epoch Duration: 187.75731229782104
2020-01-12 14:36:46.389118 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #247 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1924822
Z variance train             0.010403683
KL Divergence                20.620205
KL Loss                      2.0620205
QF Loss                      1687.1753
VF Loss                      254.4296
Policy Loss                  -952.37225
Q Predictions Mean           948.5033
Q Predictions Std            358.00717
Q Predictions Max            1415.0232
Q Predictions Min            292.5406
V Predictions Mean           958.8263
V Predictions Std            358.61667
V Predictions Max            1410.0385
V Predictions Min            300.84692
Log Pis Mean                 -0.33353665
Log Pis Std                  3.0198476
Log Pis Max                  14.63559
Log Pis Min                  -7.149976
Policy mu Mean               -0.014790118
Policy mu Std                0.58367
Policy mu Max                2.9644904
Policy mu Min                -2.8869889
Policy log std Mean          -0.9519507
Policy log std Std           0.24231909
Policy log std Max           -0.38706988
Policy log std Min           -2.340812
Z mean eval                  1.1014087
Z variance eval              0.0105519835
total_rewards                [  55.36041361 3491.65657734  969.01934493  423.28416875  156.5227717
 3186.00715797  886.40626451  961.27496089  202.59288572  502.48918615]
total_rewards_mean           1083.461373157301
total_rewards_std            1172.708778899034
total_rewards_max            3491.6565773434177
total_rewards_min            55.360413610355685
Number of train steps total  996000
Number of env steps total    1221812
Number of rollouts total     0
Train Time (s)               152.88073267322034
(Previous) Eval Time (s)     18.757918587885797
Sample Time (s)              11.802446173969656
Epoch Time (s)               183.4410974350758
Total Train Time (s)         45837.01827404322
Epoch                        248
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:39:49.923346 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #248 | Epoch Duration: 183.53408455848694
2020-01-12 14:39:49.923545 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1056677
Z variance train             0.010566036
KL Divergence                20.625336
KL Loss                      2.0625336
QF Loss                      993.2765
VF Loss                      204.20071
Policy Loss                  -959.9129
Q Predictions Mean           957.0936
Q Predictions Std            381.47678
Q Predictions Max            1420.5369
Q Predictions Min            -14.477545
V Predictions Mean           958.8235
V Predictions Std            382.3129
V Predictions Max            1409.5966
V Predictions Min            72.5171
Log Pis Mean                 -0.40822062
Log Pis Std                  3.3793035
Log Pis Max                  11.410946
Log Pis Min                  -8.0171585
Policy mu Mean               0.037674524
Policy mu Std                0.5834073
Policy mu Max                2.839424
Policy mu Min                -2.27975
Policy log std Mean          -0.9687236
Policy log std Std           0.26899117
Policy log std Max           -0.4104563
Policy log std Min           -2.2199283
Z mean eval                  1.2100631
Z variance eval              0.00858981
total_rewards                [2231.79867767 2272.49288716 1083.73669227 2424.76444654  142.59591494
 3167.74608748  352.24081121 2259.95766155 3195.47564461 3400.32575773]
total_rewards_mean           2053.1134581162923
total_rewards_std            1100.2762982548054
total_rewards_max            3400.3257577327363
total_rewards_min            142.5959149373052
Number of train steps total  1000000
Number of env steps total    1231651
Number of rollouts total     0
Train Time (s)               152.63570267381147
(Previous) Eval Time (s)     24.0417970251292
Sample Time (s)              11.266486328560859
Epoch Time (s)               187.94398602750152
Total Train Time (s)         46025.05111516267
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:42:57.957466 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #249 | Epoch Duration: 188.03379321098328
2020-01-12 14:42:57.957593 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1984608
Z variance train             0.008560783
KL Divergence                21.211685
KL Loss                      2.1211686
QF Loss                      593.839
VF Loss                      90.664566
Policy Loss                  -1018.7179
Q Predictions Mean           1016.2212
Q Predictions Std            353.7492
Q Predictions Max            1407.8921
Q Predictions Min            309.58005
V Predictions Mean           1019.218
V Predictions Std            350.40475
V Predictions Max            1395.9998
V Predictions Min            318.00784
Log Pis Mean                 0.008065678
Log Pis Std                  2.8651118
Log Pis Max                  12.613289
Log Pis Min                  -7.3812838
Policy mu Mean               0.030368902
Policy mu Std                0.5846158
Policy mu Max                2.3367429
Policy mu Min                -2.2249138
Policy log std Mean          -0.9708394
Policy log std Std           0.25496534
Policy log std Max           -0.36129087
Policy log std Min           -2.0490386
Z mean eval                  1.1075809
Z variance eval              0.011417593
total_rewards                [3288.15848999 3369.69979018 1071.00160125 3457.76259929 1375.91334841
  493.29628389 3362.25442234 3328.13111421 1984.05235781 3504.69614405]
total_rewards_mean           2523.4966151421595
total_rewards_std            1110.2579424825005
total_rewards_max            3504.696144053269
total_rewards_min            493.2962838882322
Number of train steps total  1004000
Number of env steps total    1241094
Number of rollouts total     0
Train Time (s)               154.2679670653306
(Previous) Eval Time (s)     25.47615888994187
Sample Time (s)              10.556021339260042
Epoch Time (s)               190.3001472945325
Total Train Time (s)         46215.5332111991
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:46:08.443407 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #250 | Epoch Duration: 190.48569869995117
2020-01-12 14:46:08.443625 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1055027
Z variance train             0.011385612
KL Divergence                21.631798
KL Loss                      2.1631799
QF Loss                      480.3116
VF Loss                      109.57513
Policy Loss                  -945.3663
Q Predictions Mean           943.9733
Q Predictions Std            378.85126
Q Predictions Max            1411.773
Q Predictions Min            -0.7067529
V Predictions Mean           951.1282
V Predictions Std            377.79077
V Predictions Max            1407.6472
V Predictions Min            37.402473
Log Pis Mean                 -0.7488664
Log Pis Std                  3.118898
Log Pis Max                  16.606075
Log Pis Min                  -8.238204
Policy mu Mean               0.017628198
Policy mu Std                0.5572905
Policy mu Max                2.724751
Policy mu Min                -2.3857179
Policy log std Mean          -0.91561925
Policy log std Std           0.23365502
Policy log std Max           -0.34865427
Policy log std Min           -2.0935931
Z mean eval                  1.0435594
Z variance eval              0.007429057
total_rewards                [1814.87868234 3419.93229888  116.44435881 2901.39960505 3384.93596234
 1269.57933305  628.42990022  424.67659944 2925.26104361  737.8406231 ]
total_rewards_mean           1762.3378406850447
total_rewards_std            1229.2075632050999
total_rewards_max            3419.932298883111
total_rewards_min            116.44435880804025
Number of train steps total  1008000
Number of env steps total    1250001
Number of rollouts total     0
Train Time (s)               152.72866003774107
(Previous) Eval Time (s)     21.199861652217805
Sample Time (s)              11.976923607289791
Epoch Time (s)               185.90544529724866
Total Train Time (s)         46401.52538098395
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:49:14.443679 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #251 | Epoch Duration: 185.99987745285034
2020-01-12 14:49:14.443891 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0491229
Z variance train             0.007526861
KL Divergence                22.035412
KL Loss                      2.2035413
QF Loss                      565.5577
VF Loss                      148.39537
Policy Loss                  -983.7127
Q Predictions Mean           978.8701
Q Predictions Std            374.0981
Q Predictions Max            1392.366
Q Predictions Min            5.418974
V Predictions Mean           981.71063
V Predictions Std            368.10556
V Predictions Max            1380.773
V Predictions Min            69.15481
Log Pis Mean                 -0.6079149
Log Pis Std                  3.049263
Log Pis Max                  14.095161
Log Pis Min                  -8.636501
Policy mu Mean               -0.017280154
Policy mu Std                0.5739599
Policy mu Max                3.4158287
Policy mu Min                -3.4777076
Policy log std Mean          -0.9395584
Policy log std Std           0.24021424
Policy log std Max           -0.0006175041
Policy log std Min           -2.2173352
Z mean eval                  1.1636106
Z variance eval              0.003882389
total_rewards                [2373.19429688 2656.00586622 1385.59068588  863.73634503  134.58035296
 1939.61765672 2826.35671796  912.01952068   66.29978097  494.99640942]
total_rewards_mean           1365.2397632715627
total_rewards_std            977.9182878793899
total_rewards_max            2826.356717964889
total_rewards_min            66.29978097073281
Number of train steps total  1012000
Number of env steps total    1259929
Number of rollouts total     0
Train Time (s)               143.0417911047116
(Previous) Eval Time (s)     20.170757967978716
Sample Time (s)              12.022869301959872
Epoch Time (s)               175.23541837465018
Total Train Time (s)         46576.85743171722
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:52:09.776731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #252 | Epoch Duration: 175.33265566825867
2020-01-12 14:52:09.777010 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1654608
Z variance train             0.0038822498
KL Divergence                25.159367
KL Loss                      2.5159366
QF Loss                      410.2617
VF Loss                      208.13739
Policy Loss                  -979.9922
Q Predictions Mean           975.78674
Q Predictions Std            367.34067
Q Predictions Max            1417.3673
Q Predictions Min            -45.672382
V Predictions Mean           979.3299
V Predictions Std            364.18692
V Predictions Max            1409.3473
V Predictions Min            -20.092735
Log Pis Mean                 -0.8124721
Log Pis Std                  3.272414
Log Pis Max                  17.989975
Log Pis Min                  -8.4723835
Policy mu Mean               -0.027522746
Policy mu Std                0.56693614
Policy mu Max                2.4721007
Policy mu Min                -3.2181013
Policy log std Mean          -0.9000351
Policy log std Std           0.24824318
Policy log std Max           -0.08922279
Policy log std Min           -2.4492865
Z mean eval                  1.0517375
Z variance eval              0.015819862
total_rewards                [ 564.84213612 3272.47265678 3235.69152842 1947.78514751 1927.36021837
 1984.03279578  411.71272337 3296.321922   1950.82146708  648.77307103]
total_rewards_mean           1923.9813666461264
total_rewards_std            1057.7148767177296
total_rewards_max            3296.3219219961857
total_rewards_min            411.71272336936556
Number of train steps total  1016000
Number of env steps total    1267646
Number of rollouts total     0
Train Time (s)               142.6859728381969
(Previous) Eval Time (s)     24.6161771658808
Sample Time (s)              13.357610593549907
Epoch Time (s)               180.6597605976276
Total Train Time (s)         46757.60775711201
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:55:10.529941 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #253 | Epoch Duration: 180.75275421142578
2020-01-12 14:55:10.530143 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0523497
Z variance train             0.015893197
KL Divergence                22.447565
KL Loss                      2.2447565
QF Loss                      893.3608
VF Loss                      1239.1978
Policy Loss                  -1008.06165
Q Predictions Mean           1001.4392
Q Predictions Std            362.61572
Q Predictions Max            1412.9923
Q Predictions Min            49.547913
V Predictions Mean           1004.9823
V Predictions Std            357.33167
V Predictions Max            1403.588
V Predictions Min            177.569
Log Pis Mean                 -0.479546
Log Pis Std                  3.2632315
Log Pis Max                  17.839947
Log Pis Min                  -8.836822
Policy mu Mean               -0.038474612
Policy mu Std                0.5682539
Policy mu Max                3.2566044
Policy mu Min                -2.6505573
Policy log std Mean          -0.95296
Policy log std Std           0.24994639
Policy log std Max           -0.33909988
Policy log std Min           -2.5998957
Z mean eval                  1.0259831
Z variance eval              0.026686918
total_rewards                [1432.20819817 2057.97266756 2215.23932589 1652.43133586 3476.57873121
 3088.81893302 3572.41507014  197.75056986 3642.1183738  1434.38763456]
total_rewards_mean           2276.992084008544
total_rewards_std            1087.589437203967
total_rewards_max            3642.1183738011673
total_rewards_min            197.75056986425975
Number of train steps total  1020000
Number of env steps total    1277184
Number of rollouts total     0
Train Time (s)               151.53827206417918
(Previous) Eval Time (s)     27.693305043969303
Sample Time (s)              11.660873922985047
Epoch Time (s)               190.89245103113353
Total Train Time (s)         46948.60149055673
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:58:21.528222 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #254 | Epoch Duration: 190.99787044525146
2020-01-12 14:58:21.528622 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0255909
Z variance train             0.02672771
KL Divergence                18.5566
KL Loss                      1.8556601
QF Loss                      756.9948
VF Loss                      195.53532
Policy Loss                  -916.61395
Q Predictions Mean           909.6544
Q Predictions Std            384.34238
Q Predictions Max            1417.4673
Q Predictions Min            1.620048
V Predictions Mean           917.58264
V Predictions Std            377.0772
V Predictions Max            1405.133
V Predictions Min            315.67276
Log Pis Mean                 -0.44316232
Log Pis Std                  3.2927654
Log Pis Max                  13.916138
Log Pis Min                  -7.0535946
Policy mu Mean               -8.041016e-05
Policy mu Std                0.551775
Policy mu Max                2.3631678
Policy mu Min                -2.4540646
Policy log std Mean          -0.96528494
Policy log std Std           0.2682999
Policy log std Max           -0.305107
Policy log std Min           -2.5519032
Z mean eval                  1.274718
Z variance eval              0.012733149
total_rewards                [3113.24031798 1069.07353904 2414.26303954 3417.29143691  547.75798969
 3349.36546448 3430.21079084 3595.08576548 3506.54867808 3334.39431782]
total_rewards_mean           2777.723133986129
total_rewards_std            1039.5968866140554
total_rewards_max            3595.0857654824354
total_rewards_min            547.7579896852192
Number of train steps total  1024000
Number of env steps total    1284445
Number of rollouts total     0
Train Time (s)               152.18933157622814
(Previous) Eval Time (s)     30.770339787006378
Sample Time (s)              11.854491868522018
Epoch Time (s)               194.81416323175654
Total Train Time (s)         47143.50488226209
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:01:36.433760 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #255 | Epoch Duration: 194.90491437911987
2020-01-12 15:01:36.433952 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2774454
Z variance train             0.01277489
KL Divergence                20.316624
KL Loss                      2.0316625
QF Loss                      573.6678
VF Loss                      184.62036
Policy Loss                  -971.59314
Q Predictions Mean           969.73047
Q Predictions Std            374.389
Q Predictions Max            1414.2522
Q Predictions Min            323.78937
V Predictions Mean           976.4613
V Predictions Std            373.6716
V Predictions Max            1418.4696
V Predictions Min            330.46918
Log Pis Mean                 -0.78798974
Log Pis Std                  2.8559916
Log Pis Max                  7.5994015
Log Pis Min                  -7.6247625
Policy mu Mean               -0.02329218
Policy mu Std                0.5525654
Policy mu Max                2.1965036
Policy mu Min                -2.348581
Policy log std Mean          -0.91479677
Policy log std Std           0.23907724
Policy log std Max           -0.3046133
Policy log std Min           -1.9751239
Z mean eval                  1.1212847
Z variance eval              0.011008394
total_rewards                [3562.91859768  929.08500122 3477.16960721   99.6735101  1413.94426389
 2115.61082536 3579.66726113  857.23527075 3430.57566767 3478.05306449]
total_rewards_mean           2294.3933069485615
total_rewards_std            1300.209397597265
total_rewards_max            3579.6672611320864
total_rewards_min            99.67351009585302
Number of train steps total  1028000
Number of env steps total    1295403
Number of rollouts total     0
Train Time (s)               152.12493413081393
(Previous) Eval Time (s)     24.551784995943308
Sample Time (s)              13.138557231519371
Epoch Time (s)               189.8152763582766
Total Train Time (s)         47333.40723469015
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:04:46.339107 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #256 | Epoch Duration: 189.90501070022583
2020-01-12 15:04:46.339302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1272681
Z variance train             0.011048524
KL Divergence                20.444128
KL Loss                      2.0444129
QF Loss                      541.8827
VF Loss                      123.74128
Policy Loss                  -987.3609
Q Predictions Mean           983.2703
Q Predictions Std            372.46317
Q Predictions Max            1403.0764
Q Predictions Min            144.64854
V Predictions Mean           987.96826
V Predictions Std            371.61325
V Predictions Max            1407.2927
V Predictions Min            232.94688
Log Pis Mean                 -0.5437762
Log Pis Std                  2.8179288
Log Pis Max                  7.3534164
Log Pis Min                  -7.252457
Policy mu Mean               -0.00019567413
Policy mu Std                0.56547546
Policy mu Max                2.716228
Policy mu Min                -2.4111092
Policy log std Mean          -0.93705624
Policy log std Std           0.24887986
Policy log std Max           -0.3459618
Policy log std Min           -1.9588614
Z mean eval                  1.0589422
Z variance eval              0.021850096
total_rewards                [3429.25440714 3655.16665806 3599.25646138 2380.80486575 2291.67064108
 3696.7751051  3450.13529132 1703.36144767 2602.94689318 3453.00077216]
total_rewards_mean           3026.237254283458
total_rewards_std            676.9866981277162
total_rewards_max            3696.775105100231
total_rewards_min            1703.3614476738887
Number of train steps total  1032000
Number of env steps total    1304951
Number of rollouts total     0
Train Time (s)               153.44380103098229
(Previous) Eval Time (s)     33.5588319003582
Sample Time (s)              11.921953046694398
Epoch Time (s)               198.92458597803488
Total Train Time (s)         47532.42615406355
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:08:05.361929 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #257 | Epoch Duration: 199.0224597454071
2020-01-12 15:08:05.362250 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0435671
Z variance train             0.020754801
KL Divergence                20.183407
KL Loss                      2.0183408
QF Loss                      1320.0553
VF Loss                      1235.6359
Policy Loss                  -1016.94116
Q Predictions Mean           1006.16077
Q Predictions Std            355.56155
Q Predictions Max            1422.167
Q Predictions Min            -41.57386
V Predictions Mean           1007.6627
V Predictions Std            343.0182
V Predictions Max            1416.6117
V Predictions Min            332.48282
Log Pis Mean                 -0.46682066
Log Pis Std                  3.5455532
Log Pis Max                  24.586994
Log Pis Min                  -7.3202095
Policy mu Mean               0.033003762
Policy mu Std                0.61051565
Policy mu Max                3.6202292
Policy mu Min                -4.223944
Policy log std Mean          -0.9553637
Policy log std Std           0.25414628
Policy log std Max           -0.3733502
Policy log std Min           -2.100921
Z mean eval                  1.1210932
Z variance eval              0.038558997
total_rewards                [ 495.68136678  534.58402711  331.26454929 3339.10226857 1510.79386285
 1811.72330897  163.55852995 1543.07214602 3282.75417974  760.45729549]
total_rewards_mean           1377.2991534772175
total_rewards_std            1102.212478018769
total_rewards_max            3339.102268572518
total_rewards_min            163.55852994556608
Number of train steps total  1036000
Number of env steps total    1313673
Number of rollouts total     0
Train Time (s)               147.63197336997837
(Previous) Eval Time (s)     19.24743855698034
Sample Time (s)              12.437786253169179
Epoch Time (s)               179.3171981801279
Total Train Time (s)         47711.83348304825
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:11:04.772432 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #258 | Epoch Duration: 179.40999555587769
2020-01-12 15:11:04.772626 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0905963
Z variance train             0.038269572
KL Divergence                17.931997
KL Loss                      1.7931998
QF Loss                      621.9378
VF Loss                      199.03836
Policy Loss                  -938.82214
Q Predictions Mean           931.7727
Q Predictions Std            379.37598
Q Predictions Max            1415.4243
Q Predictions Min            -84.789734
V Predictions Mean           941.1276
V Predictions Std            374.85052
V Predictions Max            1424.9164
V Predictions Min            186.54895
Log Pis Mean                 -0.6790633
Log Pis Std                  3.379529
Log Pis Max                  27.47678
Log Pis Min                  -9.399417
Policy mu Mean               0.029090106
Policy mu Std                0.6136143
Policy mu Max                5.1959405
Policy mu Min                -3.294137
Policy log std Mean          -0.8763515
Policy log std Std           0.2547637
Policy log std Max           -0.34198737
Policy log std Min           -2.765026
Z mean eval                  1.2664692
Z variance eval              0.013508886
total_rewards                [3598.67475043 3225.9793275   718.34393476 1698.82043827 1410.68020338
  507.46004456 1915.17840363 1652.5499886  1704.75236138 1931.59684625]
total_rewards_mean           1836.4036298751319
total_rewards_std            912.0986601436192
total_rewards_max            3598.6747504297978
total_rewards_min            507.46004455775
Number of train steps total  1040000
Number of env steps total    1324209
Number of rollouts total     0
Train Time (s)               143.430351795163
(Previous) Eval Time (s)     21.150936515070498
Sample Time (s)              11.353653507307172
Epoch Time (s)               175.93494181754068
Total Train Time (s)         47887.855085296556
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:14:00.797181 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #259 | Epoch Duration: 176.024409532547
2020-01-12 15:14:00.797373 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2613623
Z variance train             0.013535192
KL Divergence                20.522697
KL Loss                      2.0522697
QF Loss                      615.7903
VF Loss                      136.63644
Policy Loss                  -1001.4429
Q Predictions Mean           998.54034
Q Predictions Std            353.59866
Q Predictions Max            1427.2428
Q Predictions Min            318.8953
V Predictions Mean           1004.79346
V Predictions Std            352.83472
V Predictions Max            1423.1476
V Predictions Min            331.3041
Log Pis Mean                 -0.22748621
Log Pis Std                  3.0226257
Log Pis Max                  9.73216
Log Pis Min                  -7.7073936
Policy mu Mean               -0.0033296647
Policy mu Std                0.6027421
Policy mu Max                2.5928192
Policy mu Min                -2.6040585
Policy log std Mean          -0.9360545
Policy log std Std           0.2541074
Policy log std Max           -0.2592193
Policy log std Min           -2.4294486
Z mean eval                  1.0549811
Z variance eval              0.11780335
total_rewards                [3469.14518384   74.78701992 1188.72264816 1979.85099038 2500.47004904
 1477.76318868 3459.27108609 3418.76510278  346.35307842 3504.83294142]
total_rewards_mean           2141.996128873838
total_rewards_std            1264.3741102761348
total_rewards_max            3504.8329414188565
total_rewards_min            74.78701992285053
Number of train steps total  1044000
Number of env steps total    1333206
Number of rollouts total     0
Train Time (s)               144.74825614597648
(Previous) Eval Time (s)     26.001518482342362
Sample Time (s)              11.771907612681389
Epoch Time (s)               182.52168224100024
Total Train Time (s)         48070.466037801
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:17:03.411088 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #260 | Epoch Duration: 182.6135721206665
2020-01-12 15:17:03.411704 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0560777
Z variance train             0.11874094
KL Divergence                18.409588
KL Loss                      1.8409588
QF Loss                      1039.7206
VF Loss                      212.41577
Policy Loss                  -929.5557
Q Predictions Mean           923.68744
Q Predictions Std            349.49496
Q Predictions Max            1345.974
Q Predictions Min            189.8198
V Predictions Mean           936.06134
V Predictions Std            348.94388
V Predictions Max            1342.7975
V Predictions Min            253.86061
Log Pis Mean                 -0.29409876
Log Pis Std                  3.6095948
Log Pis Max                  32.956535
Log Pis Min                  -7.8345647
Policy mu Mean               0.00038064318
Policy mu Std                0.6196219
Policy mu Max                4.299395
Policy mu Min                -6.455852
Policy log std Mean          -0.9538676
Policy log std Std           0.25336772
Policy log std Max           -0.35124266
Policy log std Min           -2.8354535
Z mean eval                  1.0225323
Z variance eval              0.037147522
total_rewards                [ 171.37618013 3520.5624896  2648.23398116 3422.74678431   54.60270254
 2441.79466041 1988.17142889 1834.02333741 3647.70597258 1059.44551062]
total_rewards_mean           2078.8663047646774
total_rewards_std            1250.8081859262002
total_rewards_max            3647.705972583606
total_rewards_min            54.60270254476933
Number of train steps total  1048000
Number of env steps total    1340610
Number of rollouts total     0
Train Time (s)               152.46801265422255
(Previous) Eval Time (s)     22.764653909020126
Sample Time (s)              11.44701334927231
Epoch Time (s)               186.67967991251498
Total Train Time (s)         48257.24638244836
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:20:10.196785 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #261 | Epoch Duration: 186.78488206863403
2020-01-12 15:20:10.197251 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0316833
Z variance train             0.037136726
KL Divergence                18.438156
KL Loss                      1.8438157
QF Loss                      1141.5146
VF Loss                      199.9754
Policy Loss                  -992.31055
Q Predictions Mean           985.3959
Q Predictions Std            375.75623
Q Predictions Max            1453.5891
Q Predictions Min            -37.490158
V Predictions Mean           986.3127
V Predictions Std            371.5458
V Predictions Max            1450.8624
V Predictions Min            36.02092
Log Pis Mean                 -0.61317563
Log Pis Std                  3.0485637
Log Pis Max                  13.089296
Log Pis Min                  -8.160755
Policy mu Mean               0.01798214
Policy mu Std                0.5758018
Policy mu Max                2.308783
Policy mu Min                -2.6106453
Policy log std Mean          -0.90633225
Policy log std Std           0.2651006
Policy log std Max           -0.281098
Policy log std Min           -2.3992486
Z mean eval                  1.1354636
Z variance eval              0.023675965
total_rewards                [3244.35487321 3345.42389209 3272.93651507 3238.30831568 3504.44995526
 2170.35790754 2928.61039729  118.50228411 3342.32638837 1203.97518538]
total_rewards_mean           2636.9245713990836
total_rewards_std            1076.37671413084
total_rewards_max            3504.449955259057
total_rewards_min            118.50228411216881
Number of train steps total  1052000
Number of env steps total    1347942
Number of rollouts total     0
Train Time (s)               151.92054936196655
(Previous) Eval Time (s)     35.73298595612869
Sample Time (s)              12.411701274104416
Epoch Time (s)               200.06523659219965
Total Train Time (s)         48457.425890097395
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:23:30.382559 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #262 | Epoch Duration: 200.1850664615631
2020-01-12 15:23:30.382821 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1361452
Z variance train             0.023560304
KL Divergence                19.714855
KL Loss                      1.9714855
QF Loss                      3238.4143
VF Loss                      138.30275
Policy Loss                  -975.81433
Q Predictions Mean           974.54004
Q Predictions Std            381.30865
Q Predictions Max            1452.6578
Q Predictions Min            329.3814
V Predictions Mean           973.73413
V Predictions Std            380.7512
V Predictions Max            1434.5621
V Predictions Min            317.9382
Log Pis Mean                 -0.89055085
Log Pis Std                  3.2120075
Log Pis Max                  11.8768635
Log Pis Min                  -9.398873
Policy mu Mean               0.015277432
Policy mu Std                0.58074063
Policy mu Max                2.047421
Policy mu Min                -2.5667214
Policy log std Mean          -0.893818
Policy log std Std           0.25531358
Policy log std Max           -0.28073376
Policy log std Min           -2.2421355
Z mean eval                  1.0972182
Z variance eval              0.014262527
total_rewards                [ 979.115486   3223.25764467 1821.34945706 3369.57201617 2106.02559214
  512.56377674 2092.67245316 2313.65405326 2288.05034423 2434.52144554]
total_rewards_mean           2114.0782268967696
total_rewards_std            831.7767995212739
total_rewards_max            3369.572016167972
total_rewards_min            512.5637767438276
Number of train steps total  1056000
Number of env steps total    1356313
Number of rollouts total     0
Train Time (s)               151.93757773004472
(Previous) Eval Time (s)     28.074006178881973
Sample Time (s)              10.286138582509011
Epoch Time (s)               190.2977224914357
Total Train Time (s)         48647.824837191496
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:26:40.781872 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #263 | Epoch Duration: 190.39887762069702
2020-01-12 15:26:40.782124 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0999556
Z variance train             0.014169132
KL Divergence                20.682068
KL Loss                      2.0682068
QF Loss                      523.5771
VF Loss                      78.43045
Policy Loss                  -986.4939
Q Predictions Mean           983.3728
Q Predictions Std            370.12772
Q Predictions Max            1420.0349
Q Predictions Min            287.97797
V Predictions Mean           990.56384
V Predictions Std            368.74033
V Predictions Max            1427.9993
V Predictions Min            281.29465
Log Pis Mean                 -0.72921705
Log Pis Std                  3.0800698
Log Pis Max                  12.125067
Log Pis Min                  -10.687713
Policy mu Mean               0.015749604
Policy mu Std                0.5868583
Policy mu Max                2.1278217
Policy mu Min                -2.5575778
Policy log std Mean          -0.89006424
Policy log std Std           0.2432506
Policy log std Max           -0.33787638
Policy log std Min           -1.8645499
Z mean eval                  1.1416595
Z variance eval              0.022087526
total_rewards                [ 919.14376042  624.46601592 2402.80287361  194.34497797 3534.95939607
 3525.05775449  616.79595563 1405.50517107 3535.84378606  919.54544568]
total_rewards_mean           1767.8465136917844
total_rewards_std            1281.3590037431584
total_rewards_max            3535.8437860556087
total_rewards_min            194.34497796567646
Number of train steps total  1060000
Number of env steps total    1366504
Number of rollouts total     0
Train Time (s)               153.39152397867292
(Previous) Eval Time (s)     24.8113626036793
Sample Time (s)              12.688567526172847
Epoch Time (s)               190.89145410852507
Total Train Time (s)         48838.80490246415
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:29:51.764657 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #264 | Epoch Duration: 190.98236632347107
2020-01-12 15:29:51.764845 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1335298
Z variance train             0.022308841
KL Divergence                21.523901
KL Loss                      2.1523902
QF Loss                      370.7269
VF Loss                      65.06588
Policy Loss                  -993.30084
Q Predictions Mean           991.822
Q Predictions Std            366.39505
Q Predictions Max            1440.607
Q Predictions Min            345.36154
V Predictions Mean           992.252
V Predictions Std            368.80347
V Predictions Max            1435.0673
V Predictions Min            345.11163
Log Pis Mean                 -0.9914065
Log Pis Std                  2.8477373
Log Pis Max                  8.232889
Log Pis Min                  -7.758939
Policy mu Mean               0.04133202
Policy mu Std                0.5473544
Policy mu Max                2.1836338
Policy mu Min                -2.2798214
Policy log std Mean          -0.8924537
Policy log std Std           0.24454509
Policy log std Max           0.16402662
Policy log std Min           -1.7937739
Z mean eval                  1.1308056
Z variance eval              0.022817496
total_rewards                [1457.32012249 3166.54630993 2353.1507163  1995.66496262  459.83474579
 1366.43817728 1014.08227226 3380.3440942  2604.80816611  178.20790946]
total_rewards_mean           1797.6397476430025
total_rewards_std            1034.706806926955
total_rewards_max            3380.344094196843
total_rewards_min            178.207909455884
Number of train steps total  1064000
Number of env steps total    1375426
Number of rollouts total     0
Train Time (s)               145.77149751828983
(Previous) Eval Time (s)     23.57444160571322
Sample Time (s)              12.678952483460307
Epoch Time (s)               182.02489160746336
Total Train Time (s)         49021.039857409894
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:32:54.002667 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #265 | Epoch Duration: 182.23768281936646
2020-01-12 15:32:54.002858 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1377815
Z variance train             0.022776976
KL Divergence                21.667103
KL Loss                      2.1667104
QF Loss                      12557.431
VF Loss                      219.4167
Policy Loss                  -1006.7237
Q Predictions Mean           1001.9133
Q Predictions Std            363.23593
Q Predictions Max            1427.9884
Q Predictions Min            253.71204
V Predictions Mean           1012.2774
V Predictions Std            356.53198
V Predictions Max            1431.6316
V Predictions Min            368.56363
Log Pis Mean                 -0.44907576
Log Pis Std                  3.2300537
Log Pis Max                  12.986841
Log Pis Min                  -11.288146
Policy mu Mean               0.017719176
Policy mu Std                0.58848625
Policy mu Max                2.790548
Policy mu Min                -2.2843485
Policy log std Mean          -0.91601914
Policy log std Std           0.26517665
Policy log std Max           -0.28222948
Policy log std Min           -2.63241
Z mean eval                  1.0194849
Z variance eval              0.03126047
total_rewards                [1033.52235826 3271.17808458 1910.07215124 3370.24222222  397.06169452
 1455.64495548 3089.20535254 2595.9586241  1185.14796792  672.38988631]
total_rewards_mean           1898.042329717145
total_rewards_std            1056.6679189983136
total_rewards_max            3370.242222217246
total_rewards_min            397.061694519091
Number of train steps total  1068000
Number of env steps total    1384324
Number of rollouts total     0
Train Time (s)               143.55532472673804
(Previous) Eval Time (s)     21.077080257236958
Sample Time (s)              12.927234946750104
Epoch Time (s)               177.5596399307251
Total Train Time (s)         49198.69020131091
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:35:51.656222 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #266 | Epoch Duration: 177.65322017669678
2020-01-12 15:35:51.656412 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #266 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0163825
Z variance train             0.030850684
KL Divergence                20.442493
KL Loss                      2.0442493
QF Loss                      901.7895
VF Loss                      244.62096
Policy Loss                  -993.62524
Q Predictions Mean           988.5857
Q Predictions Std            363.25845
Q Predictions Max            1434.2628
Q Predictions Min            294.40674
V Predictions Mean           994.45703
V Predictions Std            361.20065
V Predictions Max            1422.8003
V Predictions Min            358.27863
Log Pis Mean                 -0.72715056
Log Pis Std                  3.2219625
Log Pis Max                  8.74021
Log Pis Min                  -8.447862
Policy mu Mean               0.06508049
Policy mu Std                0.5897381
Policy mu Max                2.3987312
Policy mu Min                -2.294916
Policy log std Mean          -0.8961773
Policy log std Std           0.26712632
Policy log std Max           -0.33148998
Policy log std Min           -2.592592
Z mean eval                  1.1637948
Z variance eval              0.018457
total_rewards                [3386.13761296   13.72043123  389.00405463 1366.88844871 2378.5505562
   11.55901809  747.92655112 1670.28933788 3591.240153   3473.91119475]
total_rewards_mean           1702.9227358555868
total_rewards_std            1358.6142833725999
total_rewards_max            3591.2401530008556
total_rewards_min            11.559018085822826
Number of train steps total  1072000
Number of env steps total    1393076
Number of rollouts total     0
Train Time (s)               146.57793792989105
(Previous) Eval Time (s)     19.048806559760123
Sample Time (s)              11.677638425957412
Epoch Time (s)               177.30438291560858
Total Train Time (s)         49376.081369020976
Epoch                        267
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:38:49.050615 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #267 | Epoch Duration: 177.39405798912048
2020-01-12 15:38:49.050824 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1649635
Z variance train             0.018551117
KL Divergence                20.00369
KL Loss                      2.000369
QF Loss                      756.6199
VF Loss                      96.85214
Policy Loss                  -1047.8695
Q Predictions Mean           1041.5367
Q Predictions Std            357.2957
Q Predictions Max            1474.6753
Q Predictions Min            -86.29408
V Predictions Mean           1047.105
V Predictions Std            356.15622
V Predictions Max            1468.1676
V Predictions Min            39.009438
Log Pis Mean                 -0.32243687
Log Pis Std                  3.0119433
Log Pis Max                  8.331614
Log Pis Min                  -6.8299932
Policy mu Mean               0.022541888
Policy mu Std                0.61069655
Policy mu Max                2.5230992
Policy mu Min                -2.205474
Policy log std Mean          -0.9269272
Policy log std Std           0.26774442
Policy log std Max           -0.33930606
Policy log std Min           -2.50036
Z mean eval                  1.0066602
Z variance eval              0.013446513
total_rewards                [ 107.89161605 3568.14351598 2069.15240397 1228.4607857  2907.33001172
  292.46904362 3566.0053997  3489.13791508  161.7994286  1833.21051211]
total_rewards_mean           1922.360063252312
total_rewards_std            1356.2646450045875
total_rewards_max            3568.143515983891
total_rewards_min            107.89161605461902
Number of train steps total  1076000
Number of env steps total    1402675
Number of rollouts total     0
Train Time (s)               154.88831547275186
(Previous) Eval Time (s)     21.945882617030293
Sample Time (s)              10.855587437748909
Epoch Time (s)               187.68978552753106
Total Train Time (s)         49563.861293849535
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:41:56.833878 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #268 | Epoch Duration: 187.78289127349854
2020-01-12 15:41:56.834130 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0069826
Z variance train             0.013402452
KL Divergence                19.211487
KL Loss                      1.9211487
QF Loss                      500.6092
VF Loss                      89.11803
Policy Loss                  -1017.56366
Q Predictions Mean           1011.291
Q Predictions Std            336.4235
Q Predictions Max            1432.5707
Q Predictions Min            356.43652
V Predictions Mean           1013.5882
V Predictions Std            336.7273
V Predictions Max            1424.8013
V Predictions Min            359.35983
Log Pis Mean                 -0.62911654
Log Pis Std                  2.9200666
Log Pis Max                  8.035797
Log Pis Min                  -9.927098
Policy mu Mean               0.022358268
Policy mu Std                0.5889767
Policy mu Max                2.245686
Policy mu Min                -2.4700048
Policy log std Mean          -0.91111237
Policy log std Std           0.25503054
Policy log std Max           -0.35904038
Policy log std Min           -2.0659647
Z mean eval                  1.1463884
Z variance eval              0.031827677
total_rewards                [2175.33974491 1539.6741152    14.930569   3656.01288976 3567.26565262
  446.61085812 2156.57848727 3485.05027971 1725.35856287 3578.97940441]
total_rewards_mean           2234.580056386572
total_rewards_std            1266.6127956581588
total_rewards_max            3656.0128897564764
total_rewards_min            14.930569001970886
Number of train steps total  1080000
Number of env steps total    1411954
Number of rollouts total     0
Train Time (s)               153.62083309190348
(Previous) Eval Time (s)     25.55139531614259
Sample Time (s)              11.29211312578991
Epoch Time (s)               190.46434153383598
Total Train Time (s)         49754.41102151759
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:45:07.390660 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #269 | Epoch Duration: 190.55634236335754
2020-01-12 15:45:07.390970 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1468484
Z variance train             0.031781018
KL Divergence                18.86513
KL Loss                      1.886513
QF Loss                      1080.7856
VF Loss                      68.67398
Policy Loss                  -1041.2329
Q Predictions Mean           1036.4141
Q Predictions Std            331.0933
Q Predictions Max            1445.2977
Q Predictions Min            330.76468
V Predictions Mean           1042.9723
V Predictions Std            332.07892
V Predictions Max            1450.071
V Predictions Min            343.56332
Log Pis Mean                 -0.42749777
Log Pis Std                  2.7483768
Log Pis Max                  6.7944307
Log Pis Min                  -8.381867
Policy mu Mean               0.03583514
Policy mu Std                0.61694324
Policy mu Max                2.388544
Policy mu Min                -2.3280234
Policy log std Mean          -0.90123206
Policy log std Std           0.22689275
Policy log std Max           -0.38737386
Policy log std Min           -1.7968022
Z mean eval                  1.0116796
Z variance eval              0.01639537
total_rewards                [3373.99882023 2718.56816132 3617.64262555  340.8468533    86.43715692
 1391.27959583  741.01805453 1084.13311362 3564.25255013 3065.06443843]
total_rewards_mean           1998.3241369843902
total_rewards_std            1334.5823683669805
total_rewards_max            3617.642625547367
total_rewards_min            86.43715691705862
Number of train steps total  1084000
Number of env steps total    1421575
Number of rollouts total     0
Train Time (s)               153.04009199002758
(Previous) Eval Time (s)     30.46591162867844
Sample Time (s)              11.022070804145187
Epoch Time (s)               194.5280744228512
Total Train Time (s)         49949.04425954679
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:48:22.027923 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #270 | Epoch Duration: 194.6366732120514
2020-01-12 15:48:22.028306 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0106255
Z variance train             0.016435318
KL Divergence                19.236303
KL Loss                      1.9236304
QF Loss                      554.47156
VF Loss                      115.98984
Policy Loss                  -999.5424
Q Predictions Mean           992.352
Q Predictions Std            368.33365
Q Predictions Max            1442.7705
Q Predictions Min            -23.93295
V Predictions Mean           998.9064
V Predictions Std            365.73337
V Predictions Max            1451.8612
V Predictions Min            252.18881
Log Pis Mean                 -0.6810354
Log Pis Std                  3.1170948
Log Pis Max                  16.632206
Log Pis Min                  -7.335866
Policy mu Mean               0.014954584
Policy mu Std                0.57053536
Policy mu Max                2.7540689
Policy mu Min                -2.3076189
Policy log std Mean          -0.93110275
Policy log std Std           0.26235253
Policy log std Max           -0.3357892
Policy log std Min           -2.6308932
Z mean eval                  1.0584238
Z variance eval              0.018426357
total_rewards                [ 491.71914267 2686.64644094 1943.95180386  770.57236358  325.51923424
 1381.24353325 2282.27237193 3350.62152129  182.07151317 3107.1489999 ]
total_rewards_mean           1652.1766924841309
total_rewards_std            1125.7203088421961
total_rewards_max            3350.621521288651
total_rewards_min            182.0715131689734
Number of train steps total  1088000
Number of env steps total    1432345
Number of rollouts total     0
Train Time (s)               152.19010671880096
(Previous) Eval Time (s)     18.97770568029955
Sample Time (s)              12.749894842971116
Epoch Time (s)               183.91770724207163
Total Train Time (s)         50133.05811947398
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:51:26.045924 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #271 | Epoch Duration: 184.01731038093567
2020-01-12 15:51:26.046213 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0613832
Z variance train             0.018338231
KL Divergence                19.360796
KL Loss                      1.9360796
QF Loss                      1425.6415
VF Loss                      450.1999
Policy Loss                  -1027.0671
Q Predictions Mean           1027.575
Q Predictions Std            356.3596
Q Predictions Max            1472.1235
Q Predictions Min            337.57852
V Predictions Mean           1043.0447
V Predictions Std            356.56058
V Predictions Max            1453.2087
V Predictions Min            365.3715
Log Pis Mean                 -0.64267415
Log Pis Std                  2.9275532
Log Pis Max                  7.637039
Log Pis Min                  -7.435134
Policy mu Mean               0.020044506
Policy mu Std                0.5791636
Policy mu Max                2.5417614
Policy mu Min                -2.5904818
Policy log std Mean          -0.92403746
Policy log std Std           0.25057784
Policy log std Max           -0.3931957
Policy log std Min           -2.2441761
Z mean eval                  1.0451531
Z variance eval              0.013060264
total_rewards                [ 333.69070278  984.61243286 2810.50703501  367.46794972 2519.71561417
 1212.75112263 3429.75160938  806.02098666 2130.73873157 2576.43211577]
total_rewards_mean           1717.1688300551075
total_rewards_std            1050.6547335328444
total_rewards_max            3429.7516093767917
total_rewards_min            333.6907027752551
Number of train steps total  1092000
Number of env steps total    1443509
Number of rollouts total     0
Train Time (s)               145.33939300104976
(Previous) Eval Time (s)     20.111035676207393
Sample Time (s)              12.603166684973985
Epoch Time (s)               178.05359536223114
Total Train Time (s)         50311.202059911564
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:54:24.192453 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #272 | Epoch Duration: 178.14606475830078
2020-01-12 15:54:24.192651 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0446103
Z variance train             0.013087863
KL Divergence                19.859169
KL Loss                      1.985917
QF Loss                      1118.6611
VF Loss                      108.19149
Policy Loss                  -992.4165
Q Predictions Mean           990.8495
Q Predictions Std            354.44843
Q Predictions Max            1446.0804
Q Predictions Min            360.80542
V Predictions Mean           995.314
V Predictions Std            356.18457
V Predictions Max            1447.9287
V Predictions Min            342.79153
Log Pis Mean                 -0.883621
Log Pis Std                  3.0618706
Log Pis Max                  14.566004
Log Pis Min                  -8.672869
Policy mu Mean               0.021366064
Policy mu Std                0.5755198
Policy mu Max                2.3721232
Policy mu Min                -2.905166
Policy log std Mean          -0.8918346
Policy log std Std           0.25246397
Policy log std Max           -0.1990344
Policy log std Min           -2.4314697
Z mean eval                  1.1077497
Z variance eval              0.012880882
total_rewards                [3332.46857936 2074.55684956 3186.60844436  932.88322839 1266.16910016
  219.90125407 2277.4692607  3240.17999747 3118.60030233 2293.25160029]
total_rewards_mean           2194.2088616689366
total_rewards_std            1030.058071799473
total_rewards_max            3332.468579364706
total_rewards_min            219.90125407070124
Number of train steps total  1096000
Number of env steps total    1453486
Number of rollouts total     0
Train Time (s)               144.59314617794007
(Previous) Eval Time (s)     29.797801771201193
Sample Time (s)              11.201032461132854
Epoch Time (s)               185.59198041027412
Total Train Time (s)         50496.89021658525
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:57:29.888701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #273 | Epoch Duration: 185.69587445259094
2020-01-12 15:57:29.888915 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1011894
Z variance train             0.0128349485
KL Divergence                19.978088
KL Loss                      1.9978088
QF Loss                      3568.3667
VF Loss                      121.94455
Policy Loss                  -984.2663
Q Predictions Mean           979.51794
Q Predictions Std            363.9148
Q Predictions Max            1443.4413
Q Predictions Min            355.02866
V Predictions Mean           980.95276
V Predictions Std            361.8517
V Predictions Max            1433.8013
V Predictions Min            361.9398
Log Pis Mean                 -0.8025934
Log Pis Std                  3.0005026
Log Pis Max                  11.636439
Log Pis Min                  -7.2640824
Policy mu Mean               0.029594235
Policy mu Std                0.56471676
Policy mu Max                2.5918162
Policy mu Min                -2.2975569
Policy log std Mean          -0.8942994
Policy log std Std           0.26445568
Policy log std Max           -0.26671487
Policy log std Min           -2.4781923
Z mean eval                  1.0012791
Z variance eval              0.0147269815
total_rewards                [2171.95163063  401.48688496   78.12936912  782.75061645  667.05037588
 1637.81185644 1548.51294152 1358.21675646  738.80141723 1305.70822655]
total_rewards_mean           1069.042007525021
total_rewards_std            607.4200085257569
total_rewards_max            2171.951630631829
total_rewards_min            78.12936912141123
Number of train steps total  1100000
Number of env steps total    1461969
Number of rollouts total     0
Train Time (s)               147.8650624230504
(Previous) Eval Time (s)     13.655104632955045
Sample Time (s)              11.018544679041952
Epoch Time (s)               172.5387117350474
Total Train Time (s)         50669.5238888422
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:00:22.525773 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #274 | Epoch Duration: 172.6367084980011
2020-01-12 16:00:22.525977 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #274 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9985962
Z variance train             0.014759843
KL Divergence                19.940203
KL Loss                      1.9940203
QF Loss                      565.3544
VF Loss                      233.31732
Policy Loss                  -1025.2605
Q Predictions Mean           1022.16113
Q Predictions Std            351.10333
Q Predictions Max            1451.6609
Q Predictions Min            371.36996
V Predictions Mean           1026.9471
V Predictions Std            350.01245
V Predictions Max            1457.3298
V Predictions Min            367.55353
Log Pis Mean                 -0.6703682
Log Pis Std                  3.0690045
Log Pis Max                  17.938854
Log Pis Min                  -8.203094
Policy mu Mean               0.027387131
Policy mu Std                0.57180315
Policy mu Max                3.2506423
Policy mu Min                -2.4061816
Policy log std Mean          -0.92464316
Policy log std Std           0.24761903
Policy log std Max           -0.33642995
Policy log std Min           -2.367736
Z mean eval                  1.1514769
Z variance eval              0.014691274
total_rewards                [1.09035163e+03 3.55216282e+03 3.14107509e+03 1.59534197e+03
 1.67718736e+03 3.22449561e+03 5.75544280e+02 2.06789675e+00
 1.26159945e+03 7.34407648e+02]
total_rewards_mean           1685.423374041648
total_rewards_std            1161.2169977182575
total_rewards_max            3552.162815021042
total_rewards_min            2.0678967545106484
Number of train steps total  1104000
Number of env steps total    1469715
Number of rollouts total     0
Train Time (s)               154.68322593998164
(Previous) Eval Time (s)     19.04784030513838
Sample Time (s)              12.033588559366763
Epoch Time (s)               185.76465480448678
Total Train Time (s)         50855.39024710888
Epoch                        275
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:03:28.395770 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #275 | Epoch Duration: 185.86961770057678
2020-01-12 16:03:28.396081 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #275 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1555916
Z variance train             0.014775207
KL Divergence                20.716417
KL Loss                      2.0716417
QF Loss                      757.6687
VF Loss                      50.920593
Policy Loss                  -1025.7573
Q Predictions Mean           1017.894
Q Predictions Std            362.7739
Q Predictions Max            1488.1825
Q Predictions Min            313.85568
V Predictions Mean           1023.0807
V Predictions Std            360.50537
V Predictions Max            1482.0504
V Predictions Min            316.6996
Log Pis Mean                 -0.67212033
Log Pis Std                  2.6641357
Log Pis Max                  8.078575
Log Pis Min                  -7.1982327
Policy mu Mean               0.029060323
Policy mu Std                0.6016163
Policy mu Max                1.97909
Policy mu Min                -2.3581736
Policy log std Mean          -0.8688997
Policy log std Std           0.23152047
Policy log std Max           -0.26790178
Policy log std Min           -1.7254356
Z mean eval                  1.2063159
Z variance eval              0.039177634
total_rewards                [3195.31331631  242.20341441 1332.47796345 1059.56527625 1167.7081765
 2251.85211129 3374.51660475 3358.66423978 3282.72632805  471.35096118]
total_rewards_mean           1973.6378391953112
total_rewards_std            1196.4628936710908
total_rewards_max            3374.516604748384
total_rewards_min            242.20341440772873
Number of train steps total  1108000
Number of env steps total    1477833
Number of rollouts total     0
Train Time (s)               153.2827833951451
(Previous) Eval Time (s)     22.08194280602038
Sample Time (s)              11.229811494704336
Epoch Time (s)               186.5945376958698
Total Train Time (s)         51042.078839947004
Epoch                        276
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:06:35.087049 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #276 | Epoch Duration: 186.69074988365173
2020-01-12 16:06:35.087254 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.208052
Z variance train             0.03886432
KL Divergence                19.340527
KL Loss                      1.9340527
QF Loss                      2748.0845
VF Loss                      769.9839
Policy Loss                  -1040.7316
Q Predictions Mean           1038.2495
Q Predictions Std            349.35928
Q Predictions Max            1469.1929
Q Predictions Min            359.3812
V Predictions Mean           1040.9646
V Predictions Std            349.9657
V Predictions Max            1462.4777
V Predictions Min            360.9885
Log Pis Mean                 -0.6326813
Log Pis Std                  3.0608258
Log Pis Max                  10.620162
Log Pis Min                  -7.670501
Policy mu Mean               0.025964197
Policy mu Std                0.60229474
Policy mu Max                2.6913142
Policy mu Min                -2.2682934
Policy log std Mean          -0.9016442
Policy log std Std           0.25680152
Policy log std Max           -0.18376493
Policy log std Min           -2.5469842
Z mean eval                  1.0517671
Z variance eval              0.029080445
total_rewards                [ 321.08130384  805.34380836 3032.41369986 3245.03103037 3515.46715957
  533.0759834  3451.45287504 3297.36904887 3368.64871894 2540.50751855]
total_rewards_mean           2411.0391146790835
total_rewards_std            1248.0447329305418
total_rewards_max            3515.4671595721534
total_rewards_min            321.08130383726876
Number of train steps total  1112000
Number of env steps total    1488458
Number of rollouts total     0
Train Time (s)               153.28785199578851
(Previous) Eval Time (s)     27.542608429212123
Sample Time (s)              12.249857081100345
Epoch Time (s)               193.08031750610098
Total Train Time (s)         51235.24409264419
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:09:48.256878 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #277 | Epoch Duration: 193.1694371700287
2020-01-12 16:09:48.257295 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0575631
Z variance train             0.028758978
KL Divergence                19.051758
KL Loss                      1.9051758
QF Loss                      510.39368
VF Loss                      155.51042
Policy Loss                  -1001.6245
Q Predictions Mean           995.66943
Q Predictions Std            350.21997
Q Predictions Max            1409.758
Q Predictions Min            353.4728
V Predictions Mean           999.03357
V Predictions Std            350.98474
V Predictions Max            1411.7765
V Predictions Min            345.4565
Log Pis Mean                 -0.7898246
Log Pis Std                  3.0491688
Log Pis Max                  9.779414
Log Pis Min                  -7.481603
Policy mu Mean               0.054716397
Policy mu Std                0.5899908
Policy mu Max                2.1289804
Policy mu Min                -2.5642893
Policy log std Mean          -0.8947085
Policy log std Std           0.262842
Policy log std Max           -0.23249584
Policy log std Min           -1.8802836
Z mean eval                  1.0482135
Z variance eval              0.053685825
total_rewards                [2955.47651685  668.53338682  346.42819407 3426.43774235 3472.41777841
 2278.39041248 3249.85939333  580.03244295 2313.56211009 3514.353156  ]
total_rewards_mean           2280.549113336391
total_rewards_std            1219.968991268566
total_rewards_max            3514.353155998281
total_rewards_min            346.42819407371206
Number of train steps total  1116000
Number of env steps total    1496842
Number of rollouts total     0
Train Time (s)               152.92794058285654
(Previous) Eval Time (s)     26.11409752489999
Sample Time (s)              12.46279912116006
Epoch Time (s)               191.50483722891659
Total Train Time (s)         51426.873007722665
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:12:59.889469 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #278 | Epoch Duration: 191.63187551498413
2020-01-12 16:12:59.889882 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0487688
Z variance train             0.053791177
KL Divergence                17.450893
KL Loss                      1.7450894
QF Loss                      1111.6638
VF Loss                      465.78568
Policy Loss                  -1011.0688
Q Predictions Mean           1004.51685
Q Predictions Std            342.04507
Q Predictions Max            1451.8584
Q Predictions Min            339.25372
V Predictions Mean           1014.4019
V Predictions Std            344.7716
V Predictions Max            1461.839
V Predictions Min            335.40094
Log Pis Mean                 -0.605629
Log Pis Std                  3.2276154
Log Pis Max                  21.448341
Log Pis Min                  -6.990406
Policy mu Mean               -3.5681296e-06
Policy mu Std                0.59473604
Policy mu Max                3.0003648
Policy mu Min                -2.882147
Policy log std Mean          -0.90931445
Policy log std Std           0.27602145
Policy log std Max           -0.21044338
Policy log std Min           -2.4675593
Z mean eval                  1.2472485
Z variance eval              0.00706964
total_rewards                [1295.83890493 1363.28503634 1708.10254014  463.02053945  903.64609935
  110.02434047 2795.4652856  1516.05364893 2258.49218322  981.04635468]
total_rewards_mean           1339.4974933115636
total_rewards_std            757.1114098377783
total_rewards_max            2795.465285604568
total_rewards_min            110.02434047490736
Number of train steps total  1120000
Number of env steps total    1506323
Number of rollouts total     0
Train Time (s)               143.51549919741228
(Previous) Eval Time (s)     16.8821171480231
Sample Time (s)              11.232196114957333
Epoch Time (s)               171.6298124603927
Total Train Time (s)         51598.59536730265
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:15:51.613907 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #279 | Epoch Duration: 171.723778963089
2020-01-12 16:15:51.614102 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2392948
Z variance train             0.0070998883
KL Divergence                22.466324
KL Loss                      2.2466323
QF Loss                      641.96765
VF Loss                      430.49475
Policy Loss                  -1008.8087
Q Predictions Mean           1002.7646
Q Predictions Std            366.6497
Q Predictions Max            1477.5088
Q Predictions Min            41.950924
V Predictions Mean           1003.77045
V Predictions Std            362.3287
V Predictions Max            1458.4777
V Predictions Min            353.73526
Log Pis Mean                 -0.43618506
Log Pis Std                  3.306006
Log Pis Max                  17.143986
Log Pis Min                  -8.8417015
Policy mu Mean               0.03143868
Policy mu Std                0.6012944
Policy mu Max                2.4234798
Policy mu Min                -2.2687194
Policy log std Mean          -0.92151177
Policy log std Std           0.2818043
Policy log std Max           -0.25353968
Policy log std Min           -2.2860434
Z mean eval                  1.1968086
Z variance eval              0.015570328
total_rewards                [ 199.35450151 1866.02665186 1228.79407416  276.77323539  516.95919218
  383.90261797 3329.45638925 1949.40052074  564.36788603 1249.43340273]
total_rewards_mean           1156.4468471823425
total_rewards_std            944.1561355500937
total_rewards_max            3329.456389252898
total_rewards_min            199.35450150667694
Number of train steps total  1124000
Number of env steps total    1514412
Number of rollouts total     0
Train Time (s)               144.62338744290173
(Previous) Eval Time (s)     12.123481415212154
Sample Time (s)              11.853202279657125
Epoch Time (s)               168.600071137771
Total Train Time (s)         51767.2831341452
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:18:40.304698 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #280 | Epoch Duration: 168.6904537677765
2020-01-12 16:18:40.304876 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1956165
Z variance train             0.015589306
KL Divergence                19.799295
KL Loss                      1.9799296
QF Loss                      5006.507
VF Loss                      168.27454
Policy Loss                  -986.3475
Q Predictions Mean           978.62573
Q Predictions Std            354.90616
Q Predictions Max            1438.9269
Q Predictions Min            193.06357
V Predictions Mean           985.60046
V Predictions Std            354.9512
V Predictions Max            1436.9937
V Predictions Min            306.51703
Log Pis Mean                 -0.2366607
Log Pis Std                  3.4028141
Log Pis Max                  17.091291
Log Pis Min                  -7.9312572
Policy mu Mean               0.07071763
Policy mu Std                0.6249454
Policy mu Max                3.1323385
Policy mu Min                -3.1314564
Policy log std Mean          -0.9154391
Policy log std Std           0.26244587
Policy log std Max           0.077907324
Policy log std Min           -2.065556
Z mean eval                  0.9863914
Z variance eval              0.013257007
total_rewards                [2725.49963604 2193.34802544 1029.36829474  949.10087733 3390.10436463
 2178.10133129 3506.28380706 3398.21154912   75.61814397 1186.62476995]
total_rewards_mean           2063.2260799562714
total_rewards_std            1145.5607424851323
total_rewards_max            3506.2838070554812
total_rewards_min            75.61814396509644
Number of train steps total  1128000
Number of env steps total    1521637
Number of rollouts total     0
Train Time (s)               148.5237696361728
(Previous) Eval Time (s)     23.788712741341442
Sample Time (s)              11.04682796029374
Epoch Time (s)               183.35931033780798
Total Train Time (s)         51950.72860483406
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:21:43.753548 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #281 | Epoch Duration: 183.44853687286377
2020-01-12 16:21:43.753726 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #281 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9878584
Z variance train             0.013132067
KL Divergence                19.411938
KL Loss                      1.9411938
QF Loss                      478.8957
VF Loss                      110.63722
Policy Loss                  -1035.0181
Q Predictions Mean           1029.6276
Q Predictions Std            339.33942
Q Predictions Max            1442.8107
Q Predictions Min            328.31912
V Predictions Mean           1032.6434
V Predictions Std            337.51758
V Predictions Max            1441.6259
V Predictions Min            361.53912
Log Pis Mean                 -0.37798327
Log Pis Std                  3.2662327
Log Pis Max                  17.938522
Log Pis Min                  -7.892683
Policy mu Mean               0.04984292
Policy mu Std                0.6021003
Policy mu Max                2.468258
Policy mu Min                -2.3542068
Policy log std Mean          -0.91779155
Policy log std Std           0.258242
Policy log std Max           -0.21156979
Policy log std Min           -2.3138256
Z mean eval                  1.0703534
Z variance eval              0.019349694
total_rewards                [3300.44178295 3531.21520722 1481.75223855 3348.28145004 2236.8023972
 2507.75614396 1054.20706417 3345.22024048 3374.04105834 1089.4594877 ]
total_rewards_mean           2526.9177070618425
total_rewards_std            952.9373566374587
total_rewards_max            3531.2152072227673
total_rewards_min            1054.207064171934
Number of train steps total  1132000
Number of env steps total    1532894
Number of rollouts total     0
Train Time (s)               154.512791542802
(Previous) Eval Time (s)     27.477044499013573
Sample Time (s)              11.760528015438467
Epoch Time (s)               193.75036405725405
Total Train Time (s)         52144.56450788025
Epoch                        282
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:24:57.592665 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #282 | Epoch Duration: 193.8387966156006
2020-01-12 16:24:57.592864 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0682323
Z variance train             0.019391362
KL Divergence                19.793037
KL Loss                      1.9793037
QF Loss                      385.57397
VF Loss                      51.433994
Policy Loss                  -1014.99725
Q Predictions Mean           1007.78674
Q Predictions Std            367.50595
Q Predictions Max            1560.2037
Q Predictions Min            6.7146635
V Predictions Mean           1015.6374
V Predictions Std            364.3914
V Predictions Max            1561.0659
V Predictions Min            380.00232
Log Pis Mean                 -0.69887555
Log Pis Std                  3.0080857
Log Pis Max                  9.731867
Log Pis Min                  -7.0573387
Policy mu Mean               3.196078e-05
Policy mu Std                0.5956769
Policy mu Max                2.1830103
Policy mu Min                -2.404478
Policy log std Mean          -0.86769617
Policy log std Std           0.25445563
Policy log std Max           -0.24699235
Policy log std Min           -2.220717
Z mean eval                  1.2414083
Z variance eval              0.015505212
total_rewards                [ 127.82002115 1638.42991963 2587.29070107  249.80917309  519.83735202
  751.25205857 3490.30073212 2345.08703081    6.14991287  506.20856331]
total_rewards_mean           1222.2185464642903
total_rewards_std            1152.892642127832
total_rewards_max            3490.300732122636
total_rewards_min            6.149912870755275
Number of train steps total  1136000
Number of env steps total    1542282
Number of rollouts total     0
Train Time (s)               153.7837832630612
(Previous) Eval Time (s)     13.300561941228807
Sample Time (s)              12.41809633281082
Epoch Time (s)               179.50244153710082
Total Train Time (s)         52324.16250946466
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:27:57.194204 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #283 | Epoch Duration: 179.60119771957397
2020-01-12 16:27:57.194400 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.242583
Z variance train             0.01553455
KL Divergence                20.121439
KL Loss                      2.0121439
QF Loss                      339.7262
VF Loss                      80.2236
Policy Loss                  -1033.6168
Q Predictions Mean           1028.1588
Q Predictions Std            342.11
Q Predictions Max            1464.25
Q Predictions Min            356.98523
V Predictions Mean           1032.7527
V Predictions Std            342.30447
V Predictions Max            1463.8743
V Predictions Min            357.44595
Log Pis Mean                 -0.34726864
Log Pis Std                  3.1845765
Log Pis Max                  8.661622
Log Pis Min                  -9.10254
Policy mu Mean               -0.0053372774
Policy mu Std                0.629223
Policy mu Max                2.7451267
Policy mu Min                -2.2983725
Policy log std Mean          -0.89693594
Policy log std Std           0.2571477
Policy log std Max           -0.29638863
Policy log std Min           -2.0482998
Z mean eval                  1.2017756
Z variance eval              0.01014478
total_rewards                [ 305.07576428 3401.65775991  183.88656639  527.85205179 2503.29445221
  757.44023403  294.5124719   777.06645752  803.35832506 3498.22766288]
total_rewards_mean           1305.2371745964294
total_rewards_std            1239.1165422904087
total_rewards_max            3498.227662877134
total_rewards_min            183.88656638715685
Number of train steps total  1140000
Number of env steps total    1552426
Number of rollouts total     0
Train Time (s)               154.733177495189
(Previous) Eval Time (s)     17.549797659739852
Sample Time (s)              11.579345420468599
Epoch Time (s)               183.86232057539746
Total Train Time (s)         52508.11480732169
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:31:01.149693 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #284 | Epoch Duration: 183.95515275001526
2020-01-12 16:31:01.149880 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2141057
Z variance train             0.010089986
KL Divergence                20.541245
KL Loss                      2.0541246
QF Loss                      543.9736
VF Loss                      81.20375
Policy Loss                  -1008.5488
Q Predictions Mean           1002.13525
Q Predictions Std            364.7858
Q Predictions Max            1457.1427
Q Predictions Min            378.63214
V Predictions Mean           1005.03326
V Predictions Std            364.65338
V Predictions Max            1458.5845
V Predictions Min            372.5642
Log Pis Mean                 -1.0846913
Log Pis Std                  2.909019
Log Pis Max                  8.283813
Log Pis Min                  -9.418367
Policy mu Mean               -0.021987181
Policy mu Std                0.5422641
Policy mu Max                2.9168391
Policy mu Min                -2.3948922
Policy log std Mean          -0.87848586
Policy log std Std           0.23856765
Policy log std Max           -0.2698179
Policy log std Min           -1.7879313
Z mean eval                  0.9879514
Z variance eval              0.011634862
total_rewards                [3420.88886343 3431.94154415 1642.57953704 3285.28142601 2153.75316432
 1667.76347853 1701.81341769 2460.69457429 1145.73558927 3516.54706427]
total_rewards_mean           2442.6998659001742
total_rewards_std            857.5608619071417
total_rewards_max            3516.5470642681703
total_rewards_min            1145.735589270728
Number of train steps total  1144000
Number of env steps total    1563279
Number of rollouts total     0
Train Time (s)               153.13309106836095
(Previous) Eval Time (s)     30.192771608941257
Sample Time (s)              11.358320924453437
Epoch Time (s)               194.68418360175565
Total Train Time (s)         52702.88553857058
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:34:15.923422 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #285 | Epoch Duration: 194.77340412139893
2020-01-12 16:34:15.923610 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9879626
Z variance train             0.011679786
KL Divergence                20.411978
KL Loss                      2.0411978
QF Loss                      402.15405
VF Loss                      155.79514
Policy Loss                  -1065.1167
Q Predictions Mean           1059.22
Q Predictions Std            339.25388
Q Predictions Max            1480.245
Q Predictions Min            344.62408
V Predictions Mean           1064.6002
V Predictions Std            338.54514
V Predictions Max            1481.3494
V Predictions Min            375.05133
Log Pis Mean                 -0.71690315
Log Pis Std                  2.777496
Log Pis Max                  7.871819
Log Pis Min                  -8.132344
Policy mu Mean               -0.010959061
Policy mu Std                0.5792774
Policy mu Max                1.9764206
Policy mu Min                -2.584974
Policy log std Mean          -0.9087044
Policy log std Std           0.25102392
Policy log std Max           -0.26975197
Policy log std Min           -1.7751138
Z mean eval                  1.0913305
Z variance eval              0.008685613
total_rewards                [1768.13576733 3419.01627595 2388.83758195 3491.69911034   79.37794608
  585.31125297 1284.22560537  422.83250955  444.97593335  395.10243611]
total_rewards_mean           1427.9514418996107
total_rewards_std            1218.813079469434
total_rewards_max            3491.6991103416403
total_rewards_min            79.37794608337502
Number of train steps total  1148000
Number of env steps total    1573565
Number of rollouts total     0
Train Time (s)               144.11210432834923
(Previous) Eval Time (s)     17.95622381195426
Sample Time (s)              10.301475157029927
Epoch Time (s)               172.36980329733342
Total Train Time (s)         52875.46540881181
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:37:08.506830 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #286 | Epoch Duration: 172.58307647705078
2020-01-12 16:37:08.507030 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0909789
Z variance train             0.008695437
KL Divergence                20.532303
KL Loss                      2.0532303
QF Loss                      688.98364
VF Loss                      73.21281
Policy Loss                  -1068.6786
Q Predictions Mean           1064.7456
Q Predictions Std            346.0473
Q Predictions Max            1482.5245
Q Predictions Min            382.3567
V Predictions Mean           1070.2297
V Predictions Std            345.2509
V Predictions Max            1480.0763
V Predictions Min            382.37668
Log Pis Mean                 -0.8374493
Log Pis Std                  2.8663342
Log Pis Max                  8.106817
Log Pis Min                  -9.594872
Policy mu Mean               -0.015760427
Policy mu Std                0.58657503
Policy mu Max                2.0682364
Policy mu Min                -2.3600428
Policy log std Mean          -0.8937369
Policy log std Std           0.2496182
Policy log std Max           -0.27548337
Policy log std Min           -1.8034575
Z mean eval                  1.181637
Z variance eval              0.3218279
total_rewards                [1539.83473694  212.1117229  1375.93426131 3653.3070091  1700.97333317
 3296.45382623  612.58861298 3646.35978327 3318.71469033 3740.41622737]
total_rewards_mean           2309.6694203602697
total_rewards_std            1294.059682433887
total_rewards_max            3740.4162273668244
total_rewards_min            212.11172290273802
Number of train steps total  1152000
Number of env steps total    1582056
Number of rollouts total     0
Train Time (s)               144.16482623200864
(Previous) Eval Time (s)     28.381731364876032
Sample Time (s)              12.135706119704992
Epoch Time (s)               184.68226371658966
Total Train Time (s)         53060.238546963315
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:40:13.283320 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #287 | Epoch Duration: 184.7761414051056
2020-01-12 16:40:13.283514 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1861635
Z variance train             0.32170746
KL Divergence                21.014713
KL Loss                      2.1014714
QF Loss                      1026.3827
VF Loss                      172.61841
Policy Loss                  -1076.068
Q Predictions Mean           1071.4299
Q Predictions Std            341.64392
Q Predictions Max            1513.8934
Q Predictions Min            70.13629
V Predictions Mean           1073.0968
V Predictions Std            336.71503
V Predictions Max            1517.0886
V Predictions Min            354.8726
Log Pis Mean                 -0.34192234
Log Pis Std                  3.3254557
Log Pis Max                  24.407225
Log Pis Min                  -8.098004
Policy mu Mean               -0.012810836
Policy mu Std                0.61307985
Policy mu Max                3.6342633
Policy mu Min                -3.0375118
Policy log std Mean          -0.9302951
Policy log std Std           0.27317122
Policy log std Max           -0.31200075
Policy log std Min           -2.4629571
Z mean eval                  1.0246129
Z variance eval              0.012939328
total_rewards                [1546.27827891 3506.80929604  464.90636033 3519.93178482 1257.73829791
  416.52596805 3490.16641229 3401.4542421   633.85504176 2362.15961425]
total_rewards_mean           2059.9825296451254
total_rewards_std            1278.5768547733583
total_rewards_max            3519.931784823278
total_rewards_min            416.5259680476851
Number of train steps total  1156000
Number of env steps total    1593313
Number of rollouts total     0
Train Time (s)               150.93568548373878
(Previous) Eval Time (s)     30.245241893921047
Sample Time (s)              11.233423022553325
Epoch Time (s)               192.41435040021315
Total Train Time (s)         53252.769883545116
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:43:25.818316 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #288 | Epoch Duration: 192.53464603424072
2020-01-12 16:43:25.818536 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0248567
Z variance train             0.012925136
KL Divergence                21.35316
KL Loss                      2.1353161
QF Loss                      449.05255
VF Loss                      124.34816
Policy Loss                  -1068.3933
Q Predictions Mean           1062.9099
Q Predictions Std            341.24524
Q Predictions Max            1482.3209
Q Predictions Min            3.1141634
V Predictions Mean           1069.719
V Predictions Std            336.5742
V Predictions Max            1474.8696
V Predictions Min            314.41382
Log Pis Mean                 -0.23002928
Log Pis Std                  3.5332415
Log Pis Max                  21.952246
Log Pis Min                  -7.4838343
Policy mu Mean               0.037101123
Policy mu Std                0.61559594
Policy mu Max                3.3839989
Policy mu Min                -2.4768515
Policy log std Mean          -0.9221495
Policy log std Std           0.2720184
Policy log std Max           -0.30176425
Policy log std Min           -2.0420065
Z mean eval                  1.0557001
Z variance eval              0.036796957
total_rewards                [1155.73083869  384.12116107 2641.01112135   92.42251707  400.26711143
  638.97458541  821.82579304  192.93952275 3554.19329701  549.92478051]
total_rewards_mean           1043.1410728328442
total_rewards_std            1086.3307210924102
total_rewards_max            3554.1932970100447
total_rewards_min            92.42251707136074
Number of train steps total  1160000
Number of env steps total    1602736
Number of rollouts total     0
Train Time (s)               153.63832810288295
(Previous) Eval Time (s)     12.353299980051816
Sample Time (s)              10.812232812400907
Epoch Time (s)               176.80386089533567
Total Train Time (s)         53429.66149332002
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:46:22.713207 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #289 | Epoch Duration: 176.89451575279236
2020-01-12 16:46:22.713429 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0595629
Z variance train             0.036503293
KL Divergence                17.716282
KL Loss                      1.7716283
QF Loss                      10574.465
VF Loss                      94.81291
Policy Loss                  -1048.7567
Q Predictions Mean           1049.204
Q Predictions Std            354.61038
Q Predictions Max            1493.164
Q Predictions Min            389.8669
V Predictions Mean           1054.6858
V Predictions Std            355.8015
V Predictions Max            1509.1356
V Predictions Min            394.27737
Log Pis Mean                 -0.804615
Log Pis Std                  2.8388414
Log Pis Max                  12.847662
Log Pis Min                  -7.7065554
Policy mu Mean               0.02597788
Policy mu Std                0.5817005
Policy mu Max                2.4925823
Policy mu Min                -2.4998207
Policy log std Mean          -0.8851532
Policy log std Std           0.2537233
Policy log std Max           -0.26401687
Policy log std Min           -2.028601
Z mean eval                  1.0293825
Z variance eval              0.023744116
total_rewards                [ 290.14160801 3415.61610463 1508.70474806 3352.95178105 3282.17816162
 2098.21999554 3383.11070673 3344.39542804 3495.90120926  176.4723648 ]
total_rewards_mean           2434.769210774058
total_rewards_std            1266.7354625285705
total_rewards_max            3495.9012092605794
total_rewards_min            176.4723648007816
Number of train steps total  1164000
Number of env steps total    1612472
Number of rollouts total     0
Train Time (s)               153.06344231031835
(Previous) Eval Time (s)     27.611191108822823
Sample Time (s)              11.791093500796705
Epoch Time (s)               192.46572691993788
Total Train Time (s)         53622.23486772273
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:49:35.290192 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #290 | Epoch Duration: 192.57660150527954
2020-01-12 16:49:35.290402 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0314993
Z variance train             0.023863068
KL Divergence                20.372028
KL Loss                      2.0372028
QF Loss                      391.42108
VF Loss                      73.63926
Policy Loss                  -1044.7633
Q Predictions Mean           1037.7148
Q Predictions Std            349.4199
Q Predictions Max            1468.0498
Q Predictions Min            374.58426
V Predictions Mean           1045.9528
V Predictions Std            348.09985
V Predictions Max            1471.6553
V Predictions Min            385.49548
Log Pis Mean                 -0.65122837
Log Pis Std                  2.8846357
Log Pis Max                  9.429583
Log Pis Min                  -8.320538
Policy mu Mean               -0.0027913535
Policy mu Std                0.58322465
Policy mu Max                2.5578847
Policy mu Min                -2.2595134
Policy log std Mean          -0.9049972
Policy log std Std           0.2528664
Policy log std Max           -0.28798717
Policy log std Min           -1.9909258
Z mean eval                  1.0026635
Z variance eval              0.010373758
total_rewards                [ 772.40686341 2070.94024002  684.93545934 3111.0637833  1950.81806315
  497.92925802 2820.46202914 1312.65128212  349.21046051 1679.90937828]
total_rewards_mean           1525.0326817294358
total_rewards_std            919.3335116769467
total_rewards_max            3111.0637833035034
total_rewards_min            349.21046051163114
Number of train steps total  1168000
Number of env steps total    1622045
Number of rollouts total     0
Train Time (s)               154.80846773600206
(Previous) Eval Time (s)     22.25150630204007
Sample Time (s)              11.458436476998031
Epoch Time (s)               188.51841051504016
Total Train Time (s)         53810.90585615346
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:52:43.964654 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #291 | Epoch Duration: 188.67409229278564
2020-01-12 16:52:43.964902 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0046104
Z variance train             0.010344591
KL Divergence                20.620161
KL Loss                      2.0620162
QF Loss                      1006.4354
VF Loss                      338.75427
Policy Loss                  -954.11804
Q Predictions Mean           947.0766
Q Predictions Std            331.1191
Q Predictions Max            1414.6014
Q Predictions Min            373.55347
V Predictions Mean           954.6444
V Predictions Std            329.26425
V Predictions Max            1419.4595
V Predictions Min            369.1601
Log Pis Mean                 -0.85198635
Log Pis Std                  3.2952905
Log Pis Max                  9.892502
Log Pis Min                  -10.140732
Policy mu Mean               -0.010250335
Policy mu Std                0.5969641
Policy mu Max                2.7133107
Policy mu Min                -2.2912414
Policy log std Mean          -0.8830773
Policy log std Std           0.2556104
Policy log std Max           -0.3277998
Policy log std Min           -2.2201865
Z mean eval                  1.0618814
Z variance eval              0.041118372
total_rewards                [1227.8239269    91.10040399  500.68035272 1519.19020968  834.27628723
 3403.12162106  677.22711654 2321.35324635 1402.97447809 3517.1333302 ]
total_rewards_mean           1549.4880972768071
total_rewards_std            1119.30658683487
total_rewards_max            3517.133330203623
total_rewards_min            91.10040399003351
Number of train steps total  1172000
Number of env steps total    1631880
Number of rollouts total     0
Train Time (s)               152.96908886777237
(Previous) Eval Time (s)     24.33213480282575
Sample Time (s)              12.09094048384577
Epoch Time (s)               189.3921641544439
Total Train Time (s)         54000.390143861994
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:55:53.451977 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #292 | Epoch Duration: 189.48691725730896
2020-01-12 16:55:53.452193 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0633341
Z variance train             0.041653555
KL Divergence                17.466846
KL Loss                      1.7466847
QF Loss                      615.0245
VF Loss                      329.53223
Policy Loss                  -1046.6299
Q Predictions Mean           1041.1931
Q Predictions Std            349.98685
Q Predictions Max            1554.2771
Q Predictions Min            89.78325
V Predictions Mean           1048.1926
V Predictions Std            344.9469
V Predictions Max            1545.1697
V Predictions Min            359.9436
Log Pis Mean                 -0.65288675
Log Pis Std                  3.1861422
Log Pis Max                  18.361137
Log Pis Min                  -9.78856
Policy mu Mean               0.0026511166
Policy mu Std                0.5976162
Policy mu Max                2.0948358
Policy mu Min                -2.5354407
Policy log std Mean          -0.8832685
Policy log std Std           0.27751282
Policy log std Max           -0.17788899
Policy log std Min           -2.8833773
Z mean eval                  1.1691682
Z variance eval              0.051209737
total_rewards                [3491.32915915  401.63240804 3665.84811267  338.40699154  542.30527115
 2231.9872263  2747.00575023  174.1626828  1175.64026578 2513.57485628]
total_rewards_mean           1728.189272393522
total_rewards_std            1288.0097733953992
total_rewards_max            3665.8481126698366
total_rewards_min            174.16268280037798
Number of train steps total  1176000
Number of env steps total    1641326
Number of rollouts total     0
Train Time (s)               144.50332704000175
(Previous) Eval Time (s)     19.811038156971335
Sample Time (s)              11.855773708317429
Epoch Time (s)               176.17013890529051
Total Train Time (s)         54176.64931959892
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:58:49.714931 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #293 | Epoch Duration: 176.2625651359558
2020-01-12 16:58:49.715165 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1699942
Z variance train             0.05160203
KL Divergence                19.229168
KL Loss                      1.9229168
QF Loss                      447.56357
VF Loss                      75.80665
Policy Loss                  -1068.1494
Q Predictions Mean           1061.1978
Q Predictions Std            348.619
Q Predictions Max            1489.3704
Q Predictions Min            129.51727
V Predictions Mean           1068.2781
V Predictions Std            345.7005
V Predictions Max            1480.3536
V Predictions Min            378.03564
Log Pis Mean                 -0.72859395
Log Pis Std                  3.21014
Log Pis Max                  15.623208
Log Pis Min                  -9.045637
Policy mu Mean               0.021926854
Policy mu Std                0.6136352
Policy mu Max                2.4157846
Policy mu Min                -3.0844562
Policy log std Mean          -0.8943398
Policy log std Std           0.2802802
Policy log std Max           -0.2766577
Policy log std Min           -2.6844263
Z mean eval                  1.0966202
Z variance eval              0.027036825
total_rewards                [ 489.58589978 3406.7972025   881.62283572 1235.91740063 3386.79287964
 1654.52091635  122.95009682 1170.9659825   255.78926905 3350.35177413]
total_rewards_mean           1595.5294257123285
total_rewards_std            1248.1161558936299
total_rewards_max            3406.797202497431
total_rewards_min            122.95009681893146
Number of train steps total  1180000
Number of env steps total    1651943
Number of rollouts total     0
Train Time (s)               144.17557275202125
(Previous) Eval Time (s)     19.68120743520558
Sample Time (s)              11.514757025055587
Epoch Time (s)               175.37153721228242
Total Train Time (s)         54352.11081402097
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:01:45.179729 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #294 | Epoch Duration: 175.46436309814453
2020-01-12 17:01:45.179943 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0926416
Z variance train             0.027273908
KL Divergence                20.11799
KL Loss                      2.011799
QF Loss                      376.77625
VF Loss                      66.4114
Policy Loss                  -1078.5547
Q Predictions Mean           1076.3024
Q Predictions Std            337.5795
Q Predictions Max            1505.9741
Q Predictions Min            34.670414
V Predictions Mean           1080.9977
V Predictions Std            337.4357
V Predictions Max            1491.4294
V Predictions Min            37.96412
Log Pis Mean                 -0.52279234
Log Pis Std                  3.0418587
Log Pis Max                  8.87076
Log Pis Min                  -10.655525
Policy mu Mean               0.022177741
Policy mu Std                0.6006573
Policy mu Max                2.1539285
Policy mu Min                -2.6057353
Policy log std Mean          -0.90165234
Policy log std Std           0.27409416
Policy log std Max           -0.16706568
Policy log std Min           -2.2939086
Z mean eval                  1.1682255
Z variance eval              0.0146229835
total_rewards                [ 106.68451094  744.45434521 1035.22200532   61.90249386  155.54081357
  336.62099971 2680.28269493  450.68062602  880.57328318 1189.64775284]
total_rewards_mean           764.160952559794
total_rewards_std            742.7581597197122
total_rewards_max            2680.2826949319133
total_rewards_min            61.902493864991115
Number of train steps total  1184000
Number of env steps total    1661439
Number of rollouts total     0
Train Time (s)               151.28618284408003
(Previous) Eval Time (s)     8.903277185745537
Sample Time (s)              11.130401749163866
Epoch Time (s)               171.31986177898943
Total Train Time (s)         54523.51929890644
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:04:36.591649 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #295 | Epoch Duration: 171.4115617275238
2020-01-12 17:04:36.591827 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1695929
Z variance train             0.014637646
KL Divergence                20.324018
KL Loss                      2.0324018
QF Loss                      2370.0435
VF Loss                      212.07445
Policy Loss                  -1057.1487
Q Predictions Mean           1053.9575
Q Predictions Std            336.3078
Q Predictions Max            1497.7827
Q Predictions Min            403.59973
V Predictions Mean           1055.1558
V Predictions Std            338.78714
V Predictions Max            1499.4619
V Predictions Min            393.9311
Log Pis Mean                 -0.4185224
Log Pis Std                  3.1140118
Log Pis Max                  21.321033
Log Pis Min                  -7.5611467
Policy mu Mean               -0.036485218
Policy mu Std                0.63496524
Policy mu Max                3.3329587
Policy mu Min                -2.7524161
Policy log std Mean          -0.8765216
Policy log std Std           0.25977257
Policy log std Max           -0.15107423
Policy log std Min           -2.503191
Z mean eval                  1.1046752
Z variance eval              0.01647028
total_rewards                [1594.45618256  607.56337809  831.32919209 3592.22928051  404.18057098
 1185.73143481  622.60179099 3034.66629802  878.72988445  841.17820591]
total_rewards_mean           1359.2666218427235
total_rewards_std            1033.2708356104822
total_rewards_max            3592.2292805122906
total_rewards_min            404.180570983669
Number of train steps total  1188000
Number of env steps total    1670207
Number of rollouts total     0
Train Time (s)               153.82984286593273
(Previous) Eval Time (s)     28.69526020111516
Sample Time (s)              12.707954261917621
Epoch Time (s)               195.23305732896551
Total Train Time (s)         54718.84822419565
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:07:51.922676 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #296 | Epoch Duration: 195.33072018623352
2020-01-12 17:07:51.922808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1017822
Z variance train             0.016430166
KL Divergence                19.080925
KL Loss                      1.9080925
QF Loss                      595.9436
VF Loss                      57.744106
Policy Loss                  -1081.6818
Q Predictions Mean           1078.1792
Q Predictions Std            335.1066
Q Predictions Max            1486.143
Q Predictions Min            384.6722
V Predictions Mean           1082.2362
V Predictions Std            335.43954
V Predictions Max            1504.0482
V Predictions Min            396.929
Log Pis Mean                 -0.27736104
Log Pis Std                  2.867723
Log Pis Max                  10.119513
Log Pis Min                  -9.089668
Policy mu Mean               -0.012792399
Policy mu Std                0.5707401
Policy mu Max                2.3368495
Policy mu Min                -2.340695
Policy log std Mean          -0.9607924
Policy log std Std           0.2730246
Policy log std Max           -0.21887296
Policy log std Min           -1.9435698
Z mean eval                  1.0403416
Z variance eval              0.049894836
total_rewards                [2659.00586189  881.05497202  780.5225405  3652.31211173 3485.89731856
 1545.8787099   209.398798   3016.62170475  567.40109926 2043.68353058]
total_rewards_mean           1884.1776647185773
total_rewards_std            1203.2280066881417
total_rewards_max            3652.3121117259834
total_rewards_min            209.39879800410438
Number of train steps total  1192000
Number of env steps total    1679823
Number of rollouts total     0
Train Time (s)               152.8678523749113
(Previous) Eval Time (s)     23.789393851999193
Sample Time (s)              11.581156335771084
Epoch Time (s)               188.23840256268159
Total Train Time (s)         54907.17616556026
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:11:00.254731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #297 | Epoch Duration: 188.33180952072144
2020-01-12 17:11:00.254951 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #297 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0423306
Z variance train             0.049928304
KL Divergence                16.974731
KL Loss                      1.6974732
QF Loss                      11798.695
VF Loss                      84.93175
Policy Loss                  -1090.1987
Q Predictions Mean           1085.9705
Q Predictions Std            323.2767
Q Predictions Max            1479.0166
Q Predictions Min            400.34143
V Predictions Mean           1092.9032
V Predictions Std            324.84918
V Predictions Max            1471.7606
V Predictions Min            399.55127
Log Pis Mean                 -0.2709642
Log Pis Std                  2.814211
Log Pis Max                  9.3467045
Log Pis Min                  -6.476461
Policy mu Mean               0.018835044
Policy mu Std                0.6332092
Policy mu Max                2.2361274
Policy mu Min                -2.3570302
Policy log std Mean          -0.89924586
Policy log std Std           0.25099546
Policy log std Max           -0.30957693
Policy log std Min           -1.9575188
Z mean eval                  1.3945816
Z variance eval              0.006581488
total_rewards                [ 321.48771536 2814.68130805 1618.67585542  314.46388622 2795.8292234
  522.28285865 2181.45148401  518.52198958 1107.44875791 1563.56365636]
total_rewards_mean           1375.8406734947048
total_rewards_std            927.5569421719537
total_rewards_max            2814.6813080478487
total_rewards_min            314.46388622174914
Number of train steps total  1196000
Number of env steps total    1688436
Number of rollouts total     0
Train Time (s)               154.34343484602869
(Previous) Eval Time (s)     20.34293374978006
Sample Time (s)              13.427225401159376
Epoch Time (s)               188.11359399696812
Total Train Time (s)         55095.38050434319
Epoch                        298
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:14:08.467665 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #298 | Epoch Duration: 188.21256041526794
2020-01-12 17:14:08.468001 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4166317
Z variance train             0.0064804256
KL Divergence                22.55276
KL Loss                      2.255276
QF Loss                      578.3037
VF Loss                      190.74927
Policy Loss                  -1044.6675
Q Predictions Mean           1037.6843
Q Predictions Std            355.9526
Q Predictions Max            1478.2498
Q Predictions Min            392.60568
V Predictions Mean           1038.9418
V Predictions Std            356.42444
V Predictions Max            1466.0225
V Predictions Min            375.89194
Log Pis Mean                 -0.6734221
Log Pis Std                  3.0729666
Log Pis Max                  12.448935
Log Pis Min                  -5.9172983
Policy mu Mean               -0.018403463
Policy mu Std                0.5943779
Policy mu Max                2.3786101
Policy mu Min                -2.297082
Policy log std Mean          -0.92008215
Policy log std Std           0.27428156
Policy log std Max           -0.32480025
Policy log std Min           -2.433599
Z mean eval                  0.97662246
Z variance eval              0.01927759
total_rewards                [1184.22225765 3363.78033068  737.49774158 3571.33427784  804.28679551
 3446.31244295  104.59780784 1530.39419919 1322.44214518 2745.00640771]
total_rewards_mean           1880.9874406121903
total_rewards_std            1216.3676093170263
total_rewards_max            3571.334277835905
total_rewards_min            104.5978078367983
Number of train steps total  1200000
Number of env steps total    1698554
Number of rollouts total     0
Train Time (s)               152.60856210021302
(Previous) Eval Time (s)     21.219944483134896
Sample Time (s)              12.357201931998134
Epoch Time (s)               186.18570851534605
Total Train Time (s)         55281.66493512364
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:17:14.750054 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #299 | Epoch Duration: 186.28177189826965
2020-01-12 17:17:14.750259 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #299 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98503125
Z variance train             0.018925285
KL Divergence                17.604794
KL Loss                      1.7604793
QF Loss                      718.01855
VF Loss                      118.09555
Policy Loss                  -1033.8243
Q Predictions Mean           1028.8411
Q Predictions Std            348.84125
Q Predictions Max            1525.5889
Q Predictions Min            393.75388
V Predictions Mean           1033.0374
V Predictions Std            351.1013
V Predictions Max            1530.5725
V Predictions Min            397.51718
Log Pis Mean                 -0.6036198
Log Pis Std                  3.1921906
Log Pis Max                  12.547067
Log Pis Min                  -7.250758
Policy mu Mean               -0.04075501
Policy mu Std                0.5895654
Policy mu Max                2.2577574
Policy mu Min                -2.174966
Policy log std Mean          -0.8791478
Policy log std Std           0.2643929
Policy log std Max           -0.007813215
Policy log std Min           -2.0076349
Z mean eval                  1.1969192
Z variance eval              0.044678263
total_rewards                [ 943.97342777 1272.94281573  287.96147476   74.59981379  603.6582036
  577.96254646  129.75040029 1458.7488283  1198.29138292  385.78773645]
total_rewards_mean           693.3676630067037
total_rewards_std            471.2038502495122
total_rewards_max            1458.7488283045616
total_rewards_min            74.599813787189
Number of train steps total  1204000
Number of env steps total    1709470
Number of rollouts total     0
Train Time (s)               144.1198589792475
(Previous) Eval Time (s)     13.149532365147024
Sample Time (s)              11.858327321708202
Epoch Time (s)               169.12771866610274
Total Train Time (s)         55450.89432366658
Epoch                        300
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:20:03.983897 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #300 | Epoch Duration: 169.2334749698639
2020-01-12 17:20:03.984185 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1977028
Z variance train             0.044915795
KL Divergence                17.087763
KL Loss                      1.7087764
QF Loss                      655.69214
VF Loss                      114.118515
Policy Loss                  -1102.6023
Q Predictions Mean           1093.7157
Q Predictions Std            315.19128
Q Predictions Max            1452.892
Q Predictions Min            393.01566
V Predictions Mean           1100.226
V Predictions Std            313.24753
V Predictions Max            1462.3243
V Predictions Min            397.4785
Log Pis Mean                 -0.38117623
Log Pis Std                  3.088946
Log Pis Max                  13.076898
Log Pis Min                  -10.088754
Policy mu Mean               -0.014054565
Policy mu Std                0.6282985
Policy mu Max                3.1713686
Policy mu Min                -2.7568777
Policy log std Mean          -0.91500235
Policy log std Std           0.24762431
Policy log std Max           -0.21138853
Policy log std Min           -2.612358
Z mean eval                  1.1143624
Z variance eval              0.02114938
total_rewards                [ 672.39411666 2935.25616344 3323.20888267 1349.47504176 3210.85214863
 1454.27856845 1582.11264909 2123.11586257  887.36877713   96.06318881]
total_rewards_mean           1763.4125399206373
total_rewards_std            1052.0577673304647
total_rewards_max            3323.208882672493
total_rewards_min            96.06318881347366
Number of train steps total  1208000
Number of env steps total    1718451
Number of rollouts total     0
Train Time (s)               145.16558888182044
(Previous) Eval Time (s)     23.857500575948507
Sample Time (s)              11.71942164329812
Epoch Time (s)               180.74251110106707
Total Train Time (s)         55631.71986250719
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:23:04.818173 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #301 | Epoch Duration: 180.83381009101868
2020-01-12 17:23:04.818391 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1099138
Z variance train             0.02114449
KL Divergence                18.385025
KL Loss                      1.8385025
QF Loss                      381.61475
VF Loss                      300.54388
Policy Loss                  -1091.2771
Q Predictions Mean           1086.554
Q Predictions Std            341.6021
Q Predictions Max            1483.4038
Q Predictions Min            -14.8081875
V Predictions Mean           1095.7412
V Predictions Std            336.2176
V Predictions Max            1488.0717
V Predictions Min            349.8533
Log Pis Mean                 -0.55441743
Log Pis Std                  2.9366035
Log Pis Max                  19.792652
Log Pis Min                  -8.474423
Policy mu Mean               -0.064113736
Policy mu Std                0.5983052
Policy mu Max                2.3942983
Policy mu Min                -2.67786
Policy log std Mean          -0.8990448
Policy log std Std           0.2585118
Policy log std Max           -0.14686203
Policy log std Min           -2.0026226
Z mean eval                  1.1849782
Z variance eval              0.029065032
total_rewards                [ 767.19117119 1271.76140631 3295.60405846 2414.08821638 3620.14102197
 3516.83437481  172.34714082 3550.83753025 3269.97180149 3268.84405861]
total_rewards_mean           2514.7620780295792
total_rewards_std            1230.6200513333204
total_rewards_max            3620.1410219748195
total_rewards_min            172.34714081862484
Number of train steps total  1212000
Number of env steps total    1728360
Number of rollouts total     0
Train Time (s)               153.37039896287024
(Previous) Eval Time (s)     31.982023219112307
Sample Time (s)              12.56262410711497
Epoch Time (s)               197.91504628909752
Total Train Time (s)         55829.727905492764
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:26:22.829656 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #302 | Epoch Duration: 198.01109886169434
2020-01-12 17:26:22.829879 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1884445
Z variance train             0.029338092
KL Divergence                18.793388
KL Loss                      1.8793389
QF Loss                      378.31458
VF Loss                      64.88612
Policy Loss                  -1087.0264
Q Predictions Mean           1083.7902
Q Predictions Std            326.22522
Q Predictions Max            1476.0929
Q Predictions Min            395.83896
V Predictions Mean           1087.0457
V Predictions Std            324.70023
V Predictions Max            1462.0237
V Predictions Min            395.02887
Log Pis Mean                 -0.4262805
Log Pis Std                  3.0854714
Log Pis Max                  17.875435
Log Pis Min                  -7.7156386
Policy mu Mean               -0.013199026
Policy mu Std                0.6018571
Policy mu Max                2.0283625
Policy mu Min                -2.9905777
Policy log std Mean          -0.93223375
Policy log std Std           0.26309302
Policy log std Max           -0.3626752
Policy log std Min           -2.232664
Z mean eval                  1.0155152
Z variance eval              0.007911214
total_rewards                [3623.01429609 3490.0661742  2646.76808569 1806.26900239 2835.0519258
    9.21973799 2106.28190877 3370.92901649 3502.46071716 3347.75455543]
total_rewards_mean           2673.7815420009247
total_rewards_std            1067.5012005885255
total_rewards_max            3623.014296094216
total_rewards_min            9.219737987522794
Number of train steps total  1216000
Number of env steps total    1738467
Number of rollouts total     0
Train Time (s)               153.31702026585117
(Previous) Eval Time (s)     32.29711522581056
Sample Time (s)              12.773288094438612
Epoch Time (s)               198.38742358610034
Total Train Time (s)         56028.20416114433
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:29:41.308752 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #303 | Epoch Duration: 198.47873163223267
2020-01-12 17:29:41.308911 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0240989
Z variance train             0.007978454
KL Divergence                21.476753
KL Loss                      2.1476753
QF Loss                      349.24164
VF Loss                      87.083664
Policy Loss                  -1101.3129
Q Predictions Mean           1095.6958
Q Predictions Std            311.64697
Q Predictions Max            1507.2936
Q Predictions Min            406.18582
V Predictions Mean           1101.4716
V Predictions Std            310.72168
V Predictions Max            1504.746
V Predictions Min            409.83185
Log Pis Mean                 -0.4574495
Log Pis Std                  3.0437536
Log Pis Max                  9.1446085
Log Pis Min                  -10.875417
Policy mu Mean               0.01293197
Policy mu Std                0.6209324
Policy mu Max                1.9316833
Policy mu Min                -2.5768929
Policy log std Mean          -0.92456627
Policy log std Std           0.2719474
Policy log std Max           -0.28442836
Policy log std Min           -2.1672716
Z mean eval                  1.1400734
Z variance eval              0.037026547
total_rewards                [1079.4399436  3557.76817551 2648.2877563  3744.45660715  383.83089464
  672.19433628  729.98786322 3504.89751075 1961.40038006 1064.54345385]
total_rewards_mean           1934.6806921354696
total_rewards_std            1257.9387480725068
total_rewards_max            3744.456607154003
total_rewards_min            383.8308946401812
Number of train steps total  1220000
Number of env steps total    1748019
Number of rollouts total     0
Train Time (s)               152.73106244625524
(Previous) Eval Time (s)     24.0870358729735
Sample Time (s)              11.260218621697277
Epoch Time (s)               188.07831694092602
Total Train Time (s)         56216.41641390929
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:32:49.526451 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #304 | Epoch Duration: 188.2173764705658
2020-01-12 17:32:49.526780 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.139281
Z variance train             0.036733624
KL Divergence                18.614704
KL Loss                      1.8614705
QF Loss                      349.52234
VF Loss                      69.18687
Policy Loss                  -1096.2015
Q Predictions Mean           1091.4724
Q Predictions Std            321.00986
Q Predictions Max            1488.9269
Q Predictions Min            404.92648
V Predictions Mean           1096.7485
V Predictions Std            323.19147
V Predictions Max            1493.5922
V Predictions Min            405.63275
Log Pis Mean                 -0.4948453
Log Pis Std                  2.7807922
Log Pis Max                  10.773922
Log Pis Min                  -9.867314
Policy mu Mean               -0.04771593
Policy mu Std                0.605634
Policy mu Max                2.4590378
Policy mu Min                -2.829356
Policy log std Mean          -0.9077426
Policy log std Std           0.25689065
Policy log std Max           -0.2829489
Policy log std Min           -2.2756724
Z mean eval                  1.0170169
Z variance eval              0.010651868
total_rewards                [3488.30984835 3580.57858748 2348.91588589 3554.20822495 1201.85716086
  334.17624852 3514.39158714 3633.62050093 3674.93739364 3539.86248875]
total_rewards_mean           2887.0857926501917
total_rewards_std            1137.1929775720682
total_rewards_max            3674.9373936379043
total_rewards_min            334.17624851569906
Number of train steps total  1224000
Number of env steps total    1756994
Number of rollouts total     0
Train Time (s)               154.64021803392097
(Previous) Eval Time (s)     31.64884701371193
Sample Time (s)              11.944088126067072
Epoch Time (s)               198.23315317369998
Total Train Time (s)         56414.73590965755
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:36:07.848902 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #305 | Epoch Duration: 198.32194256782532
2020-01-12 17:36:07.849080 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0131667
Z variance train             0.010652669
KL Divergence                20.230167
KL Loss                      2.0230167
QF Loss                      746.2006
VF Loss                      209.18437
Policy Loss                  -1074.7401
Q Predictions Mean           1070.2015
Q Predictions Std            332.0848
Q Predictions Max            1498.0511
Q Predictions Min            403.2053
V Predictions Mean           1073.1417
V Predictions Std            332.81253
V Predictions Max            1491.636
V Predictions Min            401.59402
Log Pis Mean                 -0.63004047
Log Pis Std                  3.0878203
Log Pis Max                  14.448248
Log Pis Min                  -7.850202
Policy mu Mean               -0.03426415
Policy mu Std                0.6022895
Policy mu Max                2.1290298
Policy mu Min                -2.5377173
Policy log std Mean          -0.9022031
Policy log std Std           0.2563329
Policy log std Max           -0.32052624
Policy log std Min           -2.6339293
Z mean eval                  1.0085267
Z variance eval              0.019832145
total_rewards                [ 239.75488248 3456.86260582 1231.38480251 1857.15718987 2352.73197951
 3408.89987302  892.55814159  932.93240145  345.32281439 3498.03086769]
total_rewards_mean           1821.5635558319784
total_rewards_std            1223.5285763097108
total_rewards_max            3498.0308676858776
total_rewards_min            239.75488247959922
Number of train steps total  1228000
Number of env steps total    1765669
Number of rollouts total     0
Train Time (s)               149.0089652086608
(Previous) Eval Time (s)     18.324732682667673
Sample Time (s)              11.81807386642322
Epoch Time (s)               179.1517717577517
Total Train Time (s)         56593.9805145571
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:39:07.099838 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #306 | Epoch Duration: 179.25061011314392
2020-01-12 17:39:07.100142 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #306 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.013365
Z variance train             0.019810159
KL Divergence                17.948143
KL Loss                      1.7948143
QF Loss                      399.31137
VF Loss                      80.732994
Policy Loss                  -1093.9719
Q Predictions Mean           1091.6819
Q Predictions Std            337.0518
Q Predictions Max            1508.7472
Q Predictions Min            390.9883
V Predictions Mean           1098.427
V Predictions Std            336.24683
V Predictions Max            1511.8834
V Predictions Min            401.8192
Log Pis Mean                 -0.721107
Log Pis Std                  2.640774
Log Pis Max                  6.37869
Log Pis Min                  -6.9864545
Policy mu Mean               -0.017549574
Policy mu Std                0.60453516
Policy mu Max                2.0413406
Policy mu Min                -1.9468813
Policy log std Mean          -0.9031836
Policy log std Std           0.25471163
Policy log std Max           -0.30752313
Policy log std Min           -2.0388029
Z mean eval                  1.1239855
Z variance eval              0.009929461
total_rewards                [1093.15038022 3499.29594018  843.03073848  561.65105106 3552.2039709
 1600.01795028 3716.51322845  234.34863079 2682.60317607 3614.20940925]
total_rewards_mean           2139.702447567529
total_rewards_std            1341.1713806569398
total_rewards_max            3716.513228449434
total_rewards_min            234.348630787216
Number of train steps total  1232000
Number of env steps total    1776111
Number of rollouts total     0
Train Time (s)               145.01619992870837
(Previous) Eval Time (s)     24.031977529171854
Sample Time (s)              10.968691044021398
Epoch Time (s)               180.01686850190163
Total Train Time (s)         56774.09704514686
Epoch                        307
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:42:07.219034 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #307 | Epoch Duration: 180.11865043640137
2020-01-12 17:42:07.219254 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.120343
Z variance train             0.009929095
KL Divergence                21.306145
KL Loss                      2.1306145
QF Loss                      332.6753
VF Loss                      118.31647
Policy Loss                  -1093.1803
Q Predictions Mean           1090.238
Q Predictions Std            318.23627
Q Predictions Max            1495.1564
Q Predictions Min            412.09412
V Predictions Mean           1090.4575
V Predictions Std            319.16083
V Predictions Max            1488.6163
V Predictions Min            406.84094
Log Pis Mean                 -0.21869549
Log Pis Std                  2.866117
Log Pis Max                  8.074708
Log Pis Min                  -8.5074215
Policy mu Mean               -0.030357884
Policy mu Std                0.6097702
Policy mu Max                2.2016654
Policy mu Min                -2.4318588
Policy log std Mean          -0.92180693
Policy log std Std           0.25596514
Policy log std Max           -0.31665736
Policy log std Min           -2.0760775
Z mean eval                  1.0860965
Z variance eval              0.017373335
total_rewards                [2729.40536146 3140.31389576 1525.62603777   92.14713209  818.98730668
 1736.11776887  293.82899835 3612.66635254  609.50603563 3721.74311212]
total_rewards_mean           1828.0342001261172
total_rewards_std            1314.3655768015376
total_rewards_max            3721.7431121158875
total_rewards_min            92.14713208686041
Number of train steps total  1236000
Number of env steps total    1787291
Number of rollouts total     0
Train Time (s)               145.34709922224283
(Previous) Eval Time (s)     26.09877637634054
Sample Time (s)              12.910936851520091
Epoch Time (s)               184.35681245010346
Total Train Time (s)         56958.545717725065
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:45:11.671332 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #308 | Epoch Duration: 184.45191359519958
2020-01-12 17:45:11.671543 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0856351
Z variance train             0.017347246
KL Divergence                19.236238
KL Loss                      1.9236239
QF Loss                      357.14874
VF Loss                      152.36145
Policy Loss                  -1100.9392
Q Predictions Mean           1095.0664
Q Predictions Std            317.91513
Q Predictions Max            1529.9171
Q Predictions Min            378.57397
V Predictions Mean           1091.5017
V Predictions Std            313.96207
V Predictions Max            1514.9858
V Predictions Min            384.4007
Log Pis Mean                 -0.77805275
Log Pis Std                  2.8897414
Log Pis Max                  7.3464813
Log Pis Min                  -9.673117
Policy mu Mean               0.034082532
Policy mu Std                0.56199366
Policy mu Max                1.9658573
Policy mu Min                -1.9451765
Policy log std Mean          -0.9258771
Policy log std Std           0.2494011
Policy log std Max           -0.15649736
Policy log std Min           -2.2275486
Z mean eval                  1.0174234
Z variance eval              0.011602218
total_rewards                [2267.84842478 3214.06501377 2719.82299466 1274.30981327 3438.72033542
 3208.03901439 3702.49063784  756.04700031 1929.73307928 2689.27450325]
total_rewards_mean           2520.0350816985747
total_rewards_std            913.3076068515268
total_rewards_max            3702.490637843087
total_rewards_min            756.0470003054406
Number of train steps total  1240000
Number of env steps total    1797831
Number of rollouts total     0
Train Time (s)               154.2282172231935
(Previous) Eval Time (s)     27.26229175599292
Sample Time (s)              13.472044501453638
Epoch Time (s)               194.96255348064005
Total Train Time (s)         57153.60024027387
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:48:26.729344 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #309 | Epoch Duration: 195.0576512813568
2020-01-12 17:48:26.729545 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0168309
Z variance train             0.011551726
KL Divergence                20.435991
KL Loss                      2.0435991
QF Loss                      743.1166
VF Loss                      73.75372
Policy Loss                  -1068.3688
Q Predictions Mean           1061.8027
Q Predictions Std            325.96698
Q Predictions Max            1488.7632
Q Predictions Min            373.23065
V Predictions Mean           1065.2673
V Predictions Std            323.80423
V Predictions Max            1476.5863
V Predictions Min            375.78104
Log Pis Mean                 -0.47608122
Log Pis Std                  3.058899
Log Pis Max                  11.2284355
Log Pis Min                  -8.203607
Policy mu Mean               -0.03145121
Policy mu Std                0.6215261
Policy mu Max                2.3925853
Policy mu Min                -2.4431765
Policy log std Mean          -0.8891562
Policy log std Std           0.2419667
Policy log std Max           -0.28020018
Policy log std Min           -1.846365
Z mean eval                  1.1718043
Z variance eval              0.012968105
total_rewards                [ 363.64927166  959.30688647  511.71919299 1267.33658332  437.02868488
  223.96711274  115.17630412 1194.66009358 1578.48638686  154.8965533 ]
total_rewards_mean           680.6227069898424
total_rewards_std            498.526050003542
total_rewards_max            1578.486386858422
total_rewards_min            115.1763041165348
Number of train steps total  1244000
Number of env steps total    1808286
Number of rollouts total     0
Train Time (s)               152.86632027989253
(Previous) Eval Time (s)     11.056981260888278
Sample Time (s)              12.458147414959967
Epoch Time (s)               176.38144895574078
Total Train Time (s)         57330.06637514802
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:51:23.199365 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #310 | Epoch Duration: 176.46964597702026
2020-01-12 17:51:23.199661 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1671231
Z variance train             0.013002326
KL Divergence                21.42205
KL Loss                      2.142205
QF Loss                      1366.0969
VF Loss                      143.2039
Policy Loss                  -1124.8375
Q Predictions Mean           1117.865
Q Predictions Std            315.65906
Q Predictions Max            1524.8063
Q Predictions Min            397.5328
V Predictions Mean           1119.146
V Predictions Std            312.69974
V Predictions Max            1516.9022
V Predictions Min            394.44467
Log Pis Mean                 -0.095822684
Log Pis Std                  3.3110766
Log Pis Max                  12.686159
Log Pis Min                  -14.011497
Policy mu Mean               0.065186955
Policy mu Std                0.6793136
Policy mu Max                2.61588
Policy mu Min                -2.5087016
Policy log std Mean          -0.8850558
Policy log std Std           0.25095794
Policy log std Max           -0.28796625
Policy log std Min           -2.1604955
Z mean eval                  1.2355243
Z variance eval              0.02533868
total_rewards                [2024.51008499  277.80076382 3573.28231285 1366.83374137 3474.73490036
 3301.94658578 1337.73912468 2171.71902199  999.85848269 2065.98868648]
total_rewards_mean           2059.441370501639
total_rewards_std            1055.9345303843243
total_rewards_max            3573.282312853773
total_rewards_min            277.80076381689855
Number of train steps total  1248000
Number of env steps total    1819457
Number of rollouts total     0
Train Time (s)               151.91181061277166
(Previous) Eval Time (s)     24.562867044005543
Sample Time (s)              11.483444275800139
Epoch Time (s)               187.95812193257734
Total Train Time (s)         57518.11171577778
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:54:31.248203 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #311 | Epoch Duration: 188.04837012290955
2020-01-12 17:54:31.248400 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #311 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2296112
Z variance train             0.025841366
KL Divergence                19.34752
KL Loss                      1.9347521
QF Loss                      5252.927
VF Loss                      653.3864
Policy Loss                  -1125.5457
Q Predictions Mean           1124.3168
Q Predictions Std            304.76755
Q Predictions Max            1512.2878
Q Predictions Min            87.29684
V Predictions Mean           1128.3906
V Predictions Std            303.0672
V Predictions Max            1514.0358
V Predictions Min            316.31784
Log Pis Mean                 0.13702588
Log Pis Std                  3.4772449
Log Pis Max                  33.44645
Log Pis Min                  -6.706066
Policy mu Mean               -0.030554958
Policy mu Std                0.66345376
Policy mu Max                2.7614722
Policy mu Min                -5.9480414
Policy log std Mean          -0.9214442
Policy log std Std           0.23696384
Policy log std Max           1.6833304
Policy log std Min           -1.8438486
Z mean eval                  1.155549
Z variance eval              0.009762785
total_rewards                [3169.54740878  100.96485021 1621.01208486 3606.55895511   64.429332
  270.52328561 2584.70170658 1343.81861152 3247.31566444  257.44183204]
total_rewards_mean           1626.6313731142068
total_rewards_std            1356.726825649295
total_rewards_max            3606.5589551068297
total_rewards_min            64.42933200409021
Number of train steps total  1252000
Number of env steps total    1829011
Number of rollouts total     0
Train Time (s)               153.904285187833
(Previous) Eval Time (s)     28.151181939058006
Sample Time (s)              12.559824377298355
Epoch Time (s)               194.61529150418937
Total Train Time (s)         57712.833088691346
Epoch                        312
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:57:45.971290 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #312 | Epoch Duration: 194.72275710105896
2020-01-12 17:57:45.971434 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #312 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1566719
Z variance train             0.009712921
KL Divergence                22.284863
KL Loss                      2.2284863
QF Loss                      608.03784
VF Loss                      121.983505
Policy Loss                  -1130.0696
Q Predictions Mean           1123.3293
Q Predictions Std            315.28732
Q Predictions Max            1534.5872
Q Predictions Min            389.33768
V Predictions Mean           1135.6929
V Predictions Std            308.98584
V Predictions Max            1525.743
V Predictions Min            473.35684
Log Pis Mean                 0.22386706
Log Pis Std                  3.2932293
Log Pis Max                  17.901255
Log Pis Min                  -6.59988
Policy mu Mean               -0.004207664
Policy mu Std                0.71649295
Policy mu Max                2.6226892
Policy mu Min                -2.9821775
Policy log std Mean          -0.9041678
Policy log std Std           0.25157475
Policy log std Max           -0.14194584
Policy log std Min           -2.04576
Z mean eval                  1.4709315
Z variance eval              0.011056872
total_rewards                [ -975.51149951   849.02462614  -878.92621785  1053.25367795
 -1103.34625582 -1205.77212022  -266.02012677  -790.23311258
 -1196.91823153  -578.03387475]
total_rewards_mean           -509.24831349288615
total_rewards_std            780.6543741999791
total_rewards_max            1053.2536779528232
total_rewards_min            -1205.772120215317
Number of train steps total  1256000
Number of env steps total    1838019
Number of rollouts total     0
Train Time (s)               147.19839857891202
(Previous) Eval Time (s)     33.88832867704332
Sample Time (s)              12.552435484714806
Epoch Time (s)               193.63916274067014
Total Train Time (s)         57906.56466300413
Epoch                        313
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:00:59.707238 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #313 | Epoch Duration: 193.73565363883972
2020-01-12 18:00:59.707450 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4458406
Z variance train             0.011026426
KL Divergence                26.23642
KL Loss                      2.623642
QF Loss                      1035.7025
VF Loss                      389.00003
Policy Loss                  -1329.8358
Q Predictions Mean           1316.7852
Q Predictions Std            251.08601
Q Predictions Max            2069.5364
Q Predictions Min            636.4136
V Predictions Mean           1337.731
V Predictions Std            251.20847
V Predictions Max            2113.5273
V Predictions Min            654.54877
Log Pis Mean                 1.9780924
Log Pis Std                  4.0562086
Log Pis Max                  13.801552
Log Pis Min                  -6.0523195
Policy mu Mean               0.033522703
Policy mu Std                0.9088365
Policy mu Max                3.2848618
Policy mu Min                -3.3263562
Policy log std Mean          -0.9149214
Policy log std Std           0.2568676
Policy log std Max           -0.058027506
Policy log std Min           -1.8781936
Z mean eval                  1.4111719
Z variance eval              0.0019201599
total_rewards                [-356.63972978 -977.23237367 -785.80790831 -796.22365748 -977.11541825
  150.15403139 -373.5548448  -342.81999691 -229.03478948 -885.65407947]
total_rewards_mean           -557.3928766751696
total_rewards_std            360.27526006833904
total_rewards_max            150.1540313940214
total_rewards_min            -977.232373672735
Number of train steps total  1260000
Number of env steps total    1847177
Number of rollouts total     0
Train Time (s)               143.68227604869753
(Previous) Eval Time (s)     33.86959840031341
Sample Time (s)              11.382225766777992
Epoch Time (s)               188.93410021578893
Total Train Time (s)         58095.58645602828
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:04:08.732676 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #314 | Epoch Duration: 189.02506613731384
2020-01-12 18:04:08.732897 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4184649
Z variance train             0.0018792946
KL Divergence                34.332134
KL Loss                      3.4332135
QF Loss                      1280.7993
VF Loss                      448.75916
Policy Loss                  -1569.1508
Q Predictions Mean           1548.9596
Q Predictions Std            290.27975
Q Predictions Max            2344.0054
Q Predictions Min            -65.24384
V Predictions Mean           1571.9651
V Predictions Std            284.92017
V Predictions Max            2438.4226
V Predictions Min            752.3802
Log Pis Mean                 2.646749
Log Pis Std                  4.2662325
Log Pis Max                  16.22276
Log Pis Min                  -6.792287
Policy mu Mean               0.16861936
Policy mu Std                0.96585655
Policy mu Max                2.8324294
Policy mu Min                -2.8461766
Policy log std Mean          -0.9201001
Policy log std Std           0.27577734
Policy log std Max           0.04555279
Policy log std Min           -2.2732873
Z mean eval                  1.4429919
Z variance eval              0.039977632
total_rewards                [-725.52646819 -752.35051571 -848.63082574 -720.79455543 -702.04422483
 -606.95252017 -779.6901808  -766.39442316 -769.28769975 -833.50541049]
total_rewards_mean           -750.5176824274807
total_rewards_std            65.14644062268621
total_rewards_max            -606.952520173006
total_rewards_min            -848.630825739513
Number of train steps total  1264000
Number of env steps total    1858435
Number of rollouts total     0
Train Time (s)               148.51147568505257
(Previous) Eval Time (s)     37.350319895893335
Sample Time (s)              11.133202984463423
Epoch Time (s)               196.99499856540933
Total Train Time (s)         58292.67321140366
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:07:25.822593 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #315 | Epoch Duration: 197.089537858963
2020-01-12 18:07:25.822784 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #315 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4450203
Z variance train             0.03967111
KL Divergence                32.243183
KL Loss                      3.2243183
QF Loss                      4305.5293
VF Loss                      411.82068
Policy Loss                  -1656.2714
Q Predictions Mean           1638.0592
Q Predictions Std            307.02948
Q Predictions Max            2722.139
Q Predictions Min            540.0096
V Predictions Mean           1660.0065
V Predictions Std            308.5592
V Predictions Max            2782.8389
V Predictions Min            604.6637
Log Pis Mean                 2.2938242
Log Pis Std                  4.007882
Log Pis Max                  18.491617
Log Pis Min                  -11.8235
Policy mu Mean               0.18787071
Policy mu Std                0.934286
Policy mu Max                4.5075264
Policy mu Min                -2.6148229
Policy log std Mean          -0.9289403
Policy log std Std           0.25029305
Policy log std Max           -0.22366846
Policy log std Min           -2.7448664
Z mean eval                  1.4779624
Z variance eval              0.06930202
total_rewards                [-1245.02876269 -1312.3454143  -1075.21291839 -1131.00225419
 -1345.38136998 -1309.723159   -1225.60841701 -1274.04792515
 -1280.89492713 -1093.57067741]
total_rewards_mean           -1229.281582526377
total_rewards_std            91.42891557719898
total_rewards_max            -1075.2129183948632
total_rewards_min            -1345.3813699826078
Number of train steps total  1268000
Number of env steps total    1868848
Number of rollouts total     0
Train Time (s)               154.58948649279773
(Previous) Eval Time (s)     37.71306660491973
Sample Time (s)              12.118201351258904
Epoch Time (s)               204.42075444897637
Total Train Time (s)         58497.18560497789
Epoch                        316
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:10:50.336796 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #316 | Epoch Duration: 204.5138864517212
2020-01-12 18:10:50.336921 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #316 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4801724
Z variance train             0.06869622
KL Divergence                32.909702
KL Loss                      3.2909703
QF Loss                      1606.8629
VF Loss                      353.04645
Policy Loss                  -1900.4507
Q Predictions Mean           1874.023
Q Predictions Std            499.24075
Q Predictions Max            3622.0989
Q Predictions Min            1439.1503
V Predictions Mean           1901.197
V Predictions Std            523.31647
V Predictions Max            3772.6343
V Predictions Min            1461.222
Log Pis Mean                 3.7097383
Log Pis Std                  4.308485
Log Pis Max                  18.964706
Log Pis Min                  -6.705779
Policy mu Mean               -0.055219077
Policy mu Std                1.1209675
Policy mu Max                3.198918
Policy mu Min                -3.1061995
Policy log std Mean          -0.9023528
Policy log std Std           0.25475162
Policy log std Max           -0.08522189
Policy log std Min           -2.1275897
Z mean eval                  1.3931012
Z variance eval              0.004489407
total_rewards                [ -719.12768993 -1081.85729373  -992.02498209 -1018.3435289
 -1742.45956722  -879.9355635  -1036.70492552 -1076.58988965
 -1070.42569441 -1051.26273608]
total_rewards_mean           -1066.8731871025482
total_rewards_std            249.34560607631875
total_rewards_max            -719.1276899292783
total_rewards_min            -1742.4595672174112
Number of train steps total  1272000
Number of env steps total    1878691
Number of rollouts total     0
Train Time (s)               154.2077472708188
(Previous) Eval Time (s)     34.855496814940125
Sample Time (s)              12.037464685738087
Epoch Time (s)               201.100708771497
Total Train Time (s)         58698.39980738005
Epoch                        317
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:14:11.556368 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #317 | Epoch Duration: 201.21932172775269
2020-01-12 18:14:11.556609 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #317 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4008201
Z variance train             0.004498971
KL Divergence                36.478893
KL Loss                      3.6478894
QF Loss                      5940.845
VF Loss                      1648.4819
Policy Loss                  -2101.3706
Q Predictions Mean           2050.568
Q Predictions Std            578.34375
Q Predictions Max            5341.4243
Q Predictions Min            1467.2473
V Predictions Mean           2071.901
V Predictions Std            594.12537
V Predictions Max            5419.5723
V Predictions Min            1638.8203
Log Pis Mean                 6.8672037
Log Pis Std                  4.9904594
Log Pis Max                  35.442966
Log Pis Min                  -4.01447
Policy mu Mean               -0.24616438
Policy mu Std                1.3932669
Policy mu Max                4.3703985
Policy mu Min                -3.9607115
Policy log std Mean          -0.85318005
Policy log std Std           0.2958892
Policy log std Max           0.00050103664
Policy log std Min           -2.6135745
Z mean eval                  1.7240446
Z variance eval              0.92411727
total_rewards                [   -9.72734321 -1579.13812267    -6.3400673   -686.1713692
   -24.08552826  -724.99548764 -1350.51036538   -18.95041645
   -10.53139543  -610.15265012]
total_rewards_mean           -502.0602745660769
total_rewards_std            562.7460426214794
total_rewards_max            -6.340067299402408
total_rewards_min            -1579.1381226686558
Number of train steps total  1276000
Number of env steps total    1888632
Number of rollouts total     0
Train Time (s)               155.86250674631447
(Previous) Eval Time (s)     19.6783701707609
Sample Time (s)              12.039343386888504
Epoch Time (s)               187.58022030396387
Total Train Time (s)         58886.25867235288
Epoch                        318
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:17:19.418059 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #318 | Epoch Duration: 187.86126565933228
2020-01-12 18:17:19.418265 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7244368
Z variance train             0.92715895
KL Divergence                34.19626
KL Loss                      3.419626
QF Loss                      11286.811
VF Loss                      2973.0786
Policy Loss                  -2516.6523
Q Predictions Mean           2468.9072
Q Predictions Std            911.10236
Q Predictions Max            5517.823
Q Predictions Min            1466.092
V Predictions Mean           2490.8013
V Predictions Std            939.0236
V Predictions Max            5675.052
V Predictions Min            1061.0239
Log Pis Mean                 6.951073
Log Pis Std                  4.5721993
Log Pis Max                  18.797764
Log Pis Min                  -3.6772804
Policy mu Mean               0.047948632
Policy mu Std                1.3351609
Policy mu Max                4.0273614
Policy mu Min                -3.6500764
Policy log std Mean          -0.98576915
Policy log std Std           0.34061486
Policy log std Max           0.143103
Policy log std Min           -2.3622596
Z mean eval                  1.7661139
Z variance eval              0.01290791
total_rewards                [ -559.52499634 -1257.28019839    10.23531116  -548.93897002
 -1431.03986413  -378.89486835  -160.04480499  -483.68208366
 -1123.25359376  -437.41774596]
total_rewards_mean           -636.9841814436901
total_rewards_std            451.8632570965373
total_rewards_max            10.235311164872579
total_rewards_min            -1431.039864134808
Number of train steps total  1280000
Number of env steps total    1899693
Number of rollouts total     0
Train Time (s)               153.48924480192363
(Previous) Eval Time (s)     33.8296360289678
Sample Time (s)              11.583649832755327
Epoch Time (s)               198.90253066364676
Total Train Time (s)         59085.249533290975
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:20:38.412725 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #319 | Epoch Duration: 198.99432802200317
2020-01-12 18:20:38.412850 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #319 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7588854
Z variance train             0.0128829
KL Divergence                37.828167
KL Loss                      3.7828166
QF Loss                      10072.697
VF Loss                      1915.7358
Policy Loss                  -3171.1692
Q Predictions Mean           3139.445
Q Predictions Std            815.3507
Q Predictions Max            6141.162
Q Predictions Min            1776.8739
V Predictions Mean           3153.4941
V Predictions Std            817.8694
V Predictions Max            6136.8594
V Predictions Min            1625.7472
Log Pis Mean                 6.4965563
Log Pis Std                  3.6633596
Log Pis Max                  17.316998
Log Pis Min                  -5.78523
Policy mu Mean               0.14961559
Policy mu Std                1.2507815
Policy mu Max                3.4473913
Policy mu Min                -3.564956
Policy log std Mean          -1.0451543
Policy log std Std           0.3370662
Policy log std Max           -0.071371794
Policy log std Min           -2.470273
Z mean eval                  1.6535925
Z variance eval              0.019697959
total_rewards                [-1.06456678e+02 -1.70673153e+02  4.60616217e+01 -2.56798671e+02
 -9.39090918e+00 -1.40836869e+03 -1.35948638e+03  2.14164723e+01
 -8.70515533e+01 -1.26867516e+00]
total_rewards_mean           -333.2016609689879
total_rewards_std            532.7408483614877
total_rewards_max            46.06162167347942
total_rewards_min            -1408.3686869701212
Number of train steps total  1284000
Number of env steps total    1910099
Number of rollouts total     0
Train Time (s)               144.41916404338554
(Previous) Eval Time (s)     33.877994813025
Sample Time (s)              11.208727843128145
Epoch Time (s)               189.50588669953868
Total Train Time (s)         59274.85030045826
Epoch                        320
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:23:48.017286 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #320 | Epoch Duration: 189.6043312549591
2020-01-12 18:23:48.017466 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #320 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6511018
Z variance train             0.019803515
KL Divergence                40.80596
KL Loss                      4.0805964
QF Loss                      7322.426
VF Loss                      1003.06165
Policy Loss                  -3507.8354
Q Predictions Mean           3465.6704
Q Predictions Std            667.368
Q Predictions Max            5616.64
Q Predictions Min            2180.242
V Predictions Mean           3489.5645
V Predictions Std            663.901
V Predictions Max            5573.1284
V Predictions Min            2259.681
Log Pis Mean                 6.4421415
Log Pis Std                  3.9911811
Log Pis Max                  25.906345
Log Pis Min                  -3.9553595
Policy mu Mean               0.17354132
Policy mu Std                1.2373941
Policy mu Max                3.8686955
Policy mu Min                -3.6464767
Policy log std Mean          -1.0657573
Policy log std Std           0.35646933
Policy log std Max           0.14646077
Policy log std Min           -2.2123723
Z mean eval                  1.6701326
Z variance eval              0.13528252
total_rewards                [-7.08085209e-03 -5.09132362e+02  2.66045318e+01 -7.70833958e+02
 -5.51724100e+02  3.16015916e+00 -1.04498127e+02 -9.68866909e+01
 -4.15098137e+02 -3.75355358e+02]
total_rewards_mean           -279.3771121728407
total_rewards_std            266.74094394364016
total_rewards_max            26.604531768000587
total_rewards_min            -770.8339581705745
Number of train steps total  1288000
Number of env steps total    1919876
Number of rollouts total     0
Train Time (s)               144.9526311941445
(Previous) Eval Time (s)     27.33575610537082
Sample Time (s)              11.123611492104828
Epoch Time (s)               183.41199879162014
Total Train Time (s)         59458.35025365651
Epoch                        321
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:26:51.520994 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #321 | Epoch Duration: 183.50337481498718
2020-01-12 18:26:51.521183 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #321 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6710926
Z variance train             0.135169
KL Divergence                36.250965
KL Loss                      3.6250966
QF Loss                      5941.991
VF Loss                      1136.5273
Policy Loss                  -3473.806
Q Predictions Mean           3441.315
Q Predictions Std            558.4651
Q Predictions Max            4893.691
Q Predictions Min            805.09357
V Predictions Mean           3474.3015
V Predictions Std            525.75275
V Predictions Max            4896.7617
V Predictions Min            2550.8486
Log Pis Mean                 5.337529
Log Pis Std                  3.7245114
Log Pis Max                  32.75962
Log Pis Min                  -2.9680097
Policy mu Mean               0.23491043
Policy mu Std                1.1109779
Policy mu Max                5.909814
Policy mu Min                -3.6515546
Policy log std Mean          -1.0920823
Policy log std Std           0.32045048
Policy log std Max           0.32393062
Policy log std Min           -2.2643847
Z mean eval                  1.9148245
Z variance eval              0.090813905
total_rewards                [ -931.04906135    -4.24920872    -3.42591471   117.62022084
  -349.55739429  -121.81224634  -829.08928734    -6.62207325
 -1213.67751259   117.28663658]
total_rewards_mean           -322.45758411679776
total_rewards_std            463.9136214091902
total_rewards_max            117.62022084387206
total_rewards_min            -1213.6775125886836
Number of train steps total  1292000
Number of env steps total    1930375
Number of rollouts total     0
Train Time (s)               153.630740580149
(Previous) Eval Time (s)     26.80248801317066
Sample Time (s)              11.89106961619109
Epoch Time (s)               192.32429820951074
Total Train Time (s)         59650.76055729389
Epoch                        322
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:30:03.934451 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #322 | Epoch Duration: 192.41311883926392
2020-01-12 18:30:03.934670 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #322 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9240595
Z variance train             0.090616375
KL Divergence                36.148575
KL Loss                      3.6148574
QF Loss                      57669.71
VF Loss                      738.6092
Policy Loss                  -3269.5093
Q Predictions Mean           3243.9922
Q Predictions Std            375.80023
Q Predictions Max            4845.3223
Q Predictions Min            2564.9138
V Predictions Mean           3270.3967
V Predictions Std            387.21765
V Predictions Max            4939.578
V Predictions Min            2607.8328
Log Pis Mean                 4.809881
Log Pis Std                  3.8736994
Log Pis Max                  22.991913
Log Pis Min                  -4.1885753
Policy mu Mean               0.1734287
Policy mu Std                1.101365
Policy mu Max                3.232794
Policy mu Min                -3.5201201
Policy log std Mean          -1.0549815
Policy log std Std           0.30525875
Policy log std Max           0.16277397
Policy log std Min           -2.0569062
Z mean eval                  1.731941
Z variance eval              1.575454
total_rewards                [   -7.4977506  -1196.89044057  -859.18475701  -820.91022837
  -829.06008232  -869.99547322  -854.77517121  -855.74462041
  -880.38655668  -855.44759162]
total_rewards_mean           -802.9892671997242
total_rewards_std            284.74912180803756
total_rewards_max            -7.497750595845712
total_rewards_min            -1196.890440566067
Number of train steps total  1296000
Number of env steps total    1942029
Number of rollouts total     0
Train Time (s)               153.59153491444886
(Previous) Eval Time (s)     33.623831258155406
Sample Time (s)              10.6905010570772
Epoch Time (s)               197.90586722968146
Total Train Time (s)         59848.7539765113
Epoch                        323
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:33:21.931650 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #323 | Epoch Duration: 197.99682545661926
2020-01-12 18:33:21.931842 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7337658
Z variance train             1.5780925
KL Divergence                33.807476
KL Loss                      3.3807476
QF Loss                      4768.3564
VF Loss                      1163.3759
Policy Loss                  -3390.4004
Q Predictions Mean           3348.71
Q Predictions Std            341.5412
Q Predictions Max            4854.7583
Q Predictions Min            2578.8147
V Predictions Mean           3379.5786
V Predictions Std            350.4373
V Predictions Max            4915.099
V Predictions Min            2599.2317
Log Pis Mean                 6.6745996
Log Pis Std                  3.9751377
Log Pis Max                  27.252956
Log Pis Min                  -7.087332
Policy mu Mean               0.078560114
Policy mu Std                1.3401877
Policy mu Max                4.2013016
Policy mu Min                -3.375782
Policy log std Mean          -0.9803177
Policy log std Std           0.32880253
Policy log std Max           0.0053520203
Policy log std Min           -2.269502
Z mean eval                  1.9961879
Z variance eval              0.7066411
total_rewards                [-1241.09919455  -692.71829624  -902.2606745   -938.38699987
  -972.90528651 -1037.79467686 -1270.39589227 -1209.82168709
 -1064.18134846  -759.61182861]
total_rewards_mean           -1008.9175884950971
total_rewards_std            186.094634320913
total_rewards_max            -692.7182962427102
total_rewards_min            -1270.3958922738932
Number of train steps total  1300000
Number of env steps total    1952580
Number of rollouts total     0
Train Time (s)               152.57076527597383
(Previous) Eval Time (s)     39.66360830422491
Sample Time (s)              10.546502003911883
Epoch Time (s)               202.78087558411062
Total Train Time (s)         60051.63529673079
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:36:44.818064 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #324 | Epoch Duration: 202.88606190681458
2020-01-12 18:36:44.818324 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #324 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9906414
Z variance train             0.7068297
KL Divergence                31.08393
KL Loss                      3.108393
QF Loss                      50882.504
VF Loss                      721.191
Policy Loss                  -2857.0386
Q Predictions Mean           2842.7568
Q Predictions Std            359.28122
Q Predictions Max            4312.521
Q Predictions Min            2032.2297
V Predictions Mean           2856.4067
V Predictions Std            363.90518
V Predictions Max            4348.1396
V Predictions Min            2079.1746
Log Pis Mean                 2.8936
Log Pis Std                  3.39598
Log Pis Max                  18.676414
Log Pis Min                  -5.005078
Policy mu Mean               0.100892484
Policy mu Std                0.8980893
Policy mu Max                3.0002034
Policy mu Min                -2.672014
Policy log std Mean          -1.0852115
Policy log std Std           0.26254845
Policy log std Max           -0.18164837
Policy log std Min           -2.1359422
Z mean eval                  1.4874717
Z variance eval              0.040515713
total_rewards                [   96.751902    -570.20731316    77.37586224 -1125.49364771
    59.5779912      8.95121919   325.06996863  -204.6854327
 -1270.54727907   198.94588247]
total_rewards_mean           -240.42608469110755
total_rewards_std            532.3757496670526
total_rewards_max            325.06996862938
total_rewards_min            -1270.5472790650037
Number of train steps total  1304000
Number of env steps total    1964635
Number of rollouts total     0
Train Time (s)               154.99739852780476
(Previous) Eval Time (s)     22.198996601160616
Sample Time (s)              12.54458750039339
Epoch Time (s)               189.74098262935877
Total Train Time (s)         60241.46346932044
Epoch                        325
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:39:54.648660 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #325 | Epoch Duration: 189.83017539978027
2020-01-12 18:39:54.648816 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4820178
Z variance train             0.04016469
KL Divergence                29.06754
KL Loss                      2.906754
QF Loss                      1749.1487
VF Loss                      332.24902
Policy Loss                  -2859.9321
Q Predictions Mean           2849.0957
Q Predictions Std            392.99948
Q Predictions Max            4098.1694
Q Predictions Min            2040.8386
V Predictions Mean           2857.622
V Predictions Std            394.09653
V Predictions Max            4134.913
V Predictions Min            2067.5325
Log Pis Mean                 2.2174015
Log Pis Std                  3.1443548
Log Pis Max                  13.821455
Log Pis Min                  -6.1987643
Policy mu Mean               0.12280393
Policy mu Std                0.8780367
Policy mu Max                2.933448
Policy mu Min                -2.6509573
Policy log std Mean          -0.9993282
Policy log std Std           0.2944557
Policy log std Max           -0.22024655
Policy log std Min           -2.2891808
Z mean eval                  1.5341567
Z variance eval              0.037801128
total_rewards                [-290.41439204 -322.06082605  313.02810475   68.10541512 -301.28956793
 -490.00349297 -350.59135073 -242.80863378  302.87098568 -194.54715247]
total_rewards_mean           -150.77109104203012
total_rewards_std            265.6497696187147
total_rewards_max            313.02810475088177
total_rewards_min            -490.0034929733567
Number of train steps total  1308000
Number of env steps total    1976410
Number of rollouts total     0
Train Time (s)               149.07535095419735
(Previous) Eval Time (s)     32.52825285680592
Sample Time (s)              11.59793690033257
Epoch Time (s)               193.20154071133584
Total Train Time (s)         60434.7989484882
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:43:07.987738 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #326 | Epoch Duration: 193.3387942314148
2020-01-12 18:43:07.987925 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5381489
Z variance train             0.03784546
KL Divergence                29.157715
KL Loss                      2.9157715
QF Loss                      68637.61
VF Loss                      742.2949
Policy Loss                  -2272.35
Q Predictions Mean           2263.8755
Q Predictions Std            314.29175
Q Predictions Max            3254.5127
Q Predictions Min            63.944054
V Predictions Mean           2281.0857
V Predictions Std            313.3693
V Predictions Max            3273.0146
V Predictions Min            66.57733
Log Pis Mean                 2.0920029
Log Pis Std                  3.4857376
Log Pis Max                  24.129684
Log Pis Min                  -6.348624
Policy mu Mean               0.01754966
Policy mu Std                0.8340175
Policy mu Max                3.0751288
Policy mu Min                -3.257087
Policy log std Mean          -1.0353347
Policy log std Std           0.27414805
Policy log std Max           -0.29341853
Policy log std Min           -2.6648147
Z mean eval                  1.3897512
Z variance eval              0.10093031
total_rewards                [ 422.6138678   127.0931969   943.21802276   24.26777621 -163.54458485
  220.77992433   15.32116923 -299.78024423  113.59673191  107.90868571]
total_rewards_mean           151.14745457728324
total_rewards_std            323.5260169375456
total_rewards_max            943.2180227585708
total_rewards_min            -299.78024422780254
Number of train steps total  1312000
Number of env steps total    1984161
Number of rollouts total     0
Train Time (s)               144.23100022692233
(Previous) Eval Time (s)     16.98962543392554
Sample Time (s)              11.882729331962764
Epoch Time (s)               173.10335499281064
Total Train Time (s)         60607.997451334726
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:46:01.189713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #327 | Epoch Duration: 173.20164608955383
2020-01-12 18:46:01.189891 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3861634
Z variance train             0.10072454
KL Divergence                24.059666
KL Loss                      2.4059665
QF Loss                      2815.9836
VF Loss                      266.267
Policy Loss                  -2189.4749
Q Predictions Mean           2180.5278
Q Predictions Std            257.49765
Q Predictions Max            2957.9536
Q Predictions Min            810.3203
V Predictions Mean           2183.5537
V Predictions Std            247.02258
V Predictions Max            2957.4568
V Predictions Min            1440.3163
Log Pis Mean                 1.1753213
Log Pis Std                  2.8427353
Log Pis Max                  11.171413
Log Pis Min                  -8.007212
Policy mu Mean               0.053433333
Policy mu Std                0.74832195
Policy mu Max                2.6079326
Policy mu Min                -2.5627494
Policy log std Mean          -1.0320431
Policy log std Std           0.24041659
Policy log std Max           -0.36364168
Policy log std Min           -2.2867215
Z mean eval                  1.4148248
Z variance eval              0.036942173
total_rewards                [-304.37302985  139.70750809  169.31792004  151.33817797  176.36449398
  -49.63136549  -46.99007918  511.66595097  122.89951758 -106.2199199 ]
total_rewards_mean           76.4079174209567
total_rewards_std            207.19942464395524
total_rewards_max            511.6659509652572
total_rewards_min            -304.3730298514408
Number of train steps total  1316000
Number of env steps total    1995900
Number of rollouts total     0
Train Time (s)               146.92609975626692
(Previous) Eval Time (s)     26.65702383313328
Sample Time (s)              12.139623035211116
Epoch Time (s)               185.72274662461132
Total Train Time (s)         60793.809568865225
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:49:07.006074 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #328 | Epoch Duration: 185.81601905822754
2020-01-12 18:49:07.006366 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #328 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4120858
Z variance train             0.037304107
KL Divergence                24.933762
KL Loss                      2.4933763
QF Loss                      983.51794
VF Loss                      305.97345
Policy Loss                  -1911.882
Q Predictions Mean           1908.3533
Q Predictions Std            249.5635
Q Predictions Max            2505.4062
Q Predictions Min            103.66696
V Predictions Mean           1912.7163
V Predictions Std            245.88753
V Predictions Max            2524.4353
V Predictions Min            203.24167
Log Pis Mean                 0.60984313
Log Pis Std                  2.898901
Log Pis Max                  22.04485
Log Pis Min                  -6.6028023
Policy mu Mean               -0.018440975
Policy mu Std                0.76904535
Policy mu Max                10.9977255
Policy mu Min                -5.532728
Policy log std Mean          -0.97369814
Policy log std Std           0.24113135
Policy log std Max           2.0
Policy log std Min           -1.9452858
Z mean eval                  1.1792623
Z variance eval              0.030163089
total_rewards                [ 192.28819981 1634.18752367  -39.93917416 -161.72883824 1297.1986607
  668.9933573   392.73777929 1532.51324919  715.56554866  482.66820075]
total_rewards_mean           671.4484506973314
total_rewards_std            600.4151643428085
total_rewards_max            1634.1875236741896
total_rewards_min            -161.7288382376796
Number of train steps total  1320000
Number of env steps total    2008030
Number of rollouts total     0
Train Time (s)               156.19717214489356
(Previous) Eval Time (s)     28.433223966974765
Sample Time (s)              12.380513921380043
Epoch Time (s)               197.01091003324836
Total Train Time (s)         60990.911891299766
Epoch                        329
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:52:24.111798 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #329 | Epoch Duration: 197.1052589416504
2020-01-12 18:52:24.111990 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1882333
Z variance train             0.030447554
KL Divergence                22.707825
KL Loss                      2.2707825
QF Loss                      1998.3512
VF Loss                      693.2447
Policy Loss                  -1698.403
Q Predictions Mean           1697.0154
Q Predictions Std            187.61089
Q Predictions Max            2043.447
Q Predictions Min            896.3644
V Predictions Mean           1709.0812
V Predictions Std            183.58757
V Predictions Max            2049.1772
V Predictions Min            789.2833
Log Pis Mean                 0.26998472
Log Pis Std                  2.399108
Log Pis Max                  11.138495
Log Pis Min                  -7.7739873
Policy mu Mean               0.08093317
Policy mu Std                0.6305301
Policy mu Max                2.2179275
Policy mu Min                -2.2854867
Policy log std Mean          -1.0063239
Policy log std Std           0.20537253
Policy log std Max           -0.37355608
Policy log std Min           -2.0717974
Z mean eval                  1.1296539
Z variance eval              0.02860567
total_rewards                [2412.30420717  297.8839778  1737.72008138 1786.78503492   95.78722951
 2606.43469431 1505.50788542 1282.6177979  2464.80318403  248.36869643]
total_rewards_mean           1443.821278885957
total_rewards_std            901.4044932056643
total_rewards_max            2606.434694310523
total_rewards_min            95.7872295050162
Number of train steps total  1324000
Number of env steps total    2018962
Number of rollouts total     0
Train Time (s)               155.0573328831233
(Previous) Eval Time (s)     33.30829914705828
Sample Time (s)              13.374270870815963
Epoch Time (s)               201.73990290099755
Total Train Time (s)         61192.74025470996
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:55:45.950021 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #330 | Epoch Duration: 201.83786416053772
2020-01-12 18:55:45.950430 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1209881
Z variance train             0.028220687
KL Divergence                20.931686
KL Loss                      2.0931687
QF Loss                      1079.1083
VF Loss                      269.85928
Policy Loss                  -1568.8525
Q Predictions Mean           1568.0266
Q Predictions Std            212.87796
Q Predictions Max            1884.4386
Q Predictions Min            -60.200455
V Predictions Mean           1576.0508
V Predictions Std            206.4254
V Predictions Max            1878.3431
V Predictions Min            65.499245
Log Pis Mean                 0.069856524
Log Pis Std                  2.5617542
Log Pis Max                  16.703163
Log Pis Min                  -9.268141
Policy mu Mean               0.0024718153
Policy mu Std                0.61726516
Policy mu Max                2.6555247
Policy mu Min                -2.335024
Policy log std Mean          -0.998894
Policy log std Std           0.21974169
Policy log std Max           -0.38377655
Policy log std Min           -2.7996225
Z mean eval                  1.2716177
Z variance eval              0.054341156
total_rewards                [2652.6064687   847.75211063 1334.26840256  839.29720044 1108.25584463
  797.82487217 1433.12437086 1416.92890027 2922.95578427  629.96275186]
total_rewards_mean           1398.297670638784
total_rewards_std            745.2613650638881
total_rewards_max            2922.9557842691684
total_rewards_min            629.9627518613786
Number of train steps total  1328000
Number of env steps total    2027328
Number of rollouts total     0
Train Time (s)               154.75381695711985
(Previous) Eval Time (s)     26.21646440308541
Sample Time (s)              12.039162663277239
Epoch Time (s)               193.0094440234825
Total Train Time (s)         61385.84941241145
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:58:59.057128 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #331 | Epoch Duration: 193.10636854171753
2020-01-12 18:58:59.057312 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2711265
Z variance train             0.054646276
KL Divergence                19.58432
KL Loss                      1.9584321
QF Loss                      6250.953
VF Loss                      128.13939
Policy Loss                  -1451.4568
Q Predictions Mean           1447.4781
Q Predictions Std            185.2005
Q Predictions Max            1780.4437
Q Predictions Min            856.14154
V Predictions Mean           1457.7471
V Predictions Std            183.00127
V Predictions Max            1796.5104
V Predictions Min            875.30786
Log Pis Mean                 0.38884762
Log Pis Std                  2.4796627
Log Pis Max                  9.392909
Log Pis Min                  -7.18613
Policy mu Mean               -0.02549319
Policy mu Std                0.6732537
Policy mu Max                2.1811533
Policy mu Min                -2.3807764
Policy log std Mean          -0.96283185
Policy log std Std           0.19836488
Policy log std Max           -0.40259707
Policy log std Min           -1.9557233
Z mean eval                  1.225997
Z variance eval              0.13595384
total_rewards                [2227.83268376 1368.22114539 2403.35059221  321.59521961 1111.95158122
 2880.0714423  1849.80509015 2797.07217073 2895.02435949  112.48714458]
total_rewards_mean           1796.741142943408
total_rewards_std            979.9212523311987
total_rewards_max            2895.024359491789
total_rewards_min            112.48714457795106
Number of train steps total  1332000
Number of env steps total    2038733
Number of rollouts total     0
Train Time (s)               155.066851596348
(Previous) Eval Time (s)     31.15353419072926
Sample Time (s)              10.679881270043552
Epoch Time (s)               196.9002670571208
Total Train Time (s)         61582.83724723151
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:02:16.047710 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #332 | Epoch Duration: 196.9902582168579
2020-01-12 19:02:16.047903 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2222011
Z variance train             0.13538532
KL Divergence                17.596815
KL Loss                      1.7596816
QF Loss                      1319.2026
VF Loss                      468.63354
Policy Loss                  -1384.6808
Q Predictions Mean           1380.5286
Q Predictions Std            220.56181
Q Predictions Max            1715.1744
Q Predictions Min            787.7792
V Predictions Mean           1392.7994
V Predictions Std            221.67244
V Predictions Max            1721.154
V Predictions Min            793.5081
Log Pis Mean                 0.027879488
Log Pis Std                  2.3039644
Log Pis Max                  8.146363
Log Pis Min                  -7.106935
Policy mu Mean               -0.004601561
Policy mu Std                0.6209308
Policy mu Max                1.822417
Policy mu Min                -2.4003184
Policy log std Mean          -0.9576603
Policy log std Std           0.1911495
Policy log std Max           -0.39268404
Policy log std Min           -1.6699022
Z mean eval                  1.122215
Z variance eval              0.054073226
total_rewards                [ 231.66663036 1656.65551257  534.3932257   604.16997188  707.44152385
  115.93984049 1926.85458603  113.59648805 1088.01212868  941.90302741]
total_rewards_mean           792.0632935028614
total_rewards_std            590.3957824782149
total_rewards_max            1926.8545860297272
total_rewards_min            113.59648805325517
Number of train steps total  1336000
Number of env steps total    2048806
Number of rollouts total     0
Train Time (s)               145.97132091689855
(Previous) Eval Time (s)     24.19625486107543
Sample Time (s)              11.970035036094487
Epoch Time (s)               182.13761081406847
Total Train Time (s)         61765.091523405164
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:05:18.306630 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #333 | Epoch Duration: 182.25855827331543
2020-01-12 19:05:18.306999 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1266239
Z variance train             0.05395568
KL Divergence                18.714352
KL Loss                      1.8714352
QF Loss                      436.3711
VF Loss                      857.649
Policy Loss                  -1245.6755
Q Predictions Mean           1240.7107
Q Predictions Std            264.63013
Q Predictions Max            1646.4956
Q Predictions Min            202.23006
V Predictions Mean           1239.7795
V Predictions Std            264.83047
V Predictions Max            1625.2767
V Predictions Min            -135.63536
Log Pis Mean                 0.050369665
Log Pis Std                  2.4514816
Log Pis Max                  12.599258
Log Pis Min                  -6.450273
Policy mu Mean               -0.0045799743
Policy mu Std                0.6350779
Policy mu Max                1.998552
Policy mu Min                -2.6111622
Policy log std Mean          -0.967299
Policy log std Std           0.2071231
Policy log std Max           -0.045988083
Policy log std Min           -2.5288997
Z mean eval                  1.2182274
Z variance eval              0.4833538
total_rewards                [ 521.3869255   942.0497634   405.94165335  249.84919855 1767.57392259
  428.87420681 1334.15860786 2552.89657081 1397.22610714 2898.73452221]
total_rewards_mean           1249.8691478228232
total_rewards_std            878.9311598751195
total_rewards_max            2898.734522214219
total_rewards_min            249.8491985528303
Number of train steps total  1340000
Number of env steps total    2059355
Number of rollouts total     0
Train Time (s)               145.22537313122302
(Previous) Eval Time (s)     24.142613308038563
Sample Time (s)              11.895266279112548
Epoch Time (s)               181.26325271837413
Total Train Time (s)         61946.4416283248
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:08:19.662215 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #334 | Epoch Duration: 181.35486388206482
2020-01-12 19:08:19.662471 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #334 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2132056
Z variance train             0.4785861
KL Divergence                17.293802
KL Loss                      1.7293802
QF Loss                      16086.309
VF Loss                      361.67514
Policy Loss                  -1239.5847
Q Predictions Mean           1234.5553
Q Predictions Std            257.34372
Q Predictions Max            1591.1553
Q Predictions Min            618.2622
V Predictions Mean           1248.0522
V Predictions Std            256.40027
V Predictions Max            1601.4644
V Predictions Min            618.9964
Log Pis Mean                 -0.19984698
Log Pis Std                  2.6543438
Log Pis Max                  8.918297
Log Pis Min                  -6.6948814
Policy mu Mean               -0.051542178
Policy mu Std                0.64265984
Policy mu Max                2.3935263
Policy mu Min                -2.2477968
Policy log std Mean          -0.90229535
Policy log std Std           0.21004356
Policy log std Max           -0.32194078
Policy log std Min           -1.8129966
Z mean eval                  1.0373015
Z variance eval              0.11092244
total_rewards                [1698.5609815  3101.63778464  991.61688333 2313.83394208  516.5839375
  597.49344237 3136.32931816 3014.85137752  674.45352524 1265.8661971 ]
total_rewards_mean           1731.122738942328
total_rewards_std            1023.7964212791643
total_rewards_max            3136.329318155126
total_rewards_min            516.5839374991255
Number of train steps total  1344000
Number of env steps total    2071059
Number of rollouts total     0
Train Time (s)               151.29030657093972
(Previous) Eval Time (s)     24.688588007818907
Sample Time (s)              11.7950129234232
Epoch Time (s)               187.77390750218183
Total Train Time (s)         62134.305890669115
Epoch                        335
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:11:27.528730 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #335 | Epoch Duration: 187.86607336997986
2020-01-12 19:11:27.528939 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0282261
Z variance train             0.110424854
KL Divergence                17.030376
KL Loss                      1.7030376
QF Loss                      3944.1467
VF Loss                      89.80071
Policy Loss                  -1101.9886
Q Predictions Mean           1097.7133
Q Predictions Std            280.26633
Q Predictions Max            1517.1571
Q Predictions Min            502.30862
V Predictions Mean           1100.669
V Predictions Std            275.74057
V Predictions Max            1494.468
V Predictions Min            522.0986
Log Pis Mean                 -0.2558037
Log Pis Std                  2.8706396
Log Pis Max                  20.512321
Log Pis Min                  -7.6930103
Policy mu Mean               0.069409415
Policy mu Std                0.6312177
Policy mu Max                3.7111504
Policy mu Min                -2.23212
Policy log std Mean          -0.9124168
Policy log std Std           0.21034484
Policy log std Max           -0.21589142
Policy log std Min           -2.472507
Z mean eval                  1.1660681
Z variance eval              0.06213841
total_rewards                [ 154.597428   3044.97048213 2918.26061882 1158.28673655  233.43416727
 2167.28129885 1282.01579191 2982.20296109 2998.61789716 1045.43832599]
total_rewards_mean           1798.5105707767682
total_rewards_std            1103.6559876376612
total_rewards_max            3044.970482127466
total_rewards_min            154.59742800324867
Number of train steps total  1348000
Number of env steps total    2082279
Number of rollouts total     0
Train Time (s)               154.60706338193268
(Previous) Eval Time (s)     21.56496499525383
Sample Time (s)              11.267354012001306
Epoch Time (s)               187.4393823891878
Total Train Time (s)         62321.83821318485
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:14:35.065202 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #336 | Epoch Duration: 187.5360996723175
2020-01-12 19:14:35.065463 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1699047
Z variance train             0.061753374
KL Divergence                17.772278
KL Loss                      1.7772278
QF Loss                      12851.748
VF Loss                      144.03743
Policy Loss                  -1110.0568
Q Predictions Mean           1105.4592
Q Predictions Std            297.9744
Q Predictions Max            1473.1638
Q Predictions Min            -184.75723
V Predictions Mean           1115.8232
V Predictions Std            295.06674
V Predictions Max            1492.7703
V Predictions Min            -71.32197
Log Pis Mean                 -0.19598372
Log Pis Std                  3.377337
Log Pis Max                  28.507927
Log Pis Min                  -8.836941
Policy mu Mean               0.039776467
Policy mu Std                0.63223505
Policy mu Max                5.006557
Policy mu Min                -3.3857782
Policy log std Mean          -0.9470116
Policy log std Std           0.21841228
Policy log std Max           -0.21620429
Policy log std Min           -2.720397
Z mean eval                  1.139856
Z variance eval              0.044395156
total_rewards                [3097.27571311 1226.37364716  305.51298403 1725.94084104 1385.24804724
  449.46441633 1382.53094966  389.42393875 1023.84966637 1025.77456881]
total_rewards_mean           1201.13947724964
total_rewards_std            776.2997840833646
total_rewards_max            3097.2757131107296
total_rewards_min            305.5129840284609
Number of train steps total  1352000
Number of env steps total    2093325
Number of rollouts total     0
Train Time (s)               154.9100159071386
(Previous) Eval Time (s)     24.57879181811586
Sample Time (s)              12.740956163965166
Epoch Time (s)               192.2297638892196
Total Train Time (s)         62514.17183020385
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:17:47.402349 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #337 | Epoch Duration: 192.33670687675476
2020-01-12 19:17:47.402589 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1343832
Z variance train             0.04434942
KL Divergence                16.778976
KL Loss                      1.6778977
QF Loss                      319.38544
VF Loss                      72.81346
Policy Loss                  -1112.0128
Q Predictions Mean           1107.9233
Q Predictions Std            266.4179
Q Predictions Max            1454.5264
Q Predictions Min            446.04382
V Predictions Mean           1109.9854
V Predictions Std            265.97534
V Predictions Max            1457.4357
V Predictions Min            445.1164
Log Pis Mean                 -0.40705138
Log Pis Std                  2.6655285
Log Pis Max                  7.1741705
Log Pis Min                  -8.124761
Policy mu Mean               0.0403626
Policy mu Std                0.6169504
Policy mu Max                2.5988495
Policy mu Min                -2.6155198
Policy log std Mean          -0.91689795
Policy log std Std           0.20499563
Policy log std Max           -0.36865425
Policy log std Min           -1.8467398
Z mean eval                  0.9920209
Z variance eval              0.13386653
total_rewards                [  51.39180669 2419.74222933 2680.11156761 2810.5384031   682.35767015
 2671.34761749  993.22453521 1939.89027478  654.19422231 2948.13175327]
total_rewards_mean           1785.0930079944083
total_rewards_std            1026.8971460958307
total_rewards_max            2948.1317532688627
total_rewards_min            51.39180668541072
Number of train steps total  1356000
Number of env steps total    2103742
Number of rollouts total     0
Train Time (s)               155.78221913799644
(Previous) Eval Time (s)     29.052906896919012
Sample Time (s)              12.41004431527108
Epoch Time (s)               197.24517035018653
Total Train Time (s)         62711.50931305159
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:21:04.743979 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #338 | Epoch Duration: 197.34123468399048
2020-01-12 19:21:04.744191 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9925116
Z variance train             0.13529266
KL Divergence                15.681095
KL Loss                      1.5681095
QF Loss                      8530.499
VF Loss                      104.23615
Policy Loss                  -1099.1437
Q Predictions Mean           1096.4644
Q Predictions Std            276.7569
Q Predictions Max            1438.0244
Q Predictions Min            432.40234
V Predictions Mean           1103.5688
V Predictions Std            280.3825
V Predictions Max            1439.8186
V Predictions Min            427.17596
Log Pis Mean                 0.03849694
Log Pis Std                  2.5673273
Log Pis Max                  8.610442
Log Pis Min                  -8.030345
Policy mu Mean               -0.017109588
Policy mu Std                0.62357557
Policy mu Max                2.846597
Policy mu Min                -2.170761
Policy log std Mean          -0.914984
Policy log std Std           0.21050534
Policy log std Max           -0.3047757
Policy log std Min           -2.034986
Z mean eval                  1.1469705
Z variance eval              0.051059045
total_rewards                [1540.82353804 2309.07407257 2733.82224301 3241.99345776 3207.81832257
 3186.67889659 3028.45175165  769.11955241 1291.37890906 1201.65707081]
total_rewards_mean           2251.0817814475818
total_rewards_std            913.0333453960558
total_rewards_max            3241.9934577611107
total_rewards_min            769.1195524117365
Number of train steps total  1360000
Number of env steps total    2114154
Number of rollouts total     0
Train Time (s)               153.35119965299964
(Previous) Eval Time (s)     26.073352369945496
Sample Time (s)              11.445613254792988
Epoch Time (s)               190.87016527773812
Total Train Time (s)         62902.46955805784
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:24:15.707548 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #339 | Epoch Duration: 190.96321177482605
2020-01-12 19:24:15.707747 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1482829
Z variance train             0.050870627
KL Divergence                19.223183
KL Loss                      1.9223183
QF Loss                      13225.365
VF Loss                      228.16371
Policy Loss                  -1101.216
Q Predictions Mean           1096.4645
Q Predictions Std            303.29315
Q Predictions Max            1497.4371
Q Predictions Min            432.8503
V Predictions Mean           1109.9342
V Predictions Std            304.43478
V Predictions Max            1506.8422
V Predictions Min            446.7641
Log Pis Mean                 -0.3418768
Log Pis Std                  2.8692107
Log Pis Max                  11.382925
Log Pis Min                  -8.821535
Policy mu Mean               0.02057055
Policy mu Std                0.64782786
Policy mu Max                2.4433658
Policy mu Min                -2.3976746
Policy log std Mean          -0.90599597
Policy log std Std           0.21916315
Policy log std Max           -0.3080731
Policy log std Min           -2.0374234
Z mean eval                  1.2461016
Z variance eval              0.22764933
total_rewards                [1011.20688531  100.22469272  212.87046564  125.52514402 3057.17105292
 1153.13056071 1183.69785125 2669.0575301  2869.16325666 1876.61213326]
total_rewards_mean           1425.8659572595438
total_rewards_std            1082.4741105962537
total_rewards_max            3057.171052921316
total_rewards_min            100.2246927193884
Number of train steps total  1364000
Number of env steps total    2124941
Number of rollouts total     0
Train Time (s)               145.84985592216253
(Previous) Eval Time (s)     18.655385673977435
Sample Time (s)              11.349499142263085
Epoch Time (s)               175.85474073840305
Total Train Time (s)         63078.41504433099
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:27:11.656931 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #340 | Epoch Duration: 175.94904112815857
2020-01-12 19:27:11.657114 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2681984
Z variance train             0.2275984
KL Divergence                17.046652
KL Loss                      1.7046652
QF Loss                      609.4907
VF Loss                      120.8654
Policy Loss                  -1066.6234
Q Predictions Mean           1060.0364
Q Predictions Std            285.78714
Q Predictions Max            1483.1571
Q Predictions Min            111.31125
V Predictions Mean           1062.5203
V Predictions Std            291.96503
V Predictions Max            1469.0358
V Predictions Min            -96.32096
Log Pis Mean                 -0.16265552
Log Pis Std                  3.4430184
Log Pis Max                  32.29221
Log Pis Min                  -8.27111
Policy mu Mean               -0.026790533
Policy mu Std                0.64170647
Policy mu Max                4.5704536
Policy mu Min                -3.911483
Policy log std Mean          -0.92994475
Policy log std Std           0.26056218
Policy log std Max           2.0
Policy log std Min           -1.774481
Z mean eval                  1.2904537
Z variance eval              0.1199619
total_rewards                [ 703.93723138  137.120356   3131.94814559  900.53932328 1491.78689886
  264.18220653 3000.11048274  806.19021117  819.64647878 1489.42006533]
total_rewards_mean           1274.488139966378
total_rewards_std            986.2666031225582
total_rewards_max            3131.948145592197
total_rewards_min            137.12035599662056
Number of train steps total  1368000
Number of env steps total    2135025
Number of rollouts total     0
Train Time (s)               144.74875654978678
(Previous) Eval Time (s)     21.179621427785605
Sample Time (s)              11.723892621695995
Epoch Time (s)               177.65227059926838
Total Train Time (s)         63256.15787223913
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:30:09.403464 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #341 | Epoch Duration: 177.74620723724365
2020-01-12 19:30:09.403655 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2909353
Z variance train             0.12169148
KL Divergence                15.325059
KL Loss                      1.5325059
QF Loss                      942.27045
VF Loss                      126.46101
Policy Loss                  -1005.6851
Q Predictions Mean           1002.3135
Q Predictions Std            305.52335
Q Predictions Max            1395.3738
Q Predictions Min            398.20047
V Predictions Mean           1007.1031
V Predictions Std            307.44513
V Predictions Max            1400.7382
V Predictions Min            390.6891
Log Pis Mean                 -0.4596801
Log Pis Std                  3.0640535
Log Pis Max                  12.87546
Log Pis Min                  -10.30134
Policy mu Mean               0.058880538
Policy mu Std                0.6289819
Policy mu Max                4.000637
Policy mu Min                -2.3632843
Policy log std Mean          -0.9268764
Policy log std Std           0.23223044
Policy log std Max           -0.30863547
Policy log std Min           -2.1773648
Z mean eval                  1.2435051
Z variance eval              0.07521473
total_rewards                [3015.21431193  387.96232653  357.2755676   242.11798179 2985.09583456
  282.30849295 1457.50699075 2815.45047301 1265.54168254  385.93787994]
total_rewards_mean           1319.4411541597617
total_rewards_std            1131.8646777436168
total_rewards_max            3015.2143119274583
total_rewards_min            242.11798178621686
Number of train steps total  1372000
Number of env steps total    2147005
Number of rollouts total     0
Train Time (s)               152.35868421429768
(Previous) Eval Time (s)     25.24386825505644
Sample Time (s)              12.913728238549083
Epoch Time (s)               190.5162807079032
Total Train Time (s)         63447.023114404175
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:33:20.272633 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #342 | Epoch Duration: 190.8688235282898
2020-01-12 19:33:20.272852 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2473419
Z variance train             0.07566033
KL Divergence                16.69371
KL Loss                      1.669371
QF Loss                      335.8734
VF Loss                      68.784935
Policy Loss                  -1076.6656
Q Predictions Mean           1072.9319
Q Predictions Std            308.28342
Q Predictions Max            1442.088
Q Predictions Min            125.79235
V Predictions Mean           1079.4075
V Predictions Std            308.41483
V Predictions Max            1455.9578
V Predictions Min            156.28886
Log Pis Mean                 -0.39354196
Log Pis Std                  2.8684282
Log Pis Max                  12.449972
Log Pis Min                  -10.051002
Policy mu Mean               -0.008521595
Policy mu Std                0.6172612
Policy mu Max                1.8200343
Policy mu Min                -2.1227012
Policy log std Mean          -0.9100368
Policy log std Std           0.21436077
Policy log std Max           -0.35923934
Policy log std Min           -2.5537858
Z mean eval                  1.182569
Z variance eval              0.05160706
total_rewards                [ 481.40383523 2922.620206   2831.83290595  464.70497855 1407.64175177
 2348.43502192 2499.61690022 1354.67927543   77.77710074  893.9335621 ]
total_rewards_mean           1528.2645537901901
total_rewards_std            1001.886760726556
total_rewards_max            2922.62020599811
total_rewards_min            77.77710073717334
Number of train steps total  1376000
Number of env steps total    2157487
Number of rollouts total     0
Train Time (s)               154.25871644215658
(Previous) Eval Time (s)     24.491683477070183
Sample Time (s)              12.218645930755883
Epoch Time (s)               190.96904584998265
Total Train Time (s)         63638.093734912574
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:36:31.347109 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #343 | Epoch Duration: 191.07407879829407
2020-01-12 19:36:31.347544 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1841538
Z variance train             0.05188351
KL Divergence                16.259045
KL Loss                      1.6259044
QF Loss                      1104.0046
VF Loss                      170.03502
Policy Loss                  -1091.3611
Q Predictions Mean           1085.0952
Q Predictions Std            283.1911
Q Predictions Max            1418.3953
Q Predictions Min            117.33065
V Predictions Mean           1087.4294
V Predictions Std            285.0522
V Predictions Max            1425.635
V Predictions Min            89.22546
Log Pis Mean                 -0.19634886
Log Pis Std                  3.3994706
Log Pis Max                  27.405865
Log Pis Min                  -7.0177827
Policy mu Mean               0.06572862
Policy mu Std                0.6394694
Policy mu Max                4.3931108
Policy mu Min                -2.6787052
Policy log std Mean          -0.91854525
Policy log std Std           0.24917386
Policy log std Max           0.39660704
Policy log std Min           -3.0009933
Z mean eval                  1.0974886
Z variance eval              0.048067518
total_rewards                [ 530.85306701 3357.21117071   36.51434103  166.55177331 1390.48985333
  350.13455247  639.14513199 1214.14548089 2366.71364477  617.012173  ]
total_rewards_mean           1066.8771188508672
total_rewards_std            1005.9933513716918
total_rewards_max            3357.2111707104773
total_rewards_min            36.514341030615135
Number of train steps total  1380000
Number of env steps total    2168287
Number of rollouts total     0
Train Time (s)               152.62860260810703
(Previous) Eval Time (s)     18.681319469120353
Sample Time (s)              12.349929504096508
Epoch Time (s)               183.6598515813239
Total Train Time (s)         63821.85457096947
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:39:35.112779 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #344 | Epoch Duration: 183.7649405002594
2020-01-12 19:39:35.113183 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0984263
Z variance train             0.047793675
KL Divergence                16.236044
KL Loss                      1.6236044
QF Loss                      495.79083
VF Loss                      74.70315
Policy Loss                  -1003.62213
Q Predictions Mean           999.8921
Q Predictions Std            301.41708
Q Predictions Max            1383.6238
Q Predictions Min            350.35852
V Predictions Mean           1005.04584
V Predictions Std            304.28998
V Predictions Max            1380.1755
V Predictions Min            344.07874
Log Pis Mean                 -0.42858186
Log Pis Std                  3.0368857
Log Pis Max                  18.78659
Log Pis Min                  -8.867646
Policy mu Mean               0.021726806
Policy mu Std                0.61276054
Policy mu Max                2.289562
Policy mu Min                -2.5354233
Policy log std Mean          -0.8997172
Policy log std Std           0.24496332
Policy log std Max           -0.28635585
Policy log std Min           -2.3465915
Z mean eval                  1.2803259
Z variance eval              0.018151429
total_rewards                [3052.73696872 3202.85255466 2068.89493753 3257.46569424 2711.69920186
  448.94532849 3141.96827566 3070.12051893  665.03921822 3022.81577188]
total_rewards_mean           2464.25384702126
total_rewards_std            1008.7401915827733
total_rewards_max            3257.4656942415036
total_rewards_min            448.94532849119446
Number of train steps total  1384000
Number of env steps total    2180462
Number of rollouts total     0
Train Time (s)               154.74058041907847
(Previous) Eval Time (s)     33.35705667408183
Sample Time (s)              12.024157613981515
Epoch Time (s)               200.12179470714182
Total Train Time (s)         64022.19639710989
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:42:55.458381 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #345 | Epoch Duration: 200.34494972229004
2020-01-12 19:42:55.458576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2810564
Z variance train             0.018195843
KL Divergence                17.447914
KL Loss                      1.7447914
QF Loss                      473.5284
VF Loss                      173.54733
Policy Loss                  -993.8183
Q Predictions Mean           989.5029
Q Predictions Std            301.6005
Q Predictions Max            1415.8003
Q Predictions Min            347.8409
V Predictions Mean           991.06537
V Predictions Std            299.31583
V Predictions Max            1389.9796
V Predictions Min            350.58502
Log Pis Mean                 -0.32980794
Log Pis Std                  2.7410936
Log Pis Max                  11.191424
Log Pis Min                  -6.920253
Policy mu Mean               -0.005897247
Policy mu Std                0.5842161
Policy mu Max                1.9319435
Policy mu Min                -2.5790782
Policy log std Mean          -0.942902
Policy log std Std           0.23691435
Policy log std Max           -0.30774063
Policy log std Min           -2.0053463
Z mean eval                  0.9614577
Z variance eval              0.11247082
total_rewards                [1178.28240812 1199.33610196  592.05509536 1531.81087532 3135.85613192
 1042.68536716 1263.51414802 3066.86733648 1123.3625566   207.24092935]
total_rewards_mean           1434.1010950285206
total_rewards_std            904.7150246337394
total_rewards_max            3135.856131915258
total_rewards_min            207.24092934734574
Number of train steps total  1388000
Number of env steps total    2190220
Number of rollouts total     0
Train Time (s)               150.17297364771366
(Previous) Eval Time (s)     19.678888389840722
Sample Time (s)              13.230647271033376
Epoch Time (s)               183.08250930858776
Total Train Time (s)         64205.379546939395
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:45:58.645150 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #346 | Epoch Duration: 183.18642473220825
2020-01-12 19:45:58.645363 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9629774
Z variance train             0.11042769
KL Divergence                16.247688
KL Loss                      1.6247689
QF Loss                      284.38034
VF Loss                      86.346825
Policy Loss                  -994.1537
Q Predictions Mean           989.77045
Q Predictions Std            306.99533
Q Predictions Max            1420.2627
Q Predictions Min            357.07422
V Predictions Mean           994.3401
V Predictions Std            309.8405
V Predictions Max            1402.8768
V Predictions Min            358.11548
Log Pis Mean                 -0.5468159
Log Pis Std                  2.9142544
Log Pis Max                  9.403638
Log Pis Min                  -9.4002
Policy mu Mean               -0.0003791079
Policy mu Std                0.6025455
Policy mu Max                2.8227155
Policy mu Min                -2.4429483
Policy log std Mean          -0.90842664
Policy log std Std           0.24319583
Policy log std Max           -0.2634915
Policy log std Min           -1.7564073
Z mean eval                  1.0917609
Z variance eval              0.076958224
total_rewards                [1275.52362084  948.34270639  237.62995414 1368.95362976 1929.04818874
  638.24594161 3301.87868651  746.34699133 1812.69394649 3140.94770214]
total_rewards_mean           1539.9611367954658
total_rewards_std            973.7272052694055
total_rewards_max            3301.8786865101097
total_rewards_min            237.6299541367234
Number of train steps total  1392000
Number of env steps total    2202336
Number of rollouts total     0
Train Time (s)               145.2760340468958
(Previous) Eval Time (s)     21.525639054365456
Sample Time (s)              11.038048027548939
Epoch Time (s)               177.8397211288102
Total Train Time (s)         64383.31633551838
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:48:56.586254 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #347 | Epoch Duration: 177.94073152542114
2020-01-12 19:48:56.586475 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0952985
Z variance train             0.078128755
KL Divergence                15.483388
KL Loss                      1.5483388
QF Loss                      349.57758
VF Loss                      89.21744
Policy Loss                  -1034.7076
Q Predictions Mean           1030.979
Q Predictions Std            301.94547
Q Predictions Max            1422.6189
Q Predictions Min            32.359303
V Predictions Mean           1033.5432
V Predictions Std            301.48093
V Predictions Max            1420.6041
V Predictions Min            32.923058
Log Pis Mean                 -0.35101166
Log Pis Std                  3.3310406
Log Pis Max                  25.842587
Log Pis Min                  -7.889675
Policy mu Mean               -0.0177194
Policy mu Std                0.62918055
Policy mu Max                5.6422563
Policy mu Min                -4.0816607
Policy log std Mean          -0.91000485
Policy log std Std           0.24365975
Policy log std Max           0.46032798
Policy log std Min           -2.2133894
Z mean eval                  1.0855954
Z variance eval              0.016899142
total_rewards                [1632.27411448  984.72714379 2565.2805585   940.0478812   829.21938529
 3305.70324358 3285.76230424  510.72133299  873.68343444  135.32808664]
total_rewards_mean           1506.2747485131736
total_rewards_std            1089.206586157265
total_rewards_max            3305.703243575743
total_rewards_min            135.32808663747085
Number of train steps total  1396000
Number of env steps total    2214524
Number of rollouts total     0
Train Time (s)               145.38460571598262
(Previous) Eval Time (s)     20.24320965912193
Sample Time (s)              12.161287159193307
Epoch Time (s)               177.78910253429785
Total Train Time (s)         64561.21632063016
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:51:54.490076 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #348 | Epoch Duration: 177.90343475341797
2020-01-12 19:51:54.490267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.084738
Z variance train             0.016902268
KL Divergence                19.380936
KL Loss                      1.9380935
QF Loss                      456.81436
VF Loss                      47.740036
Policy Loss                  -1029.0703
Q Predictions Mean           1022.96814
Q Predictions Std            291.77557
Q Predictions Max            1412.7333
Q Predictions Min            342.65622
V Predictions Mean           1029.3115
V Predictions Std            293.1402
V Predictions Max            1407.517
V Predictions Min            337.0841
Log Pis Mean                 -0.38926563
Log Pis Std                  2.743925
Log Pis Max                  9.644721
Log Pis Min                  -6.7434444
Policy mu Mean               -0.017951475
Policy mu Std                0.60211515
Policy mu Max                2.2102237
Policy mu Min                -2.3830972
Policy log std Mean          -0.9127596
Policy log std Std           0.2264982
Policy log std Max           -0.28976333
Policy log std Min           -2.5512614
Z mean eval                  1.1763881
Z variance eval              0.09161936
total_rewards                [1264.2062266  3319.35494348 1066.9070861  1512.06242443 3189.72454117
 3372.28229094 1364.78905297 3103.10069055  157.70076249 2752.84309795]
total_rewards_mean           2110.2971116691283
total_rewards_std            1102.2226336057654
total_rewards_max            3372.282290941268
total_rewards_min            157.70076249111864
Number of train steps total  1400000
Number of env steps total    2226348
Number of rollouts total     0
Train Time (s)               154.08954999269918
(Previous) Eval Time (s)     32.755193187855184
Sample Time (s)              12.816460023168474
Epoch Time (s)               199.66120320372283
Total Train Time (s)         64760.96933440771
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:55:14.245629 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #349 | Epoch Duration: 199.75523495674133
2020-01-12 19:55:14.245757 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1758776
Z variance train             0.09109914
KL Divergence                17.443558
KL Loss                      1.7443558
QF Loss                      985.4492
VF Loss                      471.70477
Policy Loss                  -1028.5352
Q Predictions Mean           1020.46515
Q Predictions Std            300.6303
Q Predictions Max            1398.1622
Q Predictions Min            13.746922
V Predictions Mean           1029.0696
V Predictions Std            295.49164
V Predictions Max            1382.2285
V Predictions Min            319.99692
Log Pis Mean                 -0.47933155
Log Pis Std                  2.9329607
Log Pis Max                  14.770815
Log Pis Min                  -10.590024
Policy mu Mean               0.014742364
Policy mu Std                0.6067743
Policy mu Max                2.870311
Policy mu Min                -3.8372474
Policy log std Mean          -0.90983266
Policy log std Std           0.2415599
Policy log std Max           -0.27709746
Policy log std Min           -2.0348654
Z mean eval                  1.0709194
Z variance eval              0.07584307
total_rewards                [1644.32888191 3276.97794271 3319.26313927  784.09253818 3149.69754886
 3155.06318815 3260.12409332 2002.53401731 1083.76329013 1142.04603571]
total_rewards_mean           2281.7890675555777
total_rewards_std            1000.0739621878738
total_rewards_max            3319.2631392686594
total_rewards_min            784.0925381823445
Number of train steps total  1404000
Number of env steps total    2235260
Number of rollouts total     0
Train Time (s)               153.73117669299245
(Previous) Eval Time (s)     33.825766512192786
Sample Time (s)              11.479712960775942
Epoch Time (s)               199.03665616596118
Total Train Time (s)         64960.104930278845
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:58:33.386071 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #350 | Epoch Duration: 199.14019966125488
2020-01-12 19:58:33.386284 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #350 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0712731
Z variance train             0.07563148
KL Divergence                15.976104
KL Loss                      1.5976104
QF Loss                      899.2602
VF Loss                      102.55065
Policy Loss                  -1014.90015
Q Predictions Mean           1010.7063
Q Predictions Std            306.30518
Q Predictions Max            1408.5906
Q Predictions Min            327.65485
V Predictions Mean           1009.5465
V Predictions Std            307.1518
V Predictions Max            1393.7152
V Predictions Min            319.74026
Log Pis Mean                 -0.53363776
Log Pis Std                  2.6377501
Log Pis Max                  7.729777
Log Pis Min                  -9.694672
Policy mu Mean               0.025116205
Policy mu Std                0.600956
Policy mu Max                2.0335746
Policy mu Min                -2.1344097
Policy log std Mean          -0.8974859
Policy log std Std           0.22400358
Policy log std Max           -0.3506531
Policy log std Min           -2.0339777
Z mean eval                  1.0361954
Z variance eval              0.15775865
total_rewards                [1963.22690202 3139.1989416  2942.70216911 2492.58209162 3282.6246846
 2962.37651083  427.82540132 3154.24687729 3325.61163028  720.45202218]
total_rewards_mean           2441.084723085275
total_rewards_std            1012.654745262471
total_rewards_max            3325.6116302842556
total_rewards_min            427.8254013209564
Number of train steps total  1408000
Number of env steps total    2245227
Number of rollouts total     0
Train Time (s)               153.60434939758852
(Previous) Eval Time (s)     37.87001624703407
Sample Time (s)              11.679640252143145
Epoch Time (s)               203.15400589676574
Total Train Time (s)         65163.371794687584
Epoch                        351
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:01:56.658115 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #351 | Epoch Duration: 203.27164888381958
2020-01-12 20:01:56.658447 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0355089
Z variance train             0.1586582
KL Divergence                14.060594
KL Loss                      1.4060594
QF Loss                      1456.864
VF Loss                      85.81682
Policy Loss                  -1042.8867
Q Predictions Mean           1037.0806
Q Predictions Std            273.82587
Q Predictions Max            1414.2031
Q Predictions Min            332.52167
V Predictions Mean           1040.6604
V Predictions Std            274.18234
V Predictions Max            1397.7959
V Predictions Min            329.9715
Log Pis Mean                 -0.10865853
Log Pis Std                  2.9574733
Log Pis Max                  16.545254
Log Pis Min                  -7.2794404
Policy mu Mean               0.032665677
Policy mu Std                0.6252188
Policy mu Max                3.362601
Policy mu Min                -2.7011561
Policy log std Mean          -0.9459413
Policy log std Std           0.2322852
Policy log std Max           -0.31926644
Policy log std Min           -2.0926197
Z mean eval                  1.0993131
Z variance eval              0.045321066
total_rewards                [3050.80680473 1057.83861811 3325.40502211 2948.13380932 3355.59612074
 3340.78682345 3184.52114946 1099.98881719 2988.31451881  113.74993722]
total_rewards_mean           2446.514162112757
total_rewards_std            1141.7940161138476
total_rewards_max            3355.5961207356077
total_rewards_min            113.74993722381367
Number of train steps total  1412000
Number of env steps total    2256899
Number of rollouts total     0
Train Time (s)               153.47885007597506
(Previous) Eval Time (s)     28.65166571130976
Sample Time (s)              11.551151175517589
Epoch Time (s)               193.6816669628024
Total Train Time (s)         65357.14741420839
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:05:10.439940 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #352 | Epoch Duration: 193.78125619888306
2020-01-12 20:05:10.440291 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.101082
Z variance train             0.04573582
KL Divergence                18.337667
KL Loss                      1.8337668
QF Loss                      352.86954
VF Loss                      91.38078
Policy Loss                  -1060.6835
Q Predictions Mean           1055.7908
Q Predictions Std            303.4276
Q Predictions Max            1417.2762
Q Predictions Min            313.27075
V Predictions Mean           1056.945
V Predictions Std            302.69113
V Predictions Max            1413.0676
V Predictions Min            325.18594
Log Pis Mean                 -0.05240669
Log Pis Std                  2.7738209
Log Pis Max                  9.393957
Log Pis Min                  -7.9944873
Policy mu Mean               0.01668171
Policy mu Std                0.60667247
Policy mu Max                1.8820826
Policy mu Min                -2.1462715
Policy log std Mean          -0.947067
Policy log std Std           0.2352083
Policy log std Max           -0.33417183
Policy log std Min           -1.880583
Z mean eval                  1.0499687
Z variance eval              0.029456442
total_rewards                [ 418.6063488    66.4851779  3301.71672911 1185.79043802 3280.53517093
 3350.78768182 1677.05830203  158.51082781  503.19191159 2220.0869285 ]
total_rewards_mean           1616.2769516506028
total_rewards_std            1279.5663104811265
total_rewards_max            3350.7876818192485
total_rewards_min            66.48517789672225
Number of train steps total  1416000
Number of env steps total    2268154
Number of rollouts total     0
Train Time (s)               146.35124565195292
(Previous) Eval Time (s)     29.848437692970037
Sample Time (s)              13.115340325515717
Epoch Time (s)               189.31502367043868
Total Train Time (s)         65546.55140787037
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:08:19.846711 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #353 | Epoch Duration: 189.40620112419128
2020-01-12 20:08:19.846919 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0438089
Z variance train             0.029485738
KL Divergence                17.376032
KL Loss                      1.7376032
QF Loss                      435.51428
VF Loss                      44.112827
Policy Loss                  -1050.8031
Q Predictions Mean           1046.3125
Q Predictions Std            290.39966
Q Predictions Max            1390.6467
Q Predictions Min            324.2672
V Predictions Mean           1053.3325
V Predictions Std            291.0563
V Predictions Max            1375.3698
V Predictions Min            334.39868
Log Pis Mean                 -0.4104619
Log Pis Std                  2.6911914
Log Pis Max                  8.830757
Log Pis Min                  -8.354654
Policy mu Mean               0.022216685
Policy mu Std                0.59019405
Policy mu Max                2.4454825
Policy mu Min                -2.2531316
Policy log std Mean          -0.938203
Policy log std Std           0.22923344
Policy log std Max           -0.24612051
Policy log std Min           -1.7598096
Z mean eval                  1.157496
Z variance eval              0.046232186
total_rewards                [3308.8926552   232.21682056  941.426682    394.12875574  384.19257632
 3326.31701555 3192.14683936  899.3036128  2684.75331871 1602.51185717]
total_rewards_mean           1696.589013340378
total_rewards_std            1234.7735022069264
total_rewards_max            3326.31701554576
total_rewards_min            232.21682056475981
Number of train steps total  1420000
Number of env steps total    2279041
Number of rollouts total     0
Train Time (s)               145.17302241595462
(Previous) Eval Time (s)     21.630457068793476
Sample Time (s)              11.511615421622992
Epoch Time (s)               178.3150949063711
Total Train Time (s)         65724.95260160649
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:11:18.259065 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #354 | Epoch Duration: 178.4119644165039
2020-01-12 20:11:18.259551 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1571944
Z variance train             0.046351165
KL Divergence                17.706833
KL Loss                      1.7706833
QF Loss                      241.16965
VF Loss                      98.05525
Policy Loss                  -1072.1731
Q Predictions Mean           1068.6067
Q Predictions Std            280.0009
Q Predictions Max            1403.0085
Q Predictions Min            330.90005
V Predictions Mean           1076.8237
V Predictions Std            280.48166
V Predictions Max            1423.4392
V Predictions Min            330.8858
Log Pis Mean                 -0.50397384
Log Pis Std                  2.4970455
Log Pis Max                  11.031864
Log Pis Min                  -6.515819
Policy mu Mean               0.062710114
Policy mu Std                0.57573366
Policy mu Max                2.7229345
Policy mu Min                -2.0287335
Policy log std Mean          -0.93789244
Policy log std Std           0.23421432
Policy log std Max           -0.25823098
Policy log std Min           -2.2747386
Z mean eval                  1.0576669
Z variance eval              0.046049222
total_rewards                [ 656.46841317  228.19339147 2609.37862271 3169.81755812  535.47949785
 2303.7006628   657.35045188   76.74998858 2406.33475776   85.98533827]
total_rewards_mean           1272.945868261154
total_rewards_std            1138.653897070583
total_rewards_max            3169.817558122019
total_rewards_min            76.74998858487876
Number of train steps total  1424000
Number of env steps total    2289256
Number of rollouts total     0
Train Time (s)               149.58068259386346
(Previous) Eval Time (s)     19.415047908201814
Sample Time (s)              10.267850821372122
Epoch Time (s)               179.2635813234374
Total Train Time (s)         65904.31124379346
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:14:17.614355 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #355 | Epoch Duration: 179.3544056415558
2020-01-12 20:14:17.614601 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0571059
Z variance train             0.045933675
KL Divergence                17.31347
KL Loss                      1.7313471
QF Loss                      11732.465
VF Loss                      65.45181
Policy Loss                  -1000.12634
Q Predictions Mean           995.68835
Q Predictions Std            314.32007
Q Predictions Max            1431.874
Q Predictions Min            295.68207
V Predictions Mean           1001.02576
V Predictions Std            311.0235
V Predictions Max            1422.2272
V Predictions Min            322.67365
Log Pis Mean                 -0.48202324
Log Pis Std                  2.697547
Log Pis Max                  11.939366
Log Pis Min                  -6.454962
Policy mu Mean               0.012985727
Policy mu Std                0.5975619
Policy mu Max                2.9119627
Policy mu Min                -2.1816566
Policy log std Mean          -0.8945868
Policy log std Std           0.23583485
Policy log std Max           -0.30471712
Policy log std Min           -2.03328
Z mean eval                  1.0606873
Z variance eval              0.059031866
total_rewards                [  80.04838297  303.26132271 3002.13823106 2119.32790008  438.85366062
 2023.37655796 3254.9911004  3347.11282718 3040.58041315  743.40835357]
total_rewards_mean           1835.309874970096
total_rewards_std            1257.0480623111769
total_rewards_max            3347.1128271826583
total_rewards_min            80.04838297325858
Number of train steps total  1428000
Number of env steps total    2299647
Number of rollouts total     0
Train Time (s)               156.34567295014858
(Previous) Eval Time (s)     24.41188055742532
Sample Time (s)              11.504998039919883
Epoch Time (s)               192.26255154749379
Total Train Time (s)         66096.66621657228
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:17:29.979262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #356 | Epoch Duration: 192.36444568634033
2020-01-12 20:17:29.979672 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #356 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0633239
Z variance train             0.05787327
KL Divergence                15.184028
KL Loss                      1.5184028
QF Loss                      342.26984
VF Loss                      589.16614
Policy Loss                  -1011.12964
Q Predictions Mean           1005.5973
Q Predictions Std            312.8895
Q Predictions Max            1389.5295
Q Predictions Min            48.37918
V Predictions Mean           1009.23505
V Predictions Std            312.70425
V Predictions Max            1383.0497
V Predictions Min            315.69388
Log Pis Mean                 -0.59622675
Log Pis Std                  2.5424192
Log Pis Max                  9.92817
Log Pis Min                  -6.4731894
Policy mu Mean               0.033670828
Policy mu Std                0.6173479
Policy mu Max                2.646952
Policy mu Min                -2.5266564
Policy log std Mean          -0.88759893
Policy log std Std           0.22645675
Policy log std Max           -0.3059684
Policy log std Min           -2.4815345
Z mean eval                  1.0217448
Z variance eval              0.097186185
total_rewards                [1.36170243e+00 3.45864121e+03 3.22994689e+03 5.41987588e+02
 1.13467556e+03 2.76967217e+03 5.64521316e+02 1.12168827e+02
 1.45740717e+03 3.92592306e+02]
total_rewards_mean           1366.29747411392
total_rewards_std            1248.5521046285671
total_rewards_max            3458.641211390782
total_rewards_min            1.361702431042903
Number of train steps total  1432000
Number of env steps total    2308255
Number of rollouts total     0
Train Time (s)               154.88049503182992
(Previous) Eval Time (s)     17.188914836850017
Sample Time (s)              13.173360304441303
Epoch Time (s)               185.24277017312124
Total Train Time (s)         66282.0133956573
Epoch                        357
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:20:35.324731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #357 | Epoch Duration: 185.3447449207306
2020-01-12 20:20:35.324930 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0144508
Z variance train             0.09472039
KL Divergence                14.854185
KL Loss                      1.4854186
QF Loss                      475.496
VF Loss                      204.3403
Policy Loss                  -1035.8223
Q Predictions Mean           1032.9573
Q Predictions Std            259.4449
Q Predictions Max            1393.1697
Q Predictions Min            -17.584362
V Predictions Mean           1035.8723
V Predictions Std            257.8683
V Predictions Max            1389.1919
V Predictions Min            31.609268
Log Pis Mean                 -0.22861154
Log Pis Std                  2.6030788
Log Pis Max                  8.191493
Log Pis Min                  -7.9484606
Policy mu Mean               0.014690239
Policy mu Std                0.61000335
Policy mu Max                2.0544205
Policy mu Min                -2.5454783
Policy log std Mean          -0.9648065
Policy log std Std           0.24351247
Policy log std Max           -0.4196269
Policy log std Min           -2.4200344
Z mean eval                  1.2042153
Z variance eval              0.049000204
total_rewards                [ 969.66222243  161.54497266 3520.4745356  1955.65684265 2815.72781293
  441.08867936 3572.82668966 1547.66097314  519.9232861  1407.50462949]
total_rewards_mean           1691.2070644020328
total_rewards_std            1188.1700125047214
total_rewards_max            3572.826689659154
total_rewards_min            161.54497265902097
Number of train steps total  1436000
Number of env steps total    2319500
Number of rollouts total     0
Train Time (s)               155.42966494895518
(Previous) Eval Time (s)     23.863879788201302
Sample Time (s)              12.413471192587167
Epoch Time (s)               191.70701592974365
Total Train Time (s)         66473.81699536834
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:23:47.131879 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #358 | Epoch Duration: 191.8067910671234
2020-01-12 20:23:47.132075 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2079194
Z variance train             0.047820795
KL Divergence                18.632877
KL Loss                      1.8632878
QF Loss                      735.35846
VF Loss                      103.053024
Policy Loss                  -1055.0037
Q Predictions Mean           1046.1038
Q Predictions Std            269.04706
Q Predictions Max            1355.8623
Q Predictions Min            19.208729
V Predictions Mean           1053.5016
V Predictions Std            263.58994
V Predictions Max            1366.2017
V Predictions Min            231.05046
Log Pis Mean                 -0.42239153
Log Pis Std                  2.881264
Log Pis Max                  12.266588
Log Pis Min                  -7.5448055
Policy mu Mean               -0.022872385
Policy mu Std                0.6100786
Policy mu Max                2.5033731
Policy mu Min                -2.7031322
Policy log std Mean          -0.97242117
Policy log std Std           0.23557901
Policy log std Max           -0.13299698
Policy log std Min           -1.9648559
Z mean eval                  1.0582718
Z variance eval              0.06587453
total_rewards                [3426.968673   1848.63711143 2374.14294768 2014.50831608 3290.24650581
 3200.86177436 3338.24283383 1277.54371119 3070.14780115 1330.25244603]
total_rewards_mean           2517.1552120555834
total_rewards_std            808.5956184332674
total_rewards_max            3426.9686729963546
total_rewards_min            1277.5437111857589
Number of train steps total  1440000
Number of env steps total    2330082
Number of rollouts total     0
Train Time (s)               153.58251582505181
(Previous) Eval Time (s)     29.65009194985032
Sample Time (s)              12.535317606758326
Epoch Time (s)               195.76792538166046
Total Train Time (s)         66669.67903835559
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:27:02.999243 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #359 | Epoch Duration: 195.86697816848755
2020-01-12 20:27:02.999549 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0615808
Z variance train             0.06419109
KL Divergence                17.239233
KL Loss                      1.7239233
QF Loss                      346.08524
VF Loss                      98.73128
Policy Loss                  -1073.7697
Q Predictions Mean           1068.8848
Q Predictions Std            286.44995
Q Predictions Max            1391.7527
Q Predictions Min            309.71494
V Predictions Mean           1071.0413
V Predictions Std            283.89825
V Predictions Max            1391.8184
V Predictions Min            330.1097
Log Pis Mean                 -0.33025783
Log Pis Std                  2.7879066
Log Pis Max                  12.652011
Log Pis Min                  -7.308745
Policy mu Mean               0.09746951
Policy mu Std                0.56302017
Policy mu Max                2.68267
Policy mu Min                -2.2240784
Policy log std Mean          -0.9519789
Policy log std Std           0.24170803
Policy log std Max           -0.28308308
Policy log std Min           -2.4054446
Z mean eval                  1.0666244
Z variance eval              0.025343072
total_rewards                [ 112.09262537  112.54239322  291.23617705  447.28960845 3193.12960408
 1475.22289334  658.5719486  3339.61672525 2648.60690807 3275.72974075]
total_rewards_mean           1555.40386241652
total_rewards_std            1334.9885888574813
total_rewards_max            3339.6167252523064
total_rewards_min            112.09262536511864
Number of train steps total  1444000
Number of env steps total    2340117
Number of rollouts total     0
Train Time (s)               145.43063986394554
(Previous) Eval Time (s)     24.917540574911982
Sample Time (s)              11.500901526305825
Epoch Time (s)               181.84908196516335
Total Train Time (s)         66851.62198818475
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:30:04.945834 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #360 | Epoch Duration: 181.94608306884766
2020-01-12 20:30:04.946043 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0695193
Z variance train             0.025366306
KL Divergence                19.107609
KL Loss                      1.9107609
QF Loss                      311.40442
VF Loss                      123.55563
Policy Loss                  -1038.5826
Q Predictions Mean           1033.8264
Q Predictions Std            300.05353
Q Predictions Max            1373.3385
Q Predictions Min            332.5037
V Predictions Mean           1037.395
V Predictions Std            299.11276
V Predictions Max            1365.5734
V Predictions Min            330.0475
Log Pis Mean                 -0.15025742
Log Pis Std                  3.0102754
Log Pis Max                  15.302868
Log Pis Min                  -7.302169
Policy mu Mean               0.022055201
Policy mu Std                0.5882564
Policy mu Max                3.4799101
Policy mu Min                -2.1960943
Policy log std Mean          -0.9431008
Policy log std Std           0.26522818
Policy log std Max           -0.10391021
Policy log std Min           -2.3029234
Z mean eval                  1.0709336
Z variance eval              0.023698095
total_rewards                [ 245.73747768  133.66200545  414.67038249  366.32569255 2159.32540005
  259.73896527  341.00867194  316.24865355 3546.74141946  386.09746455]
total_rewards_mean           816.9556132981068
total_rewards_std            1067.0112616568704
total_rewards_max            3546.741419464747
total_rewards_min            133.66200544857864
Number of train steps total  1448000
Number of env steps total    2350007
Number of rollouts total     0
Train Time (s)               144.7054669102654
(Previous) Eval Time (s)     18.615443627815694
Sample Time (s)              11.273317295126617
Epoch Time (s)               174.5942278332077
Total Train Time (s)         67026.56213308731
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:32:59.890178 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #361 | Epoch Duration: 174.94398641586304
2020-01-12 20:32:59.890377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0702112
Z variance train             0.023779135
KL Divergence                17.477615
KL Loss                      1.7477616
QF Loss                      246.12006
VF Loss                      72.372795
Policy Loss                  -1103.3092
Q Predictions Mean           1100.4485
Q Predictions Std            278.53156
Q Predictions Max            1417.9324
Q Predictions Min            320.20752
V Predictions Mean           1102.8945
V Predictions Std            277.103
V Predictions Max            1420.1539
V Predictions Min            322.95648
Log Pis Mean                 -0.40532282
Log Pis Std                  2.612609
Log Pis Max                  8.898451
Log Pis Min                  -11.165732
Policy mu Mean               -0.001887109
Policy mu Std                0.6084495
Policy mu Max                2.370725
Policy mu Min                -2.5927713
Policy log std Mean          -0.9435464
Policy log std Std           0.2223325
Policy log std Max           -0.26473993
Policy log std Min           -2.32888
Z mean eval                  1.078936
Z variance eval              0.09622575
total_rewards                [3344.01114574 1004.61917688 1831.82947164  978.19820988 1821.11946086
 3416.03280073 1675.29917426 2894.09123013  919.91781369 1241.316015  ]
total_rewards_mean           1912.6434498799827
total_rewards_std            920.7254374492402
total_rewards_max            3416.032800731266
total_rewards_min            919.9178136886565
Number of train steps total  1452000
Number of env steps total    2359116
Number of rollouts total     0
Train Time (s)               151.10973591031507
(Previous) Eval Time (s)     32.22817890532315
Sample Time (s)              11.349347701761872
Epoch Time (s)               194.6872625174001
Total Train Time (s)         67221.34712000843
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:36:14.679475 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #362 | Epoch Duration: 194.78894567489624
2020-01-12 20:36:14.679689 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0846837
Z variance train             0.09641611
KL Divergence                14.296548
KL Loss                      1.4296548
QF Loss                      404.41055
VF Loss                      168.30109
Policy Loss                  -1062.4438
Q Predictions Mean           1055.9056
Q Predictions Std            330.577
Q Predictions Max            1428.6451
Q Predictions Min            260.3527
V Predictions Mean           1059.4286
V Predictions Std            331.09607
V Predictions Max            1439.7661
V Predictions Min            219.09085
Log Pis Mean                 -0.58437145
Log Pis Std                  2.7850502
Log Pis Max                  8.356637
Log Pis Min                  -8.408097
Policy mu Mean               0.009269192
Policy mu Std                0.58677334
Policy mu Max                2.1987407
Policy mu Min                -2.2897112
Policy log std Mean          -0.92224085
Policy log std Std           0.22255209
Policy log std Max           -0.37174487
Policy log std Min           -1.9962893
Z mean eval                  1.0889356
Z variance eval              0.01200044
total_rewards                [2792.31732467 1767.95467236  512.53437519  876.61295728 2399.99111658
 3176.89343363  758.40662301  977.67820283 2415.4133921   483.97094953]
total_rewards_mean           1616.177304717989
total_rewards_std            963.6205156630107
total_rewards_max            3176.8934336252423
total_rewards_min            483.97094953241054
Number of train steps total  1456000
Number of env steps total    2368391
Number of rollouts total     0
Train Time (s)               155.2725290870294
(Previous) Eval Time (s)     19.178215401712805
Sample Time (s)              13.479633943643421
Epoch Time (s)               187.93037843238562
Total Train Time (s)         67409.37296712864
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:39:22.709798 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #363 | Epoch Duration: 188.0299482345581
2020-01-12 20:39:22.710034 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.086252
Z variance train             0.012047365
KL Divergence                20.295341
KL Loss                      2.029534
QF Loss                      317.6663
VF Loss                      198.42386
Policy Loss                  -1049.1694
Q Predictions Mean           1044.993
Q Predictions Std            304.2641
Q Predictions Max            1412.1993
Q Predictions Min            286.4904
V Predictions Mean           1051.1921
V Predictions Std            307.4681
V Predictions Max            1433.4064
V Predictions Min            308.85553
Log Pis Mean                 -0.17903261
Log Pis Std                  2.8363168
Log Pis Max                  9.260995
Log Pis Min                  -7.280485
Policy mu Mean               0.029456113
Policy mu Std                0.60848117
Policy mu Max                2.2413917
Policy mu Min                -2.4389975
Policy log std Mean          -0.94850934
Policy log std Std           0.24098217
Policy log std Max           -0.09711802
Policy log std Min           -2.0185313
Z mean eval                  1.1252847
Z variance eval              0.04688065
total_rewards                [3268.40323486  503.11086495 3517.66093533 3533.06232534 3216.99816603
  855.21763749  141.27623276 3302.64045074 3393.23925572 3317.03139184]
total_rewards_mean           2504.8640495061877
total_rewards_std            1325.6412132715259
total_rewards_max            3533.06232533929
total_rewards_min            141.27623275762096
Number of train steps total  1460000
Number of env steps total    2379231
Number of rollouts total     0
Train Time (s)               153.6303052417934
(Previous) Eval Time (s)     29.79254601476714
Sample Time (s)              13.025388181209564
Epoch Time (s)               196.4482394377701
Total Train Time (s)         67605.90842458745
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:42:39.248731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #364 | Epoch Duration: 196.53854656219482
2020-01-12 20:42:39.248922 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1260276
Z variance train             0.046744645
KL Divergence                16.214905
KL Loss                      1.6214905
QF Loss                      10707.1875
VF Loss                      129.14497
Policy Loss                  -1056.864
Q Predictions Mean           1052.5225
Q Predictions Std            295.63083
Q Predictions Max            1424.2579
Q Predictions Min            -44.508083
V Predictions Mean           1055.3799
V Predictions Std            294.12384
V Predictions Max            1415.2417
V Predictions Min            6.667878
Log Pis Mean                 -0.34254384
Log Pis Std                  2.6011457
Log Pis Max                  12.271285
Log Pis Min                  -7.406988
Policy mu Mean               0.013249055
Policy mu Std                0.5772961
Policy mu Max                2.2191825
Policy mu Min                -2.4051452
Policy log std Mean          -0.9680312
Policy log std Std           0.23118934
Policy log std Max           -0.20244253
Policy log std Min           -2.0426772
Z mean eval                  1.216258
Z variance eval              0.008883098
total_rewards                [1528.73063963  218.840984   3234.98388834 2186.82703707 3495.39231473
 1815.84576939  169.77367311 1159.34642602  562.85652108 1852.65206457]
total_rewards_mean           1622.5249317931516
total_rewards_std            1092.8617530667607
total_rewards_max            3495.3923147300093
total_rewards_min            169.77367310847404
Number of train steps total  1464000
Number of env steps total    2389984
Number of rollouts total     0
Train Time (s)               155.40376405837014
(Previous) Eval Time (s)     19.19995762826875
Sample Time (s)              11.499421161133796
Epoch Time (s)               186.1031428477727
Total Train Time (s)         67792.10999729345
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:45:45.455485 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #365 | Epoch Duration: 186.20639514923096
2020-01-12 20:45:45.455788 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.215242
Z variance train             0.008869898
KL Divergence                19.444979
KL Loss                      1.944498
QF Loss                      431.01025
VF Loss                      178.60797
Policy Loss                  -1076.1721
Q Predictions Mean           1072.5513
Q Predictions Std            284.88318
Q Predictions Max            1431.6729
Q Predictions Min            320.97763
V Predictions Mean           1086.5927
V Predictions Std            284.4308
V Predictions Max            1433.1866
V Predictions Min            331.5056
Log Pis Mean                 -0.18312716
Log Pis Std                  2.7864797
Log Pis Max                  9.758419
Log Pis Min                  -7.009043
Policy mu Mean               0.044579577
Policy mu Std                0.59825397
Policy mu Max                1.8836306
Policy mu Min                -2.4167674
Policy log std Mean          -0.9605945
Policy log std Std           0.22387245
Policy log std Max           -0.40304124
Policy log std Min           -1.9535542
Z mean eval                  1.0335815
Z variance eval              0.041554116
total_rewards                [ 785.86407833  567.48853383 3221.22583858 2993.22870616  139.64849513
 3593.48122413  826.26471856 1435.65226311  927.12433204  635.72807531]
total_rewards_mean           1512.5706265169933
total_rewards_std            1197.3625225029186
total_rewards_max            3593.4812241261607
total_rewards_min            139.64849513247285
Number of train steps total  1468000
Number of env steps total    2399931
Number of rollouts total     0
Train Time (s)               152.5060122050345
(Previous) Eval Time (s)     18.04951490694657
Sample Time (s)              11.972153502050787
Epoch Time (s)               182.52768061403185
Total Train Time (s)         67974.72643436026
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:48:48.075493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #366 | Epoch Duration: 182.61952710151672
2020-01-12 20:48:48.075693 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0323234
Z variance train             0.04353111
KL Divergence                16.6077
KL Loss                      1.66077
QF Loss                      455.62674
VF Loss                      91.93873
Policy Loss                  -1061.7267
Q Predictions Mean           1056.6893
Q Predictions Std            295.21484
Q Predictions Max            1439.8215
Q Predictions Min            -26.146187
V Predictions Mean           1060.9414
V Predictions Std            290.90338
V Predictions Max            1439.4503
V Predictions Min            92.00031
Log Pis Mean                 -0.014263719
Log Pis Std                  2.96922
Log Pis Max                  20.95632
Log Pis Min                  -7.8966584
Policy mu Mean               -0.037482455
Policy mu Std                0.6163016
Policy mu Max                2.7445478
Policy mu Min                -2.8961017
Policy log std Mean          -0.96342087
Policy log std Std           0.25548574
Policy log std Max           -0.17348158
Policy log std Min           -2.8067813
Z mean eval                  0.9325348
Z variance eval              0.052246798
total_rewards                [ 410.03256233 1299.72627272 2208.84733189  116.96855257 1526.1279458
 2442.14580606 1031.76392549 2107.20473229 3301.4776712  2571.87563503]
total_rewards_mean           1701.6170435389613
total_rewards_std            954.3263570533054
total_rewards_max            3301.477671197525
total_rewards_min            116.96855257457725
Number of train steps total  1472000
Number of env steps total    2408965
Number of rollouts total     0
Train Time (s)               144.88928426988423
(Previous) Eval Time (s)     21.328761484008282
Sample Time (s)              13.067757778335363
Epoch Time (s)               179.28580353222787
Total Train Time (s)         68154.09912722139
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:51:47.452267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #367 | Epoch Duration: 179.37642550468445
2020-01-12 20:51:47.452506 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94031125
Z variance train             0.052098304
KL Divergence                16.178268
KL Loss                      1.6178268
QF Loss                      1185.4725
VF Loss                      78.31975
Policy Loss                  -1067.5912
Q Predictions Mean           1061.9543
Q Predictions Std            314.17358
Q Predictions Max            1440.6615
Q Predictions Min            232.62985
V Predictions Mean           1067.9243
V Predictions Std            314.07693
V Predictions Max            1450.6819
V Predictions Min            312.22366
Log Pis Mean                 -0.3490817
Log Pis Std                  2.770562
Log Pis Max                  8.651562
Log Pis Min                  -6.8380384
Policy mu Mean               0.008284202
Policy mu Std                0.5876867
Policy mu Max                2.2850802
Policy mu Min                -3.0795293
Policy log std Mean          -0.9507227
Policy log std Std           0.23636705
Policy log std Max           -0.3235522
Policy log std Min           -2.1059113
Z mean eval                  1.0127599
Z variance eval              0.021298736
total_rewards                [1730.82325822  469.95888686  361.44507587  631.67460707  356.14179905
  141.06623937 1040.79901404 1065.03879594  959.02648041  942.17386309]
total_rewards_mean           769.8148019915809
total_rewards_std            446.3012248236655
total_rewards_max            1730.8232582205237
total_rewards_min            141.0662393691383
Number of train steps total  1476000
Number of env steps total    2420965
Number of rollouts total     0
Train Time (s)               145.9239089912735
(Previous) Eval Time (s)     8.393153077922761
Sample Time (s)              10.917748831678182
Epoch Time (s)               165.23481090087444
Total Train Time (s)         68319.42352980562
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:54:32.780287 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #368 | Epoch Duration: 165.32763671875
2020-01-12 20:54:32.780472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0114841
Z variance train             0.021356981
KL Divergence                17.623222
KL Loss                      1.7623223
QF Loss                      1249.7455
VF Loss                      80.2191
Policy Loss                  -1019.41266
Q Predictions Mean           1012.27264
Q Predictions Std            324.86786
Q Predictions Max            1406.7593
Q Predictions Min            314.57712
V Predictions Mean           1018.5963
V Predictions Std            324.26093
V Predictions Max            1396.5123
V Predictions Min            312.85318
Log Pis Mean                 -0.7026214
Log Pis Std                  2.8760955
Log Pis Max                  13.538151
Log Pis Min                  -6.945898
Policy mu Mean               0.014390072
Policy mu Std                0.58104897
Policy mu Max                2.9272997
Policy mu Min                -2.3232138
Policy log std Mean          -0.9239389
Policy log std Std           0.24930981
Policy log std Max           -0.25041378
Policy log std Min           -2.006406
Z mean eval                  1.1760724
Z variance eval              0.055644434
total_rewards                [ 709.79468876  279.52259289 1899.56350471  307.06371778 2101.24449847
  213.28856564 1208.44425461 2905.58820307 1787.27212204  967.89364927]
total_rewards_mean           1237.967579724744
total_rewards_std            863.3420099979353
total_rewards_max            2905.5882030685652
total_rewards_min            213.28856564154515
Number of train steps total  1480000
Number of env steps total    2432872
Number of rollouts total     0
Train Time (s)               153.97015423700213
(Previous) Eval Time (s)     15.592668309807777
Sample Time (s)              12.012938977219164
Epoch Time (s)               181.57576152402908
Total Train Time (s)         68501.09329182142
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:57:34.452854 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #369 | Epoch Duration: 181.67223572731018
2020-01-12 20:57:34.453056 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1741259
Z variance train             0.05645076
KL Divergence                16.167316
KL Loss                      1.6167316
QF Loss                      1080.9419
VF Loss                      72.72158
Policy Loss                  -985.2387
Q Predictions Mean           979.64624
Q Predictions Std            307.89667
Q Predictions Max            1323.198
Q Predictions Min            268.68643
V Predictions Mean           984.3386
V Predictions Std            306.43863
V Predictions Max            1317.7504
V Predictions Min            289.204
Log Pis Mean                 -0.2514834
Log Pis Std                  2.972864
Log Pis Max                  10.766664
Log Pis Min                  -7.7925053
Policy mu Mean               0.0067767594
Policy mu Std                0.6105659
Policy mu Max                2.0373285
Policy mu Min                -2.766641
Policy log std Mean          -0.9182256
Policy log std Std           0.25766677
Policy log std Max           -0.22970808
Policy log std Min           -2.4401143
Z mean eval                  1.1683524
Z variance eval              0.048632655
total_rewards                [1397.99740386  933.93568087 3410.26438045  149.01877475 1858.79576904
 3405.85540113 1398.58372199  485.82759658  288.31736942  104.39540797]
total_rewards_mean           1343.2991506075527
total_rewards_std            1173.6813523659346
total_rewards_max            3410.264380448276
total_rewards_min            104.39540797419542
Number of train steps total  1484000
Number of env steps total    2444184
Number of rollouts total     0
Train Time (s)               155.07484502438456
(Previous) Eval Time (s)     16.24991381773725
Sample Time (s)              13.165771923493594
Epoch Time (s)               184.4905307656154
Total Train Time (s)         68685.67039423576
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:00:39.036740 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #370 | Epoch Duration: 184.58351230621338
2020-01-12 21:00:39.037015 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1608074
Z variance train             0.048558533
KL Divergence                16.436768
KL Loss                      1.6436768
QF Loss                      327.82208
VF Loss                      63.462006
Policy Loss                  -1052.0377
Q Predictions Mean           1044.0862
Q Predictions Std            305.85355
Q Predictions Max            1383.7948
Q Predictions Min            -2.311279
V Predictions Mean           1049.9397
V Predictions Std            298.84708
V Predictions Max            1376.9695
V Predictions Min            285.96652
Log Pis Mean                 -0.19375494
Log Pis Std                  2.6971085
Log Pis Max                  10.806915
Log Pis Min                  -5.989669
Policy mu Mean               0.0061415955
Policy mu Std                0.6105855
Policy mu Max                2.2833648
Policy mu Min                -2.5933518
Policy log std Mean          -0.94645655
Policy log std Std           0.24535586
Policy log std Max           -0.24960268
Policy log std Min           -2.071781
Z mean eval                  0.9330282
Z variance eval              0.023826001
total_rewards                [ 218.7701708   418.19868307   77.79316029  461.43351796  575.66218244
 2034.22942296 1559.63216688  823.48906636 1948.48398102 3159.05311407]
total_rewards_mean           1127.6745465844635
total_rewards_std            952.968719161931
total_rewards_max            3159.053114070735
total_rewards_min            77.79316028664803
Number of train steps total  1488000
Number of env steps total    2456099
Number of rollouts total     0
Train Time (s)               153.6992734260857
(Previous) Eval Time (s)     20.179374222178012
Sample Time (s)              12.835717947687954
Epoch Time (s)               186.71436559595168
Total Train Time (s)         68872.47717687255
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:03:45.847379 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #371 | Epoch Duration: 186.81018805503845
2020-01-12 21:03:45.847584 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93265486
Z variance train             0.023841321
KL Divergence                16.78074
KL Loss                      1.6780741
QF Loss                      1504.2258
VF Loss                      285.7618
Policy Loss                  -1032.1719
Q Predictions Mean           1026.3835
Q Predictions Std            303.8583
Q Predictions Max            1437.1991
Q Predictions Min            310.45703
V Predictions Mean           1030.1282
V Predictions Std            302.1932
V Predictions Max            1425.7748
V Predictions Min            308.3984
Log Pis Mean                 -0.15395032
Log Pis Std                  3.1491466
Log Pis Max                  22.483292
Log Pis Min                  -8.732092
Policy mu Mean               -0.014229126
Policy mu Std                0.63566864
Policy mu Max                4.55394
Policy mu Min                -2.648468
Policy log std Mean          -0.96051586
Policy log std Std           0.2454275
Policy log std Max           -0.017548323
Policy log std Min           -2.255004
Z mean eval                  0.9700743
Z variance eval              0.084943786
total_rewards                [ 622.59928002  124.74292702  525.44728639 1880.0855034   356.6977658
  407.7886551  3136.61581746  785.86411427 1568.26781498  103.7018473 ]
total_rewards_mean           951.1811011751921
total_rewards_std            915.7639558492695
total_rewards_max            3136.615817463938
total_rewards_min            103.70184730478913
Number of train steps total  1492000
Number of env steps total    2465804
Number of rollouts total     0
Train Time (s)               155.86303772823885
(Previous) Eval Time (s)     15.195344486739486
Sample Time (s)              13.258479215204716
Epoch Time (s)               184.31686143018305
Total Train Time (s)         69056.88708968088
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:06:50.262327 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #372 | Epoch Duration: 184.41457724571228
2020-01-12 21:06:50.262580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96811104
Z variance train             0.083903834
KL Divergence                14.363126
KL Loss                      1.4363126
QF Loss                      774.5725
VF Loss                      180.49718
Policy Loss                  -1032.8114
Q Predictions Mean           1027.8801
Q Predictions Std            295.92307
Q Predictions Max            1395.6221
Q Predictions Min            301.76822
V Predictions Mean           1031.8348
V Predictions Std            298.21964
V Predictions Max            1386.9578
V Predictions Min            301.82358
Log Pis Mean                 -0.050640106
Log Pis Std                  2.981002
Log Pis Max                  14.893117
Log Pis Min                  -8.11429
Policy mu Mean               0.0012219318
Policy mu Std                0.62205416
Policy mu Max                2.1510384
Policy mu Min                -2.5042555
Policy log std Mean          -0.94940186
Policy log std Std           0.2715416
Policy log std Max           -0.34202588
Policy log std Min           -2.8776307
Z mean eval                  0.9471485
Z variance eval              0.0548221
total_rewards                [1277.81305908 3819.87975241  738.83346087  601.45968206 3415.06232155
  426.58011088 3031.30505039 2772.10964909 3471.53572583  696.85343956]
total_rewards_mean           2025.1432251713493
total_rewards_std            1318.144674245603
total_rewards_max            3819.879752410062
total_rewards_min            426.5801108798653
Number of train steps total  1496000
Number of env steps total    2474964
Number of rollouts total     0
Train Time (s)               153.64394230488688
(Previous) Eval Time (s)     23.20480819698423
Sample Time (s)              12.133730148430914
Epoch Time (s)               188.98248065030202
Total Train Time (s)         69245.95609867852
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:09:59.335796 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #373 | Epoch Duration: 189.07303094863892
2020-01-12 21:09:59.336017 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94739044
Z variance train             0.05471257
KL Divergence                15.759472
KL Loss                      1.5759472
QF Loss                      303.67645
VF Loss                      66.45312
Policy Loss                  -1060.8226
Q Predictions Mean           1055.2356
Q Predictions Std            273.21365
Q Predictions Max            1412.1158
Q Predictions Min            310.28363
V Predictions Mean           1061.791
V Predictions Std            272.01108
V Predictions Max            1403.7358
V Predictions Min            297.67108
Log Pis Mean                 -0.31309518
Log Pis Std                  2.8903146
Log Pis Max                  10.710152
Log Pis Min                  -10.27043
Policy mu Mean               -0.007784988
Policy mu Std                0.6189663
Policy mu Max                2.9672666
Policy mu Min                -2.630437
Policy log std Mean          -0.9441849
Policy log std Std           0.22825977
Policy log std Max           -0.27132636
Policy log std Min           -1.918678
Z mean eval                  0.9507812
Z variance eval              0.04392739
total_rewards                [2409.4694742  2287.02246138 3297.12664799  665.44845895 1201.02109937
  268.19682659  691.39104567 2171.01192516  152.77283226 1836.25930733]
total_rewards_mean           1497.9720078901566
total_rewards_std            1000.5779661936087
total_rewards_max            3297.1266479902833
total_rewards_min            152.77283225835197
Number of train steps total  1500000
Number of env steps total    2484838
Number of rollouts total     0
Train Time (s)               145.69913306599483
(Previous) Eval Time (s)     21.412858366966248
Sample Time (s)              11.56056691519916
Epoch Time (s)               178.67255834816024
Total Train Time (s)         69424.72222126974
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:12:58.106487 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #374 | Epoch Duration: 178.77029585838318
2020-01-12 21:12:58.106754 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95647687
Z variance train             0.04397904
KL Divergence                17.600866
KL Loss                      1.7600867
QF Loss                      348.4789
VF Loss                      101.37673
Policy Loss                  -1064.6984
Q Predictions Mean           1060.0703
Q Predictions Std            308.153
Q Predictions Max            1404.6221
Q Predictions Min            328.1983
V Predictions Mean           1059.4451
V Predictions Std            306.70084
V Predictions Max            1409.3064
V Predictions Min            328.73914
Log Pis Mean                 -0.51594734
Log Pis Std                  2.6693847
Log Pis Max                  7.153879
Log Pis Min                  -7.0077305
Policy mu Mean               -0.008378159
Policy mu Std                0.61005807
Policy mu Max                2.3905673
Policy mu Min                -2.191318
Policy log std Mean          -0.9365799
Policy log std Std           0.2354747
Policy log std Max           -0.3400604
Policy log std Min           -2.0519996
Z mean eval                  0.95018417
Z variance eval              0.056026768
total_rewards                [ 494.11613923 1929.70837732  813.06533349  441.03419674  939.11717936
 1814.6465707  2991.06591854  713.66617828   74.91829581 3481.73272939]
total_rewards_mean           1369.3070918861617
total_rewards_std            1087.7612792810733
total_rewards_max            3481.7327293907756
total_rewards_min            74.91829580695749
Number of train steps total  1504000
Number of env steps total    2495139
Number of rollouts total     0
Train Time (s)               145.5478665935807
(Previous) Eval Time (s)     18.5865174732171
Sample Time (s)              11.421552136540413
Epoch Time (s)               175.5559362033382
Total Train Time (s)         69600.37816705229
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:15:53.766433 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #375 | Epoch Duration: 175.65949845314026
2020-01-12 21:15:53.766644 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9484021
Z variance train             0.055975348
KL Divergence                16.017515
KL Loss                      1.6017516
QF Loss                      636.8272
VF Loss                      223.92484
Policy Loss                  -1065.5212
Q Predictions Mean           1061.5823
Q Predictions Std            290.02493
Q Predictions Max            1367.0577
Q Predictions Min            312.00974
V Predictions Mean           1061.4868
V Predictions Std            290.70218
V Predictions Max            1360.3359
V Predictions Min            309.55206
Log Pis Mean                 7.998198e-05
Log Pis Std                  2.9718027
Log Pis Max                  15.353889
Log Pis Min                  -7.2887826
Policy mu Mean               0.019834753
Policy mu Std                0.60911554
Policy mu Max                4.1106358
Policy mu Min                -3.4723132
Policy log std Mean          -0.98926014
Policy log std Std           0.25415784
Policy log std Max           0.3095553
Policy log std Min           -2.3625188
Z mean eval                  1.1213753
Z variance eval              0.048737127
total_rewards                [ 345.32157998  297.59878562  222.49042928  703.20079791 1185.17707619
 1067.67280476  443.40508651  670.89718847  912.50642462  852.55607473]
total_rewards_mean           670.0826248073167
total_rewards_std            318.1978955215101
total_rewards_max            1185.1770761921905
total_rewards_min            222.49042928117967
Number of train steps total  1508000
Number of env steps total    2507187
Number of rollouts total     0
Train Time (s)               153.4645899985917
(Previous) Eval Time (s)     21.000448820646852
Sample Time (s)              12.418742658104748
Epoch Time (s)               186.8837814773433
Total Train Time (s)         69787.36809752509
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:19:00.760853 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #376 | Epoch Duration: 186.99405360221863
2020-01-12 21:19:00.761043 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1194389
Z variance train             0.049401734
KL Divergence                15.450618
KL Loss                      1.5450618
QF Loss                      240.70921
VF Loss                      137.68823
Policy Loss                  -1093.7925
Q Predictions Mean           1090.0264
Q Predictions Std            268.24115
Q Predictions Max            1453.8655
Q Predictions Min            332.4756
V Predictions Mean           1083.808
V Predictions Std            267.80298
V Predictions Max            1444.7429
V Predictions Min            327.4713
Log Pis Mean                 -0.22131003
Log Pis Std                  2.6507084
Log Pis Max                  6.482535
Log Pis Min                  -8.842302
Policy mu Mean               0.007808819
Policy mu Std                0.6113541
Policy mu Max                2.192614
Policy mu Min                -2.3462
Policy log std Mean          -0.9441366
Policy log std Std           0.2322028
Policy log std Max           -0.29371744
Policy log std Min           -1.9249139
Z mean eval                  0.95062315
Z variance eval              0.04075665
total_rewards                [3519.45836766  230.50316124 2284.50195262 3484.39277363 2876.13517882
 1144.24397045 3051.86425878 3617.74662672 1107.62853566 3472.26822825]
total_rewards_mean           2478.8743053826993
total_rewards_std            1166.978338464717
total_rewards_max            3617.746626716839
total_rewards_min            230.5031612401891
Number of train steps total  1512000
Number of env steps total    2518563
Number of rollouts total     0
Train Time (s)               154.76652874285355
(Previous) Eval Time (s)     29.99797925585881
Sample Time (s)              13.456157040782273
Epoch Time (s)               198.22066503949463
Total Train Time (s)         69985.68442832213
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:22:19.081032 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #377 | Epoch Duration: 198.31983041763306
2020-01-12 21:22:19.081284 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9464984
Z variance train             0.04056589
KL Divergence                17.086092
KL Loss                      1.7086092
QF Loss                      336.02786
VF Loss                      134.732
Policy Loss                  -1077.8605
Q Predictions Mean           1076.2483
Q Predictions Std            279.36246
Q Predictions Max            1437.524
Q Predictions Min            320.8434
V Predictions Mean           1085.1807
V Predictions Std            281.65677
V Predictions Max            1438.2335
V Predictions Min            316.57068
Log Pis Mean                 -0.07051574
Log Pis Std                  2.8289647
Log Pis Max                  9.231604
Log Pis Min                  -10.696342
Policy mu Mean               0.06354697
Policy mu Std                0.6017623
Policy mu Max                2.7312193
Policy mu Min                -2.3305612
Policy log std Mean          -0.97559494
Policy log std Std           0.23627652
Policy log std Max           -0.26861846
Policy log std Min           -2.1602669
Z mean eval                  0.9384363
Z variance eval              0.09175863
total_rewards                [3410.83800813 1922.03079501  414.35220104 2636.62481962 3489.77748142
  274.06124352 3430.32124613 3536.90894099  602.16207246 3449.01306405]
total_rewards_mean           2316.608987236924
total_rewards_std            1325.6507799630253
total_rewards_max            3536.9089409879657
total_rewards_min            274.061243520917
Number of train steps total  1516000
Number of env steps total    2528341
Number of rollouts total     0
Train Time (s)               153.664029289037
(Previous) Eval Time (s)     31.07997904997319
Sample Time (s)              12.275550544261932
Epoch Time (s)               197.0195588832721
Total Train Time (s)         70182.8076756713
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:25:36.207808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #378 | Epoch Duration: 197.126371383667
2020-01-12 21:25:36.207992 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9348062
Z variance train             0.0905749
KL Divergence                13.595192
KL Loss                      1.3595192
QF Loss                      363.99252
VF Loss                      117.424805
Policy Loss                  -1032.9656
Q Predictions Mean           1030.015
Q Predictions Std            269.84143
Q Predictions Max            1354.6608
Q Predictions Min            305.4496
V Predictions Mean           1038.2949
V Predictions Std            270.451
V Predictions Max            1352.8448
V Predictions Min            308.4432
Log Pis Mean                 -0.334475
Log Pis Std                  2.878681
Log Pis Max                  8.502519
Log Pis Min                  -8.695658
Policy mu Mean               0.008351475
Policy mu Std                0.5803731
Policy mu Max                2.3012896
Policy mu Min                -2.2230675
Policy log std Mean          -0.98070085
Policy log std Std           0.2523945
Policy log std Max           -0.23221767
Policy log std Min           -2.1914825
Z mean eval                  0.94683456
Z variance eval              0.04389222
total_rewards                [3015.64239317  428.16756387 3187.91381651 2587.58526536 3440.77514473
  137.32631933 3380.71210622  509.71280516  978.72581893  717.60494281]
total_rewards_mean           1838.4166176092046
total_rewards_std            1317.4876318310119
total_rewards_max            3440.7751447299415
total_rewards_min            137.3263193272711
Number of train steps total  1520000
Number of env steps total    2538412
Number of rollouts total     0
Train Time (s)               155.09218467399478
(Previous) Eval Time (s)     30.47878108220175
Sample Time (s)              12.005612096283585
Epoch Time (s)               197.5765778524801
Total Train Time (s)         70380.47229151847
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:28:53.876493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #379 | Epoch Duration: 197.66835522651672
2020-01-12 21:28:53.876685 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9494502
Z variance train             0.04390042
KL Divergence                16.468565
KL Loss                      1.6468565
QF Loss                      10903.416
VF Loss                      73.642746
Policy Loss                  -1078.7725
Q Predictions Mean           1074.9341
Q Predictions Std            258.75998
Q Predictions Max            1392.3695
Q Predictions Min            294.4932
V Predictions Mean           1083.1208
V Predictions Std            259.56537
V Predictions Max            1390.0961
V Predictions Min            298.03778
Log Pis Mean                 0.38172063
Log Pis Std                  2.8039656
Log Pis Max                  8.144419
Log Pis Min                  -7.966834
Policy mu Mean               0.020821659
Policy mu Std                0.62261593
Policy mu Max                2.332299
Policy mu Min                -2.4692943
Policy log std Mean          -0.99868006
Policy log std Std           0.2482875
Policy log std Max           -0.30638546
Policy log std Min           -1.9955726
Z mean eval                  1.0127732
Z variance eval              0.04478748
total_rewards                [1293.17044399 2967.87135299  338.2473998  3477.70510334 2677.70055553
  258.23908978  387.46594328  293.23898099 3318.12309455 3511.66810817]
total_rewards_mean           1852.3430072414922
total_rewards_std            1385.3623537497058
total_rewards_max            3511.6681081662286
total_rewards_min            258.239089775779
Number of train steps total  1524000
Number of env steps total    2550797
Number of rollouts total     0
Train Time (s)               149.6100397100672
(Previous) Eval Time (s)     25.75650705071166
Sample Time (s)              12.360302917193621
Epoch Time (s)               187.7268496779725
Total Train Time (s)         70568.30178474961
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:32:01.710113 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #380 | Epoch Duration: 187.83328533172607
2020-01-12 21:32:01.710301 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0115587
Z variance train             0.044943117
KL Divergence                16.227459
KL Loss                      1.6227459
QF Loss                      307.6502
VF Loss                      68.85536
Policy Loss                  -1075.0024
Q Predictions Mean           1071.3899
Q Predictions Std            266.0381
Q Predictions Max            1400.7461
Q Predictions Min            295.52954
V Predictions Mean           1071.555
V Predictions Std            265.19656
V Predictions Max            1389.5228
V Predictions Min            294.79382
Log Pis Mean                 -0.048489608
Log Pis Std                  2.5503263
Log Pis Max                  11.275879
Log Pis Min                  -9.43288
Policy mu Mean               0.04164931
Policy mu Std                0.6105208
Policy mu Max                2.134098
Policy mu Min                -2.626412
Policy log std Mean          -0.9776497
Policy log std Std           0.246051
Policy log std Max           -0.061522484
Policy log std Min           -2.8678
Z mean eval                  1.0040883
Z variance eval              0.084718235
total_rewards                [3531.98824583  307.66620589 1045.45251843 3178.48172313 3316.90341025
 3436.4799732  2309.15509617 3540.45882311 3434.03779641 1678.58675189]
total_rewards_mean           2577.9210544303733
total_rewards_std            1122.3682422864392
total_rewards_max            3540.458823114176
total_rewards_min            307.6662058924695
Number of train steps total  1528000
Number of env steps total    2561696
Number of rollouts total     0
Train Time (s)               145.49047930911183
(Previous) Eval Time (s)     32.56511037796736
Sample Time (s)              11.906323487404734
Epoch Time (s)               189.96191317448393
Total Train Time (s)         70758.34918140015
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:35:11.761252 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #381 | Epoch Duration: 190.0508098602295
2020-01-12 21:35:11.761425 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0026639
Z variance train             0.085011736
KL Divergence                13.923891
KL Loss                      1.3923892
QF Loss                      11046.393
VF Loss                      108.688484
Policy Loss                  -1027.1636
Q Predictions Mean           1022.7872
Q Predictions Std            283.5083
Q Predictions Max            1379.1495
Q Predictions Min            255.84511
V Predictions Mean           1025.0459
V Predictions Std            282.71768
V Predictions Max            1366.2308
V Predictions Min            265.03802
Log Pis Mean                 -0.046880953
Log Pis Std                  2.89634
Log Pis Max                  10.290144
Log Pis Min                  -9.071616
Policy mu Mean               0.017744279
Policy mu Std                0.634927
Policy mu Max                2.2217948
Policy mu Min                -2.6365323
Policy log std Mean          -0.9493176
Policy log std Std           0.27350807
Policy log std Max           -0.2981882
Policy log std Min           -2.3280897
Z mean eval                  1.0947492
Z variance eval              0.088697046
total_rewards                [1413.45942348 2512.98746545  836.65766671  253.36984518 2330.3163245
  801.7405817   556.94524377 1715.62700282 1642.27300215 2998.62362599]
total_rewards_mean           1506.2000181751678
total_rewards_std            860.5992876730999
total_rewards_max            2998.623625993801
total_rewards_min            253.3698451782325
Number of train steps total  1532000
Number of env steps total    2572962
Number of rollouts total     0
Train Time (s)               147.7262653959915
(Previous) Eval Time (s)     14.96643230970949
Sample Time (s)              11.268855911679566
Epoch Time (s)               173.96155361738056
Total Train Time (s)         70932.39762628404
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:38:05.813805 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #382 | Epoch Duration: 174.05223989486694
2020-01-12 21:38:05.813998 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.094232
Z variance train             0.08838563
KL Divergence                13.880537
KL Loss                      1.3880538
QF Loss                      202.76773
VF Loss                      82.119385
Policy Loss                  -1078.8085
Q Predictions Mean           1074.0476
Q Predictions Std            303.89886
Q Predictions Max            1437.4216
Q Predictions Min            331.79434
V Predictions Mean           1074.8308
V Predictions Std            303.18295
V Predictions Max            1421.7465
V Predictions Min            329.4874
Log Pis Mean                 -0.3835813
Log Pis Std                  2.6614313
Log Pis Max                  9.316481
Log Pis Min                  -9.047032
Policy mu Mean               0.04679899
Policy mu Std                0.5977651
Policy mu Max                2.5318267
Policy mu Min                -2.376063
Policy log std Mean          -0.95995414
Policy log std Std           0.24800688
Policy log std Max           -0.2705589
Policy log std Min           -2.2650208
Z mean eval                  0.8673301
Z variance eval              0.06747334
total_rewards                [  98.48511082 2599.29527562  774.5360192   247.73817847  481.78498868
 3442.48640526  335.84215254 3686.62127855  862.03180042 3505.17956161]
total_rewards_mean           1603.400077117437
total_rewards_std            1432.9890382225922
total_rewards_max            3686.6212785464713
total_rewards_min            98.4851108245234
Number of train steps total  1536000
Number of env steps total    2585279
Number of rollouts total     0
Train Time (s)               156.134403409902
(Previous) Eval Time (s)     20.915027615614235
Sample Time (s)              13.121235236525536
Epoch Time (s)               190.17066626204178
Total Train Time (s)         71122.65954413079
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:41:16.080341 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #383 | Epoch Duration: 190.26619744300842
2020-01-12 21:41:16.080548 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86231244
Z variance train             0.067455515
KL Divergence                14.602121
KL Loss                      1.4602121
QF Loss                      688.98126
VF Loss                      56.078896
Policy Loss                  -1042.5061
Q Predictions Mean           1038.1163
Q Predictions Std            308.5093
Q Predictions Max            1374.7267
Q Predictions Min            297.863
V Predictions Mean           1046.6221
V Predictions Std            308.58606
V Predictions Max            1383.0839
V Predictions Min            309.62625
Log Pis Mean                 0.0878693
Log Pis Std                  2.7190268
Log Pis Max                  8.986563
Log Pis Min                  -7.194241
Policy mu Mean               -0.023574648
Policy mu Std                0.60029036
Policy mu Max                2.7330534
Policy mu Min                -2.5218306
Policy log std Mean          -0.9898497
Policy log std Std           0.2560784
Policy log std Max           0.024115562
Policy log std Min           -2.0992622
Z mean eval                  1.0667573
Z variance eval              0.10559527
total_rewards                [3391.81135284 2520.72294822   77.44112712 3047.41101329 3526.47102066
 1899.18735234 2533.93527386  830.96607802 3655.26148403 2922.98015669]
total_rewards_mean           2440.618780706604
total_rewards_std            1124.4523861173916
total_rewards_max            3655.2614840306605
total_rewards_min            77.44112711872812
Number of train steps total  1540000
Number of env steps total    2593950
Number of rollouts total     0
Train Time (s)               154.79055056720972
(Previous) Eval Time (s)     26.38985814899206
Sample Time (s)              11.707676435355097
Epoch Time (s)               192.88808515155688
Total Train Time (s)         71315.63422232587
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:44:29.059089 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #384 | Epoch Duration: 192.97837829589844
2020-01-12 21:44:29.059308 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.068831
Z variance train             0.10546295
KL Divergence                14.390091
KL Loss                      1.4390091
QF Loss                      265.33423
VF Loss                      43.685337
Policy Loss                  -1073.3846
Q Predictions Mean           1068.476
Q Predictions Std            323.61972
Q Predictions Max            1404.3966
Q Predictions Min            291.27933
V Predictions Mean           1073.1682
V Predictions Std            324.04636
V Predictions Max            1403.5862
V Predictions Min            296.75946
Log Pis Mean                 -0.17565994
Log Pis Std                  2.8380246
Log Pis Max                  9.057539
Log Pis Min                  -9.103194
Policy mu Mean               0.04241079
Policy mu Std                0.607554
Policy mu Max                2.6057718
Policy mu Min                -2.0795403
Policy log std Mean          -0.9440836
Policy log std Std           0.25166297
Policy log std Max           -0.16230154
Policy log std Min           -2.157264
Z mean eval                  1.0363102
Z variance eval              0.038205523
total_rewards                [2598.21884445 3573.8439237  3486.74272328  529.02733966 3256.92945599
 3344.24588125  211.78091571 3182.43013767 3262.58254864 3440.81283371]
total_rewards_mean           2688.661460405088
total_rewards_std            1188.245024758396
total_rewards_max            3573.8439237014704
total_rewards_min            211.78091570934595
Number of train steps total  1544000
Number of env steps total    2605651
Number of rollouts total     0
Train Time (s)               154.44127891398966
(Previous) Eval Time (s)     31.73978559114039
Sample Time (s)              12.032003683038056
Epoch Time (s)               198.2130681881681
Total Train Time (s)         71513.95021588076
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:47:47.380428 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #385 | Epoch Duration: 198.32093286514282
2020-01-12 21:47:47.380755 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0377364
Z variance train             0.038382933
KL Divergence                14.948042
KL Loss                      1.4948043
QF Loss                      1659.733
VF Loss                      121.887955
Policy Loss                  -1089.6555
Q Predictions Mean           1077.991
Q Predictions Std            293.68207
Q Predictions Max            1408.7474
Q Predictions Min            313.96594
V Predictions Mean           1087.6754
V Predictions Std            291.84875
V Predictions Max            1413.7622
V Predictions Min            318.05798
Log Pis Mean                 -0.019680485
Log Pis Std                  2.9078722
Log Pis Max                  12.349348
Log Pis Min                  -7.988263
Policy mu Mean               0.03710407
Policy mu Std                0.6030006
Policy mu Max                2.6151843
Policy mu Min                -2.8691728
Policy log std Mean          -0.998302
Policy log std Std           0.27025554
Policy log std Max           0.08184683
Policy log std Min           -2.342986
Z mean eval                  1.054601
Z variance eval              0.21956126
total_rewards                [ 680.24273591 3542.33156677  351.17082154 1054.61211923 1229.91338722
 1619.13053344 2975.52540731 2171.28548575 3451.10610489 2660.27393132]
total_rewards_mean           1973.559209337175
total_rewards_std            1094.8381031193253
total_rewards_max            3542.33156676895
total_rewards_min            351.17082153889015
Number of train steps total  1548000
Number of env steps total    2614117
Number of rollouts total     0
Train Time (s)               154.7117391419597
(Previous) Eval Time (s)     25.849643101915717
Sample Time (s)              11.882146610412747
Epoch Time (s)               192.44352885428816
Total Train Time (s)         71706.48838193994
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:50:59.921957 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #386 | Epoch Duration: 192.5410122871399
2020-01-12 21:50:59.922151 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0462637
Z variance train             0.21812816
KL Divergence                13.852175
KL Loss                      1.3852175
QF Loss                      477.498
VF Loss                      149.3677
Policy Loss                  -1095.8524
Q Predictions Mean           1091.9454
Q Predictions Std            316.56696
Q Predictions Max            1452.4272
Q Predictions Min            59.645996
V Predictions Mean           1104.4214
V Predictions Std            315.28625
V Predictions Max            1461.116
V Predictions Min            163.6636
Log Pis Mean                 -0.0016805679
Log Pis Std                  2.9695857
Log Pis Max                  12.7171135
Log Pis Min                  -7.6750607
Policy mu Mean               0.01008612
Policy mu Std                0.61256623
Policy mu Max                2.1948066
Policy mu Min                -2.6555882
Policy log std Mean          -0.96435547
Policy log std Std           0.259173
Policy log std Max           -0.25505644
Policy log std Min           -2.4944952
Z mean eval                  1.0484304
Z variance eval              0.112924054
total_rewards                [3417.4132207  3416.37328009 1649.89703891 1003.01227369 3196.50592185
 2562.51393254  768.07079082 1043.50276994 3406.75551236 2568.28861674]
total_rewards_mean           2303.2333357646667
total_rewards_std            1034.152960335491
total_rewards_max            3417.413220703977
total_rewards_min            768.0707908179522
Number of train steps total  1552000
Number of env steps total    2623874
Number of rollouts total     0
Train Time (s)               146.01159071270376
(Previous) Eval Time (s)     26.262571034021676
Sample Time (s)              12.065216567832977
Epoch Time (s)               184.33937831455842
Total Train Time (s)         71890.91335507901
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:54:04.351022 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #387 | Epoch Duration: 184.42872714996338
2020-01-12 21:54:04.351304 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0520842
Z variance train             0.11379059
KL Divergence                14.930826
KL Loss                      1.4930826
QF Loss                      472.83044
VF Loss                      61.12039
Policy Loss                  -1072.5126
Q Predictions Mean           1061.6766
Q Predictions Std            303.39175
Q Predictions Max            1416.878
Q Predictions Min            129.09901
V Predictions Mean           1068.3052
V Predictions Std            296.75888
V Predictions Max            1405.1157
V Predictions Min            291.73804
Log Pis Mean                 -0.18607356
Log Pis Std                  2.5865886
Log Pis Max                  13.434467
Log Pis Min                  -15.71018
Policy mu Mean               -0.05461374
Policy mu Std                0.5842001
Policy mu Max                1.7289423
Policy mu Min                -2.3992789
Policy log std Mean          -1.0038946
Policy log std Std           0.2331552
Policy log std Max           -0.25400072
Policy log std Min           -1.9472339
Z mean eval                  1.1103017
Z variance eval              0.26694486
total_rewards                [1014.09000741 1064.18939949 1784.54854082  711.99074022  760.27038424
  155.99658469 3479.02516754 1081.79420859 3220.85931499 1387.46068054]
total_rewards_mean           1466.0225028519276
total_rewards_std            1026.4221756074726
total_rewards_max            3479.025167536563
total_rewards_min            155.9965846860636
Number of train steps total  1556000
Number of env steps total    2634530
Number of rollouts total     0
Train Time (s)               145.8236125339754
(Previous) Eval Time (s)     25.500765919219702
Sample Time (s)              11.40069478424266
Epoch Time (s)               182.72507323743775
Total Train Time (s)         72073.7343285745
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:57:07.176237 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #388 | Epoch Duration: 182.824782371521
2020-01-12 21:57:07.176437 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1093776
Z variance train             0.2656078
KL Divergence                12.204699
KL Loss                      1.2204698
QF Loss                      11317.386
VF Loss                      124.636
Policy Loss                  -1125.7202
Q Predictions Mean           1125.6407
Q Predictions Std            264.14536
Q Predictions Max            1415.716
Q Predictions Min            313.16977
V Predictions Mean           1134.2319
V Predictions Std            263.4285
V Predictions Max            1412.4635
V Predictions Min            324.50266
Log Pis Mean                 0.2075511
Log Pis Std                  2.509832
Log Pis Max                  7.9481173
Log Pis Min                  -6.166641
Policy mu Mean               0.041136526
Policy mu Std                0.56995106
Policy mu Max                2.2121959
Policy mu Min                -2.256117
Policy log std Mean          -1.0314014
Policy log std Std           0.25018317
Policy log std Max           -0.3255247
Policy log std Min           -2.3127432
Z mean eval                  0.9643281
Z variance eval              0.2071501
total_rewards                [ 373.09628072 3367.29848694 1112.44095194 2639.01975841  429.21850533
 2764.20953364 1816.17258621  843.01172529 3295.58419147  847.54678547]
total_rewards_mean           1748.7598805416958
total_rewards_std            1118.5563961386838
total_rewards_max            3367.2984869351794
total_rewards_min            373.0962807186114
Number of train steps total  1560000
Number of env steps total    2646554
Number of rollouts total     0
Train Time (s)               149.45867306180298
(Previous) Eval Time (s)     24.958006928674877
Sample Time (s)              10.942022535018623
Epoch Time (s)               185.35870252549648
Total Train Time (s)         72259.18271555379
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:00:12.629067 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #389 | Epoch Duration: 185.45245337486267
2020-01-12 22:00:12.629329 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9567526
Z variance train             0.20687363
KL Divergence                12.039477
KL Loss                      1.2039478
QF Loss                      384.10486
VF Loss                      80.07754
Policy Loss                  -1108.0795
Q Predictions Mean           1105.3242
Q Predictions Std            298.45734
Q Predictions Max            1402.0581
Q Predictions Min            305.69992
V Predictions Mean           1111.3242
V Predictions Std            299.445
V Predictions Max            1425.3389
V Predictions Min            306.06436
Log Pis Mean                 -0.074096836
Log Pis Std                  2.720121
Log Pis Max                  8.86976
Log Pis Min                  -5.8807592
Policy mu Mean               0.06290649
Policy mu Std                0.59161085
Policy mu Max                2.208991
Policy mu Min                -2.1427653
Policy log std Mean          -0.98500586
Policy log std Std           0.23662573
Policy log std Max           -0.37874472
Policy log std Min           -2.1249752
Z mean eval                  0.95785856
Z variance eval              0.13302514
total_rewards                [ 994.84986434 2903.15622059 2416.2797107   617.40633698  171.11467383
 1187.24518762   69.21285876 2142.79375524 3503.01012132 1044.58414614]
total_rewards_mean           1504.965287551137
total_rewards_std            1112.9177042601204
total_rewards_max            3503.010121322429
total_rewards_min            69.21285875571989
Number of train steps total  1564000
Number of env steps total    2658872
Number of rollouts total     0
Train Time (s)               156.12944735214114
(Previous) Eval Time (s)     22.681738913059235
Sample Time (s)              13.12441854737699
Epoch Time (s)               191.93560481257737
Total Train Time (s)         72451.28673355421
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:03:24.737261 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #390 | Epoch Duration: 192.10775470733643
2020-01-12 22:03:24.737472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.958844
Z variance train             0.13344467
KL Divergence                12.329926
KL Loss                      1.2329925
QF Loss                      227.668
VF Loss                      74.703255
Policy Loss                  -1129.8635
Q Predictions Mean           1126.9164
Q Predictions Std            276.33188
Q Predictions Max            1446.8608
Q Predictions Min            311.76297
V Predictions Mean           1134.9788
V Predictions Std            276.1833
V Predictions Max            1434.6199
V Predictions Min            306.6311
Log Pis Mean                 -0.098319
Log Pis Std                  2.6812296
Log Pis Max                  11.153324
Log Pis Min                  -9.190401
Policy mu Mean               0.0054364246
Policy mu Std                0.5986366
Policy mu Max                4.255139
Policy mu Min                -3.5053048
Policy log std Mean          -1.0011163
Policy log std Std           0.24291685
Policy log std Max           0.09686923
Policy log std Min           -1.9001956
Z mean eval                  1.0453423
Z variance eval              0.15738524
total_rewards                [ 432.57944213  472.26740157  348.28923561 1312.70933506  397.03842711
  137.86320378  706.54856215 1731.80853882  197.80341889 3593.57645722]
total_rewards_mean           933.0484022342318
total_rewards_std            1008.8020054013211
total_rewards_max            3593.5764572222224
total_rewards_min            137.8632037827014
Number of train steps total  1568000
Number of env steps total    2671176
Number of rollouts total     0
Train Time (s)               155.78484528977424
(Previous) Eval Time (s)     24.311104509979486
Sample Time (s)              12.92441733321175
Epoch Time (s)               193.02036713296548
Total Train Time (s)         72644.40258734301
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:06:37.858041 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #391 | Epoch Duration: 193.12035536766052
2020-01-12 22:06:37.858262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0239619
Z variance train             0.15847251
KL Divergence                13.435606
KL Loss                      1.3435606
QF Loss                      256.78738
VF Loss                      123.46474
Policy Loss                  -1105.1031
Q Predictions Mean           1103.9446
Q Predictions Std            303.37433
Q Predictions Max            1440.0385
Q Predictions Min            285.6211
V Predictions Mean           1112.4442
V Predictions Std            303.24112
V Predictions Max            1440.2401
V Predictions Min            294.1601
Log Pis Mean                 -0.49355757
Log Pis Std                  2.478193
Log Pis Max                  8.281638
Log Pis Min                  -8.1094
Policy mu Mean               -0.03373088
Policy mu Std                0.5794331
Policy mu Max                2.442672
Policy mu Min                -2.2863758
Policy log std Mean          -0.9617673
Policy log std Std           0.23980027
Policy log std Max           -0.13486993
Policy log std Min           -2.1060429
Z mean eval                  0.9521452
Z variance eval              0.10282578
total_rewards                [1534.3535898   278.13831207 2805.95195751 2227.05751264 1761.87230697
 2822.09641411 1409.55218839 3493.00996077  100.23043381 1234.93263808]
total_rewards_mean           1766.71953141295
total_rewards_std            1041.3096225286422
total_rewards_max            3493.0099607728407
total_rewards_min            100.2304338096734
Number of train steps total  1572000
Number of env steps total    2681811
Number of rollouts total     0
Train Time (s)               156.74619844695553
(Previous) Eval Time (s)     24.653452578932047
Sample Time (s)              11.99969933880493
Epoch Time (s)               193.3993503646925
Total Train Time (s)         72837.90029299678
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:09:51.358825 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #392 | Epoch Duration: 193.5004003047943
2020-01-12 22:09:51.359009 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9525935
Z variance train             0.103005745
KL Divergence                13.567782
KL Loss                      1.3567783
QF Loss                      376.4111
VF Loss                      114.30189
Policy Loss                  -1130.6517
Q Predictions Mean           1126.7245
Q Predictions Std            274.65125
Q Predictions Max            1476.496
Q Predictions Min            309.74945
V Predictions Mean           1129.907
V Predictions Std            274.07315
V Predictions Max            1475.9872
V Predictions Min            283.95917
Log Pis Mean                 0.2629492
Log Pis Std                  2.7157676
Log Pis Max                  10.348233
Log Pis Min                  -8.146161
Policy mu Mean               -0.028529638
Policy mu Std                0.62170225
Policy mu Max                3.1670358
Policy mu Min                -2.4552035
Policy log std Mean          -1.00539
Policy log std Std           0.26014414
Policy log std Max           -0.23385572
Policy log std Min           -2.2913938
Z mean eval                  0.9995866
Z variance eval              0.11737859
total_rewards                [3405.64954888 1136.59713593  957.87947855  713.20721467  789.27623444
 3337.66446051 3411.58321105 1290.72447934 1642.08660745 1219.8033584 ]
total_rewards_mean           1790.4471729217537
total_rewards_std            1072.9253519093766
total_rewards_max            3411.583211052744
total_rewards_min            713.207214666183
Number of train steps total  1576000
Number of env steps total    2691751
Number of rollouts total     0
Train Time (s)               154.38129679812118
(Previous) Eval Time (s)     23.42266326583922
Sample Time (s)              11.50625104829669
Epoch Time (s)               189.3102111122571
Total Train Time (s)         73027.330825001
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:13:00.793427 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #393 | Epoch Duration: 189.4342794418335
2020-01-12 22:13:00.793623 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0013926
Z variance train             0.11747122
KL Divergence                12.164698
KL Loss                      1.2164698
QF Loss                      2419.7212
VF Loss                      230.40244
Policy Loss                  -1128.0969
Q Predictions Mean           1126.2427
Q Predictions Std            316.83688
Q Predictions Max            1454.2495
Q Predictions Min            311.48422
V Predictions Mean           1121.7781
V Predictions Std            317.27988
V Predictions Max            1431.5637
V Predictions Min            298.3078
Log Pis Mean                 0.12423838
Log Pis Std                  2.6120548
Log Pis Max                  8.331729
Log Pis Min                  -10.788939
Policy mu Mean               -0.031281903
Policy mu Std                0.62435484
Policy mu Max                2.2769
Policy mu Min                -2.564732
Policy log std Mean          -0.9512539
Policy log std Std           0.24282604
Policy log std Max           -0.28177303
Policy log std Min           -1.9473125
Z mean eval                  0.9815825
Z variance eval              0.29334897
total_rewards                [ 592.4161225  1614.15114584   94.71607821   73.3650331  1216.72893269
 1613.78106423 3149.73208539 3127.63246368 1403.40301863 1908.12842587]
total_rewards_mean           1479.4054370135705
total_rewards_std            1023.8407911152451
total_rewards_max            3149.7320853855863
total_rewards_min            73.3650331011439
Number of train steps total  1580000
Number of env steps total    2704090
Number of rollouts total     0
Train Time (s)               145.90101838996634
(Previous) Eval Time (s)     17.42058579204604
Sample Time (s)              11.979575397446752
Epoch Time (s)               175.30117957945913
Total Train Time (s)         73202.7194502647
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:15:56.186382 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #394 | Epoch Duration: 175.39261078834534
2020-01-12 22:15:56.186571 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98423547
Z variance train             0.2929257
KL Divergence                13.635141
KL Loss                      1.3635142
QF Loss                      335.2789
VF Loss                      51.22711
Policy Loss                  -1150.1884
Q Predictions Mean           1145.4474
Q Predictions Std            254.4523
Q Predictions Max            1441.8744
Q Predictions Min            266.97113
V Predictions Mean           1151.3438
V Predictions Std            252.17883
V Predictions Max            1428.7607
V Predictions Min            284.88022
Log Pis Mean                 0.38336536
Log Pis Std                  2.6494877
Log Pis Max                  8.068035
Log Pis Min                  -9.381189
Policy mu Mean               0.005520586
Policy mu Std                0.6269619
Policy mu Max                2.1144702
Policy mu Min                -2.2159104
Policy log std Mean          -0.9956181
Policy log std Std           0.25308737
Policy log std Max           -0.29685158
Policy log std Min           -2.1913204
Z mean eval                  1.035505
Z variance eval              0.1825893
total_rewards                [3358.77500733 3680.58578692 2972.03439654  430.60120084 2253.42343967
 1666.25428212 3531.17792563 3505.66908831 3494.3768086  3517.51914224]
total_rewards_mean           2841.041707820318
total_rewards_std            1016.2761093443559
total_rewards_max            3680.585786921383
total_rewards_min            430.60120083815957
Number of train steps total  1584000
Number of env steps total    2714434
Number of rollouts total     0
Train Time (s)               145.8197345728986
(Previous) Eval Time (s)     32.47811661986634
Sample Time (s)              11.209201131016016
Epoch Time (s)               189.50705232378095
Total Train Time (s)         73392.3156955503
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:19:05.787067 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #395 | Epoch Duration: 189.60033535957336
2020-01-12 22:19:05.787390 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0409757
Z variance train             0.18247174
KL Divergence                13.007607
KL Loss                      1.3007607
QF Loss                      395.87146
VF Loss                      409.6503
Policy Loss                  -1123.3663
Q Predictions Mean           1119.868
Q Predictions Std            262.05234
Q Predictions Max            1402.8495
Q Predictions Min            92.88394
V Predictions Mean           1125.4325
V Predictions Std            256.38727
V Predictions Max            1411.3336
V Predictions Min            296.96805
Log Pis Mean                 0.016077958
Log Pis Std                  2.8034022
Log Pis Max                  21.774015
Log Pis Min                  -9.148444
Policy mu Mean               0.004146006
Policy mu Std                0.59234565
Policy mu Max                2.4801626
Policy mu Min                -2.7503457
Policy log std Mean          -1.0019997
Policy log std Std           0.243562
Policy log std Max           -0.33770102
Policy log std Min           -3.1438365
Z mean eval                  0.9169413
Z variance eval              0.13155898
total_rewards                [2399.17195903 2197.70019005  891.57920797 2771.42379593 3715.58884291
  165.57935887  573.65487674 1911.54086604 3519.1522208  3580.27965391]
total_rewards_mean           2172.567097225158
total_rewards_std            1219.8384221997096
total_rewards_max            3715.5888429137076
total_rewards_min            165.57935887397784
Number of train steps total  1588000
Number of env steps total    2725791
Number of rollouts total     0
Train Time (s)               153.14915715623647
(Previous) Eval Time (s)     24.639568706974387
Sample Time (s)              11.034196738153696
Epoch Time (s)               188.82292260136455
Total Train Time (s)         73581.23536546435
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:22:14.712199 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #396 | Epoch Duration: 188.92455410957336
2020-01-12 22:22:14.712726 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91332996
Z variance train             0.1312362
KL Divergence                12.735377
KL Loss                      1.2735378
QF Loss                      305.4831
VF Loss                      48.81358
Policy Loss                  -1072.6361
Q Predictions Mean           1068.5885
Q Predictions Std            292.12344
Q Predictions Max            1416.3973
Q Predictions Min            290.95685
V Predictions Mean           1074.0823
V Predictions Std            292.74033
V Predictions Max            1406.2949
V Predictions Min            294.73273
Log Pis Mean                 -0.2495603
Log Pis Std                  2.5231833
Log Pis Max                  8.01906
Log Pis Min                  -7.073303
Policy mu Mean               0.00891328
Policy mu Std                0.60072577
Policy mu Max                2.286135
Policy mu Min                -2.443389
Policy log std Mean          -0.9550033
Policy log std Std           0.24264991
Policy log std Max           -0.22867703
Policy log std Min           -2.1966248
Z mean eval                  0.92916584
Z variance eval              0.20817992
total_rewards                [3596.68746895 1360.27496081 3759.27683429  212.29955163 3497.70088531
 3493.94904721 3546.72943442 3476.57298275 3586.22576173 3481.10934012]
total_rewards_mean           3001.08262672265
total_rewards_std            1139.5328461948443
total_rewards_max            3759.2768342940985
total_rewards_min            212.29955162809583
Number of train steps total  1592000
Number of env steps total    2737160
Number of rollouts total     0
Train Time (s)               156.10114666400477
(Previous) Eval Time (s)     31.313529575243592
Sample Time (s)              12.52757032494992
Epoch Time (s)               199.94224656419829
Total Train Time (s)         73781.26257531671
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:25:34.742214 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #397 | Epoch Duration: 200.02920770645142
2020-01-12 22:25:34.742410 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9281479
Z variance train             0.20817685
KL Divergence                13.38682
KL Loss                      1.338682
QF Loss                      645.2851
VF Loss                      57.140568
Policy Loss                  -1122.6532
Q Predictions Mean           1119.0275
Q Predictions Std            270.4424
Q Predictions Max            1426.8435
Q Predictions Min            304.75906
V Predictions Mean           1121.9359
V Predictions Std            271.4148
V Predictions Max            1446.7365
V Predictions Min            304.69095
Log Pis Mean                 0.15524974
Log Pis Std                  2.9870818
Log Pis Max                  15.335439
Log Pis Min                  -7.00097
Policy mu Mean               0.0031785362
Policy mu Std                0.6208728
Policy mu Max                2.8535235
Policy mu Min                -2.5785244
Policy log std Mean          -1.0364399
Policy log std Std           0.28003013
Policy log std Max           -0.3664602
Policy log std Min           -2.5653517
Z mean eval                  1.0165315
Z variance eval              0.1580503
total_rewards                [2509.37013311 2686.39667087  691.69686206 3144.45536865 3128.64369681
 1039.78503167 2593.16653929 3163.99204423  225.65499008  142.75451329]
total_rewards_mean           1932.5915850036745
total_rewards_std            1191.9240321420198
total_rewards_max            3163.992044230212
total_rewards_min            142.75451328816246
Number of train steps total  1596000
Number of env steps total    2749257
Number of rollouts total     0
Train Time (s)               154.5582267967984
(Previous) Eval Time (s)     31.17493745405227
Sample Time (s)              12.081610423047096
Epoch Time (s)               197.81477467389777
Total Train Time (s)         73979.17486113682
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:28:52.659163 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #398 | Epoch Duration: 197.9166135787964
2020-01-12 22:28:52.659377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.010751
Z variance train             0.15734473
KL Divergence                13.988701
KL Loss                      1.3988701
QF Loss                      367.58633
VF Loss                      86.43002
Policy Loss                  -1125.0477
Q Predictions Mean           1120.274
Q Predictions Std            266.80075
Q Predictions Max            1433.8766
Q Predictions Min            289.10602
V Predictions Mean           1122.6533
V Predictions Std            269.26648
V Predictions Max            1431.6666
V Predictions Min            286.70807
Log Pis Mean                 0.32760203
Log Pis Std                  2.9205453
Log Pis Max                  8.442077
Log Pis Min                  -7.964823
Policy mu Mean               0.041190796
Policy mu Std                0.62785256
Policy mu Max                2.332108
Policy mu Min                -2.1288953
Policy log std Mean          -1.0242333
Policy log std Std           0.24234895
Policy log std Max           -0.42518842
Policy log std Min           -2.0705683
Z mean eval                  0.99128485
Z variance eval              0.079711735
total_rewards                [2574.19672759   57.85885721  606.58307927  632.73992075 1545.76379607
  487.67610197 3202.8776254   684.24244919  194.46125642 1282.63077672]
total_rewards_mean           1126.9030590596726
total_rewards_std            986.7024693279795
total_rewards_max            3202.8776254030618
total_rewards_min            57.85885721149427
Number of train steps total  1600000
Number of env steps total    2759053
Number of rollouts total     0
Train Time (s)               155.95915522705764
(Previous) Eval Time (s)     13.250663218088448
Sample Time (s)              12.921557479538023
Epoch Time (s)               182.1313759246841
Total Train Time (s)         74161.39794104453
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:31:54.887677 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #399 | Epoch Duration: 182.2281153202057
2020-01-12 22:31:54.888028 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99019825
Z variance train             0.07969177
KL Divergence                13.252669
KL Loss                      1.325267
QF Loss                      262.11038
VF Loss                      70.619354
Policy Loss                  -1149.037
Q Predictions Mean           1144.9396
Q Predictions Std            250.08781
Q Predictions Max            1419.2668
Q Predictions Min            292.35342
V Predictions Mean           1144.5502
V Predictions Std            248.29378
V Predictions Max            1418.673
V Predictions Min            301.69452
Log Pis Mean                 0.4730352
Log Pis Std                  2.4944334
Log Pis Max                  9.309877
Log Pis Min                  -8.168519
Policy mu Mean               -0.048233032
Policy mu Std                0.6507203
Policy mu Max                2.1737375
Policy mu Min                -2.1626868
Policy log std Mean          -0.9499507
Policy log std Std           0.22945416
Policy log std Max           -0.1426726
Policy log std Min           -2.2526112
Z mean eval                  1.0051458
Z variance eval              0.07877834
total_rewards                [3488.10907189 2194.13796508 3532.22597123 3366.37322263   20.03108013
 1411.98077261 3597.54901435 1756.49612556 1649.94601708 3450.65414223]
total_rewards_mean           2446.750338280566
total_rewards_std            1165.1363645121396
total_rewards_max            3597.5490143521483
total_rewards_min            20.03108013446075
Number of train steps total  1604000
Number of env steps total    2769976
Number of rollouts total     0
Train Time (s)               152.4514170079492
(Previous) Eval Time (s)     27.620732359588146
Sample Time (s)              12.927793037611991
Epoch Time (s)               192.99994240514934
Total Train Time (s)         74354.48551318422
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:35:07.978985 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #400 | Epoch Duration: 193.09077620506287
2020-01-12 22:35:07.979168 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0086113
Z variance train             0.07887299
KL Divergence                13.028774
KL Loss                      1.3028774
QF Loss                      340.75272
VF Loss                      73.542755
Policy Loss                  -1085.3966
Q Predictions Mean           1081.1063
Q Predictions Std            301.18927
Q Predictions Max            1412.1311
Q Predictions Min            264.10294
V Predictions Mean           1085.1909
V Predictions Std            300.6089
V Predictions Max            1413.51
V Predictions Min            273.7182
Log Pis Mean                 -0.20417176
Log Pis Std                  2.489364
Log Pis Max                  6.0393906
Log Pis Min                  -7.342661
Policy mu Mean               0.0063265003
Policy mu Std                0.58478546
Policy mu Max                2.5468736
Policy mu Min                -2.0264213
Policy log std Mean          -0.99835336
Policy log std Std           0.2608186
Policy log std Max           -0.29816908
Policy log std Min           -1.9963808
Z mean eval                  0.9222635
Z variance eval              0.058010977
total_rewards                [1689.35608063 2668.01918434 3147.62613776  370.0678458   140.50681724
  237.27338756  581.75611568 3471.92135756 3487.07641087 3445.82763879]
total_rewards_mean           1923.9430976225285
total_rewards_std            1396.5432090963238
total_rewards_max            3487.076410873299
total_rewards_min            140.50681723637257
Number of train steps total  1608000
Number of env steps total    2780076
Number of rollouts total     0
Train Time (s)               144.73098561819643
(Previous) Eval Time (s)     26.304136170074344
Sample Time (s)              11.894977784715593
Epoch Time (s)               182.93009957298636
Total Train Time (s)         74537.50452820398
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:38:11.001933 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #401 | Epoch Duration: 183.02259802818298
2020-01-12 22:38:11.002119 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9115802
Z variance train             0.058360964
KL Divergence                14.066717
KL Loss                      1.4066718
QF Loss                      185.11568
VF Loss                      51.25775
Policy Loss                  -1115.8164
Q Predictions Mean           1112.1323
Q Predictions Std            272.8249
Q Predictions Max            1409.9336
Q Predictions Min            274.6708
V Predictions Mean           1112.4095
V Predictions Std            273.70898
V Predictions Max            1405.9414
V Predictions Min            267.45392
Log Pis Mean                 0.47819847
Log Pis Std                  2.7422519
Log Pis Max                  10.2008295
Log Pis Min                  -9.004873
Policy mu Mean               -0.01302267
Policy mu Std                0.62376016
Policy mu Max                2.1076238
Policy mu Min                -2.2187948
Policy log std Mean          -1.0319895
Policy log std Std           0.25189462
Policy log std Max           -0.36823565
Policy log std Min           -2.0846305
Z mean eval                  1.006738
Z variance eval              0.09965535
total_rewards                [3790.23330972  683.56199081 3515.77439206 3483.44700399 3210.49037053
 1760.12574185 1414.0173022  3377.94867127 1410.38595141  712.13439078]
total_rewards_mean           2335.811912462913
total_rewards_std            1186.575845211895
total_rewards_max            3790.233309722328
total_rewards_min            683.5619908053222
Number of train steps total  1612000
Number of env steps total    2790402
Number of rollouts total     0
Train Time (s)               145.6855387990363
(Previous) Eval Time (s)     26.623129677958786
Sample Time (s)              11.613207587506622
Epoch Time (s)               183.9218760645017
Total Train Time (s)         74721.52739700722
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:41:15.030554 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #402 | Epoch Duration: 184.02825903892517
2020-01-12 22:41:15.030869 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0092934
Z variance train             0.09950353
KL Divergence                13.122034
KL Loss                      1.3122034
QF Loss                      408.72723
VF Loss                      74.89644
Policy Loss                  -1068.2855
Q Predictions Mean           1065.2727
Q Predictions Std            296.80646
Q Predictions Max            1377.4681
Q Predictions Min            248.98438
V Predictions Mean           1062.569
V Predictions Std            299.02585
V Predictions Max            1375.8561
V Predictions Min            245.1047
Log Pis Mean                 -0.17801157
Log Pis Std                  2.638937
Log Pis Max                  8.55203
Log Pis Min                  -7.639982
Policy mu Mean               0.00860361
Policy mu Std                0.60105586
Policy mu Max                2.5836592
Policy mu Min                -2.1887789
Policy log std Mean          -0.9613313
Policy log std Std           0.23998228
Policy log std Max           -0.19564098
Policy log std Min           -1.9142609
Z mean eval                  0.99985063
Z variance eval              0.06744353
total_rewards                [ 793.98261554 2236.18512732 2221.11242933 2828.49000251  367.03952166
 1437.9207869  2375.30332597  724.79287795 1961.54096567 2202.73414213]
total_rewards_mean           1714.9101794989579
total_rewards_std            788.9781153529485
total_rewards_max            2828.490002512055
total_rewards_min            367.0395216575558
Number of train steps total  1616000
Number of env steps total    2800541
Number of rollouts total     0
Train Time (s)               155.30553232412785
(Previous) Eval Time (s)     17.88006603671238
Sample Time (s)              12.15343527821824
Epoch Time (s)               185.33903363905847
Total Train Time (s)         74906.97159647476
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:44:20.479349 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #403 | Epoch Duration: 185.44824385643005
2020-01-12 22:44:20.479694 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9951867
Z variance train             0.0671704
KL Divergence                13.088654
KL Loss                      1.3088654
QF Loss                      10907.98
VF Loss                      179.60635
Policy Loss                  -1127.7733
Q Predictions Mean           1123.8661
Q Predictions Std            238.03366
Q Predictions Max            1394.6606
Q Predictions Min            269.59677
V Predictions Mean           1133.7765
V Predictions Std            239.5595
V Predictions Max            1407.4987
V Predictions Min            253.63474
Log Pis Mean                 0.60773814
Log Pis Std                  2.831966
Log Pis Max                  8.758132
Log Pis Min                  -7.715802
Policy mu Mean               -0.036970604
Policy mu Std                0.63161445
Policy mu Max                2.3540518
Policy mu Min                -2.4532053
Policy log std Mean          -1.0426514
Policy log std Std           0.27334702
Policy log std Max           -0.2276454
Policy log std Min           -2.5089803
Z mean eval                  0.96793497
Z variance eval              0.11342861
total_rewards                [ 348.31401314  261.36719766 1362.35822751  702.67641559   43.27808306
 2626.20818599 1373.01046787  868.1609487  1101.77214074 1423.31642187]
total_rewards_mean           1011.0462102155718
total_rewards_std            713.7716897028516
total_rewards_max            2626.2081859870286
total_rewards_min            43.278083064953975
Number of train steps total  1620000
Number of env steps total    2811847
Number of rollouts total     0
Train Time (s)               154.24752862704918
(Previous) Eval Time (s)     24.278809285722673
Sample Time (s)              12.658774298150092
Epoch Time (s)               191.18511221092194
Total Train Time (s)         75098.28046153439
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:47:31.792108 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #404 | Epoch Duration: 191.31222677230835
2020-01-12 22:47:31.792312 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96862423
Z variance train             0.113956906
KL Divergence                11.860609
KL Loss                      1.1860609
QF Loss                      297.4188
VF Loss                      85.46145
Policy Loss                  -1102.836
Q Predictions Mean           1100.2141
Q Predictions Std            256.9236
Q Predictions Max            1385.3191
Q Predictions Min            255.75063
V Predictions Mean           1108.8566
V Predictions Std            257.95032
V Predictions Max            1376.1711
V Predictions Min            256.6523
Log Pis Mean                 0.013633788
Log Pis Std                  2.6297765
Log Pis Max                  9.77361
Log Pis Min                  -6.740343
Policy mu Mean               0.02846745
Policy mu Std                0.6115846
Policy mu Max                2.333548
Policy mu Min                -2.2424855
Policy log std Mean          -1.0006111
Policy log std Std           0.23717676
Policy log std Max           -0.32820326
Policy log std Min           -2.0433674
Z mean eval                  0.91901225
Z variance eval              0.16683103
total_rewards                [3546.65884597 3628.54032286  186.09779538  556.28847425 1307.11160748
 2217.35139105 1073.68684026  792.00759249 1140.31155837 3697.53641744]
total_rewards_mean           1814.5590845566742
total_rewards_std            1286.0905799633229
total_rewards_max            3697.5364174439096
total_rewards_min            186.09779537804408
Number of train steps total  1624000
Number of env steps total    2822349
Number of rollouts total     0
Train Time (s)               153.57601160695776
(Previous) Eval Time (s)     17.195209776982665
Sample Time (s)              11.853267888072878
Epoch Time (s)               182.6244892720133
Total Train Time (s)         75281.01079714531
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:50:34.527569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #405 | Epoch Duration: 182.73506140708923
2020-01-12 22:50:34.527961 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9224512
Z variance train             0.16524322
KL Divergence                11.073491
KL Loss                      1.1073492
QF Loss                      297.77917
VF Loss                      77.81245
Policy Loss                  -1090.1626
Q Predictions Mean           1083.5923
Q Predictions Std            264.31128
Q Predictions Max            1376.3551
Q Predictions Min            226.86063
V Predictions Mean           1086.0227
V Predictions Std            264.49088
V Predictions Max            1356.8654
V Predictions Min            233.3221
Log Pis Mean                 0.34929535
Log Pis Std                  2.946172
Log Pis Max                  14.444134
Log Pis Min                  -9.192203
Policy mu Mean               -0.04804992
Policy mu Std                0.6349948
Policy mu Max                2.8160708
Policy mu Min                -2.7157536
Policy log std Mean          -1.0110204
Policy log std Std           0.25489193
Policy log std Max           -0.36340022
Policy log std Min           -2.1150951
Z mean eval                  0.8976551
Z variance eval              0.030966219
total_rewards                [ 264.69435297 3550.71243214  867.79395093 3423.66968768 2596.75690742
 3402.50018754 1170.02350054 2050.93565538 3228.03999137 2515.7243398 ]
total_rewards_mean           2307.085100575285
total_rewards_std            1121.1754051588455
total_rewards_max            3550.712432141842
total_rewards_min            264.6943529659498
Number of train steps total  1628000
Number of env steps total    2833321
Number of rollouts total     0
Train Time (s)               155.25630477862433
(Previous) Eval Time (s)     25.332323462236673
Sample Time (s)              12.373795459978282
Epoch Time (s)               192.96242370083928
Total Train Time (s)         75474.05881913286
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:53:47.579754 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #406 | Epoch Duration: 193.05157279968262
2020-01-12 22:53:47.579943 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8947837
Z variance train             0.030984676
KL Divergence                14.755705
KL Loss                      1.4755706
QF Loss                      528.7195
VF Loss                      477.5897
Policy Loss                  -1139.3326
Q Predictions Mean           1135.4032
Q Predictions Std            254.12444
Q Predictions Max            1412.0695
Q Predictions Min            277.36203
V Predictions Mean           1152.1984
V Predictions Std            257.19504
V Predictions Max            1449.6276
V Predictions Min            281.19415
Log Pis Mean                 0.28647125
Log Pis Std                  2.777952
Log Pis Max                  12.715866
Log Pis Min                  -8.155733
Policy mu Mean               -0.03230661
Policy mu Std                0.6354558
Policy mu Max                3.687905
Policy mu Min                -2.3128486
Policy log std Mean          -0.9968655
Policy log std Std           0.24307819
Policy log std Max           -0.38620698
Policy log std Min           -2.792676
Z mean eval                  1.0709819
Z variance eval              0.047082882
total_rewards                [ 275.60256128 2661.06927249 3526.05804792 3628.6359954  1863.78582971
 2350.35984902 3449.76277306 3421.78625558 1701.79787593 2592.49938589]
total_rewards_mean           2547.1357846282185
total_rewards_std            1005.1301617405643
total_rewards_max            3628.635995401435
total_rewards_min            275.60256128057426
Number of train steps total  1632000
Number of env steps total    2842802
Number of rollouts total     0
Train Time (s)               149.71840478712693
(Previous) Eval Time (s)     33.30803974997252
Sample Time (s)              12.469655907712877
Epoch Time (s)               195.49610044481233
Total Train Time (s)         75669.65465013077
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:57:03.180401 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #407 | Epoch Duration: 195.60028958320618
2020-01-12 22:57:03.180706 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0744317
Z variance train             0.04724563
KL Divergence                14.240313
KL Loss                      1.4240313
QF Loss                      1197.5608
VF Loss                      125.07004
Policy Loss                  -1118.8112
Q Predictions Mean           1117.172
Q Predictions Std            245.77513
Q Predictions Max            1428.6791
Q Predictions Min            260.77655
V Predictions Mean           1117.1123
V Predictions Std            247.24763
V Predictions Max            1428.1104
V Predictions Min            252.12679
Log Pis Mean                 0.3257307
Log Pis Std                  2.7005377
Log Pis Max                  8.7645855
Log Pis Min                  -6.417373
Policy mu Mean               0.009924113
Policy mu Std                0.59032536
Policy mu Max                1.9669101
Policy mu Min                -2.416938
Policy log std Mean          -1.0206088
Policy log std Std           0.2427495
Policy log std Max           -0.32574695
Policy log std Min           -2.3355055
Z mean eval                  0.9617669
Z variance eval              0.12487692
total_rewards                [3189.10920566 2817.49953045 2838.24247712 3331.55012212 3585.69928221
 3279.23912338 3288.85844171  205.7073408  3514.5764711   852.52669581]
total_rewards_mean           2690.300869034967
total_rewards_std            1115.1225723733403
total_rewards_max            3585.6992822144816
total_rewards_min            205.70734079742
Number of train steps total  1636000
Number of env steps total    2853449
Number of rollouts total     0
Train Time (s)               145.26164772268385
(Previous) Eval Time (s)     31.03256217110902
Sample Time (s)              12.375348755158484
Epoch Time (s)               188.66955864895135
Total Train Time (s)         75858.41937488224
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:00:11.949757 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #408 | Epoch Duration: 188.76884293556213
2020-01-12 23:00:11.949979 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9601151
Z variance train             0.12591115
KL Divergence                13.169754
KL Loss                      1.3169755
QF Loss                      340.62408
VF Loss                      125.739204
Policy Loss                  -1135.4832
Q Predictions Mean           1131.0964
Q Predictions Std            250.48923
Q Predictions Max            1469.1925
Q Predictions Min            246.37955
V Predictions Mean           1143.3827
V Predictions Std            251.26245
V Predictions Max            1472.8507
V Predictions Min            256.1241
Log Pis Mean                 -0.114337206
Log Pis Std                  2.5759127
Log Pis Max                  6.9330554
Log Pis Min                  -8.135688
Policy mu Mean               -0.044684157
Policy mu Std                0.6074054
Policy mu Max                2.1647186
Policy mu Min                -2.1162004
Policy log std Mean          -0.98894846
Policy log std Std           0.23348011
Policy log std Max           -0.28121656
Policy log std Min           -1.9776442
Z mean eval                  0.91608846
Z variance eval              0.44213247
total_rewards                [1700.93657154  943.03297896  186.431378    774.78496827 2816.96313517
  438.0808013  3521.71094282  738.03293285  267.16388745 3539.50339091]
total_rewards_mean           1492.6640987278574
total_rewards_std            1257.4132643830633
total_rewards_max            3539.503390914507
total_rewards_min            186.4313779990299
Number of train steps total  1640000
Number of env steps total    2865629
Number of rollouts total     0
Train Time (s)               149.19044243684039
(Previous) Eval Time (s)     22.468032172881067
Sample Time (s)              12.16423610644415
Epoch Time (s)               183.8227107161656
Total Train Time (s)         76042.34692145744
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:03:15.882465 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #409 | Epoch Duration: 183.93229269981384
2020-01-12 23:03:15.882835 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91781473
Z variance train             0.44250083
KL Divergence                12.993185
KL Loss                      1.2993186
QF Loss                      549.1829
VF Loss                      65.68995
Policy Loss                  -1066.0754
Q Predictions Mean           1059.8691
Q Predictions Std            277.3792
Q Predictions Max            1376.1335
Q Predictions Min            82.84005
V Predictions Mean           1063.5579
V Predictions Std            276.3486
V Predictions Max            1378.7655
V Predictions Min            238.363
Log Pis Mean                 0.1278583
Log Pis Std                  2.8460991
Log Pis Max                  8.735104
Log Pis Min                  -7.2958465
Policy mu Mean               -0.049363583
Policy mu Std                0.6347301
Policy mu Max                2.7696152
Policy mu Min                -2.4635923
Policy log std Mean          -1.0046574
Policy log std Std           0.24940802
Policy log std Max           -0.055687487
Policy log std Min           -1.8322968
Z mean eval                  1.0285044
Z variance eval              0.048641898
total_rewards                [ 655.94592462 1230.36468115 1292.4201732  3573.88711571 1557.31040691
 1207.25662127 1729.05681474 3349.77316769  856.34686485  232.47790882]
total_rewards_mean           1568.4839678947394
total_rewards_std            1032.7797285385213
total_rewards_max            3573.887115705783
total_rewards_min            232.47790881562062
Number of train steps total  1644000
Number of env steps total    2876780
Number of rollouts total     0
Train Time (s)               156.4626654391177
(Previous) Eval Time (s)     20.86139238020405
Sample Time (s)              12.670436256565154
Epoch Time (s)               189.9944940758869
Total Train Time (s)         76232.43508755323
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:06:25.980185 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #410 | Epoch Duration: 190.09709429740906
2020-01-12 23:06:25.980372 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.030714
Z variance train             0.049184132
KL Divergence                14.808832
KL Loss                      1.4808832
QF Loss                      473.5301
VF Loss                      216.80856
Policy Loss                  -1111.8079
Q Predictions Mean           1109.2306
Q Predictions Std            266.4902
Q Predictions Max            1405.4764
Q Predictions Min            271.32703
V Predictions Mean           1108.5884
V Predictions Std            268.42447
V Predictions Max            1389.0045
V Predictions Min            266.9193
Log Pis Mean                 0.05537325
Log Pis Std                  2.7108533
Log Pis Max                  11.562965
Log Pis Min                  -7.067201
Policy mu Mean               -0.0021542334
Policy mu Std                0.5933053
Policy mu Max                2.7744179
Policy mu Min                -2.29037
Policy log std Mean          -1.0341716
Policy log std Std           0.2582155
Policy log std Max           -0.3456753
Policy log std Min           -2.4645362
Z mean eval                  0.99262553
Z variance eval              0.12271931
total_rewards                [3539.07750028  573.9709319  1111.42306124  883.69375163 3506.03086208
 2529.10436584  688.14550423  403.2573191  3632.35451132 1595.4765638 ]
total_rewards_mean           1846.253437142351
total_rewards_std            1258.9081487900046
total_rewards_max            3632.354511323655
total_rewards_min            403.25731910484444
Number of train steps total  1648000
Number of env steps total    2885562
Number of rollouts total     0
Train Time (s)               154.97096049180254
(Previous) Eval Time (s)     28.37504075979814
Sample Time (s)              12.481939830817282
Epoch Time (s)               195.82794108241796
Total Train Time (s)         76428.36178417504
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:09:41.905379 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #411 | Epoch Duration: 195.92485857009888
2020-01-12 23:09:41.905580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9813365
Z variance train             0.121252455
KL Divergence                13.449715
KL Loss                      1.3449715
QF Loss                      532.7234
VF Loss                      81.20479
Policy Loss                  -1137.9982
Q Predictions Mean           1131.762
Q Predictions Std            234.05363
Q Predictions Max            1386.2443
Q Predictions Min            234.01302
V Predictions Mean           1138.1761
V Predictions Std            226.74721
V Predictions Max            1384.9797
V Predictions Min            246.45314
Log Pis Mean                 0.29241198
Log Pis Std                  3.2592454
Log Pis Max                  20.39815
Log Pis Min                  -8.491224
Policy mu Mean               -0.0002097683
Policy mu Std                0.653706
Policy mu Max                2.5051858
Policy mu Min                -3.4662309
Policy log std Mean          -1.038216
Policy log std Std           0.2538892
Policy log std Max           -0.0014657974
Policy log std Min           -2.5656834
Z mean eval                  0.93996847
Z variance eval              0.03801196
total_rewards                [2581.09940811  317.71482886 1567.70400598 1316.36500947  327.24536961
  280.45085401 2479.10976161 2866.92640999 1604.22874915 2304.65759842]
total_rewards_mean           1564.550199522468
total_rewards_std            943.9993260979458
total_rewards_max            2866.9264099921243
total_rewards_min            280.4508540116959
Number of train steps total  1652000
Number of env steps total    2896280
Number of rollouts total     0
Train Time (s)               156.22157031297684
(Previous) Eval Time (s)     20.141460770275444
Sample Time (s)              11.845009332057089
Epoch Time (s)               188.20804041530937
Total Train Time (s)         76616.65605483018
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:12:50.204304 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #412 | Epoch Duration: 188.29855823516846
2020-01-12 23:12:50.204578 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93888694
Z variance train             0.037969418
KL Divergence                15.792183
KL Loss                      1.5792183
QF Loss                      223.38094
VF Loss                      77.17287
Policy Loss                  -1103.386
Q Predictions Mean           1097.8545
Q Predictions Std            280.6521
Q Predictions Max            1405.646
Q Predictions Min            240.47903
V Predictions Mean           1104.4805
V Predictions Std            279.41064
V Predictions Max            1404.4865
V Predictions Min            255.054
Log Pis Mean                 0.653453
Log Pis Std                  2.8503866
Log Pis Max                  14.518463
Log Pis Min                  -6.3638716
Policy mu Mean               0.04155583
Policy mu Std                0.6321641
Policy mu Max                2.354663
Policy mu Min                -2.3572078
Policy log std Mean          -1.0101911
Policy log std Std           0.2652387
Policy log std Max           -0.26677734
Policy log std Min           -2.1763558
Z mean eval                  0.9775872
Z variance eval              0.03423094
total_rewards                [  65.68692063 1811.92750796 1934.87599718 2888.55726276 3670.91357593
  529.17892236 3378.94840373 3621.11538715 2021.86487699 3524.77916245]
total_rewards_mean           2344.784801715317
total_rewards_std            1232.564728024452
total_rewards_max            3670.9135759330934
total_rewards_min            65.68692062591875
Number of train steps total  1656000
Number of env steps total    2907378
Number of rollouts total     0
Train Time (s)               154.4405668983236
(Previous) Eval Time (s)     25.940056776162237
Sample Time (s)              11.924338568933308
Epoch Time (s)               192.30496224341914
Total Train Time (s)         76809.08524649125
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:16:02.637498 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #413 | Epoch Duration: 192.43275451660156
2020-01-12 23:16:02.637681 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9763341
Z variance train             0.03469326
KL Divergence                15.818953
KL Loss                      1.5818952
QF Loss                      814.0257
VF Loss                      98.67848
Policy Loss                  -1117.7451
Q Predictions Mean           1114.588
Q Predictions Std            246.31499
Q Predictions Max            1392.5452
Q Predictions Min            216.07573
V Predictions Mean           1124.8542
V Predictions Std            244.58707
V Predictions Max            1398.632
V Predictions Min            214.90994
Log Pis Mean                 0.3692861
Log Pis Std                  2.6423647
Log Pis Max                  13.655827
Log Pis Min                  -8.848842
Policy mu Mean               -0.013784019
Policy mu Std                0.6082532
Policy mu Max                2.2851787
Policy mu Min                -2.327499
Policy log std Mean          -1.0372182
Policy log std Std           0.24324411
Policy log std Max           -0.43578017
Policy log std Min           -2.4553428
Z mean eval                  0.96539986
Z variance eval              0.11309256
total_rewards                [1280.19568814  528.10572786  464.84137697 1400.6954481  3695.05999538
 3363.44526615 3766.87252798  857.52271537 1313.05984461 2514.0193903 ]
total_rewards_mean           1918.381798086118
total_rewards_std            1234.0689040383274
total_rewards_max            3766.8725279830137
total_rewards_min            464.8413769671108
Number of train steps total  1660000
Number of env steps total    2917816
Number of rollouts total     0
Train Time (s)               146.40055381366983
(Previous) Eval Time (s)     27.70593979768455
Sample Time (s)              11.897097694687545
Epoch Time (s)               186.00359130604193
Total Train Time (s)         76995.17955479398
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:19:08.737184 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #414 | Epoch Duration: 186.09934830665588
2020-01-12 23:19:08.737466 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9808518
Z variance train             0.11348933
KL Divergence                13.936327
KL Loss                      1.3936328
QF Loss                      11997.734
VF Loss                      583.7556
Policy Loss                  -1129.3893
Q Predictions Mean           1126.9924
Q Predictions Std            298.98288
Q Predictions Max            1423.6437
Q Predictions Min            -61.910023
V Predictions Mean           1141.8
V Predictions Std            293.07956
V Predictions Max            1446.797
V Predictions Min            272.99783
Log Pis Mean                 -0.09113977
Log Pis Std                  2.7416208
Log Pis Max                  11.3121
Log Pis Min                  -6.6643248
Policy mu Mean               -0.0057623424
Policy mu Std                0.58706945
Policy mu Max                1.9015441
Policy mu Min                -2.2217615
Policy log std Mean          -0.9968153
Policy log std Std           0.24928959
Policy log std Max           -0.39214644
Policy log std Min           -2.1489372
Z mean eval                  1.0014805
Z variance eval              0.08682105
total_rewards                [1813.81628661 3661.01490955 3039.97556733 1026.90080857 3483.00615876
 3571.96476327 3324.01641917  484.12052581  721.16370613 1863.90089278]
total_rewards_mean           2298.9880037980915
total_rewards_std            1195.9683789119488
total_rewards_max            3661.014909545657
total_rewards_min            484.1205258144153
Number of train steps total  1664000
Number of env steps total    2927820
Number of rollouts total     0
Train Time (s)               146.33085096813738
(Previous) Eval Time (s)     25.65144157782197
Sample Time (s)              12.288505043834448
Epoch Time (s)               184.2707975897938
Total Train Time (s)         77179.54220879357
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:22:13.106052 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #415 | Epoch Duration: 184.36837196350098
2020-01-12 23:22:13.106445 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0033443
Z variance train             0.086709544
KL Divergence                13.382925
KL Loss                      1.3382925
QF Loss                      5973.668
VF Loss                      132.66737
Policy Loss                  -1151.376
Q Predictions Mean           1147.8347
Q Predictions Std            238.32567
Q Predictions Max            1436.6492
Q Predictions Min            287.1265
V Predictions Mean           1145.1038
V Predictions Std            238.05464
V Predictions Max            1428.0895
V Predictions Min            279.99988
Log Pis Mean                 0.39423037
Log Pis Std                  2.4105456
Log Pis Max                  10.938554
Log Pis Min                  -5.5451455
Policy mu Mean               -0.020453546
Policy mu Std                0.60021275
Policy mu Max                2.0858054
Policy mu Min                -2.4451127
Policy log std Mean          -1.0485405
Policy log std Std           0.24691488
Policy log std Max           -0.2796077
Policy log std Min           -2.1091938
Z mean eval                  0.94014883
Z variance eval              0.0538132
total_rewards                [3313.2100572  3568.07461015 1759.60809659  497.1475296  3261.9194939
 2472.70486384 3345.405805    336.61358552 3593.97064783 3291.90896568]
total_rewards_mean           2544.0563655314404
total_rewards_std            1189.2179029386816
total_rewards_max            3593.9706478267044
total_rewards_min            336.6135855232684
Number of train steps total  1668000
Number of env steps total    2937247
Number of rollouts total     0
Train Time (s)               152.14923598291352
(Previous) Eval Time (s)     28.21739216800779
Sample Time (s)              11.411131941713393
Epoch Time (s)               191.7777600926347
Total Train Time (s)         77371.41717532929
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:25:24.984537 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #416 | Epoch Duration: 191.8778612613678
2020-01-12 23:25:24.984743 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93462926
Z variance train             0.053497832
KL Divergence                14.47287
KL Loss                      1.447287
QF Loss                      1172.7744
VF Loss                      98.05417
Policy Loss                  -1187.1371
Q Predictions Mean           1183.8271
Q Predictions Std            247.37619
Q Predictions Max            1442.896
Q Predictions Min            239.02603
V Predictions Mean           1192.858
V Predictions Std            248.6508
V Predictions Max            1446.9886
V Predictions Min            235.69289
Log Pis Mean                 0.52888155
Log Pis Std                  2.3745725
Log Pis Max                  8.82132
Log Pis Min                  -6.3358903
Policy mu Mean               0.0035130354
Policy mu Std                0.6243371
Policy mu Max                2.253912
Policy mu Min                -1.9903983
Policy log std Mean          -1.0403506
Policy log std Std           0.24515699
Policy log std Max           0.1843695
Policy log std Min           -2.0060644
Z mean eval                  0.9788097
Z variance eval              0.14469256
total_rewards                [1328.72523392 -316.67531722 3721.29745752 2716.01695022 2442.95169574
 1211.06993488 3573.46504769   12.99061928 -211.35642787  674.99675296]
total_rewards_mean           1515.348194712543
total_rewards_std            1443.3506873613103
total_rewards_max            3721.2974575171947
total_rewards_min            -316.6753172181087
Number of train steps total  1672000
Number of env steps total    2948457
Number of rollouts total     0
Train Time (s)               155.58559090038761
(Previous) Eval Time (s)     24.709924592636526
Sample Time (s)              11.128868691623211
Epoch Time (s)               191.42438418464735
Total Train Time (s)         77562.9293186781
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:28:36.502534 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #417 | Epoch Duration: 191.51761770248413
2020-01-12 23:28:36.502867 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97554
Z variance train             0.14622626
KL Divergence                12.459871
KL Loss                      1.2459872
QF Loss                      891.2073
VF Loss                      607.66473
Policy Loss                  -1148.7587
Q Predictions Mean           1143.5559
Q Predictions Std            260.70364
Q Predictions Max            1474.4816
Q Predictions Min            280.76135
V Predictions Mean           1150.4082
V Predictions Std            259.67017
V Predictions Max            1467.2919
V Predictions Min            285.5934
Log Pis Mean                 0.4532717
Log Pis Std                  2.8817914
Log Pis Max                  11.340348
Log Pis Min                  -7.4647546
Policy mu Mean               -0.053833194
Policy mu Std                0.6368782
Policy mu Max                2.1656823
Policy mu Min                -2.760436
Policy log std Mean          -1.0445852
Policy log std Std           0.2530295
Policy log std Max           -0.34330106
Policy log std Min           -2.15167
Z mean eval                  0.96132267
Z variance eval              0.055261202
total_rewards                [3326.83219334 3553.79176839 3571.36051218 1386.51936289 3501.12304109
 1660.02986527 1139.00322646 3557.36861396 3461.88036551 3473.39805436]
total_rewards_mean           2863.13070034505
total_rewards_std            970.257562290747
total_rewards_max            3571.360512175293
total_rewards_min            1139.0032264609222
Number of train steps total  1676000
Number of env steps total    2960826
Number of rollouts total     0
Train Time (s)               154.02694790810347
(Previous) Eval Time (s)     33.10198389785364
Sample Time (s)              12.944504613988101
Epoch Time (s)               200.0734364199452
Total Train Time (s)         77763.09640218224
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:31:56.673701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #418 | Epoch Duration: 200.17065978050232
2020-01-12 23:31:56.673889 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9667107
Z variance train             0.055029847
KL Divergence                13.852278
KL Loss                      1.3852278
QF Loss                      447.9926
VF Loss                      417.41043
Policy Loss                  -1155.5292
Q Predictions Mean           1143.9087
Q Predictions Std            229.27063
Q Predictions Max            1432.1268
Q Predictions Min            1.2719038
V Predictions Mean           1150.2598
V Predictions Std            218.70435
V Predictions Max            1421.3433
V Predictions Min            260.0745
Log Pis Mean                 0.831768
Log Pis Std                  2.632288
Log Pis Max                  13.286062
Log Pis Min                  -7.7046146
Policy mu Mean               -0.026334967
Policy mu Std                0.6615259
Policy mu Max                3.2142792
Policy mu Min                -2.7300775
Policy log std Mean          -1.0354618
Policy log std Std           0.23140714
Policy log std Max           -0.35268253
Policy log std Min           -2.1777983
Z mean eval                  0.92990905
Z variance eval              0.06700621
total_rewards                [1443.46589633  346.79026289  121.79793502 1537.68761218 3665.72966431
 1282.52226354 1753.86939298 3136.08353124 1088.08324897 1803.02899711]
total_rewards_mean           1617.9058804584452
total_rewards_std            1040.9291350372512
total_rewards_max            3665.7296643112318
total_rewards_min            121.79793502108353
Number of train steps total  1680000
Number of env steps total    2971415
Number of rollouts total     0
Train Time (s)               157.02904765168205
(Previous) Eval Time (s)     21.9490875499323
Sample Time (s)              12.10880900034681
Epoch Time (s)               191.08694420196116
Total Train Time (s)         77954.29188972339
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:35:07.873849 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #419 | Epoch Duration: 191.1998131275177
2020-01-12 23:35:07.874059 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9317854
Z variance train             0.06719952
KL Divergence                13.330717
KL Loss                      1.3330717
QF Loss                      709.58704
VF Loss                      120.28067
Policy Loss                  -1151.686
Q Predictions Mean           1145.8877
Q Predictions Std            226.4775
Q Predictions Max            1449.1167
Q Predictions Min            264.9384
V Predictions Mean           1148.8594
V Predictions Std            225.44844
V Predictions Max            1442.5426
V Predictions Min            261.7763
Log Pis Mean                 0.31691954
Log Pis Std                  2.5369132
Log Pis Max                  10.313698
Log Pis Min                  -8.334292
Policy mu Mean               -0.037496664
Policy mu Std                0.62106645
Policy mu Max                2.0924127
Policy mu Min                -2.1578765
Policy log std Mean          -1.0222551
Policy log std Std           0.23695107
Policy log std Max           -0.19348669
Policy log std Min           -2.214044
Z mean eval                  0.9527197
Z variance eval              0.058262367
total_rewards                [ 502.76150765  465.5139358  1551.56202861  312.89762374 1460.04147224
 2384.48292916 1760.53847505 1483.99366854  428.66400642  574.7776455 ]
total_rewards_mean           1092.5233292697092
total_rewards_std            683.5191878971808
total_rewards_max            2384.4829291570522
total_rewards_min            312.8976237403235
Number of train steps total  1684000
Number of env steps total    2983311
Number of rollouts total     0
Train Time (s)               154.2000241712667
(Previous) Eval Time (s)     17.31940729310736
Sample Time (s)              12.428962695877999
Epoch Time (s)               183.94839416025206
Total Train Time (s)         78138.33051297581
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:38:11.916685 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #420 | Epoch Duration: 184.0424680709839
2020-01-12 23:38:11.916886 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95706254
Z variance train             0.058393247
KL Divergence                14.347567
KL Loss                      1.4347566
QF Loss                      12116.185
VF Loss                      57.347923
Policy Loss                  -1218.0854
Q Predictions Mean           1213.0481
Q Predictions Std            234.0186
Q Predictions Max            1474.0493
Q Predictions Min            275.32767
V Predictions Mean           1220.0642
V Predictions Std            230.79369
V Predictions Max            1467.6558
V Predictions Min            293.32312
Log Pis Mean                 0.37548903
Log Pis Std                  2.6572902
Log Pis Max                  8.689292
Log Pis Min                  -8.92867
Policy mu Mean               -0.013387449
Policy mu Std                0.63379306
Policy mu Max                2.6898124
Policy mu Min                -2.1357923
Policy log std Mean          -1.0273833
Policy log std Std           0.22961617
Policy log std Max           -0.059039235
Policy log std Min           -2.0568032
Z mean eval                  1.0072119
Z variance eval              0.05061982
total_rewards                [ 849.58427116 2088.92882596 2547.73053585  423.79622474 2780.5587011
   73.29498246 2914.77643394   23.74985908  769.08315936 1538.41000671]
total_rewards_mean           1400.9913000356041
total_rewards_std            1063.9428454811136
total_rewards_max            2914.7764339403484
total_rewards_min            23.749859080006104
Number of train steps total  1688000
Number of env steps total    2993925
Number of rollouts total     0
Train Time (s)               146.12910269619897
(Previous) Eval Time (s)     20.916786100249738
Sample Time (s)              11.600009799934924
Epoch Time (s)               178.64589859638363
Total Train Time (s)         78317.07772767125
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:41:10.668626 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #421 | Epoch Duration: 178.7515950202942
2020-01-12 23:41:10.668822 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0058415
Z variance train             0.05102859
KL Divergence                14.169016
KL Loss                      1.4169016
QF Loss                      670.25354
VF Loss                      195.3543
Policy Loss                  -1263.5905
Q Predictions Mean           1256.3041
Q Predictions Std            174.06877
Q Predictions Max            1501.2533
Q Predictions Min            335.6498
V Predictions Mean           1262.5068
V Predictions Std            173.9047
V Predictions Max            1516.206
V Predictions Min            339.58817
Log Pis Mean                 0.7205797
Log Pis Std                  2.7707295
Log Pis Max                  15.975512
Log Pis Min                  -4.7889795
Policy mu Mean               -0.025922654
Policy mu Std                0.6541232
Policy mu Max                2.6182942
Policy mu Min                -2.493511
Policy log std Mean          -1.0525906
Policy log std Std           0.26709655
Policy log std Max           -0.27882516
Policy log std Min           -3.087914
Z mean eval                  1.1191959
Z variance eval              0.034593157
total_rewards                [3220.40498382 3256.24117627 3442.2948704   178.6247844  3208.95488437
 1521.09226275 3469.56633204 2050.82009506 3335.9007756  3258.86255959]
total_rewards_mean           2694.2762724286545
total_rewards_std            1042.470872870973
total_rewards_max            3469.566332039657
total_rewards_min            178.62478439932343
Number of train steps total  1692000
Number of env steps total    3003671
Number of rollouts total     0
Train Time (s)               145.54209599411115
(Previous) Eval Time (s)     30.009150844998658
Sample Time (s)              12.392041468527168
Epoch Time (s)               187.94328830763698
Total Train Time (s)         78505.1280228938
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:44:18.723838 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #422 | Epoch Duration: 188.0548496246338
2020-01-12 23:44:18.724184 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1163948
Z variance train             0.03445415
KL Divergence                15.157558
KL Loss                      1.5157559
QF Loss                      445.02435
VF Loss                      106.93751
Policy Loss                  -1172.2549
Q Predictions Mean           1165.1165
Q Predictions Std            202.4522
Q Predictions Max            1433.0253
Q Predictions Min            248.19629
V Predictions Mean           1165.2792
V Predictions Std            201.1939
V Predictions Max            1426.3633
V Predictions Min            255.40295
Log Pis Mean                 0.53747827
Log Pis Std                  2.3951132
Log Pis Max                  8.124689
Log Pis Min                  -8.122932
Policy mu Mean               -0.02162935
Policy mu Std                0.6251301
Policy mu Max                2.1415224
Policy mu Min                -2.3655753
Policy log std Mean          -1.0537205
Policy log std Std           0.24894582
Policy log std Max           -0.37253183
Policy log std Min           -2.093804
Z mean eval                  0.87028134
Z variance eval              0.13345876
total_rewards                [3560.58827022 3637.27735658 3287.36141513 2280.34675628 2358.80071717
 3632.54752531 2400.03869319 2540.22072184 1249.90077743 3625.77248055]
total_rewards_mean           2857.2854713701554
total_rewards_std            771.6363507391436
total_rewards_max            3637.2773565802318
total_rewards_min            1249.9007774309878
Number of train steps total  1696000
Number of env steps total    3015546
Number of rollouts total     0
Train Time (s)               155.595994703006
(Previous) Eval Time (s)     31.420724655035883
Sample Time (s)              11.636585192289203
Epoch Time (s)               198.6533045503311
Total Train Time (s)         78703.86780468235
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:47:37.467630 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #423 | Epoch Duration: 198.7432713508606
2020-01-12 23:47:37.467823 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87109995
Z variance train             0.13303182
KL Divergence                11.751453
KL Loss                      1.1751454
QF Loss                      421.2157
VF Loss                      182.49414
Policy Loss                  -1112.5775
Q Predictions Mean           1106.6521
Q Predictions Std            210.12311
Q Predictions Max            1347.8068
Q Predictions Min            243.56503
V Predictions Mean           1112.6981
V Predictions Std            206.26828
V Predictions Max            1359.7062
V Predictions Min            238.42737
Log Pis Mean                 0.48114467
Log Pis Std                  2.6486886
Log Pis Max                  14.617708
Log Pis Min                  -10.96224
Policy mu Mean               -0.01722417
Policy mu Std                0.6143338
Policy mu Max                3.2675445
Policy mu Min                -2.030616
Policy log std Mean          -1.0553669
Policy log std Std           0.25339755
Policy log std Max           -0.35937053
Policy log std Min           -2.5574193
Z mean eval                  1.0171025
Z variance eval              0.08371123
total_rewards                [3372.82860509 3524.17505052 2175.36032864  318.31975223 3289.00455232
  183.50361934 1401.09867369 3322.89899059 3647.39074883 3328.24266113]
total_rewards_mean           2456.282298238157
total_rewards_std            1285.7952219653328
total_rewards_max            3647.3907488261048
total_rewards_min            183.5036193415989
Number of train steps total  1700000
Number of env steps total    3026798
Number of rollouts total     0
Train Time (s)               155.14173313369974
(Previous) Eval Time (s)     35.93969185091555
Sample Time (s)              12.449007394257933
Epoch Time (s)               203.53043237887323
Total Train Time (s)         78907.48523473041
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:51:01.089811 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #424 | Epoch Duration: 203.62184238433838
2020-01-12 23:51:01.090005 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0236164
Z variance train             0.08392816
KL Divergence                13.732601
KL Loss                      1.3732601
QF Loss                      496.17395
VF Loss                      56.985317
Policy Loss                  -1163.4974
Q Predictions Mean           1158.572
Q Predictions Std            205.52855
Q Predictions Max            1448.292
Q Predictions Min            279.03345
V Predictions Mean           1163.5999
V Predictions Std            205.74306
V Predictions Max            1451.171
V Predictions Min            274.63266
Log Pis Mean                 0.59927857
Log Pis Std                  2.5883765
Log Pis Max                  11.363991
Log Pis Min                  -7.7232056
Policy mu Mean               -0.023274342
Policy mu Std                0.61571944
Policy mu Max                2.1281343
Policy mu Min                -2.2544854
Policy log std Mean          -1.0759804
Policy log std Std           0.26547685
Policy log std Max           -0.4057405
Policy log std Min           -2.454711
Z mean eval                  1.0099783
Z variance eval              0.085369304
total_rewards                [  76.42651294 3514.75409431  151.25424926 3373.63431745 3103.68810761
  510.42984882  173.12785569 3021.22969356  741.27085175 3535.65739713]
total_rewards_mean           1820.1472928528208
total_rewards_std            1507.8407858731741
total_rewards_max            3535.657397129925
total_rewards_min            76.42651293950611
Number of train steps total  1704000
Number of env steps total    3037016
Number of rollouts total     0
Train Time (s)               154.86620753398165
(Previous) Eval Time (s)     24.66052071703598
Sample Time (s)              11.876470991410315
Epoch Time (s)               191.40319924242795
Total Train Time (s)         79098.98617824493
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:54:12.594842 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #425 | Epoch Duration: 191.50469255447388
2020-01-12 23:54:12.595071 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0143175
Z variance train             0.084544435
KL Divergence                14.409606
KL Loss                      1.4409606
QF Loss                      689.2378
VF Loss                      75.74426
Policy Loss                  -1168.1779
Q Predictions Mean           1162.5793
Q Predictions Std            201.47043
Q Predictions Max            1474.8597
Q Predictions Min            283.8174
V Predictions Mean           1170.2682
V Predictions Std            200.10445
V Predictions Max            1476.1302
V Predictions Min            280.3267
Log Pis Mean                 0.7861075
Log Pis Std                  2.7513914
Log Pis Max                  14.63126
Log Pis Min                  -7.774294
Policy mu Mean               0.0060732807
Policy mu Std                0.64932805
Policy mu Max                3.2971606
Policy mu Min                -2.2114656
Policy log std Mean          -1.04215
Policy log std Std           0.25491902
Policy log std Max           -0.29622954
Policy log std Min           -2.4540052
Z mean eval                  0.96989965
Z variance eval              0.14316593
total_rewards                [3393.99601105  268.22294001 2709.33745123 3476.30885359 3570.73049233
 3469.53077236 2489.33909427 3363.9452226  3468.87272937 3134.32639514]
total_rewards_mean           2934.4609961951633
total_rewards_std            952.0266979888053
total_rewards_max            3570.730492330422
total_rewards_min            268.22294000927775
Number of train steps total  1708000
Number of env steps total    3049037
Number of rollouts total     0
Train Time (s)               155.7562835761346
(Previous) Eval Time (s)     35.50675132870674
Sample Time (s)              11.249402253422886
Epoch Time (s)               202.51243715826422
Total Train Time (s)         79301.59367261594
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:57:35.207279 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #426 | Epoch Duration: 202.61196851730347
2020-01-12 23:57:35.207524 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9763797
Z variance train             0.14425954
KL Divergence                14.298589
KL Loss                      1.4298589
QF Loss                      237.84128
VF Loss                      60.31724
Policy Loss                  -1172.0524
Q Predictions Mean           1166.1102
Q Predictions Std            232.39078
Q Predictions Max            1427.3695
Q Predictions Min            317.0342
V Predictions Mean           1173.0754
V Predictions Std            232.53331
V Predictions Max            1421.3008
V Predictions Min            325.1723
Log Pis Mean                 0.6104338
Log Pis Std                  2.6718748
Log Pis Max                  10.194658
Log Pis Min                  -8.594357
Policy mu Mean               -0.025258463
Policy mu Std                0.6324533
Policy mu Max                1.9558936
Policy mu Min                -2.250618
Policy log std Mean          -1.1022154
Policy log std Std           0.2641225
Policy log std Max           -0.029629588
Policy log std Min           -2.3733075
Z mean eval                  1.0839759
Z variance eval              0.034915395
total_rewards                [3349.77766345 1333.4854897  3547.91895731  288.00938292 3487.09579398
 1482.72638277  212.51049323   64.0341015   444.42269764 3474.28133274]
total_rewards_mean           1768.4262295233143
total_rewards_std            1451.6293251739933
total_rewards_max            3547.9189573148224
total_rewards_min            64.034101499614
Number of train steps total  1712000
Number of env steps total    3060918
Number of rollouts total     0
Train Time (s)               149.01528962608427
(Previous) Eval Time (s)     20.928842425812036
Sample Time (s)              12.67668198607862
Epoch Time (s)               182.62081403797492
Total Train Time (s)         79484.32797676232
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:00:37.944886 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #427 | Epoch Duration: 182.7372031211853
2020-01-13 00:00:37.945071 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0838518
Z variance train             0.03514116
KL Divergence                15.416842
KL Loss                      1.5416843
QF Loss                      12578.203
VF Loss                      78.57794
Policy Loss                  -1198.9397
Q Predictions Mean           1196.0771
Q Predictions Std            195.529
Q Predictions Max            1498.3198
Q Predictions Min            306.61536
V Predictions Mean           1203.1086
V Predictions Std            194.88614
V Predictions Max            1477.2698
V Predictions Min            306.90765
Log Pis Mean                 0.7490258
Log Pis Std                  2.8873549
Log Pis Max                  15.550429
Log Pis Min                  -6.9714994
Policy mu Mean               -0.029559068
Policy mu Std                0.64631623
Policy mu Max                3.7271001
Policy mu Min                -3.795836
Policy log std Mean          -1.0807867
Policy log std Std           0.25712353
Policy log std Max           0.041532874
Policy log std Min           -2.2885866
Z mean eval                  0.8906825
Z variance eval              0.0396999
total_rewards                [3137.42443088 3604.12553498 1667.47911653  669.99738987 2543.7817503
 1073.3446296    13.25553817 3563.68015357 1950.83200272 3209.4824592 ]
total_rewards_mean           2143.340300581982
total_rewards_std            1206.3527257386866
total_rewards_max            3604.125534975167
total_rewards_min            13.255538165629687
Number of train steps total  1716000
Number of env steps total    3071617
Number of rollouts total     0
Train Time (s)               146.66877563111484
(Previous) Eval Time (s)     27.823167771100998
Sample Time (s)              11.007491875905544
Epoch Time (s)               185.49943527812138
Total Train Time (s)         79669.92571902741
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:03:43.547994 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #428 | Epoch Duration: 185.60277199745178
2020-01-13 00:03:43.548240 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.893361
Z variance train             0.039594688
KL Divergence                14.064567
KL Loss                      1.4064567
QF Loss                      502.86746
VF Loss                      107.30055
Policy Loss                  -1181.9962
Q Predictions Mean           1176.4761
Q Predictions Std            221.9614
Q Predictions Max            1479.326
Q Predictions Min            88.67482
V Predictions Mean           1176.3892
V Predictions Std            219.70427
V Predictions Max            1463.9486
V Predictions Min            204.11409
Log Pis Mean                 0.9791949
Log Pis Std                  2.7110243
Log Pis Max                  13.136222
Log Pis Min                  -6.102696
Policy mu Mean               -0.07783581
Policy mu Std                0.6911593
Policy mu Max                2.3227997
Policy mu Min                -3.0802422
Policy log std Mean          -1.0513804
Policy log std Std           0.2891248
Policy log std Max           -0.27878374
Policy log std Min           -2.8634388
Z mean eval                  0.893788
Z variance eval              0.14875868
total_rewards                [2302.16637723 3052.02800132 1298.16446252  174.40734246 2603.33438976
 2050.43793233 1204.5920308  1103.910149    207.0332262  3552.65218785]
total_rewards_mean           1754.872609949319
total_rewards_std            1088.5871867836718
total_rewards_max            3552.652187852977
total_rewards_min            174.40734245934908
Number of train steps total  1720000
Number of env steps total    3082917
Number of rollouts total     0
Train Time (s)               150.5583564271219
(Previous) Eval Time (s)     18.137164204847068
Sample Time (s)              10.47136475564912
Epoch Time (s)               179.1668853876181
Total Train Time (s)         79849.18192174425
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:06:42.808702 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #429 | Epoch Duration: 179.26030158996582
2020-01-13 00:06:42.808905 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89260894
Z variance train             0.15098752
KL Divergence                12.441171
KL Loss                      1.2441171
QF Loss                      340.10596
VF Loss                      116.14165
Policy Loss                  -1200.8855
Q Predictions Mean           1196.7332
Q Predictions Std            202.21178
Q Predictions Max            1420.2455
Q Predictions Min            304.22714
V Predictions Mean           1195.7942
V Predictions Std            202.29414
V Predictions Max            1414.5289
V Predictions Min            310.5777
Log Pis Mean                 0.49016568
Log Pis Std                  2.5452194
Log Pis Max                  8.105939
Log Pis Min                  -7.3877196
Policy mu Mean               -0.009884113
Policy mu Std                0.61306536
Policy mu Max                1.99165
Policy mu Min                -2.6074057
Policy log std Mean          -1.0570986
Policy log std Std           0.24953233
Policy log std Max           -0.18691766
Policy log std Min           -2.120798
Z mean eval                  0.9718148
Z variance eval              0.06702489
total_rewards                [3533.1167883  3259.83860981 1452.24897381   29.84610174 3283.6701228
 1422.29507293   18.12291238 2398.85070267  164.90176424 1183.55932357]
total_rewards_mean           1674.645037226764
total_rewards_std            1310.0859137575185
total_rewards_max            3533.1167883018825
total_rewards_min            18.122912382641655
Number of train steps total  1724000
Number of env steps total    3094330
Number of rollouts total     0
Train Time (s)               156.14025880489498
(Previous) Eval Time (s)     30.110905314795673
Sample Time (s)              10.530124392360449
Epoch Time (s)               196.7812885120511
Total Train Time (s)         80046.09317206778
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:09:59.722370 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #430 | Epoch Duration: 196.91333198547363
2020-01-13 00:09:59.722497 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97034436
Z variance train             0.06665576
KL Divergence                13.353891
KL Loss                      1.3353891
QF Loss                      244.99042
VF Loss                      84.23326
Policy Loss                  -1215.7166
Q Predictions Mean           1209.4968
Q Predictions Std            208.48347
Q Predictions Max            1446.2197
Q Predictions Min            332.77307
V Predictions Mean           1218.6539
V Predictions Std            207.90096
V Predictions Max            1446.7495
V Predictions Min            338.68066
Log Pis Mean                 0.67794025
Log Pis Std                  2.7749968
Log Pis Max                  11.68982
Log Pis Min                  -7.9270077
Policy mu Mean               -0.04016804
Policy mu Std                0.6744037
Policy mu Max                2.3114116
Policy mu Min                -2.5356941
Policy log std Mean          -1.05262
Policy log std Std           0.271267
Policy log std Max           -0.28763586
Policy log std Min           -2.2469559
Z mean eval                  1.1596221
Z variance eval              0.06613246
total_rewards                [3586.83646743 1317.43556871 2897.03004798 1794.06126292 1700.77453982
 2649.63712792  601.3087404  3501.34436399 3511.70486492 3588.55580057]
total_rewards_mean           2514.868878466551
total_rewards_std            1034.930711236647
total_rewards_max            3588.555800566923
total_rewards_min            601.3087403977099
Number of train steps total  1728000
Number of env steps total    3105684
Number of rollouts total     0
Train Time (s)               156.55635457113385
(Previous) Eval Time (s)     29.464024554006755
Sample Time (s)              11.718356468714774
Epoch Time (s)               197.73873559385538
Total Train Time (s)         80243.92089327471
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:13:17.556152 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #431 | Epoch Duration: 197.83353805541992
2020-01-13 00:13:17.556378 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1617525
Z variance train             0.066055946
KL Divergence                13.661083
KL Loss                      1.3661083
QF Loss                      276.05975
VF Loss                      99.72282
Policy Loss                  -1214.8046
Q Predictions Mean           1209.8197
Q Predictions Std            199.58876
Q Predictions Max            1449.7609
Q Predictions Min            295.74637
V Predictions Mean           1213.9243
V Predictions Std            196.71077
V Predictions Max            1448.2874
V Predictions Min            294.0969
Log Pis Mean                 0.84521556
Log Pis Std                  2.6290593
Log Pis Max                  12.598141
Log Pis Min                  -5.897646
Policy mu Mean               -0.018060055
Policy mu Std                0.6511793
Policy mu Max                2.8446927
Policy mu Min                -2.0782664
Policy log std Mean          -1.0565147
Policy log std Std           0.2580888
Policy log std Max           0.15679991
Policy log std Min           -2.1305056
Z mean eval                  1.1203
Z variance eval              0.2929257
total_rewards                [2321.94400241 3780.42693101 3192.10676888  358.97846653  787.60372456
  318.0210947  1713.218412    629.69578426  309.33120154 1172.98259435]
total_rewards_mean           1458.4308980229912
total_rewards_std            1193.9816230475278
total_rewards_max            3780.4269310115287
total_rewards_min            309.3312015389808
Number of train steps total  1732000
Number of env steps total    3116981
Number of rollouts total     0
Train Time (s)               156.97397910570726
(Previous) Eval Time (s)     23.160470891278237
Sample Time (s)              12.025093680713326
Epoch Time (s)               192.15954367769882
Total Train Time (s)         80436.16978724347
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:16:29.808550 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #432 | Epoch Duration: 192.25202775001526
2020-01-13 00:16:29.808757 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1214858
Z variance train             0.29015422
KL Divergence                14.767169
KL Loss                      1.4767169
QF Loss                      395.57373
VF Loss                      144.11423
Policy Loss                  -1244.0332
Q Predictions Mean           1239.4844
Q Predictions Std            186.95818
Q Predictions Max            1534.6488
Q Predictions Min            326.62592
V Predictions Mean           1253.3406
V Predictions Std            188.30986
V Predictions Max            1548.7827
V Predictions Min            338.177
Log Pis Mean                 0.612398
Log Pis Std                  2.523637
Log Pis Max                  10.899405
Log Pis Min                  -5.3185887
Policy mu Mean               -0.022891402
Policy mu Std                0.6464778
Policy mu Max                2.120454
Policy mu Min                -2.506447
Policy log std Mean          -1.043827
Policy log std Std           0.24851637
Policy log std Max           -0.35540074
Policy log std Min           -2.1745353
Z mean eval                  0.9198972
Z variance eval              0.15226085
total_rewards                [3490.38950464 3275.25521414 3645.63951866 1758.35437554 2334.88005595
 2923.83954911 2724.5243327  1926.40232432 2506.86041205 3585.81915408]
total_rewards_mean           2817.1964441199966
total_rewards_std            648.3567416772798
total_rewards_max            3645.6395186563304
total_rewards_min            1758.3543755437174
Number of train steps total  1736000
Number of env steps total    3128323
Number of rollouts total     0
Train Time (s)               156.17823860794306
(Previous) Eval Time (s)     29.54304147697985
Sample Time (s)              14.0935587300919
Epoch Time (s)               199.8148388150148
Total Train Time (s)         80636.07600313844
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:19:49.717305 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #433 | Epoch Duration: 199.90841484069824
2020-01-13 00:19:49.717448 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #433 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91950625
Z variance train             0.15296634
KL Divergence                12.750565
KL Loss                      1.2750565
QF Loss                      387.31787
VF Loss                      51.377754
Policy Loss                  -1247.8323
Q Predictions Mean           1242.668
Q Predictions Std            257.59726
Q Predictions Max            1518.1532
Q Predictions Min            342.07166
V Predictions Mean           1248.317
V Predictions Std            257.68817
V Predictions Max            1503.9543
V Predictions Min            347.27588
Log Pis Mean                 0.66987514
Log Pis Std                  2.8283706
Log Pis Max                  8.792003
Log Pis Min                  -8.597033
Policy mu Mean               -0.024194269
Policy mu Std                0.6727882
Policy mu Max                2.5130186
Policy mu Min                -2.3767953
Policy log std Mean          -1.0249581
Policy log std Std           0.25654018
Policy log std Max           -0.34475774
Policy log std Min           -1.975437
Z mean eval                  0.9229903
Z variance eval              0.115974665
total_rewards                [2577.45417315 3235.0989002  3067.61257745  386.19347505 1410.9374817
 1596.59508091 3439.50114536  913.90517253 2185.16770958  643.72558696]
total_rewards_mean           1945.619130289133
total_rewards_std            1058.7153066820397
total_rewards_max            3439.5011453565207
total_rewards_min            386.19347505265483
Number of train steps total  1740000
Number of env steps total    3137648
Number of rollouts total     0
Train Time (s)               146.03523934958503
(Previous) Eval Time (s)     23.640980921220034
Sample Time (s)              11.027333414647728
Epoch Time (s)               180.7035536854528
Total Train Time (s)         80817.27390373452
Epoch                        434
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:22:50.920355 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #434 | Epoch Duration: 181.20278596878052
2020-01-13 00:22:50.920561 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92485505
Z variance train             0.11587332
KL Divergence                13.658755
KL Loss                      1.3658756
QF Loss                      11623.315
VF Loss                      59.638405
Policy Loss                  -1227.986
Q Predictions Mean           1223.3005
Q Predictions Std            183.6499
Q Predictions Max            1436.5942
Q Predictions Min            328.6467
V Predictions Mean           1224.1838
V Predictions Std            183.70029
V Predictions Max            1423.514
V Predictions Min            329.06244
Log Pis Mean                 0.840242
Log Pis Std                  2.649914
Log Pis Max                  7.696944
Log Pis Min                  -9.18027
Policy mu Mean               -0.14209445
Policy mu Std                0.6896894
Policy mu Max                2.385094
Policy mu Min                -2.3066294
Policy log std Mean          -1.0185663
Policy log std Std           0.25031304
Policy log std Max           -0.20317966
Policy log std Min           -2.0021565
Z mean eval                  0.92185414
Z variance eval              0.10426848
total_rewards                [3125.88222761 3218.04369383 3403.35526482 1592.82892592  835.67196715
 3390.8612467  3224.54458875 3475.42544712  411.19550985 3159.82068194]
total_rewards_mean           2583.762955369611
total_rewards_std            1109.7149107076955
total_rewards_max            3475.4254471240533
total_rewards_min            411.1955098510529
Number of train steps total  1744000
Number of env steps total    3147701
Number of rollouts total     0
Train Time (s)               145.7733832099475
(Previous) Eval Time (s)     27.4394216039218
Sample Time (s)              12.595944990869612
Epoch Time (s)               185.8087498047389
Total Train Time (s)         81003.17285033548
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:25:56.823774 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #435 | Epoch Duration: 185.90305876731873
2020-01-13 00:25:56.824003 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92223656
Z variance train             0.104738235
KL Divergence                13.52689
KL Loss                      1.352689
QF Loss                      256.54105
VF Loss                      54.81294
Policy Loss                  -1211.6046
Q Predictions Mean           1206.6853
Q Predictions Std            206.06436
Q Predictions Max            1457.4321
Q Predictions Min            304.2269
V Predictions Mean           1213.9209
V Predictions Std            208.20941
V Predictions Max            1457.8602
V Predictions Min            303.04105
Log Pis Mean                 0.9247623
Log Pis Std                  2.41348
Log Pis Max                  8.954465
Log Pis Min                  -8.402182
Policy mu Mean               -0.02322953
Policy mu Std                0.64238286
Policy mu Max                2.9510143
Policy mu Min                -2.1415584
Policy log std Mean          -1.074611
Policy log std Std           0.2573541
Policy log std Max           -0.23116583
Policy log std Min           -2.239121
Z mean eval                  0.9571268
Z variance eval              0.12301634
total_rewards                [1386.53523583 1202.6788836  1255.70328754  523.49947033  770.6080261
 3188.66283504 1028.49305789 1079.05581774  776.2573309   745.16988548]
total_rewards_mean           1195.6663830447299
total_rewards_std            711.6880172505279
total_rewards_max            3188.662835041494
total_rewards_min            523.4994703286596
Number of train steps total  1748000
Number of env steps total    3159403
Number of rollouts total     0
Train Time (s)               154.22104819398373
(Previous) Eval Time (s)     13.69493463402614
Sample Time (s)              11.090422461275011
Epoch Time (s)               179.00640528928488
Total Train Time (s)         81182.26855289657
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:28:55.924088 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #436 | Epoch Duration: 179.0999345779419
2020-01-13 00:28:55.924292 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9552759
Z variance train             0.12376791
KL Divergence                14.889828
KL Loss                      1.4889828
QF Loss                      293.81888
VF Loss                      82.17607
Policy Loss                  -1222.1846
Q Predictions Mean           1219.3691
Q Predictions Std            225.8327
Q Predictions Max            1454.0444
Q Predictions Min            311.5835
V Predictions Mean           1227.3755
V Predictions Std            224.95477
V Predictions Max            1459.7673
V Predictions Min            323.83664
Log Pis Mean                 0.70925903
Log Pis Std                  2.4286406
Log Pis Max                  11.483162
Log Pis Min                  -5.7709484
Policy mu Mean               -0.04711231
Policy mu Std                0.62203795
Policy mu Max                2.187826
Policy mu Min                -2.302648
Policy log std Mean          -1.0649655
Policy log std Std           0.24254635
Policy log std Max           -0.36754555
Policy log std Min           -2.1254497
Z mean eval                  0.81281376
Z variance eval              0.7343356
total_rewards                [1388.82118121 3415.6484325  3217.13316334 3424.65181123 -166.28287496
  946.12347033  369.75687674 3377.20086702  417.37002163 2656.46710152]
total_rewards_mean           1904.689005055307
total_rewards_std            1381.71208661448
total_rewards_max            3424.6518112252943
total_rewards_min            -166.28287496422467
Number of train steps total  1752000
Number of env steps total    3169057
Number of rollouts total     0
Train Time (s)               155.8430254110135
(Previous) Eval Time (s)     27.535807483363897
Sample Time (s)              10.828938053920865
Epoch Time (s)               194.20777094829828
Total Train Time (s)         81376.57262040675
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:32:10.232462 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #437 | Epoch Duration: 194.3080232143402
2020-01-13 00:32:10.232650 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8065497
Z variance train             0.7306052
KL Divergence                10.427065
KL Loss                      1.0427065
QF Loss                      280.30432
VF Loss                      72.4862
Policy Loss                  -1263.8204
Q Predictions Mean           1259.8486
Q Predictions Std            230.7032
Q Predictions Max            1552.4937
Q Predictions Min            332.18292
V Predictions Mean           1258.074
V Predictions Std            230.45586
V Predictions Max            1544.3492
V Predictions Min            333.84225
Log Pis Mean                 0.51639724
Log Pis Std                  2.6287923
Log Pis Max                  10.690472
Log Pis Min                  -5.922366
Policy mu Mean               -0.0054309247
Policy mu Std                0.6425386
Policy mu Max                2.019349
Policy mu Min                -2.4287257
Policy log std Mean          -1.0347228
Policy log std Std           0.25221264
Policy log std Max           -0.2184366
Policy log std Min           -2.128376
Z mean eval                  1.203194
Z variance eval              0.10056503
total_rewards                [ 503.12909178  736.88233916 1768.53418321 2816.63465564 1403.54077607
 3791.7844917  2357.39090977 1391.54085843  931.33786374 3100.40499704]
total_rewards_mean           1880.1180166546878
total_rewards_std            1040.6717256500426
total_rewards_max            3791.784491696456
total_rewards_min            503.12909177774134
Number of train steps total  1756000
Number of env steps total    3180305
Number of rollouts total     0
Train Time (s)               154.6231912258081
(Previous) Eval Time (s)     21.149702557362616
Sample Time (s)              11.903265638742596
Epoch Time (s)               187.67615942191333
Total Train Time (s)         81564.33670177963
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:35:18.001115 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #438 | Epoch Duration: 187.768324136734
2020-01-13 00:35:18.001314 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2065209
Z variance train             0.09924598
KL Divergence                13.810354
KL Loss                      1.3810354
QF Loss                      602.9557
VF Loss                      66.74631
Policy Loss                  -1226.4792
Q Predictions Mean           1218.8887
Q Predictions Std            194.77162
Q Predictions Max            1456.4565
Q Predictions Min            327.72748
V Predictions Mean           1223.196
V Predictions Std            193.58723
V Predictions Max            1461.881
V Predictions Min            318.38657
Log Pis Mean                 0.955446
Log Pis Std                  2.7127128
Log Pis Max                  14.108842
Log Pis Min                  -6.680163
Policy mu Mean               -0.08148201
Policy mu Std                0.65215063
Policy mu Max                2.158526
Policy mu Min                -2.6765447
Policy log std Mean          -1.0870013
Policy log std Std           0.2608939
Policy log std Max           -0.38887292
Policy log std Min           -2.1880202
Z mean eval                  1.0253456
Z variance eval              0.20061931
total_rewards                [2016.38145574 1282.37677727  221.99443816  824.75912614 1729.16600101
 3351.77715938 2922.77466593 2034.69379457 1260.77071277  558.34590609]
total_rewards_mean           1620.3040037060414
total_rewards_std            948.3802817470382
total_rewards_max            3351.777159384082
total_rewards_min            221.99443816337418
Number of train steps total  1760000
Number of env steps total    3192119
Number of rollouts total     0
Train Time (s)               156.94025003630668
(Previous) Eval Time (s)     24.231351213995367
Sample Time (s)              12.473620474804193
Epoch Time (s)               193.64522172510624
Total Train Time (s)         81758.07016242389
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:38:31.737053 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #439 | Epoch Duration: 193.73561596870422
2020-01-13 00:38:31.737172 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0197151
Z variance train             0.19652069
KL Divergence                13.985294
KL Loss                      1.3985294
QF Loss                      650.68884
VF Loss                      394.91684
Policy Loss                  -1149.0336
Q Predictions Mean           1143.4888
Q Predictions Std            249.13509
Q Predictions Max            1444.4241
Q Predictions Min            313.6968
V Predictions Mean           1157.2378
V Predictions Std            252.80785
V Predictions Max            1446.5948
V Predictions Min            315.2825
Log Pis Mean                 0.69080615
Log Pis Std                  2.7514088
Log Pis Max                  14.718237
Log Pis Min                  -5.8084593
Policy mu Mean               -0.045856155
Policy mu Std                0.6585222
Policy mu Max                2.0599687
Policy mu Min                -2.6807601
Policy log std Mean          -1.0209832
Policy log std Std           0.25660565
Policy log std Max           -0.25709134
Policy log std Min           -2.4515758
Z mean eval                  1.0127946
Z variance eval              0.11420778
total_rewards                [3452.1882514   841.23095969 1062.70851908   68.33009393  224.8665407
  183.9992521  2892.93353047  100.40284209   23.61216606 3589.99699146]
total_rewards_mean           1244.0269146976902
total_rewards_std            1401.2659906452666
total_rewards_max            3589.99699145672
total_rewards_min            23.612166062884164
Number of train steps total  1764000
Number of env steps total    3202459
Number of rollouts total     0
Train Time (s)               154.12005431903526
(Previous) Eval Time (s)     16.790514649823308
Sample Time (s)              12.843529464676976
Epoch Time (s)               183.75409843353555
Total Train Time (s)         81941.91376924934
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:41:35.585885 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #440 | Epoch Duration: 183.84860634803772
2020-01-13 00:41:35.586078 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0156094
Z variance train             0.11461703
KL Divergence                14.383902
KL Loss                      1.4383901
QF Loss                      490.76038
VF Loss                      128.61476
Policy Loss                  -1191.0001
Q Predictions Mean           1186.3768
Q Predictions Std            209.69917
Q Predictions Max            1462.0322
Q Predictions Min            353.5152
V Predictions Mean           1187.3481
V Predictions Std            209.00024
V Predictions Max            1441.6887
V Predictions Min            350.7223
Log Pis Mean                 0.70386654
Log Pis Std                  2.8312953
Log Pis Max                  11.976581
Log Pis Min                  -8.216362
Policy mu Mean               -0.018116701
Policy mu Std                0.66084886
Policy mu Max                2.7396708
Policy mu Min                -2.3409998
Policy log std Mean          -1.058104
Policy log std Std           0.26687193
Policy log std Max           -0.30888915
Policy log std Min           -2.1297603
Z mean eval                  1.0336183
Z variance eval              0.13587055
total_rewards                [3432.9049502   214.14762653 3014.98517515 3606.43007833 3628.63544812
 3379.11928807  283.42832755 3420.12821929  176.14406244 2948.42213891]
total_rewards_mean           2410.4345314593347
total_rewards_std            1446.1152681007707
total_rewards_max            3628.6354481209755
total_rewards_min            176.14406244422946
Number of train steps total  1768000
Number of env steps total    3213750
Number of rollouts total     0
Train Time (s)               146.81335486704484
(Previous) Eval Time (s)     24.91494841594249
Sample Time (s)              11.4564024284482
Epoch Time (s)               183.18470571143553
Total Train Time (s)         82125.20878389664
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:44:38.888829 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #441 | Epoch Duration: 183.302588224411
2020-01-13 00:44:38.889103 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0286064
Z variance train             0.13391504
KL Divergence                13.045756
KL Loss                      1.3045757
QF Loss                      1314.9358
VF Loss                      63.35321
Policy Loss                  -1158.1388
Q Predictions Mean           1151.1721
Q Predictions Std            268.47205
Q Predictions Max            1482.8413
Q Predictions Min            328.4058
V Predictions Mean           1159.3029
V Predictions Std            267.7012
V Predictions Max            1488.8097
V Predictions Min            330.26782
Log Pis Mean                 0.7421463
Log Pis Std                  2.7289627
Log Pis Max                  8.359683
Log Pis Min                  -9.29933
Policy mu Mean               -0.061918404
Policy mu Std                0.65813744
Policy mu Max                1.9934592
Policy mu Min                -2.8524234
Policy log std Mean          -1.0420135
Policy log std Std           0.2859932
Policy log std Max           -0.11752218
Policy log std Min           -2.2059417
Z mean eval                  0.94862527
Z variance eval              0.14882925
total_rewards                [ 193.04311917 3539.96762096 3122.88059252 3168.0935114  3302.04632438
 3220.5866987  3693.32533407  114.01047329 3515.99883802 2402.91118857]
total_rewards_mean           2627.2863701083697
total_rewards_std            1280.5103834994952
total_rewards_max            3693.3253340666397
total_rewards_min            114.01047328642812
Number of train steps total  1772000
Number of env steps total    3224172
Number of rollouts total     0
Train Time (s)               146.6818850589916
(Previous) Eval Time (s)     26.812679717317224
Sample Time (s)              11.308640602976084
Epoch Time (s)               184.80320537928492
Total Train Time (s)         82310.0958378734
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:47:43.780443 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #442 | Epoch Duration: 184.89117431640625
2020-01-13 00:47:43.780644 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9461315
Z variance train             0.14923881
KL Divergence                13.050098
KL Loss                      1.3050098
QF Loss                      12482.06
VF Loss                      124.653275
Policy Loss                  -1208.4674
Q Predictions Mean           1205.4951
Q Predictions Std            229.23549
Q Predictions Max            1477.2388
Q Predictions Min            332.0607
V Predictions Mean           1213.2113
V Predictions Std            230.83147
V Predictions Max            1476.5612
V Predictions Min            304.09006
Log Pis Mean                 0.56029224
Log Pis Std                  2.5853019
Log Pis Max                  11.283522
Log Pis Min                  -5.8929787
Policy mu Mean               -0.03771814
Policy mu Std                0.6356836
Policy mu Max                2.0739448
Policy mu Min                -2.7042742
Policy log std Mean          -1.0802314
Policy log std Std           0.27119827
Policy log std Max           -0.21227294
Policy log std Min           -2.4561555
Z mean eval                  0.90859795
Z variance eval              0.28358293
total_rewards                [3610.50527256 2376.53641519 3749.5984564   105.68807539 1475.70239078
  -94.34636734 3688.91031047 3428.40525251  456.09029657 3648.72786961]
total_rewards_mean           2244.5817972139143
total_rewards_std            1531.1012973675788
total_rewards_max            3749.5984564011083
total_rewards_min            -94.34636734034477
Number of train steps total  1776000
Number of env steps total    3234773
Number of rollouts total     0
Train Time (s)               155.32065781299025
(Previous) Eval Time (s)     29.16787676885724
Sample Time (s)              11.896669452544302
Epoch Time (s)               196.3852040343918
Total Train Time (s)         82506.58048625011
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:51:00.269697 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #443 | Epoch Duration: 196.48889541625977
2020-01-13 00:51:00.269914 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9072838
Z variance train             0.2838375
KL Divergence                11.306942
KL Loss                      1.1306943
QF Loss                      317.18008
VF Loss                      99.39106
Policy Loss                  -1228.719
Q Predictions Mean           1222.6611
Q Predictions Std            241.50125
Q Predictions Max            1496.0763
Q Predictions Min            359.0595
V Predictions Mean           1221.9738
V Predictions Std            238.83032
V Predictions Max            1491.0695
V Predictions Min            357.2151
Log Pis Mean                 0.4803763
Log Pis Std                  2.7003448
Log Pis Max                  8.730457
Log Pis Min                  -7.71321
Policy mu Mean               -0.014150167
Policy mu Std                0.65713793
Policy mu Max                2.3847868
Policy mu Min                -2.3780324
Policy log std Mean          -1.0390182
Policy log std Std           0.25861973
Policy log std Max           -0.08721578
Policy log std Min           -2.1574268
Z mean eval                  1.2247496
Z variance eval              0.1496843
total_rewards                [3387.67419697 3352.79550996 3351.03226615 3368.45613266 3547.04028595
 3489.33454439 3206.22214806 1717.2938674  3490.87615102 3294.59560552]
total_rewards_mean           3220.5320708105364
total_rewards_std            510.0691639415147
total_rewards_max            3547.040285950553
total_rewards_min            1717.293867404232
Number of train steps total  1780000
Number of env steps total    3246242
Number of rollouts total     0
Train Time (s)               155.39765394013375
(Previous) Eval Time (s)     37.407337544020265
Sample Time (s)              11.998290662188083
Epoch Time (s)               204.8032821463421
Total Train Time (s)         82711.4717191835
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:54:25.166459 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #444 | Epoch Duration: 204.89635491371155
2020-01-13 00:54:25.166819 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #444 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2271068
Z variance train             0.15446644
KL Divergence                12.234687
KL Loss                      1.2234687
QF Loss                      397.73566
VF Loss                      66.856865
Policy Loss                  -1147.2792
Q Predictions Mean           1142.774
Q Predictions Std            182.13162
Q Predictions Max            1378.057
Q Predictions Min            313.4048
V Predictions Mean           1148.0381
V Predictions Std            181.2969
V Predictions Max            1360.5109
V Predictions Min            335.0933
Log Pis Mean                 0.5316107
Log Pis Std                  2.5561597
Log Pis Max                  9.865283
Log Pis Min                  -8.268704
Policy mu Mean               -0.010507414
Policy mu Std                0.62840897
Policy mu Max                2.1888034
Policy mu Min                -2.0903516
Policy log std Mean          -1.0706341
Policy log std Std           0.24684948
Policy log std Max           -0.31534338
Policy log std Min           -2.0937471
Z mean eval                  0.8950362
Z variance eval              0.14764227
total_rewards                [ 8.44170631e+02  1.05282901e+03  2.87465661e+02  5.94813062e+02
  3.01559801e+03  1.65432362e+02  9.82734363e+02  5.46736704e+02
 -1.63273314e-02  2.11023842e+02]
total_rewards_mean           770.0787321368614
total_rewards_std            822.0533855759876
total_rewards_max            3015.598013517057
total_rewards_min            -0.016327331411250423
Number of train steps total  1784000
Number of env steps total    3258116
Number of rollouts total     0
Train Time (s)               154.58934545703232
(Previous) Eval Time (s)     19.739386819303036
Sample Time (s)              12.503147145267576
Epoch Time (s)               186.83187942160293
Total Train Time (s)         82898.39085533889
Epoch                        445
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:57:32.089239 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #445 | Epoch Duration: 186.92222356796265
2020-01-13 00:57:32.089425 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89537793
Z variance train             0.14640746
KL Divergence                11.636014
KL Loss                      1.1636014
QF Loss                      298.2386
VF Loss                      99.34479
Policy Loss                  -1260.7435
Q Predictions Mean           1255.0781
Q Predictions Std            150.61148
Q Predictions Max            1462.6207
Q Predictions Min            369.32
V Predictions Mean           1260.2002
V Predictions Std            148.32108
V Predictions Max            1445.352
V Predictions Min            377.23257
Log Pis Mean                 0.6374849
Log Pis Std                  2.6020513
Log Pis Max                  9.041895
Log Pis Min                  -9.166976
Policy mu Mean               -0.013533248
Policy mu Std                0.6250738
Policy mu Max                2.174928
Policy mu Min                -2.6224177
Policy log std Mean          -1.0817262
Policy log std Std           0.25405544
Policy log std Max           -0.3171689
Policy log std Min           -2.2772305
Z mean eval                  0.8590458
Z variance eval              0.14189911
total_rewards                [3365.16356834  580.93385352 2737.79028253 2330.76010134 3095.85516365
 1142.060179   2716.97393666  -40.34251165 3647.16710058 3509.70336744]
total_rewards_mean           2308.606504143613
total_rewards_std            1232.2803852945833
total_rewards_max            3647.1671005836415
total_rewards_min            -40.34251165099214
Number of train steps total  1788000
Number of env steps total    3270331
Number of rollouts total     0
Train Time (s)               155.95496339397505
(Previous) Eval Time (s)     28.201375784818083
Sample Time (s)              12.748323714360595
Epoch Time (s)               196.90466289315373
Total Train Time (s)         83095.38401200855
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:00:49.087129 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #446 | Epoch Duration: 196.99755764007568
2020-01-13 01:00:49.087346 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8520244
Z variance train             0.13941106
KL Divergence                13.360502
KL Loss                      1.3360503
QF Loss                      282.53635
VF Loss                      131.19862
Policy Loss                  -1212.9698
Q Predictions Mean           1211.0732
Q Predictions Std            225.37695
Q Predictions Max            1467.995
Q Predictions Min            288.9732
V Predictions Mean           1221.6377
V Predictions Std            225.52292
V Predictions Max            1467.2634
V Predictions Min            308.60217
Log Pis Mean                 0.8541467
Log Pis Std                  2.423577
Log Pis Max                  13.219353
Log Pis Min                  -6.6720233
Policy mu Mean               -0.03438396
Policy mu Std                0.6362843
Policy mu Max                2.5271647
Policy mu Min                -2.252293
Policy log std Mean          -1.0609398
Policy log std Std           0.25156036
Policy log std Max           -0.29654068
Policy log std Min           -2.2244153
Z mean eval                  1.0103357
Z variance eval              0.17083792
total_rewards                [1919.61856116 -339.59267816 3213.32078376  222.41936568 1652.54855122
  650.2928095  3453.10279806  -78.29614718 3211.84132146 1367.89643955]
total_rewards_mean           1527.3151805047041
total_rewards_std            1346.0741009089488
total_rewards_max            3453.102798061962
total_rewards_min            -339.59267815555603
Number of train steps total  1792000
Number of env steps total    3281547
Number of rollouts total     0
Train Time (s)               150.28612108295783
(Previous) Eval Time (s)     32.19724460877478
Sample Time (s)              13.6089823897928
Epoch Time (s)               196.09234808152542
Total Train Time (s)         83291.56313243974
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:04:05.270664 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #447 | Epoch Duration: 196.183171749115
2020-01-13 01:04:05.270864 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0117898
Z variance train             0.17185396
KL Divergence                11.794322
KL Loss                      1.1794323
QF Loss                      232.3186
VF Loss                      55.818436
Policy Loss                  -1189.9587
Q Predictions Mean           1185.0854
Q Predictions Std            249.962
Q Predictions Max            1472.223
Q Predictions Min            306.95276
V Predictions Mean           1191.3986
V Predictions Std            250.29039
V Predictions Max            1476.6791
V Predictions Min            318.8466
Log Pis Mean                 0.814129
Log Pis Std                  2.8306336
Log Pis Max                  9.433075
Log Pis Min                  -7.576112
Policy mu Mean               -0.017547062
Policy mu Std                0.66011
Policy mu Max                2.3119404
Policy mu Min                -2.402186
Policy log std Mean          -1.0474725
Policy log std Std           0.27250051
Policy log std Max           -0.2034412
Policy log std Min           -2.2634056
Z mean eval                  0.93446416
Z variance eval              0.11976979
total_rewards                [ 722.75057382 2977.81881139  280.94773598 3598.66998868  195.39431288
 3509.54565641 3488.9046058  1405.3092403  3365.34811806 1068.18947607]
total_rewards_mean           2061.28785193883
total_rewards_std            1374.7396215794004
total_rewards_max            3598.669988678849
total_rewards_min            195.39431287968156
Number of train steps total  1796000
Number of env steps total    3292557
Number of rollouts total     0
Train Time (s)               145.33837824175134
(Previous) Eval Time (s)     24.89358245069161
Sample Time (s)              12.534236243460327
Epoch Time (s)               182.76619693590328
Total Train Time (s)         83474.45933496067
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:07:08.172455 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #448 | Epoch Duration: 182.90143585205078
2020-01-13 01:07:08.172716 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93539655
Z variance train             0.119258784
KL Divergence                11.822304
KL Loss                      1.1822304
QF Loss                      246.96631
VF Loss                      76.24971
Policy Loss                  -1192.533
Q Predictions Mean           1188.5571
Q Predictions Std            243.82216
Q Predictions Max            1436.916
Q Predictions Min            294.18472
V Predictions Mean           1189.3254
V Predictions Std            245.70988
V Predictions Max            1426.0109
V Predictions Min            290.93893
Log Pis Mean                 0.70258105
Log Pis Std                  2.3689983
Log Pis Max                  6.438652
Log Pis Min                  -6.130699
Policy mu Mean               -0.045046616
Policy mu Std                0.6269411
Policy mu Max                2.114289
Policy mu Min                -2.1853683
Policy log std Mean          -1.0647845
Policy log std Std           0.24611107
Policy log std Max           -0.3068565
Policy log std Min           -1.8917248
Z mean eval                  1.0486763
Z variance eval              0.2912019
total_rewards                [3588.37398444 2209.34904138 1967.19112373 3300.33651827 3441.30487328
 3339.25187765 2087.04962128 3310.61725869 1889.37462413 3633.31117115]
total_rewards_mean           2876.6160094005754
total_rewards_std            696.4444026460728
total_rewards_max            3633.311171147876
total_rewards_min            1889.374624133191
Number of train steps total  1800000
Number of env steps total    3303777
Number of rollouts total     0
Train Time (s)               148.95683728111908
(Previous) Eval Time (s)     30.394993360619992
Sample Time (s)              12.008568243589252
Epoch Time (s)               191.36039888532832
Total Train Time (s)         83665.91650875797
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:10:19.634181 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #449 | Epoch Duration: 191.46129846572876
2020-01-13 01:10:19.634373 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0488704
Z variance train             0.2927156
KL Divergence                10.216116
KL Loss                      1.0216116
QF Loss                      1418.8237
VF Loss                      58.376343
Policy Loss                  -1120.2611
Q Predictions Mean           1114.946
Q Predictions Std            189.5891
Q Predictions Max            1373.8691
Q Predictions Min            284.5977
V Predictions Mean           1122.4746
V Predictions Std            187.48085
V Predictions Max            1386.0249
V Predictions Min            288.8189
Log Pis Mean                 0.47826442
Log Pis Std                  2.675541
Log Pis Max                  7.3097534
Log Pis Min                  -8.410018
Policy mu Mean               -0.047361955
Policy mu Std                0.5999516
Policy mu Max                2.4451969
Policy mu Min                -2.1468623
Policy log std Mean          -1.0710028
Policy log std Std           0.25139242
Policy log std Max           -0.1912328
Policy log std Min           -2.1603734
Z mean eval                  0.9078323
Z variance eval              0.12383701
total_rewards                [3240.08317211 3467.33623444 1118.41760652 1671.87490176  679.14296118
   43.04803559 3553.50819992 2430.62191445 1559.55924749  596.3343387 ]
total_rewards_mean           1835.992661216309
total_rewards_std            1210.130738272238
total_rewards_max            3553.50819992433
total_rewards_min            43.04803558861171
Number of train steps total  1804000
Number of env steps total    3314648
Number of rollouts total     0
Train Time (s)               158.0892867310904
(Previous) Eval Time (s)     19.839233440812677
Sample Time (s)              11.378828462678939
Epoch Time (s)               189.307348634582
Total Train Time (s)         83855.31604277482
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:13:29.044171 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #450 | Epoch Duration: 189.40960812568665
2020-01-13 01:13:29.044477 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9131299
Z variance train             0.12312585
KL Divergence                11.030597
KL Loss                      1.1030596
QF Loss                      353.3192
VF Loss                      167.6657
Policy Loss                  -1188.3594
Q Predictions Mean           1182.1384
Q Predictions Std            224.94771
Q Predictions Max            1420.7914
Q Predictions Min            303.3779
V Predictions Mean           1185.4968
V Predictions Std            224.8079
V Predictions Max            1411.3337
V Predictions Min            301.081
Log Pis Mean                 0.9650868
Log Pis Std                  2.9405951
Log Pis Max                  20.805168
Log Pis Min                  -7.268071
Policy mu Mean               -0.08675984
Policy mu Std                0.64445066
Policy mu Max                4.640289
Policy mu Min                -3.916966
Policy log std Mean          -1.084172
Policy log std Std           0.26235387
Policy log std Max           0.7755978
Policy log std Min           -2.2929058
Z mean eval                  0.96561575
Z variance eval              0.043078095
total_rewards                [1547.49119141 3466.20028554 2530.10455818 3017.04667502 3423.87741112
 3227.19445357 3542.5129892  2858.15243912 3285.3819139  3362.16512554]
total_rewards_mean           3026.0127042600375
total_rewards_std            574.4377356272614
total_rewards_max            3542.5129891968927
total_rewards_min            1547.4911914066226
Number of train steps total  1808000
Number of env steps total    3325204
Number of rollouts total     0
Train Time (s)               156.87208345206454
(Previous) Eval Time (s)     35.29917153995484
Sample Time (s)              11.564803844783455
Epoch Time (s)               203.73605883680284
Total Train Time (s)         84059.15132633038
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:16:52.882351 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #451 | Epoch Duration: 203.8376591205597
2020-01-13 01:16:52.882658 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9643834
Z variance train             0.043246284
KL Divergence                13.473818
KL Loss                      1.3473818
QF Loss                      312.87164
VF Loss                      130.9428
Policy Loss                  -1209.0167
Q Predictions Mean           1204.2788
Q Predictions Std            221.58876
Q Predictions Max            1461.6022
Q Predictions Min            283.27484
V Predictions Mean           1216.144
V Predictions Std            217.59908
V Predictions Max            1449.0819
V Predictions Min            295.80496
Log Pis Mean                 0.7321799
Log Pis Std                  2.6446824
Log Pis Max                  11.171226
Log Pis Min                  -6.6040363
Policy mu Mean               -0.05528322
Policy mu Std                0.6489567
Policy mu Max                2.1596172
Policy mu Min                -2.0396051
Policy log std Mean          -1.0228057
Policy log std Std           0.25110337
Policy log std Max           -0.25080758
Policy log std Min           -2.0539036
Z mean eval                  0.93567485
Z variance eval              0.17673427
total_rewards                [ 183.76294847 1680.25764888  342.83129889  658.24605258 1125.93383045
 2206.83475894 1027.27163662  157.6257431   128.39800566 2240.90325508]
total_rewards_mean           975.2065178668236
total_rewards_std            784.454664640567
total_rewards_max            2240.903255076402
total_rewards_min            128.3980056575018
Number of train steps total  1812000
Number of env steps total    3336678
Number of rollouts total     0
Train Time (s)               158.2118852850981
(Previous) Eval Time (s)     18.74398627318442
Sample Time (s)              12.863578875083476
Epoch Time (s)               189.819450433366
Total Train Time (s)         84249.0697812601
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:20:02.805587 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #452 | Epoch Duration: 189.9227192401886
2020-01-13 01:20:02.805921 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #452 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9119464
Z variance train             0.17300145
KL Divergence                11.067175
KL Loss                      1.1067175
QF Loss                      877.1521
VF Loss                      138.86198
Policy Loss                  -1184.6848
Q Predictions Mean           1179.0212
Q Predictions Std            230.176
Q Predictions Max            1445.762
Q Predictions Min            -134.88817
V Predictions Mean           1189.3308
V Predictions Std            215.79541
V Predictions Max            1449.1393
V Predictions Min            305.93002
Log Pis Mean                 0.5913937
Log Pis Std                  2.7623007
Log Pis Max                  10.683633
Log Pis Min                  -8.884374
Policy mu Mean               -0.06980412
Policy mu Std                0.6102798
Policy mu Max                2.0101593
Policy mu Min                -2.4185026
Policy log std Mean          -1.0842726
Policy log std Std           0.26379725
Policy log std Max           -0.3810705
Policy log std Min           -2.888866
Z mean eval                  1.061204
Z variance eval              0.11719938
total_rewards                [1252.65887734 1770.92351793    6.14743181  155.73637371   82.4336351
 1698.75614777 1761.843056   1198.82958828  352.54332994  288.54523368]
total_rewards_mean           856.8417191559505
total_rewards_std            709.1709880100633
total_rewards_max            1770.9235179310033
total_rewards_min            6.147431809980688
Number of train steps total  1816000
Number of env steps total    3346623
Number of rollouts total     0
Train Time (s)               155.87476254208013
(Previous) Eval Time (s)     15.316036602947861
Sample Time (s)              11.13349477155134
Epoch Time (s)               182.32429391657934
Total Train Time (s)         84431.48379343841
Epoch                        453
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:23:05.223987 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #453 | Epoch Duration: 182.41781640052795
2020-01-13 01:23:05.224180 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0507969
Z variance train             0.11798284
KL Divergence                10.853295
KL Loss                      1.0853295
QF Loss                      800.1194
VF Loss                      270.30054
Policy Loss                  -1177.7909
Q Predictions Mean           1175.5923
Q Predictions Std            265.94873
Q Predictions Max            1444.646
Q Predictions Min            292.21378
V Predictions Mean           1180.4968
V Predictions Std            268.84576
V Predictions Max            1449.3341
V Predictions Min            298.12537
Log Pis Mean                 0.4495499
Log Pis Std                  2.9395428
Log Pis Max                  14.274422
Log Pis Min                  -7.1605377
Policy mu Mean               -0.03295576
Policy mu Std                0.630382
Policy mu Max                3.7762406
Policy mu Min                -2.3185894
Policy log std Mean          -1.0444366
Policy log std Std           0.25450438
Policy log std Max           -0.34543002
Policy log std Min           -2.4976425
Z mean eval                  0.9567261
Z variance eval              0.12169866
total_rewards                [1664.04299818 3720.34697204 3388.37172694 1324.96886957  412.09319864
 -530.66743465 3570.6214327    41.76989016  716.95661615  496.89607219]
total_rewards_mean           1480.5400341910395
total_rewards_std            1479.5297088912605
total_rewards_max            3720.3469720360845
total_rewards_min            -530.6674346544617
Number of train steps total  1820000
Number of env steps total    3355970
Number of rollouts total     0
Train Time (s)               147.24944340484217
(Previous) Eval Time (s)     22.737019226886332
Sample Time (s)              10.727197113912553
Epoch Time (s)               180.71365974564105
Total Train Time (s)         84612.30163716478
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:26:06.045870 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #454 | Epoch Duration: 180.82154822349548
2020-01-13 01:26:06.046058 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #454 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.955667
Z variance train             0.12128129
KL Divergence                12.601184
KL Loss                      1.2601184
QF Loss                      265.31082
VF Loss                      58.817276
Policy Loss                  -1278.0961
Q Predictions Mean           1273.1233
Q Predictions Std            192.81155
Q Predictions Max            1502.3832
Q Predictions Min            313.84952
V Predictions Mean           1278.6531
V Predictions Std            193.0521
V Predictions Max            1503.1603
V Predictions Min            304.62146
Log Pis Mean                 0.99173796
Log Pis Std                  2.8816955
Log Pis Max                  10.08102
Log Pis Min                  -7.954212
Policy mu Mean               -0.069168895
Policy mu Std                0.6580666
Policy mu Max                2.3864267
Policy mu Min                -2.4304192
Policy log std Mean          -1.0667784
Policy log std Std           0.27430356
Policy log std Max           -0.24710327
Policy log std Min           -2.4254599
Z mean eval                  0.8625237
Z variance eval              0.23489308
total_rewards                [ 163.11369994 3637.70489411  339.51910182 1441.82868081 3644.7162729
 3736.81854938 2287.85077984 1974.18781193 3767.862287     17.65536689]
total_rewards_mean           2101.125744461344
total_rewards_std            1479.2869368365803
total_rewards_max            3767.862287001308
total_rewards_min            17.655366885033207
Number of train steps total  1824000
Number of env steps total    3366849
Number of rollouts total     0
Train Time (s)               146.3574780188501
(Previous) Eval Time (s)     22.724041253793985
Sample Time (s)              11.41462202789262
Epoch Time (s)               180.4961413005367
Total Train Time (s)         84792.88589889323
Epoch                        455
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:29:06.634484 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #455 | Epoch Duration: 180.58827710151672
2020-01-13 01:29:06.634661 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8643309
Z variance train             0.23653674
KL Divergence                10.72661
KL Loss                      1.072661
QF Loss                      1337.2808
VF Loss                      374.10098
Policy Loss                  -1254.2552
Q Predictions Mean           1245.7784
Q Predictions Std            217.28456
Q Predictions Max            1500.959
Q Predictions Min            315.41425
V Predictions Mean           1241.7583
V Predictions Std            215.02391
V Predictions Max            1493.912
V Predictions Min            298.77008
Log Pis Mean                 0.4599343
Log Pis Std                  3.026776
Log Pis Max                  19.648287
Log Pis Min                  -7.5466413
Policy mu Mean               -0.034341082
Policy mu Std                0.6469818
Policy mu Max                2.695949
Policy mu Min                -2.6552904
Policy log std Mean          -1.0595357
Policy log std Std           0.2563189
Policy log std Max           -0.28661025
Policy log std Min           -2.271428
Z mean eval                  0.97492474
Z variance eval              0.18483591
total_rewards                [3602.61670461 2605.57137649 3685.45119458  388.71807767 3592.7531053
 3150.77863602 3687.47682047 3690.52306143 3520.80314904 3543.61641947]
total_rewards_mean           3146.8308545084865
total_rewards_std            973.7584968038146
total_rewards_max            3690.5230614339375
total_rewards_min            388.71807766521454
Number of train steps total  1828000
Number of env steps total    3378664
Number of rollouts total     0
Train Time (s)               152.78247792599723
(Previous) Eval Time (s)     34.39265306200832
Sample Time (s)              11.079637185670435
Epoch Time (s)               198.25476817367598
Total Train Time (s)         84991.2274331078
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:32:24.978450 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #456 | Epoch Duration: 198.34366488456726
2020-01-13 01:32:24.978588 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9715411
Z variance train             0.18435545
KL Divergence                11.325306
KL Loss                      1.1325306
QF Loss                      383.0523
VF Loss                      119.174835
Policy Loss                  -1213.5815
Q Predictions Mean           1209.1748
Q Predictions Std            229.79245
Q Predictions Max            1476.206
Q Predictions Min            250.30719
V Predictions Mean           1213.0856
V Predictions Std            228.81944
V Predictions Max            1466.9185
V Predictions Min            261.86423
Log Pis Mean                 1.3466047
Log Pis Std                  2.6874397
Log Pis Max                  14.560698
Log Pis Min                  -5.1736083
Policy mu Mean               -0.010759836
Policy mu Std                0.69181603
Policy mu Max                3.9030766
Policy mu Min                -3.4199805
Policy log std Mean          -1.0724885
Policy log std Std           0.26742658
Policy log std Max           0.11625373
Policy log std Min           -2.1113973
Z mean eval                  1.0848923
Z variance eval              0.138893
total_rewards                [ 461.65476523 3410.50955181  820.01416537 2280.35225066 2843.9054765
 1030.63121501 2499.76801697 2404.17653145 3646.93934101 3099.05366035]
total_rewards_mean           2249.7004974352594
total_rewards_std            1057.7717618897734
total_rewards_max            3646.9393410056095
total_rewards_min            461.65476522820666
Number of train steps total  1832000
Number of env steps total    3388921
Number of rollouts total     0
Train Time (s)               157.35155383357778
(Previous) Eval Time (s)     27.27370251668617
Sample Time (s)              11.877916345838457
Epoch Time (s)               196.5031726961024
Total Train Time (s)         85187.81958844978
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:35:41.576014 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #457 | Epoch Duration: 196.59730410575867
2020-01-13 01:35:41.576232 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0815077
Z variance train             0.1396719
KL Divergence                13.03298
KL Loss                      1.303298
QF Loss                      680.00397
VF Loss                      213.30325
Policy Loss                  -1227.0834
Q Predictions Mean           1226.4373
Q Predictions Std            221.99274
Q Predictions Max            1457.702
Q Predictions Min            298.49896
V Predictions Mean           1232.5554
V Predictions Std            223.24716
V Predictions Max            1462.4451
V Predictions Min            283.80618
Log Pis Mean                 0.37537247
Log Pis Std                  2.6919067
Log Pis Max                  10.028545
Log Pis Min                  -6.1194983
Policy mu Mean               -0.013459055
Policy mu Std                0.64227223
Policy mu Max                2.2306519
Policy mu Min                -2.2867205
Policy log std Mean          -1.029518
Policy log std Std           0.24414133
Policy log std Max           -0.34745246
Policy log std Min           -2.096403
Z mean eval                  0.9228605
Z variance eval              0.05648824
total_rewards                [ 341.54959511  615.27597136  362.87875154   51.94495638 3321.48532168
 3451.58029803  655.99263288  874.55271438 3621.26745328  751.03312308]
total_rewards_mean           1404.7560817732844
total_rewards_std            1368.0157974819379
total_rewards_max            3621.267453282606
total_rewards_min            51.94495637919632
Number of train steps total  1836000
Number of env steps total    3400876
Number of rollouts total     0
Train Time (s)               156.6567488219589
(Previous) Eval Time (s)     24.781037291977555
Sample Time (s)              11.782120005693287
Epoch Time (s)               193.21990611962974
Total Train Time (s)         85381.16432173504
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:38:54.929758 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #458 | Epoch Duration: 193.35332918167114
2020-01-13 01:38:54.930076 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9307076
Z variance train             0.05633851
KL Divergence                13.115963
KL Loss                      1.3115963
QF Loss                      445.0222
VF Loss                      80.68875
Policy Loss                  -1251.9872
Q Predictions Mean           1244.9633
Q Predictions Std            183.27582
Q Predictions Max            1616.0106
Q Predictions Min            311.69678
V Predictions Mean           1247.4651
V Predictions Std            183.441
V Predictions Max            1613.7686
V Predictions Min            304.00638
Log Pis Mean                 0.73629063
Log Pis Std                  2.8176267
Log Pis Max                  11.077629
Log Pis Min                  -6.2730103
Policy mu Mean               -0.064623274
Policy mu Std                0.6612305
Policy mu Max                2.3371572
Policy mu Min                -2.5680864
Policy log std Mean          -1.049899
Policy log std Std           0.24329555
Policy log std Max           -0.29385448
Policy log std Min           -2.1357203
Z mean eval                  1.0728462
Z variance eval              0.018600872
total_rewards                [ 263.27672897 1679.18990898 1764.85859294  624.78631941 3503.7253349
  454.39054337 3556.67119408 2122.10387649  940.80771117 1193.65396867]
total_rewards_mean           1610.3464178979136
total_rewards_std            1113.8961849359123
total_rewards_max            3556.6711940842906
total_rewards_min            263.27672896552343
Number of train steps total  1840000
Number of env steps total    3412191
Number of rollouts total     0
Train Time (s)               158.3069243002683
(Previous) Eval Time (s)     18.954176746308804
Sample Time (s)              12.240794050041586
Epoch Time (s)               189.50189509661868
Total Train Time (s)         85570.76208571903
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:42:04.532401 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #459 | Epoch Duration: 189.60212111473083
2020-01-13 01:42:04.532740 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #459 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0700624
Z variance train             0.01841927
KL Divergence                15.369431
KL Loss                      1.5369431
QF Loss                      456.82538
VF Loss                      112.39296
Policy Loss                  -1246.9694
Q Predictions Mean           1239.8179
Q Predictions Std            203.62816
Q Predictions Max            2244.5208
Q Predictions Min            248.58379
V Predictions Mean           1244.6614
V Predictions Std            202.4983
V Predictions Max            2268.538
V Predictions Min            230.5869
Log Pis Mean                 0.9151061
Log Pis Std                  3.0111098
Log Pis Max                  13.125711
Log Pis Min                  -6.501791
Policy mu Mean               -0.07353205
Policy mu Std                0.70747536
Policy mu Max                3.0667217
Policy mu Min                -3.0417123
Policy log std Mean          -1.0383122
Policy log std Std           0.2406115
Policy log std Max           -0.20376211
Policy log std Min           -2.0411031
Z mean eval                  0.9714797
Z variance eval              0.059071224
total_rewards                [  125.72644093  3555.08817249  3675.26085968  1332.787897
  -316.9475614   2332.11096476  -748.16425908  3236.30806043
  2234.81644873 -1390.84425382]
total_rewards_mean           1403.6142769723785
total_rewards_std            1781.529788106985
total_rewards_max            3675.2608596788514
total_rewards_min            -1390.844253820006
Number of train steps total  1844000
Number of env steps total    3423598
Number of rollouts total     0
Train Time (s)               154.02491983678192
(Previous) Eval Time (s)     28.194676832761616
Sample Time (s)              13.809603879693896
Epoch Time (s)               196.02920054923743
Total Train Time (s)         85766.8798130257
Epoch                        460
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:45:20.654417 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #460 | Epoch Duration: 196.12143540382385
2020-01-13 01:45:20.654613 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9675225
Z variance train             0.058732636
KL Divergence                14.494343
KL Loss                      1.4494343
QF Loss                      329.35486
VF Loss                      159.661
Policy Loss                  -1252.0675
Q Predictions Mean           1246.1415
Q Predictions Std            237.9668
Q Predictions Max            2687.8284
Q Predictions Min            37.742046
V Predictions Mean           1259.5309
V Predictions Std            238.19048
V Predictions Max            2794.2898
V Predictions Min            289.33728
Log Pis Mean                 0.953016
Log Pis Std                  3.2590737
Log Pis Max                  19.010078
Log Pis Min                  -7.1041017
Policy mu Mean               -0.05882886
Policy mu Std                0.7168505
Policy mu Max                3.4905236
Policy mu Min                -2.6515632
Policy log std Mean          -1.032587
Policy log std Std           0.24786682
Policy log std Max           0.2180227
Policy log std Min           -2.7340038
Z mean eval                  1.3479321
Z variance eval              1.2609997
total_rewards                [-1204.99290724  -153.44866208 -1110.88518718 -1024.56526855
 -1107.08495288 -1147.29547712 -1831.56201186  -263.09997826
  -497.28428743 -1211.75759108]
total_rewards_mean           -955.1976323681884
total_rewards_std            481.32548725468234
total_rewards_max            -153.44866207865525
total_rewards_min            -1831.562011855275
Number of train steps total  1848000
Number of env steps total    3435689
Number of rollouts total     0
Train Time (s)               145.62788562709466
(Previous) Eval Time (s)     28.501319308765233
Sample Time (s)              11.222723597195
Epoch Time (s)               185.3519285330549
Total Train Time (s)         85952.34885031357
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:48:26.129231 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #461 | Epoch Duration: 185.47446060180664
2020-01-13 01:48:26.129476 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #461 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3437138
Z variance train             1.275666
KL Divergence                22.05524
KL Loss                      2.2055242
QF Loss                      9303.874
VF Loss                      1396.841
Policy Loss                  -2009.4512
Q Predictions Mean           1897.0647
Q Predictions Std            521.6058
Q Predictions Max            5025.799
Q Predictions Min            552.1881
V Predictions Mean           2017.1971
V Predictions Std            528.2412
V Predictions Max            5090.659
V Predictions Min            513.0493
Log Pis Mean                 10.708737
Log Pis Std                  4.390694
Log Pis Max                  21.467686
Log Pis Min                  -1.2977687
Policy mu Mean               0.57279074
Policy mu Std                1.5632331
Policy mu Max                4.0805984
Policy mu Min                -3.789943
Policy log std Mean          -0.9754025
Policy log std Std           0.36520895
Policy log std Max           0.004839301
Policy log std Min           -2.9472485
Z mean eval                  1.8313977
Z variance eval              0.15702382
total_rewards                [-1228.72401993  -721.89903565 -1092.44763423 -1162.95128414
 -1176.20857588 -1259.02005844  -720.35937849  -554.01812533
 -1282.7926503  -1003.23006315]
total_rewards_mean           -1020.1650825542469
total_rewards_std            248.1753177057004
total_rewards_max            -554.0181253343912
total_rewards_min            -1282.7926503004865
Number of train steps total  1852000
Number of env steps total    3445632
Number of rollouts total     0
Train Time (s)               146.387982416898
(Previous) Eval Time (s)     37.601451041176915
Sample Time (s)              11.277534376364201
Epoch Time (s)               195.26696783443913
Total Train Time (s)         86147.70964983525
Epoch                        462
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:51:41.494486 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #462 | Epoch Duration: 195.36484026908875
2020-01-13 01:51:41.494705 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8375736
Z variance train             0.15692994
KL Divergence                30.101124
KL Loss                      3.0101125
QF Loss                      4569.579
VF Loss                      763.2567
Policy Loss                  -2435.973
Q Predictions Mean           2393.1729
Q Predictions Std            452.47894
Q Predictions Max            5198.005
Q Predictions Min            680.7157
V Predictions Mean           2429.566
V Predictions Std            463.63217
V Predictions Max            5323.5166
V Predictions Min            704.4107
Log Pis Mean                 5.6454754
Log Pis Std                  3.4505112
Log Pis Max                  16.898167
Log Pis Min                  -3.7259183
Policy mu Mean               0.2433016
Policy mu Std                1.1193708
Policy mu Max                3.6186104
Policy mu Min                -3.6239674
Policy log std Mean          -1.1417534
Policy log std Std           0.3623766
Policy log std Max           0.1028831
Policy log std Min           -2.3172135
Z mean eval                  1.5064553
Z variance eval              0.36936206
total_rewards                [  -15.39097755 -1650.58153818    -6.29233436 -1581.59029224
 -1538.47231723 -1661.74895076  -695.83224458  -647.77680299
  -118.14072883 -1735.46088091]
total_rewards_mean           -965.1287067619569
total_rewards_std            704.9308606152464
total_rewards_max            -6.292334356092611
total_rewards_min            -1735.460880910667
Number of train steps total  1856000
Number of env steps total    3455241
Number of rollouts total     0
Train Time (s)               155.83874588413164
(Previous) Eval Time (s)     32.84383060969412
Sample Time (s)              11.84323683893308
Epoch Time (s)               200.52581333275884
Total Train Time (s)         86348.33462292328
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:55:02.124944 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #463 | Epoch Duration: 200.6300573348999
2020-01-13 01:55:02.125260 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #463 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5068963
Z variance train             0.3703989
KL Divergence                29.065975
KL Loss                      2.9065976
QF Loss                      1398.0286
VF Loss                      885.5798
Policy Loss                  -2427.071
Q Predictions Mean           2414.1218
Q Predictions Std            436.07278
Q Predictions Max            5810.136
Q Predictions Min            811.8073
V Predictions Mean           2408.5425
V Predictions Std            439.76907
V Predictions Max            5821.5186
V Predictions Min            838.1353
Log Pis Mean                 2.751493
Log Pis Std                  3.4741054
Log Pis Max                  20.047932
Log Pis Min                  -3.5919576
Policy mu Mean               0.09968827
Policy mu Std                0.84843105
Policy mu Max                4.444823
Policy mu Min                -2.9808865
Policy log std Mean          -1.0762329
Policy log std Std           0.25913233
Policy log std Max           -0.20737088
Policy log std Min           -2.5306683
Z mean eval                  1.649677
Z variance eval              0.09449485
total_rewards                [ -975.62834349    -3.79698549 -1151.93974304 -1405.50389313
 -1327.04829197 -1058.16741598  -858.88150902  -535.02112735
 -1509.1356246    -31.56453966]
total_rewards_mean           -885.6687473724617
total_rewards_std            509.2511465392485
total_rewards_max            -3.796985486461879
total_rewards_min            -1509.1356246032383
Number of train steps total  1860000
Number of env steps total    3465787
Number of rollouts total     0
Train Time (s)               155.215238397941
(Previous) Eval Time (s)     31.847028187010437
Sample Time (s)              12.356147425249219
Epoch Time (s)               199.41841401020065
Total Train Time (s)         86547.83890439896
Epoch                        464
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:58:21.633359 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #464 | Epoch Duration: 199.50790858268738
2020-01-13 01:58:21.633589 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6558739
Z variance train             0.09436588
KL Divergence                32.99464
KL Loss                      3.299464
QF Loss                      2597.4536
VF Loss                      492.97147
Policy Loss                  -2451.636
Q Predictions Mean           2423.767
Q Predictions Std            403.03238
Q Predictions Max            5700.271
Q Predictions Min            1472.6166
V Predictions Mean           2452.6384
V Predictions Std            411.32065
V Predictions Max            5769.8647
V Predictions Min            1518.505
Log Pis Mean                 3.7324312
Log Pis Std                  3.7645948
Log Pis Max                  20.74686
Log Pis Min                  -7.583216
Policy mu Mean               0.19407423
Policy mu Std                1.0274291
Policy mu Max                3.6114235
Policy mu Min                -3.8583739
Policy log std Mean          -1.0306243
Policy log std Std           0.32641754
Policy log std Max           -0.009143591
Policy log std Min           -2.104727
Z mean eval                  1.4670593
Z variance eval              0.04022694
total_rewards                [ -600.4442791   -597.34793685  -610.89934876  -611.92237831
 -1136.94994001  -874.46668766  -644.10624255  -242.12884497
 -1070.03093699  -522.61408405]
total_rewards_mean           -691.0910679249416
total_rewards_std            252.56174093249467
total_rewards_max            -242.1288449727212
total_rewards_min            -1136.9499400081365
Number of train steps total  1864000
Number of env steps total    3476740
Number of rollouts total     0
Train Time (s)               155.32623335439712
(Previous) Eval Time (s)     39.1166378618218
Sample Time (s)              12.497152728494257
Epoch Time (s)               206.94002394471318
Total Train Time (s)         86754.87209829828
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:01:48.672575 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #465 | Epoch Duration: 207.03877472877502
2020-01-13 02:01:48.672995 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #465 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4705396
Z variance train             0.039684854
KL Divergence                34.811302
KL Loss                      3.4811304
QF Loss                      1860.9951
VF Loss                      251.60751
Policy Loss                  -2455.9456
Q Predictions Mean           2439.9922
Q Predictions Std            498.89856
Q Predictions Max            5476.131
Q Predictions Min            1792.189
V Predictions Mean           2451.5605
V Predictions Std            508.34427
V Predictions Max            5485.5654
V Predictions Min            1865.7659
Log Pis Mean                 3.125389
Log Pis Std                  3.0373724
Log Pis Max                  14.421695
Log Pis Min                  -4.304636
Policy mu Mean               0.056924686
Policy mu Std                0.92460394
Policy mu Max                3.2702234
Policy mu Min                -2.8541641
Policy log std Mean          -1.081892
Policy log std Std           0.31865126
Policy log std Max           -0.20511395
Policy log std Min           -2.5438843
Z mean eval                  1.5339372
Z variance eval              0.057225578
total_rewards                [  133.8433251   -153.56753905   -42.95456686  -111.40241391
    -4.88242179   -46.15362596   -95.95826525  -592.67374849
   -88.14005566 -1389.59969161]
total_rewards_mean           -239.14890034860022
total_rewards_std            422.51754760808905
total_rewards_max            133.8433250954985
total_rewards_min            -1389.5996916108504
Number of train steps total  1868000
Number of env steps total    3487338
Number of rollouts total     0
Train Time (s)               155.50987715274096
(Previous) Eval Time (s)     27.589270228054374
Sample Time (s)              12.390494063030928
Epoch Time (s)               195.48964144382626
Total Train Time (s)         86950.45323932031
Epoch                        466
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:05:04.258229 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #466 | Epoch Duration: 195.58493638038635
2020-01-13 02:05:04.258447 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #466 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.53384
Z variance train             0.057561614
KL Divergence                37.62921
KL Loss                      3.762921
QF Loss                      2796.5308
VF Loss                      452.15607
Policy Loss                  -2462.885
Q Predictions Mean           2446.0586
Q Predictions Std            404.8417
Q Predictions Max            4816.201
Q Predictions Min            1774.5165
V Predictions Mean           2458.642
V Predictions Std            389.11377
V Predictions Max            4758.111
V Predictions Min            1930.8787
Log Pis Mean                 3.200127
Log Pis Std                  4.886862
Log Pis Max                  35.910347
Log Pis Min                  -8.014471
Policy mu Mean               0.1709156
Policy mu Std                0.97258073
Policy mu Max                4.3826013
Policy mu Min                -6.048238
Policy log std Mean          -1.0172975
Policy log std Std           0.34338868
Policy log std Max           1.654614
Policy log std Min           -2.481945
Z mean eval                  2.1115394
Z variance eval              1.9846064
total_rewards                [-1569.79678491 -1541.14441643 -1539.21352751 -1588.68883011
 -1586.59454838 -1546.95081984 -1603.60809781 -1601.3974497
 -1602.60883158 -1578.16293838]
total_rewards_mean           -1575.816624465217
total_rewards_std            24.173024935097914
total_rewards_max            -1539.213527513276
total_rewards_min            -1603.6080978060043
Number of train steps total  1872000
Number of env steps total    3496537
Number of rollouts total     0
Train Time (s)               147.1874412917532
(Previous) Eval Time (s)     37.757904454134405
Sample Time (s)              10.198910893406719
Epoch Time (s)               195.14425663929433
Total Train Time (s)         87145.68494963972
Epoch                        467
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:08:19.493908 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #467 | Epoch Duration: 195.23531246185303
2020-01-13 02:08:19.494099 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.104244
Z variance train             1.9859552
KL Divergence                46.25187
KL Loss                      4.625187
QF Loss                      2671.1362
VF Loss                      744.7527
Policy Loss                  -3377.26
Q Predictions Mean           3320.0103
Q Predictions Std            256.8821
Q Predictions Max            4748.6113
Q Predictions Min            2669.5024
V Predictions Mean           3369.7153
V Predictions Std            254.2407
V Predictions Max            4712.885
V Predictions Min            2657.6995
Log Pis Mean                 6.877804
Log Pis Std                  3.4533467
Log Pis Max                  17.766865
Log Pis Min                  -1.6849246
Policy mu Mean               0.12830679
Policy mu Std                1.2813418
Policy mu Max                3.3009722
Policy mu Min                -4.0496225
Policy log std Mean          -1.1012304
Policy log std Std           0.39060915
Policy log std Max           -0.07941997
Policy log std Min           -2.4677644
Z mean eval                  1.8881868
Z variance eval              1.9746933
total_rewards                [-649.73024981  -27.76163975  -41.51454344  -41.58334714  -85.88661337
  -78.65345344   81.98524214  -88.15332464  -66.53226801  -72.21405807]
total_rewards_mean           -107.00442555392746
total_rewards_std            186.9679504333822
total_rewards_max            81.9852421417807
total_rewards_min            -649.7302498080759
Number of train steps total  1876000
Number of env steps total    3506886
Number of rollouts total     0
Train Time (s)               146.1362286619842
(Previous) Eval Time (s)     36.63175381766632
Sample Time (s)              9.305538319051266
Epoch Time (s)               192.0735207987018
Total Train Time (s)         87337.84424523031
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:11:31.657474 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #468 | Epoch Duration: 192.1632354259491
2020-01-13 02:11:31.657659 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8877052
Z variance train             1.9733584
KL Divergence                36.88369
KL Loss                      3.688369
QF Loss                      2525.3325
VF Loss                      2129.0356
Policy Loss                  -3484.0684
Q Predictions Mean           3462.833
Q Predictions Std            306.01807
Q Predictions Max            4708.0728
Q Predictions Min            -348.60083
V Predictions Mean           3467.0823
V Predictions Std            251.36989
V Predictions Max            4718.7627
V Predictions Min            872.4731
Log Pis Mean                 2.3749845
Log Pis Std                  3.034281
Log Pis Max                  22.303846
Log Pis Min                  -5.929846
Policy mu Mean               0.26923913
Policy mu Std                0.76303345
Policy mu Max                3.339601
Policy mu Min                -5.5510044
Policy log std Mean          -1.1324221
Policy log std Std           0.30110082
Policy log std Max           0.56741774
Policy log std Min           -2.4532852
Z mean eval                  1.511378
Z variance eval              0.6469886
total_rewards                [ 206.32473102  193.74885306 -100.70732976  193.14299031  167.5334714
  171.10799045  217.10214026  192.34129615  257.25404077  170.57083923]
total_rewards_mean           166.8419022897579
total_rewards_std            92.70408011745324
total_rewards_max            257.25404076775123
total_rewards_min            -100.70732975832178
Number of train steps total  1880000
Number of env steps total    3517107
Number of rollouts total     0
Train Time (s)               151.5053587188013
(Previous) Eval Time (s)     38.27368598198518
Sample Time (s)              11.236215603072196
Epoch Time (s)               201.01526030385867
Total Train Time (s)         87538.97572779749
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:14:52.794516 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #469 | Epoch Duration: 201.136714220047
2020-01-13 02:14:52.794701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5130684
Z variance train             0.6514498
KL Divergence                27.709202
KL Loss                      2.7709203
QF Loss                      1421.4337
VF Loss                      477.47623
Policy Loss                  -2628.4573
Q Predictions Mean           2617.288
Q Predictions Std            228.28343
Q Predictions Max            3992.0544
Q Predictions Min            2171.3823
V Predictions Mean           2642.5132
V Predictions Std            233.33405
V Predictions Max            4090.2915
V Predictions Min            2244.3438
Log Pis Mean                 1.3464617
Log Pis Std                  3.0846443
Log Pis Max                  16.358215
Log Pis Min                  -6.7212124
Policy mu Mean               0.012771241
Policy mu Std                0.758811
Policy mu Max                2.753052
Policy mu Min                -2.5987368
Policy log std Mean          -1.0670648
Policy log std Std           0.28474715
Policy log std Max           -0.11076856
Policy log std Min           -2.336464
Z mean eval                  1.651881
Z variance eval              0.15953156
total_rewards                [  132.92861726  -230.59497359    62.34665059  -404.36717016
  -637.27021955  -665.3895596     80.9541662   -183.52561986
  -131.73736852 -1131.41694561]
total_rewards_mean           -310.80724228344866
total_rewards_std            381.9402337680712
total_rewards_max            132.92861726032154
total_rewards_min            -1131.416945606462
Number of train steps total  1884000
Number of env steps total    3526751
Number of rollouts total     0
Train Time (s)               156.75627081422135
(Previous) Eval Time (s)     38.24716995516792
Sample Time (s)              12.27584118861705
Epoch Time (s)               207.27928195800632
Total Train Time (s)         87746.34475207841
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:18:20.167768 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #470 | Epoch Duration: 207.37292790412903
2020-01-13 02:18:20.167956 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6463255
Z variance train             0.15928319
KL Divergence                26.47218
KL Loss                      2.647218
QF Loss                      1160.5433
VF Loss                      455.33432
Policy Loss                  -2483.851
Q Predictions Mean           2472.5767
Q Predictions Std            295.3593
Q Predictions Max            4573.889
Q Predictions Min            2196.8506
V Predictions Mean           2485.9932
V Predictions Std            290.12457
V Predictions Max            4568.028
V Predictions Min            2178.6272
Log Pis Mean                 1.2383931
Log Pis Std                  3.6525822
Log Pis Max                  29.329075
Log Pis Min                  -6.281073
Policy mu Mean               -0.23317403
Policy mu Std                0.83765787
Policy mu Max                3.6641645
Policy mu Min                -3.2340252
Policy log std Mean          -0.8694089
Policy log std Std           0.20962384
Policy log std Max           0.49293673
Policy log std Min           -1.9819367
Z mean eval                  1.3724445
Z variance eval              0.040557772
total_rewards                [ -701.8655357   -213.92625428 -1282.65360445   147.38106066
 -1433.92331772  -501.0359526   -989.13530484 -1548.07824513
 -1208.51203642 -1196.56325599]
total_rewards_mean           -892.8312446472988
total_rewards_std            529.9243137762738
total_rewards_max            147.38106065895784
total_rewards_min            -1548.0782451294128
Number of train steps total  1888000
Number of env steps total    3538764
Number of rollouts total     0
Train Time (s)               154.5295878490433
(Previous) Eval Time (s)     34.59819925809279
Sample Time (s)              12.944148647598922
Epoch Time (s)               202.07193575473502
Total Train Time (s)         87948.50755064562
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:21:42.335767 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #471 | Epoch Duration: 202.16765236854553
2020-01-13 02:21:42.335986 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #471 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3764166
Z variance train             0.040424313
KL Divergence                27.430431
KL Loss                      2.7430432
QF Loss                      1922.9053
VF Loss                      418.10126
Policy Loss                  -2344.7021
Q Predictions Mean           2329.1025
Q Predictions Std            522.8097
Q Predictions Max            5324.17
Q Predictions Min            2009.6099
V Predictions Mean           2347.9658
V Predictions Std            533.0293
V Predictions Max            5424.415
V Predictions Min            2021.0354
Log Pis Mean                 1.5231928
Log Pis Std                  3.6864562
Log Pis Max                  13.894294
Log Pis Min                  -10.548094
Policy mu Mean               -0.108149566
Policy mu Std                0.8771419
Policy mu Max                3.9705608
Policy mu Min                -2.9425447
Policy log std Mean          -0.9029944
Policy log std Std           0.25123522
Policy log std Max           0.4697739
Policy log std Min           -2.359798
Z mean eval                  2.2070887
Z variance eval              0.029800028
total_rewards                [-2109.28240386 -1561.31293955 -1587.6009717    -34.65849265
 -1032.03986411  -431.62683272 -1575.03922132 -1288.47319328
 -2063.83459115 -1499.26492321]
total_rewards_mean           -1318.3133433555574
total_rewards_std            626.7755539377654
total_rewards_max            -34.65849265036888
total_rewards_min            -2109.2824038636045
Number of train steps total  1892000
Number of env steps total    3548506
Number of rollouts total     0
Train Time (s)               156.7699905829504
(Previous) Eval Time (s)     33.442267037928104
Sample Time (s)              12.208178667351604
Epoch Time (s)               202.42043628823012
Total Train Time (s)         88151.03096219013
Epoch                        472
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:25:04.864680 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #472 | Epoch Duration: 202.52851724624634
2020-01-13 02:25:04.864943 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #472 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2085512
Z variance train             0.029182117
KL Divergence                47.091568
KL Loss                      4.709157
QF Loss                      8681.773
VF Loss                      1224.814
Policy Loss                  -3536.3477
Q Predictions Mean           3412.9873
Q Predictions Std            476.32193
Q Predictions Max            6515.452
Q Predictions Min            2675.5537
V Predictions Mean           3530.0376
V Predictions Std            485.99866
V Predictions Max            6722.547
V Predictions Min            2679.3345
Log Pis Mean                 11.765144
Log Pis Std                  4.1446996
Log Pis Max                  24.1194
Log Pis Min                  -2.4798625
Policy mu Mean               0.19813332
Policy mu Std                1.7121174
Policy mu Max                3.6062796
Policy mu Min                -3.8428705
Policy log std Mean          -0.91487235
Policy log std Std           0.35932347
Policy log std Max           0.10360038
Policy log std Min           -2.356411
Z mean eval                  2.1718335
Z variance eval              0.5872631
total_rewards                [ 18.01663442  30.256869    92.72074995 -22.62190939   7.3637615
  21.43119532 -89.65955084  97.11349658 -11.08262339  44.23150996]
total_rewards_mean           18.777013310364048
total_rewards_std            51.85155890576186
total_rewards_max            97.11349657974264
total_rewards_min            -89.65955084126195
Number of train steps total  1896000
Number of env steps total    3558858
Number of rollouts total     0
Train Time (s)               151.67419994296506
(Previous) Eval Time (s)     37.013111669104546
Sample Time (s)              12.178819119930267
Epoch Time (s)               200.86613073199987
Total Train Time (s)         88351.98635580251
Epoch                        473
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:28:25.824579 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #473 | Epoch Duration: 200.95946264266968
2020-01-13 02:28:25.824783 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1677806
Z variance train             0.5841539
KL Divergence                46.55629
KL Loss                      4.655629
QF Loss                      1940.3091
VF Loss                      601.46765
Policy Loss                  -3835.9368
Q Predictions Mean           3817.9644
Q Predictions Std            304.46622
Q Predictions Max            5885.3843
Q Predictions Min            2893.337
V Predictions Mean           3847.1462
V Predictions Std            306.98672
V Predictions Max            5987.678
V Predictions Min            2877.9065
Log Pis Mean                 3.5674095
Log Pis Std                  2.8162315
Log Pis Max                  12.050602
Log Pis Min                  -8.333241
Policy mu Mean               0.23021689
Policy mu Std                0.8687053
Policy mu Max                2.7837272
Policy mu Min                -2.5728374
Policy log std Mean          -1.171576
Policy log std Std           0.27529266
Policy log std Max           -0.29912752
Policy log std Min           -2.6179938
Z mean eval                  1.8064249
Z variance eval              0.18604465
total_rewards                [-1470.99372312    74.13602468   659.32242027  -368.98454889
  -850.80672751    96.04362818  -499.32114511 -1495.12213663
     3.17924843   112.63576128]
total_rewards_mean           -373.991119841861
total_rewards_std            676.1646216286244
total_rewards_max            659.3224202678535
total_rewards_min            -1495.1221366272475
Number of train steps total  1900000
Number of env steps total    3569425
Number of rollouts total     0
Train Time (s)               147.43013457208872
(Previous) Eval Time (s)     26.517106999177486
Sample Time (s)              11.543551869224757
Epoch Time (s)               185.49079344049096
Total Train Time (s)         88537.57717126422
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:31:31.419740 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #474 | Epoch Duration: 185.59480786323547
2020-01-13 02:31:31.419965 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8085451
Z variance train             0.18804342
KL Divergence                37.113716
KL Loss                      3.7113717
QF Loss                      70445.15
VF Loss                      2400.1938
Policy Loss                  -3087.977
Q Predictions Mean           3078.0557
Q Predictions Std            476.9553
Q Predictions Max            5525.264
Q Predictions Min            -146.44978
V Predictions Mean           3121.9404
V Predictions Std            505.3262
V Predictions Max            5608.5913
V Predictions Min            -24.747017
Log Pis Mean                 3.0020964
Log Pis Std                  3.7263348
Log Pis Max                  17.181757
Log Pis Min                  -5.6721992
Policy mu Mean               0.031168777
Policy mu Std                0.9728331
Policy mu Max                3.6208098
Policy mu Min                -4.6247277
Policy log std Mean          -0.9680705
Policy log std Std           0.2861239
Policy log std Max           0.038116693
Policy log std Min           -2.3827648
Z mean eval                  1.6374677
Z variance eval              0.25213757
total_rewards                [ -308.0476967   -744.21249037 -1146.8071778     64.89839202
  -692.16907679  -731.06756562   176.20732459  -762.49337452
  -730.71520477  -548.53635137]
total_rewards_mean           -542.2943221328567
total_rewards_std            385.76322057359846
total_rewards_max            176.20732459344967
total_rewards_min            -1146.8071777987327
Number of train steps total  1904000
Number of env steps total    3579909
Number of rollouts total     0
Train Time (s)               148.59202477522194
(Previous) Eval Time (s)     31.32321002194658
Sample Time (s)              10.258651015348732
Epoch Time (s)               190.17388581251726
Total Train Time (s)         88727.83991139848
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:34:41.686835 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #475 | Epoch Duration: 190.26672840118408
2020-01-13 02:34:41.687041 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6501383
Z variance train             0.25051194
KL Divergence                29.77692
KL Loss                      2.9776921
QF Loss                      1539.2621
VF Loss                      968.79144
Policy Loss                  -2858.311
Q Predictions Mean           2845.1978
Q Predictions Std            455.0972
Q Predictions Max            4743.884
Q Predictions Min            2407.9543
V Predictions Mean           2836.1917
V Predictions Std            458.94678
V Predictions Max            4766.1064
V Predictions Min            2395.4785
Log Pis Mean                 1.5569141
Log Pis Std                  3.1118958
Log Pis Max                  10.879843
Log Pis Min                  -9.480036
Policy mu Mean               -0.04831212
Policy mu Std                0.8125181
Policy mu Max                2.77695
Policy mu Min                -2.5303268
Policy log std Mean          -1.0348387
Policy log std Std           0.26228806
Policy log std Max           0.17380798
Policy log std Min           -2.2581367
Z mean eval                  1.4659308
Z variance eval              0.14255208
total_rewards                [-365.63453864  138.05249148   33.22611279   65.09038335 -177.22415855
 -355.90503417 -156.54013552 -249.60501214 -308.80968218   31.13288171]
total_rewards_mean           -134.62166918688862
total_rewards_std            178.34653028521487
total_rewards_max            138.05249148228978
total_rewards_min            -365.63453864120123
Number of train steps total  1908000
Number of env steps total    3589201
Number of rollouts total     0
Train Time (s)               157.7367255068384
(Previous) Eval Time (s)     26.843141599092633
Sample Time (s)              12.169076247606426
Epoch Time (s)               196.74894335353747
Total Train Time (s)         88924.67588792462
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:37:58.527417 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #476 | Epoch Duration: 196.840234041214
2020-01-13 02:37:58.527592 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.464988
Z variance train             0.14470778
KL Divergence                28.989937
KL Loss                      2.8989937
QF Loss                      1688.063
VF Loss                      493.39706
Policy Loss                  -2464.1172
Q Predictions Mean           2451.4724
Q Predictions Std            326.96976
Q Predictions Max            3980.1375
Q Predictions Min            2028.0542
V Predictions Mean           2455.2056
V Predictions Std            332.6365
V Predictions Max            3970.9958
V Predictions Min            1997.677
Log Pis Mean                 2.1050289
Log Pis Std                  3.334293
Log Pis Max                  10.0509615
Log Pis Min                  -9.6533
Policy mu Mean               -0.0011637739
Policy mu Std                0.8959143
Policy mu Max                3.095164
Policy mu Min                -2.9874072
Policy log std Mean          -1.011713
Policy log std Std           0.3028885
Policy log std Max           -0.14779437
Policy log std Min           -2.3732734
Z mean eval                  1.3616287
Z variance eval              0.059483536
total_rewards                [ -67.09960373 -490.73534416   -1.67859603 -100.56066037 -131.47374077
   -3.39421353  -21.3189905   -10.58671169 -533.67741467 -101.58614859]
total_rewards_mean           -146.21114240349237
total_rewards_std            188.32328290178071
total_rewards_max            -1.678596025784616
total_rewards_min            -533.6774146695341
Number of train steps total  1912000
Number of env steps total    3601323
Number of rollouts total     0
Train Time (s)               156.81388277281076
(Previous) Eval Time (s)     29.874452830292284
Sample Time (s)              12.023861976340413
Epoch Time (s)               198.71219757944345
Total Train Time (s)         89123.47853773879
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:41:17.335227 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #477 | Epoch Duration: 198.80748748779297
2020-01-13 02:41:17.335425 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3670542
Z variance train             0.058624603
KL Divergence                28.83055
KL Loss                      2.883055
QF Loss                      938.06604
VF Loss                      256.89975
Policy Loss                  -2291.1792
Q Predictions Mean           2282.1108
Q Predictions Std            243.62788
Q Predictions Max            3351.432
Q Predictions Min            1066.9342
V Predictions Mean           2293.8008
V Predictions Std            242.16576
V Predictions Max            3353.8315
V Predictions Min            1053.6154
Log Pis Mean                 1.890149
Log Pis Std                  2.8925586
Log Pis Max                  17.532288
Log Pis Min                  -6.417572
Policy mu Mean               0.07339918
Policy mu Std                0.81272876
Policy mu Max                2.7186255
Policy mu Min                -2.5021768
Policy log std Mean          -1.0206597
Policy log std Std           0.31945157
Policy log std Max           -0.21443748
Policy log std Min           -3.3049417
Z mean eval                  1.3460915
Z variance eval              0.18903759
total_rewards                [ 175.92485354   85.80921396   32.27848008  103.95394195  -14.12768667
    5.31072366 -534.04041542   23.57582059  -92.42746577   99.40432649]
total_rewards_mean           -11.433820760160433
total_rewards_std            187.9522842453893
total_rewards_max            175.9248535374344
total_rewards_min            -534.0404154182312
Number of train steps total  1916000
Number of env steps total    3612323
Number of rollouts total     0
Train Time (s)               156.0955765149556
(Previous) Eval Time (s)     36.05135988164693
Sample Time (s)              11.515338053461164
Epoch Time (s)               203.6622744500637
Total Train Time (s)         89327.2317202054
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:44:41.093587 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #478 | Epoch Duration: 203.75800228118896
2020-01-13 02:44:41.093837 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3455818
Z variance train             0.18940254
KL Divergence                22.142014
KL Loss                      2.2142015
QF Loss                      528.17334
VF Loss                      121.26129
Policy Loss                  -2058.0725
Q Predictions Mean           2053.1514
Q Predictions Std            158.23024
Q Predictions Max            2741.1316
Q Predictions Min            1726.5397
V Predictions Mean           2055.4307
V Predictions Std            154.13692
V Predictions Max            2755.7617
V Predictions Min            1755.4749
Log Pis Mean                 1.6197436
Log Pis Std                  2.8884976
Log Pis Max                  12.108721
Log Pis Min                  -7.958538
Policy mu Mean               0.0065767295
Policy mu Std                0.76225674
Policy mu Max                2.4216673
Policy mu Min                -2.8668067
Policy log std Mean          -1.0493013
Policy log std Std           0.26838413
Policy log std Max           -0.2801854
Policy log std Min           -2.3451433
Z mean eval                  1.086322
Z variance eval              1.4962488
total_rewards                [ 571.85293817   51.90948321  128.37297224 -393.8762518  -230.25825955
  -24.99107511   23.02336537  -58.14479045 -331.67955086  -77.80455554]
total_rewards_mean           -34.159572431592515
total_rewards_std            257.5420199587362
total_rewards_max            571.8529381697474
total_rewards_min            -393.87625179930825
Number of train steps total  1920000
Number of env steps total    3621053
Number of rollouts total     0
Train Time (s)               156.0752785447985
(Previous) Eval Time (s)     37.73319547390565
Sample Time (s)              12.679944318253547
Epoch Time (s)               206.4884183369577
Total Train Time (s)         89533.81129262643
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:48:07.678620 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #479 | Epoch Duration: 206.58460545539856
2020-01-13 02:48:07.678855 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0844413
Z variance train             1.4981116
KL Divergence                15.095649
KL Loss                      1.5095649
QF Loss                      785.6883
VF Loss                      1063.8011
Policy Loss                  -2299.7239
Q Predictions Mean           2297.2024
Q Predictions Std            160.44185
Q Predictions Max            2761.3652
Q Predictions Min            437.4043
V Predictions Mean           2285.7812
V Predictions Std            143.23083
V Predictions Max            2735.1963
V Predictions Min            790.53986
Log Pis Mean                 0.9358182
Log Pis Std                  2.723105
Log Pis Max                  7.695134
Log Pis Min                  -6.6436396
Policy mu Mean               0.05017925
Policy mu Std                0.6933471
Policy mu Max                2.1826282
Policy mu Min                -2.3004081
Policy log std Mean          -1.0410205
Policy log std Std           0.28418067
Policy log std Max           0.04163885
Policy log std Min           -2.725298
Z mean eval                  1.0994899
Z variance eval              0.1535901
total_rewards                [ 230.71784875  731.75761516  209.40203671   12.97097248 -524.65737505
 1413.2348816   372.92298838  986.75316909   45.67479912  104.12567993]
total_rewards_mean           358.2902616164431
total_rewards_std            524.1353055003145
total_rewards_max            1413.2348816028732
total_rewards_min            -524.6573750483459
Number of train steps total  1924000
Number of env steps total    3630078
Number of rollouts total     0
Train Time (s)               146.9065451528877
(Previous) Eval Time (s)     28.457637226209044
Sample Time (s)              12.342356280889362
Epoch Time (s)               187.7065386599861
Total Train Time (s)         89721.62160738604
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:51:15.493771 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #480 | Epoch Duration: 187.81474494934082
2020-01-13 02:51:15.493985 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0967361
Z variance train             0.15503374
KL Divergence                13.270209
KL Loss                      1.327021
QF Loss                      940.3413
VF Loss                      122.47278
Policy Loss                  -1723.9142
Q Predictions Mean           1721.0698
Q Predictions Std            75.0796
Q Predictions Max            1921.7606
Q Predictions Min            1423.1536
V Predictions Mean           1727.1226
V Predictions Std            71.87636
V Predictions Max            1920.989
V Predictions Min            1430.3363
Log Pis Mean                 0.7706996
Log Pis Std                  2.1356866
Log Pis Max                  5.8758016
Log Pis Min                  -5.661238
Policy mu Mean               0.019178526
Policy mu Std                0.6161614
Policy mu Max                2.1085618
Policy mu Min                -2.4611032
Policy log std Mean          -1.0970309
Policy log std Std           0.21986507
Policy log std Max           -0.44118
Policy log std Min           -2.028706
Z mean eval                  0.99225795
Z variance eval              0.21327397
total_rewards                [1056.35357193  393.70937789 1711.27838695   47.67443356  456.48259339
 1186.98270875 1386.63954273  312.14155718  460.19561567  242.66180996]
total_rewards_mean           725.4119598019778
total_rewards_std            533.6274017521843
total_rewards_max            1711.2783869472705
total_rewards_min            47.67443356397398
Number of train steps total  1928000
Number of env steps total    3641954
Number of rollouts total     0
Train Time (s)               147.78048055199906
(Previous) Eval Time (s)     20.516153757926077
Sample Time (s)              11.815248299390078
Epoch Time (s)               180.11188260931522
Total Train Time (s)         89901.8319723974
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:54:15.708662 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #481 | Epoch Duration: 180.21452260017395
2020-01-13 02:54:15.708850 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0199561
Z variance train             0.2100027
KL Divergence                11.268215
KL Loss                      1.1268215
QF Loss                      1128.2477
VF Loss                      444.1781
Policy Loss                  -1496.203
Q Predictions Mean           1491.2056
Q Predictions Std            121.019485
Q Predictions Max            1719.3634
Q Predictions Min            799.21606
V Predictions Mean           1491.9397
V Predictions Std            110.11837
V Predictions Max            1719.7905
V Predictions Min            948.596
Log Pis Mean                 1.080584
Log Pis Std                  2.7013621
Log Pis Max                  14.305279
Log Pis Min                  -5.007361
Policy mu Mean               -0.0110668605
Policy mu Std                0.6507311
Policy mu Max                3.727755
Policy mu Min                -2.7475138
Policy log std Mean          -1.1065046
Policy log std Std           0.23939224
Policy log std Max           -0.21726733
Policy log std Min           -2.1546326
Z mean eval                  1.0281537
Z variance eval              0.11372882
total_rewards                [ 223.09966672  224.63855993  272.37660361 1278.15040726 1233.22174122
  844.90940618  605.54766164  132.22864883  627.23619219   19.30098185]
total_rewards_mean           546.0709869428223
total_rewards_std            428.81652444021864
total_rewards_max            1278.1504072634011
total_rewards_min            19.30098184866982
Number of train steps total  1932000
Number of env steps total    3652481
Number of rollouts total     0
Train Time (s)               154.2237919261679
(Previous) Eval Time (s)     12.371468075085431
Sample Time (s)              11.190975163597614
Epoch Time (s)               177.78623516485095
Total Train Time (s)         90079.71914189914
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:57:13.600669 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #482 | Epoch Duration: 177.8916699886322
2020-01-13 02:57:13.600881 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0299575
Z variance train             0.113900706
KL Divergence                12.915306
KL Loss                      1.2915306
QF Loss                      488.30124
VF Loss                      240.70033
Policy Loss                  -1500.4496
Q Predictions Mean           1496.2737
Q Predictions Std            137.85965
Q Predictions Max            1741.5146
Q Predictions Min            994.6639
V Predictions Mean           1499.0709
V Predictions Std            135.34367
V Predictions Max            1725.9753
V Predictions Min            1009.8266
Log Pis Mean                 0.5812944
Log Pis Std                  2.2714357
Log Pis Max                  6.756836
Log Pis Min                  -7.444729
Policy mu Mean               0.003610616
Policy mu Std                0.6231733
Policy mu Max                2.1516078
Policy mu Min                -2.2910082
Policy log std Mean          -1.0661137
Policy log std Std           0.2045464
Policy log std Max           -0.33058417
Policy log std Min           -2.0879807
Z mean eval                  0.88468564
Z variance eval              0.05836014
total_rewards                [1894.30887092 3129.77307893  400.1981261  2930.73592089 3090.84698216
 2147.40424836  750.72091745 2189.48494239 1337.68395347 2171.1915472 ]
total_rewards_mean           2004.2348587875053
total_rewards_std            893.8266546846922
total_rewards_max            3129.773078927155
total_rewards_min            400.19812609901436
Number of train steps total  1936000
Number of env steps total    3664445
Number of rollouts total     0
Train Time (s)               157.25302554573864
(Previous) Eval Time (s)     31.92729904083535
Sample Time (s)              12.531807195860893
Epoch Time (s)               201.71213178243488
Total Train Time (s)         90281.52216790151
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:00:35.409198 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #483 | Epoch Duration: 201.80812239646912
2020-01-13 03:00:35.409483 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8847786
Z variance train             0.05847159
KL Divergence                11.940444
KL Loss                      1.1940445
QF Loss                      429.94937
VF Loss                      118.7641
Policy Loss                  -1357.3978
Q Predictions Mean           1351.5105
Q Predictions Std            178.43466
Q Predictions Max            1577.8124
Q Predictions Min            778.52185
V Predictions Mean           1356.5674
V Predictions Std            180.09094
V Predictions Max            1570.3536
V Predictions Min            768.2548
Log Pis Mean                 0.55510694
Log Pis Std                  2.466086
Log Pis Max                  8.8101635
Log Pis Min                  -6.410637
Policy mu Mean               0.03814994
Policy mu Std                0.6240757
Policy mu Max                1.9363247
Policy mu Min                -2.4548826
Policy log std Mean          -1.071042
Policy log std Std           0.23500696
Policy log std Max           -0.35070145
Policy log std Min           -2.275991
Z mean eval                  1.0720505
Z variance eval              0.33122426
total_rewards                [  55.43864696  418.05529884  543.11427088  119.92608543  573.05963144
  590.31743365 2321.09525235 1968.43653329  849.68157684  786.22853302]
total_rewards_mean           822.5353262696286
total_rewards_std            707.1610199878392
total_rewards_max            2321.0952523456085
total_rewards_min            55.43864696220638
Number of train steps total  1940000
Number of env steps total    3676297
Number of rollouts total     0
Train Time (s)               156.22344792308286
(Previous) Eval Time (s)     17.32925790315494
Sample Time (s)              11.617081863805652
Epoch Time (s)               185.16978769004345
Total Train Time (s)         90466.78213822236
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:03:40.673672 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #484 | Epoch Duration: 185.2640242576599
2020-01-13 03:03:40.673871 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.070938
Z variance train             0.3307286
KL Divergence                10.859671
KL Loss                      1.0859671
QF Loss                      472.09503
VF Loss                      87.05776
Policy Loss                  -1450.0492
Q Predictions Mean           1446.8813
Q Predictions Std            163.25644
Q Predictions Max            1697.912
Q Predictions Min            793.7174
V Predictions Mean           1454.6849
V Predictions Std            163.51389
V Predictions Max            1673.9355
V Predictions Min            797.45
Log Pis Mean                 0.08129963
Log Pis Std                  2.1681275
Log Pis Max                  9.063774
Log Pis Min                  -5.71247
Policy mu Mean               0.031218437
Policy mu Std                0.6076
Policy mu Max                2.4014516
Policy mu Min                -1.9831285
Policy log std Mean          -1.0050879
Policy log std Std           0.19335048
Policy log std Max           -0.26674616
Policy log std Min           -2.0512927
Z mean eval                  0.77631056
Z variance eval              0.16933446
total_rewards                [3182.48979096  323.19765545  601.70560034  526.21808933 3497.51703597
  571.77095553 2913.87087505 1722.03262659  359.51454997 3285.93556783]
total_rewards_mean           1698.4252747016235
total_rewards_std            1302.5889419593213
total_rewards_max            3497.5170359663675
total_rewards_min            323.1976554458289
Number of train steps total  1944000
Number of env steps total    3688686
Number of rollouts total     0
Train Time (s)               157.89984565600753
(Previous) Eval Time (s)     27.19442773377523
Sample Time (s)              12.048894727602601
Epoch Time (s)               197.14316811738536
Total Train Time (s)         90664.0243445728
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:06:57.920786 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #485 | Epoch Duration: 197.24676275253296
2020-01-13 03:06:57.920993 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7748818
Z variance train             0.16926901
KL Divergence                9.857824
KL Loss                      0.98578244
QF Loss                      370.4488
VF Loss                      942.504
Policy Loss                  -1226.5463
Q Predictions Mean           1222.0278
Q Predictions Std            183.9265
Q Predictions Max            1450.9952
Q Predictions Min            43.59958
V Predictions Mean           1224.154
V Predictions Std            172.68806
V Predictions Max            1451.4462
V Predictions Min            535.8017
Log Pis Mean                 0.47056216
Log Pis Std                  2.5539834
Log Pis Max                  8.822739
Log Pis Min                  -9.104761
Policy mu Mean               0.0063110767
Policy mu Std                0.61808413
Policy mu Max                2.4105277
Policy mu Min                -2.0642793
Policy log std Mean          -1.0481054
Policy log std Std           0.23279092
Policy log std Max           -0.22646797
Policy log std Min           -2.4265833
Z mean eval                  0.97461814
Z variance eval              0.14691249
total_rewards                [1553.24655696  289.34914552  818.39273265  829.73978591 1301.73851479
  723.09277037  377.7268719  2158.75918434  725.03476453  820.40450079]
total_rewards_mean           959.7484827769846
total_rewards_std            535.0144994178199
total_rewards_max            2158.7591843444648
total_rewards_min            289.34914552323164
Number of train steps total  1948000
Number of env steps total    3700189
Number of rollouts total     0
Train Time (s)               154.03655574191362
(Previous) Eval Time (s)     16.46603644406423
Sample Time (s)              11.779820902273059
Epoch Time (s)               182.2824130882509
Total Train Time (s)         90846.39790165285
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:10:00.299722 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #486 | Epoch Duration: 182.37858057022095
2020-01-13 03:10:00.299941 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9740728
Z variance train             0.14668079
KL Divergence                10.568987
KL Loss                      1.0568987
QF Loss                      13605.193
VF Loss                      57.09163
Policy Loss                  -1265.0077
Q Predictions Mean           1260.7251
Q Predictions Std            218.32559
Q Predictions Max            1546.1681
Q Predictions Min            467.451
V Predictions Mean           1267.2063
V Predictions Std            218.79762
V Predictions Max            1552.5444
V Predictions Min            464.44064
Log Pis Mean                 0.17483309
Log Pis Std                  2.5611231
Log Pis Max                  6.623026
Log Pis Min                  -8.177667
Policy mu Mean               0.017744936
Policy mu Std                0.62942964
Policy mu Max                2.3577976
Policy mu Min                -2.550344
Policy log std Mean          -1.0117452
Policy log std Std           0.25007394
Policy log std Max           -0.3026806
Policy log std Min           -2.2807155
Z mean eval                  0.9137982
Z variance eval              0.4056898
total_rewards                [3284.46059136 3226.35226826 3514.7731891  3086.76191194 2245.54712459
 3194.36208146 3281.58165539 3384.28413219 3093.17119842 3140.8443202 ]
total_rewards_mean           3145.2138472911497
total_rewards_std            325.00121631847674
total_rewards_max            3514.7731891045887
total_rewards_min            2245.5471245938465
Number of train steps total  1952000
Number of env steps total    3710517
Number of rollouts total     0
Train Time (s)               146.46870141895488
(Previous) Eval Time (s)     35.90183064667508
Sample Time (s)              12.422869224566966
Epoch Time (s)               194.79340129019693
Total Train Time (s)         91041.28845147276
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:13:15.194787 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #487 | Epoch Duration: 194.89470148086548
2020-01-13 03:13:15.194961 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9133965
Z variance train             0.4057835
KL Divergence                9.436678
KL Loss                      0.9436678
QF Loss                      1592.4642
VF Loss                      127.57171
Policy Loss                  -1104.947
Q Predictions Mean           1100.2898
Q Predictions Std            219.00735
Q Predictions Max            1355.1962
Q Predictions Min            172.04335
V Predictions Mean           1105.7231
V Predictions Std            215.6126
V Predictions Max            1356.9199
V Predictions Min            397.6741
Log Pis Mean                 0.19803198
Log Pis Std                  2.5617537
Log Pis Max                  11.562245
Log Pis Min                  -6.8019934
Policy mu Mean               -0.007658816
Policy mu Std                0.5976412
Policy mu Max                3.0493608
Policy mu Min                -2.3360412
Policy log std Mean          -1.0504856
Policy log std Std           0.23447995
Policy log std Max           -0.3715179
Policy log std Min           -2.1943092
Z mean eval                  0.78319144
Z variance eval              0.33449095
total_rewards                [ 975.78531003  403.5556957  3264.4265885  1425.83504647 3121.55906162
 3439.55364161 3305.07617166 3275.3924633  2896.59265945 3316.97977698]
total_rewards_mean           2542.4756415321594
total_rewards_std            1085.4337942908942
total_rewards_max            3439.553641607851
total_rewards_min            403.55569570355726
Number of train steps total  1956000
Number of env steps total    3720643
Number of rollouts total     0
Train Time (s)               147.04821848496795
(Previous) Eval Time (s)     28.137658598367125
Sample Time (s)              11.110798901878297
Epoch Time (s)               186.29667598521337
Total Train Time (s)         91227.67006479204
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:16:21.581272 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #488 | Epoch Duration: 186.3861644268036
2020-01-13 03:16:21.581461 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79240984
Z variance train             0.33480826
KL Divergence                9.263448
KL Loss                      0.9263448
QF Loss                      866.0349
VF Loss                      67.86053
Policy Loss                  -1213.0598
Q Predictions Mean           1205.5325
Q Predictions Std            214.2181
Q Predictions Max            1446.5461
Q Predictions Min            441.66727
V Predictions Mean           1212.346
V Predictions Std            212.1815
V Predictions Max            1453.3553
V Predictions Min            441.08405
Log Pis Mean                 0.30084664
Log Pis Std                  2.5945544
Log Pis Max                  9.118002
Log Pis Min                  -8.220424
Policy mu Mean               0.017102491
Policy mu Std                0.6287512
Policy mu Max                2.8581245
Policy mu Min                -2.1216755
Policy log std Mean          -1.0449991
Policy log std Std           0.23455487
Policy log std Max           -0.2697904
Policy log std Min           -2.2631178
Z mean eval                  0.7719073
Z variance eval              0.115203716
total_rewards                [1825.74080744 1352.04720357  951.02162677   65.39068228  636.97010254
   62.00534905  286.77516228 2775.25341135 1622.66836347 1041.94904149]
total_rewards_mean           1061.9821750236647
total_rewards_std            818.8147104489158
total_rewards_max            2775.253411350576
total_rewards_min            62.00534905307855
Number of train steps total  1960000
Number of env steps total    3731277
Number of rollouts total     0
Train Time (s)               156.2592238667421
(Previous) Eval Time (s)     14.65529271075502
Sample Time (s)              11.405473788734525
Epoch Time (s)               182.31999036623165
Total Train Time (s)         91410.08609912498
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:19:24.002952 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #489 | Epoch Duration: 182.4213309288025
2020-01-13 03:19:24.003236 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77323925
Z variance train             0.115926884
KL Divergence                11.102877
KL Loss                      1.1102877
QF Loss                      702.8611
VF Loss                      66.39022
Policy Loss                  -1229.4756
Q Predictions Mean           1224.6167
Q Predictions Std            285.58395
Q Predictions Max            1519.1298
Q Predictions Min            349.32675
V Predictions Mean           1229.0828
V Predictions Std            285.10065
V Predictions Max            1501.6543
V Predictions Min            350.64655
Log Pis Mean                 0.21299879
Log Pis Std                  2.3978975
Log Pis Max                  8.878485
Log Pis Min                  -5.968558
Policy mu Mean               0.024339492
Policy mu Std                0.58987266
Policy mu Max                2.319182
Policy mu Min                -2.4222422
Policy log std Mean          -1.0408123
Policy log std Std           0.23297267
Policy log std Max           -0.24619997
Policy log std Min           -2.2820582
Z mean eval                  0.80931294
Z variance eval              0.26483506
total_rewards                [2760.9613509  2659.33987167 2479.99607873 3237.76903092 3371.76183579
 1848.31692853  512.03563195  637.64347819 3182.40143228 1508.44598807]
total_rewards_mean           2219.867162702484
total_rewards_std            995.3559160525939
total_rewards_max            3371.7618357889855
total_rewards_min            512.0356319500252
Number of train steps total  1964000
Number of env steps total    3742318
Number of rollouts total     0
Train Time (s)               156.1744965412654
(Previous) Eval Time (s)     28.645975910127163
Sample Time (s)              12.430069982539862
Epoch Time (s)               197.25054243393242
Total Train Time (s)         91607.43752974365
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:22:41.360243 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #490 | Epoch Duration: 197.35682439804077
2020-01-13 03:22:41.360569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8146478
Z variance train             0.26378483
KL Divergence                8.249653
KL Loss                      0.8249653
QF Loss                      338.3971
VF Loss                      142.017
Policy Loss                  -1125.6927
Q Predictions Mean           1119.463
Q Predictions Std            222.02876
Q Predictions Max            1391.247
Q Predictions Min            347.08847
V Predictions Mean           1116.4434
V Predictions Std            222.06879
V Predictions Max            1389.6492
V Predictions Min            343.55875
Log Pis Mean                 0.6099752
Log Pis Std                  2.3823879
Log Pis Max                  8.708969
Log Pis Min                  -5.4163
Policy mu Mean               -0.025924623
Policy mu Std                0.64141214
Policy mu Max                2.0927675
Policy mu Min                -2.7672582
Policy log std Mean          -1.0334961
Policy log std Std           0.22908227
Policy log std Max           -0.33405966
Policy log std Min           -1.839479
Z mean eval                  0.8733013
Z variance eval              0.13095024
total_rewards                [ 308.90379882 1665.63202622 3211.19356801 2933.08157705 1275.88410139
  904.55755295 1943.72852706  265.05634497  712.44919887 1638.34168695]
total_rewards_mean           1485.8828382283123
total_rewards_std            958.7592287434688
total_rewards_max            3211.193568013182
total_rewards_min            265.05634496911335
Number of train steps total  1968000
Number of env steps total    3752827
Number of rollouts total     0
Train Time (s)               155.5984173170291
(Previous) Eval Time (s)     24.541277300100774
Sample Time (s)              13.114550909493119
Epoch Time (s)               193.25424552662298
Total Train Time (s)         91800.80156697286
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:25:54.729749 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #491 | Epoch Duration: 193.3689205646515
2020-01-13 03:25:54.730145 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87180203
Z variance train             0.13089153
KL Divergence                9.914138
KL Loss                      0.9914138
QF Loss                      248.85701
VF Loss                      72.33217
Policy Loss                  -1211.2716
Q Predictions Mean           1209.3444
Q Predictions Std            258.79523
Q Predictions Max            1515.919
Q Predictions Min            363.30432
V Predictions Mean           1209.1125
V Predictions Std            258.14868
V Predictions Max            1507.8699
V Predictions Min            364.617
Log Pis Mean                 0.5213634
Log Pis Std                  2.653518
Log Pis Max                  10.845838
Log Pis Min                  -9.813751
Policy mu Mean               0.047015693
Policy mu Std                0.6068443
Policy mu Max                2.3506968
Policy mu Min                -2.3114407
Policy log std Mean          -1.0436965
Policy log std Std           0.24050844
Policy log std Max           -0.1826666
Policy log std Min           -2.0578675
Z mean eval                  0.8750206
Z variance eval              0.15984781
total_rewards                [1428.65912586  590.89336228 2473.45764977 2539.11065663 1306.81652392
 1445.52319066 3365.46962965 3362.14689675 2121.59747197 3342.80250624]
total_rewards_mean           2197.6477013724125
total_rewards_std            936.0540623255897
total_rewards_max            3365.46962965306
total_rewards_min            590.8933622754644
Number of train steps total  1972000
Number of env steps total    3764418
Number of rollouts total     0
Train Time (s)               156.20857019722462
(Previous) Eval Time (s)     26.470679733902216
Sample Time (s)              13.698197953402996
Epoch Time (s)               196.37744788452983
Total Train Time (s)         91997.26519981446
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:29:11.197753 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #492 | Epoch Duration: 196.46733903884888
2020-01-13 03:29:11.197936 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86604464
Z variance train             0.1617158
KL Divergence                8.841335
KL Loss                      0.8841335
QF Loss                      1123.41
VF Loss                      123.496086
Policy Loss                  -1212.1776
Q Predictions Mean           1208.4171
Q Predictions Std            233.8579
Q Predictions Max            1445.9946
Q Predictions Min            314.41843
V Predictions Mean           1218.8213
V Predictions Std            234.76825
V Predictions Max            1440.0653
V Predictions Min            324.38235
Log Pis Mean                 0.5935321
Log Pis Std                  2.7486844
Log Pis Max                  10.919751
Log Pis Min                  -9.4812565
Policy mu Mean               0.034412302
Policy mu Std                0.6159943
Policy mu Max                3.675852
Policy mu Min                -3.5251398
Policy log std Mean          -1.0775102
Policy log std Std           0.23522589
Policy log std Max           -0.0054041147
Policy log std Min           -2.0246522
Z mean eval                  0.7549162
Z variance eval              0.24231625
total_rewards                [3249.5087859  3248.41450629 3335.2354799   578.32311288 3287.8692738
 3279.15653477 3644.55605672 3396.01560758  351.01018738 3259.39387046]
total_rewards_mean           2762.948341568554
total_rewards_std            1155.7007162286313
total_rewards_max            3644.556056717033
total_rewards_min            351.01018738247194
Number of train steps total  1976000
Number of env steps total    3774568
Number of rollouts total     0
Train Time (s)               151.58570497995242
(Previous) Eval Time (s)     30.57145654084161
Sample Time (s)              10.826602808199823
Epoch Time (s)               192.98376432899386
Total Train Time (s)         92190.33616726892
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:32:24.273225 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #493 | Epoch Duration: 193.07514548301697
2020-01-13 03:32:24.273418 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75748026
Z variance train             0.24209991
KL Divergence                7.978837
KL Loss                      0.7978837
QF Loss                      313.72046
VF Loss                      58.540302
Policy Loss                  -1198.1495
Q Predictions Mean           1191.5188
Q Predictions Std            235.41492
Q Predictions Max            1429.8146
Q Predictions Min            313.37994
V Predictions Mean           1200.7
V Predictions Std            236.63637
V Predictions Max            1427.6719
V Predictions Min            304.8554
Log Pis Mean                 0.3162272
Log Pis Std                  2.5864444
Log Pis Max                  8.876523
Log Pis Min                  -9.164942
Policy mu Mean               0.055672877
Policy mu Std                0.6175199
Policy mu Max                2.4924994
Policy mu Min                -2.2099724
Policy log std Mean          -1.0488988
Policy log std Std           0.22904898
Policy log std Max           -0.28621984
Policy log std Min           -2.2382379
Z mean eval                  0.737934
Z variance eval              0.16595066
total_rewards                [3442.50093384   56.78375081 3306.49187713 3286.51438232 1553.82031789
 3433.98107717 1697.7687779  2360.33522628  254.16029353 3359.90946   ]
total_rewards_mean           2275.2266096882477
total_rewards_std            1258.3844799887768
total_rewards_max            3442.500933841198
total_rewards_min            56.78375080832636
Number of train steps total  1980000
Number of env steps total    3785475
Number of rollouts total     0
Train Time (s)               147.2775862440467
(Previous) Eval Time (s)     26.31016763485968
Sample Time (s)              12.583026391919702
Epoch Time (s)               186.17078027082607
Total Train Time (s)         92376.60488932068
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:35:30.546937 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #494 | Epoch Duration: 186.2733714580536
2020-01-13 03:35:30.547143 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7401204
Z variance train             0.16697687
KL Divergence                8.509519
KL Loss                      0.85095185
QF Loss                      309.35242
VF Loss                      146.13654
Policy Loss                  -1160.943
Q Predictions Mean           1157.1512
Q Predictions Std            289.73187
Q Predictions Max            1454.701
Q Predictions Min            22.846712
V Predictions Mean           1161.4801
V Predictions Std            292.92697
V Predictions Max            1445.3857
V Predictions Min            11.570965
Log Pis Mean                 0.04908684
Log Pis Std                  2.7851067
Log Pis Max                  9.927481
Log Pis Min                  -7.956107
Policy mu Mean               0.008682311
Policy mu Std                0.61373824
Policy mu Max                2.1750782
Policy mu Min                -2.488887
Policy log std Mean          -1.0162327
Policy log std Std           0.24393865
Policy log std Max           -0.20714766
Policy log std Min           -2.677575
Z mean eval                  0.6808321
Z variance eval              0.21811633
total_rewards                [  87.5905694   794.05419582 1114.87516796 3176.4654041  3272.53574333
  136.58108066 2335.95156166 1636.92117076  141.37540401 2151.18770072]
total_rewards_mean           1484.75379984143
total_rewards_std            1159.2262740784663
total_rewards_max            3272.535743327403
total_rewards_min            87.59056940494125
Number of train steps total  1984000
Number of env steps total    3797524
Number of rollouts total     0
Train Time (s)               150.39080640021712
(Previous) Eval Time (s)     21.100904310587794
Sample Time (s)              11.30593330739066
Epoch Time (s)               182.79764401819557
Total Train Time (s)         92559.48826488154
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:38:33.435077 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #495 | Epoch Duration: 182.8877625465393
2020-01-13 03:38:33.435285 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67667615
Z variance train             0.22213677
KL Divergence                7.899561
KL Loss                      0.7899561
QF Loss                      11523.546
VF Loss                      43.852554
Policy Loss                  -1138.7397
Q Predictions Mean           1133.7496
Q Predictions Std            300.68356
Q Predictions Max            1443.4652
Q Predictions Min            278.4529
V Predictions Mean           1138.2054
V Predictions Std            301.21188
V Predictions Max            1437.2173
V Predictions Min            262.88712
Log Pis Mean                 0.28486758
Log Pis Std                  2.6931634
Log Pis Max                  8.027833
Log Pis Min                  -8.627378
Policy mu Mean               0.034481607
Policy mu Std                0.6148598
Policy mu Max                1.9771924
Policy mu Min                -2.2534592
Policy log std Mean          -1.0274484
Policy log std Std           0.25198781
Policy log std Max           -0.07892692
Policy log std Min           -2.0000036
Z mean eval                  0.677036
Z variance eval              0.21725643
total_rewards                [2303.09797975 1362.20050355 1248.27776517 1863.82754982  544.47613287
  235.87013185 3558.53796102 2845.04244045  620.3250398  2042.22927483]
total_rewards_mean           1662.3884779105356
total_rewards_std            1011.019187162384
total_rewards_max            3558.5379610195932
total_rewards_min            235.8701318522575
Number of train steps total  1988000
Number of env steps total    3808433
Number of rollouts total     0
Train Time (s)               157.78421488637105
(Previous) Eval Time (s)     18.097000695299357
Sample Time (s)              11.915323622524738
Epoch Time (s)               187.79653920419514
Total Train Time (s)         92747.37358478596
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:41:41.325714 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #496 | Epoch Duration: 187.89027667045593
2020-01-13 03:41:41.325927 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67169034
Z variance train             0.21702206
KL Divergence                7.6998463
KL Loss                      0.76998466
QF Loss                      884.56555
VF Loss                      158.0368
Policy Loss                  -1188.5665
Q Predictions Mean           1185.4739
Q Predictions Std            257.21143
Q Predictions Max            1458.9612
Q Predictions Min            239.10762
V Predictions Mean           1191.2258
V Predictions Std            257.36273
V Predictions Max            1450.0658
V Predictions Min            248.8356
Log Pis Mean                 0.57877576
Log Pis Std                  2.5923944
Log Pis Max                  7.4365907
Log Pis Min                  -5.696145
Policy mu Mean               -0.024243403
Policy mu Std                0.63060427
Policy mu Max                2.4070437
Policy mu Min                -2.081682
Policy log std Mean          -1.043837
Policy log std Std           0.23665667
Policy log std Max           -0.19883835
Policy log std Min           -1.9593438
Z mean eval                  0.7500289
Z variance eval              0.12948295
total_rewards                [1289.03914117 2903.76120099 2251.25307374  727.90907256  533.58905341
  227.51235262  869.25459569  757.22384785 3152.00605949  790.50557443]
total_rewards_mean           1350.205397194988
total_rewards_std            984.1955503001486
total_rewards_max            3152.0060594866018
total_rewards_min            227.51235262122918
Number of train steps total  1992000
Number of env steps total    3819106
Number of rollouts total     0
Train Time (s)               157.90452619222924
(Previous) Eval Time (s)     21.393290624022484
Sample Time (s)              11.366341033019125
Epoch Time (s)               190.66415784927085
Total Train Time (s)         92938.13063910557
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:44:52.087589 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #497 | Epoch Duration: 190.7615053653717
2020-01-13 03:44:52.087801 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7501462
Z variance train             0.12984902
KL Divergence                8.30725
KL Loss                      0.830725
QF Loss                      352.8753
VF Loss                      48.423634
Policy Loss                  -1155.3792
Q Predictions Mean           1149.897
Q Predictions Std            255.63521
Q Predictions Max            1402.4197
Q Predictions Min            294.16083
V Predictions Mean           1155.3538
V Predictions Std            255.64458
V Predictions Max            1411.9086
V Predictions Min            295.80566
Log Pis Mean                 0.32520798
Log Pis Std                  2.6786482
Log Pis Max                  17.53635
Log Pis Min                  -5.3240356
Policy mu Mean               -0.0006571533
Policy mu Std                0.616159
Policy mu Max                2.2597363
Policy mu Min                -2.5909846
Policy log std Mean          -1.0424864
Policy log std Std           0.25918207
Policy log std Max           -0.30778182
Policy log std Min           -2.5973296
Z mean eval                  0.7226556
Z variance eval              0.28818575
total_rewards                [ 958.28950923 2022.85575265  769.52603031 3362.09023382 3454.93285095
 2255.92504817 1544.68696848 2457.81229944 3309.15053342  209.02063446]
total_rewards_mean           2034.4289860934678
total_rewards_std            1093.796008062887
total_rewards_max            3454.9328509539755
total_rewards_min            209.02063445900802
Number of train steps total  1996000
Number of env steps total    3830506
Number of rollouts total     0
Train Time (s)               158.59571590879932
(Previous) Eval Time (s)     26.91185570694506
Sample Time (s)              13.276686748024076
Epoch Time (s)               198.78425836376846
Total Train Time (s)         93137.0171995163
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:48:10.979541 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #498 | Epoch Duration: 198.89156031608582
2020-01-13 03:48:10.979840 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7199866
Z variance train             0.28788155
KL Divergence                6.7552
KL Loss                      0.67552
QF Loss                      446.31073
VF Loss                      283.17218
Policy Loss                  -1141.0815
Q Predictions Mean           1135.9098
Q Predictions Std            262.05185
Q Predictions Max            1414.523
Q Predictions Min            284.95105
V Predictions Mean           1141.9662
V Predictions Std            261.2735
V Predictions Max            1415.5896
V Predictions Min            277.36514
Log Pis Mean                 0.33774906
Log Pis Std                  2.6714911
Log Pis Max                  13.973667
Log Pis Min                  -6.3091288
Policy mu Mean               -0.0022649793
Policy mu Std                0.62326884
Policy mu Max                2.7160196
Policy mu Min                -2.378961
Policy log std Mean          -1.0448613
Policy log std Std           0.25916636
Policy log std Max           -0.31769818
Policy log std Min           -2.0741653
Z mean eval                  0.7024981
Z variance eval              0.25757602
total_rewards                [3491.18713374  277.72841342 3288.06231464  135.75356385 3367.19677197
 2227.97359049 2242.99783041  152.56801931  697.45901591  462.04328889]
total_rewards_mean           1634.2969942628865
total_rewards_std            1358.0193887924224
total_rewards_max            3491.187133735996
total_rewards_min            135.7535638545575
Number of train steps total  2000000
Number of env steps total    3841391
Number of rollouts total     0
Train Time (s)               155.48280394962057
(Previous) Eval Time (s)     22.30032926471904
Sample Time (s)              9.39986155508086
Epoch Time (s)               187.18299476942047
Total Train Time (s)         93324.29207923869
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:51:18.259151 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #499 | Epoch Duration: 187.27912163734436
2020-01-13 03:51:18.259437 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #499 | Started Training: True
2020-01-13 03:51:19.251262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Variant:
2020-01-13 03:51:19.251827 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20_seed56",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015107745
Z variance train             0.69259006
KL Divergence                0.14977556
KL Loss                      0.014977557
QF Loss                      46.331024
VF Loss                      16.467674
Policy Loss                  -4.023477
Q Predictions Mean           0.0041415626
Q Predictions Std            0.0027838328
Q Predictions Max            0.0146425795
Q Predictions Min            -0.0018293844
V Predictions Mean           0.004016267
V Predictions Std            0.0015991185
V Predictions Max            0.008371308
V Predictions Min            1.0664808e-05
Log Pis Mean                 -4.0536647
Log Pis Std                  0.55837053
Log Pis Max                  -2.2691817
Log Pis Min                  -5.739599
Policy mu Mean               -0.0007698768
Policy mu Std                0.0014816081
Policy mu Max                0.0040149908
Policy mu Min                -0.004992895
Policy log std Mean          0.00074010243
Policy log std Std           0.0011658955
Policy log std Max           0.004144796
Policy log std Min           -0.003478533
Z mean eval                  1.0256958
Z variance eval              0.03827204
total_rewards                [-142.90677729 -123.32252894 -150.12502523 -139.04942806 -156.42701259
 -139.444603   -125.99907129 -162.8277051  -123.53700147 -135.88975397]
total_rewards_mean           -139.9528906953836
total_rewards_std            12.904242331790373
total_rewards_max            -123.32252894442762
total_rewards_min            -162.82770510292605
Number of train steps total  4000
Number of env steps total    14000
Number of rollouts total     0
Train Time (s)               135.1696987678297
(Previous) Eval Time (s)     0
Sample Time (s)              20.58117772405967
Epoch Time (s)               155.75087649188936
Total Train Time (s)         184.57353916717693
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:54:23.920438 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #0 | Epoch Duration: 184.57739162445068
2020-01-13 03:54:23.920696 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0417631
Z variance train             0.03664141
KL Divergence                10.514332
KL Loss                      1.0514332
QF Loss                      59.857693
VF Loss                      9.289874
Policy Loss                  -48.22554
Q Predictions Mean           42.48163
Q Predictions Std            18.279009
Q Predictions Max            93.997505
Q Predictions Min            -11.66238
V Predictions Mean           48.38044
V Predictions Std            17.458164
V Predictions Max            98.38198
V Predictions Min            6.0290623
Log Pis Mean                 -3.4644556
Log Pis Std                  1.0639559
Log Pis Max                  -0.09244096
Log Pis Min                  -7.9761
Policy mu Mean               0.02983544
Policy mu Std                0.3474364
Policy mu Max                1.42376
Policy mu Min                -1.597566
Policy log std Mean          -0.30943048
Policy log std Std           0.069340155
Policy log std Max           -0.14784056
Policy log std Min           -0.54502374
Z mean eval                  1.2237481
Z variance eval              0.025730107
total_rewards                [-104.45898172 -104.31502126 -165.65707366 -135.52606683  -98.11510974
 -107.03961969  -99.79397038 -124.32233853 -130.99353185 -129.61461923]
total_rewards_mean           -119.98363328863495
total_rewards_std            20.249323503762618
total_rewards_max            -98.11510973767759
total_rewards_min            -165.65707365923572
Number of train steps total  8000
Number of env steps total    26000
Number of rollouts total     0
Train Time (s)               135.3266730220057
(Previous) Eval Time (s)     29.190223225858063
Sample Time (s)              9.898626110050827
Epoch Time (s)               174.4155223579146
Total Train Time (s)         359.07478751055896
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:57:18.422445 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #1 | Epoch Duration: 174.50158095359802
2020-01-13 03:57:18.422634 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2211206
Z variance train             0.025687436
KL Divergence                13.108749
KL Loss                      1.3108749
QF Loss                      73.985794
VF Loss                      10.430853
Policy Loss                  -95.1689
Q Predictions Mean           87.944305
Q Predictions Std            32.02994
Q Predictions Max            180.71939
Q Predictions Min            38.674313
V Predictions Mean           95.37352
V Predictions Std            30.76746
V Predictions Max            183.48087
V Predictions Min            45.207077
Log Pis Mean                 -3.3032477
Log Pis Std                  1.3092169
Log Pis Max                  0.22357267
Log Pis Min                  -7.995988
Policy mu Mean               0.003072439
Policy mu Std                0.42127132
Policy mu Max                1.5579543
Policy mu Min                -1.3545934
Policy log std Mean          -0.33296305
Policy log std Std           0.07548411
Policy log std Max           -0.16987516
Policy log std Min           -0.6580149
Z mean eval                  1.3173906
Z variance eval              0.025655767
total_rewards                [-28.52697784   7.81355156 -13.60704546 -55.864784   -51.99874588
 -67.28123797 -40.09576258 -41.08447268 -44.31871717 -29.26379325]
total_rewards_mean           -36.42279852827694
total_rewards_std            20.643207646122434
total_rewards_max            7.8135515570331044
total_rewards_min            -67.28123796623257
Number of train steps total  12000
Number of env steps total    38000
Number of rollouts total     0
Train Time (s)               139.58098481502384
(Previous) Eval Time (s)     28.24533577496186
Sample Time (s)              9.881705069448799
Epoch Time (s)               177.7080256594345
Total Train Time (s)         536.9230066128075
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:00:16.272219 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #2 | Epoch Duration: 177.84943437576294
2020-01-13 04:00:16.272447 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3127165
Z variance train             0.025629496
KL Divergence                14.6262
KL Loss                      1.46262
QF Loss                      73.100204
VF Loss                      19.786041
Policy Loss                  -128.82664
Q Predictions Mean           125.66351
Q Predictions Std            38.509205
Q Predictions Max            240.32428
Q Predictions Min            54.57587
V Predictions Mean           130.3121
V Predictions Std            38.382797
V Predictions Max            234.53748
V Predictions Min            55.123665
Log Pis Mean                 -3.1382446
Log Pis Std                  1.5086672
Log Pis Max                  5.7533703
Log Pis Min                  -7.577321
Policy mu Mean               0.005984696
Policy mu Std                0.43812537
Policy mu Max                1.716581
Policy mu Min                -1.3873512
Policy log std Mean          -0.33384976
Policy log std Std           0.0807139
Policy log std Max           -0.16063413
Policy log std Min           -0.67838037
Z mean eval                  1.3755088
Z variance eval              0.024776427
total_rewards                [ 19.15571105 189.16534856 -18.70612017  45.78703285  77.18448995
  12.39832166  67.83417428 182.02533129  75.58477946 175.31687172]
total_rewards_mean           82.57459406458139
total_rewards_std            71.20823724536663
total_rewards_max            189.16534855720215
total_rewards_min            -18.706120167639643
Number of train steps total  16000
Number of env steps total    50000
Number of rollouts total     0
Train Time (s)               144.92921394202858
(Previous) Eval Time (s)     29.649947706144303
Sample Time (s)              10.334115873090923
Epoch Time (s)               184.9132775212638
Total Train Time (s)         721.9183142436668
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:03:21.269201 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #3 | Epoch Duration: 184.9965717792511
2020-01-13 04:03:21.269501 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3716915
Z variance train             0.024731299
KL Divergence                16.90746
KL Loss                      1.690746
QF Loss                      169.8247
VF Loss                      23.795696
Policy Loss                  -150.97406
Q Predictions Mean           148.77383
Q Predictions Std            48.9284
Q Predictions Max            296.14877
Q Predictions Min            61.08474
V Predictions Mean           154.15846
V Predictions Std            49.035534
V Predictions Max            298.77774
V Predictions Min            66.32259
Log Pis Mean                 -3.120642
Log Pis Std                  1.424811
Log Pis Max                  1.5427815
Log Pis Min                  -6.905998
Policy mu Mean               -0.022883518
Policy mu Std                0.41397294
Policy mu Max                1.7168179
Policy mu Min                -1.530792
Policy log std Mean          -0.32380208
Policy log std Std           0.07896493
Policy log std Max           -0.15063521
Policy log std Min           -0.7356856
Z mean eval                  1.3836472
Z variance eval              0.029779803
total_rewards                [ 855.65517241 1137.63770659  447.68830521  158.83821378  973.82622981
  936.94782396 1025.05641371 1062.98334437  634.16871113  982.18773725]
total_rewards_mean           821.4989658221618
total_rewards_std            296.1688558234679
total_rewards_max            1137.6377065864108
total_rewards_min            158.83821378237644
Number of train steps total  20000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               143.4624906051904
(Previous) Eval Time (s)     30.030264096334577
Sample Time (s)              10.409957405179739
Epoch Time (s)               183.9027121067047
Total Train Time (s)         905.9051445052028
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:06:25.260349 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #4 | Epoch Duration: 183.9906153678894
2020-01-13 04:06:25.260628 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3828983
Z variance train             0.029681295
KL Divergence                15.695513
KL Loss                      1.5695513
QF Loss                      83.09689
VF Loss                      11.161845
Policy Loss                  -183.80461
Q Predictions Mean           176.54773
Q Predictions Std            60.430542
Q Predictions Max            328.97162
Q Predictions Min            61.44467
V Predictions Mean           183.47455
V Predictions Std            60.534115
V Predictions Max            332.15182
V Predictions Min            79.200066
Log Pis Mean                 -3.1222565
Log Pis Std                  1.457507
Log Pis Max                  3.825158
Log Pis Min                  -8.374736
Policy mu Mean               0.016841358
Policy mu Std                0.45043907
Policy mu Max                2.0616362
Policy mu Min                -1.9694142
Policy log std Mean          -0.33246216
Policy log std Std           0.087583154
Policy log std Max           -0.08212168
Policy log std Min           -0.7211883
Z mean eval                  1.4370174
Z variance eval              0.062488187
total_rewards                [ 640.77661363  274.76512936  445.97975978 1743.79431477 1698.25846607
 1432.87023876 1684.44298758 1335.63260216  451.48972859 1649.5760709 ]
total_rewards_mean           1135.7585911597635
total_rewards_std            575.3031447053886
total_rewards_max            1743.7943147709348
total_rewards_min            274.76512935929225
Number of train steps total  24000
Number of env steps total    74000
Number of rollouts total     0
Train Time (s)               144.5262325843796
(Previous) Eval Time (s)     31.06749932700768
Sample Time (s)              9.794116429518908
Epoch Time (s)               185.3878483409062
Total Train Time (s)         1091.379744711332
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:09:30.733965 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #5 | Epoch Duration: 185.473149061203
2020-01-13 04:09:30.734171 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4394903
Z variance train             0.06280731
KL Divergence                14.83344
KL Loss                      1.483344
QF Loss                      96.6248
VF Loss                      16.07418
Policy Loss                  -226.1052
Q Predictions Mean           220.7142
Q Predictions Std            80.07861
Q Predictions Max            451.52295
Q Predictions Min            88.428345
V Predictions Mean           225.49138
V Predictions Std            80.52923
V Predictions Max            435.49176
V Predictions Min            100.400764
Log Pis Mean                 -2.9268596
Log Pis Std                  1.6014009
Log Pis Max                  2.9643326
Log Pis Min                  -6.443238
Policy mu Mean               -0.042586714
Policy mu Std                0.48837912
Policy mu Max                1.7946221
Policy mu Min                -1.5977334
Policy log std Mean          -0.34433648
Policy log std Std           0.094233155
Policy log std Max           -0.17555693
Policy log std Min           -0.91650814
Z mean eval                  1.5428356
Z variance eval              0.049679853
total_rewards                [2011.19290184 2190.53213608 1779.9249671  2009.54261371 2043.77655428
  715.27618903 1975.0241682  1929.5674816  2180.86329292 2101.47701225]
total_rewards_mean           1893.7177317012042
total_rewards_std            409.0254216699854
total_rewards_max            2190.53213607915
total_rewards_min            715.2761890251838
Number of train steps total  28000
Number of env steps total    86000
Number of rollouts total     0
Train Time (s)               143.76087479991838
(Previous) Eval Time (s)     29.776785694994032
Sample Time (s)              9.69826276646927
Epoch Time (s)               183.23592326138169
Total Train Time (s)         1274.7033358654007
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:12:34.058867 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #6 | Epoch Duration: 183.3245232105255
2020-01-13 04:12:34.059131 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #6 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5420594
Z variance train             0.04967355
KL Divergence                16.659971
KL Loss                      1.6659971
QF Loss                      315.93787
VF Loss                      23.249805
Policy Loss                  -242.95569
Q Predictions Mean           239.06415
Q Predictions Std            98.799095
Q Predictions Max            528.3048
Q Predictions Min            115.899574
V Predictions Mean           243.40158
V Predictions Std            99.13904
V Predictions Max            526.9321
V Predictions Min            115.15481
Log Pis Mean                 -2.5185337
Log Pis Std                  1.8782654
Log Pis Max                  5.2011137
Log Pis Min                  -6.962307
Policy mu Mean               -0.015966164
Policy mu Std                0.52780694
Policy mu Max                2.0171916
Policy mu Min                -1.9548225
Policy log std Mean          -0.35512245
Policy log std Std           0.10895775
Policy log std Max           -0.09002298
Policy log std Min           -1.02182
Z mean eval                  1.6425301
Z variance eval              0.034885477
total_rewards                [2400.00136015 2401.43390219 2619.59700887 2519.51685132 2422.7933659
 2453.35009662 2503.96227283 2491.5622501  2445.75059411 2574.99173896]
total_rewards_mean           2483.2959441054
total_rewards_std            69.56998836279563
total_rewards_max            2619.597008869601
total_rewards_min            2400.001360150706
Number of train steps total  32000
Number of env steps total    98000
Number of rollouts total     0
Train Time (s)               135.1293052448891
(Previous) Eval Time (s)     29.148590783122927
Sample Time (s)              9.782862472813576
Epoch Time (s)               174.0607585008256
Total Train Time (s)         1448.8738327701576
Epoch                        7
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:15:28.230421 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #7 | Epoch Duration: 174.1710877418518
2020-01-13 04:15:28.230647 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6445417
Z variance train             0.034927085
KL Divergence                18.042824
KL Loss                      1.8042824
QF Loss                      127.019295
VF Loss                      36.175797
Policy Loss                  -303.01776
Q Predictions Mean           294.76462
Q Predictions Std            129.2916
Q Predictions Max            687.1975
Q Predictions Min            129.34276
V Predictions Mean           301.51675
V Predictions Std            130.08394
V Predictions Max            684.4927
V Predictions Min            129.86626
Log Pis Mean                 -2.163064
Log Pis Std                  2.2145302
Log Pis Max                  5.4016247
Log Pis Min                  -5.916836
Policy mu Mean               -0.043593224
Policy mu Std                0.62046224
Policy mu Max                2.062754
Policy mu Min                -2.3176289
Policy log std Mean          -0.39098796
Policy log std Std           0.14314833
Policy log std Max           -0.14937966
Policy log std Min           -1.2775968
Z mean eval                  1.7445408
Z variance eval              0.05919212
total_rewards                [2843.10600668 2663.96139459 2840.73505958 2649.92767026 2774.23326425
 2902.13440623 2738.78058471 2824.48279761 2761.5133004  2836.26318204]
total_rewards_mean           2783.513766635337
total_rewards_std            77.50261318897893
total_rewards_max            2902.1344062275057
total_rewards_min            2649.927670261687
Number of train steps total  36000
Number of env steps total    110000
Number of rollouts total     0
Train Time (s)               136.02701795333996
(Previous) Eval Time (s)     29.46350857615471
Sample Time (s)              9.812893980648369
Epoch Time (s)               175.30342051014304
Total Train Time (s)         1624.2626554192975
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:18:23.621125 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #8 | Epoch Duration: 175.39025211334229
2020-01-13 04:18:23.621390 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7468193
Z variance train             0.05931946
KL Divergence                19.001722
KL Loss                      1.9001722
QF Loss                      164.75446
VF Loss                      34.524612
Policy Loss                  -316.3597
Q Predictions Mean           310.58667
Q Predictions Std            156.90396
Q Predictions Max            756.94995
Q Predictions Min            130.48213
V Predictions Mean           315.16348
V Predictions Std            155.79672
V Predictions Max            745.4276
V Predictions Min            136.95897
Log Pis Mean                 -2.294313
Log Pis Std                  2.4314578
Log Pis Max                  5.8937774
Log Pis Min                  -8.309108
Policy mu Mean               0.030981028
Policy mu Std                0.63284576
Policy mu Max                2.2234957
Policy mu Min                -2.4730527
Policy log std Mean          -0.38885424
Policy log std Std           0.1527178
Policy log std Max           -0.1300377
Policy log std Min           -1.6185329
Z mean eval                  1.9087309
Z variance eval              0.034889363
total_rewards                [ 586.12702516 2834.0862094  1788.2150089  2952.38149097 2771.43316973
 2993.49088716 3123.57567697 2751.48458213 2942.05174323 2941.78253465]
total_rewards_mean           2568.4628328288804
total_rewards_std            748.252667496856
total_rewards_max            3123.5756769682516
total_rewards_min            586.1270251635506
Number of train steps total  40000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               139.33203822607175
(Previous) Eval Time (s)     30.45475267106667
Sample Time (s)              9.741734382230788
Epoch Time (s)               179.5285252793692
Total Train Time (s)         1803.8814905546606
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:21:23.240531 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #9 | Epoch Duration: 179.6189534664154
2020-01-13 04:21:23.240765 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #9 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9109049
Z variance train             0.034960017
KL Divergence                22.360939
KL Loss                      2.236094
QF Loss                      218.84306
VF Loss                      31.833996
Policy Loss                  -381.51318
Q Predictions Mean           372.70822
Q Predictions Std            209.43826
Q Predictions Max            942.408
Q Predictions Min            136.9262
V Predictions Mean           379.15616
V Predictions Std            210.68253
V Predictions Max            941.18915
V Predictions Min            136.1458
Log Pis Mean                 -2.0302649
Log Pis Std                  2.654279
Log Pis Max                  6.3034534
Log Pis Min                  -7.7427616
Policy mu Mean               -0.056155074
Policy mu Std                0.65981376
Policy mu Max                2.0682673
Policy mu Min                -2.2433944
Policy log std Mean          -0.3962377
Policy log std Std           0.17061424
Policy log std Max           -0.16713831
Policy log std Min           -1.582621
Z mean eval                  2.0370061
Z variance eval              0.030260349
total_rewards                [3216.49864318 3373.03997529 3283.97297142 3160.68967044 3139.9842226
 3360.30436792 3367.34085274 3292.21871131 3376.02412653 3216.8702292 ]
total_rewards_mean           3278.6943770629587
total_rewards_std            85.99969987061766
total_rewards_max            3376.024126530642
total_rewards_min            3139.9842226032274
Number of train steps total  44000
Number of env steps total    134000
Number of rollouts total     0
Train Time (s)               145.5234956261702
(Previous) Eval Time (s)     30.005542759317905
Sample Time (s)              10.507124262861907
Epoch Time (s)               186.03616264835
Total Train Time (s)         1990.0095025063492
Epoch                        10
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:24:29.370704 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #10 | Epoch Duration: 186.12975978851318
2020-01-13 04:24:29.371029 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0360026
Z variance train             0.030228361
KL Divergence                25.421942
KL Loss                      2.5421941
QF Loss                      167.70357
VF Loss                      47.110382
Policy Loss                  -459.5985
Q Predictions Mean           451.8736
Q Predictions Std            257.75766
Q Predictions Max            1015.97626
Q Predictions Min            139.42593
V Predictions Mean           459.86664
V Predictions Std            256.99426
V Predictions Max            1007.1075
V Predictions Min            145.88136
Log Pis Mean                 -1.640378
Log Pis Std                  2.6879005
Log Pis Max                  6.6033874
Log Pis Min                  -6.999361
Policy mu Mean               -0.010499154
Policy mu Std                0.73554885
Policy mu Max                2.67506
Policy mu Min                -2.0956612
Policy log std Mean          -0.41938755
Policy log std Std           0.16956227
Policy log std Max           -0.14304288
Policy log std Min           -1.5932713
Z mean eval                  2.088719
Z variance eval              0.0333396
total_rewards                [3303.02192321 3207.89683964 3417.45803637 3255.30739892 3264.02272269
 3391.1786908   551.89985266 1944.87918999 3690.95178193 3259.29370947]
total_rewards_mean           2928.591014569056
total_rewards_std            905.3924366830859
total_rewards_max            3690.9517819316848
total_rewards_min            551.8998526588961
Number of train steps total  48000
Number of env steps total    146000
Number of rollouts total     0
Train Time (s)               144.48169105360284
(Previous) Eval Time (s)     27.671779538039118
Sample Time (s)              10.016145713627338
Epoch Time (s)               182.1696163052693
Total Train Time (s)         2172.2632115068845
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:27:31.624945 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #11 | Epoch Duration: 182.25357055664062
2020-01-13 04:27:31.625155 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.085892
Z variance train             0.033216156
KL Divergence                26.090431
KL Loss                      2.6090431
QF Loss                      291.6256
VF Loss                      61.000023
Policy Loss                  -512.66785
Q Predictions Mean           502.23526
Q Predictions Std            293.34406
Q Predictions Max            1108.88
Q Predictions Min            125.631645
V Predictions Mean           515.7207
V Predictions Std            296.8542
V Predictions Max            1129.8606
V Predictions Min            143.65698
Log Pis Mean                 -1.6002401
Log Pis Std                  2.7057092
Log Pis Max                  8.177647
Log Pis Min                  -7.414344
Policy mu Mean               -0.035372917
Policy mu Std                0.7033298
Policy mu Max                2.3424191
Policy mu Min                -2.2803743
Policy log std Mean          -0.428413
Policy log std Std           0.18532293
Policy log std Max           -0.15736386
Policy log std Min           -1.5418373
Z mean eval                  2.1781394
Z variance eval              0.0333805
total_rewards                [3627.15393226 3399.63803219 3700.7953177  3535.39134297 3622.10569688
 3687.80604704 3440.6597011  3754.21643921 3456.04171341 3532.17264194]
total_rewards_mean           3575.598086470981
total_rewards_std            114.87246774667308
total_rewards_max            3754.216439209252
total_rewards_min            3399.6380321917113
Number of train steps total  52000
Number of env steps total    158000
Number of rollouts total     0
Train Time (s)               144.84725447325036
(Previous) Eval Time (s)     30.07397956121713
Sample Time (s)              10.296244546305388
Epoch Time (s)               185.21747858077288
Total Train Time (s)         2357.5684253107756
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:30:36.931073 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #12 | Epoch Duration: 185.3057701587677
2020-01-13 04:30:36.931301 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #12 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1762526
Z variance train             0.033425134
KL Divergence                26.009548
KL Loss                      2.6009548
QF Loss                      600.0072
VF Loss                      86.35329
Policy Loss                  -530.9685
Q Predictions Mean           520.9466
Q Predictions Std            334.75516
Q Predictions Max            1230.6084
Q Predictions Min            140.67706
V Predictions Mean           536.80414
V Predictions Std            337.49582
V Predictions Max            1242.9822
V Predictions Min            152.92342
Log Pis Mean                 -1.5598468
Log Pis Std                  2.7517388
Log Pis Max                  8.482935
Log Pis Min                  -7.192613
Policy mu Mean               -0.0748916
Policy mu Std                0.72596675
Policy mu Max                2.3527985
Policy mu Min                -2.5379438
Policy log std Mean          -0.41959366
Policy log std Std           0.16837575
Policy log std Max           -0.15485859
Policy log std Min           -1.6184722
Z mean eval                  2.124622
Z variance eval              0.031225126
total_rewards                [3636.07098698 3631.87323206 3712.94370525 3962.13065355 3854.13157805
 3787.21512846 3914.40001626 3848.3629897  3750.78059012  355.64823078]
total_rewards_mean           3445.3557111209075
total_rewards_std            1035.170538894677
total_rewards_max            3962.1306535527833
total_rewards_min            355.6482307794189
Number of train steps total  56000
Number of env steps total    170000
Number of rollouts total     0
Train Time (s)               143.527571155224
(Previous) Eval Time (s)     30.46967876702547
Sample Time (s)              9.137081005610526
Epoch Time (s)               183.13433092786
Total Train Time (s)         2540.7812796384096
Epoch                        13
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:33:40.145214 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #13 | Epoch Duration: 183.21377205848694
2020-01-13 04:33:40.145393 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.227717
Z variance train             0.02874679
KL Divergence                26.188766
KL Loss                      2.6188767
QF Loss                      780.8178
VF Loss                      100.7383
Policy Loss                  -550.42816
Q Predictions Mean           542.33215
Q Predictions Std            360.23068
Q Predictions Max            1297.1665
Q Predictions Min            119.03455
V Predictions Mean           553.9824
V Predictions Std            363.2006
V Predictions Max            1303.0824
V Predictions Min            136.49727
Log Pis Mean                 -1.647366
Log Pis Std                  2.7591066
Log Pis Max                  7.939071
Log Pis Min                  -6.227255
Policy mu Mean               -0.036202524
Policy mu Std                0.70289916
Policy mu Max                2.2701442
Policy mu Min                -2.6456738
Policy log std Mean          -0.4306701
Policy log std Std           0.19197294
Policy log std Max           -0.1047246
Policy log std Min           -1.5626104
Z mean eval                  2.0834286
Z variance eval              0.04036904
total_rewards                [3912.31956699 3836.22063694 3763.45249836 3860.83554306 4003.50926297
 4106.80825461 3982.96969358 3814.56330703 4201.70617097 4007.36768032]
total_rewards_mean           3948.9752614833646
total_rewards_std            130.62715798580794
total_rewards_max            4201.706170973098
total_rewards_min            3763.4524983627116
Number of train steps total  60000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               136.17868360690773
(Previous) Eval Time (s)     29.47298334678635
Sample Time (s)              9.46779740601778
Epoch Time (s)               175.11946435971186
Total Train Time (s)         2715.978063723538
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:36:35.343209 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #14 | Epoch Duration: 175.19766283035278
2020-01-13 04:36:35.343394 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0812023
Z variance train             0.04005206
KL Divergence                24.159883
KL Loss                      2.4159884
QF Loss                      269.65912
VF Loss                      77.09909
Policy Loss                  -590.57495
Q Predictions Mean           581.2316
Q Predictions Std            375.46603
Q Predictions Max            1365.9534
Q Predictions Min            129.46933
V Predictions Mean           584.9343
V Predictions Std            375.7126
V Predictions Max            1351.6685
V Predictions Min            136.57303
Log Pis Mean                 -1.3395694
Log Pis Std                  2.8993192
Log Pis Max                  7.541504
Log Pis Min                  -6.913801
Policy mu Mean               0.017010804
Policy mu Std                0.75831497
Policy mu Max                2.560572
Policy mu Min                -2.2179778
Policy log std Mean          -0.4341651
Policy log std Std           0.18985143
Policy log std Max           0.04626164
Policy log std Min           -1.6777205
Z mean eval                  2.15639
Z variance eval              0.018573845
total_rewards                [3945.58046096 4220.94580097 4024.13684278 2458.72207811 4060.36271591
 3775.72387136 3924.19714662 4008.41502216 4268.21352796 4116.60474594]
total_rewards_mean           3880.2902212784525
total_rewards_std            492.93913717162457
total_rewards_max            4268.213527961186
total_rewards_min            2458.722078108466
Number of train steps total  64000
Number of env steps total    194000
Number of rollouts total     0
Train Time (s)               136.0381448729895
(Previous) Eval Time (s)     29.1315353740938
Sample Time (s)              9.793008456937969
Epoch Time (s)               174.96268870402128
Total Train Time (s)         2891.024079713039
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:39:30.390357 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #15 | Epoch Duration: 175.04682302474976
2020-01-13 04:39:30.390554 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #15 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1560109
Z variance train             0.018591741
KL Divergence                27.455746
KL Loss                      2.7455747
QF Loss                      256.09094
VF Loss                      51.13497
Policy Loss                  -628.5214
Q Predictions Mean           623.729
Q Predictions Std            427.99777
Q Predictions Max            1447.118
Q Predictions Min            109.91141
V Predictions Mean           628.1433
V Predictions Std            429.28458
V Predictions Max            1437.2018
V Predictions Min            111.93628
Log Pis Mean                 -1.3209217
Log Pis Std                  3.027526
Log Pis Max                  9.375058
Log Pis Min                  -6.195577
Policy mu Mean               -0.03234281
Policy mu Std                0.76144284
Policy mu Max                2.6741767
Policy mu Min                -3.0504224
Policy log std Mean          -0.44179294
Policy log std Std           0.18850854
Policy log std Max           -0.16483758
Policy log std Min           -1.8026974
Z mean eval                  2.1643376
Z variance eval              0.021905273
total_rewards                [3931.65543911 3986.29410851 3841.54039886 3979.4679843  4185.2588604
 4011.72114932 4026.50278836 4041.69620796 4028.05555706 4044.62236598]
total_rewards_mean           4007.6814859853594
total_rewards_std            83.35301982133022
total_rewards_max            4185.258860396818
total_rewards_min            3841.540398856878
Number of train steps total  68000
Number of env steps total    206000
Number of rollouts total     0
Train Time (s)               140.37818847596645
(Previous) Eval Time (s)     29.636836634017527
Sample Time (s)              9.637842336669564
Epoch Time (s)               179.65286744665354
Total Train Time (s)         3070.7604709006846
Epoch                        16
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:42:30.128631 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #16 | Epoch Duration: 179.73792266845703
2020-01-13 04:42:30.128918 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.168
Z variance train             0.022010658
KL Divergence                30.48648
KL Loss                      3.048648
QF Loss                      194.4691
VF Loss                      92.87509
Policy Loss                  -586.7053
Q Predictions Mean           577.2095
Q Predictions Std            442.55322
Q Predictions Max            1506.7148
Q Predictions Min            114.36398
V Predictions Mean           580.9556
V Predictions Std            443.63297
V Predictions Max            1496.9319
V Predictions Min            116.44871
Log Pis Mean                 -1.588352
Log Pis Std                  3.0819478
Log Pis Max                  10.096727
Log Pis Min                  -9.722386
Policy mu Mean               -0.023022177
Policy mu Std                0.7089354
Policy mu Max                2.5599248
Policy mu Min                -2.3732564
Policy log std Mean          -0.43543497
Policy log std Std           0.18922606
Policy log std Max           -0.18052675
Policy log std Min           -1.8358722
Z mean eval                  2.1376603
Z variance eval              0.010108475
total_rewards                [4323.54406317 4196.10113319 4488.89769579 4125.37215829 3976.00631517
 4314.71664031 4341.55639276 4443.34965304 4427.20118819 4317.55442791]
total_rewards_mean           4295.429966781452
total_rewards_std            148.75164278299883
total_rewards_max            4488.897695789037
total_rewards_min            3976.006315173197
Number of train steps total  72000
Number of env steps total    218000
Number of rollouts total     0
Train Time (s)               146.32717904122546
(Previous) Eval Time (s)     29.67210314096883
Sample Time (s)              8.717916850466281
Epoch Time (s)               184.71719903266057
Total Train Time (s)         3255.5569341504015
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:45:34.925936 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #17 | Epoch Duration: 184.79668378829956
2020-01-13 04:45:34.926154 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1420865
Z variance train             0.01018998
KL Divergence                30.990833
KL Loss                      3.0990834
QF Loss                      326.7068
VF Loss                      171.19576
Policy Loss                  -645.9472
Q Predictions Mean           633.59717
Q Predictions Std            478.03458
Q Predictions Max            1528.694
Q Predictions Min            108.33403
V Predictions Mean           635.39935
V Predictions Std            479.2504
V Predictions Max            1509.122
V Predictions Min            117.70548
Log Pis Mean                 -1.4966679
Log Pis Std                  3.168276
Log Pis Max                  12.573307
Log Pis Min                  -5.6261196
Policy mu Mean               0.044510394
Policy mu Std                0.7506248
Policy mu Max                2.7421257
Policy mu Min                -2.5264802
Policy log std Mean          -0.44282043
Policy log std Std           0.20217356
Policy log std Max           -0.15446725
Policy log std Min           -1.7667996
Z mean eval                  2.1536717
Z variance eval              0.012165952
total_rewards                [4006.44583234 4497.05333432 4079.63741918 4640.68642854 4450.07806226
 4803.53429324 4627.94236285 4309.71624647 4409.14310914 4599.91244478]
total_rewards_mean           4442.414953313202
total_rewards_std            239.24491365700183
total_rewards_max            4803.534293242833
total_rewards_min            4006.445832341439
Number of train steps total  76000
Number of env steps total    230000
Number of rollouts total     0
Train Time (s)               145.14398198202252
(Previous) Eval Time (s)     28.78586185723543
Sample Time (s)              10.034160948358476
Epoch Time (s)               183.96400478761643
Total Train Time (s)         3439.6087293094024
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:48:38.980159 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #18 | Epoch Duration: 184.0538375377655
2020-01-13 04:48:38.980382 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1567967
Z variance train             0.0121422
KL Divergence                30.461346
KL Loss                      3.0461347
QF Loss                      231.95047
VF Loss                      61.116776
Policy Loss                  -652.9917
Q Predictions Mean           642.42786
Q Predictions Std            470.12903
Q Predictions Max            1555.6818
Q Predictions Min            101.82293
V Predictions Mean           652.36487
V Predictions Std            473.4002
V Predictions Max            1563.0844
V Predictions Min            112.6152
Log Pis Mean                 -1.4672794
Log Pis Std                  2.771547
Log Pis Max                  9.089682
Log Pis Min                  -6.460285
Policy mu Mean               -0.005866179
Policy mu Std                0.7090728
Policy mu Max                2.524079
Policy mu Min                -2.383123
Policy log std Mean          -0.44240746
Policy log std Std           0.20956212
Policy log std Max           -0.06296131
Policy log std Min           -1.7830443
Z mean eval                  2.1302464
Z variance eval              0.021251814
total_rewards                [4363.74121888 4189.17263375 4401.1186752  4413.78017297 4511.95851607
 4251.12407394 4407.78787941 4569.43828854 4239.90288398 4507.96367541]
total_rewards_mean           4385.598801815455
total_rewards_std            120.26473057913094
total_rewards_max            4569.438288537868
total_rewards_min            4189.172633746299
Number of train steps total  80000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               145.51250000856817
(Previous) Eval Time (s)     30.985371564049274
Sample Time (s)              10.058291838504374
Epoch Time (s)               186.55616341112182
Total Train Time (s)         3626.2524492447264
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:51:45.624280 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #19 | Epoch Duration: 186.6437270641327
2020-01-13 04:51:45.624493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.130591
Z variance train             0.021382548
KL Divergence                28.324394
KL Loss                      2.8324394
QF Loss                      331.3884
VF Loss                      71.1032
Policy Loss                  -687.73627
Q Predictions Mean           683.3706
Q Predictions Std            493.80222
Q Predictions Max            1653.3263
Q Predictions Min            109.87888
V Predictions Mean           689.3702
V Predictions Std            494.74017
V Predictions Max            1621.7692
V Predictions Min            108.67218
Log Pis Mean                 -1.3409259
Log Pis Std                  3.297848
Log Pis Max                  9.738718
Log Pis Min                  -7.89439
Policy mu Mean               -0.041907463
Policy mu Std                0.76117015
Policy mu Max                3.0115852
Policy mu Min                -2.364581
Policy log std Mean          -0.45343503
Policy log std Std           0.20496918
Policy log std Max           0.09873229
Policy log std Min           -1.8285434
Z mean eval                  2.1448584
Z variance eval              0.019967139
total_rewards                [4253.45022951 4355.97794446 4295.13854697 4322.51323413 4285.26647418
 4253.52946319 4151.70789816 4289.65401263 4357.53102068 4330.50815898]
total_rewards_mean           4289.527698290418
total_rewards_std            57.83505892367004
total_rewards_max            4357.531020676772
total_rewards_min            4151.707898158287
Number of train steps total  84000
Number of env steps total    254000
Number of rollouts total     0
Train Time (s)               144.083226907067
(Previous) Eval Time (s)     30.77234004996717
Sample Time (s)              13.676509617827833
Epoch Time (s)               188.532076574862
Total Train Time (s)         3814.883813721128
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:54:54.257768 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #20 | Epoch Duration: 188.633118391037
2020-01-13 04:54:54.257991 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1436436
Z variance train             0.01993153
KL Divergence                28.53073
KL Loss                      2.853073
QF Loss                      342.41486
VF Loss                      184.85005
Policy Loss                  -681.49115
Q Predictions Mean           673.95624
Q Predictions Std            494.54364
Q Predictions Max            1662.2656
Q Predictions Min            92.576515
V Predictions Mean           670.4573
V Predictions Std            493.7701
V Predictions Max            1648.7828
V Predictions Min            99.10451
Log Pis Mean                 -1.3790026
Log Pis Std                  3.0705378
Log Pis Max                  7.560112
Log Pis Min                  -6.9278307
Policy mu Mean               0.024438642
Policy mu Std                0.7482956
Policy mu Max                2.493583
Policy mu Min                -2.6068683
Policy log std Mean          -0.44727182
Policy log std Std           0.21511582
Policy log std Max           -0.0851683
Policy log std Min           -1.7632575
Z mean eval                  2.1527429
Z variance eval              0.026894584
total_rewards                [4278.5236842  4624.15770525 4490.41587118 4352.03043083 4460.13082051
 4431.86865917 4485.96962047 4638.82115741 4257.97471884 4350.88133349]
total_rewards_mean           4437.077400135008
total_rewards_std            123.8440217441765
total_rewards_max            4638.821157406979
total_rewards_min            4257.974718835467
Number of train steps total  88000
Number of env steps total    266000
Number of rollouts total     0
Train Time (s)               135.80928570544347
(Previous) Eval Time (s)     29.26618640497327
Sample Time (s)              9.776092582382262
Epoch Time (s)               174.851564692799
Total Train Time (s)         3989.8180725253187
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:57:49.195442 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #21 | Epoch Duration: 174.93724465370178
2020-01-13 04:57:49.195769 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1489587
Z variance train             0.02699602
KL Divergence                28.67499
KL Loss                      2.867499
QF Loss                      382.85568
VF Loss                      190.84865
Policy Loss                  -696.4181
Q Predictions Mean           689.45325
Q Predictions Std            540.96655
Q Predictions Max            1691.5641
Q Predictions Min            76.65658
V Predictions Mean           705.0094
V Predictions Std            542.18335
V Predictions Max            1684.986
V Predictions Min            90.26904
Log Pis Mean                 -1.3285109
Log Pis Std                  3.2333457
Log Pis Max                  8.773729
Log Pis Min                  -6.0632634
Policy mu Mean               0.03206118
Policy mu Std                0.7571548
Policy mu Max                2.4250805
Policy mu Min                -2.6268053
Policy log std Mean          -0.45324895
Policy log std Std           0.22530477
Policy log std Max           -0.18276295
Policy log std Min           -2.0907576
Z mean eval                  2.1034696
Z variance eval              0.012544232
total_rewards                [4508.7953424  4590.00270581 4478.14366653 4689.3375336  4778.05999114
 4364.29345017 4456.02586868 4678.04087447 4705.05716615 4497.09983877]
total_rewards_mean           4574.485643771712
total_rewards_std            126.66723752908682
total_rewards_max            4778.059991143529
total_rewards_min            4364.29345016883
Number of train steps total  92000
Number of env steps total    278000
Number of rollouts total     0
Train Time (s)               136.93847764795646
(Previous) Eval Time (s)     29.659422919154167
Sample Time (s)              9.67853239690885
Epoch Time (s)               176.27643296401948
Total Train Time (s)         4166.179544260725
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:00:45.556064 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #22 | Epoch Duration: 176.36005640029907
2020-01-13 05:00:45.556261 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #22 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1014817
Z variance train             0.012486455
KL Divergence                28.906452
KL Loss                      2.8906453
QF Loss                      229.36212
VF Loss                      44.130836
Policy Loss                  -645.7749
Q Predictions Mean           637.2941
Q Predictions Std            529.80927
Q Predictions Max            1708.951
Q Predictions Min            67.01189
V Predictions Mean           646.35004
V Predictions Std            529.95575
V Predictions Max            1720.7213
V Predictions Min            71.77211
Log Pis Mean                 -1.5745406
Log Pis Std                  3.0480723
Log Pis Max                  11.487847
Log Pis Min                  -7.2893543
Policy mu Mean               0.015818255
Policy mu Std                0.71036273
Policy mu Max                2.4802086
Policy mu Min                -2.3022852
Policy log std Mean          -0.4477997
Policy log std Std           0.22469881
Policy log std Max           -0.11985628
Policy log std Min           -1.8561778
Z mean eval                  2.152614
Z variance eval              0.0064386735
total_rewards                [4386.50136399 4422.26333637 4541.62185822 4588.36982374 4620.0424404
 4531.79886835 4428.4804518  4526.60347199 4407.08605277 4514.1287171 ]
total_rewards_mean           4496.689638472763
total_rewards_std            76.44195013385107
total_rewards_max            4620.042440398259
total_rewards_min            4386.501363986796
Number of train steps total  96000
Number of env steps total    290000
Number of rollouts total     0
Train Time (s)               139.99108413187787
(Previous) Eval Time (s)     29.834366826806217
Sample Time (s)              9.704217810183764
Epoch Time (s)               179.52966876886785
Total Train Time (s)         4345.799460324924
Epoch                        23
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:03:45.178846 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #23 | Epoch Duration: 179.62241077423096
2020-01-13 05:03:45.179215 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1560915
Z variance train             0.006420909
KL Divergence                31.44335
KL Loss                      3.144335
QF Loss                      234.54868
VF Loss                      96.42402
Policy Loss                  -718.91345
Q Predictions Mean           711.1576
Q Predictions Std            558.226
Q Predictions Max            1762.4148
Q Predictions Min            82.48784
V Predictions Mean           722.9
V Predictions Std            559.8438
V Predictions Max            1755.1619
V Predictions Min            89.61056
Log Pis Mean                 -1.4393816
Log Pis Std                  3.034569
Log Pis Max                  9.084289
Log Pis Min                  -6.348898
Policy mu Mean               0.0034131955
Policy mu Std                0.7578485
Policy mu Max                2.61989
Policy mu Min                -2.4492407
Policy log std Mean          -0.45058176
Policy log std Std           0.22086625
Policy log std Max           -0.1475388
Policy log std Min           -1.8913441
Z mean eval                  2.1043952
Z variance eval              0.012276087
total_rewards                [4158.29490261 4418.41680707 4469.18038547 4407.71484567 4385.38706083
 4427.22344896 4563.33203754 4370.76581201 4344.05107295 4358.07081193]
total_rewards_mean           4390.243718504051
total_rewards_std            97.99444516326724
total_rewards_max            4563.332037542755
total_rewards_min            4158.294902608507
Number of train steps total  100000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               145.693601696752
(Previous) Eval Time (s)     30.00818700855598
Sample Time (s)              10.205019845161587
Epoch Time (s)               185.90680855046958
Total Train Time (s)         4531.793544896413
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:06:51.173631 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #24 | Epoch Duration: 185.99419045448303
2020-01-13 05:06:51.173899 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1015556
Z variance train             0.012275374
KL Divergence                30.165888
KL Loss                      3.016589
QF Loss                      270.86206
VF Loss                      152.7073
Policy Loss                  -686.7179
Q Predictions Mean           682.7369
Q Predictions Std            565.0525
Q Predictions Max            1764.8596
Q Predictions Min            69.8864
V Predictions Mean           692.0461
V Predictions Std            566.40765
V Predictions Max            1754.1198
V Predictions Min            76.27146
Log Pis Mean                 -1.3101013
Log Pis Std                  3.1710107
Log Pis Max                  12.364924
Log Pis Min                  -6.7979608
Policy mu Mean               -0.030437822
Policy mu Std                0.7459782
Policy mu Max                3.7669668
Policy mu Min                -2.5283887
Policy log std Mean          -0.43772817
Policy log std Std           0.20911577
Policy log std Max           -0.13612133
Policy log std Min           -1.961273
Z mean eval                  2.109567
Z variance eval              0.006008694
total_rewards                [4674.41131747 4706.86633592 4615.96564803 4693.39674345 4815.51554771
 4794.01590176 4827.26734046 4859.91484356 4734.45355073 4752.2211    ]
total_rewards_mean           4747.402832908334
total_rewards_std            72.9408472656618
total_rewards_max            4859.9148435589705
total_rewards_min            4615.96564803397
Number of train steps total  104000
Number of env steps total    314000
Number of rollouts total     0
Train Time (s)               145.0594505816698
(Previous) Eval Time (s)     29.29925661208108
Sample Time (s)              10.269540433771908
Epoch Time (s)               184.6282476275228
Total Train Time (s)         4716.536315409467
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:09:55.918236 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #25 | Epoch Duration: 184.74416065216064
2020-01-13 05:09:55.918580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1069324
Z variance train             0.0059761778
KL Divergence                32.467567
KL Loss                      3.2467568
QF Loss                      430.35516
VF Loss                      113.64252
Policy Loss                  -652.6116
Q Predictions Mean           642.47876
Q Predictions Std            570.6855
Q Predictions Max            1746.0643
Q Predictions Min            61.094395
V Predictions Mean           658.38696
V Predictions Std            571.68555
V Predictions Max            1751.9493
V Predictions Min            75.52189
Log Pis Mean                 -1.4582086
Log Pis Std                  3.262673
Log Pis Max                  8.994139
Log Pis Min                  -7.873481
Policy mu Mean               -0.004438695
Policy mu Std                0.7295299
Policy mu Max                2.6047447
Policy mu Min                -2.411281
Policy log std Mean          -0.44278923
Policy log std Std           0.22586991
Policy log std Max           -0.14189085
Policy log std Min           -1.9744833
Z mean eval                  2.1199965
Z variance eval              0.017043285
total_rewards                [4670.9383559  4963.41743254 4833.32986848 4644.41411435 4702.44808469
 4780.15379029 4579.02243871 4646.41647444 4722.98193126 4672.46482013]
total_rewards_mean           4721.5587310801175
total_rewards_std            105.676828886763
total_rewards_max            4963.417432538868
total_rewards_min            4579.022438713819
Number of train steps total  108000
Number of env steps total    326000
Number of rollouts total     0
Train Time (s)               145.3807795541361
(Previous) Eval Time (s)     29.825206984300166
Sample Time (s)              10.13071264559403
Epoch Time (s)               185.3366991840303
Total Train Time (s)         4901.9714841274545
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:13:01.354561 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #26 | Epoch Duration: 185.43572068214417
2020-01-13 05:13:01.354799 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1186569
Z variance train             0.016959604
KL Divergence                30.437723
KL Loss                      3.0437725
QF Loss                      248.0378
VF Loss                      99.18346
Policy Loss                  -707.2911
Q Predictions Mean           703.9597
Q Predictions Std            602.25256
Q Predictions Max            1820.4639
Q Predictions Min            68.527336
V Predictions Mean           707.2534
V Predictions Std            607.2852
V Predictions Max            1816.116
V Predictions Min            63.56658
Log Pis Mean                 -1.4303405
Log Pis Std                  3.1259248
Log Pis Max                  9.80846
Log Pis Min                  -6.4317484
Policy mu Mean               -0.053317606
Policy mu Std                0.757048
Policy mu Max                2.4817348
Policy mu Min                -2.964065
Policy log std Mean          -0.43340537
Policy log std Std           0.22247656
Policy log std Max           -0.1546616
Policy log std Min           -2.13376
Z mean eval                  2.1110215
Z variance eval              0.0215013
total_rewards                [4942.847207   4818.81870314 4786.85754587 4915.88387349  866.93114477
 4791.0969494  4994.24376896 4907.19255862 4908.89085153 4877.68052453]
total_rewards_mean           4481.044312731652
total_rewards_std            1206.36877496575
total_rewards_max            4994.243768963913
total_rewards_min            866.9311447664874
Number of train steps total  112000
Number of env steps total    338000
Number of rollouts total     0
Train Time (s)               144.18067615991458
(Previous) Eval Time (s)     30.826987565029413
Sample Time (s)              10.120251310057938
Epoch Time (s)               185.12791503500193
Total Train Time (s)         5087.17973590875
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:16:06.563983 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #27 | Epoch Duration: 185.2090072631836
2020-01-13 05:16:06.564208 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1119301
Z variance train             0.021515464
KL Divergence                29.851763
KL Loss                      2.9851763
QF Loss                      602.24805
VF Loss                      112.76834
Policy Loss                  -680.94464
Q Predictions Mean           673.10913
Q Predictions Std            593.21497
Q Predictions Max            1885.1666
Q Predictions Min            63.88822
V Predictions Mean           682.6601
V Predictions Std            595.27637
V Predictions Max            1879.8964
V Predictions Min            62.724743
Log Pis Mean                 -1.3530844
Log Pis Std                  3.280138
Log Pis Max                  12.090601
Log Pis Min                  -7.5672026
Policy mu Mean               0.0058047753
Policy mu Std                0.7358404
Policy mu Max                2.6127095
Policy mu Min                -3.117839
Policy log std Mean          -0.44839573
Policy log std Std           0.22369616
Policy log std Max           -0.10885444
Policy log std Min           -1.8908439
Z mean eval                  2.1111743
Z variance eval              0.0100240065
total_rewards                [4825.47685068 4572.37104485 5061.02095815 4676.97503541 4794.68229416
 5176.89254421 5346.16674642 5189.94592126 4962.34596905 4854.72137394]
total_rewards_mean           4946.059873811193
total_rewards_std            233.27646108741465
total_rewards_max            5346.166746415366
total_rewards_min            4572.371044848234
Number of train steps total  116000
Number of env steps total    350000
Number of rollouts total     0
Train Time (s)               136.56897647678852
(Previous) Eval Time (s)     29.90249990299344
Sample Time (s)              9.793058508541435
Epoch Time (s)               176.2645348883234
Total Train Time (s)         5263.535866845865
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:19:02.922485 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #28 | Epoch Duration: 176.35808873176575
2020-01-13 05:19:02.922811 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.111857
Z variance train             0.01001667
KL Divergence                30.850431
KL Loss                      3.0850432
QF Loss                      406.57465
VF Loss                      84.1924
Policy Loss                  -729.58185
Q Predictions Mean           724.7718
Q Predictions Std            627.0113
Q Predictions Max            1905.2603
Q Predictions Min            57.441727
V Predictions Mean           731.7296
V Predictions Std            627.35535
V Predictions Max            1906.0038
V Predictions Min            59.71011
Log Pis Mean                 -1.3786867
Log Pis Std                  3.4349482
Log Pis Max                  10.065784
Log Pis Min                  -6.592848
Policy mu Mean               0.02619291
Policy mu Std                0.73529124
Policy mu Max                2.7412038
Policy mu Min                -2.2242105
Policy log std Mean          -0.4527944
Policy log std Std           0.22347276
Policy log std Max           -0.13007146
Policy log std Min           -1.9190077
Z mean eval                  2.1680627
Z variance eval              0.016040947
total_rewards                [4807.82000717 5162.92191458 4862.63675134 4833.73281823 4992.91345187
 5060.2391279  4673.11463257 4746.20707863 4741.3568128  4870.5026323 ]
total_rewards_mean           4875.144522739092
total_rewards_std            145.84613957364127
total_rewards_max            5162.921914582679
total_rewards_min            4673.114632574176
Number of train steps total  120000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               135.70186604978517
(Previous) Eval Time (s)     29.753253877628595
Sample Time (s)              8.3936552926898
Epoch Time (s)               173.84877522010356
Total Train Time (s)         5437.576032161713
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:21:56.963072 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #29 | Epoch Duration: 174.0400424003601
2020-01-13 05:21:56.963316 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1663036
Z variance train             0.016079992
KL Divergence                30.404533
KL Loss                      3.0404534
QF Loss                      563.7984
VF Loss                      62.089672
Policy Loss                  -714.21295
Q Predictions Mean           704.1423
Q Predictions Std            616.4818
Q Predictions Max            1927.1195
Q Predictions Min            59.486504
V Predictions Mean           714.4134
V Predictions Std            620.5377
V Predictions Max            1916.7892
V Predictions Min            71.528946
Log Pis Mean                 -1.3700418
Log Pis Std                  3.3520048
Log Pis Max                  11.7546215
Log Pis Min                  -7.4433756
Policy mu Mean               -0.043243315
Policy mu Std                0.71753204
Policy mu Max                3.0051122
Policy mu Min                -2.603621
Policy log std Mean          -0.43904528
Policy log std Std           0.21353832
Policy log std Max           -0.13361132
Policy log std Min           -2.0866098
Z mean eval                  2.0805879
Z variance eval              0.011595969
total_rewards                [5113.48249276 5135.22408429 4987.15902774 5194.39066094 5030.82394674
 5047.94210136 5077.93156216 5255.90487718 4968.09959184 5242.75514117]
total_rewards_mean           5105.371348616238
total_rewards_std            96.3546198117572
total_rewards_max            5255.904877175152
total_rewards_min            4968.099591842125
Number of train steps total  124000
Number of env steps total    374000
Number of rollouts total     0
Train Time (s)               140.85038622980937
(Previous) Eval Time (s)     29.891151153016835
Sample Time (s)              9.359172977972776
Epoch Time (s)               180.10071036079898
Total Train Time (s)         5617.780532153789
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:24:57.168925 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #30 | Epoch Duration: 180.20545268058777
2020-01-13 05:24:57.169133 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0811143
Z variance train             0.011618823
KL Divergence                30.354874
KL Loss                      3.0354874
QF Loss                      280.776
VF Loss                      126.556145
Policy Loss                  -774.7683
Q Predictions Mean           769.2843
Q Predictions Std            639.33417
Q Predictions Max            1975.0485
Q Predictions Min            43.74199
V Predictions Mean           776.7469
V Predictions Std            642.0582
V Predictions Max            1951.678
V Predictions Min            59.901176
Log Pis Mean                 -1.2383507
Log Pis Std                  3.4634314
Log Pis Max                  11.389447
Log Pis Min                  -8.429118
Policy mu Mean               -0.026933393
Policy mu Std                0.76745445
Policy mu Max                2.6364625
Policy mu Min                -2.3934
Policy log std Mean          -0.45716357
Policy log std Std           0.21763717
Policy log std Max           -0.112641275
Policy log std Min           -1.7996583
Z mean eval                  2.132667
Z variance eval              0.011667515
total_rewards                [4784.90890619 4528.57320011 4889.22805569 4780.41956832 4480.03486013
 4756.62020714 4698.20453827 4687.77857377 4778.69819182 4745.00179581]
total_rewards_mean           4712.946789726059
total_rewards_std            117.11392104957731
total_rewards_max            4889.228055685549
total_rewards_min            4480.034860127498
Number of train steps total  128000
Number of env steps total    386000
Number of rollouts total     0
Train Time (s)               146.40916913514957
(Previous) Eval Time (s)     29.203535475302488
Sample Time (s)              10.153424886520952
Epoch Time (s)               185.766129496973
Total Train Time (s)         5803.640927994158
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:28:03.032544 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #31 | Epoch Duration: 185.86324071884155
2020-01-13 05:28:03.032832 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1307087
Z variance train             0.0116647165
KL Divergence                32.182602
KL Loss                      3.2182603
QF Loss                      311.78613
VF Loss                      168.12373
Policy Loss                  -663.3345
Q Predictions Mean           660.07745
Q Predictions Std            643.90356
Q Predictions Max            1969.8213
Q Predictions Min            54.821613
V Predictions Mean           662.2733
V Predictions Std            648.0559
V Predictions Max            1978.194
V Predictions Min            60.533672
Log Pis Mean                 -1.6306324
Log Pis Std                  3.2567031
Log Pis Max                  11.8490715
Log Pis Min                  -5.9382443
Policy mu Mean               -0.033399824
Policy mu Std                0.7032704
Policy mu Max                3.0315473
Policy mu Min                -3.0781054
Policy log std Mean          -0.42198253
Policy log std Std           0.20011961
Policy log std Max           -0.13612092
Policy log std Min           -1.8319712
Z mean eval                  2.11301
Z variance eval              0.014936668
total_rewards                [5433.1608387  5135.58947173 5476.30756074  361.42995491 5349.49380355
 5118.88633009 5268.01580436 5432.71259084 5206.52451457 5222.33425102]
total_rewards_mean           4800.445512051221
total_rewards_std            1484.5346498554034
total_rewards_max            5476.3075607402625
total_rewards_min            361.4299549093059
Number of train steps total  132000
Number of env steps total    398000
Number of rollouts total     0
Train Time (s)               145.38885322399437
(Previous) Eval Time (s)     30.179380156099796
Sample Time (s)              9.809914517216384
Epoch Time (s)               185.37814789731055
Total Train Time (s)         5989.124340560287
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:31:08.517136 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #32 | Epoch Duration: 185.4840636253357
2020-01-13 05:31:08.517472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #32 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1112041
Z variance train             0.014915159
KL Divergence                33.03687
KL Loss                      3.3036869
QF Loss                      256.3758
VF Loss                      249.41118
Policy Loss                  -766.58545
Q Predictions Mean           762.4038
Q Predictions Std            674.1757
Q Predictions Max            2005.0723
Q Predictions Min            -13.12916
V Predictions Mean           778.55194
V Predictions Std            679.4114
V Predictions Max            2007.1013
V Predictions Min            -21.549023
Log Pis Mean                 -1.1181793
Log Pis Std                  3.3534179
Log Pis Max                  9.639143
Log Pis Min                  -5.9578457
Policy mu Mean               0.0021903014
Policy mu Std                0.77222115
Policy mu Max                2.7209527
Policy mu Min                -2.2654984
Policy log std Mean          -0.4551076
Policy log std Std           0.24342433
Policy log std Max           -0.09902355
Policy log std Min           -2.0581264
Z mean eval                  2.127005
Z variance eval              0.01039577
total_rewards                [5300.83096513 5353.5809404  5497.65532438 5213.80424065 5350.5527771
 5277.05594688 5444.93077508 5300.55184499 5394.45409285 5168.47018729]
total_rewards_mean           5330.18870947615
total_rewards_std            95.16526482731577
total_rewards_max            5497.655324380367
total_rewards_min            5168.470187293002
Number of train steps total  136000
Number of env steps total    410000
Number of rollouts total     0
Train Time (s)               144.64169518183917
(Previous) Eval Time (s)     31.07165264338255
Sample Time (s)              10.133738869801164
Epoch Time (s)               185.84708669502288
Total Train Time (s)         6175.058829740621
Epoch                        33
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:34:14.453183 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #33 | Epoch Duration: 185.93549919128418
2020-01-13 05:34:14.453462 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1236777
Z variance train             0.010397362
KL Divergence                34.706795
KL Loss                      3.4706795
QF Loss                      347.06653
VF Loss                      144.34308
Policy Loss                  -725.11383
Q Predictions Mean           713.9959
Q Predictions Std            667.07324
Q Predictions Max            2025.7898
Q Predictions Min            42.64721
V Predictions Mean           730.64124
V Predictions Std            670.2611
V Predictions Max            2018.187
V Predictions Min            42.875153
Log Pis Mean                 -1.1803313
Log Pis Std                  3.6233332
Log Pis Max                  15.080845
Log Pis Min                  -5.1907196
Policy mu Mean               -0.06262204
Policy mu Std                0.7540308
Policy mu Max                2.3648534
Policy mu Min                -2.5772035
Policy log std Mean          -0.4431738
Policy log std Std           0.22888418
Policy log std Max           -0.1306504
Policy log std Min           -1.9986396
Z mean eval                  2.1250343
Z variance eval              0.008559846
total_rewards                [5273.91599055 5209.32288153 5293.51067445 5356.64445065 5200.54020577
 5191.52684763 5312.09851736 5336.2667891  5294.41391835 5400.30824165]
total_rewards_mean           5286.854851704283
total_rewards_std            66.05963099987049
total_rewards_max            5400.308241645335
total_rewards_min            5191.52684763333
Number of train steps total  140000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               144.823901578784
(Previous) Eval Time (s)     30.424145264085382
Sample Time (s)              10.149825940839946
Epoch Time (s)               185.39787278370932
Total Train Time (s)         6360.544444364961
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:37:19.940029 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #34 | Epoch Duration: 185.48636531829834
2020-01-13 05:37:19.940263 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.125375
Z variance train             0.008522726
KL Divergence                33.586365
KL Loss                      3.3586366
QF Loss                      457.00793
VF Loss                      76.90333
Policy Loss                  -797.9235
Q Predictions Mean           793.6618
Q Predictions Std            676.78705
Q Predictions Max            2026.4607
Q Predictions Min            34.352238
V Predictions Mean           800.93774
V Predictions Std            675.83484
V Predictions Max            2029.3434
V Predictions Min            50.302105
Log Pis Mean                 -1.2723565
Log Pis Std                  3.394568
Log Pis Max                  10.749321
Log Pis Min                  -6.1693077
Policy mu Mean               -0.009927802
Policy mu Std                0.77478814
Policy mu Max                3.0453033
Policy mu Min                -2.9576368
Policy log std Mean          -0.46181366
Policy log std Std           0.23282771
Policy log std Max           -0.14758363
Policy log std Min           -1.9649429
Z mean eval                  2.089369
Z variance eval              0.024710737
total_rewards                [5274.15073092 5277.6265512  5400.34284242 5132.29817512 5169.28050867
 5187.34027239 5047.72803838 5158.64583696 5156.78661368 5128.73778141]
total_rewards_mean           5193.29373511451
total_rewards_std            94.20288613609317
total_rewards_max            5400.342842421068
total_rewards_min            5047.728038382331
Number of train steps total  144000
Number of env steps total    434000
Number of rollouts total     0
Train Time (s)               136.50363826099783
(Previous) Eval Time (s)     29.57113266317174
Sample Time (s)              8.391968079842627
Epoch Time (s)               174.4667390040122
Total Train Time (s)         6535.091781661846
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:40:14.488496 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #35 | Epoch Duration: 174.54808020591736
2020-01-13 05:40:14.488689 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0930984
Z variance train             0.024696026
KL Divergence                30.17097
KL Loss                      3.0170972
QF Loss                      172.45114
VF Loss                      80.69656
Policy Loss                  -705.8486
Q Predictions Mean           699.07886
Q Predictions Std            676.1801
Q Predictions Max            2030.0559
Q Predictions Min            47.719612
V Predictions Mean           705.38635
V Predictions Std            679.897
V Predictions Max            2023.9681
V Predictions Min            56.16746
Log Pis Mean                 -1.8382403
Log Pis Std                  3.1650422
Log Pis Max                  8.768512
Log Pis Min                  -7.194309
Policy mu Mean               -0.02230967
Policy mu Std                0.67155063
Policy mu Max                2.4408631
Policy mu Min                -2.1666954
Policy log std Mean          -0.43884453
Policy log std Std           0.22316152
Policy log std Max           -0.13469201
Policy log std Min           -2.2042902
Z mean eval                  2.0887468
Z variance eval              0.012059931
total_rewards                [5413.81159856 5205.85019167 5218.36484802 5552.19500094 5117.67533731
 4964.18769714 5189.58329396 5320.84851921 4921.2417794  5406.32321664]
total_rewards_mean           5231.008148284702
total_rewards_std            189.1788143678505
total_rewards_max            5552.195000940107
total_rewards_min            4921.241779400807
Number of train steps total  148000
Number of env steps total    446000
Number of rollouts total     0
Train Time (s)               135.7681331699714
(Previous) Eval Time (s)     28.03786137374118
Sample Time (s)              9.4532196004875
Epoch Time (s)               173.2592141442001
Total Train Time (s)         6708.441079930868
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:43:07.839223 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #36 | Epoch Duration: 173.35036516189575
2020-01-13 05:43:07.839427 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0873275
Z variance train             0.012058547
KL Divergence                33.247093
KL Loss                      3.3247094
QF Loss                      1128.5049
VF Loss                      109.85789
Policy Loss                  -751.4971
Q Predictions Mean           742.8972
Q Predictions Std            696.0854
Q Predictions Max            2101.0364
Q Predictions Min            26.854395
V Predictions Mean           748.8655
V Predictions Std            697.5204
V Predictions Max            2096.1687
V Predictions Min            49.611507
Log Pis Mean                 -1.2866598
Log Pis Std                  3.6699426
Log Pis Max                  14.814001
Log Pis Min                  -6.015686
Policy mu Mean               0.008934085
Policy mu Std                0.770703
Policy mu Max                3.8101344
Policy mu Min                -2.626891
Policy log std Mean          -0.44958162
Policy log std Std           0.2225797
Policy log std Max           -0.115511954
Policy log std Min           -2.03924
Z mean eval                  2.0796592
Z variance eval              0.011098171
total_rewards                [5334.95663493 5137.06467131 5305.51999883 5304.98581315 5205.28929179
 5398.36318466 5326.17878741 5179.74984137 5415.36462827 5242.2251229 ]
total_rewards_mean           5284.969797462492
total_rewards_std            87.18024104325632
total_rewards_max            5415.364628267873
total_rewards_min            5137.064671312709
Number of train steps total  152000
Number of env steps total    458000
Number of rollouts total     0
Train Time (s)               141.29155340697616
(Previous) Eval Time (s)     29.704610521905124
Sample Time (s)              9.959739256184548
Epoch Time (s)               180.95590318506584
Total Train Time (s)         6889.479961981531
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:46:08.879567 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #37 | Epoch Duration: 181.03998470306396
2020-01-13 05:46:08.879799 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.08241
Z variance train             0.011104988
KL Divergence                33.25738
KL Loss                      3.3257382
QF Loss                      232.23781
VF Loss                      69.57449
Policy Loss                  -792.38257
Q Predictions Mean           782.9426
Q Predictions Std            688.2336
Q Predictions Max            2098.1836
Q Predictions Min            44.27765
V Predictions Mean           789.11664
V Predictions Std            686.8351
V Predictions Max            2081.9678
V Predictions Min            52.04581
Log Pis Mean                 -1.5241786
Log Pis Std                  3.0974643
Log Pis Max                  10.123113
Log Pis Min                  -6.7821503
Policy mu Mean               0.03577825
Policy mu Std                0.70882696
Policy mu Max                2.3377357
Policy mu Min                -2.4868283
Policy log std Mean          -0.44641578
Policy log std Std           0.22087532
Policy log std Max           -0.11658883
Policy log std Min           -2.0143352
Z mean eval                  2.0239816
Z variance eval              0.023644825
total_rewards                [5311.37461803 5491.95275994 5473.11379197 5461.74755427 5274.13830178
 5450.28773243 5352.84344463 5463.35674725 5555.57090106 5274.2170013 ]
total_rewards_mean           5410.8602852662
total_rewards_std            94.29751148752156
total_rewards_max            5555.570901056541
total_rewards_min            5274.138301780462
Number of train steps total  156000
Number of env steps total    470000
Number of rollouts total     0
Train Time (s)               145.92083815531805
(Previous) Eval Time (s)     30.142375172115862
Sample Time (s)              8.880198231432587
Epoch Time (s)               184.9434115588665
Total Train Time (s)         7074.771609743126
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:49:14.172679 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #38 | Epoch Duration: 185.2927234172821
2020-01-13 05:49:14.172885 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0242171
Z variance train             0.023517527
KL Divergence                29.768917
KL Loss                      2.9768918
QF Loss                      242.06262
VF Loss                      135.959
Policy Loss                  -721.5627
Q Predictions Mean           713.3756
Q Predictions Std            681.03906
Q Predictions Max            2063.7078
Q Predictions Min            46.594822
V Predictions Mean           717.7269
V Predictions Std            687.16626
V Predictions Max            2073.2273
V Predictions Min            46.73326
Log Pis Mean                 -1.4594488
Log Pis Std                  3.3349922
Log Pis Max                  8.617645
Log Pis Min                  -6.7347
Policy mu Mean               -0.0882413
Policy mu Std                0.7164073
Policy mu Max                2.4818325
Policy mu Min                -2.9175324
Policy log std Mean          -0.44580665
Policy log std Std           0.22036304
Policy log std Max           -0.18558769
Policy log std Min           -1.921897
Z mean eval                  2.0659957
Z variance eval              0.013402997
total_rewards                [5493.85811213 5479.77025608 5487.46470401 5627.98518818 1401.08158981
 5501.11524576 5575.36324504 5474.63890624 5472.98551158 5364.02374197]
total_rewards_mean           5087.828650080254
total_rewards_std            1230.642417467878
total_rewards_max            5627.9851881796985
total_rewards_min            1401.0815898083601
Number of train steps total  160000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               144.9335070680827
(Previous) Eval Time (s)     29.64245746191591
Sample Time (s)              10.204035125672817
Epoch Time (s)               184.77999965567142
Total Train Time (s)         7259.633317616768
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:52:19.036262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #39 | Epoch Duration: 184.86322021484375
2020-01-13 05:52:19.036497 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0619087
Z variance train             0.013420628
KL Divergence                32.927216
KL Loss                      3.2927215
QF Loss                      432.8795
VF Loss                      69.76184
Policy Loss                  -755.7325
Q Predictions Mean           743.81085
Q Predictions Std            689.38525
Q Predictions Max            2126.041
Q Predictions Min            42.328392
V Predictions Mean           755.6765
V Predictions Std            688.52423
V Predictions Max            2110.7336
V Predictions Min            46.544228
Log Pis Mean                 -1.2135423
Log Pis Std                  3.58145
Log Pis Max                  18.754414
Log Pis Min                  -6.35511
Policy mu Mean               -0.02385517
Policy mu Std                0.7419053
Policy mu Max                3.1129413
Policy mu Min                -3.2565775
Policy log std Mean          -0.4567825
Policy log std Std           0.24729285
Policy log std Max           -0.17240947
Policy log std Min           -2.0791461
Z mean eval                  2.046611
Z variance eval              0.01066195
total_rewards                [5529.94467473 5710.50265451 5483.81300358 5212.03384876 5455.19799368
 5298.76837771 5038.14248341 5384.20853456 5639.82622532 5307.03173254]
total_rewards_mean           5405.946952879515
total_rewards_std            191.29672179803694
total_rewards_max            5710.502654511004
total_rewards_min            5038.142483407778
Number of train steps total  164000
Number of env steps total    494000
Number of rollouts total     0
Train Time (s)               145.95017660036683
(Previous) Eval Time (s)     30.924102149903774
Sample Time (s)              10.130169194191694
Epoch Time (s)               187.0044479444623
Total Train Time (s)         7446.745163288899
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:55:26.149369 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #40 | Epoch Duration: 187.1126971244812
2020-01-13 05:55:26.149601 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0459092
Z variance train             0.010700364
KL Divergence                34.749542
KL Loss                      3.4749544
QF Loss                      330.9669
VF Loss                      162.09317
Policy Loss                  -825.4133
Q Predictions Mean           809.49207
Q Predictions Std            727.688
Q Predictions Max            2180.005
Q Predictions Min            48.849503
V Predictions Mean           817.70374
V Predictions Std            726.067
V Predictions Max            2183.1904
V Predictions Min            52.15864
Log Pis Mean                 -1.3157625
Log Pis Std                  3.472956
Log Pis Max                  15.361692
Log Pis Min                  -6.770859
Policy mu Mean               0.0033701009
Policy mu Std                0.7615785
Policy mu Max                3.378579
Policy mu Min                -2.7804766
Policy log std Mean          -0.47537985
Policy log std Std           0.23499778
Policy log std Max           -0.19121401
Policy log std Min           -2.1054826
Z mean eval                  2.0245106
Z variance eval              0.013568342
total_rewards                [5569.97933644 5289.78454067 5341.23824577 5739.04796749 5439.13624062
 5766.06998646 1863.40697228 5771.21655172 5899.66477882 5460.67905476]
total_rewards_mean           5214.022367502885
total_rewards_std            1133.4790595155189
total_rewards_max            5899.664778822243
total_rewards_min            1863.4069722804672
Number of train steps total  168000
Number of env steps total    506000
Number of rollouts total     0
Train Time (s)               144.16163227893412
(Previous) Eval Time (s)     30.401015628129244
Sample Time (s)              9.78693269053474
Epoch Time (s)               184.3495805975981
Total Train Time (s)         7631.172810378019
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:58:30.578314 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #41 | Epoch Duration: 184.4285604953766
2020-01-13 05:58:30.578521 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0223992
Z variance train             0.013627904
KL Divergence                34.138607
KL Loss                      3.4138608
QF Loss                      351.7688
VF Loss                      111.29303
Policy Loss                  -744.191
Q Predictions Mean           737.3537
Q Predictions Std            725.1245
Q Predictions Max            2174.7258
Q Predictions Min            29.611792
V Predictions Mean           746.2742
V Predictions Std            728.67725
V Predictions Max            2177.8867
V Predictions Min            48.65062
Log Pis Mean                 -1.445747
Log Pis Std                  3.5766366
Log Pis Max                  9.892241
Log Pis Min                  -7.48555
Policy mu Mean               0.015087773
Policy mu Std                0.7478343
Policy mu Max                3.2389936
Policy mu Min                -2.3513424
Policy log std Mean          -0.43230143
Policy log std Std           0.23825783
Policy log std Max           -0.11919823
Policy log std Min           -2.1189148
Z mean eval                  2.0257082
Z variance eval              0.013302381
total_rewards                [5389.82703121 5632.84405194 5748.95998634 5415.69896913 5602.08546265
 5643.4935983  5300.92257808 5457.77165824 5400.71454473 5629.55573936]
total_rewards_mean           5522.187361998166
total_rewards_std            138.93155577335028
total_rewards_max            5748.959986336664
total_rewards_min            5300.922578084906
Number of train steps total  172000
Number of env steps total    518000
Number of rollouts total     0
Train Time (s)               136.38128370186314
(Previous) Eval Time (s)     29.56881877500564
Sample Time (s)              9.726124956738204
Epoch Time (s)               175.67622743360698
Total Train Time (s)         7807.0858525079675
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:26.492609 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #42 | Epoch Duration: 175.91394424438477
2020-01-13 06:01:26.492797 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.028072
Z variance train             0.0133163165
KL Divergence                33.51174
KL Loss                      3.351174
QF Loss                      167.13824
VF Loss                      67.8954
Policy Loss                  -626.7362
Q Predictions Mean           618.28705
Q Predictions Std            666.8469
Q Predictions Max            2276.362
Q Predictions Min            37.0786
V Predictions Mean           621.95013
V Predictions Std            665.74725
V Predictions Max            2279.5066
V Predictions Min            41.056465
Log Pis Mean                 -1.9568083
Log Pis Std                  3.1081111
Log Pis Max                  12.2612
Log Pis Min                  -7.6645765
Policy mu Mean               0.009987526
Policy mu Std                0.65283734
Policy mu Max                2.6159077
Policy mu Min                -2.9470804
Policy log std Mean          -0.40909562
Policy log std Std           0.20550963
Policy log std Max           -0.09007484
Policy log std Min           -2.2105868
Z mean eval                  1.9998331
Z variance eval              0.015191587
total_rewards                [5333.46985972 5620.06031599 5338.95435507 5007.98680638 2902.99968361
 5422.14880173 5123.28270024 5195.33759645 5121.50982454 2591.87261752]
total_rewards_mean           4765.762256125842
total_rewards_std            1024.9280485186036
total_rewards_max            5620.060315992689
total_rewards_min            2591.872617517799
Number of train steps total  176000
Number of env steps total    530000
Number of rollouts total     0
Train Time (s)               136.66602864395827
(Previous) Eval Time (s)     28.56791253387928
Sample Time (s)              9.697803395800292
Epoch Time (s)               174.93174457363784
Total Train Time (s)         7982.102426167112
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:04:21.510934 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #43 | Epoch Duration: 175.01798248291016
2020-01-13 06:04:21.511226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0013242
Z variance train             0.015229998
KL Divergence                33.781242
KL Loss                      3.3781242
QF Loss                      2346.8125
VF Loss                      102.80548
Policy Loss                  -755.1904
Q Predictions Mean           753.85345
Q Predictions Std            739.6439
Q Predictions Max            2225.803
Q Predictions Min            42.663425
V Predictions Mean           757.31335
V Predictions Std            741.23224
V Predictions Max            2224.4165
V Predictions Min            44.712395
Log Pis Mean                 -1.3382711
Log Pis Std                  3.4608383
Log Pis Max                  12.64476
Log Pis Min                  -7.0084515
Policy mu Mean               -0.00047723143
Policy mu Std                0.7108425
Policy mu Max                2.4458432
Policy mu Min                -2.4688253
Policy log std Mean          -0.4501547
Policy log std Std           0.23968478
Policy log std Max           -0.15693119
Policy log std Min           -1.9646797
Z mean eval                  1.9579818
Z variance eval              0.013540564
total_rewards                [6046.26768063 6083.1590032  5770.64077372 5636.30462868 5701.48935783
 5801.07523684 3539.73521096 6071.73362264 5959.66180835 5948.87849363]
total_rewards_mean           5655.894581648079
total_rewards_std            721.1670745600624
total_rewards_max            6083.15900319873
total_rewards_min            3539.735210962765
Number of train steps total  180000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               140.2927076742053
(Previous) Eval Time (s)     29.36977302795276
Sample Time (s)              9.674066637642682
Epoch Time (s)               179.33654733980075
Total Train Time (s)         8161.725898680277
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:07:21.136968 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #44 | Epoch Duration: 179.62553310394287
2020-01-13 06:07:21.137309 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9547112
Z variance train             0.013472214
KL Divergence                35.073185
KL Loss                      3.5073185
QF Loss                      299.46506
VF Loss                      174.56305
Policy Loss                  -776.86426
Q Predictions Mean           766.5794
Q Predictions Std            739.317
Q Predictions Max            2184.7747
Q Predictions Min            44.77331
V Predictions Mean           783.205
V Predictions Std            743.0344
V Predictions Max            2187.8677
V Predictions Min            38.266518
Log Pis Mean                 -1.187521
Log Pis Std                  3.8141181
Log Pis Max                  15.618246
Log Pis Min                  -9.7429
Policy mu Mean               -0.033216614
Policy mu Std                0.77083015
Policy mu Max                3.0505178
Policy mu Min                -3.2505
Policy log std Mean          -0.45530033
Policy log std Std           0.22809207
Policy log std Max           -0.1685845
Policy log std Min           -2.0226736
Z mean eval                  1.9959366
Z variance eval              0.011198312
total_rewards                [5136.6288537  5121.92056295 5185.09741802 5225.39496705 5070.79400524
 5254.81550699 5180.04705121 5205.42855253 5074.29492644 5227.75627187]
total_rewards_mean           5168.217811600034
total_rewards_std            61.300009268274074
total_rewards_max            5254.815506992342
total_rewards_min            5070.794005240026
Number of train steps total  184000
Number of env steps total    554000
Number of rollouts total     0
Train Time (s)               146.38729037716985
(Previous) Eval Time (s)     29.891559289302677
Sample Time (s)              10.316315712872893
Epoch Time (s)               186.59516537934542
Total Train Time (s)         8348.406463594642
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:10:27.820561 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #45 | Epoch Duration: 186.68300938606262
2020-01-13 06:10:27.820948 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9951019
Z variance train             0.011227387
KL Divergence                35.187634
KL Loss                      3.5187633
QF Loss                      177.42548
VF Loss                      75.05576
Policy Loss                  -779.0234
Q Predictions Mean           770.44763
Q Predictions Std            765.7434
Q Predictions Max            2302.1384
Q Predictions Min            35.769066
V Predictions Mean           781.68274
V Predictions Std            766.5565
V Predictions Max            2289.6772
V Predictions Min            44.110893
Log Pis Mean                 -1.101001
Log Pis Std                  3.7829368
Log Pis Max                  14.134817
Log Pis Min                  -7.4491644
Policy mu Mean               -0.055205733
Policy mu Std                0.75155884
Policy mu Max                2.3074992
Policy mu Min                -2.757326
Policy log std Mean          -0.45108792
Policy log std Std           0.24164055
Policy log std Max           -0.12751514
Policy log std Min           -2.287738
Z mean eval                  2.0252297
Z variance eval              0.010684384
total_rewards                [5586.96404037 5647.94146236 5657.92902475 5511.71519512 5593.56276381
 5481.37669242 5473.60572403 5644.93123478 5507.73958869 5453.95803264]
total_rewards_mean           5555.972375896872
total_rewards_std            74.95430447337071
total_rewards_max            5657.929024753799
total_rewards_min            5453.958032636678
Number of train steps total  188000
Number of env steps total    566000
Number of rollouts total     0
Train Time (s)               145.38473775284365
(Previous) Eval Time (s)     29.79464071802795
Sample Time (s)              10.364772672299296
Epoch Time (s)               185.5441511431709
Total Train Time (s)         8534.033692013007
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:33.449701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #46 | Epoch Duration: 185.6285116672516
2020-01-13 06:13:33.450022 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #46 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.022629
Z variance train             0.010740251
KL Divergence                35.947765
KL Loss                      3.5947766
QF Loss                      663.33624
VF Loss                      237.8605
Policy Loss                  -767.93353
Q Predictions Mean           762.2193
Q Predictions Std            735.24316
Q Predictions Max            2291.898
Q Predictions Min            36.065548
V Predictions Mean           761.3637
V Predictions Std            737.35
V Predictions Max            2268.31
V Predictions Min            34.546623
Log Pis Mean                 -1.4086276
Log Pis Std                  3.276019
Log Pis Max                  9.829756
Log Pis Min                  -6.0065937
Policy mu Mean               -0.009749838
Policy mu Std                0.7359832
Policy mu Max                2.714432
Policy mu Min                -3.1117702
Policy log std Mean          -0.44244492
Policy log std Std           0.2232737
Policy log std Max           -0.12022716
Policy log std Min           -2.0728297
Z mean eval                  2.0227783
Z variance eval              0.0122182965
total_rewards                [5905.37153623 5995.27921646 5741.05884778 6012.52774576 6206.1421376
 5906.27981982 6132.20205308 5979.78647092 5996.63591432 5998.34250131]
total_rewards_mean           5987.362624327927
total_rewards_std            119.9021897555574
total_rewards_max            6206.142137600635
total_rewards_min            5741.058847775811
Number of train steps total  192000
Number of env steps total    578000
Number of rollouts total     0
Train Time (s)               145.88038295600563
(Previous) Eval Time (s)     30.094539104029536
Sample Time (s)              8.615548849571496
Epoch Time (s)               184.59047090960667
Total Train Time (s)         8718.716361828614
Epoch                        47
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:16:38.133565 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #47 | Epoch Duration: 184.68335437774658
2020-01-13 06:16:38.133795 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.020514
Z variance train             0.012190766
KL Divergence                36.49637
KL Loss                      3.649637
QF Loss                      672.4306
VF Loss                      82.735016
Policy Loss                  -701.0707
Q Predictions Mean           688.7511
Q Predictions Std            708.65735
Q Predictions Max            2271.6125
Q Predictions Min            32.854378
V Predictions Mean           704.5564
V Predictions Std            711.8039
V Predictions Max            2281.5364
V Predictions Min            41.600475
Log Pis Mean                 -1.7622938
Log Pis Std                  3.2515333
Log Pis Max                  8.603565
Log Pis Min                  -9.376663
Policy mu Mean               0.02100342
Policy mu Std                0.6964792
Policy mu Max                2.602166
Policy mu Min                -4.0878415
Policy log std Mean          -0.43501893
Policy log std Std           0.21704914
Policy log std Max           -0.13475406
Policy log std Min           -2.1087604
Z mean eval                  2.0214353
Z variance eval              0.007575405
total_rewards                [5704.76426025 6042.72244848 5708.00278718 6018.5094497  6160.12235388
 5910.37081751 6006.93089241 5874.50881057 5951.32345422 5828.25646094]
total_rewards_mean           5920.5511735145465
total_rewards_std            138.8549765502233
total_rewards_max            6160.122353877564
total_rewards_min            5704.764260251925
Number of train steps total  196000
Number of env steps total    590000
Number of rollouts total     0
Train Time (s)               145.1507929409854
(Previous) Eval Time (s)     29.680855418089777
Sample Time (s)              9.939929692540318
Epoch Time (s)               184.7715780516155
Total Train Time (s)         8903.561380140949
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:19:42.986853 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #48 | Epoch Duration: 184.8529052734375
2020-01-13 06:19:42.987039 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #48 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.020366
Z variance train             0.0075940983
KL Divergence                37.225876
KL Loss                      3.7225876
QF Loss                      138.6568
VF Loss                      118.63945
Policy Loss                  -791.9998
Q Predictions Mean           784.7882
Q Predictions Std            780.82
Q Predictions Max            2317.0781
Q Predictions Min            29.061998
V Predictions Mean           791.0008
V Predictions Std            784.4512
V Predictions Max            2323.135
V Predictions Min            39.230427
Log Pis Mean                 -1.5225763
Log Pis Std                  3.376581
Log Pis Max                  10.226857
Log Pis Min                  -6.3134823
Policy mu Mean               0.02187184
Policy mu Std                0.7207163
Policy mu Max                2.457533
Policy mu Min                -2.486671
Policy log std Mean          -0.4383665
Policy log std Std           0.23262133
Policy log std Max           -0.06257227
Policy log std Min           -2.234241
Z mean eval                  1.9986794
Z variance eval              0.012147497
total_rewards                [4937.57589549 5424.41366842 5397.53097908 5603.00829508 5552.2801411
 5740.14147581 5427.60769725 5542.55120591 5375.32751268 5485.64379448]
total_rewards_mean           5448.608066530147
total_rewards_std            199.98379674786847
total_rewards_max            5740.14147581393
total_rewards_min            4937.575895488668
Number of train steps total  200000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               136.84946279413998
(Previous) Eval Time (s)     28.259859466925263
Sample Time (s)              9.960918233729899
Epoch Time (s)               175.07024049479514
Total Train Time (s)         9078.709592363331
Epoch                        49
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:22:38.136452 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #49 | Epoch Duration: 175.1492691040039
2020-01-13 06:22:38.136651 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9997886
Z variance train             0.012166022
KL Divergence                34.557003
KL Loss                      3.4557004
QF Loss                      300.1447
VF Loss                      117.547714
Policy Loss                  -709.0722
Q Predictions Mean           699.94525
Q Predictions Std            744.76697
Q Predictions Max            2273.5496
Q Predictions Min            39.53849
V Predictions Mean           707.1188
V Predictions Std            743.399
V Predictions Max            2262.2986
V Predictions Min            39.582207
Log Pis Mean                 -1.5905968
Log Pis Std                  3.557801
Log Pis Max                  18.643559
Log Pis Min                  -7.3986583
Policy mu Mean               -0.022298692
Policy mu Std                0.72428006
Policy mu Max                3.5669618
Policy mu Min                -3.6168427
Policy log std Mean          -0.43313673
Policy log std Std           0.22697999
Policy log std Max           -0.1456872
Policy log std Min           -2.1493595
Z mean eval                  2.0200567
Z variance eval              0.022085
total_rewards                [6196.12090309 6327.35218959 6192.16531401 6374.31732235 6415.13280655
 6425.11530134 6509.86579824 6401.25520093 6241.30025099 3649.88368891]
total_rewards_mean           6073.25087760102
total_rewards_std            813.8984298711019
total_rewards_max            6509.8657982385575
total_rewards_min            3649.883688909649
Number of train steps total  204000
Number of env steps total    614000
Number of rollouts total     0
Train Time (s)               136.49422949412838
(Previous) Eval Time (s)     28.590703245718032
Sample Time (s)              9.858901346568018
Epoch Time (s)               174.94383408641443
Total Train Time (s)         9253.73437367659
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:25:33.162655 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #50 | Epoch Duration: 175.0258595943451
2020-01-13 06:25:33.162842 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0228329
Z variance train             0.022205295
KL Divergence                34.83658
KL Loss                      3.4836578
QF Loss                      238.09766
VF Loss                      134.26517
Policy Loss                  -773.56476
Q Predictions Mean           765.28455
Q Predictions Std            775.1428
Q Predictions Max            2357.061
Q Predictions Min            29.248209
V Predictions Mean           770.372
V Predictions Std            771.3907
V Predictions Max            2362.0613
V Predictions Min            31.201408
Log Pis Mean                 -1.1980177
Log Pis Std                  3.9365504
Log Pis Max                  21.077526
Log Pis Min                  -7.0957804
Policy mu Mean               -0.04984587
Policy mu Std                0.76138204
Policy mu Max                4.1796007
Policy mu Min                -3.1591907
Policy log std Mean          -0.45645896
Policy log std Std           0.23393579
Policy log std Max           -0.061897874
Policy log std Min           -2.0190425
Z mean eval                  2.0216248
Z variance eval              0.012937794
total_rewards                [5616.30520717 5802.79707214 5698.42690402 5974.3138509  5605.38547804
 1193.45023746 6100.34024832 6094.67375726 5705.02182129 5626.82307114]
total_rewards_mean           5341.7537647744575
total_rewards_std            1394.588878844147
total_rewards_max            6100.34024831757
total_rewards_min            1193.4502374642677
Number of train steps total  208000
Number of env steps total    626000
Number of rollouts total     0
Train Time (s)               141.50344343297184
(Previous) Eval Time (s)     30.107366323005408
Sample Time (s)              8.209112584590912
Epoch Time (s)               179.81992234056816
Total Train Time (s)         9433.635950988159
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:28:33.065871 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #51 | Epoch Duration: 179.9028856754303
2020-01-13 06:28:33.066070 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.020715
Z variance train             0.012893537
KL Divergence                36.347546
KL Loss                      3.6347547
QF Loss                      264.14468
VF Loss                      131.97061
Policy Loss                  -793.7319
Q Predictions Mean           785.55115
Q Predictions Std            778.5765
Q Predictions Max            2386.1743
Q Predictions Min            39.65179
V Predictions Mean           802.04895
V Predictions Std            778.99536
V Predictions Max            2394.6665
V Predictions Min            26.23598
Log Pis Mean                 -1.36414
Log Pis Std                  3.4621432
Log Pis Max                  15.368341
Log Pis Min                  -8.164765
Policy mu Mean               4.2557716e-05
Policy mu Std                0.733253
Policy mu Max                2.6704123
Policy mu Min                -3.1985502
Policy log std Mean          -0.45124778
Policy log std Std           0.24137267
Policy log std Max           -0.14931118
Policy log std Min           -2.226027
Z mean eval                  2.011811
Z variance eval              0.024778197
total_rewards                [6255.57402531 6350.06137658 6383.70941585 6458.70815181 6144.06044722
 6326.90801051 6264.44217686 6635.03739276 6368.93525968 6388.10820033]
total_rewards_mean           6357.554445690354
total_rewards_std            124.34666609675156
total_rewards_max            6635.03739275713
total_rewards_min            6144.060447219421
Number of train steps total  212000
Number of env steps total    638000
Number of rollouts total     0
Train Time (s)               146.00531670963392
(Previous) Eval Time (s)     30.054063067305833
Sample Time (s)              10.064983546268195
Epoch Time (s)               186.12436332320794
Total Train Time (s)         9619.853362502996
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:31:39.285283 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #52 | Epoch Duration: 186.21905398368835
2020-01-13 06:31:39.285522 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0130982
Z variance train             0.024825275
KL Divergence                36.523193
KL Loss                      3.6523194
QF Loss                      177.52187
VF Loss                      65.01386
Policy Loss                  -719.1867
Q Predictions Mean           710.6627
Q Predictions Std            766.6698
Q Predictions Max            2394.4631
Q Predictions Min            28.318262
V Predictions Mean           719.22375
V Predictions Std            769.8434
V Predictions Max            2401.3123
V Predictions Min            37.287132
Log Pis Mean                 -1.4834121
Log Pis Std                  3.5309596
Log Pis Max                  23.326643
Log Pis Min                  -5.845746
Policy mu Mean               0.012658595
Policy mu Std                0.7435501
Policy mu Max                3.588356
Policy mu Min                -3.3916745
Policy log std Mean          -0.4346198
Policy log std Std           0.21300694
Policy log std Max           -0.14701214
Policy log std Min           -1.9203289
Z mean eval                  2.0847006
Z variance eval              0.015446501
total_rewards                [6025.52523882 5983.95081071 6296.63738066 6105.82708826 6011.73232854
 6152.8257387  6061.46131356 6280.25019008 6105.77763339 6104.7717107 ]
total_rewards_mean           6112.875943343587
total_rewards_std            100.33417752075411
total_rewards_max            6296.637380658303
total_rewards_min            5983.950810714743
Number of train steps total  216000
Number of env steps total    650000
Number of rollouts total     0
Train Time (s)               145.7795650921762
(Previous) Eval Time (s)     27.729448957834393
Sample Time (s)              10.250517348293215
Epoch Time (s)               183.7595313983038
Total Train Time (s)         9803.918827573303
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:34:43.351919 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #53 | Epoch Duration: 184.06622123718262
2020-01-13 06:34:43.352123 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.079867
Z variance train             0.015394999
KL Divergence                35.514133
KL Loss                      3.5514133
QF Loss                      537.34106
VF Loss                      83.23999
Policy Loss                  -715.6819
Q Predictions Mean           713.14355
Q Predictions Std            740.8512
Q Predictions Max            2413.464
Q Predictions Min            37.475346
V Predictions Mean           718.9589
V Predictions Std            742.64606
V Predictions Max            2404.3345
V Predictions Min            29.783394
Log Pis Mean                 -1.3223438
Log Pis Std                  3.7855055
Log Pis Max                  16.112503
Log Pis Min                  -8.583845
Policy mu Mean               0.014840692
Policy mu Std                0.743543
Policy mu Max                2.9102461
Policy mu Min                -2.5136375
Policy log std Mean          -0.4404409
Policy log std Std           0.23722972
Policy log std Max           -0.13505581
Policy log std Min           -2.199373
Z mean eval                  2.0024207
Z variance eval              0.015083341
total_rewards                [6009.66442587 6092.00307437 6009.16927719 6124.67009831 5935.03373819
 5964.27323624 5841.73725813 5781.12302662 5912.0799988  5958.66268148]
total_rewards_mean           5962.841681520826
total_rewards_std            99.12981984924888
total_rewards_max            6124.670098313331
total_rewards_min            5781.123026622072
Number of train steps total  220000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               146.5333203957416
(Previous) Eval Time (s)     30.662334742955863
Sample Time (s)              10.043531232513487
Epoch Time (s)               187.23918637121096
Total Train Time (s)         9991.322638502344
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:37:50.757399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #54 | Epoch Duration: 187.40513134002686
2020-01-13 06:37:50.757597 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.001494
Z variance train             0.015063735
KL Divergence                35.826508
KL Loss                      3.582651
QF Loss                      588.49646
VF Loss                      95.29492
Policy Loss                  -750.9711
Q Predictions Mean           742.3648
Q Predictions Std            772.2203
Q Predictions Max            2526.168
Q Predictions Min            23.207182
V Predictions Mean           752.2582
V Predictions Std            780.677
V Predictions Max            2521.678
V Predictions Min            29.817118
Log Pis Mean                 -1.3247252
Log Pis Std                  3.7245533
Log Pis Max                  17.207088
Log Pis Min                  -6.634151
Policy mu Mean               -0.024117835
Policy mu Std                0.74851793
Policy mu Max                3.1816857
Policy mu Min                -2.7364032
Policy log std Mean          -0.45783707
Policy log std Std           0.25216967
Policy log std Max           -0.14771533
Policy log std Min           -2.2913451
Z mean eval                  2.0410383
Z variance eval              0.010049472
total_rewards                [5607.26902556 5644.62454966 2118.43142305 2211.704396   5642.01568762
 5734.70921207 5941.78518451 5570.69501941 5462.08998715 5887.03560918]
total_rewards_mean           4982.036009421957
total_rewards_std            1415.0658113794118
total_rewards_max            5941.785184507168
total_rewards_min            2118.4314230524674
Number of train steps total  224000
Number of env steps total    674000
Number of rollouts total     0
Train Time (s)               144.9160492317751
(Previous) Eval Time (s)     29.940693771932274
Sample Time (s)              10.105729040689766
Epoch Time (s)               184.96247204439715
Total Train Time (s)         10176.36445143586
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:40:55.800550 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #55 | Epoch Duration: 185.04280805587769
2020-01-13 06:40:55.800744 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0399833
Z variance train             0.010072621
KL Divergence                37.29926
KL Loss                      3.7299259
QF Loss                      211.71658
VF Loss                      38.691998
Policy Loss                  -782.91907
Q Predictions Mean           774.9159
Q Predictions Std            794.50305
Q Predictions Max            2414.2388
Q Predictions Min            23.070051
V Predictions Mean           783.19855
V Predictions Std            798.3661
V Predictions Max            2421.9614
V Predictions Min            40.185593
Log Pis Mean                 -1.7102668
Log Pis Std                  3.2495668
Log Pis Max                  13.61177
Log Pis Min                  -7.509185
Policy mu Mean               -0.054950777
Policy mu Std                0.7219232
Policy mu Max                2.9777331
Policy mu Min                -2.9590662
Policy log std Mean          -0.43351316
Policy log std Std           0.20816247
Policy log std Max           -0.15943322
Policy log std Min           -2.354859
Z mean eval                  2.0726452
Z variance eval              0.011493018
total_rewards                [6213.39579829 6324.62065921 6359.92668939 6333.07425372 6195.67253832
 6127.12646183 6513.2713117  6203.19302294 6370.03561885 6209.13818508]
total_rewards_mean           6284.945453930175
total_rewards_std            109.2299251039626
total_rewards_max            6513.2713116959685
total_rewards_min            6127.126461826021
Number of train steps total  228000
Number of env steps total    686000
Number of rollouts total     0
Train Time (s)               136.65489468770102
(Previous) Eval Time (s)     29.311760658863932
Sample Time (s)              9.249615291599184
Epoch Time (s)               175.21627063816413
Total Train Time (s)         10351.663042532746
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:43:51.101207 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #56 | Epoch Duration: 175.30029845237732
2020-01-13 06:43:51.101513 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0752823
Z variance train             0.011493772
KL Divergence                37.084053
KL Loss                      3.7084053
QF Loss                      320.82874
VF Loss                      91.77863
Policy Loss                  -731.3432
Q Predictions Mean           724.66394
Q Predictions Std            782.56775
Q Predictions Max            2488.246
Q Predictions Min            12.080773
V Predictions Mean           733.37854
V Predictions Std            789.5003
V Predictions Max            2488.1099
V Predictions Min            27.999922
Log Pis Mean                 -1.5012782
Log Pis Std                  3.4209752
Log Pis Max                  10.709225
Log Pis Min                  -8.692492
Policy mu Mean               0.02107889
Policy mu Std                0.7494929
Policy mu Max                2.923206
Policy mu Min                -3.4715009
Policy log std Mean          -0.43566823
Policy log std Std           0.22600444
Policy log std Max           -0.1626581
Policy log std Min           -2.1621392
Z mean eval                  2.0319107
Z variance eval              0.011216151
total_rewards                [6323.27529509 6233.79883859 6426.09091679 6376.95310045 6175.77442611
 6253.84257941 6189.84438361 6216.26680382 6310.02100532 6291.14173983]
total_rewards_mean           6279.700908901015
total_rewards_std            77.14363167085715
total_rewards_max            6426.090916786859
total_rewards_min            6175.7744261058015
Number of train steps total  232000
Number of env steps total    698000
Number of rollouts total     0
Train Time (s)               136.54908023308963
(Previous) Eval Time (s)     29.112394374795258
Sample Time (s)              9.713238656055182
Epoch Time (s)               175.37471326394007
Total Train Time (s)         10527.118064801209
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:46:46.557518 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #57 | Epoch Duration: 175.45578575134277
2020-01-13 06:46:46.557734 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0309176
Z variance train             0.011210425
KL Divergence                37.552868
KL Loss                      3.755287
QF Loss                      765.89966
VF Loss                      113.75896
Policy Loss                  -870.97235
Q Predictions Mean           864.92725
Q Predictions Std            830.0247
Q Predictions Max            2484.472
Q Predictions Min            1.4011962
V Predictions Mean           875.3922
V Predictions Std            830.66425
V Predictions Max            2474.3567
V Predictions Min            5.7734723
Log Pis Mean                 -0.49818736
Log Pis Std                  4.3156123
Log Pis Max                  22.120754
Log Pis Min                  -5.668517
Policy mu Mean               -0.0032747108
Policy mu Std                0.85680974
Policy mu Max                3.2178266
Policy mu Min                -3.9606266
Policy log std Mean          -0.4664111
Policy log std Std           0.24193934
Policy log std Max           -0.09159917
Policy log std Min           -2.087293
Z mean eval                  2.0310092
Z variance eval              0.101059236
total_rewards                [6245.2245674  6348.32517433 6341.11839365 6332.01283946 6395.87450023
 6334.89580136 6289.00459752 6202.61758663 6251.49971547 6226.43935613]
total_rewards_mean           6296.7012532182125
total_rewards_std            59.765971385092044
total_rewards_max            6395.874500234962
total_rewards_min            6202.617586634584
Number of train steps total  236000
Number of env steps total    710000
Number of rollouts total     0
Train Time (s)               141.60514053795487
(Previous) Eval Time (s)     30.621792658697814
Sample Time (s)              9.757855520118028
Epoch Time (s)               181.9847887167707
Total Train Time (s)         10709.18862709403
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:49:48.629377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #58 | Epoch Duration: 182.07149171829224
2020-01-13 06:49:48.629576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0341835
Z variance train             0.100820564
KL Divergence                32.55957
KL Loss                      3.2559571
QF Loss                      215.61174
VF Loss                      85.60598
Policy Loss                  -900.8065
Q Predictions Mean           890.8659
Q Predictions Std            880.4361
Q Predictions Max            2577.471
Q Predictions Min            7.570378
V Predictions Mean           896.32605
V Predictions Std            879.7057
V Predictions Max            2581.0115
V Predictions Min            21.164135
Log Pis Mean                 -1.2818806
Log Pis Std                  3.4292347
Log Pis Max                  17.136395
Log Pis Min                  -6.3677235
Policy mu Mean               -0.10774199
Policy mu Std                0.77872866
Policy mu Max                3.4362895
Policy mu Min                -4.063019
Policy log std Mean          -0.45525658
Policy log std Std           0.23672932
Policy log std Max           -0.094130754
Policy log std Min           -2.107652
Z mean eval                  2.0841107
Z variance eval              0.019792726
total_rewards                [5995.95094864 6304.12952301 6265.00543231 5991.71055564 6204.25930113
 6233.23377586 6441.06292188 6240.76505834 6203.43652506 6401.27111282]
total_rewards_mean           6228.08251546927
total_rewards_std            139.1475883332303
total_rewards_max            6441.062921881841
total_rewards_min            5991.710555637286
Number of train steps total  240000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               146.80725737893954
(Previous) Eval Time (s)     30.090622069779783
Sample Time (s)              9.617476588115096
Epoch Time (s)               186.51535603683442
Total Train Time (s)         10895.783924493473
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:52:55.226191 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #59 | Epoch Duration: 186.5964720249176
2020-01-13 06:52:55.226382 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0853515
Z variance train             0.019811848
KL Divergence                34.170506
KL Loss                      3.4170506
QF Loss                      751.3261
VF Loss                      62.373405
Policy Loss                  -771.0377
Q Predictions Mean           765.3185
Q Predictions Std            806.8498
Q Predictions Max            2498.7222
Q Predictions Min            14.610027
V Predictions Mean           770.515
V Predictions Std            807.965
V Predictions Max            2498.4827
V Predictions Min            23.997192
Log Pis Mean                 -1.2919998
Log Pis Std                  3.6155052
Log Pis Max                  16.01455
Log Pis Min                  -7.4917984
Policy mu Mean               0.040800486
Policy mu Std                0.76959974
Policy mu Max                2.6661005
Policy mu Min                -2.931451
Policy log std Mean          -0.44043204
Policy log std Std           0.24020322
Policy log std Max           -0.06021738
Policy log std Min           -2.3952565
Z mean eval                  2.0630558
Z variance eval              0.026995635
total_rewards                [6370.1920269  6146.16146701 6249.23076618 6164.1191507  5848.06748432
 6191.88025358 5754.76411196 6168.98222234 6300.02597081 6119.03227351]
total_rewards_mean           6131.24557272978
total_rewards_std            181.10322929855212
total_rewards_max            6370.192026897823
total_rewards_min            5754.764111957032
Number of train steps total  244000
Number of env steps total    734000
Number of rollouts total     0
Train Time (s)               146.3035283833742
(Previous) Eval Time (s)     29.670186700765043
Sample Time (s)              10.22651551431045
Epoch Time (s)               186.2002305984497
Total Train Time (s)         11082.146471789572
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:56:01.589267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #60 | Epoch Duration: 186.36274981498718
2020-01-13 06:56:01.589416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.067231
Z variance train             0.026877647
KL Divergence                34.368607
KL Loss                      3.4368608
QF Loss                      225.0141
VF Loss                      157.39056
Policy Loss                  -780.4479
Q Predictions Mean           774.26764
Q Predictions Std            816.712
Q Predictions Max            2592.868
Q Predictions Min            8.497872
V Predictions Mean           771.391
V Predictions Std            815.8172
V Predictions Max            2572.148
V Predictions Min            24.295061
Log Pis Mean                 -1.123083
Log Pis Std                  3.7649522
Log Pis Max                  22.64935
Log Pis Min                  -7.9086943
Policy mu Mean               -0.028985629
Policy mu Std                0.76789945
Policy mu Max                3.153464
Policy mu Min                -3.719109
Policy log std Mean          -0.42850134
Policy log std Std           0.22554928
Policy log std Max           -0.07855612
Policy log std Min           -2.2403002
Z mean eval                  2.0211747
Z variance eval              0.018558025
total_rewards                [6433.3849868  6360.93778705 6417.65578558 6349.74203388 6542.80815699
 6311.56601459 6285.4622675  6301.87403421 6690.16385276 6407.95818502]
total_rewards_mean           6410.155310437165
total_rewards_std            118.18097622325108
total_rewards_max            6690.16385275586
total_rewards_min            6285.462267498598
Number of train steps total  248000
Number of env steps total    746000
Number of rollouts total     0
Train Time (s)               147.1963484417647
(Previous) Eval Time (s)     30.253149345051497
Sample Time (s)              10.38230992294848
Epoch Time (s)               187.8318077097647
Total Train Time (s)         11270.05816411553
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:59:09.504453 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #61 | Epoch Duration: 187.91487550735474
2020-01-13 06:59:09.504700 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0219684
Z variance train             0.018581294
KL Divergence                34.45094
KL Loss                      3.4450939
QF Loss                      878.1045
VF Loss                      85.503685
Policy Loss                  -731.6569
Q Predictions Mean           726.3269
Q Predictions Std            777.0303
Q Predictions Max            2540.7393
Q Predictions Min            13.938679
V Predictions Mean           730.9416
V Predictions Std            782.4795
V Predictions Max            2550.2869
V Predictions Min            22.52729
Log Pis Mean                 -1.5788031
Log Pis Std                  3.2153296
Log Pis Max                  10.207809
Log Pis Min                  -7.1961718
Policy mu Mean               0.0153930085
Policy mu Std                0.6979507
Policy mu Max                3.0012193
Policy mu Min                -2.6345224
Policy log std Mean          -0.43904033
Policy log std Std           0.22110085
Policy log std Max           -0.12390125
Policy log std Min           -2.2432415
Z mean eval                  2.0845323
Z variance eval              0.022334734
total_rewards                [6366.61701621 6384.11024446 6568.73303968 6295.42817957 6102.76233589
 6183.61101141 6330.61750433 6171.23505039 6264.14353238 6184.54369322]
total_rewards_mean           6285.180160754356
total_rewards_std            128.89422545269178
total_rewards_max            6568.733039680914
total_rewards_min            6102.762335892759
Number of train steps total  252000
Number of env steps total    758000
Number of rollouts total     0
Train Time (s)               145.5235785022378
(Previous) Eval Time (s)     29.591422019992024
Sample Time (s)              9.253565735649318
Epoch Time (s)               184.36856625787914
Total Train Time (s)         11454.50898807589
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:02:13.956100 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #62 | Epoch Duration: 184.45122504234314
2020-01-13 07:02:13.956302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0824246
Z variance train             0.022309205
KL Divergence                36.19129
KL Loss                      3.6191292
QF Loss                      322.16986
VF Loss                      70.66058
Policy Loss                  -807.82043
Q Predictions Mean           798.75244
Q Predictions Std            850.1262
Q Predictions Max            2629.7883
Q Predictions Min            15.207573
V Predictions Mean           810.43176
V Predictions Std            849.1843
V Predictions Max            2633.8652
V Predictions Min            23.480202
Log Pis Mean                 -1.3488173
Log Pis Std                  3.5960279
Log Pis Max                  16.258965
Log Pis Min                  -8.409865
Policy mu Mean               0.038637545
Policy mu Std                0.771289
Policy mu Max                3.528965
Policy mu Min                -3.12379
Policy log std Mean          -0.44522572
Policy log std Std           0.2243221
Policy log std Max           -0.16598448
Policy log std Min           -1.9016123
Z mean eval                  2.0575664
Z variance eval              0.010132386
total_rewards                [6132.84645368 6366.42455312 6116.25993302 6399.38152619 6435.38697597
 6074.41544407 6125.11308572 6290.26757432 6428.52856672 6094.38175663]
total_rewards_mean           6246.300586945788
total_rewards_std            143.4747337144928
total_rewards_max            6435.386975974041
total_rewards_min            6074.415444071763
Number of train steps total  256000
Number of env steps total    770000
Number of rollouts total     0
Train Time (s)               137.21608006302267
(Previous) Eval Time (s)     29.720430211164057
Sample Time (s)              9.89917317731306
Epoch Time (s)               176.8356834514998
Total Train Time (s)         11631.435193000827
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:05:10.884768 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #63 | Epoch Duration: 176.92829942703247
2020-01-13 07:05:10.884971 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0587547
Z variance train             0.010155772
KL Divergence                36.21942
KL Loss                      3.6219423
QF Loss                      350.5406
VF Loss                      69.47083
Policy Loss                  -849.3924
Q Predictions Mean           842.1324
Q Predictions Std            860.4691
Q Predictions Max            2566.3105
Q Predictions Min            27.225986
V Predictions Mean           850.25104
V Predictions Std            855.89294
V Predictions Max            2549.6206
V Predictions Min            18.834291
Log Pis Mean                 -1.4086952
Log Pis Std                  3.2453396
Log Pis Max                  14.813059
Log Pis Min                  -6.4579306
Policy mu Mean               -0.0577248
Policy mu Std                0.7476513
Policy mu Max                2.4120786
Policy mu Min                -2.8667145
Policy log std Mean          -0.44939974
Policy log std Std           0.22550818
Policy log std Max           -0.1722877
Policy log std Min           -2.1234238
Z mean eval                  2.0970235
Z variance eval              0.009141954
total_rewards                [6813.19063628 6496.18668873 6573.46624873 6507.26001662 6440.65337778
 6462.32074609 6370.5955731  6446.04585438 6593.72901707 6757.03985634]
total_rewards_mean           6546.048801512634
total_rewards_std            134.83356852011465
total_rewards_max            6813.190636281009
total_rewards_min            6370.59557309754
Number of train steps total  260000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               136.8551266877912
(Previous) Eval Time (s)     28.946287341881543
Sample Time (s)              9.329092440195382
Epoch Time (s)               175.13050646986812
Total Train Time (s)         11806.647242192179
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:08:06.098032 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #64 | Epoch Duration: 175.21290016174316
2020-01-13 07:08:06.098255 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.097899
Z variance train             0.009149035
KL Divergence                37.78331
KL Loss                      3.778331
QF Loss                      731.89276
VF Loss                      70.59705
Policy Loss                  -836.2
Q Predictions Mean           829.17035
Q Predictions Std            858.44446
Q Predictions Max            2690.2883
Q Predictions Min            11.755645
V Predictions Mean           836.34296
V Predictions Std            861.8573
V Predictions Max            2688.2659
V Predictions Min            19.816572
Log Pis Mean                 -1.4623241
Log Pis Std                  3.2128038
Log Pis Max                  11.183438
Log Pis Min                  -6.821582
Policy mu Mean               -0.09639517
Policy mu Std                0.7436377
Policy mu Max                2.5424304
Policy mu Min                -3.4023108
Policy log std Mean          -0.44705358
Policy log std Std           0.23831262
Policy log std Max           -0.17251745
Policy log std Min           -1.8957052
Z mean eval                  2.0977204
Z variance eval              0.008191605
total_rewards                [5612.61133237 5857.92466128 5997.70710036 5853.44185776 5771.17277938
 5807.62818952 5911.30532305 5990.87683841 5808.12703633 5913.56048911]
total_rewards_mean           5852.435560757928
total_rewards_std            107.51423265077445
total_rewards_max            5997.707100363842
total_rewards_min            5612.611332372267
Number of train steps total  264000
Number of env steps total    794000
Number of rollouts total     0
Train Time (s)               142.88722837343812
(Previous) Eval Time (s)     30.58816342614591
Sample Time (s)              9.553132633678615
Epoch Time (s)               183.02852443326265
Total Train Time (s)         11989.77243155893
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:11:09.225288 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #65 | Epoch Duration: 183.1268548965454
2020-01-13 07:11:09.225522 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0980892
Z variance train             0.008169186
KL Divergence                37.021835
KL Loss                      3.7021835
QF Loss                      242.921
VF Loss                      101.806595
Policy Loss                  -808.25806
Q Predictions Mean           801.36475
Q Predictions Std            844.2115
Q Predictions Max            2601.8503
Q Predictions Min            27.310837
V Predictions Mean           803.95905
V Predictions Std            845.62274
V Predictions Max            2587.27
V Predictions Min            25.614859
Log Pis Mean                 -1.4002728
Log Pis Std                  3.3946464
Log Pis Max                  11.336259
Log Pis Min                  -5.9935427
Policy mu Mean               -0.053187817
Policy mu Std                0.74165964
Policy mu Max                2.9654157
Policy mu Min                -2.8074777
Policy log std Mean          -0.43778172
Policy log std Std           0.22546455
Policy log std Max           -0.11639367
Policy log std Min           -2.2684927
Z mean eval                  2.0876184
Z variance eval              0.016662026
total_rewards                [6360.07636812 6505.3540382  6449.05345397 6699.85198675 6458.85734186
 6452.14763292 6344.38639216 6404.10236575 6427.14408154 6687.89964141]
total_rewards_mean           6478.887330268617
total_rewards_std            116.48819084300024
total_rewards_max            6699.851986745947
total_rewards_min            6344.386392160023
Number of train steps total  268000
Number of env steps total    806000
Number of rollouts total     0
Train Time (s)               146.8734187236987
(Previous) Eval Time (s)     30.47038916684687
Sample Time (s)              10.475639813113958
Epoch Time (s)               187.81944770365953
Total Train Time (s)         12177.674428273924
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:14:17.128399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #66 | Epoch Duration: 187.9026997089386
2020-01-13 07:14:17.128601 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #66 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0879111
Z variance train             0.016592646
KL Divergence                35.975502
KL Loss                      3.5975502
QF Loss                      394.7705
VF Loss                      212.69884
Policy Loss                  -781.58484
Q Predictions Mean           775.0259
Q Predictions Std            826.3335
Q Predictions Max            2626.0715
Q Predictions Min            1.3439921
V Predictions Mean           789.65076
V Predictions Std            830.18256
V Predictions Max            2642.961
V Predictions Min            -1.2743202
Log Pis Mean                 -1.0049441
Log Pis Std                  4.1029935
Log Pis Max                  29.4178
Log Pis Min                  -6.3625846
Policy mu Mean               -0.037278686
Policy mu Std                0.7849453
Policy mu Max                3.766023
Policy mu Min                -4.378941
Policy log std Mean          -0.4545412
Policy log std Std           0.23014368
Policy log std Max           -0.16515332
Policy log std Min           -2.2658677
Z mean eval                  2.1196606
Z variance eval              0.030474503
total_rewards                [6484.79431641 6443.5368431  6531.01526325 6247.27149829 6260.2987938
 6400.69096296 6723.45823186 6621.85864955 6545.54292361 6588.96921251]
total_rewards_mean           6484.743669534025
total_rewards_std            144.22798981346327
total_rewards_max            6723.45823185709
total_rewards_min            6247.271498287647
Number of train steps total  272000
Number of env steps total    818000
Number of rollouts total     0
Train Time (s)               146.02240215800703
(Previous) Eval Time (s)     28.665760532952845
Sample Time (s)              10.138199139852077
Epoch Time (s)               184.82636183081195
Total Train Time (s)         12362.581625858322
Epoch                        67
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:17:22.037375 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #67 | Epoch Duration: 184.90862584114075
2020-01-13 07:17:22.037582 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.123031
Z variance train             0.030573254
KL Divergence                34.447403
KL Loss                      3.4447403
QF Loss                      308.62152
VF Loss                      321.8829
Policy Loss                  -856.62836
Q Predictions Mean           845.5367
Q Predictions Std            843.5463
Q Predictions Max            2630.4436
Q Predictions Min            18.243519
V Predictions Mean           864.38586
V Predictions Std            853.7292
V Predictions Max            2671.7188
V Predictions Min            29.57282
Log Pis Mean                 -0.82533944
Log Pis Std                  4.4015236
Log Pis Max                  27.680353
Log Pis Min                  -7.2369275
Policy mu Mean               -0.027511457
Policy mu Std                0.8367875
Policy mu Max                3.466505
Policy mu Min                -3.752751
Policy log std Mean          -0.45784363
Policy log std Std           0.22754945
Policy log std Max           -0.17017949
Policy log std Min           -2.1027927
Z mean eval                  2.0819879
Z variance eval              0.03330638
total_rewards                [6574.58632018 6595.58962956 6799.62688276 6643.38593174 6637.76132859
 6530.70301412 6619.98852944 6800.95030599 6877.44161103 6348.59684261]
total_rewards_mean           6642.863039603161
total_rewards_std            145.3313759312994
total_rewards_max            6877.441611033236
total_rewards_min            6348.596842605074
Number of train steps total  276000
Number of env steps total    830000
Number of rollouts total     0
Train Time (s)               147.89630915923044
(Previous) Eval Time (s)     30.448077380657196
Sample Time (s)              10.302103366702795
Epoch Time (s)               188.64648990659043
Total Train Time (s)         12551.310798921622
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:20:30.773052 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #68 | Epoch Duration: 188.73532056808472
2020-01-13 07:20:30.773334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0812538
Z variance train             0.033280134
KL Divergence                33.456295
KL Loss                      3.3456295
QF Loss                      353.64917
VF Loss                      95.30408
Policy Loss                  -779.6816
Q Predictions Mean           773.2162
Q Predictions Std            830.7581
Q Predictions Max            2661.9802
Q Predictions Min            18.905039
V Predictions Mean           785.7062
V Predictions Std            831.7262
V Predictions Max            2656.8967
V Predictions Min            19.61838
Log Pis Mean                 -0.99311787
Log Pis Std                  3.9309545
Log Pis Max                  24.429218
Log Pis Min                  -6.563342
Policy mu Mean               -0.01312505
Policy mu Std                0.7650897
Policy mu Max                3.1983604
Policy mu Min                -4.321917
Policy log std Mean          -0.45243225
Policy log std Std           0.2481923
Policy log std Max           -0.12100753
Policy log std Min           -2.205553
Z mean eval                  2.1139324
Z variance eval              0.011336083
total_rewards                [6608.76528687 6593.85894023 6341.15303118 6488.10640037 6673.50829262
 6489.17226835 6328.09197035 6442.03726463 6730.65654861 6453.46375924]
total_rewards_mean           6514.881376244128
total_rewards_std            127.39746220389581
total_rewards_max            6730.6565486055
total_rewards_min            6328.0919703521695
Number of train steps total  280000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               145.71024894108996
(Previous) Eval Time (s)     28.347351814154536
Sample Time (s)              10.079691198654473
Epoch Time (s)               184.13729195389897
Total Train Time (s)         12735.533161858562
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:23:34.992235 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #69 | Epoch Duration: 184.21867203712463
2020-01-13 07:23:34.992440 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #69 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1124444
Z variance train             0.011336419
KL Divergence                37.875526
KL Loss                      3.7875526
QF Loss                      276.01514
VF Loss                      94.648834
Policy Loss                  -864.4716
Q Predictions Mean           855.6941
Q Predictions Std            884.8962
Q Predictions Max            2686.0486
Q Predictions Min            -22.247665
V Predictions Mean           861.6914
V Predictions Std            885.81714
V Predictions Max            2677.923
V Predictions Min            -4.853763
Log Pis Mean                 -0.8568133
Log Pis Std                  3.9086823
Log Pis Max                  17.933487
Log Pis Min                  -6.284458
Policy mu Mean               0.029262086
Policy mu Std                0.80626285
Policy mu Max                3.0108733
Policy mu Min                -3.509879
Policy log std Mean          -0.4636415
Policy log std Std           0.22356936
Policy log std Max           -0.15024126
Policy log std Min           -1.9933683
Z mean eval                  2.0911803
Z variance eval              0.012289772
total_rewards                [6203.38445153 6482.69394202 6399.91858511 6347.11918706 6489.9626014
 6421.59437013 6430.93969376 6340.91328639 6362.4993399  6495.93792081]
total_rewards_mean           6397.49633781233
total_rewards_std            84.76328256675062
total_rewards_max            6495.937920809328
total_rewards_min            6203.384451530085
Number of train steps total  284000
Number of env steps total    854000
Number of rollouts total     0
Train Time (s)               136.9689394137822
(Previous) Eval Time (s)     28.54556140722707
Sample Time (s)              9.672037093434483
Epoch Time (s)               175.18653791444376
Total Train Time (s)         12910.810417836998
Epoch                        70
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:26:30.271698 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #70 | Epoch Duration: 175.27910327911377
2020-01-13 07:26:30.271918 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0899749
Z variance train             0.012307909
KL Divergence                38.619167
KL Loss                      3.8619168
QF Loss                      232.86732
VF Loss                      108.915855
Policy Loss                  -903.5672
Q Predictions Mean           897.1828
Q Predictions Std            922.0072
Q Predictions Max            2724.7188
Q Predictions Min            -9.4624
V Predictions Mean           903.60724
V Predictions Std            923.8631
V Predictions Max            2747.462
V Predictions Min            0.38629067
Log Pis Mean                 -1.0423926
Log Pis Std                  3.5040038
Log Pis Max                  10.858874
Log Pis Min                  -6.455991
Policy mu Mean               -0.031762745
Policy mu Std                0.80567884
Policy mu Max                2.7344728
Policy mu Min                -3.0028439
Policy log std Mean          -0.47408858
Policy log std Std           0.24076946
Policy log std Max           -0.14937961
Policy log std Min           -2.10766
Z mean eval                  2.110599
Z variance eval              0.012153321
total_rewards                [6150.29913438 5852.29309285 5986.84198943 5972.75356448 5960.02535079
 6073.42077258 4364.24970351  801.68215146 5812.72922746 5773.51656389]
total_rewards_mean           5274.781155083609
total_rewards_std            1567.7193655078597
total_rewards_max            6150.299134382287
total_rewards_min            801.6821514613205
Number of train steps total  288000
Number of env steps total    866000
Number of rollouts total     0
Train Time (s)               137.14946652762592
(Previous) Eval Time (s)     29.63227978302166
Sample Time (s)              9.713988360017538
Epoch Time (s)               176.49573467066512
Total Train Time (s)         13087.38766539609
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:29:26.849933 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #71 | Epoch Duration: 176.57785654067993
2020-01-13 07:29:26.850128 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1086354
Z variance train             0.012157956
KL Divergence                38.719612
KL Loss                      3.8719614
QF Loss                      436.4615
VF Loss                      96.89441
Policy Loss                  -751.9231
Q Predictions Mean           742.3923
Q Predictions Std            845.91693
Q Predictions Max            2778.2952
Q Predictions Min            13.757522
V Predictions Mean           752.8681
V Predictions Std            852.3013
V Predictions Max            2789.9126
V Predictions Min            13.964774
Log Pis Mean                 -1.1267648
Log Pis Std                  3.6889517
Log Pis Max                  20.19771
Log Pis Min                  -6.084217
Policy mu Mean               -0.07314942
Policy mu Std                0.7564247
Policy mu Max                2.9918113
Policy mu Min                -3.3133438
Policy log std Mean          -0.44740438
Policy log std Std           0.21413617
Policy log std Max           -0.13953781
Policy log std Min           -1.9615941
Z mean eval                  2.1063764
Z variance eval              0.0114703765
total_rewards                [6384.61311199 6313.08888656 6090.02418263 6405.65340391 2538.25239238
 6391.77191916 6179.58686901 6373.68625657 6167.08784955 6490.53658773]
total_rewards_mean           5933.430145948703
total_rewards_std            1138.0647859613425
total_rewards_max            6490.536587731553
total_rewards_min            2538.252392376063
Number of train steps total  292000
Number of env steps total    878000
Number of rollouts total     0
Train Time (s)               142.91108814440668
(Previous) Eval Time (s)     28.806983451824635
Sample Time (s)              9.76675279578194
Epoch Time (s)               181.48482439201325
Total Train Time (s)         13268.967613958754
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:32:28.432586 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #72 | Epoch Duration: 181.58228158950806
2020-01-13 07:32:28.432935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.103329
Z variance train             0.011470596
KL Divergence                39.949986
KL Loss                      3.9949987
QF Loss                      299.96375
VF Loss                      46.19597
Policy Loss                  -780.39355
Q Predictions Mean           772.00476
Q Predictions Std            860.889
Q Predictions Max            2736.397
Q Predictions Min            13.141107
V Predictions Mean           778.73145
V Predictions Std            860.34906
V Predictions Max            2738.055
V Predictions Min            10.566427
Log Pis Mean                 -1.5203233
Log Pis Std                  3.2201877
Log Pis Max                  10.739794
Log Pis Min                  -6.266714
Policy mu Mean               0.03097452
Policy mu Std                0.72115916
Policy mu Max                2.6327868
Policy mu Min                -2.38406
Policy log std Mean          -0.446349
Policy log std Std           0.23033412
Policy log std Max           -0.07541394
Policy log std Min           -2.0123277
Z mean eval                  2.2019203
Z variance eval              0.006598731
total_rewards                [5685.33022337 5752.43233413 5746.61372629 6120.38280041 5594.96967253
 5863.12899693 5843.73921492 5656.52283544 6078.00148747 6082.30178236]
total_rewards_mean           5842.342307385193
total_rewards_std            181.23989848999764
total_rewards_max            6120.3828004148145
total_rewards_min            5594.969672534106
Number of train steps total  296000
Number of env steps total    890000
Number of rollouts total     0
Train Time (s)               147.21350488904864
(Previous) Eval Time (s)     29.390954123344272
Sample Time (s)              9.87610414205119
Epoch Time (s)               186.4805631544441
Total Train Time (s)         13455.533374398481
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:35:34.999999 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #73 | Epoch Duration: 186.56684565544128
2020-01-13 07:35:35.000226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.209863
Z variance train             0.0065701036
KL Divergence                41.257305
KL Loss                      4.1257305
QF Loss                      494.68982
VF Loss                      82.483734
Policy Loss                  -833.2441
Q Predictions Mean           832.93164
Q Predictions Std            875.6959
Q Predictions Max            2761.9998
Q Predictions Min            6.910645
V Predictions Mean           833.2639
V Predictions Std            877.1724
V Predictions Max            2727.815
V Predictions Min            13.022754
Log Pis Mean                 -1.0802882
Log Pis Std                  3.791965
Log Pis Max                  20.252258
Log Pis Min                  -8.098682
Policy mu Mean               -0.09928683
Policy mu Std                0.7807346
Policy mu Max                2.7686079
Policy mu Min                -3.0948822
Policy log std Mean          -0.4460752
Policy log std Std           0.21414821
Policy log std Max           -0.05368632
Policy log std Min           -1.7591075
Z mean eval                  2.0730557
Z variance eval              0.01591972
total_rewards                [6608.70319722 6700.53359986 6691.97239184 6617.70517186 6561.22800561
 6655.18526714 6240.93455113 6667.174275   6614.32987328 6464.25433616]
total_rewards_mean           6582.202066907799
total_rewards_std            131.3045207358823
total_rewards_max            6700.533599855802
total_rewards_min            6240.934551134966
Number of train steps total  300000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               145.8157407878898
(Previous) Eval Time (s)     29.4497754490003
Sample Time (s)              10.13529523415491
Epoch Time (s)               185.40081147104502
Total Train Time (s)         13641.206930060871
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:38:40.675126 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #74 | Epoch Duration: 185.67473220825195
2020-01-13 07:38:40.675378 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0720563
Z variance train             0.015931606
KL Divergence                39.25828
KL Loss                      3.9258282
QF Loss                      768.62946
VF Loss                      107.2471
Policy Loss                  -797.45734
Q Predictions Mean           795.4379
Q Predictions Std            871.58325
Q Predictions Max            2750.6804
Q Predictions Min            5.0575905
V Predictions Mean           796.62946
V Predictions Std            874.47656
V Predictions Max            2749.2815
V Predictions Min            9.657604
Log Pis Mean                 -1.3079457
Log Pis Std                  3.2226787
Log Pis Max                  10.540916
Log Pis Min                  -6.4716883
Policy mu Mean               0.03928903
Policy mu Std                0.74910116
Policy mu Max                2.6906693
Policy mu Min                -2.3988044
Policy log std Mean          -0.4526156
Policy log std Std           0.23830636
Policy log std Max           -0.14509493
Policy log std Min           -2.0055928
Z mean eval                  2.143462
Z variance eval              0.016688589
total_rewards                [6620.28095832 6771.85029657 6769.25175108 6577.25861626 6908.34864686
 6691.70096844 6857.7844319  6868.67820502 6851.25722309 7083.35809743]
total_rewards_mean           6799.976919497541
total_rewards_std            140.74568323231924
total_rewards_max            7083.358097429029
total_rewards_min            6577.2586162588395
Number of train steps total  304000
Number of env steps total    914000
Number of rollouts total     0
Train Time (s)               148.00684638507664
(Previous) Eval Time (s)     29.34542348328978
Sample Time (s)              10.326973338611424
Epoch Time (s)               187.67924320697784
Total Train Time (s)         13828.968359329738
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:41:48.438248 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #75 | Epoch Duration: 187.76271796226501
2020-01-13 07:41:48.438454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1395898
Z variance train             0.016732372
KL Divergence                38.970016
KL Loss                      3.8970017
QF Loss                      877.72095
VF Loss                      82.382034
Policy Loss                  -837.6265
Q Predictions Mean           827.8145
Q Predictions Std            898.2625
Q Predictions Max            2726.7603
Q Predictions Min            10.481644
V Predictions Mean           834.7314
V Predictions Std            898.7692
V Predictions Max            2730.8262
V Predictions Min            -1.3769736
Log Pis Mean                 -1.127365
Log Pis Std                  3.7420564
Log Pis Max                  17.902077
Log Pis Min                  -8.899679
Policy mu Mean               0.073464006
Policy mu Std                0.788701
Policy mu Max                3.1921813
Policy mu Min                -2.9769986
Policy log std Mean          -0.45739627
Policy log std Std           0.2331701
Policy log std Max           -0.09977648
Policy log std Min           -2.1605384
Z mean eval                  2.0641928
Z variance eval              0.06708085
total_rewards                [6214.36897143 5669.39823858 5765.49412968 5832.8219851  5852.78544472
 6364.67133025 5883.30894144 5837.10794745 6041.61427083 6074.70498434]
total_rewards_mean           5953.627624380475
total_rewards_std            204.64838401163718
total_rewards_max            6364.671330249783
total_rewards_min            5669.398238581793
Number of train steps total  308000
Number of env steps total    926000
Number of rollouts total     0
Train Time (s)               146.52410517586395
(Previous) Eval Time (s)     28.66956129297614
Sample Time (s)              9.95577214146033
Epoch Time (s)               185.14943861030042
Total Train Time (s)         14014.204332933761
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:44:53.676132 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #76 | Epoch Duration: 185.23752117156982
2020-01-13 07:44:53.676359 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #76 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0644054
Z variance train             0.066518344
KL Divergence                35.79416
KL Loss                      3.579416
QF Loss                      171.58041
VF Loss                      50.042686
Policy Loss                  -726.89386
Q Predictions Mean           721.94104
Q Predictions Std            819.93304
Q Predictions Max            2721.839
Q Predictions Min            2.5528169
V Predictions Mean           724.61365
V Predictions Std            819.848
V Predictions Max            2721.6008
V Predictions Min            4.0663843
Log Pis Mean                 -1.6259139
Log Pis Std                  3.5123205
Log Pis Max                  18.46413
Log Pis Min                  -6.4318104
Policy mu Mean               -0.028187266
Policy mu Std                0.72614163
Policy mu Max                2.910152
Policy mu Min                -2.9961596
Policy log std Mean          -0.44800767
Policy log std Std           0.20380548
Policy log std Max           -0.12269321
Policy log std Min           -2.0781476
Z mean eval                  2.1072514
Z variance eval              0.015229335
total_rewards                [6768.98923571 6817.78914042 6929.05379255 7041.63428851 6890.5130514
 6659.74979526 7025.77260893 6902.78564708 7065.6143337  6851.65417242]
total_rewards_mean           6895.35560659754
total_rewards_std            121.66069006327372
total_rewards_max            7065.6143336975565
total_rewards_min            6659.749795255695
Number of train steps total  312000
Number of env steps total    938000
Number of rollouts total     0
Train Time (s)               137.5395537437871
(Previous) Eval Time (s)     28.78566810907796
Sample Time (s)              9.78655539918691
Epoch Time (s)               176.11177725205198
Total Train Time (s)         14190.404832569417
Epoch                        77
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:47:49.879403 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #77 | Epoch Duration: 176.20281863212585
2020-01-13 07:47:49.879726 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.107661
Z variance train             0.015274493
KL Divergence                37.65572
KL Loss                      3.765572
QF Loss                      181.3273
VF Loss                      89.70382
Policy Loss                  -914.85864
Q Predictions Mean           906.50146
Q Predictions Std            924.31604
Q Predictions Max            2795.6897
Q Predictions Min            -22.110786
V Predictions Mean           912.4735
V Predictions Std            922.78845
V Predictions Max            2783.6497
V Predictions Min            1.1185127
Log Pis Mean                 -0.77952594
Log Pis Std                  4.045228
Log Pis Max                  14.842594
Log Pis Min                  -9.918242
Policy mu Mean               0.037626714
Policy mu Std                0.8306497
Policy mu Max                2.819519
Policy mu Min                -2.546375
Policy log std Mean          -0.4650805
Policy log std Std           0.22881065
Policy log std Max           -0.12167463
Policy log std Min           -2.2754438
Z mean eval                  2.0753872
Z variance eval              0.040185064
total_rewards                [5803.57520441 5966.75826069 5956.83319298 5880.86742794 6059.51509992
 5855.99083142 6183.19682482 6104.92850497 5837.64320624 6003.51029711]
total_rewards_mean           5965.28188504977
total_rewards_std            117.86177821871243
total_rewards_max            6183.196824818563
total_rewards_min            5803.575204410383
Number of train steps total  316000
Number of env steps total    950000
Number of rollouts total     0
Train Time (s)               137.6191544481553
(Previous) Eval Time (s)     28.547579146921635
Sample Time (s)              10.003092363476753
Epoch Time (s)               176.1698259585537
Total Train Time (s)         14366.656896264758
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:50:46.133109 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #78 | Epoch Duration: 176.25318360328674
2020-01-13 07:50:46.133354 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.075023
Z variance train             0.04035277
KL Divergence                34.725437
KL Loss                      3.4725437
QF Loss                      256.9309
VF Loss                      139.7943
Policy Loss                  -858.60016
Q Predictions Mean           856.4757
Q Predictions Std            913.4222
Q Predictions Max            2845.8606
Q Predictions Min            -5.727179
V Predictions Mean           863.5735
V Predictions Std            911.33044
V Predictions Max            2831.8708
V Predictions Min            -10.161127
Log Pis Mean                 -1.1151247
Log Pis Std                  3.5725782
Log Pis Max                  11.242191
Log Pis Min                  -6.9923887
Policy mu Mean               -0.016199965
Policy mu Std                0.77404904
Policy mu Max                2.9752784
Policy mu Min                -2.544873
Policy log std Mean          -0.46372736
Policy log std Std           0.2517232
Policy log std Max           -0.11322236
Policy log std Min           -2.2262397
Z mean eval                  2.1234295
Z variance eval              0.028355395
total_rewards                [6402.81937198 6947.56546644 7035.77767899 6706.96743263 6625.81093428
 7040.94206924 6974.44433398 6872.53979186 6689.49328334 6702.60963842]
total_rewards_mean           6799.897000116094
total_rewards_std            197.37235366918458
total_rewards_max            7040.942069237025
total_rewards_min            6402.819371982405
Number of train steps total  320000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               143.87163301184773
(Previous) Eval Time (s)     31.03043479193002
Sample Time (s)              9.789462517015636
Epoch Time (s)               184.6915303207934
Total Train Time (s)         14551.705746451393
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:53:51.184632 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #79 | Epoch Duration: 185.051020860672
2020-01-13 07:53:51.184981 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1226258
Z variance train             0.028382689
KL Divergence                35.845955
KL Loss                      3.5845954
QF Loss                      190.48853
VF Loss                      48.90324
Policy Loss                  -894.4213
Q Predictions Mean           892.14014
Q Predictions Std            914.0419
Q Predictions Max            2864.5193
Q Predictions Min            -22.006582
V Predictions Mean           893.37585
V Predictions Std            912.39575
V Predictions Max            2847.3186
V Predictions Min            -19.865715
Log Pis Mean                 -1.010568
Log Pis Std                  3.3458807
Log Pis Max                  12.43478
Log Pis Min                  -6.000437
Policy mu Mean               0.014524044
Policy mu Std                0.7957377
Policy mu Max                2.4158564
Policy mu Min                -2.430751
Policy log std Mean          -0.47428903
Policy log std Std           0.21037886
Policy log std Max           0.10106343
Policy log std Min           -1.7857852
Z mean eval                  2.1216083
Z variance eval              0.017464476
total_rewards                [6602.20704266 6572.65354004 6762.0458665  6566.67012461 6207.67577564
 6590.84794882 6765.7775252  6923.97348763 6727.19029189 6546.1354046 ]
total_rewards_mean           6626.517700757911
total_rewards_std            180.72420684969654
total_rewards_max            6923.973487626854
total_rewards_min            6207.675775642939
Number of train steps total  324000
Number of env steps total    974000
Number of rollouts total     0
Train Time (s)               146.3639643918723
(Previous) Eval Time (s)     29.45736665278673
Sample Time (s)              9.355880638118833
Epoch Time (s)               185.17721168277785
Total Train Time (s)         14736.965306313708
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:56:56.445137 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #80 | Epoch Duration: 185.25994229316711
2020-01-13 07:56:56.445338 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1216648
Z variance train             0.017448038
KL Divergence                36.828815
KL Loss                      3.6828816
QF Loss                      344.6653
VF Loss                      71.737724
Policy Loss                  -871.1462
Q Predictions Mean           862.0591
Q Predictions Std            887.08295
Q Predictions Max            2811.7422
Q Predictions Min            -16.467
V Predictions Mean           869.47327
V Predictions Std            892.29266
V Predictions Max            2808.5542
V Predictions Min            -2.2316785
Log Pis Mean                 -1.19888
Log Pis Std                  3.7101643
Log Pis Max                  22.482307
Log Pis Min                  -8.784005
Policy mu Mean               0.03867738
Policy mu Std                0.7993944
Policy mu Max                3.6879964
Policy mu Min                -3.1515384
Policy log std Mean          -0.4596672
Policy log std Std           0.23741831
Policy log std Max           -0.07823227
Policy log std Min           -2.0651965
Z mean eval                  2.1415844
Z variance eval              0.020922218
total_rewards                [6996.4425789  6949.29640345 6723.05136449 6953.84236433 7014.61045066
 6969.66433945 6795.00308255 6810.96162126 7077.3095489  6902.5360303 ]
total_rewards_mean           6919.271778427581
total_rewards_std            105.17275337230262
total_rewards_max            7077.30954889602
total_rewards_min            6723.051364487596
Number of train steps total  328000
Number of env steps total    986000
Number of rollouts total     0
Train Time (s)               146.5783069645986
(Previous) Eval Time (s)     29.705738943070173
Sample Time (s)              10.142988996580243
Epoch Time (s)               186.427034904249
Total Train Time (s)         14923.472778168973
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:00:02.955334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #81 | Epoch Duration: 186.5098376274109
2020-01-13 08:00:02.955559 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1385903
Z variance train             0.020840166
KL Divergence                38.191593
KL Loss                      3.8191593
QF Loss                      301.6637
VF Loss                      201.78592
Policy Loss                  -938.6257
Q Predictions Mean           933.34937
Q Predictions Std            965.8454
Q Predictions Max            2803.867
Q Predictions Min            212.04608
V Predictions Mean           943.14844
V Predictions Std            973.2076
V Predictions Max            2817.1025
V Predictions Min            224.27473
Log Pis Mean                 -0.7894893
Log Pis Std                  3.7080758
Log Pis Max                  17.465088
Log Pis Min                  -7.4430103
Policy mu Mean               -0.08491242
Policy mu Std                0.815066
Policy mu Max                3.6227384
Policy mu Min                -3.5572686
Policy log std Mean          -0.48050177
Policy log std Std           0.23806494
Policy log std Max           -0.16177145
Policy log std Min           -2.2461364
Z mean eval                  2.1197398
Z variance eval              0.012035527
total_rewards                [6827.15052324 6663.65946145 6977.37095269 6740.52078231 6735.57066738
 6633.30794612 6769.89049036 6471.24163853 6632.44932568 6753.43980066]
total_rewards_mean           6720.460158842526
total_rewards_std            127.36772174006553
total_rewards_max            6977.370952693733
total_rewards_min            6471.241638526632
Number of train steps total  332000
Number of env steps total    998000
Number of rollouts total     0
Train Time (s)               147.92764376895502
(Previous) Eval Time (s)     29.64452743716538
Sample Time (s)              9.964282738044858
Epoch Time (s)               187.53645394416526
Total Train Time (s)         15111.094883355778
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:03:10.578939 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #82 | Epoch Duration: 187.6232078075409
2020-01-13 08:03:10.579139 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1182537
Z variance train             0.011981698
KL Divergence                39.790783
KL Loss                      3.9790783
QF Loss                      160.92587
VF Loss                      68.45426
Policy Loss                  -697.1734
Q Predictions Mean           689.7821
Q Predictions Std            778.19977
Q Predictions Max            2776.0764
Q Predictions Min            -9.571152
V Predictions Mean           697.35864
V Predictions Std            781.98096
V Predictions Max            2760.876
V Predictions Min            1.2414672
Log Pis Mean                 -1.5832491
Log Pis Std                  3.035222
Log Pis Max                  11.2933035
Log Pis Min                  -8.788147
Policy mu Mean               0.014168147
Policy mu Std                0.7278374
Policy mu Max                2.8008378
Policy mu Min                -2.4588666
Policy log std Mean          -0.44744968
Policy log std Std           0.21207964
Policy log std Max           -0.16043182
Policy log std Min           -2.0622003
Z mean eval                  2.109975
Z variance eval              0.010242576
total_rewards                [5734.20343909 5474.66967979 6420.02040381 6159.00268084 5525.19729515
 6159.72393784 5470.41125458 5802.34217127 6103.89223156 6262.39720046]
total_rewards_mean           5911.186029437973
total_rewards_std            334.5994057918568
total_rewards_max            6420.020403807021
total_rewards_min            5470.411254575778
Number of train steps total  336000
Number of env steps total    1010000
Number of rollouts total     0
Train Time (s)               146.25258690817282
(Previous) Eval Time (s)     28.68271677568555
Sample Time (s)              10.177431489806622
Epoch Time (s)               185.112735173665
Total Train Time (s)         15296.286340100225
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:06:15.772033 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #83 | Epoch Duration: 185.19273400306702
2020-01-13 08:06:15.772227 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1084397
Z variance train             0.010212548
KL Divergence                40.43563
KL Loss                      4.0435634
QF Loss                      897.2361
VF Loss                      70.74095
Policy Loss                  -867.486
Q Predictions Mean           860.54944
Q Predictions Std            898.9669
Q Predictions Max            2871.3274
Q Predictions Min            5.695102
V Predictions Mean           869.2261
V Predictions Std            899.2529
V Predictions Max            2865.252
V Predictions Min            1.4953486
Log Pis Mean                 -1.0312836
Log Pis Std                  3.6679192
Log Pis Max                  18.604095
Log Pis Min                  -8.241976
Policy mu Mean               -0.048197523
Policy mu Std                0.8103704
Policy mu Max                3.876639
Policy mu Min                -4.00885
Policy log std Mean          -0.4684472
Policy log std Std           0.22988404
Policy log std Max           -0.14874804
Policy log std Min           -2.1250706
Z mean eval                  2.1369581
Z variance eval              0.016321678
total_rewards                [6836.21575625 6880.85842947 7015.23551172 6823.89357003 6696.15423733
 6946.51118131 7275.34876948 7014.45433019 7012.48330028 7010.96090499]
total_rewards_mean           6951.211599104031
total_rewards_std            148.306323250736
total_rewards_max            7275.348769477548
total_rewards_min            6696.154237328006
Number of train steps total  340000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               137.40736260218546
(Previous) Eval Time (s)     28.615891305729747
Sample Time (s)              9.719627189449966
Epoch Time (s)               175.74288109736517
Total Train Time (s)         15472.110885482747
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:09:11.598192 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #84 | Epoch Duration: 175.82582998275757
2020-01-13 08:09:11.598371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1338294
Z variance train             0.016360752
KL Divergence                38.32895
KL Loss                      3.832895
QF Loss                      1862.0471
VF Loss                      262.69125
Policy Loss                  -923.9741
Q Predictions Mean           915.4725
Q Predictions Std            921.4901
Q Predictions Max            2809.2964
Q Predictions Min            -10.709495
V Predictions Mean           927.8811
V Predictions Std            924.6102
V Predictions Max            2818.6338
V Predictions Min            2.1767378
Log Pis Mean                 -0.5816431
Log Pis Std                  3.9373446
Log Pis Max                  20.615225
Log Pis Min                  -6.5302267
Policy mu Mean               -7.990593e-05
Policy mu Std                0.8264314
Policy mu Max                2.7736273
Policy mu Min                -3.870148
Policy log std Mean          -0.48921403
Policy log std Std           0.23188251
Policy log std Max           -0.13026576
Policy log std Min           -2.2231758
Z mean eval                  2.168918
Z variance eval              0.013807083
total_rewards                [6978.07765734 6776.51978848 6795.56337341 6863.01494642 6860.04579974
 6811.89162482 6639.8372295  6697.84733067 7049.4402147  6822.05698843]
total_rewards_mean           6829.429495349478
total_rewards_std            114.07616258427103
total_rewards_max            7049.440214699176
total_rewards_min            6639.837229500642
Number of train steps total  344000
Number of env steps total    1034000
Number of rollouts total     0
Train Time (s)               137.90662700822577
(Previous) Eval Time (s)     28.86975440196693
Sample Time (s)              9.748807264026254
Epoch Time (s)               176.52518867421895
Total Train Time (s)         15648.717366035096
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:12:08.208135 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #85 | Epoch Duration: 176.6096019744873
2020-01-13 08:12:08.208437 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.171674
Z variance train             0.013835764
KL Divergence                39.17444
KL Loss                      3.917444
QF Loss                      436.05994
VF Loss                      81.8331
Policy Loss                  -740.81586
Q Predictions Mean           734.6778
Q Predictions Std            863.06635
Q Predictions Max            2844.4124
Q Predictions Min            1.6617168
V Predictions Mean           741.424
V Predictions Std            861.75006
V Predictions Max            2823.7427
V Predictions Min            10.274017
Log Pis Mean                 -1.4432409
Log Pis Std                  3.1989067
Log Pis Max                  13.319553
Log Pis Min                  -7.650645
Policy mu Mean               -0.012385174
Policy mu Std                0.73886806
Policy mu Max                2.9070382
Policy mu Min                -2.585845
Policy log std Mean          -0.44474602
Policy log std Std           0.22066075
Policy log std Max           -0.154584
Policy log std Min           -2.2033162
Z mean eval                  2.1572373
Z variance eval              0.011007262
total_rewards                [4887.73730186 4793.55914394 4557.09011792 5575.98292293 5189.97839945
 4662.33818539 4782.8255905  5174.67742085 1149.41279729 5245.43552819]
total_rewards_mean           4601.903740831568
total_rewards_std            1187.9976657783843
total_rewards_max            5575.982922927902
total_rewards_min            1149.4127972865256
Number of train steps total  348000
Number of env steps total    1046000
Number of rollouts total     0
Train Time (s)               144.6358111090958
(Previous) Eval Time (s)     28.72180488705635
Sample Time (s)              9.555418741423637
Epoch Time (s)               182.9130347375758
Total Train Time (s)         15831.710077526513
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:15:11.201313 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #86 | Epoch Duration: 182.992693901062
2020-01-13 08:15:11.201467 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #86 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1598763
Z variance train             0.010987815
KL Divergence                39.18953
KL Loss                      3.918953
QF Loss                      326.682
VF Loss                      109.606705
Policy Loss                  -826.69867
Q Predictions Mean           817.6255
Q Predictions Std            884.91547
Q Predictions Max            2856.5112
Q Predictions Min            -13.055023
V Predictions Mean           821.452
V Predictions Std            885.272
V Predictions Max            2839.4236
V Predictions Min            1.7300992
Log Pis Mean                 -1.1384351
Log Pis Std                  3.1626904
Log Pis Max                  11.743075
Log Pis Min                  -6.2654033
Policy mu Mean               -0.07074263
Policy mu Std                0.7696405
Policy mu Max                2.648986
Policy mu Min                -2.3790786
Policy log std Mean          -0.46211067
Policy log std Std           0.20692372
Policy log std Max           -0.17911112
Policy log std Min           -2.0891018
Z mean eval                  2.1379528
Z variance eval              0.017911403
total_rewards                [6310.76729872 5924.17167274 5544.07142647 5983.89202361 5920.3459984
 5992.03628072 5936.79647409 6044.83854255 5853.810492   6533.73788779]
total_rewards_mean           6004.446809708288
total_rewards_std            250.78271582436304
total_rewards_max            6533.737887790943
total_rewards_min            5544.071426468975
Number of train steps total  352000
Number of env steps total    1058000
Number of rollouts total     0
Train Time (s)               146.68573481589556
(Previous) Eval Time (s)     30.516102810855955
Sample Time (s)              10.559965161141008
Epoch Time (s)               187.76180278789252
Total Train Time (s)         16019.561457824428
Epoch                        87
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:18:19.055366 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #87 | Epoch Duration: 187.85377311706543
2020-01-13 08:18:19.055597 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1386607
Z variance train             0.017831381
KL Divergence                37.763424
KL Loss                      3.7763424
QF Loss                      282.00436
VF Loss                      127.74231
Policy Loss                  -844.9407
Q Predictions Mean           837.93176
Q Predictions Std            917.1455
Q Predictions Max            2848.1787
Q Predictions Min            7.4304175
V Predictions Mean           842.7115
V Predictions Std            915.7265
V Predictions Max            2830.4111
V Predictions Min            5.429343
Log Pis Mean                 -0.7708367
Log Pis Std                  3.9747198
Log Pis Max                  17.395409
Log Pis Min                  -7.302376
Policy mu Mean               0.011534912
Policy mu Std                0.83221835
Policy mu Max                3.2145493
Policy mu Min                -3.407707
Policy log std Mean          -0.48480198
Policy log std Std           0.24387099
Policy log std Max           -0.1726312
Policy log std Min           -2.409352
Z mean eval                  2.1508892
Z variance eval              0.013806468
total_rewards                [6925.65874547 7364.69096567 6988.98311765 6945.28778225 7352.53377367
 6958.50251423 7011.55919971 7056.43211887 7142.99352774 7123.93733755]
total_rewards_mean           7087.05790828099
total_rewards_std            151.97961762894417
total_rewards_max            7364.690965667184
total_rewards_min            6925.658745467878
Number of train steps total  356000
Number of env steps total    1070000
Number of rollouts total     0
Train Time (s)               146.8011883702129
(Previous) Eval Time (s)     30.274173467885703
Sample Time (s)              9.494975087232888
Epoch Time (s)               186.5703369253315
Total Train Time (s)         16206.212696733419
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:21:25.709067 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #88 | Epoch Duration: 186.65330338478088
2020-01-13 08:21:25.709283 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.151824
Z variance train             0.013827667
KL Divergence                39.204407
KL Loss                      3.9204407
QF Loss                      645.071
VF Loss                      201.73352
Policy Loss                  -786.49243
Q Predictions Mean           774.5729
Q Predictions Std            891.9523
Q Predictions Max            2786.0803
Q Predictions Min            0.15568978
V Predictions Mean           777.1234
V Predictions Std            889.7269
V Predictions Max            2774.6106
V Predictions Min            9.530337
Log Pis Mean                 -1.0299344
Log Pis Std                  3.657962
Log Pis Max                  13.3240185
Log Pis Min                  -7.6611466
Policy mu Mean               -0.008356319
Policy mu Std                0.79738975
Policy mu Max                2.9893312
Policy mu Min                -3.5325544
Policy log std Mean          -0.46186915
Policy log std Std           0.2177811
Policy log std Max           -0.099464804
Policy log std Min           -1.8418865
Z mean eval                  2.16768
Z variance eval              0.0068011954
total_rewards                [6960.83601041 6937.72564689 7043.93048779 6986.43408723 7131.79656546
 6996.45175634 6873.46045076 7044.20799741 6906.59396595 6798.60198155]
total_rewards_mean           6968.003894979532
total_rewards_std            90.51171515686276
total_rewards_max            7131.7965654612135
total_rewards_min            6798.601981554777
Number of train steps total  360000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               148.12755434261635
(Previous) Eval Time (s)     30.120596444234252
Sample Time (s)              10.270863976795226
Epoch Time (s)               188.51901476364583
Total Train Time (s)         16394.840090105776
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:24:34.338527 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #89 | Epoch Duration: 188.62905144691467
2020-01-13 08:24:34.338817 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #89 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1668532
Z variance train             0.0068083317
KL Divergence                41.099834
KL Loss                      4.1099834
QF Loss                      364.66406
VF Loss                      285.66946
Policy Loss                  -816.9397
Q Predictions Mean           809.7075
Q Predictions Std            906.44293
Q Predictions Max            2863.0542
Q Predictions Min            -6.3987455
V Predictions Mean           820.44995
V Predictions Std            912.0888
V Predictions Max            2884.876
V Predictions Min            -0.10938877
Log Pis Mean                 -1.0049229
Log Pis Std                  3.310014
Log Pis Max                  13.308472
Log Pis Min                  -7.98476
Policy mu Mean               0.01475931
Policy mu Std                0.7848655
Policy mu Max                3.3948786
Policy mu Min                -3.490846
Policy log std Mean          -0.46094832
Policy log std Std           0.21848713
Policy log std Max           -0.1586433
Policy log std Min           -2.2828865
Z mean eval                  2.1345382
Z variance eval              0.012528298
total_rewards                [7085.42798699 7103.37531195 7329.76854166 6952.98157225 7148.3228971
 7097.27037763 7040.95037432 7196.7974443  7202.05135806 7275.11130073]
total_rewards_mean           7143.205716499884
total_rewards_std            105.94432585538485
total_rewards_max            7329.7685416585355
total_rewards_min            6952.981572253309
Number of train steps total  364000
Number of env steps total    1094000
Number of rollouts total     0
Train Time (s)               144.69379201019183
(Previous) Eval Time (s)     29.30580636765808
Sample Time (s)              10.274700044188648
Epoch Time (s)               184.27429842203856
Total Train Time (s)         16579.195167525206
Epoch                        90
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:27:38.695197 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #90 | Epoch Duration: 184.35618019104004
2020-01-13 08:27:38.695424 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.138411
Z variance train             0.012501249
KL Divergence                40.487377
KL Loss                      4.048738
QF Loss                      276.9211
VF Loss                      87.644966
Policy Loss                  -804.57904
Q Predictions Mean           802.58093
Q Predictions Std            902.3791
Q Predictions Max            2856.3003
Q Predictions Min            -19.35761
V Predictions Mean           804.3336
V Predictions Std            901.41895
V Predictions Max            2836.0928
V Predictions Min            -13.099412
Log Pis Mean                 -0.9297917
Log Pis Std                  3.389282
Log Pis Max                  20.230879
Log Pis Min                  -7.311487
Policy mu Mean               -0.042041466
Policy mu Std                0.80900997
Policy mu Max                3.7501395
Policy mu Min                -3.701105
Policy log std Mean          -0.47735092
Policy log std Std           0.22686651
Policy log std Max           -0.13402021
Policy log std Min           -2.250983
Z mean eval                  2.1857212
Z variance eval              0.055604927
total_rewards                [6937.5337121  6875.66141863 7020.71995699 6930.23561153 6983.42251508
 7111.37589811 7279.01367092 7171.01548756 7119.39004132 6955.89643425]
total_rewards_mean           7038.426474648465
total_rewards_std            120.77499850087408
total_rewards_max            7279.0136709210265
total_rewards_min            6875.661418628235
Number of train steps total  368000
Number of env steps total    1106000
Number of rollouts total     0
Train Time (s)               137.98790862364694
(Previous) Eval Time (s)     29.742380713112652
Sample Time (s)              9.477267762646079
Epoch Time (s)               177.20755709940568
Total Train Time (s)         16756.48143596109
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:30:35.983089 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #91 | Epoch Duration: 177.28750324249268
2020-01-13 08:30:35.983302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1846573
Z variance train             0.055136513
KL Divergence                38.37542
KL Loss                      3.837542
QF Loss                      135.26628
VF Loss                      38.963406
Policy Loss                  -658.5161
Q Predictions Mean           651.61395
Q Predictions Std            789.0112
Q Predictions Max            2965.503
Q Predictions Min            -9.541314
V Predictions Mean           658.6643
V Predictions Std            791.47595
V Predictions Max            2960.3972
V Predictions Min            -5.4580736
Log Pis Mean                 -1.1080592
Log Pis Std                  3.7707863
Log Pis Max                  13.166012
Log Pis Min                  -7.4634247
Policy mu Mean               0.02935552
Policy mu Std                0.7731495
Policy mu Max                2.8673892
Policy mu Min                -2.4333496
Policy log std Mean          -0.45267895
Policy log std Std           0.20616364
Policy log std Max           -0.15514876
Policy log std Min           -2.3126714
Z mean eval                  2.191526
Z variance eval              0.022609407
total_rewards                [7141.90851416 7259.24869322 7355.56017724 7160.39183817 7209.98816067
 7012.83256864 7026.38848544 7076.46386673 7509.79976675 7177.27503462]
total_rewards_mean           7192.985710564292
total_rewards_std            144.6328681522298
total_rewards_max            7509.799766751789
total_rewards_min            7012.832568635219
Number of train steps total  372000
Number of env steps total    1118000
Number of rollouts total     0
Train Time (s)               137.29667988512665
(Previous) Eval Time (s)     29.788107856176794
Sample Time (s)              9.44582693791017
Epoch Time (s)               176.5306146792136
Total Train Time (s)         16933.117551984265
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:33:32.621171 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #92 | Epoch Duration: 176.6377203464508
2020-01-13 08:33:32.621373 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #92 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1919131
Z variance train             0.022719514
KL Divergence                38.569588
KL Loss                      3.8569589
QF Loss                      289.72598
VF Loss                      67.08942
Policy Loss                  -780.08685
Q Predictions Mean           776.72253
Q Predictions Std            904.9005
Q Predictions Max            3008.444
Q Predictions Min            -20.92029
V Predictions Mean           775.7489
V Predictions Std            904.14465
V Predictions Max            3002.8552
V Predictions Min            -24.526348
Log Pis Mean                 -1.1202036
Log Pis Std                  3.6495695
Log Pis Max                  13.801452
Log Pis Min                  -6.590475
Policy mu Mean               0.013944048
Policy mu Std                0.7895491
Policy mu Max                2.9705224
Policy mu Min                -3.3228776
Policy log std Mean          -0.46897343
Policy log std Std           0.22618952
Policy log std Max           -0.09771299
Policy log std Min           -2.18535
Z mean eval                  2.153774
Z variance eval              0.014937038
total_rewards                [7195.55806288 7513.21930672 7336.97534537 7310.26055201 7301.5804041
 7322.92983398 7404.19521699 7372.29985199 7554.05333195 7356.3562823 ]
total_rewards_mean           7366.742818828321
total_rewards_std            98.80704441526524
total_rewards_max            7554.053331948682
total_rewards_min            7195.558062876313
Number of train steps total  376000
Number of env steps total    1130000
Number of rollouts total     0
Train Time (s)               145.7833464546129
(Previous) Eval Time (s)     31.05979442410171
Sample Time (s)              10.034471673890948
Epoch Time (s)               186.87761255260557
Total Train Time (s)         17120.077132986393
Epoch                        93
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:36:39.582730 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #93 | Epoch Duration: 186.96121168136597
2020-01-13 08:36:39.582945 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #93 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1531005
Z variance train             0.014880342
KL Divergence                39.65573
KL Loss                      3.965573
QF Loss                      1097.2878
VF Loss                      159.76454
Policy Loss                  -815.99976
Q Predictions Mean           810.032
Q Predictions Std            898.5083
Q Predictions Max            2979.1936
Q Predictions Min            246.65099
V Predictions Mean           822.1813
V Predictions Std            900.81506
V Predictions Max            2956.529
V Predictions Min            250.95323
Log Pis Mean                 -1.0668304
Log Pis Std                  3.2828248
Log Pis Max                  14.348874
Log Pis Min                  -6.2275834
Policy mu Mean               -0.050406378
Policy mu Std                0.79259175
Policy mu Max                3.0481238
Policy mu Min                -2.393388
Policy log std Mean          -0.47353974
Policy log std Std           0.2171418
Policy log std Max           -0.175056
Policy log std Min           -2.2492409
Z mean eval                  2.1828783
Z variance eval              0.015224342
total_rewards                [6977.23364124 7181.35101805 7356.37125076 7239.29318885 7271.9943446
 7087.59131892 7053.01286546 7156.17463574 7165.75533497 7306.6888123 ]
total_rewards_mean           7179.546641089219
total_rewards_std            112.10938240522542
total_rewards_max            7356.3712507556365
total_rewards_min            6977.233641235661
Number of train steps total  380000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               146.34396222420037
(Previous) Eval Time (s)     28.854121081065387
Sample Time (s)              10.28339993627742
Epoch Time (s)               185.48148324154317
Total Train Time (s)         17305.63843659032
Epoch                        94
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:39:45.146658 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #94 | Epoch Duration: 185.56355500221252
2020-01-13 08:39:45.146877 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1849082
Z variance train             0.015224462
KL Divergence                40.93875
KL Loss                      4.0938754
QF Loss                      1050.1091
VF Loss                      68.793655
Policy Loss                  -764.3312
Q Predictions Mean           760.76514
Q Predictions Std            872.5721
Q Predictions Max            2924.3645
Q Predictions Min            -20.299065
V Predictions Mean           766.9523
V Predictions Std            870.5845
V Predictions Max            2905.0059
V Predictions Min            -21.862305
Log Pis Mean                 -1.1259516
Log Pis Std                  3.9065607
Log Pis Max                  21.30284
Log Pis Min                  -7.9842544
Policy mu Mean               -0.042863205
Policy mu Std                0.7734029
Policy mu Max                3.656938
Policy mu Min                -3.4012666
Policy log std Mean          -0.4516324
Policy log std Std           0.22190492
Policy log std Max           -0.109794065
Policy log std Min           -2.1031191
Z mean eval                  2.1902707
Z variance eval              0.017510008
total_rewards                [7150.85700833 7223.44901481 7353.49370356 7368.3566138  7212.79850984
 6975.43559089 7210.64991407 7231.43332126 7031.06499198 7226.80244959]
total_rewards_mean           7198.434111812911
total_rewards_std            116.53175301025975
total_rewards_max            7368.356613803927
total_rewards_min            6975.435590891781
Number of train steps total  384000
Number of env steps total    1154000
Number of rollouts total     0
Train Time (s)               145.83098520012572
(Previous) Eval Time (s)     30.52102330699563
Sample Time (s)              10.298401455394924
Epoch Time (s)               186.65040996251628
Total Train Time (s)         17492.38800918497
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:42:51.898504 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #95 | Epoch Duration: 186.75145483016968
2020-01-13 08:42:51.898741 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1905258
Z variance train             0.017493378
KL Divergence                39.696484
KL Loss                      3.9696484
QF Loss                      156.6101
VF Loss                      52.827465
Policy Loss                  -777.69226
Q Predictions Mean           773.507
Q Predictions Std            867.2593
Q Predictions Max            2933.1978
Q Predictions Min            -9.068343
V Predictions Mean           773.50385
V Predictions Std            866.9157
V Predictions Max            2899.343
V Predictions Min            -15.252382
Log Pis Mean                 -1.4247267
Log Pis Std                  3.4304366
Log Pis Max                  15.536846
Log Pis Min                  -8.037222
Policy mu Mean               -0.061797272
Policy mu Std                0.7626139
Policy mu Max                2.9012685
Policy mu Min                -3.2370641
Policy log std Mean          -0.4534743
Policy log std Std           0.2156979
Policy log std Max           -0.1475393
Policy log std Min           -2.1520262
Z mean eval                  2.1863163
Z variance eval              0.02975117
total_rewards                [6917.15598702 7339.34704826 7360.86374627 7325.37573188 7216.73673882
 7283.29814052 7255.77600022 7234.91442383 7250.46871913 7309.88501204]
total_rewards_mean           7249.382154799186
total_rewards_std            119.4985638972134
total_rewards_max            7360.863746273129
total_rewards_min            6917.155987017881
Number of train steps total  388000
Number of env steps total    1166000
Number of rollouts total     0
Train Time (s)               147.54212893825024
(Previous) Eval Time (s)     29.38499680440873
Sample Time (s)              10.177734774071723
Epoch Time (s)               187.1048605167307
Total Train Time (s)         17679.573612894863
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:45:59.086108 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #96 | Epoch Duration: 187.18721556663513
2020-01-13 08:45:59.086304 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.191056
Z variance train             0.029570187
KL Divergence                38.86869
KL Loss                      3.8868692
QF Loss                      1001.3581
VF Loss                      91.10362
Policy Loss                  -885.7645
Q Predictions Mean           881.67163
Q Predictions Std            949.9729
Q Predictions Max            2967.6536
Q Predictions Min            -24.541798
V Predictions Mean           881.58887
V Predictions Std            952.91656
V Predictions Max            2952.1628
V Predictions Min            -15.492004
Log Pis Mean                 -0.71399426
Log Pis Std                  3.6957922
Log Pis Max                  15.342832
Log Pis Min                  -8.227686
Policy mu Mean               0.0024136566
Policy mu Std                0.83975935
Policy mu Max                3.410483
Policy mu Min                -3.2070956
Policy log std Mean          -0.48269382
Policy log std Std           0.22257803
Policy log std Max           -0.12552464
Policy log std Min           -2.141197
Z mean eval                  2.1938977
Z variance eval              0.02061842
total_rewards                [7143.1566521  7337.93429805 7268.91715046 7242.4762717  7111.44202929
 7222.76768273 7211.34613492 7252.90639142 7366.48184157 7294.71389353]
total_rewards_mean           7245.214234576893
total_rewards_std            75.06210879307986
total_rewards_max            7366.481841574325
total_rewards_min            7111.442029289855
Number of train steps total  392000
Number of env steps total    1178000
Number of rollouts total     0
Train Time (s)               143.51547492016107
(Previous) Eval Time (s)     29.810646147001535
Sample Time (s)              9.7128892573528
Epoch Time (s)               183.0390103245154
Total Train Time (s)         17862.715399510693
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:49:02.229747 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #97 | Epoch Duration: 183.1432933807373
2020-01-13 08:49:02.229957 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.196473
Z variance train             0.020694159
KL Divergence                39.26442
KL Loss                      3.926442
QF Loss                      114.76902
VF Loss                      71.83162
Policy Loss                  -820.6816
Q Predictions Mean           817.3686
Q Predictions Std            948.8011
Q Predictions Max            3122.1255
Q Predictions Min            -12.958345
V Predictions Mean           815.02216
V Predictions Std            947.7155
V Predictions Max            3081.0837
V Predictions Min            -7.743105
Log Pis Mean                 -1.3031343
Log Pis Std                  3.3698668
Log Pis Max                  13.028511
Log Pis Min                  -6.842313
Policy mu Mean               -0.008379918
Policy mu Std                0.7837248
Policy mu Max                2.6699462
Policy mu Min                -2.710268
Policy log std Mean          -0.4662417
Policy log std Std           0.22629222
Policy log std Max           -0.09551525
Policy log std Min           -2.4126985
Z mean eval                  2.1930175
Z variance eval              0.053611856
total_rewards                [6409.48859902 6684.45320408 6717.42589068 6594.20266426 6623.21176915
 6459.16858691 6459.78424338 6360.74939188 6427.58725551 6640.33405667]
total_rewards_mean           6537.640566154243
total_rewards_std            121.2390086597826
total_rewards_max            6717.425890677888
total_rewards_min            6360.7493918813525
Number of train steps total  396000
Number of env steps total    1190000
Number of rollouts total     0
Train Time (s)               137.92322055995464
(Previous) Eval Time (s)     29.46925922203809
Sample Time (s)              9.720700500532985
Epoch Time (s)               177.11318028252572
Total Train Time (s)         18039.91165467864
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:51:59.428000 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #98 | Epoch Duration: 177.19789338111877
2020-01-13 08:51:59.428194 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2014155
Z variance train             0.05348625
KL Divergence                38.211323
KL Loss                      3.8211324
QF Loss                      1277.3934
VF Loss                      255.74005
Policy Loss                  -826.03546
Q Predictions Mean           822.6831
Q Predictions Std            932.7851
Q Predictions Max            2987.728
Q Predictions Min            -6.812786
V Predictions Mean           819.1771
V Predictions Std            929.5567
V Predictions Max            2978.907
V Predictions Min            -16.381464
Log Pis Mean                 -0.36795303
Log Pis Std                  4.2309384
Log Pis Max                  15.991217
Log Pis Min                  -5.545556
Policy mu Mean               0.033419076
Policy mu Std                0.86983913
Policy mu Max                3.3337493
Policy mu Min                -2.9415267
Policy log std Mean          -0.45215666
Policy log std Std           0.2330683
Policy log std Max           -0.14094937
Policy log std Min           -2.2541516
Z mean eval                  2.1529553
Z variance eval              0.03471035
total_rewards                [7426.27877432 7244.27957433 7574.11292395 7508.52541491 7439.46392018
 7818.91212769 7282.59658782 7580.87970493 7454.28607947 7374.9656393 ]
total_rewards_mean           7470.430074690999
total_rewards_std            156.38032002708817
total_rewards_max            7818.9121276938595
total_rewards_min            7244.279574333321
Number of train steps total  400000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               137.1593086067587
(Previous) Eval Time (s)     28.355185375083238
Sample Time (s)              9.764369353652
Epoch Time (s)               175.27886333549395
Total Train Time (s)         18215.35665887827
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:54:54.875413 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #99 | Epoch Duration: 175.44705152511597
2020-01-13 08:54:54.875701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1502762
Z variance train             0.03484256
KL Divergence                37.893417
KL Loss                      3.7893417
QF Loss                      892.2882
VF Loss                      166.67255
Policy Loss                  -844.48065
Q Predictions Mean           841.2219
Q Predictions Std            959.17615
Q Predictions Max            2963.6938
Q Predictions Min            268.00235
V Predictions Mean           842.31116
V Predictions Std            959.70966
V Predictions Max            2966.2869
V Predictions Min            263.87488
Log Pis Mean                 -1.0378156
Log Pis Std                  3.358537
Log Pis Max                  10.517792
Log Pis Min                  -7.4165945
Policy mu Mean               0.040102523
Policy mu Std                0.82633674
Policy mu Max                2.9638283
Policy mu Min                -2.53134
Policy log std Mean          -0.47501302
Policy log std Std           0.22287256
Policy log std Max           -0.10600354
Policy log std Min           -1.9854656
Z mean eval                  2.183825
Z variance eval              0.022083445
total_rewards                [7388.64816447 7528.6378229  7563.24480917 7611.81243515 7414.80069125
 7446.62234939 7404.3221184  7657.03511448 7639.08140209 7583.15675635]
total_rewards_mean           7523.73616636388
total_rewards_std            97.09185821685243
total_rewards_max            7657.0351144837705
total_rewards_min            7388.648164466697
Number of train steps total  404000
Number of env steps total    1214000
Number of rollouts total     0
Train Time (s)               145.3866060078144
(Previous) Eval Time (s)     30.986039170995355
Sample Time (s)              8.417126053012908
Epoch Time (s)               184.78977123182267
Total Train Time (s)         18400.24097031355
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:57:59.761197 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #100 | Epoch Duration: 184.8853030204773
2020-01-13 08:57:59.761421 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1850836
Z variance train             0.022031613
KL Divergence                39.41105
KL Loss                      3.941105
QF Loss                      255.42673
VF Loss                      101.56149
Policy Loss                  -818.3731
Q Predictions Mean           818.40656
Q Predictions Std            946.024
Q Predictions Max            2954.5078
Q Predictions Min            -14.13798
V Predictions Mean           817.1457
V Predictions Std            945.81366
V Predictions Max            2933.232
V Predictions Min            -15.145747
Log Pis Mean                 -0.86168593
Log Pis Std                  3.4820106
Log Pis Max                  12.008327
Log Pis Min                  -6.654962
Policy mu Mean               0.043342784
Policy mu Std                0.8157829
Policy mu Max                2.5499098
Policy mu Min                -2.5734963
Policy log std Mean          -0.47231174
Policy log std Std           0.22794463
Policy log std Max           -0.16691908
Policy log std Min           -1.8895938
Z mean eval                  2.1929119
Z variance eval              0.025793135
total_rewards                [6944.02166907 7125.0191041  7103.17314255 7456.7855614  7041.91999455
 7006.2152085  7095.35148727 7195.84563464 7146.29641172 7125.54760612]
total_rewards_mean           7124.017581992664
total_rewards_std            130.63906954601964
total_rewards_max            7456.785561400118
total_rewards_min            6944.021669065823
Number of train steps total  408000
Number of env steps total    1226000
Number of rollouts total     0
Train Time (s)               146.32866420783103
(Previous) Eval Time (s)     30.182315890677273
Sample Time (s)              10.541102498304099
Epoch Time (s)               187.0520825968124
Total Train Time (s)         18587.382559809834
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:01:06.905678 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #101 | Epoch Duration: 187.14409041404724
2020-01-13 09:01:06.905937 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #101 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1919062
Z variance train             0.025789088
KL Divergence                40.347797
KL Loss                      4.03478
QF Loss                      243.56398
VF Loss                      36.777428
Policy Loss                  -815.84845
Q Predictions Mean           813.5459
Q Predictions Std            915.0013
Q Predictions Max            3044.2314
Q Predictions Min            -25.393776
V Predictions Mean           814.6905
V Predictions Std            918.3212
V Predictions Max            3056.6885
V Predictions Min            -21.18024
Log Pis Mean                 -0.7618853
Log Pis Std                  3.718732
Log Pis Max                  16.128119
Log Pis Min                  -8.5450325
Policy mu Mean               -0.08163043
Policy mu Std                0.8218756
Policy mu Max                3.1442566
Policy mu Min                -3.4204652
Policy log std Mean          -0.47068226
Policy log std Std           0.21736822
Policy log std Max           -0.15842035
Policy log std Min           -2.3529162
Z mean eval                  2.259646
Z variance eval              0.029343063
total_rewards                [7535.49672783 7688.76621612 7593.08880542 7561.48912045 7593.222375
 7518.95406399 7839.66860144 7494.65662088 7703.76887407 7473.3007837 ]
total_rewards_mean           7600.241218890429
total_rewards_std            107.49125567116444
total_rewards_max            7839.668601444021
total_rewards_min            7473.30078369943
Number of train steps total  412000
Number of env steps total    1238000
Number of rollouts total     0
Train Time (s)               145.55661057680845
(Previous) Eval Time (s)     29.352758693974465
Sample Time (s)              8.314478011336178
Epoch Time (s)               183.2238472821191
Total Train Time (s)         18770.68556644628
Epoch                        102
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:04:10.210157 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #102 | Epoch Duration: 183.3040497303009
2020-01-13 09:04:10.210342 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.263139
Z variance train             0.029141447
KL Divergence                40.79373
KL Loss                      4.0793734
QF Loss                      1691.0225
VF Loss                      71.98889
Policy Loss                  -778.4118
Q Predictions Mean           777.7716
Q Predictions Std            921.9068
Q Predictions Max            3140.9656
Q Predictions Min            -20.376003
V Predictions Mean           777.16113
V Predictions Std            916.06964
V Predictions Max            3104.9976
V Predictions Min            -21.230757
Log Pis Mean                 -0.9564443
Log Pis Std                  3.6666825
Log Pis Max                  20.13485
Log Pis Min                  -9.965647
Policy mu Mean               0.0312063
Policy mu Std                0.82235074
Policy mu Max                3.1271636
Policy mu Min                -2.614649
Policy log std Mean          -0.4719391
Policy log std Std           0.21007198
Policy log std Max           -0.06748626
Policy log std Min           -1.7785454
Z mean eval                  2.204769
Z variance eval              0.027566269
total_rewards                [7439.85330332 7398.2247965  7446.94849599 7455.28942532 7290.51625299
 7539.77896398 7297.89671372 7553.32379108 7318.09884571 7482.20213905]
total_rewards_mean           7422.213272765584
total_rewards_std            89.91180703216322
total_rewards_max            7553.323791075037
total_rewards_min            7290.516252994274
Number of train steps total  416000
Number of env steps total    1250000
Number of rollouts total     0
Train Time (s)               148.26390442810953
(Previous) Eval Time (s)     30.400100947823375
Sample Time (s)              10.245551762636751
Epoch Time (s)               188.90955713856965
Total Train Time (s)         18959.68132229848
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:07:19.209158 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #103 | Epoch Duration: 188.99865770339966
2020-01-13 09:07:19.209445 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1984546
Z variance train             0.027702082
KL Divergence                40.44167
KL Loss                      4.044167
QF Loss                      196.23099
VF Loss                      65.70462
Policy Loss                  -797.94714
Q Predictions Mean           795.8574
Q Predictions Std            914.2229
Q Predictions Max            3082.6106
Q Predictions Min            226.483
V Predictions Mean           798.1433
V Predictions Std            917.8869
V Predictions Max            3075.4392
V Predictions Min            212.81161
Log Pis Mean                 -0.8689893
Log Pis Std                  3.5523927
Log Pis Max                  14.472754
Log Pis Min                  -6.5236573
Policy mu Mean               -0.007673913
Policy mu Std                0.8098498
Policy mu Max                2.7159975
Policy mu Min                -2.8328636
Policy log std Mean          -0.47057378
Policy log std Std           0.20891596
Policy log std Max           -0.1503135
Policy log std Min           -1.9735777
Z mean eval                  2.2237992
Z variance eval              0.017811975
total_rewards                [7333.77209059 7350.89861319 7383.57216173 7285.19845133 7316.83726004
 7178.95597178 7314.48978356 7316.90911616 7220.71291774 7100.51554444]
total_rewards_mean           7280.186191055136
total_rewards_std            82.77696315437979
total_rewards_max            7383.572161729575
total_rewards_min            7100.515544442881
Number of train steps total  420000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               144.32140888180584
(Previous) Eval Time (s)     28.514428025111556
Sample Time (s)              10.103233359754086
Epoch Time (s)               182.93907026667148
Total Train Time (s)         19142.75573984068
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:10:22.285366 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #104 | Epoch Duration: 183.07573556900024
2020-01-13 09:10:22.285636 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2245371
Z variance train             0.017855674
KL Divergence                42.084305
KL Loss                      4.208431
QF Loss                      1148.3152
VF Loss                      58.9529
Policy Loss                  -785.4485
Q Predictions Mean           779.98615
Q Predictions Std            895.99603
Q Predictions Max            3054.9607
Q Predictions Min            284.68222
V Predictions Mean           784.38367
V Predictions Std            898.19324
V Predictions Max            3034.8286
V Predictions Min            293.9151
Log Pis Mean                 -0.88675064
Log Pis Std                  3.520896
Log Pis Max                  14.961544
Log Pis Min                  -5.9191985
Policy mu Mean               -0.0047612847
Policy mu Std                0.78379387
Policy mu Max                2.9623442
Policy mu Min                -3.2791002
Policy log std Mean          -0.46971747
Policy log std Std           0.2230571
Policy log std Max           0.030361772
Policy log std Min           -2.0982814
Z mean eval                  2.2226036
Z variance eval              0.014225401
total_rewards                [6984.55358881 6978.92058664 7378.73637546 7071.55571916 7083.04296682
 7222.21336818 7025.83750282 7221.65638927 7346.22344531 7008.63389089]
total_rewards_mean           7132.137383336716
total_rewards_std            141.654784784276
total_rewards_max            7378.736375458924
total_rewards_min            6978.920586640403
Number of train steps total  424000
Number of env steps total    1274000
Number of rollouts total     0
Train Time (s)               137.21192203788087
(Previous) Eval Time (s)     28.78846654901281
Sample Time (s)              9.847833341918886
Epoch Time (s)               175.84822192881256
Total Train Time (s)         19318.6850092588
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:13:18.216411 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #105 | Epoch Duration: 175.93058443069458
2020-01-13 09:13:18.216643 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.223888
Z variance train             0.014249936
KL Divergence                43.604893
KL Loss                      4.3604894
QF Loss                      119.22039
VF Loss                      123.562645
Policy Loss                  -818.7313
Q Predictions Mean           816.048
Q Predictions Std            954.95825
Q Predictions Max            3114.7327
Q Predictions Min            272.23706
V Predictions Mean           824.18396
V Predictions Std            952.8415
V Predictions Max            3114.1677
V Predictions Min            284.96216
Log Pis Mean                 -1.1399887
Log Pis Std                  3.2087357
Log Pis Max                  17.010223
Log Pis Min                  -6.6473255
Policy mu Mean               0.023059288
Policy mu Std                0.7718747
Policy mu Max                3.4011762
Policy mu Min                -2.8211477
Policy log std Mean          -0.47199073
Policy log std Std           0.24302234
Policy log std Max           -0.13219649
Policy log std Min           -2.2195084
Z mean eval                  2.2237446
Z variance eval              0.014580054
total_rewards                [7234.90297435 7551.87095078 7772.33348516 7614.04364118 7581.51061724
 7688.33225248 7383.45445348 7565.29983211 7436.03802203 7332.20195845]
total_rewards_mean           7515.998818725359
total_rewards_std            158.0462443957316
total_rewards_max            7772.333485156508
total_rewards_min            7234.902974349169
Number of train steps total  428000
Number of env steps total    1286000
Number of rollouts total     0
Train Time (s)               138.0795650910586
(Previous) Eval Time (s)     29.787486935034394
Sample Time (s)              9.87748417025432
Epoch Time (s)               177.74453619634733
Total Train Time (s)         19496.517926813103
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:16:16.051348 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #106 | Epoch Duration: 177.83454298973083
2020-01-13 09:16:16.051556 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.22356
Z variance train             0.014562368
KL Divergence                43.5185
KL Loss                      4.35185
QF Loss                      412.80026
VF Loss                      282.21124
Policy Loss                  -836.15985
Q Predictions Mean           830.34906
Q Predictions Std            952.9315
Q Predictions Max            3113.8728
Q Predictions Min            283.39996
V Predictions Mean           835.5029
V Predictions Std            949.4398
V Predictions Max            3099.179
V Predictions Min            283.22678
Log Pis Mean                 -1.0782642
Log Pis Std                  3.1824517
Log Pis Max                  10.119001
Log Pis Min                  -7.1467476
Policy mu Mean               0.020529972
Policy mu Std                0.8144505
Policy mu Max                2.6802542
Policy mu Min                -2.575575
Policy log std Mean          -0.47437778
Policy log std Std           0.22575618
Policy log std Max           -0.12841745
Policy log std Min           -2.0889475
Z mean eval                  2.2172346
Z variance eval              0.019844595
total_rewards                [7392.64613414 7583.45180553 7503.45847779 7593.41394636 7677.69811664
 7507.30470949 7430.94194425 7434.11000066 7464.62566835 7828.25192325]
total_rewards_mean           7541.590272644295
total_rewards_std            126.3609235437965
total_rewards_max            7828.251923246445
total_rewards_min            7392.64613413828
Number of train steps total  432000
Number of env steps total    1298000
Number of rollouts total     0
Train Time (s)               145.92928672209382
(Previous) Eval Time (s)     30.048463243991137
Sample Time (s)              10.151229731272906
Epoch Time (s)               186.12897969735786
Total Train Time (s)         19682.733186606318
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:19:22.269277 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #107 | Epoch Duration: 186.21757197380066
2020-01-13 09:19:22.269455 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2196183
Z variance train             0.020238416
KL Divergence                44.225666
KL Loss                      4.422567
QF Loss                      251.97511
VF Loss                      58.042374
Policy Loss                  -842.5406
Q Predictions Mean           837.40436
Q Predictions Std            970.10333
Q Predictions Max            3155.1536
Q Predictions Min            -64.84943
V Predictions Mean           842.4465
V Predictions Std            971.5691
V Predictions Max            3167.6118
V Predictions Min            -60.730648
Log Pis Mean                 -0.90478235
Log Pis Std                  3.630805
Log Pis Max                  22.175795
Log Pis Min                  -6.1283817
Policy mu Mean               0.030934637
Policy mu Std                0.81717294
Policy mu Max                3.535415
Policy mu Min                -3.025215
Policy log std Mean          -0.484557
Policy log std Std           0.22372088
Policy log std Max           -0.0036236346
Policy log std Min           -2.296067
Z mean eval                  2.2063746
Z variance eval              0.008482935
total_rewards                [7625.03471435 7901.71217036 7829.1941674  7424.79142972 7955.7734466
 7521.22570804 7946.15454319 8083.66940076 7786.58653679 7852.9501378 ]
total_rewards_mean           7792.709225501009
total_rewards_std            197.19381925200744
total_rewards_max            8083.6694007613205
total_rewards_min            7424.791429717124
Number of train steps total  436000
Number of env steps total    1310000
Number of rollouts total     0
Train Time (s)               146.43708127271384
(Previous) Eval Time (s)     30.298924059141427
Sample Time (s)              10.313030926976353
Epoch Time (s)               187.04903625883162
Total Train Time (s)         19869.862418119796
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:22:29.401778 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #108 | Epoch Duration: 187.1321403980255
2020-01-13 09:22:29.402069 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2075906
Z variance train             0.008486632
KL Divergence                45.00098
KL Loss                      4.500098
QF Loss                      136.34128
VF Loss                      36.408005
Policy Loss                  -751.5427
Q Predictions Mean           747.4059
Q Predictions Std            905.4206
Q Predictions Max            3145.8506
Q Predictions Min            -67.94037
V Predictions Mean           753.10095
V Predictions Std            902.0452
V Predictions Max            3133.3948
V Predictions Min            -70.80477
Log Pis Mean                 -1.1784468
Log Pis Std                  3.3054292
Log Pis Max                  21.485918
Log Pis Min                  -8.1268215
Policy mu Mean               -0.02761712
Policy mu Std                0.79171777
Policy mu Max                3.1536665
Policy mu Min                -3.206079
Policy log std Mean          -0.47303608
Policy log std Std           0.20731479
Policy log std Max           -0.09937996
Policy log std Min           -2.035439
Z mean eval                  2.1967258
Z variance eval              0.045300983
total_rewards                [7390.70098817 7728.98897094 7567.34715269 7723.65148983 7484.15158065
 7613.24092501 7606.76861862 7385.8246864  7424.23490251 7688.65773353]
total_rewards_mean           7561.356704836724
total_rewards_std            126.54394828016187
total_rewards_max            7728.9889709390145
total_rewards_min            7385.824686403929
Number of train steps total  440000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               145.47276504104957
(Previous) Eval Time (s)     30.64741423819214
Sample Time (s)              10.235449726227671
Epoch Time (s)               186.35562900546938
Total Train Time (s)         20056.334754546173
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:25:35.876538 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #109 | Epoch Duration: 186.47426748275757
2020-01-13 09:25:35.876847 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1926265
Z variance train             0.04509055
KL Divergence                42.14749
KL Loss                      4.2147493
QF Loss                      178.88013
VF Loss                      60.85398
Policy Loss                  -747.7448
Q Predictions Mean           744.765
Q Predictions Std            873.9301
Q Predictions Max            3019.1396
Q Predictions Min            -84.481026
V Predictions Mean           747.4973
V Predictions Std            872.36194
V Predictions Max            3013.4282
V Predictions Min            -82.41804
Log Pis Mean                 -1.1979858
Log Pis Std                  3.1440835
Log Pis Max                  11.63908
Log Pis Min                  -7.3957887
Policy mu Mean               0.017356055
Policy mu Std                0.7686747
Policy mu Max                2.557853
Policy mu Min                -2.612749
Policy log std Mean          -0.4786397
Policy log std Std           0.21117504
Policy log std Max           -0.09445757
Policy log std Min           -1.9690275
Z mean eval                  2.2523656
Z variance eval              0.04678189
total_rewards                [7558.67054958 7622.77197527 7660.2293128  7475.63314769 7742.94664503
 7848.62212787 7720.47501395 7634.93959142 7730.79486743 7609.63097832]
total_rewards_mean           7660.471420934594
total_rewards_std            99.96759766052118
total_rewards_max            7848.622127868885
total_rewards_min            7475.633147685608
Number of train steps total  444000
Number of env steps total    1334000
Number of rollouts total     0
Train Time (s)               147.2752164406702
(Previous) Eval Time (s)     29.641784945037216
Sample Time (s)              10.456611029803753
Epoch Time (s)               187.37361241551116
Total Train Time (s)         20243.81676131999
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:28:43.360923 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #110 | Epoch Duration: 187.48386549949646
2020-01-13 09:28:43.361268 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.246756
Z variance train             0.046766482
KL Divergence                42.58892
KL Loss                      4.258892
QF Loss                      172.90765
VF Loss                      150.24132
Policy Loss                  -765.20483
Q Predictions Mean           762.8902
Q Predictions Std            892.2823
Q Predictions Max            3100.761
Q Predictions Min            -71.55751
V Predictions Mean           771.29895
V Predictions Std            898.7847
V Predictions Max            3102.3909
V Predictions Min            -87.76018
Log Pis Mean                 -1.2011342
Log Pis Std                  3.1162112
Log Pis Max                  10.5549965
Log Pis Min                  -6.605483
Policy mu Mean               0.04201593
Policy mu Std                0.7780863
Policy mu Max                2.9121737
Policy mu Min                -2.3909698
Policy log std Mean          -0.46497333
Policy log std Std           0.23464017
Policy log std Max           -0.056801602
Policy log std Min           -2.2883332
Z mean eval                  2.183273
Z variance eval              0.018677097
total_rewards                [7707.03665228 7585.5895378  7539.58311453 7446.13333816 7596.21452555
 7465.71760138 7669.01753506 7353.12927679 7592.6555317  7175.66145051]
total_rewards_mean           7513.0738563761815
total_rewards_std            150.76469211667938
total_rewards_max            7707.036652275068
total_rewards_min            7175.661450512589
Number of train steps total  448000
Number of env steps total    1346000
Number of rollouts total     0
Train Time (s)               143.8184125390835
(Previous) Eval Time (s)     28.20409240014851
Sample Time (s)              10.219197491183877
Epoch Time (s)               182.2417024304159
Total Train Time (s)         20426.141498050652
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:31:45.687714 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #111 | Epoch Duration: 182.32617783546448
2020-01-13 09:31:45.687940 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1826348
Z variance train             0.01879129
KL Divergence                42.22451
KL Loss                      4.222451
QF Loss                      206.06401
VF Loss                      95.76503
Policy Loss                  -882.7896
Q Predictions Mean           883.3083
Q Predictions Std            999.9417
Q Predictions Max            3271.894
Q Predictions Min            287.31995
V Predictions Mean           887.8906
V Predictions Std            999.5885
V Predictions Max            3283.94
V Predictions Min            297.58414
Log Pis Mean                 -0.9252335
Log Pis Std                  3.0141208
Log Pis Max                  12.473076
Log Pis Min                  -8.697085
Policy mu Mean               0.037422102
Policy mu Std                0.8005461
Policy mu Max                2.3322036
Policy mu Min                -2.2429545
Policy log std Mean          -0.5067703
Policy log std Std           0.21344991
Policy log std Max           -0.1438653
Policy log std Min           -1.840647
Z mean eval                  2.2359657
Z variance eval              0.013674935
total_rewards                [7494.53446305 7825.58279254 7399.45571705 7355.78801653 7461.22832919
 7559.91191433 7619.92980231 7821.93362326 7468.64548656 7442.52709212]
total_rewards_mean           7544.953723694057
total_rewards_std            156.24827647788595
total_rewards_max            7825.582792540799
total_rewards_min            7355.788016525212
Number of train steps total  452000
Number of env steps total    1358000
Number of rollouts total     0
Train Time (s)               137.73497638199478
(Previous) Eval Time (s)     29.358930736780167
Sample Time (s)              9.85877746436745
Epoch Time (s)               176.9526845831424
Total Train Time (s)         20603.268309738953
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:34:42.816334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #112 | Epoch Duration: 177.12823104858398
2020-01-13 09:34:42.816565 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.232862
Z variance train             0.013810867
KL Divergence                45.940186
KL Loss                      4.5940185
QF Loss                      146.23193
VF Loss                      165.98283
Policy Loss                  -855.5809
Q Predictions Mean           852.97015
Q Predictions Std            975.0821
Q Predictions Max            3192.0466
Q Predictions Min            293.09326
V Predictions Mean           858.30664
V Predictions Std            981.2876
V Predictions Max            3197.4294
V Predictions Min            288.4859
Log Pis Mean                 -0.67765635
Log Pis Std                  3.6512249
Log Pis Max                  16.290539
Log Pis Min                  -7.3673573
Policy mu Mean               0.024092183
Policy mu Std                0.8620214
Policy mu Max                3.3655772
Policy mu Min                -2.4886863
Policy log std Mean          -0.4765075
Policy log std Std           0.21727757
Policy log std Max           -0.017930806
Policy log std Min           -2.0563807
Z mean eval                  2.2354367
Z variance eval              0.014173689
total_rewards                [7728.60054953 7588.29293513 7901.61980403 7798.69502798 7813.93325999
 7470.55346128 7665.18181613 7760.04975631 7770.92519219 7764.04749817]
total_rewards_mean           7726.189930074317
total_rewards_std            116.79290871396343
total_rewards_max            7901.619804025242
total_rewards_min            7470.553461282525
Number of train steps total  456000
Number of env steps total    1370000
Number of rollouts total     0
Train Time (s)               138.51774484757334
(Previous) Eval Time (s)     29.678686894942075
Sample Time (s)              9.880238896701485
Epoch Time (s)               178.0766706392169
Total Train Time (s)         20781.48799269041
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:37:41.037918 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #113 | Epoch Duration: 178.2211880683899
2020-01-13 09:37:41.038127 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2382798
Z variance train             0.0141950445
KL Divergence                45.282703
KL Loss                      4.5282702
QF Loss                      223.00438
VF Loss                      123.6035
Policy Loss                  -915.35645
Q Predictions Mean           912.7423
Q Predictions Std            1043.2008
Q Predictions Max            3237.5745
Q Predictions Min            302.98605
V Predictions Mean           915.60254
V Predictions Std            1042.3616
V Predictions Max            3226.0203
V Predictions Min            310.2083
Log Pis Mean                 -0.2796647
Log Pis Std                  3.7402773
Log Pis Max                  14.70418
Log Pis Min                  -7.5020285
Policy mu Mean               0.06090576
Policy mu Std                0.88315564
Policy mu Max                2.5759358
Policy mu Min                -3.365698
Policy log std Mean          -0.502865
Policy log std Std           0.239471
Policy log std Max           -0.12129706
Policy log std Min           -2.0866854
Z mean eval                  2.202918
Z variance eval              0.06189554
total_rewards                [7511.56257637 7607.0714765  7847.70638621 7976.78130124 7814.27519258
 7628.93309462 7788.73459796 7726.94266861 7686.65079145 7774.53888495]
total_rewards_mean           7736.319697048324
total_rewards_std            127.20909640979134
total_rewards_max            7976.7813012352835
total_rewards_min            7511.562576368229
Number of train steps total  460000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               145.87254969682544
(Previous) Eval Time (s)     30.22844075737521
Sample Time (s)              10.007150039542466
Epoch Time (s)               186.10814049374312
Total Train Time (s)         20967.675118437503
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:40:47.227076 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #114 | Epoch Duration: 186.18880152702332
2020-01-13 09:40:47.227317 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.20611
Z variance train             0.061774034
KL Divergence                40.942013
KL Loss                      4.0942016
QF Loss                      1148.5571
VF Loss                      72.34895
Policy Loss                  -804.75146
Q Predictions Mean           801.9972
Q Predictions Std            944.69763
Q Predictions Max            3252.1523
Q Predictions Min            313.61273
V Predictions Mean           799.75195
V Predictions Std            942.6725
V Predictions Max            3235.6584
V Predictions Min            309.6569
Log Pis Mean                 -0.77399164
Log Pis Std                  3.0164137
Log Pis Max                  10.959011
Log Pis Min                  -6.2076983
Policy mu Mean               0.021607125
Policy mu Std                0.8124362
Policy mu Max                2.450832
Policy mu Min                -2.5266252
Policy log std Mean          -0.45426953
Policy log std Std           0.21829264
Policy log std Max           -0.13017642
Policy log std Min           -2.041825
Z mean eval                  2.2222943
Z variance eval              0.041331984
total_rewards                [7370.28384971 7771.83718736 7855.38567701 7412.58632627 7403.62991997
 7421.8344045  7589.80536112 7726.08431048 7685.31464939 7207.54550362]
total_rewards_mean           7544.430718942972
total_rewards_std            199.84201277731185
total_rewards_max            7855.385677008821
total_rewards_min            7207.54550361864
Number of train steps total  464000
Number of env steps total    1394000
Number of rollouts total     0
Train Time (s)               146.33459432702512
(Previous) Eval Time (s)     30.293746382929385
Sample Time (s)              10.652891591191292
Epoch Time (s)               187.2812323011458
Total Train Time (s)         21155.038578430656
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:43:54.592384 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #115 | Epoch Duration: 187.36491870880127
2020-01-13 09:43:54.592566 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2223012
Z variance train             0.041321408
KL Divergence                42.414623
KL Loss                      4.241462
QF Loss                      811.1994
VF Loss                      56.575455
Policy Loss                  -917.7302
Q Predictions Mean           915.9201
Q Predictions Std            1029.9489
Q Predictions Max            3160.3271
Q Predictions Min            -112.02828
V Predictions Mean           915.5137
V Predictions Std            1029.6766
V Predictions Max            3150.0085
V Predictions Min            -112.02686
Log Pis Mean                 -0.71007264
Log Pis Std                  3.667181
Log Pis Max                  14.464552
Log Pis Min                  -8.135126
Policy mu Mean               0.05764766
Policy mu Std                0.8082468
Policy mu Max                2.5641637
Policy mu Min                -2.3831358
Policy log std Mean          -0.503859
Policy log std Std           0.2393854
Policy log std Max           -0.08500105
Policy log std Min           -2.182989
Z mean eval                  2.354433
Z variance eval              0.12821388
total_rewards                [7084.42188004 7313.84136155 7048.13110526 7190.93751214 7093.15711718
 7052.04578811 7055.77019996 7055.15425171 7225.06688846 7101.03789046]
total_rewards_mean           7121.956399486985
total_rewards_std            86.06197531247801
total_rewards_max            7313.841361553938
total_rewards_min            7048.131105256373
Number of train steps total  468000
Number of env steps total    1406000
Number of rollouts total     0
Train Time (s)               145.95339677203447
(Previous) Eval Time (s)     30.83973478106782
Sample Time (s)              10.55989340832457
Epoch Time (s)               187.35302496142685
Total Train Time (s)         21342.479972757865
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:47:02.037594 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #116 | Epoch Duration: 187.4448537826538
2020-01-13 09:47:02.037910 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3553085
Z variance train             0.12828366
KL Divergence                39.559437
KL Loss                      3.9559438
QF Loss                      584.44946
VF Loss                      57.45391
Policy Loss                  -889.4915
Q Predictions Mean           886.16235
Q Predictions Std            1000.04956
Q Predictions Max            3101.7966
Q Predictions Min            284.6941
V Predictions Mean           891.4599
V Predictions Std            998.76654
V Predictions Max            3087.1543
V Predictions Min            300.0021
Log Pis Mean                 -0.44193038
Log Pis Std                  3.9860985
Log Pis Max                  13.381711
Log Pis Min                  -7.544877
Policy mu Mean               -0.036845937
Policy mu Std                0.880516
Policy mu Max                2.6252186
Policy mu Min                -2.7471972
Policy log std Mean          -0.47033063
Policy log std Std           0.2187872
Policy log std Max           -0.14470248
Policy log std Min           -2.1836898
Z mean eval                  2.2302983
Z variance eval              0.10639505
total_rewards                [7193.6693421  7422.44415804 7184.40550128 7491.01546555 7530.37876481
 7581.39124091 7440.41467374 7278.05133069 7617.25926832 7343.28429581]
total_rewards_mean           7408.2314041246555
total_rewards_std            146.28322271817703
total_rewards_max            7617.259268317615
total_rewards_min            7184.405501283189
Number of train steps total  472000
Number of env steps total    1418000
Number of rollouts total     0
Train Time (s)               148.14752635918558
(Previous) Eval Time (s)     30.08403381658718
Sample Time (s)              10.564242916181684
Epoch Time (s)               188.79580309195444
Total Train Time (s)         21531.357387172524
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:50:10.916351 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #117 | Epoch Duration: 188.87822222709656
2020-01-13 09:50:10.916552 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2243695
Z variance train             0.10616028
KL Divergence                38.37422
KL Loss                      3.8374221
QF Loss                      445.96738
VF Loss                      49.267654
Policy Loss                  -814.4026
Q Predictions Mean           811.2479
Q Predictions Std            953.46423
Q Predictions Max            3200.123
Q Predictions Min            283.5124
V Predictions Mean           816.7113
V Predictions Std            957.14276
V Predictions Max            3193.886
V Predictions Min            294.34763
Log Pis Mean                 -1.3894701
Log Pis Std                  3.3239179
Log Pis Max                  11.1967945
Log Pis Min                  -10.720165
Policy mu Mean               0.052517492
Policy mu Std                0.7794981
Policy mu Max                2.64321
Policy mu Min                -2.636556
Policy log std Mean          -0.4762245
Policy log std Std           0.21631187
Policy log std Max           -0.11662373
Policy log std Min           -1.9078938
Z mean eval                  2.223112
Z variance eval              0.043899477
total_rewards                [7941.69354689 7671.35828163 7879.60582898 8179.11678282 7827.70689439
 7899.23297138 7939.25148093 7430.75372185 7875.24406582 7802.72228658]
total_rewards_mean           7844.668586127531
total_rewards_std            184.0535992182523
total_rewards_max            8179.116782818698
total_rewards_min            7430.753721851927
Number of train steps total  476000
Number of env steps total    1430000
Number of rollouts total     0
Train Time (s)               142.45159365609288
(Previous) Eval Time (s)     28.714097384363413
Sample Time (s)              10.387479118071496
Epoch Time (s)               181.5531701585278
Total Train Time (s)         21712.988547781482
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:53:12.550178 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #118 | Epoch Duration: 181.6334674358368
2020-01-13 09:53:12.550397 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2259505
Z variance train             0.044067424
KL Divergence                41.14789
KL Loss                      4.114789
QF Loss                      176.48923
VF Loss                      164.78093
Policy Loss                  -835.7743
Q Predictions Mean           834.04596
Q Predictions Std            973.55023
Q Predictions Max            3280.3044
Q Predictions Min            307.57843
V Predictions Mean           824.65857
V Predictions Std            972.2909
V Predictions Max            3269.281
V Predictions Min            302.6784
Log Pis Mean                 -0.816705
Log Pis Std                  3.307246
Log Pis Max                  12.056761
Log Pis Min                  -7.325316
Policy mu Mean               0.0068968176
Policy mu Std                0.81755006
Policy mu Max                2.8611345
Policy mu Min                -2.531086
Policy log std Mean          -0.489846
Policy log std Std           0.22595014
Policy log std Max           0.0085808635
Policy log std Min           -2.0700583
Z mean eval                  2.2926939
Z variance eval              0.040789157
total_rewards                [7554.46551744 7984.63731699 7938.09826977 7803.99729262 8018.66010397
 8037.25677148 7682.97132625 7761.01967479 7840.80594729 7728.47169612]
total_rewards_mean           7835.038391672888
total_rewards_std            150.76072400005137
total_rewards_max            8037.256771480702
total_rewards_min            7554.465517437335
Number of train steps total  480000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               137.99296158691868
(Previous) Eval Time (s)     28.21878684218973
Sample Time (s)              9.47610557358712
Epoch Time (s)               175.68785400269553
Total Train Time (s)         21888.755087023135
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:56:08.318013 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #119 | Epoch Duration: 175.76744318008423
2020-01-13 09:56:08.318190 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #119 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.294119
Z variance train             0.04072555
KL Divergence                43.172577
KL Loss                      4.317258
QF Loss                      1370.9766
VF Loss                      107.45368
Policy Loss                  -817.01544
Q Predictions Mean           814.3051
Q Predictions Std            967.0383
Q Predictions Max            3317.118
Q Predictions Min            326.58057
V Predictions Mean           823.9796
V Predictions Std            971.2531
V Predictions Max            3326.713
V Predictions Min            336.1234
Log Pis Mean                 -0.8939111
Log Pis Std                  3.3166058
Log Pis Max                  13.300394
Log Pis Min                  -5.8486633
Policy mu Mean               0.083397865
Policy mu Std                0.7987623
Policy mu Max                2.7080655
Policy mu Min                -2.518773
Policy log std Mean          -0.4651324
Policy log std Std           0.21485431
Policy log std Max           -0.050148368
Policy log std Min           -2.1036713
Z mean eval                  2.200752
Z variance eval              0.03131457
total_rewards                [7068.36913751 7228.56460735 7073.23003465 7423.73973244 7068.2704855
 7196.98154038 7194.98479255 7058.67680835 7455.59028612 7477.00921901]
total_rewards_mean           7224.541664384675
total_rewards_std            160.5208567446532
total_rewards_max            7477.009219005899
total_rewards_min            7058.67680834641
Number of train steps total  484000
Number of env steps total    1454000
Number of rollouts total     0
Train Time (s)               138.91425392916426
(Previous) Eval Time (s)     28.800435048062354
Sample Time (s)              10.149996370077133
Epoch Time (s)               177.86468534730375
Total Train Time (s)         22066.70735274302
Epoch                        120
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:59:06.273204 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #120 | Epoch Duration: 177.95486640930176
2020-01-13 09:59:06.273454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2012606
Z variance train             0.031474017
KL Divergence                42.467644
KL Loss                      4.2467647
QF Loss                      243.62924
VF Loss                      78.64425
Policy Loss                  -848.9891
Q Predictions Mean           843.8964
Q Predictions Std            1003.7488
Q Predictions Max            3429.2864
Q Predictions Min            317.34286
V Predictions Mean           842.8695
V Predictions Std            1003.10974
V Predictions Max            3402.2134
V Predictions Min            316.64377
Log Pis Mean                 -0.8915557
Log Pis Std                  3.4669597
Log Pis Max                  16.71345
Log Pis Min                  -10.484776
Policy mu Mean               -0.031039672
Policy mu Std                0.81377345
Policy mu Max                2.5480478
Policy mu Min                -2.5974882
Policy log std Mean          -0.47486022
Policy log std Std           0.21498354
Policy log std Max           -0.15780336
Policy log std Min           -1.9370519
Z mean eval                  2.2257762
Z variance eval              0.03460444
total_rewards                [7398.20089046 7835.86555261 7559.08515778 7559.38312333 7461.18904434
 7589.25863375 7837.80674635 7465.52084092 7722.47426901 7612.31538384]
total_rewards_mean           7604.109964239115
total_rewards_std            144.45845177281956
total_rewards_max            7837.806746346282
total_rewards_min            7398.200890456817
Number of train steps total  488000
Number of env steps total    1466000
Number of rollouts total     0
Train Time (s)               148.02842339826748
(Previous) Eval Time (s)     31.101976403966546
Sample Time (s)              10.126758829690516
Epoch Time (s)               189.25715863192454
Total Train Time (s)         22256.050679621752
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:02:15.618525 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #121 | Epoch Duration: 189.34489941596985
2020-01-13 10:02:15.618761 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2280364
Z variance train             0.034588836
KL Divergence                43.28274
KL Loss                      4.3282743
QF Loss                      214.40416
VF Loss                      106.46232
Policy Loss                  -778.12537
Q Predictions Mean           775.9131
Q Predictions Std            928.24884
Q Predictions Max            3293.2996
Q Predictions Min            262.9043
V Predictions Mean           785.1864
V Predictions Std            930.59393
V Predictions Max            3291.8167
V Predictions Min            253.46655
Log Pis Mean                 -0.89002734
Log Pis Std                  3.440557
Log Pis Max                  12.615843
Log Pis Min                  -7.284406
Policy mu Mean               0.04450779
Policy mu Std                0.7940537
Policy mu Max                2.864062
Policy mu Min                -2.2841349
Policy log std Mean          -0.5015888
Policy log std Std           0.21707204
Policy log std Max           -0.1001277
Policy log std Min           -1.9389348
Z mean eval                  2.2327304
Z variance eval              0.09985479
total_rewards                [7528.54008052 7649.56966702 7723.56787839 7586.1512845  7608.96609009
 7701.26184584 7480.17692613 7525.59602023 7683.4931292  7447.6194226 ]
total_rewards_mean           7593.494234453528
total_rewards_std            91.11533682232651
total_rewards_max            7723.567878387103
total_rewards_min            7447.619422599521
Number of train steps total  492000
Number of env steps total    1478000
Number of rollouts total     0
Train Time (s)               146.73119621537626
(Previous) Eval Time (s)     30.634357939008623
Sample Time (s)              10.196111775003374
Epoch Time (s)               187.56166592938825
Total Train Time (s)         22443.696008553263
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:05:23.267025 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #122 | Epoch Duration: 187.64808011054993
2020-01-13 10:05:23.267435 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.237209
Z variance train             0.10053166
KL Divergence                42.284252
KL Loss                      4.2284255
QF Loss                      151.264
VF Loss                      36.29997
Policy Loss                  -880.0988
Q Predictions Mean           877.1037
Q Predictions Std            1004.6884
Q Predictions Max            3315.4814
Q Predictions Min            333.48624
V Predictions Mean           877.8091
V Predictions Std            1004.8879
V Predictions Max            3315.4622
V Predictions Min            337.13428
Log Pis Mean                 -0.99523103
Log Pis Std                  3.2112565
Log Pis Max                  12.2981415
Log Pis Min                  -7.221841
Policy mu Mean               0.039755028
Policy mu Std                0.7966065
Policy mu Max                2.5029788
Policy mu Min                -2.4983916
Policy log std Mean          -0.48848602
Policy log std Std           0.23486413
Policy log std Max           -0.027126461
Policy log std Min           -2.2743063
Z mean eval                  2.2710752
Z variance eval              0.01721206
total_rewards                [7919.44324895 7848.34887091 7899.12348199 8125.03401631 8297.57246362
 7664.52563014 7985.03186079 8049.89637137 7864.40328036 8040.88467225]
total_rewards_mean           7969.426389669473
total_rewards_std            164.26007413162029
total_rewards_max            8297.572463619532
total_rewards_min            7664.525630138718
Number of train steps total  496000
Number of env steps total    1490000
Number of rollouts total     0
Train Time (s)               145.02622993802652
(Previous) Eval Time (s)     29.844561234116554
Sample Time (s)              10.151365553960204
Epoch Time (s)               185.02215672610328
Total Train Time (s)         22628.799404986203
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:08:28.371921 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #123 | Epoch Duration: 185.10424089431763
2020-01-13 10:08:28.372107 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2748682
Z variance train             0.017124562
KL Divergence                44.67023
KL Loss                      4.4670234
QF Loss                      220.6031
VF Loss                      79.27967
Policy Loss                  -814.5572
Q Predictions Mean           810.68585
Q Predictions Std            959.0151
Q Predictions Max            3352.9482
Q Predictions Min            333.31125
V Predictions Mean           810.80634
V Predictions Std            958.11206
V Predictions Max            3331.944
V Predictions Min            331.37976
Log Pis Mean                 -0.8560496
Log Pis Std                  3.4069185
Log Pis Max                  16.303246
Log Pis Min                  -6.456212
Policy mu Mean               0.07998626
Policy mu Std                0.7941235
Policy mu Max                2.7458053
Policy mu Min                -2.9204068
Policy log std Mean          -0.5021436
Policy log std Std           0.23356274
Policy log std Max           0.037012726
Policy log std Min           -1.9449236
Z mean eval                  2.2585816
Z variance eval              0.025999596
total_rewards                [7753.59192206 8208.95093069 8131.19591821 8023.63016972 7992.71541247
 8129.16522411 8042.88769118 8034.91150147 8256.6797209  8136.57235783]
total_rewards_mean           8071.030084862667
total_rewards_std            132.6751039179846
total_rewards_max            8256.679720898825
total_rewards_min            7753.591922061082
Number of train steps total  500000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               148.04334585601464
(Previous) Eval Time (s)     30.526003857143223
Sample Time (s)              10.67124067991972
Epoch Time (s)               189.24059039307758
Total Train Time (s)         22818.131934927776
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:11:37.706287 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #124 | Epoch Duration: 189.33402848243713
2020-01-13 10:11:37.706477 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2624342
Z variance train             0.026170794
KL Divergence                45.77014
KL Loss                      4.5770144
QF Loss                      657.14087
VF Loss                      168.91217
Policy Loss                  -836.42017
Q Predictions Mean           831.5294
Q Predictions Std            966.3386
Q Predictions Max            3308.9324
Q Predictions Min            326.41168
V Predictions Mean           832.9625
V Predictions Std            965.99695
V Predictions Max            3320.8616
V Predictions Min            325.58228
Log Pis Mean                 -1.0579256
Log Pis Std                  3.305986
Log Pis Max                  11.471533
Log Pis Min                  -9.999442
Policy mu Mean               0.035107028
Policy mu Std                0.7838379
Policy mu Max                2.4771917
Policy mu Min                -3.0554087
Policy log std Mean          -0.502237
Policy log std Std           0.23946714
Policy log std Max           0.013207674
Policy log std Min           -2.3112879
Z mean eval                  2.2492874
Z variance eval              0.030723045
total_rewards                [8159.60735527 8060.96131988 8044.31621445 7988.53587793 8310.04751852
 8163.19750292 8157.17808799 7871.90936855 8034.05034534 8169.032685  ]
total_rewards_mean           8095.883627585557
total_rewards_std            115.30653384388152
total_rewards_max            8310.047518517817
total_rewards_min            7871.909368550721
Number of train steps total  504000
Number of env steps total    1514000
Number of rollouts total     0
Train Time (s)               142.488460295368
(Previous) Eval Time (s)     29.22485596500337
Sample Time (s)              8.802326050586998
Epoch Time (s)               180.51564231095836
Total Train Time (s)         22998.724657955114
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:14:38.301048 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #125 | Epoch Duration: 180.5944287776947
2020-01-13 10:14:38.301231 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.250403
Z variance train             0.030858397
KL Divergence                44.656982
KL Loss                      4.4656982
QF Loss                      1301.01
VF Loss                      67.73529
Policy Loss                  -801.20197
Q Predictions Mean           799.969
Q Predictions Std            937.1815
Q Predictions Max            3263.8357
Q Predictions Min            331.32227
V Predictions Mean           804.1586
V Predictions Std            933.9575
V Predictions Max            3256.9998
V Predictions Min            333.10242
Log Pis Mean                 -0.6704382
Log Pis Std                  3.7261765
Log Pis Max                  16.440765
Log Pis Min                  -8.83617
Policy mu Mean               0.0034507215
Policy mu Std                0.8429099
Policy mu Max                2.6916919
Policy mu Min                -3.0967789
Policy log std Mean          -0.49163032
Policy log std Std           0.22808945
Policy log std Max           -0.055211425
Policy log std Min           -2.4517074
Z mean eval                  2.252512
Z variance eval              0.05074016
total_rewards                [7624.31792345 7853.14367688 7916.65778676 8172.09932822 7702.08909019
 7889.82298552 8076.3081238  7798.70978848 8043.4153675  8021.14662673]
total_rewards_mean           7909.771069753238
total_rewards_std            163.5291853773476
total_rewards_max            8172.099328219878
total_rewards_min            7624.317923449611
Number of train steps total  508000
Number of env steps total    1526000
Number of rollouts total     0
Train Time (s)               138.2671211110428
(Previous) Eval Time (s)     29.45742355333641
Sample Time (s)              9.828351887408644
Epoch Time (s)               177.55289655178785
Total Train Time (s)         23176.362701359205
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:17:35.942441 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #126 | Epoch Duration: 177.64105367660522
2020-01-13 10:17:35.942713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2516809
Z variance train             0.050857715
KL Divergence                44.82486
KL Loss                      4.4824862
QF Loss                      81.56642
VF Loss                      61.548943
Policy Loss                  -724.8973
Q Predictions Mean           724.1273
Q Predictions Std            868.1152
Q Predictions Max            3276.8362
Q Predictions Min            330.60138
V Predictions Mean           719.63416
V Predictions Std            867.7142
V Predictions Max            3262.6865
V Predictions Min            336.53656
Log Pis Mean                 -0.7420804
Log Pis Std                  3.2507164
Log Pis Max                  12.997391
Log Pis Min                  -10.303421
Policy mu Mean               -0.007999453
Policy mu Std                0.800462
Policy mu Max                2.4126575
Policy mu Min                -2.632082
Policy log std Mean          -0.49179065
Policy log std Std           0.21896218
Policy log std Max           -0.089259
Policy log std Min           -2.0387816
Z mean eval                  2.1986432
Z variance eval              0.037109006
total_rewards                [7416.81035907 7390.097209   7191.13388486 7410.37798278 7499.11299558
 7735.19554583 7592.77434795 7312.56749462 7364.89835464 7627.00843641]
total_rewards_mean           7453.99766107412
total_rewards_std            153.20141114793756
total_rewards_max            7735.195545831496
total_rewards_min            7191.133884860905
Number of train steps total  512000
Number of env steps total    1538000
Number of rollouts total     0
Train Time (s)               140.08238823898137
(Previous) Eval Time (s)     29.05524042621255
Sample Time (s)              9.869412596803159
Epoch Time (s)               179.00704126199707
Total Train Time (s)         23355.45496279141
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:20:35.034244 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #127 | Epoch Duration: 179.09133648872375
2020-01-13 10:20:35.034371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1987245
Z variance train             0.037143204
KL Divergence                41.886612
KL Loss                      4.188661
QF Loss                      277.80237
VF Loss                      36.941612
Policy Loss                  -768.63916
Q Predictions Mean           766.6791
Q Predictions Std            918.8564
Q Predictions Max            3300.096
Q Predictions Min            323.5407
V Predictions Mean           768.67725
V Predictions Std            918.5479
V Predictions Max            3293.6104
V Predictions Min            330.42233
Log Pis Mean                 -1.0939082
Log Pis Std                  2.9786677
Log Pis Max                  13.063374
Log Pis Min                  -8.175571
Policy mu Mean               0.06512297
Policy mu Std                0.7721148
Policy mu Max                2.5810487
Policy mu Min                -3.2685199
Policy log std Mean          -0.48444724
Policy log std Std           0.21638882
Policy log std Max           -0.11996108
Policy log std Min           -1.8642559
Z mean eval                  2.1773422
Z variance eval              0.17377838
total_rewards                [7834.85826982 7844.11096145 7908.55948434 7824.81653757 8076.63823519
 7840.04310896 7891.88437537 7800.84379565 8019.39653522 7775.21095742]
total_rewards_mean           7881.636226099099
total_rewards_std            91.78350310720327
total_rewards_max            8076.638235193928
total_rewards_min            7775.210957422052
Number of train steps total  516000
Number of env steps total    1550000
Number of rollouts total     0
Train Time (s)               148.2820712979883
(Previous) Eval Time (s)     30.56023940583691
Sample Time (s)              9.623132708948106
Epoch Time (s)               188.4654434127733
Total Train Time (s)         23544.00076702563
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:23:43.581716 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #128 | Epoch Duration: 188.54724645614624
2020-01-13 10:23:43.581868 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1758435
Z variance train             0.17339633
KL Divergence                39.119293
KL Loss                      3.9119294
QF Loss                      185.79037
VF Loss                      85.88685
Policy Loss                  -1006.61285
Q Predictions Mean           1006.6796
Q Predictions Std            1143.6677
Q Predictions Max            3548.2288
Q Predictions Min            342.49402
V Predictions Mean           1000.27356
V Predictions Std            1140.5438
V Predictions Max            3522.494
V Predictions Min            345.67877
Log Pis Mean                 -0.38314897
Log Pis Std                  3.8179948
Log Pis Max                  14.218898
Log Pis Min                  -7.1466894
Policy mu Mean               -0.020120356
Policy mu Std                0.87264425
Policy mu Max                2.7448275
Policy mu Min                -3.0314007
Policy log std Mean          -0.47863698
Policy log std Std           0.24450925
Policy log std Max           -0.122178435
Policy log std Min           -2.1003258
Z mean eval                  2.264125
Z variance eval              0.051839583
total_rewards                [7485.39697394 7393.09924324 7543.83190973 7881.63377692 7736.83904088
 7388.2317725  7665.97522607 7547.49909272 7454.25451274 7577.21479786]
total_rewards_mean           7567.397634659572
total_rewards_std            148.4000561459306
total_rewards_max            7881.633776923094
total_rewards_min            7388.23177250114
Number of train steps total  520000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               146.92050045821816
(Previous) Eval Time (s)     30.05653619673103
Sample Time (s)              9.634802786167711
Epoch Time (s)               186.6118394411169
Total Train Time (s)         23730.694866571575
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:26:50.279003 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #129 | Epoch Duration: 186.6970090866089
2020-01-13 10:26:50.279275 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2610118
Z variance train             0.051816754
KL Divergence                42.589966
KL Loss                      4.2589965
QF Loss                      1341.8599
VF Loss                      120.94327
Policy Loss                  -960.3408
Q Predictions Mean           957.1363
Q Predictions Std            1066.7155
Q Predictions Max            3402.5037
Q Predictions Min            339.63815
V Predictions Mean           964.59247
V Predictions Std            1070.7018
V Predictions Max            3402.8247
V Predictions Min            339.8914
Log Pis Mean                 -0.37302676
Log Pis Std                  3.7996528
Log Pis Max                  12.652477
Log Pis Min                  -10.303897
Policy mu Mean               0.086205415
Policy mu Std                0.8765675
Policy mu Max                2.9717028
Policy mu Min                -2.8169734
Policy log std Mean          -0.49773988
Policy log std Std           0.23587744
Policy log std Max           -0.10706338
Policy log std Min           -2.2096844
Z mean eval                  2.218779
Z variance eval              0.03929327
total_rewards                [7960.46332977 8352.38485053 7990.49929262 8163.15863117 8139.00864951
 8080.241682   7986.21133466 7902.58884592 8017.19489166 8092.73387226]
total_rewards_mean           8068.4485380104725
total_rewards_std            122.44739186600135
total_rewards_max            8352.384850533177
total_rewards_min            7902.588845920879
Number of train steps total  524000
Number of env steps total    1574000
Number of rollouts total     0
Train Time (s)               144.89495957270265
(Previous) Eval Time (s)     30.92275742581114
Sample Time (s)              9.510002214461565
Epoch Time (s)               185.32771921297535
Total Train Time (s)         23916.10463733971
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:29:55.690913 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #130 | Epoch Duration: 185.41147565841675
2020-01-13 10:29:55.691127 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #130 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2172844
Z variance train             0.039256305
KL Divergence                43.249214
KL Loss                      4.3249216
QF Loss                      345.76657
VF Loss                      51.662823
Policy Loss                  -871.8397
Q Predictions Mean           867.05115
Q Predictions Std            1006.7028
Q Predictions Max            3444.228
Q Predictions Min            344.43066
V Predictions Mean           867.18506
V Predictions Std            1006.7969
V Predictions Max            3422.4763
V Predictions Min            340.59048
Log Pis Mean                 -0.842108
Log Pis Std                  3.2182646
Log Pis Max                  11.072126
Log Pis Min                  -8.768251
Policy mu Mean               -0.007700991
Policy mu Std                0.8253099
Policy mu Max                2.8761663
Policy mu Min                -3.0561838
Policy log std Mean          -0.4890224
Policy log std Std           0.24724585
Policy log std Max           -0.09940535
Policy log std Min           -2.2135785
Z mean eval                  2.2243702
Z variance eval              0.049817942
total_rewards                [7566.01226157 7674.70426005 7876.35046558 7854.81179947 7818.765653
 7698.1552299  7671.62359746 7787.40713881 7943.05095884 7720.08268782]
total_rewards_mean           7761.096405248973
total_rewards_std            108.79432692872295
total_rewards_max            7943.050958837654
total_rewards_min            7566.012261567582
Number of train steps total  528000
Number of env steps total    1586000
Number of rollouts total     0
Train Time (s)               146.8582285209559
(Previous) Eval Time (s)     29.799095917027444
Sample Time (s)              10.634241920430213
Epoch Time (s)               187.29156635841355
Total Train Time (s)         24103.47421319876
Epoch                        131
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:33:03.062523 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #131 | Epoch Duration: 187.3712077140808
2020-01-13 10:33:03.062730 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.222925
Z variance train             0.049779717
KL Divergence                42.46879
KL Loss                      4.246879
QF Loss                      360.05774
VF Loss                      119.18646
Policy Loss                  -934.2176
Q Predictions Mean           928.2705
Q Predictions Std            1071.3677
Q Predictions Max            3472.9785
Q Predictions Min            338.194
V Predictions Mean           932.64465
V Predictions Std            1070.1959
V Predictions Max            3459.0813
V Predictions Min            340.69125
Log Pis Mean                 -0.2551142
Log Pis Std                  3.7615857
Log Pis Max                  19.82215
Log Pis Min                  -7.6205163
Policy mu Mean               0.09378811
Policy mu Std                0.85993636
Policy mu Max                4.253767
Policy mu Min                -2.9740777
Policy log std Mean          -0.52100253
Policy log std Std           0.24485803
Policy log std Max           -0.15471344
Policy log std Min           -1.9833763
Z mean eval                  2.2042596
Z variance eval              0.02083245
total_rewards                [7921.07700971 8033.85743107 8067.08467784 8319.16393924 8108.93608943
 8313.80345858 8224.72937655 8035.42023921 8098.04283677 8161.99803154]
total_rewards_mean           8128.411308993118
total_rewards_std            121.16097707630759
total_rewards_max            8319.163939237475
total_rewards_min            7921.077009711422
Number of train steps total  532000
Number of env steps total    1598000
Number of rollouts total     0
Train Time (s)               140.40443410398439
(Previous) Eval Time (s)     28.904852716252208
Sample Time (s)              9.903342127799988
Epoch Time (s)               179.21262894803658
Total Train Time (s)         24282.76426912751
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:36:02.355300 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #132 | Epoch Duration: 179.29240942001343
2020-01-13 10:36:02.355537 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2039876
Z variance train             0.020796804
KL Divergence                44.56324
KL Loss                      4.456324
QF Loss                      351.67062
VF Loss                      177.11269
Policy Loss                  -832.31903
Q Predictions Mean           828.339
Q Predictions Std            963.832
Q Predictions Max            3399.5671
Q Predictions Min            331.0883
V Predictions Mean           833.19775
V Predictions Std            964.7724
V Predictions Max            3417.8977
V Predictions Min            336.7418
Log Pis Mean                 -0.510007
Log Pis Std                  3.2082074
Log Pis Max                  11.00568
Log Pis Min                  -6.6041727
Policy mu Mean               0.102952205
Policy mu Std                0.82066274
Policy mu Max                2.9617395
Policy mu Min                -2.447607
Policy log std Mean          -0.499146
Policy log std Std           0.23317185
Policy log std Max           -0.11711264
Policy log std Min           -2.1217518
Z mean eval                  2.235373
Z variance eval              0.06400778
total_rewards                [8263.20361981 8254.28298728 8267.53988725 8557.6946612  8402.96175888
 8462.32874701 8415.16895608 8409.76597457 8355.2479153  8254.26629758]
total_rewards_mean           8364.24608049531
total_rewards_std            98.50722551353907
total_rewards_max            8557.694661199537
total_rewards_min            8254.266297577227
Number of train steps total  536000
Number of env steps total    1610000
Number of rollouts total     0
Train Time (s)               137.63101284205914
(Previous) Eval Time (s)     29.31223239330575
Sample Time (s)              9.989039117936045
Epoch Time (s)               176.93228435330093
Total Train Time (s)         24459.778262368403
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:38:59.371111 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #133 | Epoch Duration: 177.01540637016296
2020-01-13 10:38:59.371325 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2387543
Z variance train             0.06350505
KL Divergence                42.68445
KL Loss                      4.268445
QF Loss                      275.10135
VF Loss                      162.93661
Policy Loss                  -957.7121
Q Predictions Mean           953.9785
Q Predictions Std            1060.7157
Q Predictions Max            3452.0903
Q Predictions Min            339.79303
V Predictions Mean           961.89825
V Predictions Std            1061.8247
V Predictions Max            3483.7297
V Predictions Min            346.99344
Log Pis Mean                 -0.33058307
Log Pis Std                  3.4093664
Log Pis Max                  12.345338
Log Pis Min                  -8.100277
Policy mu Mean               0.07611847
Policy mu Std                0.8729784
Policy mu Max                2.8931103
Policy mu Min                -3.294944
Policy log std Mean          -0.5291233
Policy log std Std           0.22619604
Policy log std Max           -0.16041738
Policy log std Min           -2.092811
Z mean eval                  2.2413545
Z variance eval              0.022229228
total_rewards                [7904.55088415 8000.02114532 8010.14201198 8198.1320224  8112.80465216
 8122.88779088 8034.67789438 7900.88438498 8102.55558142 8093.38537885]
total_rewards_mean           8048.004174652315
total_rewards_std            91.38759297348474
total_rewards_max            8198.132022402573
total_rewards_min            7900.8843849762925
Number of train steps total  540000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               141.5760863511823
(Previous) Eval Time (s)     29.353432320058346
Sample Time (s)              9.755320924334228
Epoch Time (s)               180.68483959557489
Total Train Time (s)         24640.54763538111
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:42:00.143385 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #134 | Epoch Duration: 180.77190923690796
2020-01-13 10:42:00.143576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2419848
Z variance train             0.022164118
KL Divergence                45.35719
KL Loss                      4.535719
QF Loss                      214.8299
VF Loss                      147.26575
Policy Loss                  -1040.247
Q Predictions Mean           1038.0402
Q Predictions Std            1118.1243
Q Predictions Max            3496.8503
Q Predictions Min            357.79395
V Predictions Mean           1036.942
V Predictions Std            1115.7097
V Predictions Max            3477.6257
V Predictions Min            360.81015
Log Pis Mean                 -0.049642127
Log Pis Std                  4.059059
Log Pis Max                  17.762892
Log Pis Min                  -6.6521616
Policy mu Mean               0.082284704
Policy mu Std                0.9043703
Policy mu Max                3.4069586
Policy mu Min                -3.1014822
Policy log std Mean          -0.5142433
Policy log std Std           0.25313857
Policy log std Max           -0.0024974048
Policy log std Min           -2.4505553
Z mean eval                  2.2627861
Z variance eval              0.03895054
total_rewards                [8099.87109516 7901.74002165 7961.09065601 8213.96624676 8040.86151985
 8293.67077079 8213.84473871 8067.24984837 8095.82940948 8230.79382907]
total_rewards_mean           8111.891813586514
total_rewards_std            119.30647022647767
total_rewards_max            8293.67077079333
total_rewards_min            7901.740021653855
Number of train steps total  544000
Number of env steps total    1634000
Number of rollouts total     0
Train Time (s)               148.29791210684925
(Previous) Eval Time (s)     30.361366869416088
Sample Time (s)              10.176583805121481
Epoch Time (s)               188.83586278138682
Total Train Time (s)         24829.461013182532
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:45:09.058884 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #135 | Epoch Duration: 188.91516137123108
2020-01-13 10:45:09.059074 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2623343
Z variance train             0.039047852
KL Divergence                44.98422
KL Loss                      4.498422
QF Loss                      147.15765
VF Loss                      84.82121
Policy Loss                  -868.6917
Q Predictions Mean           865.5844
Q Predictions Std            1016.29645
Q Predictions Max            3391.2915
Q Predictions Min            324.7739
V Predictions Mean           863.8078
V Predictions Std            1011.1932
V Predictions Max            3378.2437
V Predictions Min            324.55405
Log Pis Mean                 -0.9975493
Log Pis Std                  3.26175
Log Pis Max                  14.369514
Log Pis Min                  -6.6475754
Policy mu Mean               0.0424099
Policy mu Std                0.8073026
Policy mu Max                2.6989303
Policy mu Min                -2.2366452
Policy log std Mean          -0.48304585
Policy log std Std           0.21865295
Policy log std Max           -0.062424958
Policy log std Min           -1.8774002
Z mean eval                  2.2305307
Z variance eval              0.02695414
total_rewards                [8316.844475   8289.16672765 8565.89481844 8432.72538277 8422.28534991
 8167.92233219 8403.64075487 8306.56819927 8189.51629856 8222.07626107]
total_rewards_mean           8331.664059972303
total_rewards_std            118.38605184462044
total_rewards_max            8565.894818439734
total_rewards_min            8167.922332187777
Number of train steps total  548000
Number of env steps total    1646000
Number of rollouts total     0
Train Time (s)               147.804934122134
(Previous) Eval Time (s)     29.2205831669271
Sample Time (s)              9.466749873943627
Epoch Time (s)               186.49226716300473
Total Train Time (s)         25016.036421648227
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:48:15.637298 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #136 | Epoch Duration: 186.5780589580536
2020-01-13 10:48:15.637614 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #136 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.232759
Z variance train             0.027003402
KL Divergence                45.854023
KL Loss                      4.5854025
QF Loss                      265.92474
VF Loss                      52.41188
Policy Loss                  -840.68445
Q Predictions Mean           840.3934
Q Predictions Std            974.69995
Q Predictions Max            3416.5034
Q Predictions Min            349.60406
V Predictions Mean           837.3015
V Predictions Std            972.443
V Predictions Max            3424.436
V Predictions Min            347.19025
Log Pis Mean                 -0.72055364
Log Pis Std                  3.4878454
Log Pis Max                  14.943825
Log Pis Min                  -5.9655313
Policy mu Mean               0.043547194
Policy mu Std                0.8263264
Policy mu Max                2.6698658
Policy mu Min                -3.0998652
Policy log std Mean          -0.5029783
Policy log std Std           0.23037194
Policy log std Max           -0.109910816
Policy log std Min           -2.0362082
Z mean eval                  2.2184138
Z variance eval              0.02185737
total_rewards                [7682.47228683 7895.34943365 7933.41204112 7820.20262859 8162.4278468
 7817.90711752 7840.64176596 7907.6972473  7812.24095245 7715.15545916]
total_rewards_mean           7858.750677938804
total_rewards_std            126.04295753151969
total_rewards_max            8162.4278468015555
total_rewards_min            7682.472286832342
Number of train steps total  552000
Number of env steps total    1658000
Number of rollouts total     0
Train Time (s)               146.77782084513456
(Previous) Eval Time (s)     30.971691037993878
Sample Time (s)              10.110755920410156
Epoch Time (s)               187.8602678035386
Total Train Time (s)         25203.983751546126
Epoch                        137
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:51:23.587335 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #137 | Epoch Duration: 187.9494867324829
2020-01-13 10:51:23.587654 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2223227
Z variance train             0.021829333
KL Divergence                45.533234
KL Loss                      4.5533233
QF Loss                      1685.1869
VF Loss                      76.88954
Policy Loss                  -959.57306
Q Predictions Mean           955.8024
Q Predictions Std            1069.5463
Q Predictions Max            3626.6333
Q Predictions Min            369.36633
V Predictions Mean           959.9254
V Predictions Std            1067.3517
V Predictions Max            3601.6433
V Predictions Min            376.9864
Log Pis Mean                 -0.61820257
Log Pis Std                  3.6565976
Log Pis Max                  10.482538
Log Pis Min                  -8.412802
Policy mu Mean               0.071501635
Policy mu Std                0.85967153
Policy mu Max                2.427768
Policy mu Min                -3.787291
Policy log std Mean          -0.49825034
Policy log std Std           0.25443047
Policy log std Max           -0.10334617
Policy log std Min           -2.4697654
Z mean eval                  2.2030323
Z variance eval              0.02012843
total_rewards                [7753.95985801 8114.35641272 8078.32863705 8127.02543118 8096.90060109
 7839.376919   8217.51946787 8034.78134537 8133.35424102 7953.43756734]
total_rewards_mean           8034.904048066392
total_rewards_std            136.8818562479901
total_rewards_max            8217.5194678746
total_rewards_min            7753.959858008553
Number of train steps total  556000
Number of env steps total    1670000
Number of rollouts total     0
Train Time (s)               146.0535150631331
(Previous) Eval Time (s)     29.622234331909567
Sample Time (s)              10.680300275795162
Epoch Time (s)               186.35604967083782
Total Train Time (s)         25390.41871084692
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:54:30.024101 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #138 | Epoch Duration: 186.4362552165985
2020-01-13 10:54:30.024372 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2030272
Z variance train             0.020085813
KL Divergence                45.674324
KL Loss                      4.5674324
QF Loss                      181.05405
VF Loss                      44.213318
Policy Loss                  -904.63904
Q Predictions Mean           900.9701
Q Predictions Std            1024.3329
Q Predictions Max            3588.182
Q Predictions Min            366.3472
V Predictions Mean           903.1544
V Predictions Std            1021.2892
V Predictions Max            3596.6045
V Predictions Min            376.3716
Log Pis Mean                 -0.76195383
Log Pis Std                  3.1161206
Log Pis Max                  15.532793
Log Pis Min                  -6.646266
Policy mu Mean               0.037660636
Policy mu Std                0.81321603
Policy mu Max                2.687109
Policy mu Min                -3.2212913
Policy log std Mean          -0.51918024
Policy log std Std           0.2367195
Policy log std Max           -0.13080123
Policy log std Min           -2.2262893
Z mean eval                  2.188692
Z variance eval              0.033699844
total_rewards                [8094.25841502 8399.48307159 8132.46259464 8518.03093389 8195.50339183
 8332.02344895 8386.12184945 8241.06213942 8363.69852326 8424.20347961]
total_rewards_mean           8308.684784767524
total_rewards_std            130.15305980263375
total_rewards_max            8518.030933888876
total_rewards_min            8094.258415024421
Number of train steps total  560000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               139.66554106213152
(Previous) Eval Time (s)     29.48345213709399
Sample Time (s)              10.682612034026533
Epoch Time (s)               179.83160523325205
Total Train Time (s)         25570.333674478345
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:57:29.941189 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #139 | Epoch Duration: 179.91662120819092
2020-01-13 10:57:29.941399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.185077
Z variance train             0.03358511
KL Divergence                44.433517
KL Loss                      4.4433517
QF Loss                      1631.5887
VF Loss                      122.45282
Policy Loss                  -865.50134
Q Predictions Mean           859.8165
Q Predictions Std            963.99133
Q Predictions Max            3481.7114
Q Predictions Min            359.874
V Predictions Mean           865.8188
V Predictions Std            970.0924
V Predictions Max            3489.8652
V Predictions Min            373.6952
Log Pis Mean                 -0.576596
Log Pis Std                  3.249903
Log Pis Max                  14.717731
Log Pis Min                  -6.973957
Policy mu Mean               0.04694088
Policy mu Std                0.82081777
Policy mu Max                3.5345142
Policy mu Min                -2.5150368
Policy log std Mean          -0.5094299
Policy log std Std           0.25841364
Policy log std Max           -0.11281064
Policy log std Min           -2.2652235
Z mean eval                  2.1482954
Z variance eval              0.07059306
total_rewards                [8471.50928183 8263.6547208  8177.42607495 8025.28141723 8179.33415585
 8286.42456559 8153.07762902 8415.63480162 8356.02568068 8058.02019303]
total_rewards_mean           8238.638852058744
total_rewards_std            139.633236663552
total_rewards_max            8471.509281825001
total_rewards_min            8025.281417228427
Number of train steps total  564000
Number of env steps total    1694000
Number of rollouts total     0
Train Time (s)               138.6226914790459
(Previous) Eval Time (s)     28.666053956840187
Sample Time (s)              8.744897747412324
Epoch Time (s)               176.0336431832984
Total Train Time (s)         25746.46199508896
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:00:26.072390 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #140 | Epoch Duration: 176.13080620765686
2020-01-13 11:00:26.072702 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1492968
Z variance train             0.07072438
KL Divergence                42.31694
KL Loss                      4.231694
QF Loss                      257.05084
VF Loss                      94.92305
Policy Loss                  -1006.57306
Q Predictions Mean           1001.1874
Q Predictions Std            1101.5427
Q Predictions Max            3558.1743
Q Predictions Min            358.16623
V Predictions Mean           1003.59656
V Predictions Std            1103.5714
V Predictions Max            3546.2478
V Predictions Min            366.30716
Log Pis Mean                 -0.38647908
Log Pis Std                  3.6629355
Log Pis Max                  12.437338
Log Pis Min                  -8.199776
Policy mu Mean               0.04298391
Policy mu Std                0.87494457
Policy mu Max                2.9445953
Policy mu Min                -3.3016362
Policy log std Mean          -0.5155181
Policy log std Std           0.233676
Policy log std Max           -0.10855231
Policy log std Min           -2.1403918
Z mean eval                  2.1687412
Z variance eval              0.03375037
total_rewards                [7916.72939856 8205.65110638 8444.90926576 8223.74685248 8417.65334063
 8579.34228252 2130.34910722 8341.04550973 8065.78570051 8256.47812814]
total_rewards_mean           7658.169069190471
total_rewards_std            1851.4330571605312
total_rewards_max            8579.342282520893
total_rewards_min            2130.3491072195716
Number of train steps total  568000
Number of env steps total    1706000
Number of rollouts total     0
Train Time (s)               141.61712857102975
(Previous) Eval Time (s)     29.731934366282076
Sample Time (s)              9.711050622165203
Epoch Time (s)               181.06011355947703
Total Train Time (s)         25927.60590399336
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:03:27.218044 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #141 | Epoch Duration: 181.1451609134674
2020-01-13 11:03:27.218237 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1717255
Z variance train             0.033770252
KL Divergence                45.765427
KL Loss                      4.576543
QF Loss                      272.999
VF Loss                      152.81812
Policy Loss                  -1035.7562
Q Predictions Mean           1036.0215
Q Predictions Std            1125.4829
Q Predictions Max            3550.3704
Q Predictions Min            378.8138
V Predictions Mean           1037.3767
V Predictions Std            1114.8871
V Predictions Max            3526.9402
V Predictions Min            389.33932
Log Pis Mean                 0.017832547
Log Pis Std                  3.777489
Log Pis Max                  13.274071
Log Pis Min                  -6.5853105
Policy mu Mean               0.058466837
Policy mu Std                0.8929138
Policy mu Max                2.6412728
Policy mu Min                -2.7223184
Policy log std Mean          -0.511761
Policy log std Std           0.23024018
Policy log std Max           -0.16059543
Policy log std Min           -2.033002
Z mean eval                  2.1734455
Z variance eval              0.018120896
total_rewards                [8341.60203439 8434.77206791 8475.47951262 8207.20816837 8502.34960201
 8541.61621716 8195.23187068 8158.8722167  7974.33941518 8482.62919323]
total_rewards_mean           8331.410029824512
total_rewards_std            178.62170413408398
total_rewards_max            8541.61621715982
total_rewards_min            7974.339415181298
Number of train steps total  572000
Number of env steps total    1718000
Number of rollouts total     0
Train Time (s)               149.00553187727928
(Previous) Eval Time (s)     29.615966683719307
Sample Time (s)              10.348102482035756
Epoch Time (s)               188.96960104303434
Total Train Time (s)         26116.654187864624
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:06:36.269902 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #142 | Epoch Duration: 189.05148649215698
2020-01-13 11:06:36.270286 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1716118
Z variance train             0.018112982
KL Divergence                46.889503
KL Loss                      4.6889505
QF Loss                      108.66034
VF Loss                      42.176464
Policy Loss                  -917.2148
Q Predictions Mean           914.7392
Q Predictions Std            1026.0352
Q Predictions Max            3544.734
Q Predictions Min            380.39587
V Predictions Mean           920.8008
V Predictions Std            1026.6125
V Predictions Max            3547.058
V Predictions Min            392.66992
Log Pis Mean                 -0.89202577
Log Pis Std                  3.0667152
Log Pis Max                  11.075102
Log Pis Min                  -6.596294
Policy mu Mean               0.018273847
Policy mu Std                0.81233454
Policy mu Max                3.253326
Policy mu Min                -2.74833
Policy log std Mean          -0.49143758
Policy log std Std           0.224236
Policy log std Max           -0.13267028
Policy log std Min           -1.9026294
Z mean eval                  2.176345
Z variance eval              0.022573091
total_rewards                [8176.93304521 8327.15727469 8513.29628333 8449.02412729 8317.81218338
 8435.28856656 8349.75240081 8315.25745005 8475.02443027 8348.37919253]
total_rewards_mean           8370.792495410753
total_rewards_std            93.68733778136159
total_rewards_max            8513.296283328234
total_rewards_min            8176.933045214281
Number of train steps total  576000
Number of env steps total    1730000
Number of rollouts total     0
Train Time (s)               147.6482689450495
(Previous) Eval Time (s)     29.95967560634017
Sample Time (s)              10.223689344711602
Epoch Time (s)               187.83163389610127
Total Train Time (s)         26304.56645362079
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:09:44.183474 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #143 | Epoch Duration: 187.91291332244873
2020-01-13 11:09:44.183700 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1787498
Z variance train             0.022561952
KL Divergence                47.308125
KL Loss                      4.7308125
QF Loss                      140.30885
VF Loss                      81.62327
Policy Loss                  -855.3838
Q Predictions Mean           851.1732
Q Predictions Std            966.24005
Q Predictions Max            3559.3552
Q Predictions Min            384.80353
V Predictions Mean           849.1803
V Predictions Std            966.70703
V Predictions Max            3525.5916
V Predictions Min            382.78326
Log Pis Mean                 -0.6547499
Log Pis Std                  3.490593
Log Pis Max                  17.394258
Log Pis Min                  -6.6622286
Policy mu Mean               0.018473836
Policy mu Std                0.8142593
Policy mu Max                2.7029917
Policy mu Min                -3.5589645
Policy log std Mean          -0.49341562
Policy log std Std           0.22853847
Policy log std Max           -0.115179926
Policy log std Min           -2.1738548
Z mean eval                  2.2499185
Z variance eval              0.028241068
total_rewards                [7765.62180704 8004.04515866 8047.95174436 7908.60832345 7876.70410611
 8109.3539122  7926.55068242 7823.0352433  7936.40066621 7835.6893447 ]
total_rewards_mean           7923.396098844775
total_rewards_std            100.91287424689098
total_rewards_max            8109.353912199164
total_rewards_min            7765.621807039343
Number of train steps total  580000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               147.10853546392173
(Previous) Eval Time (s)     30.939175076317042
Sample Time (s)              10.136338997632265
Epoch Time (s)               188.18404953787103
Total Train Time (s)         26492.8372672759
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:12:52.457634 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #144 | Epoch Duration: 188.2737398147583
2020-01-13 11:12:52.458018 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #144 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2469194
Z variance train             0.028144618
KL Divergence                47.29487
KL Loss                      4.729487
QF Loss                      120.347275
VF Loss                      44.02611
Policy Loss                  -945.2226
Q Predictions Mean           944.47925
Q Predictions Std            1066.3464
Q Predictions Max            3571.8738
Q Predictions Min            397.65732
V Predictions Mean           943.78864
V Predictions Std            1062.8496
V Predictions Max            3542.303
V Predictions Min            393.83026
Log Pis Mean                 -0.6736293
Log Pis Std                  3.3001277
Log Pis Max                  10.797032
Log Pis Min                  -6.461631
Policy mu Mean               0.006950704
Policy mu Std                0.82083994
Policy mu Max                3.5443857
Policy mu Min                -3.2741888
Policy log std Mean          -0.49904677
Policy log std Std           0.22338507
Policy log std Max           -0.12269206
Policy log std Min           -1.8185148
Z mean eval                  2.1668143
Z variance eval              0.034760572
total_rewards                [7795.34503475 8159.70861641 7913.48361879 7797.1608207  7764.715437
 8208.39650026 8207.75385941 7954.99317465 7676.50912748 8025.87969631]
total_rewards_mean           7950.394588575511
total_rewards_std            184.58159605662226
total_rewards_max            8208.39650025795
total_rewards_min            7676.509127478919
Number of train steps total  584000
Number of env steps total    1754000
Number of rollouts total     0
Train Time (s)               146.72189998207614
(Previous) Eval Time (s)     29.47909742873162
Sample Time (s)              10.066885977983475
Epoch Time (s)               186.26788338879123
Total Train Time (s)         26679.18685878953
Epoch                        145
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:15:58.810062 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #145 | Epoch Duration: 186.35174989700317
2020-01-13 11:15:58.810370 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.16067
Z variance train             0.03491925
KL Divergence                46.195908
KL Loss                      4.6195908
QF Loss                      108.560165
VF Loss                      137.05289
Policy Loss                  -978.1629
Q Predictions Mean           977.0746
Q Predictions Std            1067.9042
Q Predictions Max            3518.857
Q Predictions Min            393.68115
V Predictions Mean           980.699
V Predictions Std            1073.6798
V Predictions Max            3514.9055
V Predictions Min            394.637
Log Pis Mean                 -0.44817752
Log Pis Std                  3.6176713
Log Pis Max                  15.72006
Log Pis Min                  -7.287092
Policy mu Mean               0.08802574
Policy mu Std                0.8803269
Policy mu Max                2.750769
Policy mu Min                -2.962512
Policy log std Mean          -0.49383286
Policy log std Std           0.23356396
Policy log std Max           -0.103658274
Policy log std Min           -2.1011124
Z mean eval                  2.2152634
Z variance eval              0.054644138
total_rewards                [6854.47414647 7718.51505692 7766.08154682 7252.39962001 7877.23409471
 7423.29879081 7468.40955098 7946.98993338 7893.06971649 7595.97527202]
total_rewards_mean           7579.644772862206
total_rewards_std            323.3924158879938
total_rewards_max            7946.989933384826
total_rewards_min            6854.474146472708
Number of train steps total  588000
Number of env steps total    1766000
Number of rollouts total     0
Train Time (s)               138.68886513682082
(Previous) Eval Time (s)     28.269139660988003
Sample Time (s)              9.371137093752623
Epoch Time (s)               176.32914189156145
Total Train Time (s)         26855.595317708794
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:18:55.219836 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #146 | Epoch Duration: 176.4092779159546
2020-01-13 11:18:55.220053 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2085633
Z variance train             0.05450545
KL Divergence                45.15218
KL Loss                      4.5152183
QF Loss                      188.5307
VF Loss                      127.48637
Policy Loss                  -992.61224
Q Predictions Mean           989.46295
Q Predictions Std            1100.0321
Q Predictions Max            3502.4219
Q Predictions Min            389.97638
V Predictions Mean           997.8947
V Predictions Std            1103.971
V Predictions Max            3529.1755
V Predictions Min            395.58096
Log Pis Mean                 -0.44736385
Log Pis Std                  3.5215902
Log Pis Max                  10.425259
Log Pis Min                  -5.7723255
Policy mu Mean               0.06753543
Policy mu Std                0.8427409
Policy mu Max                2.6122077
Policy mu Min                -2.678588
Policy log std Mean          -0.4852033
Policy log std Std           0.24644853
Policy log std Max           -0.0941357
Policy log std Min           -2.0046868
Z mean eval                  2.205701
Z variance eval              0.026103502
total_rewards                [8118.04190141 8176.71715112 8330.86549354 8249.32542379 8198.26870886
 8225.41651062 8092.53184116 8364.01192446 8430.05040504 8372.84030672]
total_rewards_mean           8255.806966671895
total_rewards_std            108.42928290616615
total_rewards_max            8430.050405044627
total_rewards_min            8092.531841158328
Number of train steps total  592000
Number of env steps total    1778000
Number of rollouts total     0
Train Time (s)               138.26249262178317
(Previous) Eval Time (s)     28.797908112872392
Sample Time (s)              9.548860437702388
Epoch Time (s)               176.60926117235795
Total Train Time (s)         27032.28604117129
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:21:51.915416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #147 | Epoch Duration: 176.6951413154602
2020-01-13 11:21:51.915769 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.206962
Z variance train             0.02603669
KL Divergence                48.490204
KL Loss                      4.8490205
QF Loss                      198.23404
VF Loss                      143.72153
Policy Loss                  -918.561
Q Predictions Mean           914.1483
Q Predictions Std            1017.66986
Q Predictions Max            3582.7717
Q Predictions Min            394.85
V Predictions Mean           916.2964
V Predictions Std            1013.29675
V Predictions Max            3538.5464
V Predictions Min            400.25714
Log Pis Mean                 -0.6952983
Log Pis Std                  3.5611858
Log Pis Max                  11.727971
Log Pis Min                  -7.294753
Policy mu Mean               -0.00819838
Policy mu Std                0.8318244
Policy mu Max                2.7766924
Policy mu Min                -2.5570283
Policy log std Mean          -0.51063573
Policy log std Std           0.24416886
Policy log std Max           -0.11204159
Policy log std Min           -2.0376244
Z mean eval                  2.102614
Z variance eval              0.12778005
total_rewards                [8220.51675014 7708.9953958  8407.85243674 8496.50574242 8348.34114174
 8580.75973488 8438.00771009 8386.58781971 8476.5118092  8645.30401626]
total_rewards_mean           8370.938255698882
total_rewards_std            247.71477118065107
total_rewards_max            8645.304016260541
total_rewards_min            7708.995395797754
Number of train steps total  596000
Number of env steps total    1790000
Number of rollouts total     0
Train Time (s)               142.27736702328548
(Previous) Eval Time (s)     30.32547368714586
Sample Time (s)              8.94315970968455
Epoch Time (s)               181.5460004201159
Total Train Time (s)         27213.925034072716
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:24:53.554449 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #148 | Epoch Duration: 181.6384313106537
2020-01-13 11:24:53.554651 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #148 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1055434
Z variance train             0.1276926
KL Divergence                43.35855
KL Loss                      4.335855
QF Loss                      245.03069
VF Loss                      133.3502
Policy Loss                  -843.82574
Q Predictions Mean           838.3596
Q Predictions Std            951.2645
Q Predictions Max            3415.147
Q Predictions Min            362.89038
V Predictions Mean           836.0829
V Predictions Std            948.92676
V Predictions Max            3406.9856
V Predictions Min            368.63504
Log Pis Mean                 -0.4627629
Log Pis Std                  3.396911
Log Pis Max                  11.131153
Log Pis Min                  -8.456253
Policy mu Mean               0.030740852
Policy mu Std                0.8462595
Policy mu Max                3.013537
Policy mu Min                -2.5468633
Policy log std Mean          -0.5043103
Policy log std Std           0.24886185
Policy log std Max           -0.070535004
Policy log std Min           -2.292109
Z mean eval                  2.1960814
Z variance eval              0.032143585
total_rewards                [8130.69564892 7992.32624735 8494.04130584 8434.84662175 8534.9343467
 8520.89829893 8410.87701062 8670.99474364 8377.5060921  8581.31991075]
total_rewards_mean           8414.844022659769
total_rewards_std            196.55542456053303
total_rewards_max            8670.994743636002
total_rewards_min            7992.326247348571
Number of train steps total  600000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               149.33736945083365
(Previous) Eval Time (s)     28.090297194197774
Sample Time (s)              10.196435452438891
Epoch Time (s)               187.6241020974703
Total Train Time (s)         27401.722536771093
Epoch                        149
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:28:01.354378 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #149 | Epoch Duration: 187.79957175254822
2020-01-13 11:28:01.354586 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1945271
Z variance train             0.03191274
KL Divergence                46.25786
KL Loss                      4.625786
QF Loss                      775.32556
VF Loss                      194.0231
Policy Loss                  -1002.09247
Q Predictions Mean           1004.39404
Q Predictions Std            1093.3777
Q Predictions Max            3574.0425
Q Predictions Min            387.03534
V Predictions Mean           1013.29126
V Predictions Std            1091.8798
V Predictions Max            3568.6072
V Predictions Min            397.01248
Log Pis Mean                 -0.41965052
Log Pis Std                  3.5642405
Log Pis Max                  11.715264
Log Pis Min                  -8.099316
Policy mu Mean               0.051492024
Policy mu Std                0.87209743
Policy mu Max                2.5454862
Policy mu Min                -2.6318808
Policy log std Mean          -0.50167084
Policy log std Std           0.22551638
Policy log std Max           -0.06813264
Policy log std Min           -1.9083257
Z mean eval                  2.155246
Z variance eval              0.022399625
total_rewards                [8607.36041003 8807.65818939 8801.42298653 8698.43524751 8681.8746652
 8867.81971521 8935.86526514 8760.13301041 8472.16116383 8897.46557614]
total_rewards_mean           8753.019622938536
total_rewards_std            134.53409296513925
total_rewards_max            8935.865265144022
total_rewards_min            8472.161163832285
Number of train steps total  604000
Number of env steps total    1814000
Number of rollouts total     0
Train Time (s)               147.3363598510623
(Previous) Eval Time (s)     29.879186275880784
Sample Time (s)              10.248502959962934
Epoch Time (s)               187.46404908690602
Total Train Time (s)         27589.281292010564
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:31:08.915377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #150 | Epoch Duration: 187.56063532829285
2020-01-13 11:31:08.915570 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1547155
Z variance train             0.022518836
KL Divergence                47.404297
KL Loss                      4.74043
QF Loss                      256.48688
VF Loss                      75.91529
Policy Loss                  -992.201
Q Predictions Mean           991.39526
Q Predictions Std            1099.2003
Q Predictions Max            3692.956
Q Predictions Min            417.94598
V Predictions Mean           993.89825
V Predictions Std            1102.1956
V Predictions Max            3700.8477
V Predictions Min            390.35043
Log Pis Mean                 -0.1663377
Log Pis Std                  4.0353765
Log Pis Max                  16.229597
Log Pis Min                  -5.8489585
Policy mu Mean               0.044575855
Policy mu Std                0.8793151
Policy mu Max                3.2494922
Policy mu Min                -2.700223
Policy log std Mean          -0.52686363
Policy log std Std           0.2522707
Policy log std Max           -0.09054983
Policy log std Min           -2.124131
Z mean eval                  2.1817386
Z variance eval              0.03514453
total_rewards                [8262.8706516  8461.60993809 8764.34912284 8540.09214642 8610.60387473
 8531.48604987 8409.32708409 8607.79765021 8705.11446669 8719.97741647]
total_rewards_mean           8561.322840100105
total_rewards_std            146.66818475925425
total_rewards_max            8764.349122837319
total_rewards_min            8262.870651604255
Number of train steps total  608000
Number of env steps total    1826000
Number of rollouts total     0
Train Time (s)               147.80432791402563
(Previous) Eval Time (s)     30.34348106570542
Sample Time (s)              10.242589383386075
Epoch Time (s)               188.39039836311713
Total Train Time (s)         27777.777761233505
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:34:17.413075 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #151 | Epoch Duration: 188.4973738193512
2020-01-13 11:34:17.413226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1868093
Z variance train             0.034972716
KL Divergence                47.25806
KL Loss                      4.725806
QF Loss                      1982.8296
VF Loss                      108.704636
Policy Loss                  -937.9909
Q Predictions Mean           935.67535
Q Predictions Std            1040.4353
Q Predictions Max            3667.7405
Q Predictions Min            415.29492
V Predictions Mean           932.8441
V Predictions Std            1036.8679
V Predictions Max            3650.461
V Predictions Min            415.92593
Log Pis Mean                 -0.092122495
Log Pis Std                  3.5978491
Log Pis Max                  12.7207365
Log Pis Min                  -7.3469033
Policy mu Mean               0.07749698
Policy mu Std                0.866819
Policy mu Max                2.6699462
Policy mu Min                -2.5000176
Policy log std Mean          -0.49992618
Policy log std Std           0.23620218
Policy log std Max           -0.10484932
Policy log std Min           -2.0615244
Z mean eval                  2.2023687
Z variance eval              0.044835307
total_rewards                [8220.69048737 8560.07784312 8437.26827609 8471.46673781 8374.44825901
 8577.26336653 8525.18554398 8535.38984726 8705.56751349 8511.38649901]
total_rewards_mean           8491.874437367327
total_rewards_std            123.17450831486124
total_rewards_max            8705.567513493192
total_rewards_min            8220.690487370637
Number of train steps total  612000
Number of env steps total    1838000
Number of rollouts total     0
Train Time (s)               148.04452622309327
(Previous) Eval Time (s)     29.118592251092196
Sample Time (s)              9.33984117442742
Epoch Time (s)               186.5029596486129
Total Train Time (s)         27964.357852202374
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:37:23.996464 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #152 | Epoch Duration: 186.58311009407043
2020-01-13 11:37:23.996675 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2060943
Z variance train             0.04463592
KL Divergence                46.811844
KL Loss                      4.6811843
QF Loss                      181.62057
VF Loss                      43.599487
Policy Loss                  -982.5604
Q Predictions Mean           981.80725
Q Predictions Std            1096.9316
Q Predictions Max            3747.7546
Q Predictions Min            423.6278
V Predictions Mean           983.92346
V Predictions Std            1094.0532
V Predictions Max            3710.9856
V Predictions Min            428.91013
Log Pis Mean                 -0.82850885
Log Pis Std                  3.372351
Log Pis Max                  12.322427
Log Pis Min                  -7.001683
Policy mu Mean               -0.011787762
Policy mu Std                0.82584757
Policy mu Max                3.1993186
Policy mu Min                -2.8255088
Policy log std Mean          -0.4845331
Policy log std Std           0.22063337
Policy log std Max           -0.12245214
Policy log std Min           -1.8984147
Z mean eval                  2.1854167
Z variance eval              0.03947995
total_rewards                [8476.67459235 8779.37246379 8450.33586675 9039.24537163 8679.18961989
 8741.95118168 8710.46935242 8769.86780349 8745.24072343 8594.23972217]
total_rewards_mean           8698.658669758594
total_rewards_std            159.3712288778828
total_rewards_max            9039.24537163152
total_rewards_min            8450.335866746138
Number of train steps total  616000
Number of env steps total    1850000
Number of rollouts total     0
Train Time (s)               139.03246581507847
(Previous) Eval Time (s)     28.980010621715337
Sample Time (s)              9.779454745352268
Epoch Time (s)               177.79193118214607
Total Train Time (s)         28142.24498588359
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:40:21.886301 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #153 | Epoch Duration: 177.88947081565857
2020-01-13 11:40:21.886514 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1830328
Z variance train             0.039579898
KL Divergence                47.93748
KL Loss                      4.7937484
QF Loss                      639.4772
VF Loss                      101.40291
Policy Loss                  -1034.8179
Q Predictions Mean           1032.1671
Q Predictions Std            1111.3291
Q Predictions Max            3729.31
Q Predictions Min            398.50317
V Predictions Mean           1040.5721
V Predictions Std            1116.2089
V Predictions Max            3747.5032
V Predictions Min            404.65588
Log Pis Mean                 -0.4237611
Log Pis Std                  3.8210914
Log Pis Max                  13.990115
Log Pis Min                  -8.398929
Policy mu Mean               0.06511638
Policy mu Std                0.8804356
Policy mu Max                3.1477387
Policy mu Min                -2.9513342
Policy log std Mean          -0.5017607
Policy log std Std           0.2612086
Policy log std Max           -0.102843165
Policy log std Min           -2.5016274
Z mean eval                  2.1402385
Z variance eval              0.029461423
total_rewards                [7460.50964465 7670.66853423 7396.00577156 7274.7702716  7483.27715655
 7723.28405145 7401.4778014  7584.5914216  7272.71692133 7382.41545989]
total_rewards_mean           7464.971703425303
total_rewards_std            145.7539455774119
total_rewards_max            7723.284051450611
total_rewards_min            7272.716921329067
Number of train steps total  620000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               138.7877790192142
(Previous) Eval Time (s)     29.494442731142044
Sample Time (s)              9.71515161730349
Epoch Time (s)               177.99737336765975
Total Train Time (s)         28320.332520689815
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:43:19.976148 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #154 | Epoch Duration: 178.0894799232483
2020-01-13 11:43:19.976369 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1396544
Z variance train             0.029382577
KL Divergence                48.257942
KL Loss                      4.825794
QF Loss                      104.7632
VF Loss                      76.090034
Policy Loss                  -956.5761
Q Predictions Mean           955.19165
Q Predictions Std            1062.946
Q Predictions Max            3762.3535
Q Predictions Min            420.196
V Predictions Mean           960.42303
V Predictions Std            1064.8745
V Predictions Max            3758.3467
V Predictions Min            427.48312
Log Pis Mean                 -0.65334487
Log Pis Std                  3.725331
Log Pis Max                  14.085333
Log Pis Min                  -6.9621763
Policy mu Mean               0.14456354
Policy mu Std                0.8585484
Policy mu Max                2.8113418
Policy mu Min                -2.8405418
Policy log std Mean          -0.4775673
Policy log std Std           0.22460005
Policy log std Max           -0.092613965
Policy log std Min           -1.850003
Z mean eval                  2.1248848
Z variance eval              0.027565112
total_rewards                [8279.18580107 8287.97668422 8666.52930888 8499.38551141 8696.84463524
 8770.27692608 8615.47956094 8579.193668   8701.23568385 8547.83225433]
total_rewards_mean           8564.394003401187
total_rewards_std            159.4263550062697
total_rewards_max            8770.276926083556
total_rewards_min            8279.185801065145
Number of train steps total  624000
Number of env steps total    1874000
Number of rollouts total     0
Train Time (s)               144.46016362681985
(Previous) Eval Time (s)     30.379987614694983
Sample Time (s)              9.718787060119212
Epoch Time (s)               184.55893830163404
Total Train Time (s)         28504.971292742994
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:46:24.616861 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #155 | Epoch Duration: 184.6403408050537
2020-01-13 11:46:24.617050 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.127646
Z variance train             0.0276617
KL Divergence                49.039196
KL Loss                      4.9039197
QF Loss                      120.23288
VF Loss                      53.347874
Policy Loss                  -957.4368
Q Predictions Mean           956.4235
Q Predictions Std            1062.9421
Q Predictions Max            3670.1978
Q Predictions Min            423.72787
V Predictions Mean           961.8767
V Predictions Std            1060.3633
V Predictions Max            3654.935
V Predictions Min            430.4898
Log Pis Mean                 -0.6219578
Log Pis Std                  3.552361
Log Pis Max                  12.152086
Log Pis Min                  -10.418669
Policy mu Mean               0.05757178
Policy mu Std                0.8665121
Policy mu Max                2.5921223
Policy mu Min                -2.8131833
Policy log std Mean          -0.4722687
Policy log std Std           0.21534915
Policy log std Max           -0.11196807
Policy log std Min           -1.9895319
Z mean eval                  2.114313
Z variance eval              0.045393478
total_rewards                [8528.81439481 8811.29682797 8802.19168307 8585.75707285 8755.91336019
 8386.51704653 8481.94388083 8514.41777361 8608.89702594 8526.13313973]
total_rewards_mean           8600.188220552642
total_rewards_std            136.922863494649
total_rewards_max            8811.296827969563
total_rewards_min            8386.517046532268
Number of train steps total  628000
Number of env steps total    1886000
Number of rollouts total     0
Train Time (s)               148.61310618184507
(Previous) Eval Time (s)     29.862470478750765
Sample Time (s)              10.408858647104353
Epoch Time (s)               188.8844353077002
Total Train Time (s)         28693.941311164293
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:49:33.589495 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #156 | Epoch Duration: 188.9722979068756
2020-01-13 11:49:33.589701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1171176
Z variance train             0.04585295
KL Divergence                48.5512
KL Loss                      4.85512
QF Loss                      106.99804
VF Loss                      126.66464
Policy Loss                  -955.689
Q Predictions Mean           952.1184
Q Predictions Std            1045.0936
Q Predictions Max            3660.8723
Q Predictions Min            424.3985
V Predictions Mean           956.6178
V Predictions Std            1047.4104
V Predictions Max            3660.3303
V Predictions Min            427.03137
Log Pis Mean                 -0.5165478
Log Pis Std                  3.7175944
Log Pis Max                  14.841507
Log Pis Min                  -7.3378897
Policy mu Mean               0.029712193
Policy mu Std                0.84549093
Policy mu Max                3.2281477
Policy mu Min                -3.241565
Policy log std Mean          -0.49266252
Policy log std Std           0.23431638
Policy log std Max           -0.102323264
Policy log std Min           -2.0229764
Z mean eval                  2.149187
Z variance eval              0.042993844
total_rewards                [8282.98240833 8667.30176043 8425.43399938 8341.45286498 8790.80728978
 8804.43525717 8661.44908625 8684.53993453 8734.29557902 8555.50871255]
total_rewards_mean           8594.820689240383
total_rewards_std            176.4143705965199
total_rewards_max            8804.435257166075
total_rewards_min            8282.982408325952
Number of train steps total  632000
Number of env steps total    1898000
Number of rollouts total     0
Train Time (s)               147.76119852624834
(Previous) Eval Time (s)     30.36403524596244
Sample Time (s)              10.12054289598018
Epoch Time (s)               188.24577666819096
Total Train Time (s)         28882.267989005893
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:52:41.919982 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #157 | Epoch Duration: 188.33009243011475
2020-01-13 11:52:41.920371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1423697
Z variance train             0.043072052
KL Divergence                48.911617
KL Loss                      4.891162
QF Loss                      1911.1869
VF Loss                      35.46434
Policy Loss                  -1033.8604
Q Predictions Mean           1038.2355
Q Predictions Std            1130.2196
Q Predictions Max            3715.772
Q Predictions Min            432.3995
V Predictions Mean           1033.136
V Predictions Std            1126.3965
V Predictions Max            3693.2556
V Predictions Min            430.75012
Log Pis Mean                 -0.48902404
Log Pis Std                  3.5732906
Log Pis Max                  12.321733
Log Pis Min                  -6.528973
Policy mu Mean               0.029267281
Policy mu Std                0.8571983
Policy mu Max                2.8353326
Policy mu Min                -2.447666
Policy log std Mean          -0.487558
Policy log std Std           0.23550117
Policy log std Max           -0.117170736
Policy log std Min           -2.3037312
Z mean eval                  2.0993862
Z variance eval              0.07513456
total_rewards                [8414.39409768 8994.42638068 8935.80223142 8956.01389585 8936.84634674
 8887.64648043 9005.63483749 8798.58253418 9055.57127066 8965.24043398]
total_rewards_mean           8895.015850911208
total_rewards_std            173.29558305956954
total_rewards_max            9055.571270660357
total_rewards_min            8414.394097678542
Number of train steps total  636000
Number of env steps total    1910000
Number of rollouts total     0
Train Time (s)               148.90919490205124
(Previous) Eval Time (s)     29.320739227347076
Sample Time (s)              10.120643921662122
Epoch Time (s)               188.35057805106044
Total Train Time (s)         29070.702752627898
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:55:50.362275 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #158 | Epoch Duration: 188.44164109230042
2020-01-13 11:55:50.362664 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1019769
Z variance train             0.07486199
KL Divergence                47.4388
KL Loss                      4.7438803
QF Loss                      131.62767
VF Loss                      78.35807
Policy Loss                  -1018.49115
Q Predictions Mean           1016.4502
Q Predictions Std            1107.6648
Q Predictions Max            3741.8596
Q Predictions Min            434.1249
V Predictions Mean           1019.6417
V Predictions Std            1101.7777
V Predictions Max            3705.251
V Predictions Min            432.8506
Log Pis Mean                 -0.718588
Log Pis Std                  3.554472
Log Pis Max                  12.983827
Log Pis Min                  -6.1694045
Policy mu Mean               0.007900869
Policy mu Std                0.84985924
Policy mu Max                3.490955
Policy mu Min                -2.9115243
Policy log std Mean          -0.48373973
Policy log std Std           0.24873488
Policy log std Max           -0.11668843
Policy log std Min           -2.4860635
Z mean eval                  2.0359313
Z variance eval              0.15866081
total_rewards                [8494.1391949  8796.14142386 8609.37908591 8732.12775843 8994.61255993
 8568.5641419  8537.20241142 8731.41484327 8701.62179888 8697.27344177]
total_rewards_mean           8686.247666027042
total_rewards_std            138.0387182396435
total_rewards_max            8994.612559928646
total_rewards_min            8494.139194901523
Number of train steps total  640000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               146.56379760801792
(Previous) Eval Time (s)     29.410056767053902
Sample Time (s)              10.108592167962343
Epoch Time (s)               186.08244654303417
Total Train Time (s)         29256.885088548996
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:58:56.540560 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #159 | Epoch Duration: 186.1775677204132
2020-01-13 11:58:56.540780 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.038518
Z variance train             0.15851434
KL Divergence                43.32673
KL Loss                      4.332673
QF Loss                      236.57748
VF Loss                      97.11302
Policy Loss                  -1056.7646
Q Predictions Mean           1054.6855
Q Predictions Std            1112.8207
Q Predictions Max            3770.092
Q Predictions Min            449.99716
V Predictions Mean           1057.4009
V Predictions Std            1115.8022
V Predictions Max            3763.8777
V Predictions Min            444.22662
Log Pis Mean                 -0.2331002
Log Pis Std                  4.0263195
Log Pis Max                  17.49754
Log Pis Min                  -7.0812306
Policy mu Mean               0.033255104
Policy mu Std                0.88721377
Policy mu Max                2.8004773
Policy mu Min                -3.2599444
Policy log std Mean          -0.4961891
Policy log std Std           0.2713414
Policy log std Max           -0.0758504
Policy log std Min           -2.1955829
Z mean eval                  2.088977
Z variance eval              0.052288257
total_rewards                [ 872.14177753 8472.07508144 8565.92208946 8570.56069249 8521.31552799
 8532.05627957 8516.28831067 8647.01374244 8282.41485526 8672.34595283]
total_rewards_mean           7765.213430967779
total_rewards_std            2299.9047611812316
total_rewards_max            8672.345952828644
total_rewards_min            872.1417775318987
Number of train steps total  644000
Number of env steps total    1934000
Number of rollouts total     0
Train Time (s)               139.19680281635374
(Previous) Eval Time (s)     29.47788847517222
Sample Time (s)              10.102482394780964
Epoch Time (s)               178.77717368630692
Total Train Time (s)         29435.74489072524
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:01:55.403155 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #160 | Epoch Duration: 178.86221027374268
2020-01-13 12:01:55.403509 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0907037
Z variance train             0.052385516
KL Divergence                47.517445
KL Loss                      4.7517447
QF Loss                      196.12802
VF Loss                      68.12969
Policy Loss                  -1187.8673
Q Predictions Mean           1186.1699
Q Predictions Std            1223.6632
Q Predictions Max            3783.9285
Q Predictions Min            450.96832
V Predictions Mean           1185.8989
V Predictions Std            1218.7838
V Predictions Max            3774.3684
V Predictions Min            455.77518
Log Pis Mean                 -0.2771459
Log Pis Std                  3.905691
Log Pis Max                  12.35335
Log Pis Min                  -8.542013
Policy mu Mean               0.032076564
Policy mu Std                0.8934086
Policy mu Max                2.7043915
Policy mu Min                -2.9539065
Policy log std Mean          -0.48482463
Policy log std Std           0.25277996
Policy log std Max           -0.06858444
Policy log std Min           -2.7407053
Z mean eval                  2.0936055
Z variance eval              0.06686712
total_rewards                [8611.32901492 8504.17820141 8521.08869644 8574.76214874 8259.36465904
 8491.60458181 8380.13546023 8553.0191832  8198.45383683 8483.37975183]
total_rewards_mean           8457.731553444519
total_rewards_std            129.205346795666
total_rewards_max            8611.32901491626
total_rewards_min            8198.453836832692
Number of train steps total  648000
Number of env steps total    1946000
Number of rollouts total     0
Train Time (s)               138.11878685979173
(Previous) Eval Time (s)     29.07811583392322
Sample Time (s)              9.654133355244994
Epoch Time (s)               176.85103604895994
Total Train Time (s)         29612.74193705665
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:04:52.404166 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #161 | Epoch Duration: 177.0005190372467
2020-01-13 12:04:52.404297 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.092524
Z variance train             0.06706377
KL Divergence                48.18185
KL Loss                      4.8181853
QF Loss                      143.26582
VF Loss                      45.129936
Policy Loss                  -1040.7449
Q Predictions Mean           1040.3982
Q Predictions Std            1130.6501
Q Predictions Max            3728.0435
Q Predictions Min            446.6929
V Predictions Mean           1037.3105
V Predictions Std            1126.7078
V Predictions Max            3719.5122
V Predictions Min            446.99216
Log Pis Mean                 -0.41796237
Log Pis Std                  3.4052596
Log Pis Max                  12.762218
Log Pis Min                  -8.659999
Policy mu Mean               0.07660728
Policy mu Std                0.8789874
Policy mu Max                2.921904
Policy mu Min                -2.8081465
Policy log std Mean          -0.49949923
Policy log std Std           0.24428444
Policy log std Max           -0.11676003
Policy log std Min           -2.192954
Z mean eval                  2.0813148
Z variance eval              0.034179825
total_rewards                [8626.3044334  8781.15844789 8574.01519872 8868.33608389 8772.92516082
 8688.74247587 8685.54100629 8909.23153121 8721.08969443 8669.31765003]
total_rewards_mean           8729.66616825309
total_rewards_std            99.11811690845755
total_rewards_max            8909.231531208652
total_rewards_min            8574.015198720972
Number of train steps total  652000
Number of env steps total    1958000
Number of rollouts total     0
Train Time (s)               146.35174747090787
(Previous) Eval Time (s)     30.569273192901164
Sample Time (s)              9.372865123208612
Epoch Time (s)               186.29388578701764
Total Train Time (s)         29799.12605552608
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:07:58.793694 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #162 | Epoch Duration: 186.38920426368713
2020-01-13 12:07:58.794071 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0804863
Z variance train             0.03419448
KL Divergence                50.39032
KL Loss                      5.039032
QF Loss                      118.69335
VF Loss                      101.9218
Policy Loss                  -1018.22284
Q Predictions Mean           1016.0299
Q Predictions Std            1092.7087
Q Predictions Max            3774.8235
Q Predictions Min            436.17014
V Predictions Mean           1018.8371
V Predictions Std            1092.9938
V Predictions Max            3780.468
V Predictions Min            445.99518
Log Pis Mean                 -0.4794345
Log Pis Std                  3.8801067
Log Pis Max                  15.348597
Log Pis Min                  -7.6340714
Policy mu Mean               0.10174144
Policy mu Std                0.86293733
Policy mu Max                3.2753627
Policy mu Min                -3.2078245
Policy log std Mean          -0.48254827
Policy log std Std           0.2439983
Policy log std Max           -0.07415205
Policy log std Min           -2.3840494
Z mean eval                  2.080271
Z variance eval              0.044998292
total_rewards                [8482.57132657 8755.24359321 8570.02004013 8699.49387683 8641.38570555
 9132.20363051 9019.37561403 8729.67898742 8636.35691457 8823.0660457 ]
total_rewards_mean           8748.939573452399
total_rewards_std            188.56941508499602
total_rewards_max            9132.203630510576
total_rewards_min            8482.571326570614
Number of train steps total  656000
Number of env steps total    1970000
Number of rollouts total     0
Train Time (s)               147.44083258556202
(Previous) Eval Time (s)     30.815295004751533
Sample Time (s)              10.51669149659574
Epoch Time (s)               188.7728190869093
Total Train Time (s)         29987.98277012864
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:11:07.651885 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #163 | Epoch Duration: 188.85756492614746
2020-01-13 12:11:07.652111 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0788012
Z variance train             0.044786803
KL Divergence                50.523678
KL Loss                      5.0523677
QF Loss                      189.00824
VF Loss                      62.05076
Policy Loss                  -1074.9923
Q Predictions Mean           1072.2725
Q Predictions Std            1128.38
Q Predictions Max            3768.2617
Q Predictions Min            441.76245
V Predictions Mean           1070.5956
V Predictions Std            1126.8524
V Predictions Max            3763.9702
V Predictions Min            441.331
Log Pis Mean                 -0.58906305
Log Pis Std                  3.7530127
Log Pis Max                  17.239937
Log Pis Min                  -6.8967333
Policy mu Mean               0.065567635
Policy mu Std                0.8683863
Policy mu Max                3.1504638
Policy mu Min                -2.958657
Policy log std Mean          -0.47259292
Policy log std Std           0.25310633
Policy log std Max           -0.074973226
Policy log std Min           -2.5040793
Z mean eval                  2.065192
Z variance eval              0.029512847
total_rewards                [8728.60839423 9123.88031343 8785.49767038 8996.59719434 8833.21091745
 9029.57233837 8751.51379763 9073.9180536  9094.66433892 9133.16273314]
total_rewards_mean           8955.062575148075
total_rewards_std            154.08597792893508
total_rewards_max            9133.16273313538
total_rewards_min            8728.608394225766
Number of train steps total  660000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               147.34508167533204
(Previous) Eval Time (s)     30.548857225105166
Sample Time (s)              10.322490381542593
Epoch Time (s)               188.2164292819798
Total Train Time (s)         30176.30661080405
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:14:15.978847 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #164 | Epoch Duration: 188.3265643119812
2020-01-13 12:14:15.979074 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0653358
Z variance train             0.029497555
KL Divergence                51.008327
KL Loss                      5.100833
QF Loss                      192.37903
VF Loss                      24.635382
Policy Loss                  -985.9562
Q Predictions Mean           987.50104
Q Predictions Std            1060.8931
Q Predictions Max            3839.9624
Q Predictions Min            407.3807
V Predictions Mean           986.5171
V Predictions Std            1060.9158
V Predictions Max            3829.36
V Predictions Min            375.559
Log Pis Mean                 -0.510213
Log Pis Std                  3.4253006
Log Pis Max                  11.3540125
Log Pis Min                  -7.5761433
Policy mu Mean               0.05341028
Policy mu Std                0.83715177
Policy mu Max                2.504739
Policy mu Min                -2.6280622
Policy log std Mean          -0.47995055
Policy log std Std           0.25422564
Policy log std Max           -0.11248653
Policy log std Min           -2.632633
Z mean eval                  2.0572486
Z variance eval              0.027313525
total_rewards                [8414.4886776  8357.18391078 8107.50615249 8328.22705949 8267.37140704
 8452.60861146 8560.04222005 8218.24790022 8492.55711032 8336.54437556]
total_rewards_mean           8353.477742499992
total_rewards_std            127.55497765967962
total_rewards_max            8560.04222004893
total_rewards_min            8107.506152487046
Number of train steps total  664000
Number of env steps total    1994000
Number of rollouts total     0
Train Time (s)               149.34385490324348
(Previous) Eval Time (s)     29.38843216560781
Sample Time (s)              10.336214213632047
Epoch Time (s)               189.06850128248334
Total Train Time (s)         30365.456127294805
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:17:25.130935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #165 | Epoch Duration: 189.14977288246155
2020-01-13 12:17:25.131371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0592177
Z variance train             0.027386133
KL Divergence                51.509186
KL Loss                      5.1509185
QF Loss                      243.35056
VF Loss                      152.94676
Policy Loss                  -1169.4037
Q Predictions Mean           1169.5459
Q Predictions Std            1197.1067
Q Predictions Max            3846.7192
Q Predictions Min            458.2905
V Predictions Mean           1165.673
V Predictions Std            1197.1488
V Predictions Max            3845.6072
V Predictions Min            455.76926
Log Pis Mean                 -0.38107604
Log Pis Std                  4.040452
Log Pis Max                  14.450258
Log Pis Min                  -6.8665442
Policy mu Mean               0.070813395
Policy mu Std                0.90103245
Policy mu Max                3.352597
Policy mu Min                -2.9588563
Policy log std Mean          -0.5023472
Policy log std Std           0.2580431
Policy log std Max           -0.09949902
Policy log std Min           -2.4583118
Z mean eval                  2.0619712
Z variance eval              0.052271686
total_rewards                [8226.14447878 8502.56639844 8717.5035838  8497.39435372 8278.60614236
 8305.79711046 8564.22811279 8467.46620158 8534.3377758  8677.13990548]
total_rewards_mean           8477.118406321753
total_rewards_std            155.41997553448772
total_rewards_max            8717.50358380224
total_rewards_min            8226.14447877769
Number of train steps total  668000
Number of env steps total    2006000
Number of rollouts total     0
Train Time (s)               146.21844824496657
(Previous) Eval Time (s)     29.044337684754282
Sample Time (s)              10.441966796759516
Epoch Time (s)               185.70475272648036
Total Train Time (s)         30551.243156235665
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:20:30.918576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #166 | Epoch Duration: 185.7870306968689
2020-01-13 12:20:30.918722 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.061555
Z variance train             0.052122883
KL Divergence                51.110584
KL Loss                      5.1110587
QF Loss                      2305.6284
VF Loss                      76.98999
Policy Loss                  -1033.9968
Q Predictions Mean           1034.1218
Q Predictions Std            1114.0656
Q Predictions Max            3846.504
Q Predictions Min            466.44806
V Predictions Mean           1038.5042
V Predictions Std            1115.5817
V Predictions Max            3854.1284
V Predictions Min            467.35068
Log Pis Mean                 -0.29161742
Log Pis Std                  3.8608086
Log Pis Max                  13.962753
Log Pis Min                  -5.6271005
Policy mu Mean               0.02971225
Policy mu Std                0.8664263
Policy mu Max                2.6862745
Policy mu Min                -3.0667257
Policy log std Mean          -0.50445455
Policy log std Std           0.26162484
Policy log std Max           -0.13356945
Policy log std Min           -2.248378
Z mean eval                  2.011781
Z variance eval              0.050130874
total_rewards                [8987.81034936 9020.74190607 9243.38878654 9083.79504363 9034.4403238
 8942.02140973 9266.76650974 9064.48232079 9171.70013617 8982.64791257]
total_rewards_mean           9079.779469839297
total_rewards_std            106.22754438750276
total_rewards_max            9266.766509735076
total_rewards_min            8942.021409727266
Number of train steps total  672000
Number of env steps total    2018000
Number of rollouts total     0
Train Time (s)               138.90807302715257
(Previous) Eval Time (s)     28.903620639815927
Sample Time (s)              9.522300300654024
Epoch Time (s)               177.33399396762252
Total Train Time (s)         30728.656737839803
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:23:28.333875 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #167 | Epoch Duration: 177.41504502296448
2020-01-13 12:23:28.334016 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0116751
Z variance train             0.05016293
KL Divergence                50.308357
KL Loss                      5.0308356
QF Loss                      118.93103
VF Loss                      68.106544
Policy Loss                  -1056.5422
Q Predictions Mean           1054.0464
Q Predictions Std            1143.218
Q Predictions Max            3868.3706
Q Predictions Min            451.56537
V Predictions Mean           1054.0314
V Predictions Std            1135.4818
V Predictions Max            3852.9734
V Predictions Min            457.7945
Log Pis Mean                 -0.39427558
Log Pis Std                  3.7918506
Log Pis Max                  14.154652
Log Pis Min                  -6.3506284
Policy mu Mean               0.024261795
Policy mu Std                0.84954107
Policy mu Max                2.9915388
Policy mu Min                -2.9648955
Policy log std Mean          -0.5058425
Policy log std Std           0.25481188
Policy log std Max           -0.13026544
Policy log std Min           -2.6480656
Z mean eval                  1.9921631
Z variance eval              0.024620848
total_rewards                [8762.5317907  9261.919872   8755.49818921 9274.93605347 8952.06999482
 6153.68428407 9157.65519715 9228.24002931 8929.00766266 9019.71386734]
total_rewards_mean           8749.525694072556
total_rewards_std            884.2611616641001
total_rewards_max            9274.93605347022
total_rewards_min            6153.684284073283
Number of train steps total  676000
Number of env steps total    2030000
Number of rollouts total     0
Train Time (s)               138.8907105117105
(Previous) Eval Time (s)     29.542864105664194
Sample Time (s)              9.589354590512812
Epoch Time (s)               178.0229292078875
Total Train Time (s)         30906.76571068773
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:26:26.447451 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #168 | Epoch Duration: 178.11330556869507
2020-01-13 12:26:26.447699 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #168 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9928373
Z variance train             0.024756106
KL Divergence                51.449814
KL Loss                      5.1449814
QF Loss                      1835.0958
VF Loss                      40.2664
Policy Loss                  -975.5558
Q Predictions Mean           973.15186
Q Predictions Std            1055.018
Q Predictions Max            3773.9263
Q Predictions Min            461.101
V Predictions Mean           978.67737
V Predictions Std            1054.8064
V Predictions Max            3767.4727
V Predictions Min            467.48196
Log Pis Mean                 -0.70400316
Log Pis Std                  3.4757066
Log Pis Max                  12.072732
Log Pis Min                  -7.1400423
Policy mu Mean               0.029558904
Policy mu Std                0.836216
Policy mu Max                2.925242
Policy mu Min                -2.5921323
Policy log std Mean          -0.47579083
Policy log std Std           0.2564754
Policy log std Max           -0.092990994
Policy log std Min           -2.5380125
Z mean eval                  2.0424314
Z variance eval              0.028655168
total_rewards                [8305.03382643 9654.91634205 9030.52344567 9060.14512969 9193.123224
 9073.20582401 9190.39759017 8695.81786359  967.32962219 9340.51895545]
total_rewards_mean           8251.101182324233
total_rewards_std            2451.92023459167
total_rewards_max            9654.916342048868
total_rewards_min            967.3296221913628
Number of train steps total  680000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               147.35599661711603
(Previous) Eval Time (s)     31.01493593584746
Sample Time (s)              9.902735934592783
Epoch Time (s)               188.27366848755628
Total Train Time (s)         31095.125047461595
Epoch                        169
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:29:34.810879 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #169 | Epoch Duration: 188.36294388771057
2020-01-13 12:29:34.811644 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0417747
Z variance train             0.0286634
KL Divergence                51.866726
KL Loss                      5.1866727
QF Loss                      153.32265
VF Loss                      113.81043
Policy Loss                  -954.59064
Q Predictions Mean           948.28674
Q Predictions Std            1014.69556
Q Predictions Max            3815.9248
Q Predictions Min            470.61414
V Predictions Mean           958.1064
V Predictions Std            1015.2483
V Predictions Max            3817.5708
V Predictions Min            474.9649
Log Pis Mean                 -0.6078588
Log Pis Std                  3.5283787
Log Pis Max                  14.541546
Log Pis Min                  -7.6056013
Policy mu Mean               0.16008733
Policy mu Std                0.850935
Policy mu Max                3.6215177
Policy mu Min                -3.1743245
Policy log std Mean          -0.49440864
Policy log std Std           0.24288784
Policy log std Max           -0.10002375
Policy log std Min           -2.3150685
Z mean eval                  2.0093029
Z variance eval              0.031214258
total_rewards                [8549.10570954 8730.71517282 9014.54035357 8946.56376616 8655.08737275
 9038.77294568 8507.87223674 8872.10956159 8991.87202497 8900.83588834]
total_rewards_mean           8820.747503216184
total_rewards_std            186.14123740693003
total_rewards_max            9038.772945681256
total_rewards_min            8507.872236744302
Number of train steps total  684000
Number of env steps total    2054000
Number of rollouts total     0
Train Time (s)               146.89505851874128
(Previous) Eval Time (s)     30.21684702625498
Sample Time (s)              9.99187989672646
Epoch Time (s)               187.10378544172272
Total Train Time (s)         31282.319178858772
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:32:42.006029 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #170 | Epoch Duration: 187.1939561367035
2020-01-13 12:32:42.006274 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0064855
Z variance train             0.031226119
KL Divergence                51.432915
KL Loss                      5.1432915
QF Loss                      114.3945
VF Loss                      45.19129
Policy Loss                  -1001.857
Q Predictions Mean           1002.36865
Q Predictions Std            1079.2767
Q Predictions Max            3881.6711
Q Predictions Min            470.9236
V Predictions Mean           1004.51025
V Predictions Std            1078.3473
V Predictions Max            3902.6091
V Predictions Min            472.53302
Log Pis Mean                 -0.6200917
Log Pis Std                  3.4119606
Log Pis Max                  12.907988
Log Pis Min                  -7.58204
Policy mu Mean               0.034051143
Policy mu Std                0.85709935
Policy mu Max                2.863758
Policy mu Min                -3.207958
Policy log std Mean          -0.47071448
Policy log std Std           0.22804256
Policy log std Max           -0.091442764
Policy log std Min           -2.1367588
Z mean eval                  1.9648384
Z variance eval              0.04554338
total_rewards                [8847.78217009 8712.28298854 8870.47886701 8934.71803446 8962.22594662
 9025.40461268 9267.97497828 8999.93763121 9044.8551606  9137.93090971]
total_rewards_mean           8980.359129917611
total_rewards_std            147.66548519632843
total_rewards_max            9267.974978279452
total_rewards_min            8712.282988535431
Number of train steps total  688000
Number of env steps total    2066000
Number of rollouts total     0
Train Time (s)               147.3518476788886
(Previous) Eval Time (s)     29.82857843581587
Sample Time (s)              10.67811676999554
Epoch Time (s)               187.8585428847
Total Train Time (s)         31470.261907854117
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:35:49.951360 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #171 | Epoch Duration: 187.9449121952057
2020-01-13 12:35:49.951583 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9676096
Z variance train             0.045858227
KL Divergence                48.77925
KL Loss                      4.8779254
QF Loss                      173.60751
VF Loss                      76.366974
Policy Loss                  -1011.24506
Q Predictions Mean           1006.8497
Q Predictions Std            1083.1375
Q Predictions Max            3850.974
Q Predictions Min            461.4361
V Predictions Mean           1006.597
V Predictions Std            1080.275
V Predictions Max            3838.498
V Predictions Min            464.43948
Log Pis Mean                 -0.39600682
Log Pis Std                  3.5285997
Log Pis Max                  18.906393
Log Pis Min                  -7.4345784
Policy mu Mean               0.045785483
Policy mu Std                0.8536841
Policy mu Max                3.3581035
Policy mu Min                -3.4611664
Policy log std Mean          -0.5053821
Policy log std Std           0.23366924
Policy log std Max           -0.13571404
Policy log std Min           -2.5069427
Z mean eval                  1.9423927
Z variance eval              0.037884925
total_rewards                [8395.00593493 8549.02962012 9061.88296279 8500.30715355 8271.18377525
 9151.87336865 8365.09516125 8622.56035803 8099.47202785 8122.39533893]
total_rewards_mean           8513.880570136458
total_rewards_std            337.7480658977902
total_rewards_max            9151.873368654617
total_rewards_min            8099.472027849242
Number of train steps total  692000
Number of env steps total    2078000
Number of rollouts total     0
Train Time (s)               148.62380821397528
(Previous) Eval Time (s)     30.341711704153568
Sample Time (s)              10.478574963286519
Epoch Time (s)               189.44409488141537
Total Train Time (s)         31659.789719273802
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:38:59.481777 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #172 | Epoch Duration: 189.53003096580505
2020-01-13 12:38:59.482014 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9430269
Z variance train             0.037840333
KL Divergence                48.610435
KL Loss                      4.8610435
QF Loss                      162.73528
VF Loss                      59.6011
Policy Loss                  -1036.9028
Q Predictions Mean           1034.1572
Q Predictions Std            1125.5632
Q Predictions Max            3881.0437
Q Predictions Min            475.47528
V Predictions Mean           1037.8306
V Predictions Std            1127.9014
V Predictions Max            3898.7031
V Predictions Min            479.79605
Log Pis Mean                 -0.51255834
Log Pis Std                  3.558608
Log Pis Max                  11.006218
Log Pis Min                  -7.129802
Policy mu Mean               0.106965184
Policy mu Std                0.85607195
Policy mu Max                3.0427248
Policy mu Min                -2.2160244
Policy log std Mean          -0.46735254
Policy log std Std           0.23061386
Policy log std Max           -0.03921634
Policy log std Min           -2.3067317
Z mean eval                  1.9647042
Z variance eval              0.064683415
total_rewards                [9040.54456897 8842.90977615 8540.85725857 8900.814265   8881.12376202
 8852.50528707 8739.56049391 8619.91879473 8990.05058118 8837.44843216]
total_rewards_mean           8824.573321975973
total_rewards_std            146.26161023522806
total_rewards_max            9040.544568966698
total_rewards_min            8540.857258570255
Number of train steps total  696000
Number of env steps total    2090000
Number of rollouts total     0
Train Time (s)               144.3755367831327
(Previous) Eval Time (s)     28.610009549185634
Sample Time (s)              10.33257382037118
Epoch Time (s)               183.31812015268952
Total Train Time (s)         31843.265702241566
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:42:02.960515 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #173 | Epoch Duration: 183.47832918167114
2020-01-13 12:42:02.960764 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9670372
Z variance train             0.06476463
KL Divergence                48.9779
KL Loss                      4.8977904
QF Loss                      119.911705
VF Loss                      30.988598
Policy Loss                  -1115.8229
Q Predictions Mean           1115.0107
Q Predictions Std            1155.6947
Q Predictions Max            3930.6052
Q Predictions Min            488.97
V Predictions Mean           1116.1906
V Predictions Std            1157.0376
V Predictions Max            3911.0432
V Predictions Min            488.26144
Log Pis Mean                 -0.41412494
Log Pis Std                  3.599601
Log Pis Max                  11.660397
Log Pis Min                  -9.209082
Policy mu Mean               0.039444033
Policy mu Std                0.8980873
Policy mu Max                2.7892418
Policy mu Min                -2.9835293
Policy log std Mean          -0.48089132
Policy log std Std           0.24042454
Policy log std Max           -0.09311283
Policy log std Min           -2.0323386
Z mean eval                  1.9533596
Z variance eval              0.041765608
total_rewards                [9146.52828445 9288.04528486 9287.88134137 9314.72617275 9465.97744975
 9451.42155093 8928.93268398 9198.17006079 9403.69084592 9239.1211002 ]
total_rewards_mean           9272.44947750025
total_rewards_std            151.48109230548775
total_rewards_max            9465.97744975406
total_rewards_min            8928.93268397701
Number of train steps total  700000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               138.9276871001348
(Previous) Eval Time (s)     29.451921520754695
Sample Time (s)              9.564154892228544
Epoch Time (s)               177.94376351311803
Total Train Time (s)         32021.330171806738
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:45:01.027313 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #174 | Epoch Duration: 178.06636786460876
2020-01-13 12:45:01.027532 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9521786
Z variance train             0.041797552
KL Divergence                51.291817
KL Loss                      5.129182
QF Loss                      192.09938
VF Loss                      73.07231
Policy Loss                  -1076.8768
Q Predictions Mean           1074.4991
Q Predictions Std            1145.4336
Q Predictions Max            3970.5522
Q Predictions Min            483.74466
V Predictions Mean           1080.1007
V Predictions Std            1143.9653
V Predictions Max            3955.6682
V Predictions Min            487.94687
Log Pis Mean                 -0.55175006
Log Pis Std                  3.3956506
Log Pis Max                  15.893473
Log Pis Min                  -6.610014
Policy mu Mean               0.044412564
Policy mu Std                0.8560575
Policy mu Max                2.8504782
Policy mu Min                -3.1650023
Policy log std Mean          -0.5039368
Policy log std Std           0.26914015
Policy log std Max           -0.11204374
Policy log std Min           -2.8798537
Z mean eval                  1.9407545
Z variance eval              0.055985563
total_rewards                [8837.51843679 8878.89440639 9030.71989035 8931.00136285 8838.28311978
 8643.19162903 8785.95207406 8989.71668174 8888.58292669 8668.64457843]
total_rewards_mean           8849.250510612172
total_rewards_std            118.79152540093764
total_rewards_max            9030.719890345516
total_rewards_min            8643.191629030449
Number of train steps total  704000
Number of env steps total    2114000
Number of rollouts total     0
Train Time (s)               139.09171475702897
(Previous) Eval Time (s)     30.094175776001066
Sample Time (s)              9.530290581285954
Epoch Time (s)               178.716181114316
Total Train Time (s)         32200.127687871456
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:47:59.827494 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #175 | Epoch Duration: 178.7997977733612
2020-01-13 12:47:59.827713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9393566
Z variance train             0.055832904
KL Divergence                50.320232
KL Loss                      5.0320234
QF Loss                      4296.388
VF Loss                      46.93524
Policy Loss                  -1060.5804
Q Predictions Mean           1059.8915
Q Predictions Std            1112.8181
Q Predictions Max            4011.789
Q Predictions Min            482.82608
V Predictions Mean           1062.5701
V Predictions Std            1113.1864
V Predictions Max            4007.9363
V Predictions Min            491.83676
Log Pis Mean                 -0.47311157
Log Pis Std                  3.1847038
Log Pis Max                  9.594635
Log Pis Min                  -5.2763834
Policy mu Mean               0.06509998
Policy mu Std                0.84872156
Policy mu Max                2.852513
Policy mu Min                -2.7651014
Policy log std Mean          -0.47645307
Policy log std Std           0.22505325
Policy log std Max           -0.07202971
Policy log std Min           -2.1265278
Z mean eval                  1.9331948
Z variance eval              0.05834096
total_rewards                [8503.19347832 8589.48907388 8892.46325628 8750.17914026 8908.30831355
 9093.27750557 8759.41102539 8334.67829388 9039.70899621 9143.1088798 ]
total_rewards_mean           8801.38179631477
total_rewards_std            251.89674212205912
total_rewards_max            9143.10887980114
total_rewards_min            8334.678293877123
Number of train steps total  708000
Number of env steps total    2126000
Number of rollouts total     0
Train Time (s)               147.63156989216805
(Previous) Eval Time (s)     30.38207650044933
Sample Time (s)              10.313375811558217
Epoch Time (s)               188.3270222041756
Total Train Time (s)         32388.535402645823
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:51:08.237654 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #176 | Epoch Duration: 188.40978121757507
2020-01-13 12:51:08.237866 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #176 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9339005
Z variance train             0.05834223
KL Divergence                50.229855
KL Loss                      5.0229855
QF Loss                      204.52425
VF Loss                      128.11517
Policy Loss                  -1003.05536
Q Predictions Mean           997.51917
Q Predictions Std            1068.8357
Q Predictions Max            3899.3225
Q Predictions Min            488.45255
V Predictions Mean           1000.7956
V Predictions Std            1065.8785
V Predictions Max            3880.2
V Predictions Min            492.42236
Log Pis Mean                 -0.72949904
Log Pis Std                  3.3396888
Log Pis Max                  13.449586
Log Pis Min                  -6.707367
Policy mu Mean               0.024607474
Policy mu Std                0.83597344
Policy mu Max                2.7199783
Policy mu Min                -2.9641297
Policy log std Mean          -0.47630802
Policy log std Std           0.23861484
Policy log std Max           -0.07149264
Policy log std Min           -2.5776117
Z mean eval                  1.9364363
Z variance eval              0.049440607
total_rewards                [8603.99464059 8819.00558038 8913.80303427 8598.02355624 8857.9484151
 9102.53641043 8641.61755579 8588.96076069 8733.15329951 9178.5405722 ]
total_rewards_mean           8803.758382518527
total_rewards_std            201.16012945759678
total_rewards_max            9178.540572197648
total_rewards_min            8588.96076068663
Number of train steps total  712000
Number of env steps total    2138000
Number of rollouts total     0
Train Time (s)               147.24362300289795
(Previous) Eval Time (s)     29.182817824184895
Sample Time (s)              9.199539371300489
Epoch Time (s)               185.62598019838333
Total Train Time (s)         32574.25195428217
Epoch                        177
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:54:13.956835 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #177 | Epoch Duration: 185.71880316734314
2020-01-13 12:54:13.957108 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9361403
Z variance train             0.04952144
KL Divergence                50.998905
KL Loss                      5.0998907
QF Loss                      122.471664
VF Loss                      46.86341
Policy Loss                  -1123.6644
Q Predictions Mean           1119.7548
Q Predictions Std            1177.932
Q Predictions Max            3946.0225
Q Predictions Min            486.47363
V Predictions Mean           1121.508
V Predictions Std            1176.6084
V Predictions Max            3928.236
V Predictions Min            486.73532
Log Pis Mean                 -0.56523764
Log Pis Std                  3.5589895
Log Pis Max                  12.658583
Log Pis Min                  -8.538107
Policy mu Mean               0.039446253
Policy mu Std                0.84595627
Policy mu Max                2.9054801
Policy mu Min                -2.788606
Policy log std Mean          -0.4908106
Policy log std Std           0.2515977
Policy log std Max           -0.048332155
Policy log std Min           -2.5367289
Z mean eval                  1.9408255
Z variance eval              0.058695506
total_rewards                [8231.13624803 8109.04264903 8225.10950982 8513.59099069 8963.15941257
 8056.83696758 8432.68250843 8569.35385626 8416.60950502 8350.68689367]
total_rewards_mean           8386.820854109621
total_rewards_std            249.45736480477737
total_rewards_max            8963.159412566474
total_rewards_min            8056.836967582703
Number of train steps total  716000
Number of env steps total    2150000
Number of rollouts total     0
Train Time (s)               146.22352354088798
(Previous) Eval Time (s)     30.276424020994455
Sample Time (s)              10.606714885681868
Epoch Time (s)               187.1066624475643
Total Train Time (s)         32761.43847739324
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:57:21.146867 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #178 | Epoch Duration: 187.18956851959229
2020-01-13 12:57:21.147219 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9418011
Z variance train             0.058627028
KL Divergence                49.030354
KL Loss                      4.9030356
QF Loss                      97.09429
VF Loss                      47.56856
Policy Loss                  -1057.3707
Q Predictions Mean           1055.7228
Q Predictions Std            1139.593
Q Predictions Max            4029.3718
Q Predictions Min            481.11252
V Predictions Mean           1060.9369
V Predictions Std            1137.5897
V Predictions Max            4015.4326
V Predictions Min            486.88736
Log Pis Mean                 -0.5348885
Log Pis Std                  3.827223
Log Pis Max                  19.504189
Log Pis Min                  -7.4101176
Policy mu Mean               0.07398491
Policy mu Std                0.8860419
Policy mu Max                3.0662193
Policy mu Min                -3.4262702
Policy log std Mean          -0.47833022
Policy log std Std           0.25796318
Policy log std Max           -0.11561161
Policy log std Min           -2.5490515
Z mean eval                  1.9412243
Z variance eval              0.037696026
total_rewards                [9018.12613881 9389.04729295 9017.64329431 9222.64448849 9185.71627475
 7601.40539873 8923.02793312 8629.86899351 9052.82669775 8744.17698593]
total_rewards_mean           8878.448349834889
total_rewards_std            474.924762416413
total_rewards_max            9389.047292952473
total_rewards_min            7601.405398725975
Number of train steps total  720000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               148.16451917402446
(Previous) Eval Time (s)     29.893246869090945
Sample Time (s)              10.557952008210123
Epoch Time (s)               188.61571805132553
Total Train Time (s)         32950.13556086831
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:00:29.845776 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #179 | Epoch Duration: 188.69835543632507
2020-01-13 13:00:29.845974 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #179 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9367956
Z variance train             0.037942886
KL Divergence                49.78205
KL Loss                      4.978205
QF Loss                      117.694664
VF Loss                      82.3996
Policy Loss                  -1021.34894
Q Predictions Mean           1019.3909
Q Predictions Std            1105.4117
Q Predictions Max            4012.132
Q Predictions Min            492.43774
V Predictions Mean           1023.9137
V Predictions Std            1103.8093
V Predictions Max            3966.5808
V Predictions Min            496.23145
Log Pis Mean                 -0.7225971
Log Pis Std                  3.477234
Log Pis Max                  12.280769
Log Pis Min                  -6.236669
Policy mu Mean               0.09823251
Policy mu Std                0.8453424
Policy mu Max                2.7182631
Policy mu Min                -2.6215374
Policy log std Mean          -0.48751318
Policy log std Std           0.2371777
Policy log std Max           -0.10988352
Policy log std Min           -2.6464076
Z mean eval                  1.9079382
Z variance eval              0.07056258
total_rewards                [8985.32081107 9507.01356089 8942.11950867 9151.68349206 9051.7434156
 9113.42337464 8950.46186629 9207.65229514 9183.37001555 9141.80944354]
total_rewards_mean           9123.459778345376
total_rewards_std            156.86405581949512
total_rewards_max            9507.01356088754
total_rewards_min            8942.119508674434
Number of train steps total  724000
Number of env steps total    2174000
Number of rollouts total     0
Train Time (s)               143.3023061589338
(Previous) Eval Time (s)     29.362628073897213
Sample Time (s)              9.718804797623307
Epoch Time (s)               182.3837390304543
Total Train Time (s)         33132.64071074175
Epoch                        180
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:03:32.353272 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #180 | Epoch Duration: 182.50715827941895
2020-01-13 13:03:32.353454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9090945
Z variance train             0.070080325
KL Divergence                49.00385
KL Loss                      4.900385
QF Loss                      213.30762
VF Loss                      167.18324
Policy Loss                  -1099.7386
Q Predictions Mean           1093.2861
Q Predictions Std            1166.8926
Q Predictions Max            4013.5623
Q Predictions Min            470.58786
V Predictions Mean           1096.4291
V Predictions Std            1159.369
V Predictions Max            3981.045
V Predictions Min            493.043
Log Pis Mean                 -0.08214054
Log Pis Std                  4.2250586
Log Pis Max                  16.084963
Log Pis Min                  -11.045612
Policy mu Mean               0.08019078
Policy mu Std                0.9050186
Policy mu Max                3.2994976
Policy mu Min                -3.9725585
Policy log std Mean          -0.5070669
Policy log std Std           0.273952
Policy log std Max           -0.08461636
Policy log std Min           -2.7833862
Z mean eval                  1.9454508
Z variance eval              0.052446842
total_rewards                [8925.17875768 8712.03749641 8575.85511486 8975.00973277 9324.11454388
 8539.21916313 9008.75589457 8428.27420141 8714.41952442 8451.9823945 ]
total_rewards_mean           8765.484682362461
total_rewards_std            272.9955040590547
total_rewards_max            9324.114543875112
total_rewards_min            8428.274201407858
Number of train steps total  728000
Number of env steps total    2186000
Number of rollouts total     0
Train Time (s)               139.15647706016898
(Previous) Eval Time (s)     29.550926784984767
Sample Time (s)              9.771641636732966
Epoch Time (s)               178.47904548188671
Total Train Time (s)         33311.28298304463
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:06:30.998329 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #181 | Epoch Duration: 178.64473009109497
2020-01-13 13:06:30.998533 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9479742
Z variance train             0.05261262
KL Divergence                51.367516
KL Loss                      5.1367517
QF Loss                      192.61458
VF Loss                      142.67879
Policy Loss                  -1115.1973
Q Predictions Mean           1109.5247
Q Predictions Std            1175.656
Q Predictions Max            3934.6567
Q Predictions Min            501.13794
V Predictions Mean           1107.7196
V Predictions Std            1171.1675
V Predictions Max            3921.7703
V Predictions Min            497.76764
Log Pis Mean                 -0.41840714
Log Pis Std                  3.876518
Log Pis Max                  21.364971
Log Pis Min                  -8.471304
Policy mu Mean               0.006785799
Policy mu Std                0.8625613
Policy mu Max                2.8059278
Policy mu Min                -3.4685175
Policy log std Mean          -0.48070726
Policy log std Std           0.24398468
Policy log std Max           -0.08523244
Policy log std Min           -2.5041075
Z mean eval                  1.925317
Z variance eval              0.078164145
total_rewards                [8701.5537345  9101.68118792 8788.9724376  8930.34879401 9016.40996717
 8970.14135815 8960.02494283 9061.8366054  9047.61445739 8956.60803861]
total_rewards_mean           8953.519152356785
total_rewards_std            117.43979875963157
total_rewards_max            9101.681187920613
total_rewards_min            8701.553734498273
Number of train steps total  732000
Number of env steps total    2198000
Number of rollouts total     0
Train Time (s)               140.0440906570293
(Previous) Eval Time (s)     30.003740685991943
Sample Time (s)              9.20689451135695
Epoch Time (s)               179.2547258543782
Total Train Time (s)         33490.61950517632
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:09:30.336485 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #182 | Epoch Duration: 179.3378026485443
2020-01-13 13:09:30.336652 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.921369
Z variance train             0.07802439
KL Divergence                50.826122
KL Loss                      5.0826125
QF Loss                      299.59686
VF Loss                      189.92339
Policy Loss                  -1030.5309
Q Predictions Mean           1025.836
Q Predictions Std            1105.8052
Q Predictions Max            3911.8152
Q Predictions Min            480.88785
V Predictions Mean           1038.8424
V Predictions Std            1109.7521
V Predictions Max            3914.9912
V Predictions Min            485.08926
Log Pis Mean                 -0.4642915
Log Pis Std                  3.4850738
Log Pis Max                  14.5157795
Log Pis Min                  -6.714938
Policy mu Mean               0.12583391
Policy mu Std                0.8531608
Policy mu Max                3.3320043
Policy mu Min                -2.8375134
Policy log std Mean          -0.4851304
Policy log std Std           0.24261391
Policy log std Max           -0.09127593
Policy log std Min           -2.5609212
Z mean eval                  1.9254701
Z variance eval              0.08996547
total_rewards                [8927.65177671 9359.78429033 9351.10748854 9631.80423924 9585.85163599
 9418.19994587 9059.52019492 9046.03548232 9343.73385404 9175.25741285]
total_rewards_mean           9289.894632082449
total_rewards_std            221.22080951849486
total_rewards_max            9631.804239242118
total_rewards_min            8927.651776713785
Number of train steps total  736000
Number of env steps total    2210000
Number of rollouts total     0
Train Time (s)               149.61264483397827
(Previous) Eval Time (s)     31.383650433272123
Sample Time (s)              10.012826483231038
Epoch Time (s)               191.00912175048143
Total Train Time (s)         33681.71343564289
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:12:41.433234 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #183 | Epoch Duration: 191.09643650054932
2020-01-13 13:12:41.433464 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9239031
Z variance train             0.09004324
KL Divergence                52.28631
KL Loss                      5.228631
QF Loss                      2574.7725
VF Loss                      51.616764
Policy Loss                  -1107.1185
Q Predictions Mean           1108.9635
Q Predictions Std            1166.8344
Q Predictions Max            4040.808
Q Predictions Min            519.4063
V Predictions Mean           1109.9285
V Predictions Std            1165.8997
V Predictions Max            4023.188
V Predictions Min            521.2471
Log Pis Mean                 0.024978474
Log Pis Std                  3.833364
Log Pis Max                  15.110693
Log Pis Min                  -6.639738
Policy mu Mean               0.06110699
Policy mu Std                0.9086543
Policy mu Max                3.0431836
Policy mu Min                -3.4720562
Policy log std Mean          -0.49914297
Policy log std Std           0.2666703
Policy log std Max           -0.08988309
Policy log std Min           -2.6452806
Z mean eval                  1.9570885
Z variance eval              0.061071627
total_rewards                [4781.59942777 9219.82226957 9618.19571416 9487.92481085 9164.55304494
 9470.51259143 9677.27034387 9507.32926776 9511.34217927 9664.57266151]
total_rewards_mean           9010.312231111635
total_rewards_std            1418.8045641858948
total_rewards_max            9677.270343869046
total_rewards_min            4781.599427770526
Number of train steps total  740000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               147.70548482099548
(Previous) Eval Time (s)     29.46096076304093
Sample Time (s)              9.629806211218238
Epoch Time (s)               186.79625179525465
Total Train Time (s)         33868.58921069559
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:15:48.311814 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #184 | Epoch Duration: 186.87818694114685
2020-01-13 13:15:48.312038 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.95275
Z variance train             0.060998697
KL Divergence                51.906155
KL Loss                      5.1906157
QF Loss                      105.72724
VF Loss                      82.007126
Policy Loss                  -1032.5393
Q Predictions Mean           1033.1185
Q Predictions Std            1085.0953
Q Predictions Max            3962.337
Q Predictions Min            513.8967
V Predictions Mean           1034.9559
V Predictions Std            1086.3969
V Predictions Max            3972.6108
V Predictions Min            514.1047
Log Pis Mean                 -0.86006814
Log Pis Std                  3.7084157
Log Pis Max                  17.966967
Log Pis Min                  -6.619138
Policy mu Mean               0.07863775
Policy mu Std                0.81172997
Policy mu Max                3.0636256
Policy mu Min                -3.3132331
Policy log std Mean          -0.45299062
Policy log std Std           0.22764637
Policy log std Max           -0.05371517
Policy log std Min           -2.3840466
Z mean eval                  1.9401417
Z variance eval              0.10120217
total_rewards                [8935.89206188 9025.46480388 8986.41690747 8804.47110284 9225.91642328
 9437.79211727 9329.17822258 9035.5328887  9439.35541408 9302.70350287]
total_rewards_mean           9152.272344483988
total_rewards_std            211.72843744272132
total_rewards_max            9439.35541407722
total_rewards_min            8804.471102843727
Number of train steps total  744000
Number of env steps total    2234000
Number of rollouts total     0
Train Time (s)               147.19213108997792
(Previous) Eval Time (s)     31.037403407972306
Sample Time (s)              10.039826205000281
Epoch Time (s)               188.2693607029505
Total Train Time (s)         34056.96176856756
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:18:56.687606 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #185 | Epoch Duration: 188.37540936470032
2020-01-13 13:18:56.687874 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9401144
Z variance train             0.10132667
KL Divergence                50.202328
KL Loss                      5.0202327
QF Loss                      121.527405
VF Loss                      35.610394
Policy Loss                  -995.97284
Q Predictions Mean           993.3054
Q Predictions Std            1050.2698
Q Predictions Max            3979.8418
Q Predictions Min            502.5866
V Predictions Mean           995.7721
V Predictions Std            1049.021
V Predictions Max            3962.6257
V Predictions Min            503.65533
Log Pis Mean                 -0.5127485
Log Pis Std                  3.2812312
Log Pis Max                  15.736429
Log Pis Min                  -6.8817043
Policy mu Mean               -0.0049005947
Policy mu Std                0.82111794
Policy mu Max                2.5955892
Policy mu Min                -3.277822
Policy log std Mean          -0.48445547
Policy log std Std           0.22502509
Policy log std Max           -0.01312539
Policy log std Min           -2.6254475
Z mean eval                  1.9359424
Z variance eval              0.05198931
total_rewards                [9163.61609877 9270.49481424 9375.97207214 9313.50232901 9359.12338433
 9316.65101532 9436.14941364 9418.07206833 9522.14142503 9044.7418427 ]
total_rewards_mean           9322.046446352293
total_rewards_std            130.88880081649398
total_rewards_max            9522.14142503067
total_rewards_min            9044.741842700574
Number of train steps total  748000
Number of env steps total    2246000
Number of rollouts total     0
Train Time (s)               147.19583628699183
(Previous) Eval Time (s)     29.715112154837698
Sample Time (s)              10.618488805368543
Epoch Time (s)               187.52943724719808
Total Train Time (s)         34244.57641534507
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:22:04.305479 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #186 | Epoch Duration: 187.61740374565125
2020-01-13 13:22:04.305807 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9344747
Z variance train             0.051930297
KL Divergence                50.700226
KL Loss                      5.0700226
QF Loss                      203.98708
VF Loss                      45.143238
Policy Loss                  -930.1241
Q Predictions Mean           928.5874
Q Predictions Std            978.7939
Q Predictions Max            3982.1345
Q Predictions Min            477.18207
V Predictions Mean           933.5711
V Predictions Std            977.20294
V Predictions Max            3975.6624
V Predictions Min            493.06418
Log Pis Mean                 -0.9660952
Log Pis Std                  3.217488
Log Pis Max                  11.186579
Log Pis Min                  -6.917834
Policy mu Mean               0.08048938
Policy mu Std                0.79021776
Policy mu Max                2.5808325
Policy mu Min                -3.0778372
Policy log std Mean          -0.4564418
Policy log std Std           0.23572214
Policy log std Max           -0.03513211
Policy log std Min           -2.4575586
Z mean eval                  1.9503477
Z variance eval              0.16381209
total_rewards                [8756.61163363 8957.5091237  9061.97525354 8884.51249983 9315.92161007
 8676.57549625 9128.42802192 9029.11688959 9006.02016989 8624.13756595]
total_rewards_mean           8944.080826436975
total_rewards_std            202.4876197869683
total_rewards_max            9315.921610071728
total_rewards_min            8624.137565946878
Number of train steps total  752000
Number of env steps total    2258000
Number of rollouts total     0
Train Time (s)               141.85815311828628
(Previous) Eval Time (s)     28.233587838709354
Sample Time (s)              10.710410868749022
Epoch Time (s)               180.80215182574466
Total Train Time (s)         34425.468005931005
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:25:05.199128 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #187 | Epoch Duration: 180.89312720298767
2020-01-13 13:25:05.199416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #187 | Started Training: True
