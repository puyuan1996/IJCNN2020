---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019175082
Z variance train             0.6939387
KL Divergence                0.14828885
KL Loss                      0.014828885
QF Loss                      46.709827
VF Loss                      16.167742
Policy Loss                  -3.9816623
Q Predictions Mean           -0.0026792148
Q Predictions Std            0.0026757657
Q Predictions Max            0.0040889876
Q Predictions Min            -0.010387832
V Predictions Mean           -0.001651519
V Predictions Std            0.001290455
V Predictions Max            0.0017824029
V Predictions Min            -0.0049177175
Log Pis Mean                 -4.0086207
Log Pis Std                  0.54835194
Log Pis Max                  -2.2180557
Log Pis Min                  -5.7349057
Policy mu Mean               -0.0001299685
Policy mu Std                0.0013389915
Policy mu Max                0.0041198926
Policy mu Min                -0.004545611
Policy log std Mean          -0.00054704404
Policy log std Std           0.0011561852
Policy log std Max           0.0023886173
Policy log std Min           -0.0044405647
Z mean eval                  0.8570304
Z variance eval              0.047355607
total_rewards                [-119.80486682 -136.9792466  -158.74689445 -140.93463933 -123.38789593
 -141.5424727  -149.58532802 -151.90958377 -119.03849759 -164.97905753]
total_rewards_mean           -140.6908482719261
total_rewards_std            15.296767846030868
total_rewards_max            -119.0384975864594
total_rewards_min            -164.97905752784447
Number of train steps total  4000
Number of env steps total    14000
Number of rollouts total     0
Train Time (s)               141.9527783249505
(Previous) Eval Time (s)     0
Sample Time (s)              10.93709594849497
Epoch Time (s)               152.88987427344546
Total Train Time (s)         170.62058700295165
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:56:29.084136 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #0 | Epoch Duration: 170.62382292747498
2020-01-12 07:56:29.084306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90167505
Z variance train             0.041856658
KL Divergence                9.360006
KL Loss                      0.93600065
QF Loss                      47.1469
VF Loss                      9.294404
Policy Loss                  -48.83809
Q Predictions Mean           44.240807
Q Predictions Std            17.82905
Q Predictions Max            99.00708
Q Predictions Min            -16.574621
V Predictions Mean           49.184624
V Predictions Std            17.31221
V Predictions Max            101.537
V Predictions Min            -8.512872
Log Pis Mean                 -3.2385275
Log Pis Std                  1.2206479
Log Pis Max                  -0.06476468
Log Pis Min                  -8.254299
Policy mu Mean               0.06723497
Policy mu Std                0.3628978
Policy mu Max                1.6284689
Policy mu Min                -1.2889998
Policy log std Mean          -0.31089845
Policy log std Std           0.06466471
Policy log std Max           -0.16806349
Policy log std Min           -0.5761995
Z mean eval                  1.0705801
Z variance eval              0.023435056
total_rewards                [-140.71860726  -66.55020744 -116.91921201 -100.35151368  -46.52522974
 -136.85984412 -110.46513159 -127.80643182 -129.03688426 -108.42813742]
total_rewards_mean           -108.36611993377657
total_rewards_std            28.945547516274093
total_rewards_max            -46.52522973505119
total_rewards_min            -140.7186072572156
Number of train steps total  8000
Number of env steps total    26000
Number of rollouts total     0
Train Time (s)               141.15574117889628
(Previous) Eval Time (s)     17.725766093004495
Sample Time (s)              5.554469279013574
Epoch Time (s)               164.43597655091435
Total Train Time (s)         335.1402840889059
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:59:13.605309 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #1 | Epoch Duration: 164.5208625793457
2020-01-12 07:59:13.605506 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #1 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0627549
Z variance train             0.023334749
KL Divergence                12.617655
KL Loss                      1.2617655
QF Loss                      77.44399
VF Loss                      28.448317
Policy Loss                  -88.40505
Q Predictions Mean           84.29179
Q Predictions Std            26.726316
Q Predictions Max            182.0234
Q Predictions Min            20.158403
V Predictions Mean           91.97092
V Predictions Std            27.315807
V Predictions Max            176.4221
V Predictions Min            32.280903
Log Pis Mean                 -3.2033463
Log Pis Std                  1.3965696
Log Pis Max                  1.9968648
Log Pis Min                  -6.9521055
Policy mu Mean               0.023217214
Policy mu Std                0.44225755
Policy mu Max                1.6368394
Policy mu Min                -1.8417437
Policy log std Mean          -0.3282062
Policy log std Std           0.076840825
Policy log std Max           -0.10830869
Policy log std Min           -0.680839
Z mean eval                  1.1768091
Z variance eval              0.03133611
total_rewards                [-52.09384411 -20.17585418 -70.50107003 -56.87156973  -4.5261226
 -86.1482204   -4.72648553 -38.32399383  41.84297799 -71.25432327]
total_rewards_mean           -36.27785056900022
total_rewards_std            37.31738041555544
total_rewards_max            41.8429779925883
total_rewards_min            -86.14822039934562
Number of train steps total  12000
Number of env steps total    38000
Number of rollouts total     0
Train Time (s)               142.3822284513153
(Previous) Eval Time (s)     20.99292907398194
Sample Time (s)              6.486303466837853
Epoch Time (s)               169.8614609921351
Total Train Time (s)         505.0999261382967
Epoch                        2
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:02:03.564764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #2 | Epoch Duration: 169.95912408828735
2020-01-12 08:02:03.564903 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.173344
Z variance train             0.031380285
KL Divergence                13.744539
KL Loss                      1.3744539
QF Loss                      53.716454
VF Loss                      28.074799
Policy Loss                  -128.45241
Q Predictions Mean           124.663605
Q Predictions Std            39.311035
Q Predictions Max            223.57649
Q Predictions Min            49.962246
V Predictions Mean           131.93298
V Predictions Std            39.126827
V Predictions Max            227.50276
V Predictions Min            64.5722
Log Pis Mean                 -3.0888681
Log Pis Std                  1.2659762
Log Pis Max                  1.723346
Log Pis Min                  -6.025714
Policy mu Mean               0.010516976
Policy mu Std                0.41898605
Policy mu Max                1.791188
Policy mu Min                -1.301242
Policy log std Mean          -0.33096814
Policy log std Std           0.0815935
Policy log std Max           -0.16474834
Policy log std Min           -0.69333816
Z mean eval                  1.2243838
Z variance eval              0.034015235
total_rewards                [215.12223097 116.96737152 175.28799707  94.11691416 221.12375198
  46.61422166  79.10989942  49.36864236  80.11590951  67.35587742]
total_rewards_mean           114.51828160639369
total_rewards_std            62.544431445440715
total_rewards_max            221.12375197785596
total_rewards_min            46.61422165789635
Number of train steps total  16000
Number of env steps total    50000
Number of rollouts total     0
Train Time (s)               143.11390058416873
(Previous) Eval Time (s)     20.959214230068028
Sample Time (s)              6.4461075672879815
Epoch Time (s)               170.51922238152474
Total Train Time (s)         675.7064033807255
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:04:54.172490 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #3 | Epoch Duration: 170.60749053955078
2020-01-12 08:04:54.172618 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2231514
Z variance train             0.03410511
KL Divergence                14.648917
KL Loss                      1.4648918
QF Loss                      46.83977
VF Loss                      10.9094715
Policy Loss                  -149.63753
Q Predictions Mean           143.59972
Q Predictions Std            42.67657
Q Predictions Max            274.90213
Q Predictions Min            71.712555
V Predictions Mean           150.32635
V Predictions Std            41.4437
V Predictions Max            273.18155
V Predictions Min            81.26038
Log Pis Mean                 -3.2629328
Log Pis Std                  1.4189438
Log Pis Max                  2.3022041
Log Pis Min                  -7.2082367
Policy mu Mean               0.012199369
Policy mu Std                0.38947287
Policy mu Max                1.7695112
Policy mu Min                -1.4258059
Policy log std Mean          -0.32613477
Policy log std Std           0.085294366
Policy log std Max           -0.07732354
Policy log std Min           -0.7754878
Z mean eval                  1.27453
Z variance eval              0.036229327
total_rewards                [377.42888561 577.56733452 207.63355706 158.23362038 404.82230909
 246.98884586 410.91484624 323.08229238 157.35252815  62.43087185]
total_rewards_mean           292.6455091142385
total_rewards_std            146.47437471863918
total_rewards_max            577.5673345246104
total_rewards_min            62.43087185137737
Number of train steps total  20000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               140.82227462902665
(Previous) Eval Time (s)     21.069865269120783
Sample Time (s)              5.542368256952614
Epoch Time (s)               167.43450815510005
Total Train Time (s)         843.2300534984097
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:07:41.696785 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #4 | Epoch Duration: 167.52407312393188
2020-01-12 08:07:41.696921 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2748578
Z variance train             0.03630378
KL Divergence                15.50745
KL Loss                      1.550745
QF Loss                      68.44155
VF Loss                      19.164122
Policy Loss                  -191.49336
Q Predictions Mean           186.28488
Q Predictions Std            52.588593
Q Predictions Max            334.50677
Q Predictions Min            100.755165
V Predictions Mean           190.23953
V Predictions Std            52.079636
V Predictions Max            327.00708
V Predictions Min            99.7673
Log Pis Mean                 -3.179522
Log Pis Std                  1.3542868
Log Pis Max                  2.3836563
Log Pis Min                  -7.610919
Policy mu Mean               -0.03514818
Policy mu Std                0.44905213
Policy mu Max                1.946063
Policy mu Min                -1.8796372
Policy log std Mean          -0.3404627
Policy log std Std           0.09354306
Policy log std Max           -0.032215998
Policy log std Min           -0.8408439
Z mean eval                  1.3176636
Z variance eval              0.03010225
total_rewards                [1359.03449963 1683.98054731  698.55417239 1282.31917818 1284.74318036
 1253.42464325 1276.47792498 1467.87376846 1610.50044553  717.21644516]
total_rewards_mean           1263.412480522977
total_rewards_std            310.92981283036073
total_rewards_max            1683.9805473055778
total_rewards_min            698.5541723887386
Number of train steps total  24000
Number of env steps total    74000
Number of rollouts total     0
Train Time (s)               141.90008722618222
(Previous) Eval Time (s)     17.662372660823166
Sample Time (s)              6.5747709991410375
Epoch Time (s)               166.13723088614643
Total Train Time (s)         1009.4530332400464
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:10:27.923233 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #5 | Epoch Duration: 166.22619891166687
2020-01-12 08:10:27.923441 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.315428
Z variance train             0.029934848
KL Divergence                16.201488
KL Loss                      1.6201489
QF Loss                      302.90747
VF Loss                      50.24353
Policy Loss                  -223.01384
Q Predictions Mean           216.83366
Q Predictions Std            72.6502
Q Predictions Max            432.32693
Q Predictions Min            111.42569
V Predictions Mean           228.04527
V Predictions Std            71.72269
V Predictions Max            427.9796
V Predictions Min            116.36963
Log Pis Mean                 -2.908556
Log Pis Std                  1.8381262
Log Pis Max                  5.4552507
Log Pis Min                  -8.615093
Policy mu Mean               -0.006876013
Policy mu Std                0.5119946
Policy mu Max                2.0630612
Policy mu Min                -1.704877
Policy log std Mean          -0.35600626
Policy log std Std           0.10570439
Policy log std Max           -0.124134116
Policy log std Min           -0.89694417
Z mean eval                  1.3300673
Z variance eval              0.050965853
total_rewards                [1717.4468697   957.23179952 2182.97970855 2026.76438238 2364.95295906
 1805.16370186 2174.37854872  556.20935944 1851.90103585  813.99279666]
total_rewards_mean           1645.102116173703
total_rewards_std            604.6910074424577
total_rewards_max            2364.9529590588845
total_rewards_min            556.209359444083
Number of train steps total  28000
Number of env steps total    86000
Number of rollouts total     0
Train Time (s)               141.37778852460906
(Previous) Eval Time (s)     19.815300669055432
Sample Time (s)              6.597711309790611
Epoch Time (s)               167.7908005034551
Total Train Time (s)         1177.3287200927734
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:13:15.797750 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #6 | Epoch Duration: 167.87416124343872
2020-01-12 08:13:15.797921 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3293868
Z variance train             0.051017683
KL Divergence                14.408234
KL Loss                      1.4408234
QF Loss                      129.80072
VF Loss                      33.496193
Policy Loss                  -262.55328
Q Predictions Mean           254.32748
Q Predictions Std            104.98196
Q Predictions Max            570.5655
Q Predictions Min            135.75388
V Predictions Mean           263.52344
V Predictions Std            104.4851
V Predictions Max            579.60455
V Predictions Min            140.23055
Log Pis Mean                 -2.628164
Log Pis Std                  1.8245932
Log Pis Max                  4.3250685
Log Pis Min                  -6.169155
Policy mu Mean               -0.017206943
Policy mu Std                0.5317824
Policy mu Max                1.7189984
Policy mu Min                -2.1563804
Policy log std Mean          -0.36801186
Policy log std Std           0.13275558
Policy log std Max           -0.06561345
Policy log std Min           -1.3202304
Z mean eval                  1.4363272
Z variance eval              0.023656022
total_rewards                [2653.94428115 2711.7415817  2650.90073385 2677.82463629 2718.87350692
 2753.16561472 2621.09594926  844.33412152 2472.45300589 2696.02910001]
total_rewards_mean           2480.036253130594
total_rewards_std            550.0926172467537
total_rewards_max            2753.1656147219624
total_rewards_min            844.3341215245425
Number of train steps total  32000
Number of env steps total    98000
Number of rollouts total     0
Train Time (s)               142.3745892061852
(Previous) Eval Time (s)     17.83722969610244
Sample Time (s)              6.397122672293335
Epoch Time (s)               166.60894157458097
Total Train Time (s)         1344.0142849930562
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:16:02.486677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #7 | Epoch Duration: 166.6886112689972
2020-01-12 08:16:02.486818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4365635
Z variance train             0.023555791
KL Divergence                18.323
KL Loss                      1.8323001
QF Loss                      119.078415
VF Loss                      56.591427
Policy Loss                  -284.66232
Q Predictions Mean           275.00464
Q Predictions Std            114.12933
Q Predictions Max            679.53375
Q Predictions Min            142.85335
V Predictions Mean           279.9147
V Predictions Std            115.98067
V Predictions Max            685.7592
V Predictions Min            158.8588
Log Pis Mean                 -2.4140596
Log Pis Std                  2.1078944
Log Pis Max                  6.48071
Log Pis Min                  -7.6143284
Policy mu Mean               -0.010068208
Policy mu Std                0.5826307
Policy mu Max                2.2576063
Policy mu Min                -1.8932884
Policy log std Mean          -0.382583
Policy log std Std           0.1403378
Policy log std Max           -0.059430644
Policy log std Min           -1.187321
Z mean eval                  1.570262
Z variance eval              0.026734218
total_rewards                [2925.51027445 2980.84446605 2906.78806712 2941.08159982 2890.42442532
  682.37579128 2917.04663503 2833.37568792 3108.70423823 3084.19761975]
total_rewards_mean           2727.034880496346
total_rewards_std            686.2882399905322
total_rewards_max            3108.704238229665
total_rewards_min            682.3757912759372
Number of train steps total  36000
Number of env steps total    110000
Number of rollouts total     0
Train Time (s)               141.39585772203282
(Previous) Eval Time (s)     17.810863703954965
Sample Time (s)              5.681655390653759
Epoch Time (s)               164.88837681664154
Total Train Time (s)         1508.9887186517008
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:18:47.461094 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #8 | Epoch Duration: 164.97414755821228
2020-01-12 08:18:47.461321 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5714668
Z variance train             0.026570031
KL Divergence                18.710285
KL Loss                      1.8710285
QF Loss                      102.72793
VF Loss                      36.4113
Policy Loss                  -319.53604
Q Predictions Mean           312.20898
Q Predictions Std            157.32193
Q Predictions Max            809.073
Q Predictions Min            162.68185
V Predictions Mean           315.6676
V Predictions Std            157.63722
V Predictions Max            802.6678
V Predictions Min            178.22974
Log Pis Mean                 -2.2060304
Log Pis Std                  2.28106
Log Pis Max                  5.391802
Log Pis Min                  -6.3220606
Policy mu Mean               -0.043104004
Policy mu Std                0.58388966
Policy mu Max                1.9197209
Policy mu Min                -2.170544
Policy log std Mean          -0.39043918
Policy log std Std           0.16912653
Policy log std Max           -0.16119978
Policy log std Min           -1.5250498
Z mean eval                  1.6815469
Z variance eval              0.039277457
total_rewards                [3247.66095674 3338.15260218 3211.673153   3226.83353884 3144.61281778
  880.26929528 3360.72621857 3269.68389065 3201.73817106 3182.73076804]
total_rewards_mean           3006.408141213126
total_rewards_std            711.5226084700234
total_rewards_max            3360.7262185714835
total_rewards_min            880.2692952814242
Number of train steps total  40000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               142.4535206318833
(Previous) Eval Time (s)     17.709922744892538
Sample Time (s)              6.519831718411297
Epoch Time (s)               166.68327509518713
Total Train Time (s)         1675.75117145665
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:21:34.223158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #9 | Epoch Duration: 166.76168417930603
2020-01-12 08:21:34.223280 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #9 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6836075
Z variance train             0.03931024
KL Divergence                18.877396
KL Loss                      1.8877395
QF Loss                      184.54936
VF Loss                      41.86239
Policy Loss                  -396.34106
Q Predictions Mean           390.6626
Q Predictions Std            204.74251
Q Predictions Max            951.7623
Q Predictions Min            178.26329
V Predictions Mean           396.48065
V Predictions Std            205.25139
V Predictions Max            935.0167
V Predictions Min            184.77711
Log Pis Mean                 -1.6992711
Log Pis Std                  2.6339643
Log Pis Max                  8.966895
Log Pis Min                  -6.1031294
Policy mu Mean               -0.037009757
Policy mu Std                0.66445965
Policy mu Max                2.1140459
Policy mu Min                -2.4695745
Policy log std Mean          -0.41836834
Policy log std Std           0.17262731
Policy log std Max           -0.1683233
Policy log std Min           -1.6283408
Z mean eval                  1.8004423
Z variance eval              0.025630694
total_rewards                [3197.58308723 3180.13771558 3200.83346392 3350.73068538 3225.9101789
 3194.85224419 3266.06561277 3119.33723773 3179.48128653 3221.9817852 ]
total_rewards_mean           3213.691329742958
total_rewards_std            58.06846005912471
total_rewards_max            3350.7306853787322
total_rewards_min            3119.337237726468
Number of train steps total  44000
Number of env steps total    134000
Number of rollouts total     0
Train Time (s)               142.48910357616842
(Previous) Eval Time (s)     20.946224097162485
Sample Time (s)              5.543400122784078
Epoch Time (s)               168.97872779611498
Total Train Time (s)         1844.8138136649504
Epoch                        10
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:24:23.286598 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #10 | Epoch Duration: 169.0632243156433
2020-01-12 08:24:23.286748 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7987705
Z variance train             0.025562212
KL Divergence                21.54616
KL Loss                      2.154616
QF Loss                      255.54514
VF Loss                      44.870293
Policy Loss                  -419.74313
Q Predictions Mean           409.26196
Q Predictions Std            239.83783
Q Predictions Max            999.7389
Q Predictions Min            179.36961
V Predictions Mean           417.6826
V Predictions Std            242.16188
V Predictions Max            989.6034
V Predictions Min            180.6841
Log Pis Mean                 -1.6384289
Log Pis Std                  2.9173105
Log Pis Max                  9.976688
Log Pis Min                  -6.883501
Policy mu Mean               0.0390093
Policy mu Std                0.7015887
Policy mu Max                2.232673
Policy mu Min                -2.88056
Policy log std Mean          -0.43228927
Policy log std Std           0.17674474
Policy log std Max           -0.15156235
Policy log std Min           -1.5816116
Z mean eval                  1.8647034
Z variance eval              0.041358586
total_rewards                [3496.06408563 3386.06200743 3396.06383101 3379.52744395 3429.18691467
 3183.10183791 3411.18558081 3361.47100881 3626.09294958 3570.80664561]
total_rewards_mean           3423.956230539804
total_rewards_std            115.72268855520052
total_rewards_max            3626.0929495760342
total_rewards_min            3183.1018379089323
Number of train steps total  48000
Number of env steps total    146000
Number of rollouts total     0
Train Time (s)               142.06342723593116
(Previous) Eval Time (s)     17.73807872692123
Sample Time (s)              6.663839919026941
Epoch Time (s)               166.46534588187933
Total Train Time (s)         2011.3705884623341
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:27:09.846437 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #11 | Epoch Duration: 166.55957293510437
2020-01-12 08:27:09.846654 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8670645
Z variance train             0.041168876
KL Divergence                22.36293
KL Loss                      2.236293
QF Loss                      266.77255
VF Loss                      64.75019
Policy Loss                  -486.61905
Q Predictions Mean           482.40308
Q Predictions Std            303.24554
Q Predictions Max            1171.0256
Q Predictions Min            181.78835
V Predictions Mean           490.1347
V Predictions Std            303.90918
V Predictions Max            1179.5087
V Predictions Min            189.39278
Log Pis Mean                 -1.6668222
Log Pis Std                  2.8095558
Log Pis Max                  8.014477
Log Pis Min                  -6.818327
Policy mu Mean               -0.0012474066
Policy mu Std                0.69911116
Policy mu Max                2.413759
Policy mu Min                -2.1176836
Policy log std Mean          -0.4259226
Policy log std Std           0.18999746
Policy log std Max           -0.18290961
Policy log std Min           -1.7285247
Z mean eval                  1.9208361
Z variance eval              0.062533356
total_rewards                [3647.83754964 1986.71218261 3453.38915687 3731.92363645 3952.03275232
 3601.31676996 3894.62698816 3779.96119087 3853.15682137 3728.71648566]
total_rewards_mean           3562.9673533903215
total_rewards_std            543.5022192927119
total_rewards_max            3952.03275231869
total_rewards_min            1986.712182612499
Number of train steps total  52000
Number of env steps total    158000
Number of rollouts total     0
Train Time (s)               140.4986516800709
(Previous) Eval Time (s)     17.891712713986635
Sample Time (s)              6.539673796389252
Epoch Time (s)               164.9300381904468
Total Train Time (s)         2176.3850927725434
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:29:54.860620 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #12 | Epoch Duration: 165.0138087272644
2020-01-12 08:29:54.860793 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #12 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9238151
Z variance train             0.06255022
KL Divergence                21.104979
KL Loss                      2.110498
QF Loss                      192.47461
VF Loss                      53.167927
Policy Loss                  -499.34152
Q Predictions Mean           489.2808
Q Predictions Std            315.59253
Q Predictions Max            1245.9806
Q Predictions Min            180.39574
V Predictions Mean           497.90594
V Predictions Std            320.7221
V Predictions Max            1239.2789
V Predictions Min            192.77258
Log Pis Mean                 -1.6713185
Log Pis Std                  2.9008896
Log Pis Max                  7.919036
Log Pis Min                  -6.565384
Policy mu Mean               0.0073697814
Policy mu Std                0.69410866
Policy mu Max                2.2955432
Policy mu Min                -2.45524
Policy log std Mean          -0.42986774
Policy log std Std           0.19321421
Policy log std Max           -0.08899097
Policy log std Min           -1.7646841
Z mean eval                  1.9908984
Z variance eval              0.044801436
total_rewards                [3597.56510471 3754.33492186 3886.7450577  3917.08730919 1525.849065
 3699.59665719 3682.37350865 3618.87022995 3724.97316285  632.87361478]
total_rewards_mean           3204.0268631866247
total_rewards_std            1085.2310993010149
total_rewards_max            3917.087309185161
total_rewards_min            632.8736147781527
Number of train steps total  56000
Number of env steps total    170000
Number of rollouts total     0
Train Time (s)               142.7484659468755
(Previous) Eval Time (s)     17.47962373821065
Sample Time (s)              5.485343575943261
Epoch Time (s)               165.71343326102942
Total Train Time (s)         2342.293415383436
Epoch                        13
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:32:40.773009 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #13 | Epoch Duration: 165.91203117370605
2020-01-12 08:32:40.773346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9899276
Z variance train             0.044774417
KL Divergence                22.732903
KL Loss                      2.2732904
QF Loss                      213.39098
VF Loss                      78.78076
Policy Loss                  -572.7304
Q Predictions Mean           562.2091
Q Predictions Std            352.63538
Q Predictions Max            1348.5013
Q Predictions Min            166.63504
V Predictions Mean           576.347
V Predictions Std            356.1466
V Predictions Max            1359.0101
V Predictions Min            178.96198
Log Pis Mean                 -1.3015859
Log Pis Std                  3.0637565
Log Pis Max                  8.39757
Log Pis Min                  -7.7917633
Policy mu Mean               -0.0063744714
Policy mu Std                0.7601129
Policy mu Max                2.5440035
Policy mu Min                -2.5537932
Policy log std Mean          -0.44454932
Policy log std Std           0.19278629
Policy log std Max           -0.18689111
Policy log std Min           -1.6942906
Z mean eval                  1.9935968
Z variance eval              0.022119524
total_rewards                [3994.11953706 4009.57377319 3939.00621871 3846.97152189 4206.60503925
 3986.57180254 3913.63253053 4112.39257128 3591.71382445 4027.5646049 ]
total_rewards_mean           3962.8151423793547
total_rewards_std            156.15756602388578
total_rewards_max            4206.605039250798
total_rewards_min            3591.7138244491184
Number of train steps total  60000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               143.7748798429966
(Previous) Eval Time (s)     17.678873215802014
Sample Time (s)              6.872498502954841
Epoch Time (s)               168.32625156175345
Total Train Time (s)         2510.7047553318553
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:35:29.185577 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #14 | Epoch Duration: 168.41198301315308
2020-01-12 08:35:29.185810 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9973282
Z variance train             0.022061782
KL Divergence                25.375153
KL Loss                      2.5375154
QF Loss                      278.40143
VF Loss                      120.32531
Policy Loss                  -590.9313
Q Predictions Mean           580.3989
Q Predictions Std            387.98715
Q Predictions Max            1374.031
Q Predictions Min            197.42363
V Predictions Mean           582.9354
V Predictions Std            392.8555
V Predictions Max            1374.2429
V Predictions Min            182.33005
Log Pis Mean                 -1.8189039
Log Pis Std                  2.9065118
Log Pis Max                  9.886803
Log Pis Min                  -9.42384
Policy mu Mean               0.02803404
Policy mu Std                0.6917555
Policy mu Max                2.6575043
Policy mu Min                -2.3253694
Policy log std Mean          -0.4342667
Policy log std Std           0.20232873
Policy log std Max           -0.14432487
Policy log std Min           -1.814332
Z mean eval                  2.0189488
Z variance eval              0.020484768
total_rewards                [4089.35527728 3969.20606861 3892.96665691 3945.35581067 4154.40706829
 4091.61760454 4029.99428848 4089.70896751 3998.36152585 4052.11362906]
total_rewards_mean           4031.3086897186668
total_rewards_std            75.81135439617427
total_rewards_max            4154.407068286706
total_rewards_min            3892.9666569096507
Number of train steps total  64000
Number of env steps total    194000
Number of rollouts total     0
Train Time (s)               141.4555628071539
(Previous) Eval Time (s)     17.70490838587284
Sample Time (s)              6.405570060014725
Epoch Time (s)               165.56604125304148
Total Train Time (s)         2676.358530738391
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:38:14.839205 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #15 | Epoch Duration: 165.6531822681427
2020-01-12 08:38:14.839475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0222774
Z variance train             0.020504672
KL Divergence                26.754631
KL Loss                      2.6754632
QF Loss                      240.58748
VF Loss                      62.769855
Policy Loss                  -581.881
Q Predictions Mean           573.33453
Q Predictions Std            419.62024
Q Predictions Max            1431.6758
Q Predictions Min            180.37498
V Predictions Mean           577.6216
V Predictions Std            419.91595
V Predictions Max            1438.6364
V Predictions Min            193.83583
Log Pis Mean                 -1.6598133
Log Pis Std                  2.9547858
Log Pis Max                  7.375328
Log Pis Min                  -7.093722
Policy mu Mean               -0.012869437
Policy mu Std                0.7047756
Policy mu Max                3.1364698
Policy mu Min                -2.551782
Policy log std Mean          -0.4289706
Policy log std Std           0.20139201
Policy log std Max           0.0058861375
Policy log std Min           -1.7983794
Z mean eval                  2.015856
Z variance eval              0.024991319
total_rewards                [4114.56073325 4070.33360968 4153.26172274 4144.03621273 4028.69383079
 4259.75024172 4104.84860212 4150.12714683 4295.24025268 3953.23815284]
total_rewards_mean           4127.409050538331
total_rewards_std            95.47475772704307
total_rewards_max            4295.240252678438
total_rewards_min            3953.2381528432056
Number of train steps total  68000
Number of env steps total    206000
Number of rollouts total     0
Train Time (s)               138.40331477764994
(Previous) Eval Time (s)     20.69219624903053
Sample Time (s)              6.5194888999685645
Epoch Time (s)               165.61499992664903
Total Train Time (s)         2842.0592373525724
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:41:00.541037 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #16 | Epoch Duration: 165.70138359069824
2020-01-12 08:41:00.541267 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0182343
Z variance train             0.025100445
KL Divergence                25.548069
KL Loss                      2.554807
QF Loss                      452.11264
VF Loss                      75.35474
Policy Loss                  -670.85315
Q Predictions Mean           659.8121
Q Predictions Std            445.31833
Q Predictions Max            1507.5543
Q Predictions Min            179.56554
V Predictions Mean           669.7782
V Predictions Std            444.68677
V Predictions Max            1508.9167
V Predictions Min            182.09344
Log Pis Mean                 -1.2252969
Log Pis Std                  3.0463333
Log Pis Max                  9.89942
Log Pis Min                  -6.402498
Policy mu Mean               0.015006158
Policy mu Std                0.75904214
Policy mu Max                2.5791357
Policy mu Min                -2.4907227
Policy log std Mean          -0.4502164
Policy log std Std           0.21949393
Policy log std Max           -0.1407725
Policy log std Min           -1.9273262
Z mean eval                  2.0372725
Z variance eval              0.036213472
total_rewards                [4170.19527401 4160.97827397 4436.13019125 4274.02923458 4346.11147862
 3048.00019551 4248.92151438 4117.69155094 4079.86585307 4188.52261099]
total_rewards_mean           4107.04461773277
total_rewards_std            367.34531893871576
total_rewards_max            4436.130191250258
total_rewards_min            3048.0001955116168
Number of train steps total  72000
Number of env steps total    218000
Number of rollouts total     0
Train Time (s)               141.87035724613816
(Previous) Eval Time (s)     17.881520632188767
Sample Time (s)              6.634430787991732
Epoch Time (s)               166.38630866631866
Total Train Time (s)         3008.5308165517636
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:43:47.014301 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #17 | Epoch Duration: 166.47281789779663
2020-01-12 08:43:47.014578 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0378158
Z variance train             0.036215726
KL Divergence                24.724936
KL Loss                      2.4724936
QF Loss                      374.02994
VF Loss                      76.496376
Policy Loss                  -647.4341
Q Predictions Mean           642.9774
Q Predictions Std            468.45865
Q Predictions Max            1586.17
Q Predictions Min            171.4921
V Predictions Mean           645.7477
V Predictions Std            470.40665
V Predictions Max            1587.5881
V Predictions Min            184.52608
Log Pis Mean                 -1.4477639
Log Pis Std                  3.1816647
Log Pis Max                  12.205077
Log Pis Min                  -8.441115
Policy mu Mean               -0.028402278
Policy mu Std                0.72741604
Policy mu Max                2.8540606
Policy mu Min                -2.7232344
Policy log std Mean          -0.43199572
Policy log std Std           0.21164581
Policy log std Max           -0.06852865
Policy log std Min           -1.9186136
Z mean eval                  2.052632
Z variance eval              0.031677354
total_rewards                [4423.29883442 4639.7374459  4596.92142487 4585.55192501 4452.78936389
  357.0784464  4611.41226796 4639.93532078 4725.60387926 4694.20164616]
total_rewards_mean           4172.653055465287
total_rewards_std            1275.0371020760185
total_rewards_max            4725.603879259614
total_rewards_min            357.07844640025763
Number of train steps total  76000
Number of env steps total    230000
Number of rollouts total     0
Train Time (s)               143.2174494159408
(Previous) Eval Time (s)     20.94682462280616
Sample Time (s)              6.389730323571712
Epoch Time (s)               170.55400436231866
Total Train Time (s)         3179.1718197641894
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:46:37.657065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #18 | Epoch Duration: 170.64227199554443
2020-01-12 08:46:37.657384 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0513146
Z variance train             0.03166527
KL Divergence                25.73482
KL Loss                      2.573482
QF Loss                      713.3954
VF Loss                      104.504196
Policy Loss                  -735.2631
Q Predictions Mean           724.59595
Q Predictions Std            487.6482
Q Predictions Max            1631.7289
Q Predictions Min            156.41557
V Predictions Mean           736.07623
V Predictions Std            488.02353
V Predictions Max            1630.2549
V Predictions Min            165.74829
Log Pis Mean                 -1.0247283
Log Pis Std                  3.1998994
Log Pis Max                  11.451237
Log Pis Min                  -5.8777943
Policy mu Mean               -0.0056029856
Policy mu Std                0.8005643
Policy mu Max                2.5224411
Policy mu Min                -2.9216983
Policy log std Mean          -0.46340272
Policy log std Std           0.21830687
Policy log std Max           -0.18346441
Policy log std Min           -1.8705614
Z mean eval                  2.0377026
Z variance eval              0.029175634
total_rewards                [4494.37355246 4542.25351847 4710.45495347 4572.37737284 4437.07986685
 4583.15881631 4385.16812602 4538.85797426 1563.01554507 4645.52914923]
total_rewards_mean           4247.226887498035
total_rewards_std            899.1680254196839
total_rewards_max            4710.454953471471
total_rewards_min            1563.015545065152
Number of train steps total  80000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               144.04432352632284
(Previous) Eval Time (s)     17.662697550375015
Sample Time (s)              5.488814770244062
Epoch Time (s)               167.19583584694192
Total Train Time (s)         3346.4538402222097
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:49:24.937351 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #19 | Epoch Duration: 167.27975988388062
2020-01-12 08:49:24.937478 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.038317
Z variance train             0.029166698
KL Divergence                26.68172
KL Loss                      2.6681721
QF Loss                      641.4892
VF Loss                      146.53987
Policy Loss                  -671.963
Q Predictions Mean           665.6077
Q Predictions Std            481.8907
Q Predictions Max            1700.374
Q Predictions Min            156.67418
V Predictions Mean           674.1025
V Predictions Std            487.74765
V Predictions Max            1713.3905
V Predictions Min            162.89917
Log Pis Mean                 -1.2450749
Log Pis Std                  3.4889727
Log Pis Max                  17.339317
Log Pis Min                  -6.065465
Policy mu Mean               0.013075356
Policy mu Std                0.7786593
Policy mu Max                3.379003
Policy mu Min                -2.5032597
Policy log std Mean          -0.44531807
Policy log std Std           0.20463842
Policy log std Max           -0.12810335
Policy log std Min           -1.8942711
Z mean eval                  2.0361876
Z variance eval              0.013548319
total_rewards                [4760.88826166 4807.56384841 4764.86397556 4604.2524492  4596.94859848
 4850.72336513 4810.88148502 4660.62932514 4570.57482272 4758.09768673]
total_rewards_mean           4718.542381803219
total_rewards_std            96.18845413896143
total_rewards_max            4850.723365126467
total_rewards_min            4570.574822723481
Number of train steps total  84000
Number of env steps total    254000
Number of rollouts total     0
Train Time (s)               142.0042720111087
(Previous) Eval Time (s)     17.802587168756872
Sample Time (s)              5.6005626055411994
Epoch Time (s)               165.40742178540677
Total Train Time (s)         3511.9494775370695
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:52:10.434581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #20 | Epoch Duration: 165.4969961643219
2020-01-12 08:52:10.434788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0380793
Z variance train             0.013576733
KL Divergence                29.003494
KL Loss                      2.9003494
QF Loss                      434.9151
VF Loss                      56.841743
Policy Loss                  -610.7264
Q Predictions Mean           601.98413
Q Predictions Std            510.05133
Q Predictions Max            1693.618
Q Predictions Min            124.833755
V Predictions Mean           609.64
V Predictions Std            510.94025
V Predictions Max            1680.4326
V Predictions Min            135.87263
Log Pis Mean                 -1.9410557
Log Pis Std                  2.8054404
Log Pis Max                  8.169623
Log Pis Min                  -7.3368673
Policy mu Mean               -0.02429389
Policy mu Std                0.67474085
Policy mu Max                2.4181688
Policy mu Min                -2.2684376
Policy log std Mean          -0.4195682
Policy log std Std           0.20062496
Policy log std Max           -0.16138537
Policy log std Min           -1.7702808
Z mean eval                  2.025179
Z variance eval              0.015457749
total_rewards                [4642.04754859 4672.63591211 4704.63247448 4620.64115103 4752.66093323
 4602.03838834 5079.6816223  4497.61826388 4786.90901841 4648.51359052]
total_rewards_mean           4700.737890289772
total_rewards_std            147.68591752773307
total_rewards_max            5079.681622304998
total_rewards_min            4497.618263882255
Number of train steps total  88000
Number of env steps total    266000
Number of rollouts total     0
Train Time (s)               142.99548460543156
(Previous) Eval Time (s)     17.859015784226358
Sample Time (s)              6.667985321488231
Epoch Time (s)               167.52248571114615
Total Train Time (s)         3679.6615470452234
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:54:58.147837 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #21 | Epoch Duration: 167.71291279792786
2020-01-12 08:54:58.147998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.023418
Z variance train             0.015453505
KL Divergence                27.739176
KL Loss                      2.7739177
QF Loss                      547.84827
VF Loss                      152.75642
Policy Loss                  -651.7789
Q Predictions Mean           642.58344
Q Predictions Std            538.62616
Q Predictions Max            1812.4312
Q Predictions Min            96.81076
V Predictions Mean           657.5343
V Predictions Std            541.4896
V Predictions Max            1816.8794
V Predictions Min            128.5691
Log Pis Mean                 -1.495946
Log Pis Std                  3.176322
Log Pis Max                  10.926348
Log Pis Min                  -7.9325523
Policy mu Mean               0.018956264
Policy mu Std                0.7482804
Policy mu Max                2.8720756
Policy mu Min                -2.2401588
Policy log std Mean          -0.44692007
Policy log std Std           0.2161793
Policy log std Max           -0.14366439
Policy log std Min           -1.8633794
Z mean eval                  2.0281339
Z variance eval              0.01714147
total_rewards                [4597.09641947 4687.12053559 4561.88036722 4486.31165808 4745.18781628
 4584.36826656 4614.64885838 4638.46529576 4635.273062   4764.83699843]
total_rewards_mean           4631.518927775065
total_rewards_std            79.67156455104514
total_rewards_max            4764.836998426894
total_rewards_min            4486.31165808141
Number of train steps total  92000
Number of env steps total    278000
Number of rollouts total     0
Train Time (s)               143.04083065968007
(Previous) Eval Time (s)     20.841031291987747
Sample Time (s)              5.558446064591408
Epoch Time (s)               169.44030801625922
Total Train Time (s)         3849.189192353748
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:57:47.676545 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #22 | Epoch Duration: 169.52843403816223
2020-01-12 08:57:47.676697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0243769
Z variance train             0.01729947
KL Divergence                28.261993
KL Loss                      2.8261993
QF Loss                      409.73837
VF Loss                      193.96175
Policy Loss                  -746.556
Q Predictions Mean           740.37976
Q Predictions Std            556.5069
Q Predictions Max            1789.7455
Q Predictions Min            101.513115
V Predictions Mean           750.61646
V Predictions Std            560.095
V Predictions Max            1823.0089
V Predictions Min            119.21659
Log Pis Mean                 -1.3957946
Log Pis Std                  2.9787452
Log Pis Max                  8.2895355
Log Pis Min                  -5.977763
Policy mu Mean               -0.03283703
Policy mu Std                0.7476174
Policy mu Max                2.4543555
Policy mu Min                -2.4720156
Policy log std Mean          -0.466127
Policy log std Std           0.22201559
Policy log std Max           -0.1286805
Policy log std Min           -1.826636
Z mean eval                  2.0326412
Z variance eval              0.028896078
total_rewards                [4669.05711737 4852.18490254 4774.42824169 4946.57610971 4715.19232555
 4836.29778806 4619.8709596  4870.40027789 4814.16670865 4784.92612985]
total_rewards_mean           4788.310056091102
total_rewards_std            93.26397161865265
total_rewards_max            4946.576109708171
total_rewards_min            4619.870959600222
Number of train steps total  96000
Number of env steps total    290000
Number of rollouts total     0
Train Time (s)               141.10860030306503
(Previous) Eval Time (s)     20.56366327079013
Sample Time (s)              6.3761213487014174
Epoch Time (s)               168.04838492255658
Total Train Time (s)         4017.3202581135556
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:00:35.807636 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #23 | Epoch Duration: 168.13083934783936
2020-01-12 09:00:35.807768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0306573
Z variance train             0.029026305
KL Divergence                26.534168
KL Loss                      2.6534169
QF Loss                      337.837
VF Loss                      205.6247
Policy Loss                  -713.5992
Q Predictions Mean           708.9459
Q Predictions Std            557.4165
Q Predictions Max            1774.2218
Q Predictions Min            102.92879
V Predictions Mean           722.3935
V Predictions Std            560.33765
V Predictions Max            1766.4296
V Predictions Min            109.6126
Log Pis Mean                 -1.3685559
Log Pis Std                  3.2782125
Log Pis Max                  10.387593
Log Pis Min                  -6.2781324
Policy mu Mean               -0.011731562
Policy mu Std                0.7513631
Policy mu Max                3.3826246
Policy mu Min                -2.598694
Policy log std Mean          -0.4469289
Policy log std Std           0.20790525
Policy log std Max           -0.08461824
Policy log std Min           -1.7412851
Z mean eval                  2.047018
Z variance eval              0.013464752
total_rewards                [4493.17581748 4903.17742806 4902.48281753 4903.70523446 4824.49535493
 5015.17877966 4862.99264961 5055.62232655 4693.74234792 4912.4287529 ]
total_rewards_mean           4856.700150910781
total_rewards_std            152.9832616733558
total_rewards_max            5055.622326550684
total_rewards_min            4493.1758174775705
Number of train steps total  100000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               142.7698723897338
(Previous) Eval Time (s)     20.68376092100516
Sample Time (s)              6.422889966983348
Epoch Time (s)               169.8765232777223
Total Train Time (s)         4187.292667977046
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:03:25.781355 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #24 | Epoch Duration: 169.9734947681427
2020-01-12 09:03:25.781486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.049327
Z variance train             0.013461389
KL Divergence                29.153847
KL Loss                      2.9153848
QF Loss                      619.75793
VF Loss                      74.08905
Policy Loss                  -737.48126
Q Predictions Mean           732.8335
Q Predictions Std            595.222
Q Predictions Max            1905.4208
Q Predictions Min            97.762924
V Predictions Mean           734.8203
V Predictions Std            602.84515
V Predictions Max            1892.0446
V Predictions Min            89.38137
Log Pis Mean                 -1.4506104
Log Pis Std                  2.9830441
Log Pis Max                  9.500827
Log Pis Min                  -11.382517
Policy mu Mean               -0.025762184
Policy mu Std                0.7205925
Policy mu Max                2.56592
Policy mu Min                -2.437033
Policy log std Mean          -0.45581213
Policy log std Std           0.2215566
Policy log std Max           -0.10289693
Policy log std Min           -1.7334188
Z mean eval                  2.0222604
Z variance eval              0.013711552
total_rewards                [4981.23265904 4943.10141212 5007.24569139 5063.85853729 4656.56662369
 4819.71382857 5021.85060958 4961.23376933 4920.53993101 4880.39479163]
total_rewards_mean           4925.573785364833
total_rewards_std            111.97170480004746
total_rewards_max            5063.858537289605
total_rewards_min            4656.566623687077
Number of train steps total  104000
Number of env steps total    314000
Number of rollouts total     0
Train Time (s)               141.62008549598977
(Previous) Eval Time (s)     18.15337662398815
Sample Time (s)              6.579955822322518
Epoch Time (s)               166.35341794230044
Total Train Time (s)         4353.729885804933
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:06:12.220284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #25 | Epoch Duration: 166.43868494033813
2020-01-12 09:06:12.220463 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0234795
Z variance train             0.013727216
KL Divergence                29.582672
KL Loss                      2.9582672
QF Loss                      472.3687
VF Loss                      152.70818
Policy Loss                  -657.65674
Q Predictions Mean           646.95654
Q Predictions Std            594.7751
Q Predictions Max            1871.282
Q Predictions Min            74.429436
V Predictions Mean           651.1465
V Predictions Std            594.6614
V Predictions Max            1871.5942
V Predictions Min            75.58759
Log Pis Mean                 -1.2451394
Log Pis Std                  3.6449473
Log Pis Max                  16.5498
Log Pis Min                  -6.4693623
Policy mu Mean               -0.052829474
Policy mu Std                0.7481135
Policy mu Max                3.615227
Policy mu Min                -2.6340947
Policy log std Mean          -0.44625163
Policy log std Std           0.21348017
Policy log std Max           -0.13894868
Policy log std Min           -2.0049624
Z mean eval                  2.0357692
Z variance eval              0.012407092
total_rewards                [4832.67316982 4854.17474441 4925.39359424 4775.88037532 4861.57829159
 4812.29789474 5009.44890185 4743.83523951 4775.74990292 4654.94663439]
total_rewards_mean           4824.597874878151
total_rewards_std            93.19452094767739
total_rewards_max            5009.448901854064
total_rewards_min            4654.9466343894865
Number of train steps total  108000
Number of env steps total    326000
Number of rollouts total     0
Train Time (s)               141.2612595348619
(Previous) Eval Time (s)     20.997426039073616
Sample Time (s)              6.409218803979456
Epoch Time (s)               168.66790437791497
Total Train Time (s)         4522.480996177066
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:09:00.971810 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #26 | Epoch Duration: 168.751207113266
2020-01-12 09:09:00.971994 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0352776
Z variance train             0.012401191
KL Divergence                30.053246
KL Loss                      3.0053246
QF Loss                      263.26642
VF Loss                      54.5548
Policy Loss                  -710.5604
Q Predictions Mean           699.81146
Q Predictions Std            621.94183
Q Predictions Max            1934.0841
Q Predictions Min            57.98015
V Predictions Mean           714.37573
V Predictions Std            622.8636
V Predictions Max            1925.218
V Predictions Min            61.315956
Log Pis Mean                 -1.4607358
Log Pis Std                  3.2791247
Log Pis Max                  9.323282
Log Pis Min                  -6.436953
Policy mu Mean               -0.03982942
Policy mu Std                0.6925763
Policy mu Max                2.63727
Policy mu Min                -2.20095
Policy log std Mean          -0.45009172
Policy log std Std           0.21778397
Policy log std Max           -0.16445899
Policy log std Min           -2.0487385
Z mean eval                  2.0214164
Z variance eval              0.010071065
total_rewards                [5182.63918377 5091.50331903 5103.22119622 5039.1372463  5151.28000896
 5128.72296529 5039.69001429 5098.48234197 5255.90866963 5008.14275095]
total_rewards_mean           5109.872769643438
total_rewards_std            70.34264464468178
total_rewards_max            5255.90866963438
total_rewards_min            5008.142750953293
Number of train steps total  112000
Number of env steps total    338000
Number of rollouts total     0
Train Time (s)               141.0411677430384
(Previous) Eval Time (s)     18.003767985850573
Sample Time (s)              6.6133713675662875
Epoch Time (s)               165.65830709645525
Total Train Time (s)         4688.2212854032405
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:11:46.712660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #27 | Epoch Duration: 165.74053406715393
2020-01-12 09:11:46.712831 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #27 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0188687
Z variance train             0.010054784
KL Divergence                30.087471
KL Loss                      3.008747
QF Loss                      266.87878
VF Loss                      121.0192
Policy Loss                  -702.7262
Q Predictions Mean           691.6536
Q Predictions Std            639.0264
Q Predictions Max            2008.6222
Q Predictions Min            50.822777
V Predictions Mean           699.0124
V Predictions Std            641.7784
V Predictions Max            2003.8915
V Predictions Min            52.57433
Log Pis Mean                 -1.7039969
Log Pis Std                  2.9844642
Log Pis Max                  12.922958
Log Pis Min                  -7.612914
Policy mu Mean               -0.059568897
Policy mu Std                0.70399445
Policy mu Max                2.367546
Policy mu Min                -2.6718206
Policy log std Mean          -0.42861238
Policy log std Std           0.2138189
Policy log std Max           -0.10575122
Policy log std Min           -2.140331
Z mean eval                  2.027985
Z variance eval              0.01118052
total_rewards                [4410.39408363 4657.48944395 4767.114662   4921.24410369 4892.8415199
 4743.08554605 4855.15624898 4897.55695556 4526.66983644 4369.1545255 ]
total_rewards_mean           4704.0706925700915
total_rewards_std            195.0935319340546
total_rewards_max            4921.244103687312
total_rewards_min            4369.154525503183
Number of train steps total  116000
Number of env steps total    350000
Number of rollouts total     0
Train Time (s)               140.86426348332316
(Previous) Eval Time (s)     17.746226230170578
Sample Time (s)              6.709316718857735
Epoch Time (s)               165.31980643235147
Total Train Time (s)         4853.639465515502
Epoch                        28
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:14:32.134787 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #28 | Epoch Duration: 165.4217963218689
2020-01-12 09:14:32.135095 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0266674
Z variance train             0.011172461
KL Divergence                30.200075
KL Loss                      3.0200076
QF Loss                      419.12427
VF Loss                      124.63762
Policy Loss                  -685.0663
Q Predictions Mean           674.84155
Q Predictions Std            646.5492
Q Predictions Max            2002.5687
Q Predictions Min            31.501518
V Predictions Mean           681.33026
V Predictions Std            646.2774
V Predictions Max            1990.4631
V Predictions Min            46.71347
Log Pis Mean                 -1.341938
Log Pis Std                  3.5698185
Log Pis Max                  12.222639
Log Pis Min                  -6.309934
Policy mu Mean               -0.040434983
Policy mu Std                0.75269246
Policy mu Max                2.889136
Policy mu Min                -2.5509439
Policy log std Mean          -0.42825142
Policy log std Std           0.20375769
Policy log std Max           -0.14308858
Policy log std Min           -1.8292899
Z mean eval                  2.0582018
Z variance eval              0.010430889
total_rewards                [5008.13326421 4974.93899032 5062.57897545 4870.47741931 4796.37815565
 4859.92731145 4989.17966042 5047.78401663 4946.93882823 5034.46758714]
total_rewards_mean           4959.080420880951
total_rewards_std            84.9284521215626
total_rewards_max            5062.578975451279
total_rewards_min            4796.378155654111
Number of train steps total  120000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               140.1498629320413
(Previous) Eval Time (s)     17.633558608591557
Sample Time (s)              6.662011910695583
Epoch Time (s)               164.44543345132843
Total Train Time (s)         5018.166662522126
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:17:16.660337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #29 | Epoch Duration: 164.52508091926575
2020-01-12 09:17:16.660464 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0576825
Z variance train             0.010412558
KL Divergence                31.138704
KL Loss                      3.1138704
QF Loss                      285.7967
VF Loss                      116.991905
Policy Loss                  -746.8724
Q Predictions Mean           738.9391
Q Predictions Std            664.5203
Q Predictions Max            2037.9059
Q Predictions Min            30.50481
V Predictions Mean           740.34644
V Predictions Std            665.69196
V Predictions Max            2023.6799
V Predictions Min            31.49628
Log Pis Mean                 -1.5492251
Log Pis Std                  3.4208007
Log Pis Max                  13.254298
Log Pis Min                  -7.7265205
Policy mu Mean               -0.013829236
Policy mu Std                0.72250754
Policy mu Max                3.267513
Policy mu Min                -2.490012
Policy log std Mean          -0.4482905
Policy log std Std           0.22513644
Policy log std Max           -0.16336924
Policy log std Min           -2.0232937
Z mean eval                  2.0259438
Z variance eval              0.010483713
total_rewards                [5194.02909708 5278.40269842 4935.91400351 5203.3047555  5086.38994591
 5151.55745666 4928.47303166 5213.3157406  5184.3956227  5020.14055701]
total_rewards_mean           5119.592290905054
total_rewards_std            115.33950608277617
total_rewards_max            5278.402698422147
total_rewards_min            4928.473031656963
Number of train steps total  124000
Number of env steps total    374000
Number of rollouts total     0
Train Time (s)               141.5582011579536
(Previous) Eval Time (s)     17.912122840993106
Sample Time (s)              5.539829174987972
Epoch Time (s)               165.01015317393467
Total Train Time (s)         5183.252319649328
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:20:01.746949 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #30 | Epoch Duration: 165.08639454841614
2020-01-12 09:20:01.747072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.024499
Z variance train             0.010481054
KL Divergence                31.816204
KL Loss                      3.1816204
QF Loss                      320.4638
VF Loss                      120.12851
Policy Loss                  -730.2805
Q Predictions Mean           730.4114
Q Predictions Std            684.0302
Q Predictions Max            2035.8125
Q Predictions Min            28.300985
V Predictions Mean           731.5387
V Predictions Std            686.4791
V Predictions Max            2040.6293
V Predictions Min            28.085276
Log Pis Mean                 -1.7431116
Log Pis Std                  3.3617494
Log Pis Max                  10.267867
Log Pis Min                  -7.428671
Policy mu Mean               -0.093174584
Policy mu Std                0.71207017
Policy mu Max                2.730125
Policy mu Min                -2.4501557
Policy log std Mean          -0.44136313
Policy log std Std           0.21834816
Policy log std Max           -0.13053262
Policy log std Min           -1.9691508
Z mean eval                  2.0677016
Z variance eval              0.011395861
total_rewards                [4913.49948454 5029.09877209 4992.64858802 4943.18625227 5060.08056666
 4849.38693109 5159.94198972 5043.60289026 4833.75016385 4901.20610447]
total_rewards_mean           4972.64017429837
total_rewards_std            97.62232696584172
total_rewards_max            5159.94198972395
total_rewards_min            4833.750163852258
Number of train steps total  128000
Number of env steps total    386000
Number of rollouts total     0
Train Time (s)               141.90789236221462
(Previous) Eval Time (s)     20.776423908770084
Sample Time (s)              5.908073846716434
Epoch Time (s)               168.59239011770114
Total Train Time (s)         5351.927293284796
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:22:50.424460 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #31 | Epoch Duration: 168.67728209495544
2020-01-12 09:22:50.424633 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0681777
Z variance train             0.011424643
KL Divergence                31.909388
KL Loss                      3.1909387
QF Loss                      676.81323
VF Loss                      297.85492
Policy Loss                  -702.78284
Q Predictions Mean           699.1506
Q Predictions Std            674.1053
Q Predictions Max            2018.4272
Q Predictions Min            18.44637
V Predictions Mean           715.4896
V Predictions Std            679.4722
V Predictions Max            2048.6272
V Predictions Min            26.603224
Log Pis Mean                 -1.8288109
Log Pis Std                  2.8762844
Log Pis Max                  7.754303
Log Pis Min                  -6.397706
Policy mu Mean               -0.031804267
Policy mu Std                0.69080275
Policy mu Max                2.4755273
Policy mu Min                -2.460748
Policy log std Mean          -0.43325615
Policy log std Std           0.2059932
Policy log std Max           -0.17781869
Policy log std Min           -1.8117874
Z mean eval                  2.0115523
Z variance eval              0.009158669
total_rewards                [4930.71792118 4961.27760372 4962.53582958 4958.88330646 5123.64096342
 4917.26776985 4894.19879394 5066.61585105 5138.38355569 5131.77833401]
total_rewards_mean           5008.529992890032
total_rewards_std            91.07402678033239
total_rewards_max            5138.383555689717
total_rewards_min            4894.198793941758
Number of train steps total  132000
Number of env steps total    398000
Number of rollouts total     0
Train Time (s)               140.84066153736785
(Previous) Eval Time (s)     21.090258467011154
Sample Time (s)              6.336463165469468
Epoch Time (s)               168.26738316984847
Total Train Time (s)         5520.274471122306
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:25:38.771578 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #32 | Epoch Duration: 168.346825838089
2020-01-12 09:25:38.771712 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0108795
Z variance train             0.009148742
KL Divergence                31.219786
KL Loss                      3.1219785
QF Loss                      462.36652
VF Loss                      98.95071
Policy Loss                  -799.978
Q Predictions Mean           792.73425
Q Predictions Std            697.7275
Q Predictions Max            2116.9197
Q Predictions Min            7.562318
V Predictions Mean           805.38354
V Predictions Std            697.1497
V Predictions Max            2120.521
V Predictions Min            18.913448
Log Pis Mean                 -1.3409331
Log Pis Std                  3.4899313
Log Pis Max                  15.142234
Log Pis Min                  -10.815371
Policy mu Mean               -0.007524267
Policy mu Std                0.7541136
Policy mu Max                2.6081161
Policy mu Min                -2.9091694
Policy log std Mean          -0.44662738
Policy log std Std           0.23447126
Policy log std Max           -0.10689992
Policy log std Min           -1.9322999
Z mean eval                  2.0111644
Z variance eval              0.007921029
total_rewards                [5129.58879806 5111.6687505  5297.14298844 5097.01310495 5127.74535869
 5013.73793278 5257.27606019 5063.39930136 5181.40848919 5325.89018935]
total_rewards_mean           5160.487097349945
total_rewards_std            97.5905148372823
total_rewards_max            5325.8901893526845
total_rewards_min            5013.737932775146
Number of train steps total  136000
Number of env steps total    410000
Number of rollouts total     0
Train Time (s)               142.93487990368158
(Previous) Eval Time (s)     17.54302972694859
Sample Time (s)              6.32580513227731
Epoch Time (s)               166.80371476290748
Total Train Time (s)         5687.161943530664
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:28:25.666689 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #33 | Epoch Duration: 166.89479684829712
2020-01-12 09:28:25.666888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.013196
Z variance train             0.007927309
KL Divergence                32.476612
KL Loss                      3.2476614
QF Loss                      298.3022
VF Loss                      70.395615
Policy Loss                  -746.57043
Q Predictions Mean           743.2012
Q Predictions Std            706.8649
Q Predictions Max            2111.5063
Q Predictions Min            9.975159
V Predictions Mean           748.12537
V Predictions Std            704.9973
V Predictions Max            2103.6926
V Predictions Min            5.57406
Log Pis Mean                 -1.724053
Log Pis Std                  3.1172962
Log Pis Max                  10.207581
Log Pis Min                  -9.23498
Policy mu Mean               -0.11991951
Policy mu Std                0.6812127
Policy mu Max                3.2648926
Policy mu Min                -2.3841546
Policy log std Mean          -0.4455271
Policy log std Std           0.23644611
Policy log std Max           -0.14020789
Policy log std Min           -2.1365905
Z mean eval                  1.9923277
Z variance eval              0.0065028593
total_rewards                [5197.35521313 5141.54552838 5251.19244734 5284.64058169 5181.27458809
 5284.98839445 5165.15116807 5169.73454645 5271.48448344 5131.62165571]
total_rewards_mean           5207.8988606746825
total_rewards_std            56.63429281935582
total_rewards_max            5284.988394448434
total_rewards_min            5131.62165571312
Number of train steps total  140000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               141.8314101928845
(Previous) Eval Time (s)     21.229320212733
Sample Time (s)              6.686043226160109
Epoch Time (s)               169.74677363177761
Total Train Time (s)         5856.989601863548
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:31:15.490472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #34 | Epoch Duration: 169.82345485687256
2020-01-12 09:31:15.490662 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9908043
Z variance train             0.0065027988
KL Divergence                32.60604
KL Loss                      3.2606041
QF Loss                      463.14
VF Loss                      227.22041
Policy Loss                  -795.10925
Q Predictions Mean           785.98083
Q Predictions Std            677.6413
Q Predictions Max            2136.5193
Q Predictions Min            3.414191
V Predictions Mean           790.85913
V Predictions Std            679.9208
V Predictions Max            2105.9216
V Predictions Min            -4.4826446
Log Pis Mean                 -1.2362294
Log Pis Std                  3.76636
Log Pis Max                  18.776363
Log Pis Min                  -11.588324
Policy mu Mean               0.01176576
Policy mu Std                0.76745343
Policy mu Max                3.4863715
Policy mu Min                -2.9122043
Policy log std Mean          -0.46014056
Policy log std Std           0.2393165
Policy log std Max           -0.12928592
Policy log std Min           -2.080087
Z mean eval                  1.982322
Z variance eval              0.01019543
total_rewards                [5511.46937797 5275.52435592 5299.64951233 5623.86889705 5489.50535016
 5528.13720094 5434.59457079 5314.21975526 5166.55774969 5289.20242108]
total_rewards_mean           5393.272919119725
total_rewards_std            136.89826437036996
total_rewards_max            5623.86889705389
total_rewards_min            5166.557749693539
Number of train steps total  144000
Number of env steps total    434000
Number of rollouts total     0
Train Time (s)               142.30565339094028
(Previous) Eval Time (s)     17.496944373007864
Sample Time (s)              6.514322770293802
Epoch Time (s)               166.31692053424194
Total Train Time (s)         6023.396328133531
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:34:01.898952 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #35 | Epoch Duration: 166.4081506729126
2020-01-12 09:34:01.899142 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9842106
Z variance train             0.010114294
KL Divergence                31.774921
KL Loss                      3.1774921
QF Loss                      719.38043
VF Loss                      142.73395
Policy Loss                  -731.98566
Q Predictions Mean           728.1707
Q Predictions Std            687.2407
Q Predictions Max            2071.074
Q Predictions Min            -0.54025406
V Predictions Mean           730.228
V Predictions Std            691.8735
V Predictions Max            2086.4177
V Predictions Min            -3.9985905
Log Pis Mean                 -1.4094245
Log Pis Std                  3.4193897
Log Pis Max                  12.677217
Log Pis Min                  -7.1152325
Policy mu Mean               0.034444217
Policy mu Std                0.7468055
Policy mu Max                2.5352218
Policy mu Min                -2.57408
Policy log std Mean          -0.4505248
Policy log std Std           0.23987654
Policy log std Max           -0.13523254
Policy log std Min           -2.0475059
Z mean eval                  1.9508088
Z variance eval              0.016275797
total_rewards                [5003.12511508 5326.30028738 5190.58051303 5142.59032258 5331.63778743
 5310.00922322 5297.72064848 5135.7072647  5195.42553707 5284.08597899]
total_rewards_mean           5221.718267796825
total_rewards_std            101.7762467060514
total_rewards_max            5331.637787429987
total_rewards_min            5003.125115082092
Number of train steps total  148000
Number of env steps total    446000
Number of rollouts total     0
Train Time (s)               144.4348793583922
(Previous) Eval Time (s)     20.861664231866598
Sample Time (s)              6.419082653708756
Epoch Time (s)               171.71562624396756
Total Train Time (s)         6195.258109313436
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:36:53.772583 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #36 | Epoch Duration: 171.8732626438141
2020-01-12 09:36:53.772891 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9521799
Z variance train             0.0163229
KL Divergence                30.590855
KL Loss                      3.0590856
QF Loss                      715.11865
VF Loss                      172.6002
Policy Loss                  -858.7785
Q Predictions Mean           852.54987
Q Predictions Std            704.0104
Q Predictions Max            2119.3477
Q Predictions Min            172.0868
V Predictions Mean           851.788
V Predictions Std            707.78625
V Predictions Max            2117.8516
V Predictions Min            170.26138
Log Pis Mean                 -0.9219233
Log Pis Std                  3.811944
Log Pis Max                  19.309246
Log Pis Min                  -9.117815
Policy mu Mean               -0.01584625
Policy mu Std                0.82065904
Policy mu Max                2.7104678
Policy mu Min                -2.586577
Policy log std Mean          -0.45785967
Policy log std Std           0.22366466
Policy log std Max           -0.07210088
Policy log std Min           -1.7587082
Z mean eval                  1.9624538
Z variance eval              0.016997833
total_rewards                [5132.91055929 5157.18391045 5281.45662361 5146.77024401 5091.99859833
 5230.39312718 5209.76390769 5175.3328794  5100.81521801 5335.88686695]
total_rewards_mean           5186.251193492533
total_rewards_std            74.50316066494202
total_rewards_max            5335.886866950929
total_rewards_min            5091.998598326392
Number of train steps total  152000
Number of env steps total    458000
Number of rollouts total     0
Train Time (s)               145.45794845093042
(Previous) Eval Time (s)     20.677375125698745
Sample Time (s)              6.431504470761865
Epoch Time (s)               172.56682804739103
Total Train Time (s)         6367.9311778373085
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:39:46.434021 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #37 | Epoch Duration: 172.6609284877777
2020-01-12 09:39:46.434152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9644178
Z variance train             0.017000634
KL Divergence                30.903831
KL Loss                      3.0903833
QF Loss                      364.62387
VF Loss                      87.63764
Policy Loss                  -833.8527
Q Predictions Mean           825.0542
Q Predictions Std            742.15674
Q Predictions Max            2155.3752
Q Predictions Min            -25.079063
V Predictions Mean           836.38275
V Predictions Std            745.8499
V Predictions Max            2155.4973
V Predictions Min            -16.207958
Log Pis Mean                 -1.4076827
Log Pis Std                  3.2843692
Log Pis Max                  9.679754
Log Pis Min                  -6.10823
Policy mu Mean               0.041896883
Policy mu Std                0.7189112
Policy mu Max                2.3668315
Policy mu Min                -2.2783396
Policy log std Mean          -0.45866325
Policy log std Std           0.24457046
Policy log std Max           -0.16071695
Policy log std Min           -1.941442
Z mean eval                  1.9287876
Z variance eval              0.010005602
total_rewards                [5234.26838    5329.25251579 5315.78567077 5207.5551744  5415.67141014
 5449.64089351 5264.04659681 5284.43980118 5182.61279573 5300.13561691]
total_rewards_mean           5298.340885523703
total_rewards_std            80.64172329573218
total_rewards_max            5449.6408935102945
total_rewards_min            5182.612795726832
Number of train steps total  156000
Number of env steps total    470000
Number of rollouts total     0
Train Time (s)               144.1300858198665
(Previous) Eval Time (s)     19.676211544778198
Sample Time (s)              6.481772172264755
Epoch Time (s)               170.28806953690946
Total Train Time (s)         6538.415540090296
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:42:36.920236 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #38 | Epoch Duration: 170.48597359657288
2020-01-12 09:42:36.920432 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9272105
Z variance train             0.010000967
KL Divergence                32.510223
KL Loss                      3.2510223
QF Loss                      577.2046
VF Loss                      84.348495
Policy Loss                  -664.87524
Q Predictions Mean           656.20935
Q Predictions Std            689.24524
Q Predictions Max            2182.8716
Q Predictions Min            -25.503555
V Predictions Mean           665.0832
V Predictions Std            691.6892
V Predictions Max            2192.0193
V Predictions Min            -19.707468
Log Pis Mean                 -1.5502934
Log Pis Std                  3.6842868
Log Pis Max                  16.854641
Log Pis Min                  -5.7363153
Policy mu Mean               -0.032096673
Policy mu Std                0.7010603
Policy mu Max                2.8819785
Policy mu Min                -2.8021574
Policy log std Mean          -0.43353677
Policy log std Std           0.22576028
Policy log std Max           -0.111487776
Policy log std Min           -2.1224132
Z mean eval                  1.9261463
Z variance eval              0.010553861
total_rewards                [4841.72023421 4727.1767504  4673.99357773 4695.26410871 4732.95423643
 4804.11740735 4877.10070315 4711.59387007 4943.79758326 4801.65676445]
total_rewards_mean           4780.937523576407
total_rewards_std            83.19254079580932
total_rewards_max            4943.7975832642405
total_rewards_min            4673.993577734056
Number of train steps total  160000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               144.26923241792247
(Previous) Eval Time (s)     21.0937678120099
Sample Time (s)              6.575462173204869
Epoch Time (s)               171.93846240313724
Total Train Time (s)         6710.44034270104
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:45:28.946509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #39 | Epoch Duration: 172.02594590187073
2020-01-12 09:45:28.946658 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9253658
Z variance train             0.010538174
KL Divergence                31.91695
KL Loss                      3.191695
QF Loss                      289.47015
VF Loss                      93.636505
Policy Loss                  -705.2595
Q Predictions Mean           698.34973
Q Predictions Std            704.986
Q Predictions Max            2164.7893
Q Predictions Min            -40.51577
V Predictions Mean           702.0286
V Predictions Std            708.7143
V Predictions Max            2157.868
V Predictions Min            -30.491829
Log Pis Mean                 -1.5988269
Log Pis Std                  3.524259
Log Pis Max                  15.619225
Log Pis Min                  -7.467081
Policy mu Mean               0.009076622
Policy mu Std                0.71365994
Policy mu Max                2.5810375
Policy mu Min                -3.640359
Policy log std Mean          -0.4447304
Policy log std Std           0.23135073
Policy log std Max           -0.20116125
Policy log std Min           -2.151151
Z mean eval                  1.9241874
Z variance eval              0.007018107
total_rewards                [5255.78238791 5357.09015168 5286.09799596 5145.63399025 5446.89738573
 5469.86368091 5470.00097291 5484.02568532 5471.74067345 5090.33573978]
total_rewards_mean           5347.7468663903
total_rewards_std            138.95727308234007
total_rewards_max            5484.0256853181645
total_rewards_min            5090.335739783655
Number of train steps total  164000
Number of env steps total    494000
Number of rollouts total     0
Train Time (s)               143.19572606729344
(Previous) Eval Time (s)     20.853195880074054
Sample Time (s)              6.616421832703054
Epoch Time (s)               170.66534378007054
Total Train Time (s)         6881.185848126188
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:48:19.693430 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #40 | Epoch Duration: 170.74665665626526
2020-01-12 09:48:19.693619 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9250212
Z variance train             0.0070357444
KL Divergence                33.920822
KL Loss                      3.3920822
QF Loss                      243.66617
VF Loss                      69.93758
Policy Loss                  -766.4918
Q Predictions Mean           757.9278
Q Predictions Std            732.8205
Q Predictions Max            2186.0105
Q Predictions Min            -49.129402
V Predictions Mean           764.6832
V Predictions Std            730.8566
V Predictions Max            2169.438
V Predictions Min            -33.23138
Log Pis Mean                 -1.6020355
Log Pis Std                  3.108923
Log Pis Max                  8.506835
Log Pis Min                  -8.212087
Policy mu Mean               -0.054869715
Policy mu Std                0.71235174
Policy mu Max                2.9054751
Policy mu Min                -2.399456
Policy log std Mean          -0.45114264
Policy log std Std           0.22765432
Policy log std Max           -0.1610497
Policy log std Min           -2.0342834
Z mean eval                  1.9190514
Z variance eval              0.011739949
total_rewards                [5375.27445305 5470.55176071 5318.34127574 5630.99344036 5334.14956611
 5481.03371384 5555.55744295 5505.58239179 5567.26934222 5502.63762853]
total_rewards_mean           5474.139101529052
total_rewards_std            97.67854122860655
total_rewards_max            5630.993440358563
total_rewards_min            5318.341275739586
Number of train steps total  168000
Number of env steps total    506000
Number of rollouts total     0
Train Time (s)               143.62412471883
(Previous) Eval Time (s)     21.018029063940048
Sample Time (s)              6.4341979143209755
Epoch Time (s)               171.076351697091
Total Train Time (s)         7052.3416511416435
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:51:10.850680 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #41 | Epoch Duration: 171.1569230556488
2020-01-12 09:51:10.850870 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9198879
Z variance train             0.011732917
KL Divergence                34.13242
KL Loss                      3.413242
QF Loss                      609.5105
VF Loss                      74.978035
Policy Loss                  -804.8811
Q Predictions Mean           797.6124
Q Predictions Std            753.85614
Q Predictions Max            2188.6362
Q Predictions Min            -75.26409
V Predictions Mean           805.4087
V Predictions Std            756.02185
V Predictions Max            2211.2659
V Predictions Min            -47.226604
Log Pis Mean                 -1.4342676
Log Pis Std                  3.0170403
Log Pis Max                  7.873294
Log Pis Min                  -5.6499586
Policy mu Mean               -0.012094073
Policy mu Std                0.7186303
Policy mu Max                2.4601004
Policy mu Min                -2.3178265
Policy log std Mean          -0.4514916
Policy log std Std           0.2352799
Policy log std Max           -0.102035195
Policy log std Min           -2.2101946
Z mean eval                  1.9269985
Z variance eval              0.013267791
total_rewards                [5316.75040639 5394.59284535 5624.51197886 5448.12631754 5410.69106145
 5397.81146692 5397.91677631 5468.97522051 5419.58793861 5400.23368368]
total_rewards_mean           5427.919769562427
total_rewards_std            75.59835924673186
total_rewards_max            5624.511978855735
total_rewards_min            5316.750406388005
Number of train steps total  172000
Number of env steps total    518000
Number of rollouts total     0
Train Time (s)               143.49168620212004
(Previous) Eval Time (s)     17.771745512727648
Sample Time (s)              6.452022929675877
Epoch Time (s)               167.71545464452356
Total Train Time (s)         7220.141392479185
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:53:58.651610 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #42 | Epoch Duration: 167.80060124397278
2020-01-12 09:53:58.651782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9245384
Z variance train             0.013272281
KL Divergence                34.07424
KL Loss                      3.4074242
QF Loss                      357.13147
VF Loss                      52.87967
Policy Loss                  -819.3936
Q Predictions Mean           809.0873
Q Predictions Std            776.2733
Q Predictions Max            2288.3298
Q Predictions Min            -81.76934
V Predictions Mean           820.7569
V Predictions Std            779.14026
V Predictions Max            2284.8242
V Predictions Min            -53.971855
Log Pis Mean                 -1.3937776
Log Pis Std                  3.290599
Log Pis Max                  9.213146
Log Pis Min                  -6.105917
Policy mu Mean               -0.012945895
Policy mu Std                0.73307234
Policy mu Max                2.6098738
Policy mu Min                -2.747522
Policy log std Mean          -0.44627246
Policy log std Std           0.24057874
Policy log std Max           -0.107094675
Policy log std Min           -1.9801906
Z mean eval                  1.9023939
Z variance eval              0.015818728
total_rewards                [5469.7053899  5304.34691067 5318.87198343 5273.46485828 5475.76758404
 5335.37818025 5353.28994653 5586.96660554 5378.88940983 5557.66317237]
total_rewards_mean           5405.4344040848255
total_rewards_std            104.24217215954204
total_rewards_max            5586.966605542253
total_rewards_min            5273.464858280324
Number of train steps total  176000
Number of env steps total    530000
Number of rollouts total     0
Train Time (s)               143.06550880009308
(Previous) Eval Time (s)     17.937850577756763
Sample Time (s)              6.5041520041413605
Epoch Time (s)               167.5075113819912
Total Train Time (s)         7387.733203678392
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:56:46.243860 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #43 | Epoch Duration: 167.59194827079773
2020-01-12 09:56:46.244029 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9012167
Z variance train             0.015815016
KL Divergence                33.998493
KL Loss                      3.3998494
QF Loss                      239.00424
VF Loss                      67.562
Policy Loss                  -843.2859
Q Predictions Mean           835.68353
Q Predictions Std            768.2106
Q Predictions Max            2215.9426
Q Predictions Min            -88.108795
V Predictions Mean           846.5725
V Predictions Std            770.4154
V Predictions Max            2201.6748
V Predictions Min            -65.46102
Log Pis Mean                 -1.4238472
Log Pis Std                  3.4480162
Log Pis Max                  12.307868
Log Pis Min                  -7.2456417
Policy mu Mean               -0.060283113
Policy mu Std                0.7465031
Policy mu Max                2.421081
Policy mu Min                -2.3180935
Policy log std Mean          -0.45589724
Policy log std Std           0.21825029
Policy log std Max           -0.09982677
Policy log std Min           -2.124179
Z mean eval                  1.9076974
Z variance eval              0.04037873
total_rewards                [5442.26682282 5653.77333504 5710.47590112 5433.29131856 5687.16211155
 5542.57404424 5823.81447824 5477.79926265 5558.08626691 5659.14061679]
total_rewards_mean           5598.838415792896
total_rewards_std            122.03681071785272
total_rewards_max            5823.814478235809
total_rewards_min            5433.291318557084
Number of train steps total  180000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               142.94119915133342
(Previous) Eval Time (s)     17.483790965750813
Sample Time (s)              6.430965636391193
Epoch Time (s)               166.85595575347543
Total Train Time (s)         7554.683714353014
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:59:33.196329 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #44 | Epoch Duration: 166.95216512680054
2020-01-12 09:59:33.196519 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9086632
Z variance train             0.04029987
KL Divergence                33.183628
KL Loss                      3.318363
QF Loss                      304.98355
VF Loss                      73.066986
Policy Loss                  -791.1003
Q Predictions Mean           780.9748
Q Predictions Std            736.90955
Q Predictions Max            2218.1575
Q Predictions Min            -55.744564
V Predictions Mean           789.50476
V Predictions Std            740.0092
V Predictions Max            2206.0757
V Predictions Min            -64.38012
Log Pis Mean                 -1.5340321
Log Pis Std                  3.1847403
Log Pis Max                  8.749015
Log Pis Min                  -7.5470295
Policy mu Mean               0.054742172
Policy mu Std                0.72062105
Policy mu Max                2.8809147
Policy mu Min                -2.7458968
Policy log std Mean          -0.44299898
Policy log std Std           0.23286764
Policy log std Max           0.025168508
Policy log std Min           -2.0386028
Z mean eval                  1.8513556
Z variance eval              0.012730596
total_rewards                [5397.40525502 5370.16353743 5364.22663627 5264.2891714  5653.57532821
 5398.2987839  5505.47656431 5374.14392836 5670.40702041 5507.41517989]
total_rewards_mean           5450.540140520181
total_rewards_std            124.82235879247052
total_rewards_max            5670.407020414031
total_rewards_min            5264.28917139838
Number of train steps total  184000
Number of env steps total    554000
Number of rollouts total     0
Train Time (s)               144.12949279602617
(Previous) Eval Time (s)     17.7068201857619
Sample Time (s)              6.705497145652771
Epoch Time (s)               168.54181012744084
Total Train Time (s)         7723.308288410772
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:02:21.822865 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #45 | Epoch Duration: 168.62620306015015
2020-01-12 10:02:21.823058 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8514168
Z variance train             0.01271406
KL Divergence                33.495567
KL Loss                      3.3495567
QF Loss                      798.3193
VF Loss                      116.25695
Policy Loss                  -747.9724
Q Predictions Mean           744.17285
Q Predictions Std            755.35126
Q Predictions Max            2231.7295
Q Predictions Min            -56.000004
V Predictions Mean           747.9063
V Predictions Std            757.167
V Predictions Max            2235.5469
V Predictions Min            -54.767166
Log Pis Mean                 -1.1282357
Log Pis Std                  4.2470374
Log Pis Max                  23.090826
Log Pis Min                  -6.331657
Policy mu Mean               -0.06748571
Policy mu Std                0.8153058
Policy mu Max                4.0017395
Policy mu Min                -3.435657
Policy log std Mean          -0.43858957
Policy log std Std           0.21946585
Policy log std Max           -0.10813171
Policy log std Min           -2.1583917
Z mean eval                  1.8712082
Z variance eval              0.011885815
total_rewards                [5748.18982476 5783.06332014 5801.04602692 5645.08982198 5912.64965793
 5446.26334313 5708.11983901 5468.15816221 5646.84801799 5877.33752092]
total_rewards_mean           5703.6765534995375
total_rewards_std            148.3254860848242
total_rewards_max            5912.649657928322
total_rewards_min            5446.263343130335
Number of train steps total  188000
Number of env steps total    566000
Number of rollouts total     0
Train Time (s)               143.74878730112687
(Previous) Eval Time (s)     20.993784388992935
Sample Time (s)              6.59814507747069
Epoch Time (s)               171.3407167675905
Total Train Time (s)         7894.73615465872
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:05:13.254833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #46 | Epoch Duration: 171.43160009384155
2020-01-12 10:05:13.255145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #46 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8703245
Z variance train             0.01186792
KL Divergence                34.213387
KL Loss                      3.4213388
QF Loss                      263.79547
VF Loss                      90.35279
Policy Loss                  -792.53284
Q Predictions Mean           786.1685
Q Predictions Std            775.6831
Q Predictions Max            2308.4768
Q Predictions Min            -65.19418
V Predictions Mean           792.46094
V Predictions Std            777.14966
V Predictions Max            2282.9478
V Predictions Min            -66.33347
Log Pis Mean                 -1.6301293
Log Pis Std                  3.3078823
Log Pis Max                  11.368031
Log Pis Min                  -6.164665
Policy mu Mean               -0.054120336
Policy mu Std                0.69927406
Policy mu Max                2.808352
Policy mu Min                -2.4019203
Policy log std Mean          -0.45429122
Policy log std Std           0.2128615
Policy log std Max           -0.102273166
Policy log std Min           -1.7564662
Z mean eval                  1.8721428
Z variance eval              0.014268237
total_rewards                [5837.07552907 5850.41816961 5685.3987722  5558.38789608 5695.0855481
 5829.82082335 5717.63035447 5645.28799124 5734.21405516 5902.26022629]
total_rewards_mean           5745.557936558669
total_rewards_std            101.58193069532491
total_rewards_max            5902.260226291442
total_rewards_min            5558.387896084663
Number of train steps total  192000
Number of env steps total    578000
Number of rollouts total     0
Train Time (s)               143.50604869890958
(Previous) Eval Time (s)     17.73321666009724
Sample Time (s)              6.572123273741454
Epoch Time (s)               167.81138863274828
Total Train Time (s)         8062.632033065893
Epoch                        47
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:08:01.153273 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #47 | Epoch Duration: 167.8978705406189
2020-01-12 10:08:01.153607 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8735416
Z variance train             0.014314108
KL Divergence                34.210564
KL Loss                      3.4210565
QF Loss                      250.75179
VF Loss                      230.21744
Policy Loss                  -805.6316
Q Predictions Mean           799.13165
Q Predictions Std            794.46466
Q Predictions Max            2305.2632
Q Predictions Min            -59.250427
V Predictions Mean           798.6417
V Predictions Std            790.8266
V Predictions Max            2299.6558
V Predictions Min            -62.800117
Log Pis Mean                 -1.2670431
Log Pis Std                  3.7135718
Log Pis Max                  17.32623
Log Pis Min                  -6.441077
Policy mu Mean               -0.04691881
Policy mu Std                0.77236515
Policy mu Max                3.768476
Policy mu Min                -3.090287
Policy log std Mean          -0.46376157
Policy log std Std           0.24075274
Policy log std Max           -0.093961075
Policy log std Min           -2.1406426
Z mean eval                  1.9214566
Z variance eval              0.011791075
total_rewards                [5758.43177881 5669.22291618 5656.82555825 5533.6128064  5626.79835746
 5670.77350392 5878.66056699 5648.72597391 5743.69573581 5940.92112123]
total_rewards_mean           5712.7668318967935
total_rewards_std            115.32298504122477
total_rewards_max            5940.921121234132
total_rewards_min            5533.612806399934
Number of train steps total  196000
Number of env steps total    590000
Number of rollouts total     0
Train Time (s)               143.26335357129574
(Previous) Eval Time (s)     17.49813678022474
Sample Time (s)              6.509714362677187
Epoch Time (s)               167.27120471419767
Total Train Time (s)         8230.244601687416
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:10:48.769858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #48 | Epoch Duration: 167.6159737110138
2020-01-12 10:10:48.770176 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9220638
Z variance train             0.0117493365
KL Divergence                35.493843
KL Loss                      3.5493844
QF Loss                      172.55757
VF Loss                      130.18073
Policy Loss                  -838.7869
Q Predictions Mean           827.76196
Q Predictions Std            800.6093
Q Predictions Max            2316.8987
Q Predictions Min            -76.63891
V Predictions Mean           834.1653
V Predictions Std            798.9641
V Predictions Max            2306.9578
V Predictions Min            -60.37817
Log Pis Mean                 -1.3084625
Log Pis Std                  3.254869
Log Pis Max                  14.246044
Log Pis Min                  -8.17382
Policy mu Mean               -0.006135013
Policy mu Std                0.763452
Policy mu Max                3.1488557
Policy mu Min                -2.7901874
Policy log std Mean          -0.4522685
Policy log std Std           0.23155563
Policy log std Max           -0.16862334
Policy log std Min           -1.8720639
Z mean eval                  1.8891805
Z variance eval              0.026165362
total_rewards                [5804.44341711 5732.65804189 5751.82011639 5854.74367568 5720.83650314
 5904.0218234  5779.60885161 5630.85105581 5485.92094092 5787.32155007]
total_rewards_mean           5745.22259760217
total_rewards_std            111.7086290452769
total_rewards_max            5904.021823400131
total_rewards_min            5485.920940919257
Number of train steps total  200000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               143.59499228699133
(Previous) Eval Time (s)     20.5200759540312
Sample Time (s)              6.3855237369425595
Epoch Time (s)               170.5005919779651
Total Train Time (s)         8400.834318274632
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:13:39.354457 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #49 | Epoch Duration: 170.58405089378357
2020-01-12 10:13:39.354586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #49 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8877255
Z variance train             0.026143441
KL Divergence                34.261887
KL Loss                      3.4261887
QF Loss                      151.47
VF Loss                      74.689224
Policy Loss                  -777.18005
Q Predictions Mean           769.6283
Q Predictions Std            770.9103
Q Predictions Max            2333.2605
Q Predictions Min            -62.803467
V Predictions Mean           777.297
V Predictions Std            773.03485
V Predictions Max            2328.6194
V Predictions Min            -62.887608
Log Pis Mean                 -1.529425
Log Pis Std                  3.6031268
Log Pis Max                  17.604313
Log Pis Min                  -7.6806536
Policy mu Mean               -0.06453533
Policy mu Std                0.7351338
Policy mu Max                3.340883
Policy mu Min                -3.248255
Policy log std Mean          -0.4403194
Policy log std Std           0.219875
Policy log std Max           -0.12182957
Policy log std Min           -1.9094846
Z mean eval                  1.8983333
Z variance eval              0.03466819
total_rewards                [5956.75127262 1699.77521269 5811.72847505 5773.0327818  5821.3959483
 5721.56651624 5658.80711247 5837.42073997 6047.07290058 5953.67949323]
total_rewards_mean           5428.1230452949185
total_rewards_std            1247.6763245181592
total_rewards_max            6047.072900581278
total_rewards_min            1699.775212686662
Number of train steps total  204000
Number of env steps total    614000
Number of rollouts total     0
Train Time (s)               143.0922031570226
(Previous) Eval Time (s)     17.62692299997434
Sample Time (s)              6.368096839636564
Epoch Time (s)               167.0872229966335
Total Train Time (s)         8567.995984552428
Epoch                        50
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:16:26.516928 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #50 | Epoch Duration: 167.16224241256714
2020-01-12 10:16:26.517052 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8970093
Z variance train             0.03462486
KL Divergence                32.347282
KL Loss                      3.2347283
QF Loss                      238.3025
VF Loss                      70.43088
Policy Loss                  -772.3433
Q Predictions Mean           762.6304
Q Predictions Std            776.8947
Q Predictions Max            2348.6226
Q Predictions Min            -78.86066
V Predictions Mean           768.6371
V Predictions Std            777.508
V Predictions Max            2334.2148
V Predictions Min            -67.32561
Log Pis Mean                 -1.4217439
Log Pis Std                  3.4403946
Log Pis Max                  17.663092
Log Pis Min                  -6.4747696
Policy mu Mean               -0.006363314
Policy mu Std                0.7322028
Policy mu Max                2.9210782
Policy mu Min                -3.011281
Policy log std Mean          -0.4603014
Policy log std Std           0.23135853
Policy log std Max           -0.1317612
Policy log std Min           -2.0758135
Z mean eval                  1.8859174
Z variance eval              0.028622497
total_rewards                [5676.73303539 6136.70675763 5807.77601871 5843.73649974 5867.46245166
 5539.20326202 5775.14656404 5625.9146136  5841.53958546 5851.46430082]
total_rewards_mean           5796.5683089078075
total_rewards_std            154.36496215590952
total_rewards_max            6136.7067576262425
total_rewards_min            5539.203262022167
Number of train steps total  208000
Number of env steps total    626000
Number of rollouts total     0
Train Time (s)               140.98946531908587
(Previous) Eval Time (s)     20.95800048438832
Sample Time (s)              5.5577001688070595
Epoch Time (s)               167.50516597228125
Total Train Time (s)         8735.581801717635
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:19:14.104274 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #51 | Epoch Duration: 167.58712887763977
2020-01-12 10:19:14.104404 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8855245
Z variance train             0.02874494
KL Divergence                32.242107
KL Loss                      3.2242107
QF Loss                      415.83487
VF Loss                      130.15628
Policy Loss                  -863.2267
Q Predictions Mean           851.42523
Q Predictions Std            818.6352
Q Predictions Max            2347.273
Q Predictions Min            -71.14651
V Predictions Mean           862.005
V Predictions Std            818.00867
V Predictions Max            2336.8342
V Predictions Min            -59.318924
Log Pis Mean                 -1.0537436
Log Pis Std                  3.5502145
Log Pis Max                  16.264355
Log Pis Min                  -6.4583836
Policy mu Mean               -0.0024442847
Policy mu Std                0.7759726
Policy mu Max                2.6581337
Policy mu Min                -3.0068195
Policy log std Mean          -0.46276775
Policy log std Std           0.22981273
Policy log std Max           -0.11840966
Policy log std Min           -1.8850093
Z mean eval                  1.8791876
Z variance eval              0.05245585
total_rewards                [5647.46107092 5810.82622592 5733.83735299 5746.90792243 5470.40518885
 5541.54561808 5705.30807394 5811.23556752 5796.46995441 5680.22718485]
total_rewards_mean           5694.422415992133
total_rewards_std            108.62666732609759
total_rewards_max            5811.235567519679
total_rewards_min            5470.405188848102
Number of train steps total  212000
Number of env steps total    638000
Number of rollouts total     0
Train Time (s)               142.00966284796596
(Previous) Eval Time (s)     17.656149435788393
Sample Time (s)              6.600771842524409
Epoch Time (s)               166.26658412627876
Total Train Time (s)         8901.922805187758
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:22:00.445970 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #52 | Epoch Duration: 166.34147119522095
2020-01-12 10:22:00.446101 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8796126
Z variance train             0.05281351
KL Divergence                31.209103
KL Loss                      3.1209104
QF Loss                      385.22107
VF Loss                      154.79964
Policy Loss                  -882.1649
Q Predictions Mean           876.24396
Q Predictions Std            834.06836
Q Predictions Max            2412.9082
Q Predictions Min            -84.228714
V Predictions Mean           882.1519
V Predictions Std            831.72
V Predictions Max            2375.1313
V Predictions Min            -62.908863
Log Pis Mean                 -1.2079711
Log Pis Std                  3.4926126
Log Pis Max                  14.1277485
Log Pis Min                  -7.2336392
Policy mu Mean               -0.08577788
Policy mu Std                0.7572583
Policy mu Max                3.0300536
Policy mu Min                -2.4278972
Policy log std Mean          -0.45907047
Policy log std Std           0.22877806
Policy log std Max           -0.13666219
Policy log std Min           -2.0360932
Z mean eval                  1.8759577
Z variance eval              0.019643849
total_rewards                [6015.20083317 5955.70823263 6288.19307968 6084.16033687 6059.58445514
 6035.6238619  5759.36011688 6073.98305983 6069.37890615 6141.730862  ]
total_rewards_mean           6048.29237442458
total_rewards_std            127.32281349773167
total_rewards_max            6288.193079683072
total_rewards_min            5759.360116880512
Number of train steps total  216000
Number of env steps total    650000
Number of rollouts total     0
Train Time (s)               141.87324781576172
(Previous) Eval Time (s)     17.40392248891294
Sample Time (s)              5.383260604459792
Epoch Time (s)               164.66043090913445
Total Train Time (s)         9066.660925125703
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:24:45.188692 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #53 | Epoch Duration: 164.7424509525299
2020-01-12 10:24:45.188985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8752245
Z variance train             0.019695168
KL Divergence                32.45962
KL Loss                      3.2459621
QF Loss                      526.9427
VF Loss                      115.280945
Policy Loss                  -811.3098
Q Predictions Mean           811.2045
Q Predictions Std            791.34064
Q Predictions Max            2404.5454
Q Predictions Min            -61.525093
V Predictions Mean           804.0415
V Predictions Std            792.68384
V Predictions Max            2385.5576
V Predictions Min            -67.08904
Log Pis Mean                 -1.5077579
Log Pis Std                  3.3026364
Log Pis Max                  13.840845
Log Pis Min                  -7.509549
Policy mu Mean               -0.024167174
Policy mu Std                0.7159687
Policy mu Max                2.6582415
Policy mu Min                -2.9119568
Policy log std Mean          -0.4569099
Policy log std Std           0.249724
Policy log std Max           -0.0557594
Policy log std Min           -1.894979
Z mean eval                  1.8687963
Z variance eval              0.017156215
total_rewards                [6094.39871867 5967.25560032 6261.16660472 6233.36304866 6028.57398998
 6022.62935986 6103.81386295 6172.3787617  6170.77288427 5944.30641934]
total_rewards_mean           6099.865925047094
total_rewards_std            103.44228401755637
total_rewards_max            6261.166604715957
total_rewards_min            5944.306419342358
Number of train steps total  220000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               142.35266576800495
(Previous) Eval Time (s)     17.484444808214903
Sample Time (s)              5.55425452394411
Epoch Time (s)               165.39136510016397
Total Train Time (s)         9232.132719982881
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:27:30.659787 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #54 | Epoch Duration: 165.47057723999023
2020-01-12 10:27:30.659960 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8665617
Z variance train             0.017196361
KL Divergence                32.11814
KL Loss                      3.2118142
QF Loss                      869.615
VF Loss                      83.93859
Policy Loss                  -813.8923
Q Predictions Mean           803.3523
Q Predictions Std            800.8981
Q Predictions Max            2377.5645
Q Predictions Min            -71.04194
V Predictions Mean           811.28357
V Predictions Std            798.81366
V Predictions Max            2362.3835
V Predictions Min            -65.080826
Log Pis Mean                 -1.5664377
Log Pis Std                  3.0562074
Log Pis Max                  9.094181
Log Pis Min                  -6.759577
Policy mu Mean               0.015075472
Policy mu Std                0.71984273
Policy mu Max                2.4889178
Policy mu Min                -3.2864187
Policy log std Mean          -0.4525486
Policy log std Std           0.23027934
Policy log std Max           0.08763325
Policy log std Min           -2.2802095
Z mean eval                  1.9073509
Z variance eval              0.021411065
total_rewards                [5741.54867847 5813.77340642 5757.02317438 5874.51514773 6029.57331223
 5817.32682192 5908.44064017 5899.13547085 5813.33301009 5800.32795427]
total_rewards_mean           5845.499761652221
total_rewards_std            80.66765806150396
total_rewards_max            6029.573312234016
total_rewards_min            5741.5486784674285
Number of train steps total  224000
Number of env steps total    674000
Number of rollouts total     0
Train Time (s)               142.24116083234549
(Previous) Eval Time (s)     17.85305330483243
Sample Time (s)              5.736719515640289
Epoch Time (s)               165.8309336528182
Total Train Time (s)         9398.095145242289
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:30:16.627333 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #55 | Epoch Duration: 165.96720552444458
2020-01-12 10:30:16.627640 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9079523
Z variance train             0.021327242
KL Divergence                32.34118
KL Loss                      3.234118
QF Loss                      297.69354
VF Loss                      109.85297
Policy Loss                  -807.7722
Q Predictions Mean           798.99347
Q Predictions Std            800.4997
Q Predictions Max            2510.236
Q Predictions Min            -66.91797
V Predictions Mean           806.35175
V Predictions Std            800.03674
V Predictions Max            2516.539
V Predictions Min            -79.96045
Log Pis Mean                 -1.3187336
Log Pis Std                  3.8927338
Log Pis Max                  22.023584
Log Pis Min                  -7.100261
Policy mu Mean               -0.07080189
Policy mu Std                0.75371224
Policy mu Max                3.4942703
Policy mu Min                -3.4144812
Policy log std Mean          -0.44200215
Policy log std Std           0.22220433
Policy log std Max           -0.018855155
Policy log std Min           -2.0377605
Z mean eval                  1.9003198
Z variance eval              0.016185593
total_rewards                [5750.16359294 5929.24298895 6083.53535391 6139.56655124 5960.96412124
 6082.23952813 5974.01794056 6103.08198822 6121.9520657  6022.24441339]
total_rewards_mean           6016.700854428677
total_rewards_std            112.27101178876529
total_rewards_max            6139.566551243188
total_rewards_min            5750.16359293663
Number of train steps total  228000
Number of env steps total    686000
Number of rollouts total     0
Train Time (s)               143.50717155635357
(Previous) Eval Time (s)     18.054022955708206
Sample Time (s)              6.491305843926966
Epoch Time (s)               168.05250035598874
Total Train Time (s)         9566.24206357263
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:33:04.774475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #56 | Epoch Duration: 168.14661693572998
2020-01-12 10:33:04.774687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.899774
Z variance train             0.0162099
KL Divergence                34.23713
KL Loss                      3.423713
QF Loss                      760.7185
VF Loss                      149.54698
Policy Loss                  -861.9661
Q Predictions Mean           856.6144
Q Predictions Std            815.158
Q Predictions Max            2397.2427
Q Predictions Min            -80.41623
V Predictions Mean           870.09296
V Predictions Std            822.50336
V Predictions Max            2416.4675
V Predictions Min            -74.714424
Log Pis Mean                 -1.0770266
Log Pis Std                  3.4037735
Log Pis Max                  10.692542
Log Pis Min                  -7.0710588
Policy mu Mean               -0.023240903
Policy mu Std                0.77144516
Policy mu Max                2.6875458
Policy mu Min                -2.5628715
Policy log std Mean          -0.47222805
Policy log std Std           0.23849125
Policy log std Max           0.012934864
Policy log std Min           -2.3637486
Z mean eval                  1.8927075
Z variance eval              0.019894749
total_rewards                [6191.0840435  6433.2354981  6277.76043254 6195.72947268 6201.78595471
 6217.14165692 5986.72057399 6357.57680424 5997.79880047 6169.75077874]
total_rewards_mean           6202.858401589968
total_rewards_std            131.482865362053
total_rewards_max            6433.235498098495
total_rewards_min            5986.720573989353
Number of train steps total  232000
Number of env steps total    698000
Number of rollouts total     0
Train Time (s)               143.93344952864572
(Previous) Eval Time (s)     17.77554969023913
Sample Time (s)              6.518613598309457
Epoch Time (s)               168.2276128171943
Total Train Time (s)         9734.555853433907
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:35:53.088547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #57 | Epoch Duration: 168.31372570991516
2020-01-12 10:35:53.088678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8901827
Z variance train             0.019898092
KL Divergence                32.486
KL Loss                      3.2486
QF Loss                      201.25052
VF Loss                      170.5032
Policy Loss                  -729.086
Q Predictions Mean           722.7387
Q Predictions Std            750.1167
Q Predictions Max            2387.3716
Q Predictions Min            -77.74265
V Predictions Mean           729.80115
V Predictions Std            753.97125
V Predictions Max            2400.3093
V Predictions Min            -66.036446
Log Pis Mean                 -1.4717016
Log Pis Std                  3.694242
Log Pis Max                  19.116325
Log Pis Min                  -9.39739
Policy mu Mean               -0.07228136
Policy mu Std                0.73850834
Policy mu Max                2.7865067
Policy mu Min                -4.252967
Policy log std Mean          -0.44299603
Policy log std Std           0.227759
Policy log std Max           -0.08598387
Policy log std Min           -2.3459992
Z mean eval                  1.9252005
Z variance eval              0.017758148
total_rewards                [6232.47442118 6549.95927191 6500.69857661 6588.60745011 6357.09258942
 6555.11790968 6294.38454278 6280.46786495 6426.14816771 6524.62318688]
total_rewards_mean           6430.957398123196
total_rewards_std            124.19412411897807
total_rewards_max            6588.607450106943
total_rewards_min            6232.474421177899
Number of train steps total  236000
Number of env steps total    710000
Number of rollouts total     0
Train Time (s)               143.56845584418625
(Previous) Eval Time (s)     17.46554338792339
Sample Time (s)              6.655137183144689
Epoch Time (s)               167.68913641525432
Total Train Time (s)         9902.323139491957
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:38:40.857938 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #58 | Epoch Duration: 167.76915979385376
2020-01-12 10:38:40.858095 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9256147
Z variance train             0.017781407
KL Divergence                33.81601
KL Loss                      3.381601
QF Loss                      525.77045
VF Loss                      149.92085
Policy Loss                  -814.11053
Q Predictions Mean           808.9618
Q Predictions Std            809.64166
Q Predictions Max            2519.901
Q Predictions Min            -87.74165
V Predictions Mean           820.72473
V Predictions Std            811.73755
V Predictions Max            2493.5474
V Predictions Min            -75.8555
Log Pis Mean                 -1.1665244
Log Pis Std                  3.6893735
Log Pis Max                  16.430046
Log Pis Min                  -6.7211456
Policy mu Mean               -0.019803995
Policy mu Std                0.79165024
Policy mu Max                2.987426
Policy mu Min                -3.812008
Policy log std Mean          -0.44716606
Policy log std Std           0.22465664
Policy log std Max           -0.1455696
Policy log std Min           -2.0556123
Z mean eval                  1.8994443
Z variance eval              0.018577283
total_rewards                [6179.69659985 5839.93603208 6391.65903948 5682.45034428 5821.75260873
 1956.58622205 2033.34338564 5768.90171347 6056.36358283 4626.18300337]
total_rewards_mean           5035.68725317783
total_rewards_std            1583.4280347477397
total_rewards_max            6391.659039478091
total_rewards_min            1956.5862220484519
Number of train steps total  240000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               145.5277861300856
(Previous) Eval Time (s)     20.940628021024168
Sample Time (s)              5.603038269560784
Epoch Time (s)               172.07145242067054
Total Train Time (s)         10074.489447663072
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:41:33.028203 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #59 | Epoch Duration: 172.16996479034424
2020-01-12 10:41:33.028406 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8970039
Z variance train             0.018603487
KL Divergence                33.86045
KL Loss                      3.3860452
QF Loss                      277.7254
VF Loss                      156.77536
Policy Loss                  -762.06647
Q Predictions Mean           757.0532
Q Predictions Std            789.22504
Q Predictions Max            2477.9065
Q Predictions Min            -87.934555
V Predictions Mean           764.00836
V Predictions Std            793.2942
V Predictions Max            2478.8623
V Predictions Min            -81.49993
Log Pis Mean                 -1.3691115
Log Pis Std                  3.4341438
Log Pis Max                  15.413858
Log Pis Min                  -6.8653936
Policy mu Mean               0.022725277
Policy mu Std                0.7350813
Policy mu Max                2.6911309
Policy mu Min                -2.8846364
Policy log std Mean          -0.45042458
Policy log std Std           0.25385845
Policy log std Max           -0.12046051
Policy log std Min           -2.128117
Z mean eval                  1.9029392
Z variance eval              0.017013725
total_rewards                [6235.91544582 6504.20496221 6375.14782225 6369.74126573 6166.15508737
 6293.38570539 6328.76199036 6102.2269525  6278.81708252 6292.63418005]
total_rewards_mean           6294.699049421808
total_rewards_std            106.97623403139809
total_rewards_max            6504.204962212936
total_rewards_min            6102.226952496244
Number of train steps total  244000
Number of env steps total    734000
Number of rollouts total     0
Train Time (s)               143.45485528977588
(Previous) Eval Time (s)     20.97137754689902
Sample Time (s)              6.665078236721456
Epoch Time (s)               171.09131107339635
Total Train Time (s)         10245.667335619219
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:44:24.205399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #60 | Epoch Duration: 171.1768479347229
2020-01-12 10:44:24.205541 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9049244
Z variance train             0.01703859
KL Divergence                34.448112
KL Loss                      3.4448113
QF Loss                      219.80353
VF Loss                      65.774864
Policy Loss                  -732.9619
Q Predictions Mean           726.8058
Q Predictions Std            778.2118
Q Predictions Max            2483.9985
Q Predictions Min            -86.07766
V Predictions Mean           737.10645
V Predictions Std            781.17474
V Predictions Max            2484.1135
V Predictions Min            -75.22249
Log Pis Mean                 -1.8051128
Log Pis Std                  3.3693051
Log Pis Max                  11.850742
Log Pis Min                  -7.1885705
Policy mu Mean               -0.08657376
Policy mu Std                0.6796428
Policy mu Max                2.5687294
Policy mu Min                -2.6017447
Policy log std Mean          -0.4360343
Policy log std Std           0.22039998
Policy log std Max           -0.1517443
Policy log std Min           -1.8560152
Z mean eval                  1.8915558
Z variance eval              0.00734269
total_rewards                [6068.06574159 6378.23425657 6509.98468874 6065.62202989 6396.45389856
 6312.56601133 6358.0875473  6079.8965333  6382.86058413 6461.07551483]
total_rewards_mean           6301.2846806235775
total_rewards_std            159.0648778764951
total_rewards_max            6509.984688743908
total_rewards_min            6065.622029885062
Number of train steps total  248000
Number of env steps total    746000
Number of rollouts total     0
Train Time (s)               142.75785920303315
(Previous) Eval Time (s)     18.127722821664065
Sample Time (s)              6.582495357375592
Epoch Time (s)               167.4680773820728
Total Train Time (s)         10413.215161677916
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:47:11.758573 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #61 | Epoch Duration: 167.55288290977478
2020-01-12 10:47:11.758931 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8889208
Z variance train             0.0073339297
KL Divergence                35.53086
KL Loss                      3.553086
QF Loss                      297.96295
VF Loss                      41.249165
Policy Loss                  -705.5631
Q Predictions Mean           701.0416
Q Predictions Std            779.5128
Q Predictions Max            2433.4177
Q Predictions Min            -101.09969
V Predictions Mean           707.49475
V Predictions Std            783.0013
V Predictions Max            2422.8987
V Predictions Min            -79.826675
Log Pis Mean                 -1.7390406
Log Pis Std                  3.130801
Log Pis Max                  9.510326
Log Pis Min                  -6.8319407
Policy mu Mean               -0.051184982
Policy mu Std                0.6825109
Policy mu Max                2.7602153
Policy mu Min                -2.834474
Policy log std Mean          -0.42968836
Policy log std Std           0.23661794
Policy log std Max           -0.10862002
Policy log std Min           -2.1391056
Z mean eval                  1.9061356
Z variance eval              0.010682837
total_rewards                [6578.70640839 6296.01658627 6647.87899137 6412.69145483 6621.60786681
 6539.4973007  6904.93949966 6519.23629678 6655.26221568 6670.42525279]
total_rewards_mean           6584.626187329445
total_rewards_std            154.76584250645024
total_rewards_max            6904.9394996624
total_rewards_min            6296.016586272183
Number of train steps total  252000
Number of env steps total    758000
Number of rollouts total     0
Train Time (s)               144.06320699770004
(Previous) Eval Time (s)     21.253501236904413
Sample Time (s)              6.580273406114429
Epoch Time (s)               171.89698164071888
Total Train Time (s)         10585.197605942376
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:50:03.739242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #62 | Epoch Duration: 171.9801001548767
2020-01-12 10:50:03.739375 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9030536
Z variance train             0.010661701
KL Divergence                34.51133
KL Loss                      3.451133
QF Loss                      533.4357
VF Loss                      224.12732
Policy Loss                  -799.53485
Q Predictions Mean           795.2047
Q Predictions Std            836.0689
Q Predictions Max            2506.205
Q Predictions Min            -91.86117
V Predictions Mean           804.6668
V Predictions Std            837.33856
V Predictions Max            2508.2083
V Predictions Min            -87.94418
Log Pis Mean                 -1.0170063
Log Pis Std                  3.7692072
Log Pis Max                  15.681114
Log Pis Min                  -6.8727045
Policy mu Mean               -0.02965185
Policy mu Std                0.79105115
Policy mu Max                2.8841016
Policy mu Min                -3.410555
Policy log std Mean          -0.46799955
Policy log std Std           0.25324714
Policy log std Max           -0.16248855
Policy log std Min           -2.387453
Z mean eval                  1.8945932
Z variance eval              0.034098804
total_rewards                [6133.88904043 6035.04528481 5973.69116365 6196.54693396 6231.14843161
 6126.38545327 6229.95174404 6051.97928623 6301.1612887  6305.07116501]
total_rewards_mean           6158.486979171353
total_rewards_std            107.72425081504889
total_rewards_max            6305.071165012144
total_rewards_min            5973.691163654465
Number of train steps total  256000
Number of env steps total    770000
Number of rollouts total     0
Train Time (s)               143.02481592819095
(Previous) Eval Time (s)     21.04295474709943
Sample Time (s)              6.429969357326627
Epoch Time (s)               170.497740032617
Total Train Time (s)         10755.776366087608
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:52:54.318784 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #63 | Epoch Duration: 170.5793161392212
2020-01-12 10:52:54.318916 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8936714
Z variance train             0.03406387
KL Divergence                33.081333
KL Loss                      3.3081334
QF Loss                      395.1482
VF Loss                      165.02176
Policy Loss                  -799.7164
Q Predictions Mean           795.4488
Q Predictions Std            812.8137
Q Predictions Max            2613.428
Q Predictions Min            -78.51393
V Predictions Mean           806.78406
V Predictions Std            818.95404
V Predictions Max            2627.4404
V Predictions Min            -75.4325
Log Pis Mean                 -1.3049312
Log Pis Std                  3.3859644
Log Pis Max                  13.0040455
Log Pis Min                  -8.009828
Policy mu Mean               -0.088264674
Policy mu Std                0.7270105
Policy mu Max                2.7207222
Policy mu Min                -2.8013778
Policy log std Mean          -0.47342777
Policy log std Std           0.23787615
Policy log std Max           0.15596122
Policy log std Min           -2.1306317
Z mean eval                  1.8937544
Z variance eval              0.032910757
total_rewards                [6250.30204844 6413.6037487  6319.19397326 6223.21864185 6300.58138456
 5993.63460393 3371.53694921 6087.01571336 6279.91245524 6478.31883729]
total_rewards_mean           5971.73183558147
total_rewards_std            877.0039317627335
total_rewards_max            6478.318837287303
total_rewards_min            3371.536949209729
Number of train steps total  260000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               143.5806488879025
(Previous) Eval Time (s)     17.724546923767775
Sample Time (s)              6.459860369563103
Epoch Time (s)               167.76505618123338
Total Train Time (s)         10923.619017035235
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:55:42.162398 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #64 | Epoch Duration: 167.84338545799255
2020-01-12 10:55:42.162525 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8933146
Z variance train             0.03284865
KL Divergence                32.189735
KL Loss                      3.2189736
QF Loss                      363.97015
VF Loss                      155.22108
Policy Loss                  -696.5318
Q Predictions Mean           687.1306
Q Predictions Std            756.49896
Q Predictions Max            2562.2593
Q Predictions Min            -81.04364
V Predictions Mean           690.20874
V Predictions Std            759.4493
V Predictions Max            2555.3967
V Predictions Min            -85.60551
Log Pis Mean                 -1.6933634
Log Pis Std                  3.1749356
Log Pis Max                  12.735222
Log Pis Min                  -7.0048766
Policy mu Mean               -0.0028704193
Policy mu Std                0.7041377
Policy mu Max                3.1718159
Policy mu Min                -2.75017
Policy log std Mean          -0.4356241
Policy log std Std           0.21560813
Policy log std Max           -0.12779066
Policy log std Min           -1.9995737
Z mean eval                  1.9643263
Z variance eval              0.022422707
total_rewards                [5977.75288021 5776.0160587  6091.82940861 6288.05318071 5442.73526187
 6015.5980252  5741.71791203 6371.27116296 6278.92847887 6200.92333972]
total_rewards_mean           6018.482570889642
total_rewards_std            277.87865088368335
total_rewards_max            6371.271162955752
total_rewards_min            5442.735261869922
Number of train steps total  264000
Number of env steps total    794000
Number of rollouts total     0
Train Time (s)               141.49094415688887
(Previous) Eval Time (s)     17.660015925299376
Sample Time (s)              5.789603969082236
Epoch Time (s)               164.94056405127048
Total Train Time (s)         11088.639404475689
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:58:27.184284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #65 | Epoch Duration: 165.02164816856384
2020-01-12 10:58:27.184468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9642954
Z variance train             0.022471158
KL Divergence                34.296085
KL Loss                      3.4296086
QF Loss                      291.7028
VF Loss                      103.977196
Policy Loss                  -949.0619
Q Predictions Mean           940.9956
Q Predictions Std            887.71405
Q Predictions Max            2549.328
Q Predictions Min            -162.05264
V Predictions Mean           947.9253
V Predictions Std            887.99915
V Predictions Max            2527.7844
V Predictions Min            -93.95788
Log Pis Mean                 -0.87396747
Log Pis Std                  3.7186964
Log Pis Max                  16.326746
Log Pis Min                  -6.937147
Policy mu Mean               -0.0649516
Policy mu Std                0.822369
Policy mu Max                2.8577566
Policy mu Min                -3.2507486
Policy log std Mean          -0.46331108
Policy log std Std           0.25006807
Policy log std Max           -0.10547432
Policy log std Min           -2.1765544
Z mean eval                  1.9880623
Z variance eval              0.03057602
total_rewards                [6345.18806998 6759.26481283 6485.74336491 6195.50284021 6494.32211165
 6308.88445132 6364.44003704 6525.45511405 5964.05923242 6543.01058363]
total_rewards_mean           6398.587061803629
total_rewards_std            206.37954910614604
total_rewards_max            6759.2648128317505
total_rewards_min            5964.059232415425
Number of train steps total  268000
Number of env steps total    806000
Number of rollouts total     0
Train Time (s)               146.52034418284893
(Previous) Eval Time (s)     21.061013142578304
Sample Time (s)              6.558749390300363
Epoch Time (s)               174.1401067157276
Total Train Time (s)         11262.86058436893
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:01:21.408485 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #66 | Epoch Duration: 174.22382760047913
2020-01-12 11:01:21.408766 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9883578
Z variance train             0.03069983
KL Divergence                33.835472
KL Loss                      3.3835473
QF Loss                      196.62027
VF Loss                      93.62791
Policy Loss                  -756.3074
Q Predictions Mean           747.1897
Q Predictions Std            816.43384
Q Predictions Max            2587.6973
Q Predictions Min            -98.25599
V Predictions Mean           755.411
V Predictions Std            815.61005
V Predictions Max            2590.9146
V Predictions Min            -88.82018
Log Pis Mean                 -1.4048967
Log Pis Std                  3.482192
Log Pis Max                  14.167569
Log Pis Min                  -7.397729
Policy mu Mean               -0.068553604
Policy mu Std                0.76549387
Policy mu Max                2.773866
Policy mu Min                -2.9150543
Policy log std Mean          -0.45389572
Policy log std Std           0.20155948
Policy log std Max           -0.13707104
Policy log std Min           -1.894566
Z mean eval                  1.9476534
Z variance eval              0.014498072
total_rewards                [6386.06218552 6610.66714922 6554.25947498 6635.7848597  6277.62167439
 6534.4071712  6745.62575103 6625.77416542 6389.38013214 6480.643831  ]
total_rewards_mean           6524.022639459499
total_rewards_std            134.25286961555585
total_rewards_max            6745.625751030121
total_rewards_min            6277.621674385322
Number of train steps total  272000
Number of env steps total    818000
Number of rollouts total     0
Train Time (s)               141.35383306629956
(Previous) Eval Time (s)     17.545340763404965
Sample Time (s)              6.4322752663865685
Epoch Time (s)               165.3314490960911
Total Train Time (s)         11428.276671955828
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:04:06.825150 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #67 | Epoch Duration: 165.4162266254425
2020-01-12 11:04:06.825327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9495026
Z variance train             0.014513129
KL Divergence                33.638863
KL Loss                      3.3638864
QF Loss                      915.3757
VF Loss                      351.93448
Policy Loss                  -750.275
Q Predictions Mean           737.7329
Q Predictions Std            795.73987
Q Predictions Max            2546.1663
Q Predictions Min            -100.23332
V Predictions Mean           738.83435
V Predictions Std            796.2956
V Predictions Max            2540.413
V Predictions Min            -102.630936
Log Pis Mean                 -1.3221571
Log Pis Std                  3.4468234
Log Pis Max                  11.411898
Log Pis Min                  -6.660722
Policy mu Mean               0.0040029823
Policy mu Std                0.7463625
Policy mu Max                3.341102
Policy mu Min                -2.817051
Policy log std Mean          -0.46910104
Policy log std Std           0.22893475
Policy log std Max           -0.1513705
Policy log std Min           -2.0974493
Z mean eval                  1.9117606
Z variance eval              0.012644713
total_rewards                [6577.4481622  6872.44356186 6715.38265195 6774.1481082  6799.72618195
 6848.07878567 6576.24289906 6665.28158713 6660.97311759 6582.46248213]
total_rewards_mean           6707.218753773841
total_rewards_std            106.6307605052656
total_rewards_max            6872.443561857926
total_rewards_min            6576.242899055701
Number of train steps total  276000
Number of env steps total    830000
Number of rollouts total     0
Train Time (s)               141.31493050884455
(Previous) Eval Time (s)     20.594629519153386
Sample Time (s)              6.557933504227549
Epoch Time (s)               168.4674935322255
Total Train Time (s)         11596.825481682085
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:06:55.375746 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #68 | Epoch Duration: 168.5502486228943
2020-01-12 11:06:55.375969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9090292
Z variance train             0.01264553
KL Divergence                35.250046
KL Loss                      3.5250046
QF Loss                      323.01556
VF Loss                      178.41084
Policy Loss                  -806.95886
Q Predictions Mean           796.4945
Q Predictions Std            864.6997
Q Predictions Max            2598.8525
Q Predictions Min            -95.19227
V Predictions Mean           804.0812
V Predictions Std            868.6486
V Predictions Max            2600.4648
V Predictions Min            -92.77417
Log Pis Mean                 -1.2888842
Log Pis Std                  3.4355826
Log Pis Max                  9.4405
Log Pis Min                  -6.152956
Policy mu Mean               -0.041863292
Policy mu Std                0.75384337
Policy mu Max                2.6645062
Policy mu Min                -2.2961516
Policy log std Mean          -0.46271133
Policy log std Std           0.24614014
Policy log std Max           -0.15886796
Policy log std Min           -2.4293547
Z mean eval                  1.9282405
Z variance eval              0.016464395
total_rewards                [6637.55033879 6557.91798604 6797.8512828  6759.63766126 6682.06115259
 6810.53797496 6825.22869639 6733.06789363 6855.21062553 6619.97016631]
total_rewards_mean           6727.903377831164
total_rewards_std            94.46907897236079
total_rewards_max            6855.210625531985
total_rewards_min            6557.917986040426
Number of train steps total  280000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               142.8911835681647
(Previous) Eval Time (s)     21.060634987894446
Sample Time (s)              6.363416476175189
Epoch Time (s)               170.31523503223434
Total Train Time (s)         11767.224443089683
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:09:45.779470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #69 | Epoch Duration: 170.40337681770325
2020-01-12 11:09:45.779657 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9284779
Z variance train             0.016544286
KL Divergence                34.971523
KL Loss                      3.4971523
QF Loss                      218.70663
VF Loss                      90.274635
Policy Loss                  -730.20276
Q Predictions Mean           726.4252
Q Predictions Std            806.6503
Q Predictions Max            2633.4746
Q Predictions Min            -83.993904
V Predictions Mean           730.13525
V Predictions Std            810.7442
V Predictions Max            2631.3086
V Predictions Min            -90.43525
Log Pis Mean                 -1.1041367
Log Pis Std                  3.530715
Log Pis Max                  14.623306
Log Pis Min                  -5.6242113
Policy mu Mean               -0.027423477
Policy mu Std                0.77139163
Policy mu Max                3.3018475
Policy mu Min                -2.967915
Policy log std Mean          -0.44741473
Policy log std Std           0.22381204
Policy log std Max           -0.13951744
Policy log std Min           -1.9407089
Z mean eval                  1.9045881
Z variance eval              0.019563163
total_rewards                [6397.73721039 6334.65972206 6134.12455137 6244.53219982 6278.45179098
 6199.39234122 6240.07816942 6302.73183282 6057.80944138 5896.92813372]
total_rewards_mean           6208.64453931663
total_rewards_std            138.99442760472132
total_rewards_max            6397.737210388255
total_rewards_min            5896.928133724845
Number of train steps total  284000
Number of env steps total    854000
Number of rollouts total     0
Train Time (s)               145.16799584403634
(Previous) Eval Time (s)     17.54698609886691
Sample Time (s)              6.362792334519327
Epoch Time (s)               169.07777427742258
Total Train Time (s)         11936.384378995746
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:12:34.939036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #70 | Epoch Duration: 169.15923142433167
2020-01-12 11:12:34.939217 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #70 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9064925
Z variance train             0.019710252
KL Divergence                36.088448
KL Loss                      3.6088448
QF Loss                      657.52423
VF Loss                      247.75795
Policy Loss                  -954.9075
Q Predictions Mean           955.50476
Q Predictions Std            908.3305
Q Predictions Max            2633.0076
Q Predictions Min            -66.7108
V Predictions Mean           957.13446
V Predictions Std            911.1033
V Predictions Max            2625.5413
V Predictions Min            -92.77434
Log Pis Mean                 -0.80169666
Log Pis Std                  3.5094044
Log Pis Max                  9.956644
Log Pis Min                  -7.1128864
Policy mu Mean               -0.014122388
Policy mu Std                0.8351764
Policy mu Max                3.4713573
Policy mu Min                -2.980465
Policy log std Mean          -0.4906595
Policy log std Std           0.25094312
Policy log std Max           -0.10289964
Policy log std Min           -2.2119858
Z mean eval                  1.9259548
Z variance eval              0.023544218
total_rewards                [6207.18402351 6046.19454926 2299.39055116 6406.15013856 6298.8571819
 6767.19379656 6414.78696016 6645.77171238 6619.99180679 6463.21173607]
total_rewards_mean           6016.873245635494
total_rewards_std            1255.6913050618623
total_rewards_max            6767.193796562019
total_rewards_min            2299.3905511628113
Number of train steps total  288000
Number of env steps total    866000
Number of rollouts total     0
Train Time (s)               143.9915888281539
(Previous) Eval Time (s)     17.24979145405814
Sample Time (s)              6.408704467117786
Epoch Time (s)               167.65008474932984
Total Train Time (s)         12104.1184686739
Epoch                        71
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:15:22.674985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #71 | Epoch Duration: 167.73561334609985
2020-01-12 11:15:22.675226 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9274876
Z variance train             0.023443783
KL Divergence                35.6243
KL Loss                      3.56243
QF Loss                      603.8964
VF Loss                      110.7771
Policy Loss                  -898.12805
Q Predictions Mean           892.98694
Q Predictions Std            919.8184
Q Predictions Max            2740.545
Q Predictions Min            -112.776886
V Predictions Mean           903.4154
V Predictions Std            921.7069
V Predictions Max            2760.115
V Predictions Min            -94.450615
Log Pis Mean                 -0.5956864
Log Pis Std                  4.1839256
Log Pis Max                  15.474714
Log Pis Min                  -7.5330453
Policy mu Mean               -0.03236183
Policy mu Std                0.8391715
Policy mu Max                2.7498064
Policy mu Min                -3.6301155
Policy log std Mean          -0.4763801
Policy log std Std           0.24895069
Policy log std Max           0.17862576
Policy log std Min           -2.1130807
Z mean eval                  1.9065393
Z variance eval              0.020648029
total_rewards                [6800.66967287 6848.85127319 6688.03357635 6573.05473772 6421.46356637
 6926.23334063 6416.06024829 6636.83877914 6641.98357476 4944.70215119]
total_rewards_mean           6489.7890920508
total_rewards_std            538.9317912869752
total_rewards_max            6926.233340626881
total_rewards_min            4944.7021511893945
Number of train steps total  292000
Number of env steps total    878000
Number of rollouts total     0
Train Time (s)               142.37295288126916
(Previous) Eval Time (s)     20.63531113183126
Sample Time (s)              6.558693532366306
Epoch Time (s)               169.56695754546672
Total Train Time (s)         12273.768998747226
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:18:12.325227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #72 | Epoch Duration: 169.64983892440796
2020-01-12 11:18:12.325360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9069259
Z variance train             0.020696966
KL Divergence                35.30067
KL Loss                      3.5300672
QF Loss                      423.5443
VF Loss                      120.397644
Policy Loss                  -841.9248
Q Predictions Mean           837.20935
Q Predictions Std            875.8545
Q Predictions Max            2695.063
Q Predictions Min            -105.14013
V Predictions Mean           844.2478
V Predictions Std            881.29944
V Predictions Max            2689.672
V Predictions Min            -96.09946
Log Pis Mean                 -0.8446692
Log Pis Std                  3.6057746
Log Pis Max                  19.177437
Log Pis Min                  -6.6063986
Policy mu Mean               -0.08572644
Policy mu Std                0.79924846
Policy mu Max                3.4459207
Policy mu Min                -3.275269
Policy log std Mean          -0.48352802
Policy log std Std           0.24562743
Policy log std Max           -0.039794087
Policy log std Min           -2.0993092
Z mean eval                  1.9232066
Z variance eval              0.012680945
total_rewards                [6334.56660625 3353.65876259 6607.6835525  6594.60376544 6432.99780352
 6519.50576337 6524.39270468 6190.33679291 6663.14673595 6617.26892699]
total_rewards_mean           6183.816141421094
total_rewards_std            953.38237970731
total_rewards_max            6663.146735953936
total_rewards_min            3353.6587625865504
Number of train steps total  296000
Number of env steps total    890000
Number of rollouts total     0
Train Time (s)               142.93206780217588
(Previous) Eval Time (s)     20.723051264882088
Sample Time (s)              6.42490890994668
Epoch Time (s)               170.08002797700465
Total Train Time (s)         12443.935315628536
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:21:02.493345 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #73 | Epoch Duration: 170.16788530349731
2020-01-12 11:21:02.493482 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9219732
Z variance train             0.012649233
KL Divergence                36.754177
KL Loss                      3.6754177
QF Loss                      708.5473
VF Loss                      63.8428
Policy Loss                  -723.7065
Q Predictions Mean           716.6256
Q Predictions Std            813.18713
Q Predictions Max            2688.1958
Q Predictions Min            -118.86739
V Predictions Mean           718.99316
V Predictions Std            814.5323
V Predictions Max            2677.8003
V Predictions Min            -101.12744
Log Pis Mean                 -1.5221188
Log Pis Std                  3.2166948
Log Pis Max                  12.404056
Log Pis Min                  -6.1852627
Policy mu Mean               -0.0399356
Policy mu Std                0.7341676
Policy mu Max                3.1507752
Policy mu Min                -2.9435282
Policy log std Mean          -0.4478356
Policy log std Std           0.22285402
Policy log std Max           -0.15916756
Policy log std Min           -1.9836318
Z mean eval                  1.9176843
Z variance eval              0.039364442
total_rewards                [6365.15914054 6283.68921146 6131.74834958 6167.57811909 6552.78626449
 4372.49032422 6179.08144071 6602.51370961 6229.73777935 6191.17612243]
total_rewards_mean           6107.596046147545
total_rewards_std            598.5209117033972
total_rewards_max            6602.5137096075205
total_rewards_min            4372.490324218205
Number of train steps total  300000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               142.32089658873156
(Previous) Eval Time (s)     20.750394348055124
Sample Time (s)              6.607983416412026
Epoch Time (s)               169.6792743531987
Total Train Time (s)         12613.69556729123
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:23:52.254492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #74 | Epoch Duration: 169.7609167098999
2020-01-12 11:23:52.254641 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9142888
Z variance train             0.03954923
KL Divergence                33.758095
KL Loss                      3.3758094
QF Loss                      525.3814
VF Loss                      124.22824
Policy Loss                  -846.33026
Q Predictions Mean           831.631
Q Predictions Std            890.5416
Q Predictions Max            2727.1296
Q Predictions Min            -110.2047
V Predictions Mean           844.54724
V Predictions Std            889.8078
V Predictions Max            2704.8042
V Predictions Min            -97.693756
Log Pis Mean                 -0.8895787
Log Pis Std                  3.9307344
Log Pis Max                  17.172672
Log Pis Min                  -7.6534495
Policy mu Mean               -0.07315045
Policy mu Std                0.81108475
Policy mu Max                3.0775783
Policy mu Min                -3.1038806
Policy log std Mean          -0.4524858
Policy log std Std           0.2220385
Policy log std Max           -0.1042586
Policy log std Min           -2.0909927
Z mean eval                  1.9221071
Z variance eval              0.038345017
total_rewards                [6718.76190197 6772.4146805  6595.03178839 6515.63545106 6433.09545615
 6908.65216277 6557.4211703  1482.94969339 6317.05774773 6836.73879364]
total_rewards_mean           6113.775884589608
total_rewards_std            1553.4502252585623
total_rewards_max            6908.652162770284
total_rewards_min            1482.949693392347
Number of train steps total  304000
Number of env steps total    914000
Number of rollouts total     0
Train Time (s)               144.6765623362735
(Previous) Eval Time (s)     17.308902602177113
Sample Time (s)              6.515462671872228
Epoch Time (s)               168.50092761032283
Total Train Time (s)         12782.307247437537
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:26:40.868918 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #75 | Epoch Duration: 168.61415767669678
2020-01-12 11:26:40.869126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9220686
Z variance train             0.038225066
KL Divergence                33.276627
KL Loss                      3.3276627
QF Loss                      272.47702
VF Loss                      60.09032
Policy Loss                  -827.81665
Q Predictions Mean           821.15845
Q Predictions Std            844.0492
Q Predictions Max            2713.37
Q Predictions Min            -108.16551
V Predictions Mean           824.96594
V Predictions Std            845.4125
V Predictions Max            2690.336
V Predictions Min            -105.538506
Log Pis Mean                 -1.0661168
Log Pis Std                  3.3346736
Log Pis Max                  14.596866
Log Pis Min                  -6.564146
Policy mu Mean               0.010263724
Policy mu Std                0.7738751
Policy mu Max                2.7074406
Policy mu Min                -2.713632
Policy log std Mean          -0.4687407
Policy log std Std           0.23245813
Policy log std Max           -0.11971766
Policy log std Min           -2.0444312
Z mean eval                  1.935648
Z variance eval              0.021667432
total_rewards                [6476.14719352 6040.96465959 6385.53459449 6364.48569017 6451.07591961
 6335.63707979 6426.42537088 6426.62607753 6648.87476771 6605.10635166]
total_rewards_mean           6416.087770494148
total_rewards_std            156.76510137647313
total_rewards_max            6648.874767705496
total_rewards_min            6040.964659586793
Number of train steps total  308000
Number of env steps total    926000
Number of rollouts total     0
Train Time (s)               144.72288407105953
(Previous) Eval Time (s)     17.92733120592311
Sample Time (s)              6.342245437204838
Epoch Time (s)               168.99246071418747
Total Train Time (s)         12951.37879549805
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:29:29.941449 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #76 | Epoch Duration: 169.07216572761536
2020-01-12 11:29:29.941629 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9358187
Z variance train             0.021697322
KL Divergence                34.20354
KL Loss                      3.4203541
QF Loss                      385.87555
VF Loss                      93.6093
Policy Loss                  -879.66986
Q Predictions Mean           875.2638
Q Predictions Std            876.7594
Q Predictions Max            2710.769
Q Predictions Min            -93.82006
V Predictions Mean           882.414
V Predictions Std            878.2482
V Predictions Max            2700.2827
V Predictions Min            -105.51337
Log Pis Mean                 -1.0181878
Log Pis Std                  3.146918
Log Pis Max                  11.357937
Log Pis Min                  -6.000614
Policy mu Mean               0.034117606
Policy mu Std                0.77924865
Policy mu Max                2.657605
Policy mu Min                -2.4177413
Policy log std Mean          -0.48062968
Policy log std Std           0.2408191
Policy log std Max           -0.14605194
Policy log std Min           -2.060026
Z mean eval                  1.9189469
Z variance eval              0.013638318
total_rewards                [6163.72877212 6748.94202955 6535.39745781 6674.36148954 7025.42414481
 6494.51315068 6686.33099415 6709.07501976 6573.75666319 6665.36881776]
total_rewards_mean           6627.689853937109
total_rewards_std            207.5999821366779
total_rewards_max            7025.424144813877
total_rewards_min            6163.728772123472
Number of train steps total  312000
Number of env steps total    938000
Number of rollouts total     0
Train Time (s)               145.14685849659145
(Previous) Eval Time (s)     20.982759467791766
Sample Time (s)              6.589742365758866
Epoch Time (s)               172.71936033014208
Total Train Time (s)         13124.18441857677
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:32:22.747561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #77 | Epoch Duration: 172.805805683136
2020-01-12 11:32:22.747704 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9182926
Z variance train             0.013601027
KL Divergence                35.48971
KL Loss                      3.5489712
QF Loss                      309.7739
VF Loss                      103.51799
Policy Loss                  -761.9066
Q Predictions Mean           756.9069
Q Predictions Std            833.9687
Q Predictions Max            2720.9792
Q Predictions Min            -133.029
V Predictions Mean           758.75793
V Predictions Std            836.022
V Predictions Max            2699.8457
V Predictions Min            -128.14035
Log Pis Mean                 -1.2505851
Log Pis Std                  3.5732014
Log Pis Max                  18.01568
Log Pis Min                  -7.3036304
Policy mu Mean               -0.1042085
Policy mu Std                0.7657626
Policy mu Max                3.0361211
Policy mu Min                -2.945022
Policy log std Mean          -0.469956
Policy log std Std           0.22982384
Policy log std Max           -0.12308204
Policy log std Min           -2.2557588
Z mean eval                  1.94399
Z variance eval              0.02191857
total_rewards                [6784.77869933 2169.16833214 6730.45021197 7087.71559962 6775.75489183
 7106.07600229 6830.26298104 7039.087185   6825.09404071 6844.08188807]
total_rewards_mean           6419.246983199837
total_rewards_std            1422.5907445071173
total_rewards_max            7106.0760022853065
total_rewards_min            2169.168332136087
Number of train steps total  316000
Number of env steps total    950000
Number of rollouts total     0
Train Time (s)               144.8410155349411
(Previous) Eval Time (s)     18.20105986483395
Sample Time (s)              6.321663931012154
Epoch Time (s)               169.3637393307872
Total Train Time (s)         13293.63054038398
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:35:12.194590 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #78 | Epoch Duration: 169.44678473472595
2020-01-12 11:35:12.194738 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9430186
Z variance train             0.02191483
KL Divergence                33.534515
KL Loss                      3.3534515
QF Loss                      461.33008
VF Loss                      208.18115
Policy Loss                  -856.7875
Q Predictions Mean           848.7438
Q Predictions Std            890.2291
Q Predictions Max            2740.0264
Q Predictions Min            -132.73595
V Predictions Mean           868.24896
V Predictions Std            895.4994
V Predictions Max            2756.0156
V Predictions Min            -114.27151
Log Pis Mean                 -0.70113325
Log Pis Std                  3.6826344
Log Pis Max                  17.538399
Log Pis Min                  -7.46621
Policy mu Mean               -0.06077373
Policy mu Std                0.8319159
Policy mu Max                2.7827902
Policy mu Min                -3.3544865
Policy log std Mean          -0.47775874
Policy log std Std           0.2331503
Policy log std Max           -0.115655124
Policy log std Min           -2.1333344
Z mean eval                  1.9231899
Z variance eval              0.010022086
total_rewards                [6791.39886586 6895.59442615 6992.33227579 6781.41576121 6865.21895202
 6736.86717029 6945.50249449 6948.14761575 6630.03037554 6677.94892249]
total_rewards_mean           6826.44568595781
total_rewards_std            116.06020231325866
total_rewards_max            6992.332275786583
total_rewards_min            6630.030375537773
Number of train steps total  320000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               144.18312916485593
(Previous) Eval Time (s)     17.798429735004902
Sample Time (s)              5.395140776410699
Epoch Time (s)               167.37669967627153
Total Train Time (s)         13461.093271906022
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:37:59.662262 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #79 | Epoch Duration: 167.46737694740295
2020-01-12 11:37:59.662589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9211237
Z variance train             0.010034809
KL Divergence                35.451515
KL Loss                      3.5451515
QF Loss                      355.06934
VF Loss                      103.580345
Policy Loss                  -823.3496
Q Predictions Mean           811.9689
Q Predictions Std            843.40314
Q Predictions Max            2738.7295
Q Predictions Min            -121.927315
V Predictions Mean           822.4929
V Predictions Std            846.4049
V Predictions Max            2719.4226
V Predictions Min            -115.60786
Log Pis Mean                 -0.72505337
Log Pis Std                  3.8031275
Log Pis Max                  15.693098
Log Pis Min                  -5.7879877
Policy mu Mean               -0.0045198104
Policy mu Std                0.81326646
Policy mu Max                3.3265326
Policy mu Min                -3.3173363
Policy log std Mean          -0.46581006
Policy log std Std           0.2464985
Policy log std Max           -0.12999254
Policy log std Min           -2.1364317
Z mean eval                  1.9455141
Z variance eval              0.016692108
total_rewards                [6307.72662146 6177.27861646 6249.6712644  6195.71536975 6281.32905756
 6364.4853967  6228.47253397 6278.24448742 6040.67724012 6287.80328186]
total_rewards_mean           6241.140386969256
total_rewards_std            84.48518737274325
total_rewards_max            6364.485396696794
total_rewards_min            6040.677240124791
Number of train steps total  324000
Number of env steps total    974000
Number of rollouts total     0
Train Time (s)               143.84884004993364
(Previous) Eval Time (s)     20.464759598951787
Sample Time (s)              5.559265097603202
Epoch Time (s)               169.87286474648863
Total Train Time (s)         13631.051168244332
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:40:49.620492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #80 | Epoch Duration: 169.95763111114502
2020-01-12 11:40:49.620641 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9486698
Z variance train             0.016701987
KL Divergence                35.14409
KL Loss                      3.5144088
QF Loss                      253.83353
VF Loss                      190.0325
Policy Loss                  -826.6418
Q Predictions Mean           821.1393
Q Predictions Std            881.15356
Q Predictions Max            2721.5286
Q Predictions Min            -112.53979
V Predictions Mean           835.4753
V Predictions Std            882.69037
V Predictions Max            2732.1707
V Predictions Min            -123.31951
Log Pis Mean                 -1.0902462
Log Pis Std                  3.1302495
Log Pis Max                  10.575375
Log Pis Min                  -6.5758414
Policy mu Mean               0.02634734
Policy mu Std                0.7751295
Policy mu Max                3.1538591
Policy mu Min                -2.6675916
Policy log std Mean          -0.4725118
Policy log std Std           0.25235796
Policy log std Max           -0.12728155
Policy log std Min           -2.5123024
Z mean eval                  1.9192121
Z variance eval              0.017951565
total_rewards                [5807.87975832 6005.52447291 6360.43147995 6058.8051195  5955.13712917
 6075.44937861 6227.58640689 5981.45796038 6030.04323035 5920.05495236]
total_rewards_mean           6042.236988844628
total_rewards_std            148.19191634261696
total_rewards_max            6360.431479951385
total_rewards_min            5807.879758324435
Number of train steps total  328000
Number of env steps total    986000
Number of rollouts total     0
Train Time (s)               143.20830960012972
(Previous) Eval Time (s)     17.657349943183362
Sample Time (s)              6.617194666527212
Epoch Time (s)               167.4828542098403
Total Train Time (s)         13798.617211640812
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:43:37.190442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #81 | Epoch Duration: 167.56968069076538
2020-01-12 11:43:37.190646 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #81 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9189593
Z variance train             0.017912786
KL Divergence                34.725815
KL Loss                      3.4725816
QF Loss                      789.1039
VF Loss                      154.60805
Policy Loss                  -859.4405
Q Predictions Mean           851.6629
Q Predictions Std            890.95404
Q Predictions Max            2760.5967
Q Predictions Min            -115.70336
V Predictions Mean           865.77814
V Predictions Std            894.70355
V Predictions Max            2759.3745
V Predictions Min            -122.12347
Log Pis Mean                 -1.0074866
Log Pis Std                  3.3948438
Log Pis Max                  15.157591
Log Pis Min                  -7.0500264
Policy mu Mean               -0.054775495
Policy mu Std                0.7789646
Policy mu Max                2.6785607
Policy mu Min                -2.8804224
Policy log std Mean          -0.47855428
Policy log std Std           0.24742727
Policy log std Max           -0.1196104
Policy log std Min           -2.212659
Z mean eval                  1.9384058
Z variance eval              0.038305134
total_rewards                [6369.5886239  6051.82400702 6442.45906118 6010.99870121 6552.7907918
 6452.68356824 6190.55762437 6080.75837601 6028.01449084 6314.57071236]
total_rewards_mean           6249.424595692212
total_rewards_std            191.34260430743757
total_rewards_max            6552.790791803798
total_rewards_min            6010.998701206025
Number of train steps total  332000
Number of env steps total    998000
Number of rollouts total     0
Train Time (s)               142.6130550452508
(Previous) Eval Time (s)     17.538343803025782
Sample Time (s)              6.538192308973521
Epoch Time (s)               166.6895911572501
Total Train Time (s)         13965.399914619513
Epoch                        82
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:46:23.974486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #82 | Epoch Duration: 166.78368401527405
2020-01-12 11:46:23.974732 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.94098
Z variance train             0.03820688
KL Divergence                34.407875
KL Loss                      3.4407876
QF Loss                      254.24976
VF Loss                      48.29139
Policy Loss                  -851.0413
Q Predictions Mean           849.07874
Q Predictions Std            883.9519
Q Predictions Max            2773.583
Q Predictions Min            -106.49184
V Predictions Mean           849.94507
V Predictions Std            885.76495
V Predictions Max            2741.6157
V Predictions Min            -113.35897
Log Pis Mean                 -1.1637769
Log Pis Std                  3.4167147
Log Pis Max                  11.815897
Log Pis Min                  -7.1372414
Policy mu Mean               -0.028736515
Policy mu Std                0.8023472
Policy mu Max                2.5835238
Policy mu Min                -2.9365392
Policy log std Mean          -0.46769217
Policy log std Std           0.22383521
Policy log std Max           -0.11682156
Policy log std Min           -1.9243231
Z mean eval                  1.9712365
Z variance eval              0.026418012
total_rewards                [6690.53044493 6924.87712443 7148.06967873 6990.60276218 6894.89039207
 6816.19710798 6909.37127389 6960.7285762  6930.30762169 7296.81095698]
total_rewards_mean           6956.238593906298
total_rewards_std            158.6878377362714
total_rewards_max            7296.810956981488
total_rewards_min            6690.530444929169
Number of train steps total  336000
Number of env steps total    1010000
Number of rollouts total     0
Train Time (s)               143.27031986089423
(Previous) Eval Time (s)     17.746682967990637
Sample Time (s)              5.50136765325442
Epoch Time (s)               166.5183704821393
Total Train Time (s)         14132.090683217626
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:49:10.668094 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #83 | Epoch Duration: 166.69321298599243
2020-01-12 11:49:10.668265 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9672527
Z variance train             0.026458368
KL Divergence                34.10302
KL Loss                      3.410302
QF Loss                      231.01874
VF Loss                      54.513023
Policy Loss                  -812.5151
Q Predictions Mean           804.1588
Q Predictions Std            878.4718
Q Predictions Max            2738.9827
Q Predictions Min            -183.26633
V Predictions Mean           810.53455
V Predictions Std            878.19604
V Predictions Max            2723.628
V Predictions Min            -121.54699
Log Pis Mean                 -1.0447309
Log Pis Std                  3.418666
Log Pis Max                  12.548586
Log Pis Min                  -9.778387
Policy mu Mean               -0.07589989
Policy mu Std                0.7788128
Policy mu Max                3.7346258
Policy mu Min                -2.508574
Policy log std Mean          -0.4776822
Policy log std Std           0.23499379
Policy log std Max           -0.167907
Policy log std Min           -2.0649142
Z mean eval                  1.9605248
Z variance eval              0.04453638
total_rewards                [6904.48494448 7012.20663993 6921.92710338 6723.58486119 7097.62169707
 7184.79453668 7165.20523819 6827.01456413 6954.03183593 6816.4833586 ]
total_rewards_mean           6960.735477959572
total_rewards_std            145.95992093093705
total_rewards_max            7184.794536681355
total_rewards_min            6723.584861194478
Number of train steps total  340000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               145.0343587147072
(Previous) Eval Time (s)     21.011270728893578
Sample Time (s)              6.505604314152151
Epoch Time (s)               172.55123375775293
Total Train Time (s)         14304.726594283711
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:52:03.307271 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #84 | Epoch Duration: 172.63885116577148
2020-01-12 11:52:03.307532 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9616792
Z variance train             0.044243637
KL Divergence                33.639698
KL Loss                      3.3639698
QF Loss                      191.5141
VF Loss                      60.443348
Policy Loss                  -757.8577
Q Predictions Mean           750.0014
Q Predictions Std            819.1134
Q Predictions Max            2790.1428
Q Predictions Min            -156.7662
V Predictions Mean           756.552
V Predictions Std            821.15576
V Predictions Max            2795.5232
V Predictions Min            -127.847786
Log Pis Mean                 -1.1185857
Log Pis Std                  3.2382383
Log Pis Max                  9.454233
Log Pis Min                  -6.640612
Policy mu Mean               0.025142223
Policy mu Std                0.7646546
Policy mu Max                2.7468917
Policy mu Min                -2.8183126
Policy log std Mean          -0.4714192
Policy log std Std           0.23887856
Policy log std Max           -0.15221184
Policy log std Min           -2.2144492
Z mean eval                  1.9564724
Z variance eval              0.018473458
total_rewards                [6942.30077971 7047.7705823  6968.82483952 7071.70882836 6845.41130807
 7207.30030764 6856.18192482 6874.28339265 6773.45083073 7097.83206911]
total_rewards_mean           6968.506486291745
total_rewards_std            128.86500159864124
total_rewards_max            7207.3003076391715
total_rewards_min            6773.450830725401
Number of train steps total  344000
Number of env steps total    1034000
Number of rollouts total     0
Train Time (s)               145.20383495790884
(Previous) Eval Time (s)     17.260036647319794
Sample Time (s)              6.524156869854778
Epoch Time (s)               168.9880284750834
Total Train Time (s)         14473.80162749486
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:54:52.382773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #85 | Epoch Duration: 169.07504963874817
2020-01-12 11:54:52.382953 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9584984
Z variance train             0.018495385
KL Divergence                36.376415
KL Loss                      3.6376417
QF Loss                      771.8637
VF Loss                      121.42945
Policy Loss                  -758.9428
Q Predictions Mean           756.10095
Q Predictions Std            858.3358
Q Predictions Max            2790.0806
Q Predictions Min            -144.69232
V Predictions Mean           762.6328
V Predictions Std            859.2581
V Predictions Max            2779.6323
V Predictions Min            -132.52592
Log Pis Mean                 -0.89952475
Log Pis Std                  3.7501333
Log Pis Max                  16.842625
Log Pis Min                  -6.514022
Policy mu Mean               -0.060050827
Policy mu Std                0.779075
Policy mu Max                2.9006786
Policy mu Min                -3.7528172
Policy log std Mean          -0.47166553
Policy log std Std           0.23840795
Policy log std Max           -0.097542375
Policy log std Min           -2.3785365
Z mean eval                  1.917833
Z variance eval              0.011947613
total_rewards                [6723.38336053 6586.81425605 6683.31349468 6531.07100242 6748.38183354
 6824.20884668 6602.60554472 6762.81375439 6715.88557645 6685.54484295]
total_rewards_mean           6686.40225124014
total_rewards_std            84.8442351185703
total_rewards_max            6824.208846676684
total_rewards_min            6531.071002418416
Number of train steps total  348000
Number of env steps total    1046000
Number of rollouts total     0
Train Time (s)               144.9392209239304
(Previous) Eval Time (s)     20.80948308389634
Sample Time (s)              6.651611663401127
Epoch Time (s)               172.40031567122787
Total Train Time (s)         14646.309030967299
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:57:44.891635 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #86 | Epoch Duration: 172.50854420661926
2020-01-12 11:57:44.891813 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9193504
Z variance train             0.011947852
KL Divergence                37.54443
KL Loss                      3.754443
QF Loss                      302.48422
VF Loss                      124.549034
Policy Loss                  -758.5971
Q Predictions Mean           749.7369
Q Predictions Std            825.39325
Q Predictions Max            2844.6516
Q Predictions Min            -124.3326
V Predictions Mean           750.0429
V Predictions Std            822.6549
V Predictions Max            2825.7947
V Predictions Min            -135.47217
Log Pis Mean                 -1.2843583
Log Pis Std                  3.178608
Log Pis Max                  17.216084
Log Pis Min                  -9.446639
Policy mu Mean               0.036529597
Policy mu Std                0.75122565
Policy mu Max                3.1452076
Policy mu Min                -3.5980954
Policy log std Mean          -0.4869102
Policy log std Std           0.23340489
Policy log std Max           -0.14696631
Policy log std Min           -2.2146678
Z mean eval                  2.0778606
Z variance eval              0.023066204
total_rewards                [6294.18432362 6613.15722032 6650.41019992 6802.23951372 6505.46209215
 6570.41652318 6727.76468885 6616.44631544 6495.52210843 6415.72260294]
total_rewards_mean           6569.132558857034
total_rewards_std            141.02873619608417
total_rewards_max            6802.239513723461
total_rewards_min            6294.184323624649
Number of train steps total  352000
Number of env steps total    1058000
Number of rollouts total     0
Train Time (s)               144.1187355183065
(Previous) Eval Time (s)     20.705354772042483
Sample Time (s)              6.510303697548807
Epoch Time (s)               171.33439398789778
Total Train Time (s)         14817.737419188954
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:00:36.321513 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #87 | Epoch Duration: 171.4295744895935
2020-01-12 12:00:36.321651 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0807996
Z variance train             0.023039198
KL Divergence                35.8896
KL Loss                      3.58896
QF Loss                      208.56233
VF Loss                      139.0743
Policy Loss                  -805.8361
Q Predictions Mean           799.0617
Q Predictions Std            891.35333
Q Predictions Max            2843.275
Q Predictions Min            -144.12999
V Predictions Mean           802.68115
V Predictions Std            890.10406
V Predictions Max            2823.452
V Predictions Min            -143.1641
Log Pis Mean                 -1.184794
Log Pis Std                  3.180121
Log Pis Max                  12.356448
Log Pis Min                  -6.653386
Policy mu Mean               -0.09207025
Policy mu Std                0.7902631
Policy mu Max                3.784519
Policy mu Min                -2.3689399
Policy log std Mean          -0.4646425
Policy log std Std           0.2349661
Policy log std Max           0.15224183
Policy log std Min           -2.1052566
Z mean eval                  1.926891
Z variance eval              0.0233453
total_rewards                [6815.90570081 7289.6496237  7229.51027067 6995.31528024 6939.14556188
 7000.00685251 7141.58500059 7291.11815878 6593.81287209 6688.51545433]
total_rewards_mean           6998.45647756052
total_rewards_std            232.58776071583847
total_rewards_max            7291.118158781056
total_rewards_min            6593.812872091532
Number of train steps total  356000
Number of env steps total    1070000
Number of rollouts total     0
Train Time (s)               143.88833766197786
(Previous) Eval Time (s)     17.587287302594632
Sample Time (s)              6.576064620632678
Epoch Time (s)               168.05168958520517
Total Train Time (s)         14985.870213527232
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:03:24.456768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #88 | Epoch Duration: 168.13499903678894
2020-01-12 12:03:24.456973 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9271028
Z variance train             0.023267645
KL Divergence                35.154015
KL Loss                      3.5154016
QF Loss                      244.61386
VF Loss                      123.666275
Policy Loss                  -853.591
Q Predictions Mean           845.50305
Q Predictions Std            899.7223
Q Predictions Max            2820.118
Q Predictions Min            -136.60895
V Predictions Mean           854.8567
V Predictions Std            898.50446
V Predictions Max            2822.4182
V Predictions Min            -132.92235
Log Pis Mean                 -0.6983094
Log Pis Std                  3.6590133
Log Pis Max                  15.549471
Log Pis Min                  -7.363738
Policy mu Mean               0.044267733
Policy mu Std                0.83111835
Policy mu Max                3.83306
Policy mu Min                -2.9621847
Policy log std Mean          -0.4919586
Policy log std Std           0.24132477
Policy log std Max           -0.16028835
Policy log std Min           -2.203754
Z mean eval                  1.9272244
Z variance eval              0.015736718
total_rewards                [6798.99342897 6993.20036624 7270.62107761 6907.74184678 6765.08952119
 6489.69412808 7149.3802166  6972.35396072 6863.42144868 6931.90696816]
total_rewards_mean           6914.240296301823
total_rewards_std            202.6361452343653
total_rewards_max            7270.6210776110975
total_rewards_min            6489.694128076472
Number of train steps total  360000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               142.0992118776776
(Previous) Eval Time (s)     17.537145932670683
Sample Time (s)              5.57813604734838
Epoch Time (s)               165.21449385769665
Total Train Time (s)         15151.175662376918
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:06:09.767395 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #89 | Epoch Duration: 165.31020736694336
2020-01-12 12:06:09.767674 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9291741
Z variance train             0.015707111
KL Divergence                36.509743
KL Loss                      3.6509743
QF Loss                      1000.92725
VF Loss                      66.60585
Policy Loss                  -792.54034
Q Predictions Mean           788.59143
Q Predictions Std            872.82355
Q Predictions Max            2835.4275
Q Predictions Min            -155.32314
V Predictions Mean           792.95
V Predictions Std            875.2994
V Predictions Max            2789.1008
V Predictions Min            -145.24858
Log Pis Mean                 -0.95912737
Log Pis Std                  3.5319088
Log Pis Max                  13.981365
Log Pis Min                  -7.518078
Policy mu Mean               0.027622482
Policy mu Std                0.7943562
Policy mu Max                2.6899016
Policy mu Min                -2.610173
Policy log std Mean          -0.48913732
Policy log std Std           0.23090687
Policy log std Max           -0.09019421
Policy log std Min           -2.1225457
Z mean eval                  1.9263948
Z variance eval              0.03546231
total_rewards                [6962.21252432 6891.21945113 7071.40654509 6987.65388899 7120.20508048
 6950.76157563 7053.64443002 6752.48976576 6952.69758969 6842.34782823]
total_rewards_mean           6958.46386793362
total_rewards_std            104.57742089844858
total_rewards_max            7120.2050804776445
total_rewards_min            6752.4897657570555
Number of train steps total  364000
Number of env steps total    1094000
Number of rollouts total     0
Train Time (s)               144.20610792608932
(Previous) Eval Time (s)     17.521170976106077
Sample Time (s)              6.459666369948536
Epoch Time (s)               168.18694527214393
Total Train Time (s)         15319.446167192422
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:08:58.035822 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #90 | Epoch Duration: 168.26796460151672
2020-01-12 12:08:58.035964 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9271246
Z variance train             0.035411812
KL Divergence                34.936966
KL Loss                      3.4936967
QF Loss                      262.31976
VF Loss                      57.05413
Policy Loss                  -939.1956
Q Predictions Mean           938.13025
Q Predictions Std            945.0635
Q Predictions Max            2806.3594
Q Predictions Min            254.74431
V Predictions Mean           939.3331
V Predictions Std            945.3313
V Predictions Max            2786.2878
V Predictions Min            264.18433
Log Pis Mean                 -0.6832967
Log Pis Std                  3.5991898
Log Pis Max                  12.719261
Log Pis Min                  -7.2155433
Policy mu Mean               -0.021198655
Policy mu Std                0.84060055
Policy mu Max                2.7585504
Policy mu Min                -2.5623043
Policy log std Mean          -0.4961022
Policy log std Std           0.24633025
Policy log std Max           -0.10967898
Policy log std Min           -2.0952933
Z mean eval                  1.9254935
Z variance eval              0.031933405
total_rewards                [6983.59195109 7062.77059384 6930.22395019 6766.88011683 5308.97817283
 7146.32544945 6588.0054982  6606.30241647 6755.48852662 6565.82120332]
total_rewards_mean           6671.438787881707
total_rewards_std            493.75080248192126
total_rewards_max            7146.325449448679
total_rewards_min            5308.978172827709
Number of train steps total  368000
Number of env steps total    1106000
Number of rollouts total     0
Train Time (s)               143.75813356786966
(Previous) Eval Time (s)     20.968512722756714
Sample Time (s)              5.550566884689033
Epoch Time (s)               170.2772131753154
Total Train Time (s)         15489.800794639625
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:11:48.396333 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #91 | Epoch Duration: 170.3601999282837
2020-01-12 12:11:48.396599 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9250515
Z variance train             0.032038443
KL Divergence                34.908085
KL Loss                      3.4908085
QF Loss                      509.2765
VF Loss                      127.969284
Policy Loss                  -722.9397
Q Predictions Mean           712.375
Q Predictions Std            782.9121
Q Predictions Max            2825.6453
Q Predictions Min            -150.62369
V Predictions Mean           715.1199
V Predictions Std            780.5521
V Predictions Max            2791.151
V Predictions Min            -154.92726
Log Pis Mean                 -1.3459429
Log Pis Std                  3.0131645
Log Pis Max                  10.525032
Log Pis Min                  -7.659042
Policy mu Mean               -0.01008385
Policy mu Std                0.76773375
Policy mu Max                3.12268
Policy mu Min                -2.7024932
Policy log std Mean          -0.47551206
Policy log std Std           0.21089685
Policy log std Max           -0.10658145
Policy log std Min           -1.872183
Z mean eval                  1.9480652
Z variance eval              0.028568843
total_rewards                [6896.16222953 6933.43591348 7207.82974161 7108.12725061 7123.51070532
 7130.30406293 7060.38162886 7096.6089008  7156.52609358 6977.71199893]
total_rewards_mean           7069.0598525655105
total_rewards_std            96.23698279492831
total_rewards_max            7207.829741605403
total_rewards_min            6896.162229530173
Number of train steps total  372000
Number of env steps total    1118000
Number of rollouts total     0
Train Time (s)               144.4790194928646
(Previous) Eval Time (s)     20.898349762894213
Sample Time (s)              5.671871499624103
Epoch Time (s)               171.04924075538293
Total Train Time (s)         15660.93359193625
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:14:39.528145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #92 | Epoch Duration: 171.1313989162445
2020-01-12 12:14:39.528281 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9502541
Z variance train             0.028415492
KL Divergence                35.944492
KL Loss                      3.5944493
QF Loss                      451.23682
VF Loss                      175.29254
Policy Loss                  -829.1762
Q Predictions Mean           827.261
Q Predictions Std            898.9086
Q Predictions Max            2883.2905
Q Predictions Min            -146.39136
V Predictions Mean           825.4673
V Predictions Std            899.08154
V Predictions Max            2869.2632
V Predictions Min            -148.23943
Log Pis Mean                 -1.0268289
Log Pis Std                  3.411231
Log Pis Max                  12.243606
Log Pis Min                  -6.4797916
Policy mu Mean               -0.02386024
Policy mu Std                0.77204347
Policy mu Max                2.6899395
Policy mu Min                -2.8781614
Policy log std Mean          -0.49026632
Policy log std Std           0.23146656
Policy log std Max           -0.18375134
Policy log std Min           -2.2068822
Z mean eval                  1.9520752
Z variance eval              0.020687118
total_rewards                [6770.08694816 6852.6263622  6781.78102973 6721.45810336 6630.03339687
 6799.85093726 6984.73607002 6469.20997107 6962.23387439 6923.41478216]
total_rewards_mean           6789.543147521702
total_rewards_std            149.35219887864247
total_rewards_max            6984.736070018523
total_rewards_min            6469.209971071685
Number of train steps total  376000
Number of env steps total    1130000
Number of rollouts total     0
Train Time (s)               143.41464222688228
(Previous) Eval Time (s)     17.472814690787345
Sample Time (s)              6.470811376813799
Epoch Time (s)               167.35826829448342
Total Train Time (s)         15828.368514915928
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:17:26.965516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #93 | Epoch Duration: 167.4371199607849
2020-01-12 12:17:26.965702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.955849
Z variance train             0.020794028
KL Divergence                35.457333
KL Loss                      3.5457332
QF Loss                      971.7628
VF Loss                      47.19342
Policy Loss                  -829.6177
Q Predictions Mean           826.01184
Q Predictions Std            888.1491
Q Predictions Max            2963.528
Q Predictions Min            272.5681
V Predictions Mean           831.42413
V Predictions Std            887.75916
V Predictions Max            2943.7876
V Predictions Min            275.71057
Log Pis Mean                 -0.8349519
Log Pis Std                  3.562833
Log Pis Max                  11.356342
Log Pis Min                  -7.890978
Policy mu Mean               0.011857144
Policy mu Std                0.85243595
Policy mu Max                3.3515043
Policy mu Min                -3.0572422
Policy log std Mean          -0.46886578
Policy log std Std           0.21230197
Policy log std Max           0.17902192
Policy log std Min           -2.102565
Z mean eval                  1.9613756
Z variance eval              0.020575363
total_rewards                [6781.89910206 7135.13516177 7026.1236049  6985.12308895 6958.93112977
 6865.64811754 7001.42536767 6754.56096472 7080.09774399 6962.08331068]
total_rewards_mean           6955.102759205081
total_rewards_std            115.93464218903276
total_rewards_max            7135.135161774803
total_rewards_min            6754.560964716477
Number of train steps total  380000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               144.89263023482636
(Previous) Eval Time (s)     20.879871659446508
Sample Time (s)              6.523120848461986
Epoch Time (s)               172.29562274273485
Total Train Time (s)         16000.890623628162
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:20:19.490706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #94 | Epoch Duration: 172.52475881576538
2020-01-12 12:20:19.490990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #94 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9577183
Z variance train             0.020569151
KL Divergence                35.62691
KL Loss                      3.5626912
QF Loss                      328.0436
VF Loss                      105.83563
Policy Loss                  -762.04297
Q Predictions Mean           758.4116
Q Predictions Std            865.4914
Q Predictions Max            2912.8662
Q Predictions Min            -178.84142
V Predictions Mean           765.37305
V Predictions Std            866.19763
V Predictions Max            2908.577
V Predictions Min            -163.88391
Log Pis Mean                 -0.9066294
Log Pis Std                  3.525547
Log Pis Max                  17.648396
Log Pis Min                  -6.7583046
Policy mu Mean               0.011152982
Policy mu Std                0.80680907
Policy mu Max                2.91809
Policy mu Min                -2.8314044
Policy log std Mean          -0.4720684
Policy log std Std           0.23710132
Policy log std Max           -0.06470287
Policy log std Min           -2.0553463
Z mean eval                  1.9550068
Z variance eval              0.04327026
total_rewards                [6925.4990185  6891.67387614 6958.20214686 6803.17791482 6885.2944383
 6883.72798927 6757.10644823 6975.64832219 6919.30763631 6853.38276128]
total_rewards_mean           6885.302055189028
total_rewards_std            63.63132402670892
total_rewards_max            6975.648322189124
total_rewards_min            6757.106448232212
Number of train steps total  384000
Number of env steps total    1154000
Number of rollouts total     0
Train Time (s)               144.42324313195422
(Previous) Eval Time (s)     17.48837686376646
Sample Time (s)              6.4801661148667336
Epoch Time (s)               168.39178611058742
Total Train Time (s)         16169.366245115642
Epoch                        95
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:23:07.969791 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #95 | Epoch Duration: 168.4786114692688
2020-01-12 12:23:07.969997 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9518551
Z variance train             0.042925913
KL Divergence                34.443462
KL Loss                      3.4443462
QF Loss                      1031.6748
VF Loss                      90.52602
Policy Loss                  -821.28534
Q Predictions Mean           814.4607
Q Predictions Std            921.5163
Q Predictions Max            2898.069
Q Predictions Min            -160.11168
V Predictions Mean           823.7565
V Predictions Std            917.4904
V Predictions Max            2899.3906
V Predictions Min            -148.31297
Log Pis Mean                 -0.9597713
Log Pis Std                  3.2622561
Log Pis Max                  13.871848
Log Pis Min                  -6.8744698
Policy mu Mean               0.01018106
Policy mu Std                0.78635955
Policy mu Max                2.8477485
Policy mu Min                -3.26072
Policy log std Mean          -0.46347722
Policy log std Std           0.21617272
Policy log std Max           -0.0980041
Policy log std Min           -1.8197339
Z mean eval                  1.925991
Z variance eval              0.037870783
total_rewards                [6784.75083446 7108.81177622 7399.1155278  7183.25776872 7205.81909935
 7042.09442055 7076.81791695 7248.69563281 7119.30021553 7059.10557931]
total_rewards_mean           7122.776877169905
total_rewards_std            151.6301973662004
total_rewards_max            7399.115527797064
total_rewards_min            6784.750834458908
Number of train steps total  388000
Number of env steps total    1166000
Number of rollouts total     0
Train Time (s)               144.06890761805698
(Previous) Eval Time (s)     17.57093188771978
Sample Time (s)              6.366818407084793
Epoch Time (s)               168.00665791286156
Total Train Time (s)         16337.459316642024
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:25:56.063161 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #96 | Epoch Duration: 168.092933177948
2020-01-12 12:25:56.063488 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9246712
Z variance train             0.03768177
KL Divergence                33.886417
KL Loss                      3.3886418
QF Loss                      145.71849
VF Loss                      75.80509
Policy Loss                  -778.44586
Q Predictions Mean           773.874
Q Predictions Std            871.4688
Q Predictions Max            2842.3108
Q Predictions Min            -156.5935
V Predictions Mean           781.1615
V Predictions Std            866.9697
V Predictions Max            2833.1519
V Predictions Min            -156.84837
Log Pis Mean                 -0.8810864
Log Pis Std                  3.2318861
Log Pis Max                  10.44112
Log Pis Min                  -5.725468
Policy mu Mean               -0.11117516
Policy mu Std                0.80594635
Policy mu Max                2.6880643
Policy mu Min                -2.6677115
Policy log std Mean          -0.4733659
Policy log std Std           0.21655037
Policy log std Max           -0.12529892
Policy log std Min           -2.4063735
Z mean eval                  1.9261891
Z variance eval              0.015617192
total_rewards                [6910.92650716 7285.85988779 7070.93298224 7059.65686143 7061.45224823
 7394.64542133 7198.90833304 6887.95764664 7079.66250583 7115.98679961]
total_rewards_mean           7106.598919329257
total_rewards_std            146.98487998462107
total_rewards_max            7394.645421327544
total_rewards_min            6887.957646635956
Number of train steps total  392000
Number of env steps total    1178000
Number of rollouts total     0
Train Time (s)               143.565619263798
(Previous) Eval Time (s)     17.26439891103655
Sample Time (s)              6.321033394429833
Epoch Time (s)               167.15105156926438
Total Train Time (s)         16504.68865882093
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:28:43.293686 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #97 | Epoch Duration: 167.2299976348877
2020-01-12 12:28:43.293871 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9236796
Z variance train             0.015629128
KL Divergence                36.926384
KL Loss                      3.6926384
QF Loss                      140.98753
VF Loss                      70.67559
Policy Loss                  -772.65607
Q Predictions Mean           768.79614
Q Predictions Std            896.90076
Q Predictions Max            2890.0928
Q Predictions Min            -181.72795
V Predictions Mean           773.215
V Predictions Std            897.26587
V Predictions Max            2872.159
V Predictions Min            -165.36037
Log Pis Mean                 -0.8491062
Log Pis Std                  3.4017882
Log Pis Max                  16.401505
Log Pis Min                  -6.694831
Policy mu Mean               -0.07999235
Policy mu Std                0.79951745
Policy mu Max                3.4597378
Policy mu Min                -2.3984046
Policy log std Mean          -0.47717237
Policy log std Std           0.22853754
Policy log std Max           -0.14652878
Policy log std Min           -2.084047
Z mean eval                  1.955007
Z variance eval              0.01590431
total_rewards                [7173.46759039 7011.44339548 7295.25433609 7027.43267328 7365.85267069
 7230.93851412 7080.09379425 7203.13389546 7211.9468323  7115.84003063]
total_rewards_mean           7171.540373269328
total_rewards_std            108.20728990294137
total_rewards_max            7365.8526706925395
total_rewards_min            7011.443395475614
Number of train steps total  396000
Number of env steps total    1190000
Number of rollouts total     0
Train Time (s)               145.42305033281446
(Previous) Eval Time (s)     17.334379236679524
Sample Time (s)              6.631349541246891
Epoch Time (s)               169.38877911074087
Total Train Time (s)         16674.180383663625
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:31:32.795630 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #98 | Epoch Duration: 169.50161504745483
2020-01-12 12:31:32.795809 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9573311
Z variance train             0.015906803
KL Divergence                38.290527
KL Loss                      3.8290527
QF Loss                      222.62672
VF Loss                      127.45002
Policy Loss                  -823.197
Q Predictions Mean           818.0975
Q Predictions Std            913.699
Q Predictions Max            2958.4922
Q Predictions Min            -166.81929
V Predictions Mean           824.3971
V Predictions Std            913.9169
V Predictions Max            2955.7908
V Predictions Min            -187.14996
Log Pis Mean                 -0.71851224
Log Pis Std                  3.573749
Log Pis Max                  21.183805
Log Pis Min                  -5.614256
Policy mu Mean               -0.015614729
Policy mu Std                0.8101781
Policy mu Max                3.8962865
Policy mu Min                -2.9887483
Policy log std Mean          -0.47551736
Policy log std Std           0.22709781
Policy log std Max           -0.07680419
Policy log std Min           -2.0685337
Z mean eval                  1.9186201
Z variance eval              0.029956728
total_rewards                [7199.1334282  6986.66026459 7219.7231687  7054.786189   7101.66576537
 7397.95722234 7024.74711855 6969.33697813 7163.59485235 7207.62206831]
total_rewards_mean           7132.522705555524
total_rewards_std            124.74690844790118
total_rewards_max            7397.957222338196
total_rewards_min            6969.3369781315105
Number of train steps total  400000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               144.61361826816574
(Previous) Eval Time (s)     21.027083704713732
Sample Time (s)              6.556876257993281
Epoch Time (s)               172.19757823087275
Total Train Time (s)         16846.464620177634
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:34:25.076745 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #99 | Epoch Duration: 172.2808063030243
2020-01-12 12:34:25.076882 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9198582
Z variance train             0.030087644
KL Divergence                37.73826
KL Loss                      3.773826
QF Loss                      186.96909
VF Loss                      131.99274
Policy Loss                  -789.7919
Q Predictions Mean           787.02893
Q Predictions Std            913.64954
Q Predictions Max            2898.7463
Q Predictions Min            -202.56499
V Predictions Mean           792.09937
V Predictions Std            915.6611
V Predictions Max            2931.6113
V Predictions Min            -197.8871
Log Pis Mean                 -0.8441348
Log Pis Std                  3.5685039
Log Pis Max                  14.654056
Log Pis Min                  -8.287224
Policy mu Mean               -0.032866765
Policy mu Std                0.7899241
Policy mu Max                2.9057257
Policy mu Min                -2.3959796
Policy log std Mean          -0.47089636
Policy log std Std           0.24273388
Policy log std Max           -0.15467562
Policy log std Min           -2.1907928
Z mean eval                  1.9512832
Z variance eval              0.030735204
total_rewards                [6836.95180953 7186.2285294  7232.20174307 6919.99718401 7107.26881144
 7057.73115159 7045.45048829 7153.18812023 6935.67984264 7351.98645977]
total_rewards_mean           7082.668413997375
total_rewards_std            148.87800114147583
total_rewards_max            7351.986459765026
total_rewards_min            6836.951809529374
Number of train steps total  404000
Number of env steps total    1214000
Number of rollouts total     0
Train Time (s)               143.1254305159673
(Previous) Eval Time (s)     17.800623739603907
Sample Time (s)              6.571932315360755
Epoch Time (s)               167.49798657093197
Total Train Time (s)         17014.042863237206
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:37:12.658547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #100 | Epoch Duration: 167.58152103424072
2020-01-12 12:37:12.658900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9481484
Z variance train             0.030712593
KL Divergence                37.734062
KL Loss                      3.7734063
QF Loss                      211.76804
VF Loss                      112.42422
Policy Loss                  -809.84937
Q Predictions Mean           802.0088
Q Predictions Std            887.39594
Q Predictions Max            2985.6897
Q Predictions Min            -166.66971
V Predictions Mean           807.3661
V Predictions Std            890.58704
V Predictions Max            2965.6096
V Predictions Min            -190.80685
Log Pis Mean                 -0.87187636
Log Pis Std                  3.3722038
Log Pis Max                  13.284132
Log Pis Min                  -6.7265606
Policy mu Mean               0.0024157986
Policy mu Std                0.8291998
Policy mu Max                2.8632176
Policy mu Min                -2.5787098
Policy log std Mean          -0.49392834
Policy log std Std           0.22726126
Policy log std Max           -0.093110204
Policy log std Min           -2.0595007
Z mean eval                  1.9123154
Z variance eval              0.046586704
total_rewards                [6494.28234362 7286.10448183 6841.09749333 7078.7067167  7060.63968988
 6948.82282762 7006.3019518  6994.81328263 7154.83236328 7085.67850526]
total_rewards_mean           6995.127965596073
total_rewards_std            201.61603799319053
total_rewards_max            7286.104481830567
total_rewards_min            6494.2823436208755
Number of train steps total  408000
Number of env steps total    1226000
Number of rollouts total     0
Train Time (s)               143.60141613101587
(Previous) Eval Time (s)     17.73103729216382
Sample Time (s)              5.579986117780209
Epoch Time (s)               166.9124395409599
Total Train Time (s)         17181.03221380338
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:39:59.645739 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #101 | Epoch Duration: 166.98662400245667
2020-01-12 12:39:59.645866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #101 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9122131
Z variance train             0.046499323
KL Divergence                36.91224
KL Loss                      3.6912239
QF Loss                      204.64801
VF Loss                      425.9266
Policy Loss                  -830.5631
Q Predictions Mean           822.53845
Q Predictions Std            917.2486
Q Predictions Max            2953.9556
Q Predictions Min            280.40887
V Predictions Mean           834.4296
V Predictions Std            918.86285
V Predictions Max            2929.4495
V Predictions Min            291.0007
Log Pis Mean                 -0.5841043
Log Pis Std                  3.594026
Log Pis Max                  12.076417
Log Pis Min                  -7.8194447
Policy mu Mean               0.004250919
Policy mu Std                0.8290791
Policy mu Max                2.7618017
Policy mu Min                -3.0087683
Policy log std Mean          -0.5007985
Policy log std Std           0.2462666
Policy log std Max           -0.11922583
Policy log std Min           -2.0630345
Z mean eval                  1.9185776
Z variance eval              0.036846966
total_rewards                [6674.88464775 6050.55690009 6582.71613513 6281.26385174 6457.9208249
 6409.77093247 6790.2106098  6434.20594852 6581.91656938 6540.74954236]
total_rewards_mean           6480.419596214767
total_rewards_std            197.5528096253992
total_rewards_max            6790.210609800283
total_rewards_min            6050.556900093767
Number of train steps total  412000
Number of env steps total    1238000
Number of rollouts total     0
Train Time (s)               143.72307493630797
(Previous) Eval Time (s)     20.90759125724435
Sample Time (s)              5.638433326967061
Epoch Time (s)               170.26909952051938
Total Train Time (s)         17351.38688650867
Epoch                        102
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:42:50.001589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #102 | Epoch Duration: 170.35562944412231
2020-01-12 12:42:50.001722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9190061
Z variance train             0.036996357
KL Divergence                36.68301
KL Loss                      3.668301
QF Loss                      429.22845
VF Loss                      104.5327
Policy Loss                  -939.28455
Q Predictions Mean           934.9176
Q Predictions Std            1006.88794
Q Predictions Max            3030.2312
Q Predictions Min            -192.72853
V Predictions Mean           932.5804
V Predictions Std            1001.59344
V Predictions Max            2986.3684
V Predictions Min            -193.13354
Log Pis Mean                 -0.19239593
Log Pis Std                  3.7003336
Log Pis Max                  11.6999855
Log Pis Min                  -8.99497
Policy mu Mean               -0.06895702
Policy mu Std                0.870376
Policy mu Max                2.5754828
Policy mu Min                -2.6116986
Policy log std Mean          -0.5038132
Policy log std Std           0.22910304
Policy log std Max           -0.11108971
Policy log std Min           -2.2524993
Z mean eval                  1.9131848
Z variance eval              0.027703404
total_rewards                [6931.07392711 6911.31652707 6916.28483468 7033.84057386 7236.75355923
 7010.04167597 6992.58336973 7092.41402251 6858.28369889 6829.14155748]
total_rewards_mean           6981.173374653488
total_rewards_std            114.56400631425684
total_rewards_max            7236.753559230378
total_rewards_min            6829.141557477321
Number of train steps total  416000
Number of env steps total    1250000
Number of rollouts total     0
Train Time (s)               144.1944802897051
(Previous) Eval Time (s)     21.153590239118785
Sample Time (s)              6.52583810640499
Epoch Time (s)               171.87390863522887
Total Train Time (s)         17523.347225406673
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:45:41.964083 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #103 | Epoch Duration: 171.9622654914856
2020-01-12 12:45:41.964216 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9119923
Z variance train             0.02760329
KL Divergence                36.591766
KL Loss                      3.6591766
QF Loss                      355.2533
VF Loss                      113.76266
Policy Loss                  -781.56665
Q Predictions Mean           781.32465
Q Predictions Std            879.89734
Q Predictions Max            2971.0996
Q Predictions Min            -128.266
V Predictions Mean           782.276
V Predictions Std            881.92126
V Predictions Max            2991.2356
V Predictions Min            -193.10777
Log Pis Mean                 -0.85325295
Log Pis Std                  3.556944
Log Pis Max                  13.674867
Log Pis Min                  -7.6293197
Policy mu Mean               0.029721871
Policy mu Std                0.8053748
Policy mu Max                3.4148166
Policy mu Min                -2.5768363
Policy log std Mean          -0.49369538
Policy log std Std           0.23865134
Policy log std Max           -0.12624529
Policy log std Min           -2.253504
Z mean eval                  1.9161228
Z variance eval              0.026865054
total_rewards                [7080.11604718 7041.72792161 6991.95393567 7321.65221115 7051.88152365
 7375.47083907 7046.49432117 6881.59844924 7268.86431525 7133.40026517]
total_rewards_mean           7119.315982915413
total_rewards_std            148.07295165704585
total_rewards_max            7375.470839065252
total_rewards_min            6881.598449241846
Number of train steps total  420000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               144.76137865707278
(Previous) Eval Time (s)     21.319770948961377
Sample Time (s)              6.57034373190254
Epoch Time (s)               172.6514933379367
Total Train Time (s)         17696.07851255033
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:48:34.697399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #104 | Epoch Duration: 172.73307156562805
2020-01-12 12:48:34.697598 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9199657
Z variance train             0.026847642
KL Divergence                36.331535
KL Loss                      3.6331537
QF Loss                      177.95108
VF Loss                      128.5391
Policy Loss                  -786.4409
Q Predictions Mean           784.1812
Q Predictions Std            859.46
Q Predictions Max            2925.8354
Q Predictions Min            173.25728
V Predictions Mean           791.4624
V Predictions Std            859.21344
V Predictions Max            2927.9653
V Predictions Min            177.5191
Log Pis Mean                 -0.70992106
Log Pis Std                  3.55017
Log Pis Max                  12.903122
Log Pis Min                  -7.2793236
Policy mu Mean               0.020849323
Policy mu Std                0.8100438
Policy mu Max                2.7160182
Policy mu Min                -2.4194555
Policy log std Mean          -0.48243427
Policy log std Std           0.21911544
Policy log std Max           0.016684294
Policy log std Min           -1.8477298
Z mean eval                  1.9044956
Z variance eval              0.055526666
total_rewards                [7313.71779703 7495.45141191 7520.15145555 7445.75068871 7307.38067294
 7515.59825665 7384.09986366 7350.95264182 7497.84761127 7471.37889775]
total_rewards_mean           7430.232929729131
total_rewards_std            79.50700875653034
total_rewards_max            7520.151455553658
total_rewards_min            7307.380672944401
Number of train steps total  424000
Number of env steps total    1274000
Number of rollouts total     0
Train Time (s)               144.52712028520182
(Previous) Eval Time (s)     17.535538257099688
Sample Time (s)              5.701904498971999
Epoch Time (s)               167.7645630412735
Total Train Time (s)         17863.922279125545
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:51:22.543831 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #105 | Epoch Duration: 167.84603238105774
2020-01-12 12:51:22.544111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9023387
Z variance train             0.05563987
KL Divergence                35.090317
KL Loss                      3.5090318
QF Loss                      1831.6276
VF Loss                      178.37271
Policy Loss                  -817.60834
Q Predictions Mean           820.8696
Q Predictions Std            926.6495
Q Predictions Max            3012.8435
Q Predictions Min            -199.35379
V Predictions Mean           819.7685
V Predictions Std            920.3622
V Predictions Max            2977.6545
V Predictions Min            -250.17616
Log Pis Mean                 -0.36028093
Log Pis Std                  3.6196344
Log Pis Max                  14.3547535
Log Pis Min                  -7.2800493
Policy mu Mean               -0.0020337787
Policy mu Std                0.82577497
Policy mu Max                2.529899
Policy mu Min                -2.4691093
Policy log std Mean          -0.51568514
Policy log std Std           0.24168961
Policy log std Max           -0.07920104
Policy log std Min           -2.101961
Z mean eval                  1.9212914
Z variance eval              0.03641849
total_rewards                [7332.94438196 7423.87831011 7496.97089141 7566.78696447 7428.29160515
 7594.16045764 7295.23990967 7474.85704441 7493.19866737 7596.55574093]
total_rewards_mean           7470.288397312033
total_rewards_std            97.61167434436152
total_rewards_max            7596.555740926086
total_rewards_min            7295.239909671807
Number of train steps total  428000
Number of env steps total    1286000
Number of rollouts total     0
Train Time (s)               145.4948024759069
(Previous) Eval Time (s)     21.22278656810522
Sample Time (s)              6.706497674807906
Epoch Time (s)               173.42408671882004
Total Train Time (s)         18037.426344096195
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:54:16.048084 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #106 | Epoch Duration: 173.50380277633667
2020-01-12 12:54:16.048231 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9239724
Z variance train             0.03636636
KL Divergence                35.616932
KL Loss                      3.5616932
QF Loss                      1156.5464
VF Loss                      75.62479
Policy Loss                  -855.18085
Q Predictions Mean           848.7662
Q Predictions Std            939.9918
Q Predictions Max            2943.1384
Q Predictions Min            -227.2128
V Predictions Mean           850.2124
V Predictions Std            938.0852
V Predictions Max            2930.9998
V Predictions Min            -238.77425
Log Pis Mean                 -0.5033512
Log Pis Std                  3.2893548
Log Pis Max                  14.158642
Log Pis Min                  -6.04196
Policy mu Mean               -0.019183343
Policy mu Std                0.82449967
Policy mu Max                2.6877272
Policy mu Min                -2.4937038
Policy log std Mean          -0.5123274
Policy log std Std           0.24086493
Policy log std Max           -0.09537104
Policy log std Min           -2.3237872
Z mean eval                  1.90819
Z variance eval              0.03924941
total_rewards                [7079.91371451 7128.06021893 7284.29242871 7120.66729496 7280.37833744
 7242.91927915 7166.46462145 7303.89062327 7379.48486638 7054.06472779]
total_rewards_mean           7204.013611258201
total_rewards_std            103.23100055042836
total_rewards_max            7379.484866384539
total_rewards_min            7054.064727788141
Number of train steps total  432000
Number of env steps total    1298000
Number of rollouts total     0
Train Time (s)               145.1561213331297
(Previous) Eval Time (s)     17.87301849387586
Sample Time (s)              6.5740503994748
Epoch Time (s)               169.60319022648036
Total Train Time (s)         18207.126162834466
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:57:05.755293 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #107 | Epoch Duration: 169.70679092407227
2020-01-12 12:57:05.755782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9080664
Z variance train             0.03948683
KL Divergence                37.3465
KL Loss                      3.7346501
QF Loss                      1396.387
VF Loss                      39.721226
Policy Loss                  -938.37604
Q Predictions Mean           938.7648
Q Predictions Std            994.80786
Q Predictions Max            3171.219
Q Predictions Min            239.5251
V Predictions Mean           935.6797
V Predictions Std            992.1613
V Predictions Max            3157.042
V Predictions Min            236.0456
Log Pis Mean                 -0.23342033
Log Pis Std                  3.5909774
Log Pis Max                  13.300819
Log Pis Min                  -8.158692
Policy mu Mean               -0.03888278
Policy mu Std                0.8769801
Policy mu Max                2.449174
Policy mu Min                -2.502029
Policy log std Mean          -0.51083595
Policy log std Std           0.24604046
Policy log std Max           -0.13549732
Policy log std Min           -2.2447495
Z mean eval                  1.9063368
Z variance eval              0.061633624
total_rewards                [6851.39667541 7220.6755688  7322.37475953 7078.72550887 6902.9060456
 7105.45402231 7113.49357434 6819.26869596 7434.61915919 6911.04306633]
total_rewards_mean           7075.995707634696
total_rewards_std            196.48152644496312
total_rewards_max            7434.619159189323
total_rewards_min            6819.268695961751
Number of train steps total  436000
Number of env steps total    1310000
Number of rollouts total     0
Train Time (s)               142.51524862879887
(Previous) Eval Time (s)     17.76117130694911
Sample Time (s)              6.562565880361944
Epoch Time (s)               166.83898581610993
Total Train Time (s)         18374.05369709432
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:59:52.682858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #108 | Epoch Duration: 166.9267590045929
2020-01-12 12:59:52.683053 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9081059
Z variance train             0.062134463
KL Divergence                35.859013
KL Loss                      3.5859013
QF Loss                      171.74023
VF Loss                      122.72737
Policy Loss                  -851.08417
Q Predictions Mean           844.6479
Q Predictions Std            927.25684
Q Predictions Max            2995.3828
Q Predictions Min            177.99358
V Predictions Mean           845.505
V Predictions Std            925.7861
V Predictions Max            2983.0195
V Predictions Min            182.60228
Log Pis Mean                 -0.43036216
Log Pis Std                  3.7020714
Log Pis Max                  12.458061
Log Pis Min                  -7.847006
Policy mu Mean               -0.0036208492
Policy mu Std                0.85864455
Policy mu Max                3.3925426
Policy mu Min                -2.977624
Policy log std Mean          -0.49077502
Policy log std Std           0.22834393
Policy log std Max           -0.14068776
Policy log std Min           -2.0067024
Z mean eval                  1.9272276
Z variance eval              0.12757292
total_rewards                [7471.58946497 7087.35709427 6807.86512466 7140.07353814 7032.06243809
 7378.50430861 7507.8338408  7266.62277801 7258.38489962 7206.42088186]
total_rewards_mean           7215.671436904074
total_rewards_std            201.01526530273446
total_rewards_max            7507.83384080224
total_rewards_min            6807.865124664541
Number of train steps total  440000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               143.8547427719459
(Previous) Eval Time (s)     17.651402975898236
Sample Time (s)              6.479253159835935
Epoch Time (s)               167.98539890768006
Total Train Time (s)         18542.12601461634
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:02:40.756766 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #109 | Epoch Duration: 168.073561668396
2020-01-12 13:02:40.756940 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9280527
Z variance train             0.1268874
KL Divergence                37.429317
KL Loss                      3.7429318
QF Loss                      470.232
VF Loss                      92.32588
Policy Loss                  -760.1286
Q Predictions Mean           756.58325
Q Predictions Std            862.76056
Q Predictions Max            3043.059
Q Predictions Min            -303.75357
V Predictions Mean           753.98413
V Predictions Std            857.5785
V Predictions Max            3018.1267
V Predictions Min            -257.14316
Log Pis Mean                 -1.0864537
Log Pis Std                  3.5456898
Log Pis Max                  14.290344
Log Pis Min                  -7.863919
Policy mu Mean               0.002960734
Policy mu Std                0.81410563
Policy mu Max                2.5935562
Policy mu Min                -2.9445782
Policy log std Mean          -0.4749986
Policy log std Std           0.23077637
Policy log std Max           -0.10855514
Policy log std Min           -2.1209948
Z mean eval                  1.8875366
Z variance eval              0.044112746
total_rewards                [7543.11112517 7343.38792588 7567.90351152 7611.87158479 7499.49656459
 7603.1901754  7597.49106087 7496.92589915 7581.02284374 7567.32794193]
total_rewards_mean           7541.172863304377
total_rewards_std            76.03958066088532
total_rewards_max            7611.871584792599
total_rewards_min            7343.387925879508
Number of train steps total  444000
Number of env steps total    1334000
Number of rollouts total     0
Train Time (s)               145.14623410999775
(Previous) Eval Time (s)     21.108967198990285
Sample Time (s)              6.455439322628081
Epoch Time (s)               172.71064063161612
Total Train Time (s)         18714.917049956974
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:05:33.548428 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #110 | Epoch Duration: 172.7913601398468
2020-01-12 13:05:33.548575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8880463
Z variance train             0.044402517
KL Divergence                37.60445
KL Loss                      3.760445
QF Loss                      237.7527
VF Loss                      42.007004
Policy Loss                  -776.46564
Q Predictions Mean           775.03033
Q Predictions Std            867.4189
Q Predictions Max            3054.4944
Q Predictions Min            312.23987
V Predictions Mean           773.40015
V Predictions Std            867.1907
V Predictions Max            3011.364
V Predictions Min            309.64786
Log Pis Mean                 -1.0138376
Log Pis Std                  3.2418103
Log Pis Max                  11.1862545
Log Pis Min                  -6.3295317
Policy mu Mean               0.012316257
Policy mu Std                0.80221117
Policy mu Max                2.9116411
Policy mu Min                -2.8177445
Policy log std Mean          -0.48673233
Policy log std Std           0.21582386
Policy log std Max           -0.12275705
Policy log std Min           -1.8103812
Z mean eval                  1.9022865
Z variance eval              0.050370812
total_rewards                [7081.5059657  7543.53576731 7277.48006741 7360.66910782 7300.89242344
 7327.75994107 7306.46763724 7121.03569311 7213.4607395  7540.99165857]
total_rewards_mean           7307.379900116468
total_rewards_std            144.6029249580695
total_rewards_max            7543.535767311413
total_rewards_min            7081.505965704212
Number of train steps total  448000
Number of env steps total    1346000
Number of rollouts total     0
Train Time (s)               145.65298531530425
(Previous) Eval Time (s)     18.09470963384956
Sample Time (s)              6.466960986610502
Epoch Time (s)               170.2146559357643
Total Train Time (s)         18885.213521314785
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:08:23.845323 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #111 | Epoch Duration: 170.29664945602417
2020-01-12 13:08:23.845449 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #111 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9039986
Z variance train             0.049729537
KL Divergence                36.491695
KL Loss                      3.6491697
QF Loss                      1405.1643
VF Loss                      259.05408
Policy Loss                  -853.2169
Q Predictions Mean           852.65234
Q Predictions Std            924.5874
Q Predictions Max            3083.4578
Q Predictions Min            -282.27167
V Predictions Mean           866.15063
V Predictions Std            929.2659
V Predictions Max            3099.4607
V Predictions Min            -285.68552
Log Pis Mean                 -0.70494103
Log Pis Std                  3.2510262
Log Pis Max                  13.217918
Log Pis Min                  -7.246575
Policy mu Mean               -0.057437617
Policy mu Std                0.82263553
Policy mu Max                3.538799
Policy mu Min                -2.820245
Policy log std Mean          -0.4911076
Policy log std Std           0.24035822
Policy log std Max           -0.039743915
Policy log std Min           -2.3823073
Z mean eval                  1.9054581
Z variance eval              0.06622856
total_rewards                [7289.64648765 7532.49381457 7345.7478275  7529.78728686 7811.5301482
 7441.10943897 7480.99103629 7774.36640407 7638.49608968 7716.27872823]
total_rewards_mean           7556.044726200933
total_rewards_std            167.53817502530703
total_rewards_max            7811.530148195105
total_rewards_min            7289.646487646022
Number of train steps total  452000
Number of env steps total    1358000
Number of rollouts total     0
Train Time (s)               142.87984588369727
(Previous) Eval Time (s)     17.745346387848258
Sample Time (s)              5.649289525579661
Epoch Time (s)               166.2744817971252
Total Train Time (s)         19051.58230270911
Epoch                        112
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:11:10.217035 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #112 | Epoch Duration: 166.3714780807495
2020-01-12 13:11:10.217222 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9094651
Z variance train             0.066540025
KL Divergence                35.9141
KL Loss                      3.5914102
QF Loss                      196.49733
VF Loss                      51.570873
Policy Loss                  -872.6476
Q Predictions Mean           866.8109
Q Predictions Std            962.18097
Q Predictions Max            3109.0315
Q Predictions Min            324.93378
V Predictions Mean           872.9815
V Predictions Std            961.7692
V Predictions Max            3100.9292
V Predictions Min            324.6514
Log Pis Mean                 -0.53830713
Log Pis Std                  3.350883
Log Pis Max                  11.599407
Log Pis Min                  -8.683192
Policy mu Mean               0.050827205
Policy mu Std                0.8340545
Policy mu Max                2.6867223
Policy mu Min                -2.7862499
Policy log std Mean          -0.49042165
Policy log std Std           0.23613343
Policy log std Max           -0.13578013
Policy log std Min           -1.9563973
Z mean eval                  1.9007809
Z variance eval              0.038516693
total_rewards                [4591.38951419 6483.08747535 6385.76829397 6312.86570469 7034.20088381
 6490.47979072 6592.02162545 7136.36593443 6982.26341154 6307.41627828]
total_rewards_mean           6431.585891243546
total_rewards_std            679.1833723732648
total_rewards_max            7136.365934433517
total_rewards_min            4591.389514192275
Number of train steps total  456000
Number of env steps total    1370000
Number of rollouts total     0
Train Time (s)               145.5874309251085
(Previous) Eval Time (s)     18.49061840865761
Sample Time (s)              5.697768978308886
Epoch Time (s)               169.775818312075
Total Train Time (s)         19221.44087025663
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:14:00.078432 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #113 | Epoch Duration: 169.86106181144714
2020-01-12 13:14:00.078609 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9011631
Z variance train             0.03859276
KL Divergence                37.03447
KL Loss                      3.703447
QF Loss                      115.08835
VF Loss                      69.73685
Policy Loss                  -860.17303
Q Predictions Mean           857.6362
Q Predictions Std            951.5746
Q Predictions Max            3145.3337
Q Predictions Min            322.2025
V Predictions Mean           854.27527
V Predictions Std            948.4121
V Predictions Max            3117.2192
V Predictions Min            318.51343
Log Pis Mean                 -0.6824604
Log Pis Std                  3.2576005
Log Pis Max                  10.518961
Log Pis Min                  -6.5467157
Policy mu Mean               -0.06810882
Policy mu Std                0.8166818
Policy mu Max                2.3929021
Policy mu Min                -2.4685738
Policy log std Mean          -0.50172096
Policy log std Std           0.23528688
Policy log std Max           -0.14597297
Policy log std Min           -1.8952065
Z mean eval                  1.9165739
Z variance eval              0.03483177
total_rewards                [7387.95023028 7459.22926039 7579.88171534 7232.9194812  7475.48501255
 7705.07643705 7441.46705759 7774.34606089 7348.25686658 7522.10791506]
total_rewards_mean           7492.67200369349
total_rewards_std            153.70668018569066
total_rewards_max            7774.3460608938785
total_rewards_min            7232.919481199336
Number of train steps total  460000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               143.25593352224678
(Previous) Eval Time (s)     20.7247155290097
Sample Time (s)              6.684343710541725
Epoch Time (s)               170.6649927617982
Total Train Time (s)         19392.188857350964
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:16:50.827707 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #114 | Epoch Duration: 170.7489676475525
2020-01-12 13:16:50.827842 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9169391
Z variance train             0.03489836
KL Divergence                37.321022
KL Loss                      3.7321022
QF Loss                      563.5031
VF Loss                      160.4964
Policy Loss                  -918.4683
Q Predictions Mean           917.9453
Q Predictions Std            1006.29486
Q Predictions Max            3174.943
Q Predictions Min            -299.66113
V Predictions Mean           925.46716
V Predictions Std            1009.45135
V Predictions Max            3177.3132
V Predictions Min            -314.6009
Log Pis Mean                 -0.64203185
Log Pis Std                  3.3479748
Log Pis Max                  12.220511
Log Pis Min                  -8.43899
Policy mu Mean               -0.0069028228
Policy mu Std                0.82823354
Policy mu Max                2.8458598
Policy mu Min                -2.340374
Policy log std Mean          -0.5178518
Policy log std Std           0.2510042
Policy log std Max           -0.13519698
Policy log std Min           -2.045452
Z mean eval                  1.8629748
Z variance eval              0.03024486
total_rewards                [7137.35415643 7319.80341441 7098.84632851 6951.07999592 6974.04739117
 6954.5084906  6920.56350344 7176.1850445  7166.13685626 6848.58734057]
total_rewards_mean           7054.711252181047
total_rewards_std            139.28120157815005
total_rewards_max            7319.803414413312
total_rewards_min            6848.587340569953
Number of train steps total  464000
Number of env steps total    1394000
Number of rollouts total     0
Train Time (s)               143.29337359033525
(Previous) Eval Time (s)     17.866342968773097
Sample Time (s)              6.5710661839693785
Epoch Time (s)               167.73078274307773
Total Train Time (s)         19560.008664316032
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:19:38.648250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #115 | Epoch Duration: 167.8203136920929
2020-01-12 13:19:38.648383 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8643568
Z variance train             0.030050997
KL Divergence                37.71864
KL Loss                      3.771864
QF Loss                      1328.3547
VF Loss                      43.57567
Policy Loss                  -817.87854
Q Predictions Mean           814.14386
Q Predictions Std            903.1618
Q Predictions Max            3054.1433
Q Predictions Min            321.97647
V Predictions Mean           814.9961
V Predictions Std            902.37213
V Predictions Max            3042.5315
V Predictions Min            323.58896
Log Pis Mean                 -0.8339603
Log Pis Std                  3.1897955
Log Pis Max                  15.359024
Log Pis Min                  -7.761678
Policy mu Mean               -0.055720065
Policy mu Std                0.8074393
Policy mu Max                3.8086443
Policy mu Min                -3.295555
Policy log std Mean          -0.512848
Policy log std Std           0.2329146
Policy log std Max           -0.13149789
Policy log std Min           -1.798282
Z mean eval                  1.9113111
Z variance eval              0.027153749
total_rewards                [7541.83986259 7426.40661565 7606.1952651  7671.70428588 7627.94930612
 7522.72441121 7685.28793986 7927.10916377 7737.57390235 7645.39965526]
total_rewards_mean           7639.219040777648
total_rewards_std            128.5809645122482
total_rewards_max            7927.109163769693
total_rewards_min            7426.406615645668
Number of train steps total  468000
Number of env steps total    1406000
Number of rollouts total     0
Train Time (s)               142.12256727507338
(Previous) Eval Time (s)     17.5120849609375
Sample Time (s)              5.517080361023545
Epoch Time (s)               165.15173259703442
Total Train Time (s)         19725.24482318759
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:22:23.886237 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #116 | Epoch Duration: 165.2377495765686
2020-01-12 13:22:23.886400 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9126072
Z variance train             0.02712198
KL Divergence                39.05373
KL Loss                      3.905373
QF Loss                      127.00568
VF Loss                      83.04401
Policy Loss                  -790.92725
Q Predictions Mean           786.67664
Q Predictions Std            871.7051
Q Predictions Max            3136.247
Q Predictions Min            339.35434
V Predictions Mean           785.4231
V Predictions Std            868.9775
V Predictions Max            3123.198
V Predictions Min            337.20648
Log Pis Mean                 -0.9350321
Log Pis Std                  3.3906243
Log Pis Max                  15.53838
Log Pis Min                  -8.186732
Policy mu Mean               0.02482766
Policy mu Std                0.80265313
Policy mu Max                2.6167123
Policy mu Min                -3.2009027
Policy log std Mean          -0.5045402
Policy log std Std           0.24614045
Policy log std Max           -0.08879909
Policy log std Min           -2.183859
Z mean eval                  1.8970438
Z variance eval              0.052502535
total_rewards                [6770.02010606 6853.52541577 6830.70160612 6736.40662681 7035.73180251
 6552.36814977 6575.28448152 7124.27092476 6869.35050328 7054.21467063]
total_rewards_mean           6840.187428724127
total_rewards_std            182.9137719131161
total_rewards_max            7124.270924764412
total_rewards_min            6552.368149771533
Number of train steps total  472000
Number of env steps total    1418000
Number of rollouts total     0
Train Time (s)               143.2499834978953
(Previous) Eval Time (s)     21.006833757273853
Sample Time (s)              6.5547933634370565
Epoch Time (s)               170.8116106186062
Total Train Time (s)         19896.150430815294
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:25:14.793201 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #117 | Epoch Duration: 170.90667986869812
2020-01-12 13:25:14.793330 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8932397
Z variance train             0.052047856
KL Divergence                36.226376
KL Loss                      3.6226375
QF Loss                      414.04187
VF Loss                      160.24458
Policy Loss                  -951.13855
Q Predictions Mean           947.1282
Q Predictions Std            1011.3005
Q Predictions Max            3217.4246
Q Predictions Min            337.20016
V Predictions Mean           943.9464
V Predictions Std            1011.6994
V Predictions Max            3210.2717
V Predictions Min            337.15628
Log Pis Mean                 -0.22658238
Log Pis Std                  3.756109
Log Pis Max                  14.022488
Log Pis Min                  -6.1848235
Policy mu Mean               -0.017377093
Policy mu Std                0.87407607
Policy mu Max                2.7511168
Policy mu Min                -3.2514203
Policy log std Mean          -0.51549596
Policy log std Std           0.25036687
Policy log std Max           -0.11797637
Policy log std Min           -2.1203167
Z mean eval                  1.9187527
Z variance eval              0.059056066
total_rewards                [7485.80680699 7534.54266589 7780.52383127 7557.89506363 7913.54265272
 7519.79943614 7536.54924682 7841.24279322 7358.78559817 7603.69495628]
total_rewards_mean           7613.238305112495
total_rewards_std            165.86052853211416
total_rewards_max            7913.542652715864
total_rewards_min            7358.785598168658
Number of train steps total  476000
Number of env steps total    1430000
Number of rollouts total     0
Train Time (s)               146.01277970103547
(Previous) Eval Time (s)     17.829049854073673
Sample Time (s)              6.592224487569183
Epoch Time (s)               170.43405404267833
Total Train Time (s)         20066.659782813396
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:28:05.304522 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #118 | Epoch Duration: 170.51109743118286
2020-01-12 13:28:05.304642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9201494
Z variance train             0.059111483
KL Divergence                36.800495
KL Loss                      3.6800497
QF Loss                      552.80695
VF Loss                      134.59952
Policy Loss                  -880.40546
Q Predictions Mean           873.9572
Q Predictions Std            954.3509
Q Predictions Max            3245.014
Q Predictions Min            336.1944
V Predictions Mean           882.3362
V Predictions Std            954.6067
V Predictions Max            3235.073
V Predictions Min            348.3477
Log Pis Mean                 -0.5045211
Log Pis Std                  3.6810694
Log Pis Max                  17.057543
Log Pis Min                  -6.40963
Policy mu Mean               0.016252033
Policy mu Std                0.87295073
Policy mu Max                3.5429413
Policy mu Min                -3.6231174
Policy log std Mean          -0.47680545
Policy log std Std           0.23525366
Policy log std Max           0.10615286
Policy log std Min           -1.7438083
Z mean eval                  1.8499699
Z variance eval              0.041574962
total_rewards                [7166.02203731 6914.99813297 7484.81165074 7413.77446169 7244.08055029
 7277.55873161 7074.07979396 7234.95516712 7568.35890609 7165.87680776]
total_rewards_mean           7254.451623954461
total_rewards_std            184.78010153088542
total_rewards_max            7568.358906085889
total_rewards_min            6914.998132974983
Number of train steps total  480000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               143.69306420860812
(Previous) Eval Time (s)     19.218672181945294
Sample Time (s)              5.581175044644624
Epoch Time (s)               168.49291143519804
Total Train Time (s)         20235.22948155366
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:30:53.875921 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #119 | Epoch Duration: 168.5711760520935
2020-01-12 13:30:53.876085 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8507744
Z variance train             0.041518833
KL Divergence                36.75255
KL Loss                      3.6752548
QF Loss                      1290.2565
VF Loss                      70.82139
Policy Loss                  -866.0432
Q Predictions Mean           867.7007
Q Predictions Std            965.5447
Q Predictions Max            3177.8662
Q Predictions Min            330.15775
V Predictions Mean           868.81903
V Predictions Std            961.71216
V Predictions Max            3162.399
V Predictions Min            330.12518
Log Pis Mean                 -0.894922
Log Pis Std                  3.3007689
Log Pis Max                  13.019893
Log Pis Min                  -7.3243947
Policy mu Mean               0.034265686
Policy mu Std                0.8117967
Policy mu Max                3.182914
Policy mu Min                -2.5562327
Policy log std Mean          -0.4892534
Policy log std Std           0.22296138
Policy log std Max           -0.12204522
Policy log std Min           -1.8146917
Z mean eval                  1.8818638
Z variance eval              0.034975022
total_rewards                [6925.2472698  6858.91219428 7275.48051983 6775.40147855 6987.57238017
 7448.98691894 6921.66228328 6706.0192007  6943.06071979 6693.44193637]
total_rewards_mean           6953.578490169895
total_rewards_std            228.4301472721002
total_rewards_max            7448.986918937869
total_rewards_min            6693.44193637239
Number of train steps total  484000
Number of env steps total    1454000
Number of rollouts total     0
Train Time (s)               146.87898308085278
(Previous) Eval Time (s)     18.239474636036903
Sample Time (s)              5.785669642034918
Epoch Time (s)               170.9041273589246
Total Train Time (s)         20406.21143379761
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:33:44.863941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #120 | Epoch Duration: 170.98768711090088
2020-01-12 13:33:44.864266 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8801218
Z variance train             0.0349185
KL Divergence                37.942436
KL Loss                      3.7942436
QF Loss                      204.29294
VF Loss                      57.038223
Policy Loss                  -849.1939
Q Predictions Mean           845.59106
Q Predictions Std            965.028
Q Predictions Max            3183.6848
Q Predictions Min            333.11838
V Predictions Mean           851.19385
V Predictions Std            961.3914
V Predictions Max            3180.1636
V Predictions Min            346.7709
Log Pis Mean                 -0.604059
Log Pis Std                  3.5697298
Log Pis Max                  14.270751
Log Pis Min                  -8.27758
Policy mu Mean               0.019414816
Policy mu Std                0.8540691
Policy mu Max                2.6416867
Policy mu Min                -2.7371924
Policy log std Mean          -0.50075567
Policy log std Std           0.22682416
Policy log std Max           -0.06873512
Policy log std Min           -1.9365776
Z mean eval                  1.8481607
Z variance eval              0.03928976
total_rewards                [7738.27513516 7634.77287432 7616.52393936 7798.25266689 7611.83880956
 7906.00086824 7459.9396118  7570.34073781 7586.06429675 7191.06110608]
total_rewards_mean           7611.307004595483
total_rewards_std            184.47935887125516
total_rewards_max            7906.000868235701
total_rewards_min            7191.06110608216
Number of train steps total  488000
Number of env steps total    1466000
Number of rollouts total     0
Train Time (s)               145.37275499198586
(Previous) Eval Time (s)     17.57405790919438
Sample Time (s)              6.529192911926657
Epoch Time (s)               169.4760058131069
Total Train Time (s)         20575.76966544846
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:36:34.421792 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #121 | Epoch Duration: 169.55728888511658
2020-01-12 13:36:34.421968 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8494484
Z variance train             0.039281584
KL Divergence                37.28359
KL Loss                      3.728359
QF Loss                      134.6774
VF Loss                      40.87175
Policy Loss                  -881.18616
Q Predictions Mean           877.3775
Q Predictions Std            962.695
Q Predictions Max            3079.1685
Q Predictions Min            320.2457
V Predictions Mean           878.4719
V Predictions Std            961.2964
V Predictions Max            3070.5562
V Predictions Min            323.7233
Log Pis Mean                 -0.47622082
Log Pis Std                  3.5240083
Log Pis Max                  11.546876
Log Pis Min                  -6.755243
Policy mu Mean               0.081701614
Policy mu Std                0.8215505
Policy mu Max                2.4696395
Policy mu Min                -2.436808
Policy log std Mean          -0.5211946
Policy log std Std           0.24995562
Policy log std Max           -0.03588915
Policy log std Min           -2.1510968
Z mean eval                  1.8335276
Z variance eval              0.029113874
total_rewards                [6818.54030908 7301.84926138 6811.34581638 7043.46345132 7380.23103164
 7058.49506673 7224.01447336 7280.98989087 7051.34181705 7344.64222165]
total_rewards_mean           7131.491333945436
total_rewards_std            196.76628675222818
total_rewards_max            7380.231031644503
total_rewards_min            6811.345816376181
Number of train steps total  492000
Number of env steps total    1478000
Number of rollouts total     0
Train Time (s)               146.31620759889483
(Previous) Eval Time (s)     21.24554680706933
Sample Time (s)              6.6221495247446
Epoch Time (s)               174.18390393070877
Total Train Time (s)         20750.058508296497
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:39:28.711457 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #122 | Epoch Duration: 174.28935885429382
2020-01-12 13:39:28.711604 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8367221
Z variance train             0.029151142
KL Divergence                37.81427
KL Loss                      3.7814271
QF Loss                      165.36618
VF Loss                      110.80527
Policy Loss                  -836.0016
Q Predictions Mean           830.0836
Q Predictions Std            935.9544
Q Predictions Max            3156.3386
Q Predictions Min            342.55045
V Predictions Mean           830.6066
V Predictions Std            930.6443
V Predictions Max            3125.4104
V Predictions Min            347.80884
Log Pis Mean                 -0.70839316
Log Pis Std                  3.050689
Log Pis Max                  10.095632
Log Pis Min                  -7.283415
Policy mu Mean               -0.009277181
Policy mu Std                0.79680413
Policy mu Max                2.5817778
Policy mu Min                -2.573068
Policy log std Mean          -0.50226146
Policy log std Std           0.25192925
Policy log std Max           -0.07432011
Policy log std Min           -1.7558663
Z mean eval                  1.8661534
Z variance eval              0.03001014
total_rewards                [7511.9200587  7757.97548768 7564.54341975 7816.57207708 7501.55720857
 7598.05298486 7670.92197814 7388.76429501 7783.13872595 7746.39036047]
total_rewards_mean           7633.983659621799
total_rewards_std            135.51428998122637
total_rewards_max            7816.572077081103
total_rewards_min            7388.7642950086865
Number of train steps total  496000
Number of env steps total    1490000
Number of rollouts total     0
Train Time (s)               144.69395993603393
(Previous) Eval Time (s)     18.111950328107923
Sample Time (s)              6.529921711422503
Epoch Time (s)               169.33583197556436
Total Train Time (s)         20919.647980194073
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:42:18.301764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #123 | Epoch Duration: 169.5900604724884
2020-01-12 13:42:18.301900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8668585
Z variance train             0.030100679
KL Divergence                38.71598
KL Loss                      3.871598
QF Loss                      123.925125
VF Loss                      71.89647
Policy Loss                  -822.16125
Q Predictions Mean           817.5211
Q Predictions Std            927.0445
Q Predictions Max            3347.0083
Q Predictions Min            333.78275
V Predictions Mean           824.85846
V Predictions Std            930.52094
V Predictions Max            3355.614
V Predictions Min            349.46088
Log Pis Mean                 -0.7038152
Log Pis Std                  3.5019002
Log Pis Max                  13.319337
Log Pis Min                  -6.827503
Policy mu Mean               -0.030598769
Policy mu Std                0.8222927
Policy mu Max                2.509315
Policy mu Min                -2.5011435
Policy log std Mean          -0.48704568
Policy log std Std           0.23211601
Policy log std Max           -0.017534494
Policy log std Min           -2.2193139
Z mean eval                  1.8611753
Z variance eval              0.042956673
total_rewards                [7158.5776788  7441.98159803 7610.96184775 7603.48293559 7465.75990392
 7448.14934091 7425.04757104 7328.79609936 7547.71176119 7761.80167228]
total_rewards_mean           7479.227040884897
total_rewards_std            157.55871054396033
total_rewards_max            7761.8016722779485
total_rewards_min            7158.577678798395
Number of train steps total  500000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               144.9111647461541
(Previous) Eval Time (s)     20.907197867985815
Sample Time (s)              6.4997995514422655
Epoch Time (s)               172.31816216558218
Total Train Time (s)         21092.048303894233
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:45:10.703282 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #124 | Epoch Duration: 172.40126848220825
2020-01-12 13:45:10.703413 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8614782
Z variance train             0.043078624
KL Divergence                38.983948
KL Loss                      3.8983948
QF Loss                      132.79178
VF Loss                      27.679815
Policy Loss                  -837.3461
Q Predictions Mean           834.04736
Q Predictions Std            924.0828
Q Predictions Max            3197.9822
Q Predictions Min            343.19736
V Predictions Mean           838.538
V Predictions Std            923.52747
V Predictions Max            3189.5955
V Predictions Min            348.5128
Log Pis Mean                 -0.8053962
Log Pis Std                  3.5824857
Log Pis Max                  14.84872
Log Pis Min                  -7.847331
Policy mu Mean               -0.0021737823
Policy mu Std                0.79881424
Policy mu Max                2.5370014
Policy mu Min                -2.7086208
Policy log std Mean          -0.5094947
Policy log std Std           0.25337514
Policy log std Max           -0.1044265
Policy log std Min           -2.1129277
Z mean eval                  1.8212658
Z variance eval              0.117605925
total_rewards                [7274.54397431 7507.9341275  7550.00978697 6708.83347136 7222.65774553
 7564.12971838 7780.65193232 7428.45137594 7646.75578639 7645.93901233]
total_rewards_mean           7432.990693103985
total_rewards_std            290.2047326280812
total_rewards_max            7780.651932322306
total_rewards_min            6708.83347136245
Number of train steps total  504000
Number of env steps total    1514000
Number of rollouts total     0
Train Time (s)               144.13820491638035
(Previous) Eval Time (s)     20.630569559056312
Sample Time (s)              6.479814467951655
Epoch Time (s)               171.2485889433883
Total Train Time (s)         21263.37870433787
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:48:02.035144 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #125 | Epoch Duration: 171.3316352367401
2020-01-12 13:48:02.035279 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8215317
Z variance train             0.11672181
KL Divergence                36.655712
KL Loss                      3.6655712
QF Loss                      149.31471
VF Loss                      57.795654
Policy Loss                  -790.8566
Q Predictions Mean           788.6205
Q Predictions Std            888.573
Q Predictions Max            3107.344
Q Predictions Min            336.46533
V Predictions Mean           789.4405
V Predictions Std            887.24396
V Predictions Max            3087.2327
V Predictions Min            334.96527
Log Pis Mean                 -0.9328411
Log Pis Std                  3.084996
Log Pis Max                  15.2427635
Log Pis Min                  -5.618156
Policy mu Mean               0.011956084
Policy mu Std                0.81133354
Policy mu Max                2.6818419
Policy mu Min                -2.7882009
Policy log std Mean          -0.48226514
Policy log std Std           0.22172473
Policy log std Max           -0.11087811
Policy log std Min           -1.7793108
Z mean eval                  1.8387039
Z variance eval              0.040755693
total_rewards                [7486.71964412 7554.35233355 7611.01301615 7596.06526303 7757.60126009
 7930.31481413 7651.93507861 8088.65644543 7723.9233414  7720.25936113]
total_rewards_mean           7712.0840557641595
total_rewards_std            171.66021022549253
total_rewards_max            8088.656445433169
total_rewards_min            7486.719644120486
Number of train steps total  508000
Number of env steps total    1526000
Number of rollouts total     0
Train Time (s)               144.77675651712343
(Previous) Eval Time (s)     21.065692697651684
Sample Time (s)              6.5065997168421745
Epoch Time (s)               172.3490489316173
Total Train Time (s)         21435.882258300204
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:50:54.541644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #126 | Epoch Duration: 172.50624990463257
2020-01-12 13:50:54.541836 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8380674
Z variance train             0.040642887
KL Divergence                38.916622
KL Loss                      3.8916624
QF Loss                      194.88496
VF Loss                      87.83928
Policy Loss                  -974.5589
Q Predictions Mean           971.0128
Q Predictions Std            1050.6014
Q Predictions Max            3262.919
Q Predictions Min            339.52295
V Predictions Mean           968.8373
V Predictions Std            1046.3478
V Predictions Max            3262.0293
V Predictions Min            354.64798
Log Pis Mean                 -0.57238156
Log Pis Std                  3.2350988
Log Pis Max                  10.612283
Log Pis Min                  -6.500764
Policy mu Mean               0.012811299
Policy mu Std                0.84010345
Policy mu Max                2.5021422
Policy mu Min                -2.7318747
Policy log std Mean          -0.509458
Policy log std Std           0.24321648
Policy log std Max           0.03963986
Policy log std Min           -2.086578
Z mean eval                  1.8115892
Z variance eval              0.03108282
total_rewards                [7191.94307909 7615.67641713 7547.94582077 7373.66623268 7586.27329538
 7623.90373134 7477.22216229 7591.17425389 7499.34255099 7716.16888631]
total_rewards_mean           7522.331642987978
total_rewards_std            141.38893519462454
total_rewards_max            7716.168886305765
total_rewards_min            7191.943079089541
Number of train steps total  512000
Number of env steps total    1538000
Number of rollouts total     0
Train Time (s)               144.1370548917912
(Previous) Eval Time (s)     20.85098352096975
Sample Time (s)              6.478341998066753
Epoch Time (s)               171.4663804108277
Total Train Time (s)         21607.430835161358
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:53:46.092195 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #127 | Epoch Duration: 171.55021810531616
2020-01-12 13:53:46.092402 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8122171
Z variance train             0.03117317
KL Divergence                38.859158
KL Loss                      3.8859158
QF Loss                      233.37181
VF Loss                      95.50447
Policy Loss                  -797.2854
Q Predictions Mean           791.7494
Q Predictions Std            899.7598
Q Predictions Max            3268.2913
Q Predictions Min            366.93994
V Predictions Mean           800.39795
V Predictions Std            900.7093
V Predictions Max            3257.6628
V Predictions Min            381.7176
Log Pis Mean                 -0.7087847
Log Pis Std                  3.3647661
Log Pis Max                  13.444852
Log Pis Min                  -6.998047
Policy mu Mean               -0.064943895
Policy mu Std                0.81896716
Policy mu Max                2.3753378
Policy mu Min                -3.73557
Policy log std Mean          -0.48617145
Policy log std Std           0.24131653
Policy log std Max           -0.056463778
Policy log std Min           -2.247407
Z mean eval                  1.8235004
Z variance eval              0.023325099
total_rewards                [7751.78022267 7798.52808675 7968.35544488 7968.19231113 7764.52487425
 7683.84035325 7748.49370311 8035.14914481 7803.66776556 7430.69401936]
total_rewards_mean           7795.322592575672
total_rewards_std            163.65838452198463
total_rewards_max            8035.149144807296
total_rewards_min            7430.694019356463
Number of train steps total  516000
Number of env steps total    1550000
Number of rollouts total     0
Train Time (s)               143.20219663484022
(Previous) Eval Time (s)     20.714538524858654
Sample Time (s)              6.450128743890673
Epoch Time (s)               170.36686390358955
Total Train Time (s)         21777.875229611527
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:56:36.539576 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #128 | Epoch Duration: 170.4470546245575
2020-01-12 13:56:36.539771 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #128 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8205944
Z variance train             0.023453532
KL Divergence                40.743225
KL Loss                      4.0743227
QF Loss                      160.72658
VF Loss                      131.05241
Policy Loss                  -911.08704
Q Predictions Mean           911.241
Q Predictions Std            992.3962
Q Predictions Max            3220.5186
Q Predictions Min            365.47995
V Predictions Mean           920.5656
V Predictions Std            992.7454
V Predictions Max            3212.403
V Predictions Min            366.4041
Log Pis Mean                 -0.6439873
Log Pis Std                  3.2368991
Log Pis Max                  9.578053
Log Pis Min                  -11.37783
Policy mu Mean               -0.0017846028
Policy mu Std                0.8324258
Policy mu Max                2.6144614
Policy mu Min                -2.4692621
Policy log std Mean          -0.51133484
Policy log std Std           0.22946976
Policy log std Max           -0.13155514
Policy log std Min           -2.0583744
Z mean eval                  1.8370826
Z variance eval              0.030623298
total_rewards                [7640.97996849 7889.21971027 7649.08786514 7715.28459926 7597.4073414
 7639.83981536 7802.0107001  7850.27472552 7738.4543739  7647.586168  ]
total_rewards_mean           7717.01452674545
total_rewards_std            95.17211369646141
total_rewards_max            7889.219710271635
total_rewards_min            7597.407341404327
Number of train steps total  520000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               143.66975891590118
(Previous) Eval Time (s)     20.85225556930527
Sample Time (s)              6.5533627942204475
Epoch Time (s)               171.0753772794269
Total Train Time (s)         21949.042452285532
Epoch                        129
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:59:27.708551 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #129 | Epoch Duration: 171.1686396598816
2020-01-12 13:59:27.708696 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8380425
Z variance train             0.030589228
KL Divergence                39.637558
KL Loss                      3.9637558
QF Loss                      93.968155
VF Loss                      88.51391
Policy Loss                  -747.33936
Q Predictions Mean           747.517
Q Predictions Std            846.2245
Q Predictions Max            3216.586
Q Predictions Min            359.0986
V Predictions Mean           752.58655
V Predictions Std            848.822
V Predictions Max            3235.0527
V Predictions Min            362.4839
Log Pis Mean                 -0.9413626
Log Pis Std                  2.9979014
Log Pis Max                  10.618308
Log Pis Min                  -9.213745
Policy mu Mean               0.015732126
Policy mu Std                0.7790319
Policy mu Max                2.5679026
Policy mu Min                -2.3806226
Policy log std Mean          -0.4887898
Policy log std Std           0.23163384
Policy log std Max           -0.122729495
Policy log std Min           -2.1167278
Z mean eval                  1.8479391
Z variance eval              0.039434493
total_rewards                [7518.24289452 7722.2800696  7487.77548143 7429.12490418 7534.34898487
 7595.98867163 7541.69724786 7842.08173045 7541.76695474 7555.94746377]
total_rewards_mean           7576.925440305493
total_rewards_std            113.91468859699445
total_rewards_max            7842.081730447569
total_rewards_min            7429.124904177288
Number of train steps total  524000
Number of env steps total    1574000
Number of rollouts total     0
Train Time (s)               144.15348891029134
(Previous) Eval Time (s)     21.195497625041753
Sample Time (s)              6.63826256012544
Epoch Time (s)               171.98724909545854
Total Train Time (s)         22121.121800510213
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:02:19.791947 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #130 | Epoch Duration: 172.08315181732178
2020-01-12 14:02:19.792084 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8479557
Z variance train             0.03931167
KL Divergence                40.496727
KL Loss                      4.0496726
QF Loss                      272.22638
VF Loss                      47.3463
Policy Loss                  -856.77423
Q Predictions Mean           854.355
Q Predictions Std            953.03064
Q Predictions Max            3343.5535
Q Predictions Min            353.79312
V Predictions Mean           854.06635
V Predictions Std            949.42175
V Predictions Max            3334.4053
V Predictions Min            363.1797
Log Pis Mean                 -0.90828675
Log Pis Std                  2.9493513
Log Pis Max                  7.690044
Log Pis Min                  -9.09857
Policy mu Mean               0.02511003
Policy mu Std                0.79105455
Policy mu Max                2.5866976
Policy mu Min                -2.3657818
Policy log std Mean          -0.4940451
Policy log std Std           0.2441639
Policy log std Max           -0.022918224
Policy log std Min           -2.1897302
Z mean eval                  1.8197031
Z variance eval              0.030518552
total_rewards                [7397.96665046 7649.09541633 7915.0043156  7765.18771479 7627.25943077
 7827.56519487 7710.38332706 7969.31939292 7694.64637516 7800.79599882]
total_rewards_mean           7735.722381678136
total_rewards_std            153.59822334520595
total_rewards_max            7969.319392924116
total_rewards_min            7397.966650457985
Number of train steps total  528000
Number of env steps total    1586000
Number of rollouts total     0
Train Time (s)               145.58651711791754
(Previous) Eval Time (s)     20.872083269059658
Sample Time (s)              6.608593183103949
Epoch Time (s)               173.06719357008114
Total Train Time (s)         22294.277156444732
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:05:12.949026 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #131 | Epoch Duration: 173.15684413909912
2020-01-12 14:05:12.949170 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8235648
Z variance train             0.0304652
KL Divergence                41.281204
KL Loss                      4.1281204
QF Loss                      127.10039
VF Loss                      80.68078
Policy Loss                  -754.76166
Q Predictions Mean           750.10455
Q Predictions Std            864.94574
Q Predictions Max            3372.2593
Q Predictions Min            372.61035
V Predictions Mean           749.95746
V Predictions Std            858.0941
V Predictions Max            3339.909
V Predictions Min            378.69513
Log Pis Mean                 -0.81891453
Log Pis Std                  3.7001386
Log Pis Max                  17.78699
Log Pis Min                  -8.732503
Policy mu Mean               0.018080527
Policy mu Std                0.79340297
Policy mu Max                2.7478158
Policy mu Min                -3.406079
Policy log std Mean          -0.48622373
Policy log std Std           0.24465686
Policy log std Max           -0.05609697
Policy log std Min           -2.1441226
Z mean eval                  1.757605
Z variance eval              0.037237816
total_rewards                [7881.07257994 7989.81708583 7748.93395641 7991.94951057 8036.47424324
 7992.47590822 7937.53559505 7796.07200675 7974.62970543 7720.89631594]
total_rewards_mean           7906.985690737131
total_rewards_std            107.81822820191258
total_rewards_max            8036.474243237045
total_rewards_min            7720.896315935052
Number of train steps total  532000
Number of env steps total    1598000
Number of rollouts total     0
Train Time (s)               145.1648423038423
(Previous) Eval Time (s)     17.34565239585936
Sample Time (s)              6.628798060119152
Epoch Time (s)               169.13929275982082
Total Train Time (s)         22463.5015640771
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:08:02.190374 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #132 | Epoch Duration: 169.24107193946838
2020-01-12 14:08:02.190614 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #132 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7576202
Z variance train             0.03711044
KL Divergence                39.628704
KL Loss                      3.9628704
QF Loss                      133.92921
VF Loss                      35.76013
Policy Loss                  -974.7502
Q Predictions Mean           973.4297
Q Predictions Std            1038.7949
Q Predictions Max            3383.1897
Q Predictions Min            348.99744
V Predictions Mean           972.7655
V Predictions Std            1034.924
V Predictions Max            3357.0515
V Predictions Min            363.0363
Log Pis Mean                 -0.3085651
Log Pis Std                  3.3882356
Log Pis Max                  11.054456
Log Pis Min                  -7.7440033
Policy mu Mean               0.008387041
Policy mu Std                0.8577038
Policy mu Max                2.9050498
Policy mu Min                -2.5795345
Policy log std Mean          -0.49943212
Policy log std Std           0.24152018
Policy log std Max           -0.02792567
Policy log std Min           -1.9152899
Z mean eval                  1.7823569
Z variance eval              0.037143327
total_rewards                [7567.33352302 7811.53495751 7297.08661684 7600.50484106 7771.3780742
 7626.71215382 7756.75518457 7923.49619689 7722.24997083 7699.87773602]
total_rewards_mean           7677.692925476066
total_rewards_std            161.68969699172405
total_rewards_max            7923.496196892963
total_rewards_min            7297.0866168355315
Number of train steps total  536000
Number of env steps total    1610000
Number of rollouts total     0
Train Time (s)               144.92839886480942
(Previous) Eval Time (s)     20.740257733967155
Sample Time (s)              6.547158513683826
Epoch Time (s)               172.2158151124604
Total Train Time (s)         22635.814114558045
Epoch                        133
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:10:54.490164 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #133 | Epoch Duration: 172.29934668540955
2020-01-12 14:10:54.490313 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7825352
Z variance train             0.03731131
KL Divergence                40.43791
KL Loss                      4.043791
QF Loss                      1477.6377
VF Loss                      119.07679
Policy Loss                  -904.93884
Q Predictions Mean           901.77795
Q Predictions Std            947.6556
Q Predictions Max            3289.3762
Q Predictions Min            376.32318
V Predictions Mean           898.86743
V Predictions Std            945.36224
V Predictions Max            3270.4958
V Predictions Min            371.70676
Log Pis Mean                 -0.44075337
Log Pis Std                  3.5242155
Log Pis Max                  18.338017
Log Pis Min                  -7.886421
Policy mu Mean               0.04639278
Policy mu Std                0.8351306
Policy mu Max                2.9326546
Policy mu Min                -3.1506448
Policy log std Mean          -0.5185037
Policy log std Std           0.22951162
Policy log std Max           -0.12466842
Policy log std Min           -1.7184132
Z mean eval                  1.7542607
Z variance eval              0.020346548
total_rewards                [7944.3257592  7951.87777148 7855.64003529 7914.91240557 7987.81542741
 8093.280855   7807.75311511 7827.78479155 7732.1812168  8253.40491732]
total_rewards_mean           7936.897629471519
total_rewards_std            143.2074207863683
total_rewards_max            8253.404917315227
total_rewards_min            7732.1812168032575
Number of train steps total  540000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               145.91817820305005
(Previous) Eval Time (s)     17.87191461166367
Sample Time (s)              6.513427016790956
Epoch Time (s)               170.30351983150467
Total Train Time (s)         22806.203911382705
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:13:44.882971 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #134 | Epoch Duration: 170.3925404548645
2020-01-12 14:13:44.883176 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7522285
Z variance train             0.020341175
KL Divergence                41.112865
KL Loss                      4.1112866
QF Loss                      94.04376
VF Loss                      36.160748
Policy Loss                  -858.77277
Q Predictions Mean           854.3943
Q Predictions Std            947.5762
Q Predictions Max            3205.154
Q Predictions Min            326.87268
V Predictions Mean           857.1903
V Predictions Std            947.2093
V Predictions Max            3216.1804
V Predictions Min            342.64603
Log Pis Mean                 -0.730898
Log Pis Std                  3.1874325
Log Pis Max                  10.018614
Log Pis Min                  -6.873829
Policy mu Mean               0.0051218886
Policy mu Std                0.8281799
Policy mu Max                2.444793
Policy mu Min                -2.4050725
Policy log std Mean          -0.5197401
Policy log std Std           0.24925742
Policy log std Max           0.027904749
Policy log std Min           -1.8916998
Z mean eval                  1.7438694
Z variance eval              0.061626665
total_rewards                [7117.68505309 7603.99170577 7584.44224309 7338.99471001 7264.31043503
 7223.47613799 7249.63332826 7418.92431003 7387.40662598 6679.95566024]
total_rewards_mean           7286.882020950361
total_rewards_std            249.45163890752735
total_rewards_max            7603.991705768416
total_rewards_min            6679.9556602420735
Number of train steps total  544000
Number of env steps total    1634000
Number of rollouts total     0
Train Time (s)               145.06978103285655
(Previous) Eval Time (s)     21.062059884890914
Sample Time (s)              6.496819732710719
Epoch Time (s)               172.6286606504582
Total Train Time (s)         22978.912667525932
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:16:37.593020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #135 | Epoch Duration: 172.7096869945526
2020-01-12 14:16:37.593200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7433312
Z variance train             0.061525095
KL Divergence                39.24685
KL Loss                      3.924685
QF Loss                      114.83
VF Loss                      28.056816
Policy Loss                  -825.9537
Q Predictions Mean           822.30676
Q Predictions Std            914.09955
Q Predictions Max            3260.5317
Q Predictions Min            352.80777
V Predictions Mean           826.3916
V Predictions Std            914.51337
V Predictions Max            3261.9443
V Predictions Min            352.82248
Log Pis Mean                 -1.2569757
Log Pis Std                  3.0577667
Log Pis Max                  15.1072235
Log Pis Min                  -6.422102
Policy mu Mean               0.0202483
Policy mu Std                0.7696679
Policy mu Max                2.6683629
Policy mu Min                -2.4379058
Policy log std Mean          -0.48846373
Policy log std Std           0.23951235
Policy log std Max           -0.053191185
Policy log std Min           -1.9285353
Z mean eval                  1.728949
Z variance eval              0.027616441
total_rewards                [7612.87997847 7828.63250911 7691.70914418 7700.16060753 7952.91692192
 7657.40032278 7812.63787619 7754.90720842 7612.7274899  7685.72470905]
total_rewards_mean           7730.969676755973
total_rewards_std            101.94010270033357
total_rewards_max            7952.91692191959
total_rewards_min            7612.727489899622
Number of train steps total  548000
Number of env steps total    1646000
Number of rollouts total     0
Train Time (s)               144.42203078093007
(Previous) Eval Time (s)     20.776827164459974
Sample Time (s)              6.510994164273143
Epoch Time (s)               171.7098521096632
Total Train Time (s)         23150.85191868851
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:19:29.543911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #136 | Epoch Duration: 171.95056653022766
2020-01-12 14:19:29.544093 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7306238
Z variance train             0.027589971
KL Divergence                42.04811
KL Loss                      4.204811
QF Loss                      169.19385
VF Loss                      89.48551
Policy Loss                  -928.0183
Q Predictions Mean           925.94775
Q Predictions Std            996.8748
Q Predictions Max            3348.1921
Q Predictions Min            382.79813
V Predictions Mean           929.59546
V Predictions Std            998.4992
V Predictions Max            3351.2595
V Predictions Min            382.09912
Log Pis Mean                 -0.5398996
Log Pis Std                  3.2918835
Log Pis Max                  13.204885
Log Pis Min                  -7.302284
Policy mu Mean               -0.017130135
Policy mu Std                0.8295032
Policy mu Max                2.6592708
Policy mu Min                -2.7927608
Policy log std Mean          -0.5225695
Policy log std Std           0.2628406
Policy log std Max           -0.04151994
Policy log std Min           -2.1002548
Z mean eval                  1.6812592
Z variance eval              0.025864538
total_rewards                [7377.15145713 7470.03544018 7664.36614661 7508.59010866 7525.81416817
 7584.33098895 7635.74159948 7458.48776678 7437.95551676 7449.2646189 ]
total_rewards_mean           7511.173781162911
total_rewards_std            87.28221852058482
total_rewards_max            7664.366146605943
total_rewards_min            7377.151457132921
Number of train steps total  552000
Number of env steps total    1658000
Number of rollouts total     0
Train Time (s)               143.812108641956
(Previous) Eval Time (s)     17.4887810270302
Sample Time (s)              5.673709979280829
Epoch Time (s)               166.97459964826703
Total Train Time (s)         23317.917296231724
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:22:16.604091 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #137 | Epoch Duration: 167.05982613563538
2020-01-12 14:22:16.604378 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6811397
Z variance train             0.025929365
KL Divergence                41.697178
KL Loss                      4.169718
QF Loss                      1767.4293
VF Loss                      144.35196
Policy Loss                  -876.65405
Q Predictions Mean           879.4187
Q Predictions Std            960.37305
Q Predictions Max            3443.4258
Q Predictions Min            387.0552
V Predictions Mean           866.4966
V Predictions Std            954.21
V Predictions Max            3393.4272
V Predictions Min            382.9134
Log Pis Mean                 -0.8673366
Log Pis Std                  3.1024299
Log Pis Max                  12.520013
Log Pis Min                  -6.6202993
Policy mu Mean               0.0067869616
Policy mu Std                0.7825978
Policy mu Max                2.4569364
Policy mu Min                -2.6164176
Policy log std Mean          -0.50242925
Policy log std Std           0.24937904
Policy log std Max           -0.12986861
Policy log std Min           -1.8865056
Z mean eval                  1.7189758
Z variance eval              0.037884094
total_rewards                [7655.99150435 8070.7595127  2245.05594351 1965.09104499 3555.83140443
 8313.42508517 8020.45867633 7955.39379837 8035.1032499  7967.98008008]
total_rewards_mean           6378.509029982279
total_rewards_std            2514.439537110721
total_rewards_max            8313.425085166607
total_rewards_min            1965.091044985128
Number of train steps total  556000
Number of env steps total    1670000
Number of rollouts total     0
Train Time (s)               144.8537277309224
(Previous) Eval Time (s)     20.79012955306098
Sample Time (s)              6.458876014687121
Epoch Time (s)               172.1027332986705
Total Train Time (s)         23490.1010904368
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:25:08.787562 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #138 | Epoch Duration: 172.18297958374023
2020-01-12 14:25:08.787697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7218851
Z variance train             0.037715405
KL Divergence                42.475815
KL Loss                      4.2475815
QF Loss                      125.01979
VF Loss                      221.5585
Policy Loss                  -835.0908
Q Predictions Mean           831.423
Q Predictions Std            928.86206
Q Predictions Max            3451.9705
Q Predictions Min            380.3439
V Predictions Mean           821.80566
V Predictions Std            923.9096
V Predictions Max            3402.9802
V Predictions Min            385.3197
Log Pis Mean                 -0.7199174
Log Pis Std                  3.513939
Log Pis Max                  12.84791
Log Pis Min                  -7.2545214
Policy mu Mean               0.037523832
Policy mu Std                0.8159522
Policy mu Max                2.5374956
Policy mu Min                -2.8244612
Policy log std Mean          -0.49065864
Policy log std Std           0.23238008
Policy log std Max           -0.105009764
Policy log std Min           -1.9795783
Z mean eval                  1.705257
Z variance eval              0.017931748
total_rewards                [7729.36060135 7923.53621912 7807.07155965 7793.84426823 7942.65444242
 7870.73379172 7779.94549926 8228.05877882 7929.44083617 8183.05282024]
total_rewards_mean           7918.769881696554
total_rewards_std            158.66651430012783
total_rewards_max            8228.058778816141
total_rewards_min            7729.360601348091
Number of train steps total  560000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               144.2350407759659
(Previous) Eval Time (s)     20.72712330520153
Sample Time (s)              6.496301501523703
Epoch Time (s)               171.45846558269113
Total Train Time (s)         23661.656405152287
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:28:00.346687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #139 | Epoch Duration: 171.5588402748108
2020-01-12 14:28:00.346923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7078613
Z variance train             0.017957583
KL Divergence                44.437557
KL Loss                      4.4437556
QF Loss                      154.91199
VF Loss                      68.56824
Policy Loss                  -962.73395
Q Predictions Mean           960.1465
Q Predictions Std            1021.94604
Q Predictions Max            3434.551
Q Predictions Min            392.46188
V Predictions Mean           958.04315
V Predictions Std            1020.32684
V Predictions Max            3418.9783
V Predictions Min            385.89203
Log Pis Mean                 -0.27193367
Log Pis Std                  3.2791479
Log Pis Max                  12.361637
Log Pis Min                  -6.551708
Policy mu Mean               0.0127997175
Policy mu Std                0.8657557
Policy mu Max                2.821607
Policy mu Min                -3.3552132
Policy log std Mean          -0.50450176
Policy log std Std           0.23145266
Policy log std Max           -0.09376097
Policy log std Min           -1.8115304
Z mean eval                  1.6705122
Z variance eval              0.026523083
total_rewards                [7599.08982906 7823.06249443 7565.48927858 7825.88369551 7591.76505827
 7632.69361859 7555.71878536 7755.46039005 7562.97507837 7974.6254303 ]
total_rewards_mean           7688.676365852504
total_rewards_std            138.67864423690102
total_rewards_max            7974.6254303041005
total_rewards_min            7555.718785360357
Number of train steps total  564000
Number of env steps total    1694000
Number of rollouts total     0
Train Time (s)               144.3819398516789
(Previous) Eval Time (s)     17.3527836878784
Sample Time (s)              6.581952096428722
Epoch Time (s)               168.31667563598603
Total Train Time (s)         23830.049204952084
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:30:48.743985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #140 | Epoch Duration: 168.39689111709595
2020-01-12 14:30:48.744156 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #140 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6724755
Z variance train             0.026457597
KL Divergence                42.818604
KL Loss                      4.2818604
QF Loss                      212.34251
VF Loss                      135.14429
Policy Loss                  -939.9152
Q Predictions Mean           936.70435
Q Predictions Std            1014.29156
Q Predictions Max            3321.5918
Q Predictions Min            370.92145
V Predictions Mean           937.4798
V Predictions Std            1013.2774
V Predictions Max            3303.4026
V Predictions Min            374.76117
Log Pis Mean                 -0.6871144
Log Pis Std                  3.2557454
Log Pis Max                  13.116561
Log Pis Min                  -5.780411
Policy mu Mean               -0.07012439
Policy mu Std                0.83426267
Policy mu Max                3.516344
Policy mu Min                -2.5265033
Policy log std Mean          -0.51904243
Policy log std Std           0.26120734
Policy log std Max           -0.09599924
Policy log std Min           -2.169716
Z mean eval                  1.6975071
Z variance eval              0.042786114
total_rewards                [7822.48092932 7963.63732946 7960.46507618 8081.4886635  7926.4575578
 7718.57177261 7926.617254   7555.4719304  8040.40341715 8069.8527669 ]
total_rewards_mean           7906.54466973322
total_rewards_std            157.42048926383583
total_rewards_max            8081.488663503195
total_rewards_min            7555.471930399506
Number of train steps total  568000
Number of env steps total    1706000
Number of rollouts total     0
Train Time (s)               143.56427943194285
(Previous) Eval Time (s)     17.456223923247308
Sample Time (s)              5.601957100909203
Epoch Time (s)               166.62246045609936
Total Train Time (s)         23996.752792484593
Epoch                        141
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:33:35.449086 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #141 | Epoch Duration: 166.70479369163513
2020-01-12 14:33:35.449264 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7005589
Z variance train             0.04286251
KL Divergence                40.545593
KL Loss                      4.054559
QF Loss                      115.20897
VF Loss                      64.20511
Policy Loss                  -873.6405
Q Predictions Mean           871.32886
Q Predictions Std            969.471
Q Predictions Max            3401.6274
Q Predictions Min            395.1911
V Predictions Mean           871.6726
V Predictions Std            966.0788
V Predictions Max            3389.8289
V Predictions Min            397.75433
Log Pis Mean                 -0.8109594
Log Pis Std                  3.3118546
Log Pis Max                  12.546728
Log Pis Min                  -8.114454
Policy mu Mean               0.020435216
Policy mu Std                0.8312705
Policy mu Max                2.6438537
Policy mu Min                -2.7610672
Policy log std Mean          -0.48820606
Policy log std Std           0.23731178
Policy log std Max           -0.057269335
Policy log std Min           -1.8393135
Z mean eval                  1.6875916
Z variance eval              0.06020399
total_rewards                [7761.20754889 8237.20550767 8100.50827142 8114.43361214 8149.25941424
 8261.25916381 7898.71588142 7889.82849439 8199.70635419 8049.27487356]
total_rewards_mean           8066.139912174387
total_rewards_std            157.47443277164214
total_rewards_max            8261.259163808392
total_rewards_min            7761.207548891672
Number of train steps total  572000
Number of env steps total    1718000
Number of rollouts total     0
Train Time (s)               144.45822208793834
(Previous) Eval Time (s)     20.775319639593363
Sample Time (s)              6.494182187598199
Epoch Time (s)               171.7277239151299
Total Train Time (s)         24168.55801911885
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:36:27.254923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #142 | Epoch Duration: 171.8055284023285
2020-01-12 14:36:27.255064 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #142 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6896021
Z variance train             0.060075562
KL Divergence                40.33764
KL Loss                      4.033764
QF Loss                      189.56665
VF Loss                      130.34213
Policy Loss                  -902.52246
Q Predictions Mean           901.5034
Q Predictions Std            989.2753
Q Predictions Max            3351.882
Q Predictions Min            -37.8254
V Predictions Mean           895.41144
V Predictions Std            982.9141
V Predictions Max            3335.178
V Predictions Min            -214.0032
Log Pis Mean                 -0.8451228
Log Pis Std                  3.2761903
Log Pis Max                  12.555388
Log Pis Min                  -8.651445
Policy mu Mean               -0.036097694
Policy mu Std                0.810494
Policy mu Max                2.594103
Policy mu Min                -3.5895154
Policy log std Mean          -0.4847399
Policy log std Std           0.2377035
Policy log std Max           1.291451
Policy log std Min           -1.7998374
Z mean eval                  1.7047834
Z variance eval              0.030617535
total_rewards                [8066.2851058  8135.31650548 8126.91911162 8042.00357605 8213.3063808
 8138.23561531 8019.70712105 7888.50909691 7792.18019781 8210.1312531 ]
total_rewards_mean           8063.259396392452
total_rewards_std            128.5811121867668
total_rewards_max            8213.306380795511
total_rewards_min            7792.18019781153
Number of train steps total  576000
Number of env steps total    1730000
Number of rollouts total     0
Train Time (s)               145.63712676102296
(Previous) Eval Time (s)     21.089483039919287
Sample Time (s)              6.348131220322102
Epoch Time (s)               173.07474102126434
Total Train Time (s)         24341.711929821875
Epoch                        143
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:39:20.410298 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #143 | Epoch Duration: 173.15513491630554
2020-01-12 14:39:20.410439 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.704064
Z variance train             0.030686613
KL Divergence                42.12398
KL Loss                      4.212398
QF Loss                      113.489235
VF Loss                      45.46874
Policy Loss                  -1010.97015
Q Predictions Mean           1008.9187
Q Predictions Std            1047.8348
Q Predictions Max            3357.4624
Q Predictions Min            400.6333
V Predictions Mean           1009.1583
V Predictions Std            1048.1937
V Predictions Max            3351.5803
V Predictions Min            404.53513
Log Pis Mean                 -0.32177144
Log Pis Std                  3.538132
Log Pis Max                  16.532534
Log Pis Min                  -7.637881
Policy mu Mean               0.020259513
Policy mu Std                0.86021394
Policy mu Max                3.0817642
Policy mu Min                -3.2480564
Policy log std Mean          -0.5148467
Policy log std Std           0.25031292
Policy log std Max           -0.1017762
Policy log std Min           -2.1335037
Z mean eval                  1.6947591
Z variance eval              0.027009126
total_rewards                [8047.00475501 7568.39073529 8183.222503   8404.10145962 8132.54909948
 8200.20613759 8215.7009197  7886.8765491  8364.38421852 8050.43495691]
total_rewards_mean           8105.287133420633
total_rewards_std            229.5225003774886
total_rewards_max            8404.101459616077
total_rewards_min            7568.39073529063
Number of train steps total  580000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               144.97247170098126
(Previous) Eval Time (s)     17.71156317880377
Sample Time (s)              6.4146450138650835
Epoch Time (s)               169.09867989365011
Total Train Time (s)         24510.892487373203
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:42:09.594548 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #144 | Epoch Duration: 169.18398070335388
2020-01-12 14:42:09.594817 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #144 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.695317
Z variance train             0.0269678
KL Divergence                44.231728
KL Loss                      4.423173
QF Loss                      191.128
VF Loss                      48.93306
Policy Loss                  -1007.4997
Q Predictions Mean           1006.8425
Q Predictions Std            1065.3776
Q Predictions Max            3397.6692
Q Predictions Min            414.46292
V Predictions Mean           1003.80365
V Predictions Std            1061.5966
V Predictions Max            3369.1838
V Predictions Min            414.07217
Log Pis Mean                 -0.34204376
Log Pis Std                  3.390381
Log Pis Max                  11.930021
Log Pis Min                  -6.46827
Policy mu Mean               0.012326922
Policy mu Std                0.85887545
Policy mu Max                2.5322452
Policy mu Min                -2.492989
Policy log std Mean          -0.51445174
Policy log std Std           0.25449014
Policy log std Max           -0.062910855
Policy log std Min           -2.1959438
Z mean eval                  1.6749115
Z variance eval              0.035684813
total_rewards                [7794.33898786 7300.87560858 8461.92328295 8108.01400382 8127.2587326
 8413.23290417 8218.19622205 7924.93592859 7921.8125087  7480.93612209]
total_rewards_mean           7975.152430140026
total_rewards_std            355.7637574371275
total_rewards_max            8461.923282951328
total_rewards_min            7300.875608579461
Number of train steps total  584000
Number of env steps total    1754000
Number of rollouts total     0
Train Time (s)               144.5382714830339
(Previous) Eval Time (s)     20.85779401101172
Sample Time (s)              6.625020549166948
Epoch Time (s)               172.02108604321256
Total Train Time (s)         24682.995791705325
Epoch                        145
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:45:01.697795 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #145 | Epoch Duration: 172.10280060768127
2020-01-12 14:45:01.697924 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6735172
Z variance train             0.035613935
KL Divergence                42.52622
KL Loss                      4.252622
QF Loss                      255.3846
VF Loss                      54.65725
Policy Loss                  -946.40344
Q Predictions Mean           944.51465
Q Predictions Std            1009.6555
Q Predictions Max            3366.6094
Q Predictions Min            405.49487
V Predictions Mean           947.6812
V Predictions Std            1008.7205
V Predictions Max            3344.1775
V Predictions Min            407.7072
Log Pis Mean                 -0.67166626
Log Pis Std                  3.4005477
Log Pis Max                  19.14407
Log Pis Min                  -8.47286
Policy mu Mean               0.05054474
Policy mu Std                0.83535284
Policy mu Max                2.9949129
Policy mu Min                -2.993559
Policy log std Mean          -0.50306886
Policy log std Std           0.24255756
Policy log std Max           0.13695478
Policy log std Min           -2.1443942
Z mean eval                  1.6885169
Z variance eval              0.054299813
total_rewards                [8070.53551971 7833.99562536 8110.71489802 8028.12992089 8164.66064777
 8206.10809325 8162.95653143 8005.88883926 8306.53690481 8258.89763593]
total_rewards_mean           8114.842461644772
total_rewards_std            130.71722440527535
total_rewards_max            8306.536904810138
total_rewards_min            7833.99562536325
Number of train steps total  588000
Number of env steps total    1766000
Number of rollouts total     0
Train Time (s)               144.33919181581587
(Previous) Eval Time (s)     17.89652494667098
Sample Time (s)              6.5246032061986625
Epoch Time (s)               168.7603199686855
Total Train Time (s)         24851.830140058417
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:47:50.532898 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #146 | Epoch Duration: 168.83488082885742
2020-01-12 14:47:50.533016 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6845795
Z variance train             0.054148454
KL Divergence                41.15885
KL Loss                      4.1158853
QF Loss                      1865.0337
VF Loss                      160.36479
Policy Loss                  -873.4857
Q Predictions Mean           878.23566
Q Predictions Std            966.9287
Q Predictions Max            3396.9275
Q Predictions Min            410.0483
V Predictions Mean           882.6689
V Predictions Std            969.22736
V Predictions Max            3403.336
V Predictions Min            415.13788
Log Pis Mean                 -0.88807666
Log Pis Std                  3.4574506
Log Pis Max                  17.322197
Log Pis Min                  -6.8684244
Policy mu Mean               -0.057982665
Policy mu Std                0.81074435
Policy mu Max                2.4160388
Policy mu Min                -2.4674015
Policy log std Mean          -0.48417187
Policy log std Std           0.24627773
Policy log std Max           -0.07049495
Policy log std Min           -2.2624598
Z mean eval                  1.6995739
Z variance eval              0.034144156
total_rewards                [7859.22454082 8193.77730818 8013.94709021 7893.8453172  7969.60654873
 7947.76834788 8168.4819226  8004.80341609 7894.78993762 7613.99045009]
total_rewards_mean           7956.023487942997
total_rewards_std            155.44293010992695
total_rewards_max            8193.777308182089
total_rewards_min            7613.990450090866
Number of train steps total  592000
Number of env steps total    1778000
Number of rollouts total     0
Train Time (s)               142.9382596379146
(Previous) Eval Time (s)     20.754752404987812
Sample Time (s)              5.592764784581959
Epoch Time (s)               169.28577682748437
Total Train Time (s)         25021.19689891627
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:50:39.902128 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #147 | Epoch Duration: 169.3690047264099
2020-01-12 14:50:39.902318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #147 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6993278
Z variance train             0.03419941
KL Divergence                42.05922
KL Loss                      4.205922
QF Loss                      127.78282
VF Loss                      82.48812
Policy Loss                  -968.53265
Q Predictions Mean           967.4706
Q Predictions Std            1025.1672
Q Predictions Max            3507.7
Q Predictions Min            410.52313
V Predictions Mean           967.31824
V Predictions Std            1018.34875
V Predictions Max            3496.1433
V Predictions Min            416.84415
Log Pis Mean                 -0.7544557
Log Pis Std                  3.5216048
Log Pis Max                  13.356436
Log Pis Min                  -6.9355893
Policy mu Mean               -0.013523284
Policy mu Std                0.82396203
Policy mu Max                2.5335357
Policy mu Min                -2.59347
Policy log std Mean          -0.4910238
Policy log std Std           0.23108871
Policy log std Max           -0.083204165
Policy log std Min           -1.9751276
Z mean eval                  1.7093856
Z variance eval              0.06678541
total_rewards                [8372.47539888 8305.17977573 8115.75673478 8009.44016377 8122.9854833
 8193.21883932 8217.34464894 7989.21889769 8407.38607461 8120.50726524]
total_rewards_mean           8185.351328225724
total_rewards_std            134.94795300136974
total_rewards_max            8407.38607460596
total_rewards_min            7989.218897694061
Number of train steps total  596000
Number of env steps total    1790000
Number of rollouts total     0
Train Time (s)               143.79131935117766
(Previous) Eval Time (s)     20.44189016101882
Sample Time (s)              6.652902956586331
Epoch Time (s)               170.8861124687828
Total Train Time (s)         25192.165222160518
Epoch                        148
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:53:30.871925 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #148 | Epoch Duration: 170.96947979927063
2020-01-12 14:53:30.872070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7067196
Z variance train             0.06699556
KL Divergence                41.9236
KL Loss                      4.19236
QF Loss                      117.38296
VF Loss                      54.455948
Policy Loss                  -954.1566
Q Predictions Mean           952.3406
Q Predictions Std            1012.92316
Q Predictions Max            3471.4036
Q Predictions Min            403.38727
V Predictions Mean           958.19775
V Predictions Std            1011.96454
V Predictions Max            3453.7761
V Predictions Min            412.05
Log Pis Mean                 -0.9010433
Log Pis Std                  3.287745
Log Pis Max                  16.721191
Log Pis Min                  -9.495697
Policy mu Mean               0.031325307
Policy mu Std                0.8124128
Policy mu Max                2.7134693
Policy mu Min                -2.8730044
Policy log std Mean          -0.4850712
Policy log std Std           0.2469268
Policy log std Max           -0.08359355
Policy log std Min           -2.003707
Z mean eval                  1.715669
Z variance eval              0.090698436
total_rewards                [7748.58073103 6361.36515373 8195.59929725 7651.27935657 8296.16102852
 7694.80208715 8164.96740115 8046.92387212 7678.53043689 7984.44784922]
total_rewards_mean           7782.26572136293
total_rewards_std            524.211463341087
total_rewards_max            8296.161028523882
total_rewards_min            6361.365153725585
Number of train steps total  600000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               145.54839417291805
(Previous) Eval Time (s)     17.664936828892678
Sample Time (s)              6.532973472028971
Epoch Time (s)               169.7463044738397
Total Train Time (s)         25361.99229719583
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:56:20.703049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #149 | Epoch Duration: 169.83085560798645
2020-01-12 14:56:20.703257 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7178047
Z variance train             0.090257175
KL Divergence                40.92842
KL Loss                      4.092842
QF Loss                      175.07375
VF Loss                      136.16455
Policy Loss                  -986.78674
Q Predictions Mean           985.84875
Q Predictions Std            1042.5785
Q Predictions Max            3481.0479
Q Predictions Min            426.7741
V Predictions Mean           981.5595
V Predictions Std            1036.049
V Predictions Max            3461.1594
V Predictions Min            425.38358
Log Pis Mean                 -0.65893745
Log Pis Std                  3.4786277
Log Pis Max                  13.423782
Log Pis Min                  -7.2981043
Policy mu Mean               0.07259724
Policy mu Std                0.8542108
Policy mu Max                3.1013567
Policy mu Min                -2.3794746
Policy log std Mean          -0.501889
Policy log std Std           0.24229398
Policy log std Max           0.16486758
Policy log std Min           -2.094708
Z mean eval                  1.7175245
Z variance eval              0.083317116
total_rewards                [8167.88559685 8560.58897746 8351.27164624 8474.53364765 8248.41556732
 8340.90596232 8366.69041814 8209.67102664 8382.10477929 8013.19984604]
total_rewards_mean           8311.52674679435
total_rewards_std            149.3518186974628
total_rewards_max            8560.588977455489
total_rewards_min            8013.199846044453
Number of train steps total  604000
Number of env steps total    1814000
Number of rollouts total     0
Train Time (s)               142.83142576320097
(Previous) Eval Time (s)     17.749417902436107
Sample Time (s)              6.607822792604566
Epoch Time (s)               167.18866645824164
Total Train Time (s)         25529.259678859264
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:59:07.975577 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #150 | Epoch Duration: 167.272141456604
2020-01-12 14:59:07.975853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7179791
Z variance train             0.08380818
KL Divergence                40.16949
KL Loss                      4.016949
QF Loss                      1820.9321
VF Loss                      77.984406
Policy Loss                  -868.7331
Q Predictions Mean           868.7505
Q Predictions Std            920.84644
Q Predictions Max            3464.788
Q Predictions Min            414.7245
V Predictions Mean           875.4043
V Predictions Std            923.4088
V Predictions Max            3488.4612
V Predictions Min            421.67474
Log Pis Mean                 -0.89485383
Log Pis Std                  2.8976307
Log Pis Max                  12.021347
Log Pis Min                  -6.5136757
Policy mu Mean               -0.037747316
Policy mu Std                0.78664505
Policy mu Max                2.3581557
Policy mu Min                -2.7024503
Policy log std Mean          -0.49788514
Policy log std Std           0.24290256
Policy log std Max           0.011012733
Policy log std Min           -1.9909074
Z mean eval                  1.6884816
Z variance eval              0.07300848
total_rewards                [8115.59048734 8309.91026612 8316.04341789 5404.62943859 8199.53613459
 8583.06666864 8097.05125076 8220.6344292  8161.87534571 7937.79186665]
total_rewards_mean           7934.6129305484865
total_rewards_std            858.5124357528223
total_rewards_max            8583.066668639794
total_rewards_min            5404.629438591676
Number of train steps total  608000
Number of env steps total    1826000
Number of rollouts total     0
Train Time (s)               144.23151679104194
(Previous) Eval Time (s)     18.06207419699058
Sample Time (s)              6.582823527511209
Epoch Time (s)               168.87641451554373
Total Train Time (s)         25698.40862738993
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:01:57.142585 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #151 | Epoch Duration: 169.16652417182922
2020-01-12 15:01:57.142844 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.686836
Z variance train             0.0731434
KL Divergence                39.18359
KL Loss                      3.918359
QF Loss                      125.93544
VF Loss                      62.008263
Policy Loss                  -1010.30054
Q Predictions Mean           1006.9208
Q Predictions Std            1051.7389
Q Predictions Max            3697.2412
Q Predictions Min            427.8624
V Predictions Mean           1010.87366
V Predictions Std            1049.6222
V Predictions Max            3678.5056
V Predictions Min            438.3128
Log Pis Mean                 -0.7162546
Log Pis Std                  3.2384782
Log Pis Max                  12.120918
Log Pis Min                  -7.180093
Policy mu Mean               0.040409535
Policy mu Std                0.81921166
Policy mu Max                2.7138135
Policy mu Min                -2.8687184
Policy log std Mean          -0.48667845
Policy log std Std           0.24769405
Policy log std Max           -0.08386749
Policy log std Min           -2.1219926
Z mean eval                  1.6921375
Z variance eval              0.040080428
total_rewards                [8238.45074808 8551.36852417 8340.33021775 8493.60408402 8345.14772428
 8451.59515246 2590.3589485  8534.67624352 8563.24927174 8689.25094588]
total_rewards_mean           7879.803186040503
total_rewards_std            1767.5219843044065
total_rewards_max            8689.250945882563
total_rewards_min            2590.358948500473
Number of train steps total  612000
Number of env steps total    1838000
Number of rollouts total     0
Train Time (s)               142.83559004683048
(Previous) Eval Time (s)     17.5953217279166
Sample Time (s)              6.655787009745836
Epoch Time (s)               167.0866987844929
Total Train Time (s)         25865.605095817707
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:04:44.332549 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #152 | Epoch Duration: 167.18949699401855
2020-01-12 15:04:44.332879 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.693256
Z variance train             0.039960526
KL Divergence                41.038578
KL Loss                      4.103858
QF Loss                      136.55568
VF Loss                      66.44627
Policy Loss                  -942.7849
Q Predictions Mean           941.016
Q Predictions Std            1012.2404
Q Predictions Max            3522.7097
Q Predictions Min            412.33347
V Predictions Mean           942.74115
V Predictions Std            1011.7556
V Predictions Max            3520.0256
V Predictions Min            418.80405
Log Pis Mean                 -0.40801388
Log Pis Std                  3.3802607
Log Pis Max                  15.222777
Log Pis Min                  -7.1442385
Policy mu Mean               0.07008668
Policy mu Std                0.8282158
Policy mu Max                3.059695
Policy mu Min                -2.3629947
Policy log std Mean          -0.50592726
Policy log std Std           0.25840732
Policy log std Max           -0.048333526
Policy log std Min           -2.3577027
Z mean eval                  1.6963199
Z variance eval              0.04144279
total_rewards                [8253.8986913  8382.55545374 8290.22866372 8398.21415992 8497.28918823
 8213.24626783 8567.89602969 8591.49202666 8571.89852553 8200.77476557]
total_rewards_mean           8396.749377219861
total_rewards_std            145.61503610956134
total_rewards_max            8591.492026664331
total_rewards_min            8200.774765567403
Number of train steps total  616000
Number of env steps total    1850000
Number of rollouts total     0
Train Time (s)               144.7978356280364
(Previous) Eval Time (s)     18.97120857099071
Sample Time (s)              6.41348764160648
Epoch Time (s)               170.1825318406336
Total Train Time (s)         26035.876702698413
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:07:34.601915 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #153 | Epoch Duration: 170.26880526542664
2020-01-12 15:07:34.602085 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6955321
Z variance train             0.04150478
KL Divergence                41.28817
KL Loss                      4.128817
QF Loss                      143.51904
VF Loss                      67.00545
Policy Loss                  -971.3444
Q Predictions Mean           969.0608
Q Predictions Std            1012.7698
Q Predictions Max            3600.9263
Q Predictions Min            431.1245
V Predictions Mean           969.1841
V Predictions Std            1012.0774
V Predictions Max            3585.1094
V Predictions Min            431.19998
Log Pis Mean                 -0.63043904
Log Pis Std                  3.3967545
Log Pis Max                  11.379036
Log Pis Min                  -6.421377
Policy mu Mean               0.05623454
Policy mu Std                0.8380802
Policy mu Max                2.9975736
Policy mu Min                -3.0059075
Policy log std Mean          -0.5071673
Policy log std Std           0.2574827
Policy log std Max           -0.083399095
Policy log std Min           -2.121602
Z mean eval                  1.6824646
Z variance eval              0.03998089
total_rewards                [5943.84393829 7112.13828745 6304.53690215 6150.57977367 6837.87557596
 6697.69185472 6641.25379834 6296.21262397 5408.17388127 7632.39623994]
total_rewards_mean           6502.470287575382
total_rewards_std            594.4233814480615
total_rewards_max            7632.396239935801
total_rewards_min            5408.173881268125
Number of train steps total  620000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               144.73534564767033
(Previous) Eval Time (s)     17.482065471820533
Sample Time (s)              6.440991132054478
Epoch Time (s)               168.65840225154534
Total Train Time (s)         26204.624225288164
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:10:23.352315 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #154 | Epoch Duration: 168.75010299682617
2020-01-12 15:10:23.352477 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6773704
Z variance train             0.03989289
KL Divergence                41.444878
KL Loss                      4.144488
QF Loss                      300.15588
VF Loss                      176.63162
Policy Loss                  -932.2978
Q Predictions Mean           929.87787
Q Predictions Std            988.4613
Q Predictions Max            3419.7405
Q Predictions Min            422.8435
V Predictions Mean           939.0667
V Predictions Std            991.24963
V Predictions Max            3439.8638
V Predictions Min            427.20093
Log Pis Mean                 -0.58376443
Log Pis Std                  3.6474376
Log Pis Max                  12.717672
Log Pis Min                  -11.097915
Policy mu Mean               0.084276915
Policy mu Std                0.8590956
Policy mu Max                2.742898
Policy mu Min                -2.9587474
Policy log std Mean          -0.5016393
Policy log std Std           0.2567651
Policy log std Max           -0.09008881
Policy log std Min           -2.2405252
Z mean eval                  1.6808002
Z variance eval              0.039493173
total_rewards                [8080.76744991 8515.91389213 8238.1743592  7423.01857417 8185.88102562
 8361.52447008 7968.03710633 8352.09827542 8153.4835897  8246.0441083 ]
total_rewards_mean           8152.494285086135
total_rewards_std            283.57035849455036
total_rewards_max            8515.913892127788
total_rewards_min            7423.018574167669
Number of train steps total  624000
Number of env steps total    1874000
Number of rollouts total     0
Train Time (s)               143.76098084589466
(Previous) Eval Time (s)     17.13578405790031
Sample Time (s)              5.654736757278442
Epoch Time (s)               166.55150166107342
Total Train Time (s)         26371.25897920644
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:13:09.993242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #155 | Epoch Duration: 166.64058446884155
2020-01-12 15:13:09.993584 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6801609
Z variance train             0.03940464
KL Divergence                42.20976
KL Loss                      4.220976
QF Loss                      216.92978
VF Loss                      105.11313
Policy Loss                  -994.3619
Q Predictions Mean           992.47546
Q Predictions Std            1049.5995
Q Predictions Max            3547.9749
Q Predictions Min            414.82288
V Predictions Mean           993.93567
V Predictions Std            1046.69
V Predictions Max            3539.953
V Predictions Min            424.35324
Log Pis Mean                 -0.6395857
Log Pis Std                  3.3890698
Log Pis Max                  19.446762
Log Pis Min                  -7.691763
Policy mu Mean               -0.035720665
Policy mu Std                0.83088785
Policy mu Max                2.6309373
Policy mu Min                -3.7986195
Policy log std Mean          -0.5072802
Policy log std Std           0.2576026
Policy log std Max           -0.08554143
Policy log std Min           -2.346056
Z mean eval                  1.6838112
Z variance eval              0.03687975
total_rewards                [8087.8685862  8369.23098567 8194.29773205 8254.37643213 8150.03525646
 8431.08460093 8166.73737853 8314.90160849 7733.17214297 8265.90675663]
total_rewards_mean           8196.761148004818
total_rewards_std            183.4596112927521
total_rewards_max            8431.084600929693
total_rewards_min            7733.172142966617
Number of train steps total  628000
Number of env steps total    1886000
Number of rollouts total     0
Train Time (s)               146.90457370504737
(Previous) Eval Time (s)     20.62318090442568
Sample Time (s)              6.463837856426835
Epoch Time (s)               173.99159246589988
Total Train Time (s)         26545.33572577918
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:16:04.069814 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #156 | Epoch Duration: 174.0759961605072
2020-01-12 15:16:04.069958 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6855221
Z variance train             0.036920257
KL Divergence                40.59921
KL Loss                      4.059921
QF Loss                      156.14551
VF Loss                      134.67978
Policy Loss                  -873.7612
Q Predictions Mean           875.7315
Q Predictions Std            968.9583
Q Predictions Max            3495.8694
Q Predictions Min            430.46246
V Predictions Mean           881.9304
V Predictions Std            968.59985
V Predictions Max            3487.647
V Predictions Min            433.58414
Log Pis Mean                 -0.7079874
Log Pis Std                  3.3622265
Log Pis Max                  16.909262
Log Pis Min                  -9.469059
Policy mu Mean               0.0519211
Policy mu Std                0.8223465
Policy mu Max                3.328805
Policy mu Min                -2.7041535
Policy log std Mean          -0.48393586
Policy log std Std           0.25188404
Policy log std Max           0.0051498413
Policy log std Min           -2.156906
Z mean eval                  1.6692518
Z variance eval              0.0505194
total_rewards                [4134.42259465 7679.50688049 7833.52116349 7824.5074276  7976.00789373
 7753.73525323 8033.68162757 7666.49368759 7930.84792957 7647.68395113]
total_rewards_mean           7448.040840904667
total_rewards_std            1111.7472597465958
total_rewards_max            8033.681627570213
total_rewards_min            4134.4225946502265
Number of train steps total  632000
Number of env steps total    1898000
Number of rollouts total     0
Train Time (s)               145.36902018636465
(Previous) Eval Time (s)     17.324253030121326
Sample Time (s)              6.552715686149895
Epoch Time (s)               169.24598890263587
Total Train Time (s)         26714.66900205007
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:18:53.410110 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #157 | Epoch Duration: 169.3400011062622
2020-01-12 15:18:53.410387 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.670131
Z variance train             0.050728105
KL Divergence                40.101505
KL Loss                      4.0101504
QF Loss                      102.37797
VF Loss                      42.350967
Policy Loss                  -972.479
Q Predictions Mean           970.1383
Q Predictions Std            1026.8604
Q Predictions Max            3543.2964
Q Predictions Min            436.03403
V Predictions Mean           972.23627
V Predictions Std            1023.34766
V Predictions Max            3525.9258
V Predictions Min            442.33157
Log Pis Mean                 -0.75842786
Log Pis Std                  3.0300765
Log Pis Max                  10.531879
Log Pis Min                  -7.8359275
Policy mu Mean               0.05407253
Policy mu Std                0.8092073
Policy mu Max                2.8985863
Policy mu Min                -2.909739
Policy log std Mean          -0.482967
Policy log std Std           0.24299757
Policy log std Max           -0.023729205
Policy log std Min           -1.9544766
Z mean eval                  1.6684755
Z variance eval              0.059243787
total_rewards                [5940.00261673 8537.06576284 8520.15981503 8204.50175106 8164.09680543
 6609.34726375 8130.54345052 8338.11404128 8447.38003792 8473.04395161]
total_rewards_mean           7936.425549618754
total_rewards_std            855.5772270742784
total_rewards_max            8537.065762842689
total_rewards_min            5940.002616734299
Number of train steps total  636000
Number of env steps total    1910000
Number of rollouts total     0
Train Time (s)               145.28805463341996
(Previous) Eval Time (s)     21.349528718739748
Sample Time (s)              6.674951656721532
Epoch Time (s)               173.31253500888124
Total Train Time (s)         26888.064600161277
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:21:46.804754 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #158 | Epoch Duration: 173.394104719162
2020-01-12 15:21:46.805036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6666578
Z variance train             0.059202127
KL Divergence                39.49934
KL Loss                      3.949934
QF Loss                      125.46012
VF Loss                      35.91261
Policy Loss                  -984.80023
Q Predictions Mean           982.092
Q Predictions Std            996.62305
Q Predictions Max            3566.963
Q Predictions Min            420.77823
V Predictions Mean           982.0785
V Predictions Std            998.7925
V Predictions Max            3567.0232
V Predictions Min            413.30197
Log Pis Mean                 -0.5574315
Log Pis Std                  3.3183858
Log Pis Max                  11.515685
Log Pis Min                  -9.4117565
Policy mu Mean               0.008906503
Policy mu Std                0.8313205
Policy mu Max                2.9669752
Policy mu Min                -2.4077673
Policy log std Mean          -0.5148545
Policy log std Std           0.26446256
Policy log std Max           -0.14521945
Policy log std Min           -2.47193
Z mean eval                  1.6647692
Z variance eval              0.08769739
total_rewards                [8214.69070997 8519.70549844 8119.73163089 8351.10912689 8403.43391663
 8573.24854286 8454.08472371 8620.29238241 8455.73385285 8309.37525718]
total_rewards_mean           8402.140564183897
total_rewards_std            149.1186246627803
total_rewards_max            8620.292382409565
total_rewards_min            8119.731630891425
Number of train steps total  640000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               144.43296390166506
(Previous) Eval Time (s)     21.298181997146457
Sample Time (s)              6.552921161521226
Epoch Time (s)               172.28406706033275
Total Train Time (s)         27060.43429635046
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:24:39.175154 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #159 | Epoch Duration: 172.36994910240173
2020-01-12 15:24:39.175298 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6631695
Z variance train             0.0876924
KL Divergence                38.579678
KL Loss                      3.8579679
QF Loss                      195.24768
VF Loss                      85.20365
Policy Loss                  -987.6028
Q Predictions Mean           986.40546
Q Predictions Std            1046.7224
Q Predictions Max            3604.429
Q Predictions Min            427.89557
V Predictions Mean           987.4212
V Predictions Std            1040.8501
V Predictions Max            3574.9712
V Predictions Min            437.15805
Log Pis Mean                 -0.54161143
Log Pis Std                  3.2286925
Log Pis Max                  11.176964
Log Pis Min                  -6.3900795
Policy mu Mean               0.033344667
Policy mu Std                0.8332597
Policy mu Max                2.7732303
Policy mu Min                -2.5580568
Policy log std Mean          -0.48812118
Policy log std Std           0.25721726
Policy log std Max           -0.085149765
Policy log std Min           -2.10993
Z mean eval                  1.6858761
Z variance eval              0.11312804
total_rewards                [7778.41397073 7997.9124408  7872.32335618 7720.98820196 7903.96943954
 7952.47019068 7882.68079837 7581.91396263 6979.7540867  5462.1666011 ]
total_rewards_mean           7513.259304870393
total_rewards_std            738.6223227968701
total_rewards_max            7997.912440804156
total_rewards_min            5462.166601100374
Number of train steps total  644000
Number of env steps total    1934000
Number of rollouts total     0
Train Time (s)               145.56839477829635
(Previous) Eval Time (s)     21.465846753213555
Sample Time (s)              6.3990280805155635
Epoch Time (s)               173.43326961202547
Total Train Time (s)         27233.94944996247
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:27:32.692805 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #160 | Epoch Duration: 173.5173327922821
2020-01-12 15:27:32.693026 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6855644
Z variance train             0.11323136
KL Divergence                38.715633
KL Loss                      3.8715634
QF Loss                      145.97002
VF Loss                      57.43587
Policy Loss                  -1053.3379
Q Predictions Mean           1049.8362
Q Predictions Std            1089.5018
Q Predictions Max            3642.7822
Q Predictions Min            445.16068
V Predictions Mean           1053.5118
V Predictions Std            1087.329
V Predictions Max            3631.3323
V Predictions Min            446.63358
Log Pis Mean                 -0.31389982
Log Pis Std                  3.5349002
Log Pis Max                  15.372602
Log Pis Min                  -7.2831473
Policy mu Mean               0.07441337
Policy mu Std                0.8648342
Policy mu Max                3.1500065
Policy mu Min                -2.9904642
Policy log std Mean          -0.4997108
Policy log std Std           0.26974827
Policy log std Max           -0.049295485
Policy log std Min           -2.174433
Z mean eval                  1.706269
Z variance eval              0.061629813
total_rewards                [8069.84541031 8445.56400335 8387.10027589 8461.12580091 8287.55237038
 8305.26057917 8405.36678933 8175.68788902 8290.69610197 8186.85685544]
total_rewards_mean           8301.505607577363
total_rewards_std            121.37196527705841
total_rewards_max            8461.12580091366
total_rewards_min            8069.845410312459
Number of train steps total  648000
Number of env steps total    1946000
Number of rollouts total     0
Train Time (s)               144.08012962993234
(Previous) Eval Time (s)     18.6778327813372
Sample Time (s)              6.472726160660386
Epoch Time (s)               169.23068857192993
Total Train Time (s)         27403.291216287762
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:30:22.036610 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #161 | Epoch Duration: 169.34345602989197
2020-01-12 15:30:22.036783 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #161 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7067089
Z variance train             0.061644293
KL Divergence                39.990013
KL Loss                      3.9990013
QF Loss                      1927.54
VF Loss                      180.78108
Policy Loss                  -1056.0992
Q Predictions Mean           1053.0657
Q Predictions Std            1083.2035
Q Predictions Max            3586.295
Q Predictions Min            445.11728
V Predictions Mean           1062.9858
V Predictions Std            1083.0472
V Predictions Max            3611.5886
V Predictions Min            451.48813
Log Pis Mean                 -0.5531429
Log Pis Std                  3.2883127
Log Pis Max                  13.208656
Log Pis Min                  -7.936208
Policy mu Mean               0.043832522
Policy mu Std                0.84358853
Policy mu Max                3.0912414
Policy mu Min                -2.6023188
Policy log std Mean          -0.5062376
Policy log std Std           0.28084147
Policy log std Max           0.09842491
Policy log std Min           -2.3637557
Z mean eval                  1.6757586
Z variance eval              0.06733346
total_rewards                [7960.6738216  8227.36965026 8468.24236326 8700.9430975  8266.6804645
 8318.00530653 8484.96176387 8617.67743521 8503.63134857 8559.20573492]
total_rewards_mean           8410.739098620557
total_rewards_std            207.86157226089506
total_rewards_max            8700.943097501446
total_rewards_min            7960.67382159728
Number of train steps total  652000
Number of env steps total    1958000
Number of rollouts total     0
Train Time (s)               145.30942275980487
(Previous) Eval Time (s)     20.777943045832217
Sample Time (s)              6.592671235091984
Epoch Time (s)               172.68003704072908
Total Train Time (s)         27576.06158953719
Epoch                        162
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:33:14.812348 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #162 | Epoch Duration: 172.77539587020874
2020-01-12 15:33:14.812642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6757734
Z variance train             0.06743214
KL Divergence                39.702152
KL Loss                      3.9702153
QF Loss                      2026.3009
VF Loss                      85.45046
Policy Loss                  -960.99036
Q Predictions Mean           960.89606
Q Predictions Std            1032.7604
Q Predictions Max            3561.8257
Q Predictions Min            425.75882
V Predictions Mean           964.9397
V Predictions Std            1034.2883
V Predictions Max            3580.0413
V Predictions Min            436.6621
Log Pis Mean                 -0.4100744
Log Pis Std                  3.575611
Log Pis Max                  13.544498
Log Pis Min                  -5.9498224
Policy mu Mean               0.08590195
Policy mu Std                0.8717773
Policy mu Max                2.9629836
Policy mu Min                -2.8876421
Policy log std Mean          -0.5031908
Policy log std Std           0.26166865
Policy log std Max           -0.0982362
Policy log std Min           -2.3904204
Z mean eval                  1.6633358
Z variance eval              0.055999726
total_rewards                [8731.89896842 8725.92237956 8661.05932159 8683.15826959 8704.42176906
 8703.72434314 8365.46675214 8412.64892987 8213.6919596  8428.93031953]
total_rewards_mean           8563.09230124973
total_rewards_std            179.03720019231207
total_rewards_max            8731.898968420204
total_rewards_min            8213.691959603198
Number of train steps total  656000
Number of env steps total    1970000
Number of rollouts total     0
Train Time (s)               145.7679060101509
(Previous) Eval Time (s)     20.801635336130857
Sample Time (s)              6.622578330338001
Epoch Time (s)               173.19211967661977
Total Train Time (s)         27749.350282585714
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:36:08.101491 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #163 | Epoch Duration: 173.28865218162537
2020-01-12 15:36:08.101626 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #163 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.663591
Z variance train             0.05603979
KL Divergence                39.386177
KL Loss                      3.9386177
QF Loss                      246.87125
VF Loss                      66.25935
Policy Loss                  -986.45715
Q Predictions Mean           983.6944
Q Predictions Std            1018.4226
Q Predictions Max            3645.1917
Q Predictions Min            410.265
V Predictions Mean           982.8601
V Predictions Std            1013.9674
V Predictions Max            3638.7656
V Predictions Min            463.98865
Log Pis Mean                 -0.30612773
Log Pis Std                  3.875925
Log Pis Max                  16.222378
Log Pis Min                  -5.747678
Policy mu Mean               0.031479243
Policy mu Std                0.87018734
Policy mu Max                4.212607
Policy mu Min                -2.76833
Policy log std Mean          -0.48593482
Policy log std Std           0.25187275
Policy log std Max           -0.06016463
Policy log std Min           -2.197948
Z mean eval                  1.652396
Z variance eval              0.059991397
total_rewards                [8482.77786747 8698.36475853 8746.24731885 8687.32933596 8583.4225795
 8399.89611215 8609.75745802 8649.40435838 8762.64917968 8499.86422687]
total_rewards_mean           8611.971319542306
total_rewards_std            114.16327100965566
total_rewards_max            8762.649179675338
total_rewards_min            8399.896112151242
Number of train steps total  660000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               144.91382416989654
(Previous) Eval Time (s)     17.31726120505482
Sample Time (s)              6.554503338877112
Epoch Time (s)               168.78558871382847
Total Train Time (s)         27918.21486007562
Epoch                        164
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:38:56.968099 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #164 | Epoch Duration: 168.86636519432068
2020-01-12 15:38:56.968272 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6520624
Z variance train             0.060126733
KL Divergence                38.88307
KL Loss                      3.8883073
QF Loss                      177.16115
VF Loss                      100.05221
Policy Loss                  -936.2691
Q Predictions Mean           933.2539
Q Predictions Std            977.23883
Q Predictions Max            3624.445
Q Predictions Min            427.17838
V Predictions Mean           934.00745
V Predictions Std            973.2496
V Predictions Max            3598.4578
V Predictions Min            429.54123
Log Pis Mean                 -0.60585624
Log Pis Std                  3.5035627
Log Pis Max                  22.018147
Log Pis Min                  -7.7542787
Policy mu Mean               0.102687955
Policy mu Std                0.8617833
Policy mu Max                3.4867532
Policy mu Min                -2.5813835
Policy log std Mean          -0.4898169
Policy log std Std           0.2581751
Policy log std Max           -0.055503666
Policy log std Min           -2.1160653
Z mean eval                  1.6549307
Z variance eval              0.049500596
total_rewards                [8560.36756444 8804.43648673 8657.3518918  8243.41274752 8583.03812002
 8793.11679864 8420.86880505 8761.42629635 8703.32335427 8494.54362294]
total_rewards_mean           8602.188568776066
total_rewards_std            170.67097506409874
total_rewards_max            8804.436486732982
total_rewards_min            8243.41274752131
Number of train steps total  664000
Number of env steps total    1994000
Number of rollouts total     0
Train Time (s)               145.9682332049124
(Previous) Eval Time (s)     17.64883640082553
Sample Time (s)              6.589735724963248
Epoch Time (s)               170.20680533070117
Total Train Time (s)         28088.503470460884
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:41:47.259983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #165 | Epoch Duration: 170.29151725769043
2020-01-12 15:41:47.260255 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6567894
Z variance train             0.049710847
KL Divergence                38.783916
KL Loss                      3.8783917
QF Loss                      2300.9534
VF Loss                      74.5664
Policy Loss                  -1039.1998
Q Predictions Mean           1037.0245
Q Predictions Std            1075.2072
Q Predictions Max            3612.7527
Q Predictions Min            456.65234
V Predictions Mean           1041.5654
V Predictions Std            1079.2737
V Predictions Max            3619.7522
V Predictions Min            470.455
Log Pis Mean                 -0.606949
Log Pis Std                  3.495847
Log Pis Max                  14.524021
Log Pis Min                  -9.15163
Policy mu Mean               0.040339224
Policy mu Std                0.83455193
Policy mu Max                2.7011616
Policy mu Min                -2.6176834
Policy log std Mean          -0.5019823
Policy log std Std           0.2531119
Policy log std Max           -0.08505887
Policy log std Min           -2.01134
Z mean eval                  1.6605324
Z variance eval              0.08821193
total_rewards                [8706.8521606  8821.33295602 8683.74250931 9104.20513826 8935.74866726
 8832.43370236 8517.35477475 8908.95892219  537.5930163  8725.83854958]
total_rewards_mean           7977.406039662242
total_rewards_std            2484.6063883495144
total_rewards_max            9104.205138262496
total_rewards_min            537.5930162992486
Number of train steps total  668000
Number of env steps total    2006000
Number of rollouts total     0
Train Time (s)               146.48404628923163
(Previous) Eval Time (s)     17.58264566073194
Sample Time (s)              6.506538621149957
Epoch Time (s)               170.57323057111353
Total Train Time (s)         28259.162818637677
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:44:37.923338 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #166 | Epoch Duration: 170.6628942489624
2020-01-12 15:44:37.923517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6599884
Z variance train             0.08812831
KL Divergence                37.18761
KL Loss                      3.7187612
QF Loss                      125.12697
VF Loss                      129.45154
Policy Loss                  -1044.5137
Q Predictions Mean           1042.2798
Q Predictions Std            1071.4978
Q Predictions Max            3527.7073
Q Predictions Min            453.3944
V Predictions Mean           1046.7501
V Predictions Std            1072.6708
V Predictions Max            3550.8145
V Predictions Min            462.24417
Log Pis Mean                 -0.50661314
Log Pis Std                  3.7162547
Log Pis Max                  20.383276
Log Pis Min                  -7.911856
Policy mu Mean               0.017188562
Policy mu Std                0.870014
Policy mu Max                3.0606408
Policy mu Min                -3.49635
Policy log std Mean          -0.48185587
Policy log std Std           0.26425943
Policy log std Max           -0.07888186
Policy log std Min           -2.4321558
Z mean eval                  1.702982
Z variance eval              0.046680797
total_rewards                [8087.70545572 7971.05566275 8444.00460868 8295.40399072 8295.42607427
 8146.72682979 8244.65551981 8108.03837929 8256.18014317 8475.03219699]
total_rewards_mean           8232.42288611841
total_rewards_std            149.78232492859763
total_rewards_max            8475.0321969906
total_rewards_min            7971.055662750041
Number of train steps total  672000
Number of env steps total    2018000
Number of rollouts total     0
Train Time (s)               144.9417073582299
(Previous) Eval Time (s)     20.810718567110598
Sample Time (s)              6.608845453243703
Epoch Time (s)               172.3612713785842
Total Train Time (s)         28431.607398571447
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:47:30.366788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #167 | Epoch Duration: 172.4431381225586
2020-01-12 15:47:30.366933 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7016321
Z variance train             0.04675547
KL Divergence                39.42159
KL Loss                      3.942159
QF Loss                      140.04364
VF Loss                      80.33762
Policy Loss                  -1067.7583
Q Predictions Mean           1068.8872
Q Predictions Std            1101.6366
Q Predictions Max            3605.6501
Q Predictions Min            458.04523
V Predictions Mean           1069.8123
V Predictions Std            1103.8966
V Predictions Max            3614.9998
V Predictions Min            455.02527
Log Pis Mean                 -0.419085
Log Pis Std                  3.468799
Log Pis Max                  12.653125
Log Pis Min                  -6.702613
Policy mu Mean               0.060690235
Policy mu Std                0.8657343
Policy mu Max                2.8345518
Policy mu Min                -2.4403539
Policy log std Mean          -0.49641475
Policy log std Std           0.25748968
Policy log std Max           -0.07634348
Policy log std Min           -2.2391026
Z mean eval                  1.6878445
Z variance eval              0.051007003
total_rewards                [7900.46783036 8184.69743467 8310.31626619 8749.77395926 8276.80498693
 8310.9087901  8414.90839878 8491.06746268 8201.09901321 8251.19720909]
total_rewards_mean           8309.12413512604
total_rewards_std            209.05071653575988
total_rewards_max            8749.773959264885
total_rewards_min            7900.467830360265
Number of train steps total  676000
Number of env steps total    2030000
Number of rollouts total     0
Train Time (s)               146.2720042890869
(Previous) Eval Time (s)     20.62562488298863
Sample Time (s)              6.499655156861991
Epoch Time (s)               173.39728432893753
Total Train Time (s)         28605.098575496115
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:50:23.859825 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #168 | Epoch Duration: 173.49277544021606
2020-01-12 15:50:23.859999 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.687454
Z variance train             0.050934933
KL Divergence                39.88109
KL Loss                      3.9881089
QF Loss                      295.7052
VF Loss                      86.86297
Policy Loss                  -1072.0112
Q Predictions Mean           1070.7645
Q Predictions Std            1109.3578
Q Predictions Max            3642.529
Q Predictions Min            474.8323
V Predictions Mean           1078.8192
V Predictions Std            1110.3694
V Predictions Max            3636.7578
V Predictions Min            478.18896
Log Pis Mean                 -0.6712061
Log Pis Std                  3.4327505
Log Pis Max                  11.017113
Log Pis Min                  -6.7748785
Policy mu Mean               0.0124715455
Policy mu Std                0.82966834
Policy mu Max                2.6371453
Policy mu Min                -2.3315418
Policy log std Mean          -0.50378966
Policy log std Std           0.25258705
Policy log std Max           -0.14151967
Policy log std Min           -2.4408998
Z mean eval                  1.6869953
Z variance eval              0.053444393
total_rewards                [8222.75704986 8769.34860381 8667.29303842 8751.50126783 8714.62780148
 8685.13704641 8756.17191276 8591.48364041 8698.82390947 8863.25572692]
total_rewards_mean           8672.039999738172
total_rewards_std            164.46712489085743
total_rewards_max            8863.25572692445
total_rewards_min            8222.757049858508
Number of train steps total  680000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               145.8144045220688
(Previous) Eval Time (s)     18.04896749276668
Sample Time (s)              6.472155757714063
Epoch Time (s)               170.33552777254954
Total Train Time (s)         28775.51926541142
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:53:14.286049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #169 | Epoch Duration: 170.42587423324585
2020-01-12 15:53:14.286361 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.678326
Z variance train             0.0542598
KL Divergence                39.349335
KL Loss                      3.9349334
QF Loss                      115.38569
VF Loss                      100.75787
Policy Loss                  -923.0727
Q Predictions Mean           923.8257
Q Predictions Std            985.7428
Q Predictions Max            3852.1685
Q Predictions Min            488.97018
V Predictions Mean           931.28723
V Predictions Std            986.6508
V Predictions Max            3862.1404
V Predictions Min            494.59235
Log Pis Mean                 -0.77732897
Log Pis Std                  3.018531
Log Pis Max                  11.096724
Log Pis Min                  -7.9351444
Policy mu Mean               0.03150111
Policy mu Std                0.8071585
Policy mu Max                2.5668807
Policy mu Min                -2.4092195
Policy log std Mean          -0.48112497
Policy log std Std           0.23909311
Policy log std Max           -0.13827014
Policy log std Min           -2.3621607
Z mean eval                  1.6825974
Z variance eval              0.046334367
total_rewards                [8641.91015272 8888.73980555 8773.01330649 8796.47860474 8995.73795362
 8694.15572269 8695.28649672 8702.49986467 8888.052827   8958.91222216]
total_rewards_mean           8803.478695635657
total_rewards_std            116.82498358731809
total_rewards_max            8995.737953622373
total_rewards_min            8641.910152717783
Number of train steps total  684000
Number of env steps total    2054000
Number of rollouts total     0
Train Time (s)               145.4497742978856
(Previous) Eval Time (s)     20.640418864320964
Sample Time (s)              6.541411028243601
Epoch Time (s)               172.63160419045016
Total Train Time (s)         28948.235827020835
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:56:07.003728 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #170 | Epoch Duration: 172.71710586547852
2020-01-12 15:56:07.003941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6831436
Z variance train             0.046361286
KL Divergence                39.943245
KL Loss                      3.9943244
QF Loss                      115.007515
VF Loss                      46.87203
Policy Loss                  -942.1672
Q Predictions Mean           944.5106
Q Predictions Std            1002.2489
Q Predictions Max            3653.888
Q Predictions Min            453.87137
V Predictions Mean           941.97736
V Predictions Std            998.1779
V Predictions Max            3662.0325
V Predictions Min            453.36603
Log Pis Mean                 -0.61720127
Log Pis Std                  3.7740662
Log Pis Max                  17.2194
Log Pis Min                  -7.306044
Policy mu Mean               0.049936432
Policy mu Std                0.8299118
Policy mu Max                2.6820574
Policy mu Min                -2.7269726
Policy log std Mean          -0.4855143
Policy log std Std           0.24522267
Policy log std Max           -0.024852633
Policy log std Min           -2.467192
Z mean eval                  1.7050524
Z variance eval              0.09448192
total_rewards                [8653.16417191 8191.78583263 8793.55862292 8733.481518   8818.76590684
 8798.24848307 8717.48609557 8864.71789551 8843.92545433 8909.30582322]
total_rewards_mean           8732.44398040007
total_rewards_std            193.78923132276046
total_rewards_max            8909.305823221206
total_rewards_min            8191.7858326297865
Number of train steps total  688000
Number of env steps total    2066000
Number of rollouts total     0
Train Time (s)               145.12360028736293
(Previous) Eval Time (s)     17.576523912139237
Sample Time (s)              6.44432009011507
Epoch Time (s)               169.14444428961724
Total Train Time (s)         29117.466860174667
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:58:56.239897 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #171 | Epoch Duration: 169.2357897758484
2020-01-12 15:58:56.240164 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.706785
Z variance train             0.09420597
KL Divergence                39.010014
KL Loss                      3.9010015
QF Loss                      108.08577
VF Loss                      56.964302
Policy Loss                  -1012.15857
Q Predictions Mean           1013.34033
Q Predictions Std            1064.8325
Q Predictions Max            3734.7783
Q Predictions Min            470.01334
V Predictions Mean           1013.3255
V Predictions Std            1059.7817
V Predictions Max            3713.7957
V Predictions Min            472.16
Log Pis Mean                 -0.6319942
Log Pis Std                  3.0129151
Log Pis Max                  10.336362
Log Pis Min                  -7.9501543
Policy mu Mean               -0.003745328
Policy mu Std                0.8164501
Policy mu Max                2.4558353
Policy mu Min                -2.3234966
Policy log std Mean          -0.49421227
Policy log std Std           0.2609263
Policy log std Max           -0.06880888
Policy log std Min           -2.427072
Z mean eval                  1.6682355
Z variance eval              0.06003164
total_rewards                [8377.95027439 8412.9917206  8492.48902766 8474.81419142 8686.04625457
 8650.74650746 8485.18638406 8620.08692774 8541.25718181 8582.5044903 ]
total_rewards_mean           8532.407296002064
total_rewards_std            96.51018872477731
total_rewards_max            8686.04625456935
total_rewards_min            8377.950274388246
Number of train steps total  692000
Number of env steps total    2078000
Number of rollouts total     0
Train Time (s)               144.63459149608389
(Previous) Eval Time (s)     20.807526072021574
Sample Time (s)              6.478848413564265
Epoch Time (s)               171.92096598166972
Total Train Time (s)         29289.479592790827
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:01:48.252105 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #172 | Epoch Duration: 172.01175665855408
2020-01-12 16:01:48.252250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6671692
Z variance train             0.06010034
KL Divergence                39.07331
KL Loss                      3.9073312
QF Loss                      218.5209
VF Loss                      59.68052
Policy Loss                  -1067.602
Q Predictions Mean           1065.636
Q Predictions Std            1091.7543
Q Predictions Max            3639.1086
Q Predictions Min            477.81512
V Predictions Mean           1071.2861
V Predictions Std            1091.6047
V Predictions Max            3646.7468
V Predictions Min            476.20978
Log Pis Mean                 -0.6094056
Log Pis Std                  3.657351
Log Pis Max                  18.121746
Log Pis Min                  -10.36287
Policy mu Mean               0.031787086
Policy mu Std                0.8510661
Policy mu Max                2.7436037
Policy mu Min                -3.6127958
Policy log std Mean          -0.48602223
Policy log std Std           0.24332404
Policy log std Max           -0.049574703
Policy log std Min           -2.0343928
Z mean eval                  1.6780691
Z variance eval              0.062889606
total_rewards                [8493.76380846 8803.50052567 8707.00051943 8541.49716024 8620.10012156
 8641.5397058  8753.3827365  8334.10530247 8642.85443628 8528.10379821]
total_rewards_mean           8606.584811460943
total_rewards_std            130.57490989875575
total_rewards_max            8803.500525665982
total_rewards_min            8334.105302474423
Number of train steps total  696000
Number of env steps total    2090000
Number of rollouts total     0
Train Time (s)               147.4393158662133
(Previous) Eval Time (s)     17.911498561967164
Sample Time (s)              6.306300093885511
Epoch Time (s)               171.65711452206597
Total Train Time (s)         29461.219214608893
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:04:39.999537 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #173 | Epoch Duration: 171.74715304374695
2020-01-12 16:04:39.999763 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6771953
Z variance train             0.06303736
KL Divergence                40.09716
KL Loss                      4.009716
QF Loss                      171.9212
VF Loss                      260.6278
Policy Loss                  -1093.9211
Q Predictions Mean           1094.0339
Q Predictions Std            1115.9945
Q Predictions Max            3843.4707
Q Predictions Min            477.94824
V Predictions Mean           1103.3811
V Predictions Std            1119.4736
V Predictions Max            3821.106
V Predictions Min            490.99857
Log Pis Mean                 -0.63847864
Log Pis Std                  3.3520322
Log Pis Max                  13.690289
Log Pis Min                  -8.105515
Policy mu Mean               0.05621764
Policy mu Std                0.8360838
Policy mu Max                2.6801543
Policy mu Min                -2.920197
Policy log std Mean          -0.5023609
Policy log std Std           0.2499272
Policy log std Max           -0.061777055
Policy log std Min           -2.141471
Z mean eval                  1.6952012
Z variance eval              0.08217262
total_rewards                [8994.79626886 8887.80253752 9007.1559942  8952.93364084 8779.99238509
 9049.43228975 8970.81669913 8779.14907914 8766.53432564 8869.16749198]
total_rewards_mean           8905.778071215484
total_rewards_std            99.096490162204
total_rewards_max            9049.432289747085
total_rewards_min            8766.5343256448
Number of train steps total  700000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               145.814381333068
(Previous) Eval Time (s)     18.041688065044582
Sample Time (s)              6.3963568159379065
Epoch Time (s)               170.2524262140505
Total Train Time (s)         29631.557638970204
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:07:30.338697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #174 | Epoch Duration: 170.33875370025635
2020-01-12 16:07:30.338867 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.699496
Z variance train             0.08201949
KL Divergence                40.458797
KL Loss                      4.04588
QF Loss                      2202.725
VF Loss                      43.693214
Policy Loss                  -989.17926
Q Predictions Mean           987.53174
Q Predictions Std            1031.5293
Q Predictions Max            3803.191
Q Predictions Min            479.6905
V Predictions Mean           986.94324
V Predictions Std            1029.3966
V Predictions Max            3798.5305
V Predictions Min            483.41013
Log Pis Mean                 -0.68058753
Log Pis Std                  3.3727345
Log Pis Max                  13.08857
Log Pis Min                  -6.8905516
Policy mu Mean               0.038336482
Policy mu Std                0.83896935
Policy mu Max                2.6149118
Policy mu Min                -2.573729
Policy log std Mean          -0.49962616
Policy log std Std           0.24840404
Policy log std Max           -0.09239374
Policy log std Min           -2.1204078
Z mean eval                  1.6692533
Z variance eval              0.046211023
total_rewards                [8333.73656886 8750.26098998 9034.47775155 8948.32172134 8102.27504625
 8743.94914796 8607.45412672 8698.87804488 8531.88960273 8972.09332575]
total_rewards_mean           8672.333632601772
total_rewards_std            277.96193297027963
total_rewards_max            9034.477751549268
total_rewards_min            8102.275046247401
Number of train steps total  704000
Number of env steps total    2114000
Number of rollouts total     0
Train Time (s)               147.14764814032242
(Previous) Eval Time (s)     17.547311436850578
Sample Time (s)              6.3446714375168085
Epoch Time (s)               171.0396310146898
Total Train Time (s)         29802.680935938843
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:10:21.463682 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #175 | Epoch Duration: 171.12469339370728
2020-01-12 16:10:21.463817 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6701155
Z variance train             0.0460886
KL Divergence                41.09267
KL Loss                      4.109267
QF Loss                      124.47223
VF Loss                      73.095665
Policy Loss                  -956.966
Q Predictions Mean           951.4667
Q Predictions Std            982.78516
Q Predictions Max            3790.957
Q Predictions Min            478.27386
V Predictions Mean           954.1848
V Predictions Std            982.9141
V Predictions Max            3777.9802
V Predictions Min            486.54233
Log Pis Mean                 -0.86854744
Log Pis Std                  3.6279929
Log Pis Max                  18.509642
Log Pis Min                  -8.219343
Policy mu Mean               0.03843839
Policy mu Std                0.8116225
Policy mu Max                2.5132086
Policy mu Min                -3.596787
Policy log std Mean          -0.48347154
Policy log std Std           0.2693095
Policy log std Max           -0.040167928
Policy log std Min           -2.158823
Z mean eval                  1.6875372
Z variance eval              0.081984885
total_rewards                [8439.33403788 8701.4236542  8834.11082476 8797.29582384 8694.45912375
 8570.34329271 8749.04885477 8712.35527044 8668.13716022 8705.15952461]
total_rewards_mean           8687.166756718527
total_rewards_std            106.86248504119249
total_rewards_max            8834.110824755706
total_rewards_min            8439.334037879886
Number of train steps total  708000
Number of env steps total    2126000
Number of rollouts total     0
Train Time (s)               146.53834656393155
(Previous) Eval Time (s)     17.39765392197296
Sample Time (s)              6.364318030420691
Epoch Time (s)               170.3003185163252
Total Train Time (s)         29973.064368319232
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:13:11.851123 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #176 | Epoch Duration: 170.38719606399536
2020-01-12 16:13:11.851307 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6870663
Z variance train             0.0821037
KL Divergence                39.30276
KL Loss                      3.9302762
QF Loss                      134.93512
VF Loss                      38.91426
Policy Loss                  -976.9003
Q Predictions Mean           974.7768
Q Predictions Std            992.91876
Q Predictions Max            3697.3428
Q Predictions Min            494.9932
V Predictions Mean           979.1826
V Predictions Std            993.11835
V Predictions Max            3699.1135
V Predictions Min            488.99396
Log Pis Mean                 -0.59026265
Log Pis Std                  3.3876312
Log Pis Max                  10.000638
Log Pis Min                  -7.647888
Policy mu Mean               0.08149911
Policy mu Std                0.8220604
Policy mu Max                2.6009073
Policy mu Min                -2.5139763
Policy log std Mean          -0.49613747
Policy log std Std           0.2510641
Policy log std Max           -0.054849803
Policy log std Min           -2.2915
Z mean eval                  1.6964394
Z variance eval              0.067754745
total_rewards                [8487.54192292 8404.53119327 8051.99293928 8442.23132165 8560.56940351
 8356.34996091 8678.5822314  8547.65228727 7992.68358381 8418.15471798]
total_rewards_mean           8394.028956199334
total_rewards_std            205.80412014956647
total_rewards_max            8678.582231395738
total_rewards_min            7992.683583807222
Number of train steps total  712000
Number of env steps total    2138000
Number of rollouts total     0
Train Time (s)               146.09187183436006
(Previous) Eval Time (s)     20.882548933383077
Sample Time (s)              6.350449597928673
Epoch Time (s)               173.3248703656718
Total Train Time (s)         30146.475852184463
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:16:05.263603 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #177 | Epoch Duration: 173.4121596813202
2020-01-12 16:16:05.263731 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6978409
Z variance train             0.06774948
KL Divergence                40.42994
KL Loss                      4.042994
QF Loss                      138.07967
VF Loss                      29.455578
Policy Loss                  -1188.4291
Q Predictions Mean           1186.4222
Q Predictions Std            1179.2341
Q Predictions Max            3747.4812
Q Predictions Min            495.2209
V Predictions Mean           1187.3906
V Predictions Std            1177.5553
V Predictions Max            3750.9885
V Predictions Min            504.87775
Log Pis Mean                 -0.32210502
Log Pis Std                  3.705509
Log Pis Max                  13.144321
Log Pis Min                  -8.604168
Policy mu Mean               0.04275152
Policy mu Std                0.8962559
Policy mu Max                2.7351732
Policy mu Min                -2.4133248
Policy log std Mean          -0.50958824
Policy log std Std           0.24450162
Policy log std Max           -0.108245075
Policy log std Min           -2.1293695
Z mean eval                  1.6942619
Z variance eval              0.09794376
total_rewards                [8632.95683872 8676.85682769 8846.70275567 8936.89101883 8814.78527627
 8655.71828775 8790.97966925 8984.45267754 8870.11069264 8885.57510328]
total_rewards_mean           8809.502914764484
total_rewards_std            114.22061292773593
total_rewards_max            8984.452677544608
total_rewards_min            8632.956838724718
Number of train steps total  716000
Number of env steps total    2150000
Number of rollouts total     0
Train Time (s)               146.35559205524623
(Previous) Eval Time (s)     20.77053590072319
Sample Time (s)              6.486894185654819
Epoch Time (s)               173.61302214162424
Total Train Time (s)         30320.169105020817
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:18:58.962791 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #178 | Epoch Duration: 173.69892239570618
2020-01-12 16:18:58.963072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6923759
Z variance train             0.09796882
KL Divergence                39.548027
KL Loss                      3.9548028
QF Loss                      61.839207
VF Loss                      34.932076
Policy Loss                  -999.14734
Q Predictions Mean           999.6631
Q Predictions Std            1043.4205
Q Predictions Max            3716.914
Q Predictions Min            490.51797
V Predictions Mean           1002.34155
V Predictions Std            1042.5122
V Predictions Max            3712.7183
V Predictions Min            492.71558
Log Pis Mean                 -0.6330274
Log Pis Std                  3.2349293
Log Pis Max                  12.966345
Log Pis Min                  -6.320859
Policy mu Mean               -0.0055714077
Policy mu Std                0.8329428
Policy mu Max                2.5080755
Policy mu Min                -2.821793
Policy log std Mean          -0.4750462
Policy log std Std           0.22285497
Policy log std Max           -0.10340795
Policy log std Min           -2.2282233
Z mean eval                  1.665493
Z variance eval              0.0717429
total_rewards                [8381.87379153 8549.96148071 8853.64190725 8527.36108798 9025.33989149
 8840.53107773 8804.64839396 8704.600654   8791.36482238 8661.75903721]
total_rewards_mean           8714.108214422427
total_rewards_std            179.3077905254657
total_rewards_max            9025.33989148942
total_rewards_min            8381.873791527078
Number of train steps total  720000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               146.66667354479432
(Previous) Eval Time (s)     21.00497518805787
Sample Time (s)              6.549058952834457
Epoch Time (s)               174.22070768568665
Total Train Time (s)         30494.485300237313
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:21:53.280360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #179 | Epoch Duration: 174.31706285476685
2020-01-12 16:21:53.280609 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6676804
Z variance train             0.07192029
KL Divergence                38.664013
KL Loss                      3.8664014
QF Loss                      163.47878
VF Loss                      63.28457
Policy Loss                  -999.7759
Q Predictions Mean           993.6079
Q Predictions Std            1031.436
Q Predictions Max            3866.0
Q Predictions Min            505.05972
V Predictions Mean           996.6956
V Predictions Std            1030.2202
V Predictions Max            3841.573
V Predictions Min            512.34106
Log Pis Mean                 -0.37884724
Log Pis Std                  3.5527956
Log Pis Max                  12.49021
Log Pis Min                  -6.804724
Policy mu Mean               0.040824775
Policy mu Std                0.87437457
Policy mu Max                3.037385
Policy mu Min                -2.5841727
Policy log std Mean          -0.4913896
Policy log std Std           0.24801785
Policy log std Max           -0.12252971
Policy log std Min           -2.3237867
Z mean eval                  1.6852986
Z variance eval              0.08071253
total_rewards                [8307.95503807 8588.03873402 8505.76663806 2710.04149442 8287.56850041
 8635.45374516 8374.33722866 8378.77664905 8664.99503136 8263.15127305]
total_rewards_mean           7871.608433226717
total_rewards_std            1726.1751648219597
total_rewards_max            8664.99503136222
total_rewards_min            2710.041494419003
Number of train steps total  724000
Number of env steps total    2174000
Number of rollouts total     0
Train Time (s)               147.2059444868937
(Previous) Eval Time (s)     17.471482718829066
Sample Time (s)              6.327668683603406
Epoch Time (s)               171.00509588932618
Total Train Time (s)         30665.56648411695
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:24:44.361942 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #180 | Epoch Duration: 171.08116483688354
2020-01-12 16:24:44.362068 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6831768
Z variance train             0.080553666
KL Divergence                39.089607
KL Loss                      3.9089608
QF Loss                      223.28995
VF Loss                      185.13126
Policy Loss                  -1074.1578
Q Predictions Mean           1074.1628
Q Predictions Std            1092.0956
Q Predictions Max            3709.9834
Q Predictions Min            481.3003
V Predictions Mean           1076.3568
V Predictions Std            1086.2292
V Predictions Max            3728.8147
V Predictions Min            479.9881
Log Pis Mean                 -0.031360164
Log Pis Std                  3.6914644
Log Pis Max                  14.1808405
Log Pis Min                  -7.292016
Policy mu Mean               0.06914342
Policy mu Std                0.88528514
Policy mu Max                2.8421896
Policy mu Min                -3.7197642
Policy log std Mean          -0.505972
Policy log std Std           0.27387154
Policy log std Max           -0.040644944
Policy log std Min           -2.1336203
Z mean eval                  1.6642364
Z variance eval              0.07359573
total_rewards                [8071.77297664 8645.21069709 8616.77793377 8133.30952114 8909.45257923
 8494.54120956 8931.40190433 8867.6406523  8492.38885446 8651.72305269]
total_rewards_mean           8581.421938122372
total_rewards_std            282.54105589875655
total_rewards_max            8931.401904331064
total_rewards_min            8071.772976637262
Number of train steps total  728000
Number of env steps total    2186000
Number of rollouts total     0
Train Time (s)               146.1806647819467
(Previous) Eval Time (s)     17.724677585996687
Sample Time (s)              5.538220029789954
Epoch Time (s)               169.44356239773333
Total Train Time (s)         30835.091072749812
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:27:33.889254 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #181 | Epoch Duration: 169.52707433700562
2020-01-12 16:27:33.889432 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.666394
Z variance train             0.07386148
KL Divergence                38.181942
KL Loss                      3.8181942
QF Loss                      88.28792
VF Loss                      117.02282
Policy Loss                  -988.9998
Q Predictions Mean           989.24805
Q Predictions Std            1027.7803
Q Predictions Max            3847.2217
Q Predictions Min            500.704
V Predictions Mean           996.5965
V Predictions Std            1031.8088
V Predictions Max            3856.3242
V Predictions Min            501.0525
Log Pis Mean                 -0.35387734
Log Pis Std                  3.3473692
Log Pis Max                  10.734791
Log Pis Min                  -6.961877
Policy mu Mean               0.070555635
Policy mu Std                0.8689796
Policy mu Max                3.0094094
Policy mu Min                -2.5190241
Policy log std Mean          -0.4791762
Policy log std Std           0.23633948
Policy log std Max           -0.08435693
Policy log std Min           -1.9202514
Z mean eval                  1.6807957
Z variance eval              0.064743124
total_rewards                [8706.59883502 8771.12533754 8990.24525982 8800.47538849 8815.26327129
 8713.48342967 8809.10891983 8779.53177383 8965.91448974 8779.91740545]
total_rewards_mean           8813.166411068467
total_rewards_std            89.53680719700253
total_rewards_max            8990.245259819143
total_rewards_min            8706.598835023608
Number of train steps total  732000
Number of env steps total    2198000
Number of rollouts total     0
Train Time (s)               149.24344892520458
(Previous) Eval Time (s)     17.857403772883117
Sample Time (s)              6.533390552736819
Epoch Time (s)               173.6342432508245
Total Train Time (s)         31008.819211825263
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:30:27.620311 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #182 | Epoch Duration: 173.7307367324829
2020-01-12 16:30:27.620498 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6829824
Z variance train             0.06493826
KL Divergence                39.348465
KL Loss                      3.9348466
QF Loss                      123.732704
VF Loss                      142.9529
Policy Loss                  -1080.3712
Q Predictions Mean           1080.1722
Q Predictions Std            1101.5328
Q Predictions Max            3815.661
Q Predictions Min            478.71362
V Predictions Mean           1083.5515
V Predictions Std            1096.1123
V Predictions Max            3804.0725
V Predictions Min            498.78085
Log Pis Mean                 -0.40878057
Log Pis Std                  3.5061734
Log Pis Max                  11.946826
Log Pis Min                  -8.707611
Policy mu Mean               0.11593282
Policy mu Std                0.88142234
Policy mu Max                2.5572546
Policy mu Min                -3.1984022
Policy log std Mean          -0.499899
Policy log std Std           0.25807902
Policy log std Max           -0.076355815
Policy log std Min           -2.2470255
Z mean eval                  1.7054663
Z variance eval              0.06387605
total_rewards                [8609.04569985 8540.91817057 8834.56172915 8796.34900845 8505.38756551
 8575.07879459 8312.59609099 8686.11627069 8478.85044974 5108.41324401]
total_rewards_mean           8244.73170235509
total_rewards_std            1055.4825379121958
total_rewards_max            8834.561729151344
total_rewards_min            5108.413244013979
Number of train steps total  736000
Number of env steps total    2210000
Number of rollouts total     0
Train Time (s)               146.43098805705085
(Previous) Eval Time (s)     20.93689208989963
Sample Time (s)              6.604247314855456
Epoch Time (s)               173.97212746180594
Total Train Time (s)         31182.87598949764
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:33:21.678286 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #183 | Epoch Duration: 174.0576560497284
2020-01-12 16:33:21.678429 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7065881
Z variance train             0.06390907
KL Divergence                39.776844
KL Loss                      3.9776845
QF Loss                      4888.587
VF Loss                      48.15546
Policy Loss                  -1006.6428
Q Predictions Mean           1007.22797
Q Predictions Std            1046.6392
Q Predictions Max            3801.2883
Q Predictions Min            511.84335
V Predictions Mean           1009.0315
V Predictions Std            1041.226
V Predictions Max            3775.3562
V Predictions Min            513.9399
Log Pis Mean                 -0.68028575
Log Pis Std                  3.4260874
Log Pis Max                  10.661764
Log Pis Min                  -7.1725845
Policy mu Mean               0.007901371
Policy mu Std                0.82892424
Policy mu Max                2.9780633
Policy mu Min                -3.4027102
Policy log std Mean          -0.47880825
Policy log std Std           0.2370721
Policy log std Max           0.02617824
Policy log std Min           -1.8947015
Z mean eval                  1.6658407
Z variance eval              0.07405462
total_rewards                [8551.77222059 8900.15261778 8753.70547601 8826.49185518 8678.45074752
 8884.72119487 9010.04493606 8648.13219382 8866.12390708 8492.95586875]
total_rewards_mean           8761.255101766921
total_rewards_std            157.24629860340355
total_rewards_max            9010.044936057562
total_rewards_min            8492.955868752744
Number of train steps total  740000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               146.44592164317146
(Previous) Eval Time (s)     20.677749255672097
Sample Time (s)              6.5903394902125
Epoch Time (s)               173.71401038905606
Total Train Time (s)         31356.66955866618
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:36:15.473873 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #184 | Epoch Duration: 173.79534792900085
2020-01-12 16:36:15.474004 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6681888
Z variance train             0.074279994
KL Divergence                39.36576
KL Loss                      3.9365761
QF Loss                      115.72508
VF Loss                      156.89676
Policy Loss                  -1058.6951
Q Predictions Mean           1059.3735
Q Predictions Std            1089.0216
Q Predictions Max            3764.249
Q Predictions Min            477.86212
V Predictions Mean           1065.9973
V Predictions Std            1090.9125
V Predictions Max            3784.62
V Predictions Min            493.19843
Log Pis Mean                 -0.26908827
Log Pis Std                  3.6085756
Log Pis Max                  18.669975
Log Pis Min                  -7.5180674
Policy mu Mean               0.121090375
Policy mu Std                0.852294
Policy mu Max                2.666929
Policy mu Min                -3.775427
Policy log std Mean          -0.5035259
Policy log std Std           0.2531225
Policy log std Max           -0.025385618
Policy log std Min           -2.2420769
Z mean eval                  1.6881678
Z variance eval              0.0752055
total_rewards                [8960.7718307  8891.70750301 8975.32849256 9165.19634514 9073.00157654
 9133.3876182  9064.66258784 9015.89149942 9110.71160039 8898.28628901]
total_rewards_mean           9028.894534281313
total_rewards_std            91.08990236879298
total_rewards_max            9165.196345138613
total_rewards_min            8891.70750301241
Number of train steps total  744000
Number of env steps total    2234000
Number of rollouts total     0
Train Time (s)               146.0289580952376
(Previous) Eval Time (s)     20.61761238798499
Sample Time (s)              6.599296495318413
Epoch Time (s)               173.24586697854102
Total Train Time (s)         31529.99859035015
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:39:08.804063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #185 | Epoch Duration: 173.32996201515198
2020-01-12 16:39:08.804216 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6929147
Z variance train             0.07503499
KL Divergence                40.433067
KL Loss                      4.043307
QF Loss                      107.75513
VF Loss                      77.071236
Policy Loss                  -1160.8866
Q Predictions Mean           1159.7887
Q Predictions Std            1187.3699
Q Predictions Max            3895.4338
Q Predictions Min            508.6103
V Predictions Mean           1156.3226
V Predictions Std            1179.4282
V Predictions Max            3851.3083
V Predictions Min            510.72162
Log Pis Mean                 -0.12497142
Log Pis Std                  4.0862308
Log Pis Max                  14.847245
Log Pis Min                  -7.8579445
Policy mu Mean               0.034792468
Policy mu Std                0.89092773
Policy mu Max                2.8521965
Policy mu Min                -3.0593386
Policy log std Mean          -0.5130408
Policy log std Std           0.2736389
Policy log std Max           0.053883433
Policy log std Min           -2.652573
Z mean eval                  1.6832106
Z variance eval              0.044726856
total_rewards                [9127.28107347 9217.31309368 9381.53577756 9228.52926014 9224.72640406
 9374.82394744 8873.76168263 9323.7496019  9134.47222852 9045.91052268]
total_rewards_mean           9193.210359207356
total_rewards_std            148.27461606291993
total_rewards_max            9381.535777556284
total_rewards_min            8873.761682633372
Number of train steps total  748000
Number of env steps total    2246000
Number of rollouts total     0
Train Time (s)               146.69075849512592
(Previous) Eval Time (s)     17.503177902661264
Sample Time (s)              6.564194628037512
Epoch Time (s)               170.7581310258247
Total Train Time (s)         31700.83462200174
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:41:59.642702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #186 | Epoch Duration: 170.83836913108826
2020-01-12 16:41:59.642883 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6812952
Z variance train             0.044778105
KL Divergence                40.98622
KL Loss                      4.0986223
QF Loss                      120.175
VF Loss                      71.116554
Policy Loss                  -971.51263
Q Predictions Mean           965.75305
Q Predictions Std            1000.7689
Q Predictions Max            3814.5374
Q Predictions Min            490.57425
V Predictions Mean           968.2259
V Predictions Std            998.333
V Predictions Max            3797.3052
V Predictions Min            497.30133
Log Pis Mean                 -0.24333163
Log Pis Std                  3.7976022
Log Pis Max                  13.078165
Log Pis Min                  -8.25565
Policy mu Mean               0.07299315
Policy mu Std                0.8828938
Policy mu Max                2.7121458
Policy mu Min                -3.1922593
Policy log std Mean          -0.5220061
Policy log std Std           0.28319255
Policy log std Max           -0.08892533
Policy log std Min           -2.6927388
Z mean eval                  1.6982969
Z variance eval              0.073754236
total_rewards                [8729.11549421 8855.43115109 8534.85000619 8831.61565705 8747.45175516
 8842.92723104 8770.72902408 8771.01114152 8901.01092031 8798.67341147]
total_rewards_mean           8778.28157921226
total_rewards_std            95.49375458707605
total_rewards_max            8901.010920314637
total_rewards_min            8534.850006192728
Number of train steps total  752000
Number of env steps total    2258000
Number of rollouts total     0
Train Time (s)               146.2334445733577
(Previous) Eval Time (s)     20.514015895780176
Sample Time (s)              6.6737998547032475
Epoch Time (s)               173.42126032384112
Total Train Time (s)         31874.334378214553
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:44:53.143604 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #187 | Epoch Duration: 173.50058937072754
2020-01-12 16:44:53.143743 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.69918
Z variance train             0.07376666
KL Divergence                42.022305
KL Loss                      4.2022305
QF Loss                      203.33348
VF Loss                      58.304123
Policy Loss                  -1030.2057
Q Predictions Mean           1028.2969
Q Predictions Std            1052.1324
Q Predictions Max            3857.9048
Q Predictions Min            514.5825
V Predictions Mean           1027.4722
V Predictions Std            1046.4413
V Predictions Max            3834.3877
V Predictions Min            508.94064
Log Pis Mean                 -0.41910595
Log Pis Std                  3.8669984
Log Pis Max                  30.93509
Log Pis Min                  -6.8133607
Policy mu Mean               0.07851252
Policy mu Std                0.8694224
Policy mu Max                3.6326108
Policy mu Min                -5.131987
Policy log std Mean          -0.5172955
Policy log std Std           0.282295
Policy log std Max           0.24783498
Policy log std Min           -2.7574666
Z mean eval                  1.7012974
Z variance eval              0.06981384
total_rewards                [9055.8527424  9227.38238675 9326.92775445 9275.0929231  9042.88766155
 9357.5628536  9187.13099104 9025.91320589 9145.90520355 8998.66282145]
total_rewards_mean           9164.331854376103
total_rewards_std            124.0970315032281
total_rewards_max            9357.562853595204
total_rewards_min            8998.662821447433
Number of train steps total  756000
Number of env steps total    2270000
Number of rollouts total     0
Train Time (s)               146.06117654778063
(Previous) Eval Time (s)     17.705133387818933
Sample Time (s)              6.505432340782136
Epoch Time (s)               170.2717422763817
Total Train Time (s)         32044.684192322195
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:47:43.496358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #188 | Epoch Duration: 170.35249853134155
2020-01-12 16:47:43.496534 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7033889
Z variance train             0.06980344
KL Divergence                42.23034
KL Loss                      4.223034
QF Loss                      180.09535
VF Loss                      54.474594
Policy Loss                  -1079.5981
Q Predictions Mean           1071.3921
Q Predictions Std            1086.5505
Q Predictions Max            3827.7783
Q Predictions Min            499.3461
V Predictions Mean           1075.8838
V Predictions Std            1088.7896
V Predictions Max            3827.151
V Predictions Min            501.15488
Log Pis Mean                 -0.1831907
Log Pis Std                  3.8747375
Log Pis Max                  15.6215725
Log Pis Min                  -6.2285876
Policy mu Mean               0.019477552
Policy mu Std                0.9053817
Policy mu Max                3.1374824
Policy mu Min                -3.2183952
Policy log std Mean          -0.5156011
Policy log std Std           0.27503237
Policy log std Max           -0.07646938
Policy log std Min           -2.2903826
Z mean eval                  1.6967999
Z variance eval              0.07256846
total_rewards                [8055.87149681 8438.19148796 7923.94645699 8513.50889405 8402.25122365
 8342.48249914 8283.66198916 8091.45583201 8566.28655266 8177.85165204]
total_rewards_mean           8279.550808447138
total_rewards_std            200.83890490163424
total_rewards_max            8566.286552657562
total_rewards_min            7923.9464569894135
Number of train steps total  760000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               145.58566031977534
(Previous) Eval Time (s)     20.964581673964858
Sample Time (s)              6.614951249677688
Epoch Time (s)               173.1651932434179
Total Train Time (s)         32217.93081958685
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:50:36.743347 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #189 | Epoch Duration: 173.24668431282043
2020-01-12 16:50:36.743489 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.696228
Z variance train             0.072551355
KL Divergence                42.545883
KL Loss                      4.2545886
QF Loss                      4958.597
VF Loss                      58.29444
Policy Loss                  -1021.5836
Q Predictions Mean           1021.991
Q Predictions Std            1050.3866
Q Predictions Max            3894.7454
Q Predictions Min            499.67386
V Predictions Mean           1025.7759
V Predictions Std            1047.016
V Predictions Max            3896.5864
V Predictions Min            511.02496
Log Pis Mean                 -0.86824906
Log Pis Std                  3.1057398
Log Pis Max                  11.126255
Log Pis Min                  -7.6991215
Policy mu Mean               0.03502843
Policy mu Std                0.8167613
Policy mu Max                2.6623375
Policy mu Min                -2.4730887
Policy log std Mean          -0.4988329
Policy log std Std           0.24804287
Policy log std Max           -0.11597058
Policy log std Min           -2.2328906
Z mean eval                  1.7131548
Z variance eval              0.08508169
total_rewards                [8744.03473491 9010.82991797 9198.84992993 9036.29581483 9028.87370554
 9055.00217434 9186.43438188 9279.97704646 9036.0440885  9127.85564615]
total_rewards_mean           9070.419744051094
total_rewards_std            138.4033522907744
total_rewards_max            9279.977046456052
total_rewards_min            8744.034734910481
Number of train steps total  764000
Number of env steps total    2294000
Number of rollouts total     0
Train Time (s)               146.3015253241174
(Previous) Eval Time (s)     20.888772434089333
Sample Time (s)              6.453080204315484
Epoch Time (s)               173.6433779625222
Total Train Time (s)         32391.86983862752
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:53:30.684624 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #190 | Epoch Duration: 173.94103336334229
2020-01-12 16:53:30.684769 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7122301
Z variance train             0.085130155
KL Divergence                43.088146
KL Loss                      4.3088145
QF Loss                      111.17697
VF Loss                      73.83535
Policy Loss                  -1075.9713
Q Predictions Mean           1074.2484
Q Predictions Std            1101.0171
Q Predictions Max            3814.6982
Q Predictions Min            524.4989
V Predictions Mean           1079.4575
V Predictions Std            1099.6755
V Predictions Max            3809.6775
V Predictions Min            531.6801
Log Pis Mean                 -0.4649627
Log Pis Std                  3.5166104
Log Pis Max                  13.519795
Log Pis Min                  -7.2708373
Policy mu Mean               0.100054145
Policy mu Std                0.8456689
Policy mu Max                3.5056214
Policy mu Min                -2.8714228
Policy log std Mean          -0.49662375
Policy log std Std           0.26584595
Policy log std Max           -0.06025821
Policy log std Min           -2.2817042
Z mean eval                  1.7108405
Z variance eval              0.09768604
total_rewards                [9064.96492276 8843.84718069 9080.48177216 7849.36996687 8888.08364186
 8996.29248104 8447.2173203  8684.48798925 8790.55424429 8933.08400103]
total_rewards_mean           8757.838352024508
total_rewards_std            351.9387883956527
total_rewards_max            9080.481772161405
total_rewards_min            7849.369966873522
Number of train steps total  768000
Number of env steps total    2306000
Number of rollouts total     0
Train Time (s)               147.20914561674
(Previous) Eval Time (s)     20.798536719288677
Sample Time (s)              6.364354544319212
Epoch Time (s)               174.37203688034788
Total Train Time (s)         32566.33170265844
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:56:25.148654 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #191 | Epoch Duration: 174.46378540992737
2020-01-12 16:56:25.148788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.71293
Z variance train             0.09752443
KL Divergence                42.328804
KL Loss                      4.2328806
QF Loss                      109.03102
VF Loss                      39.30071
Policy Loss                  -1110.9706
Q Predictions Mean           1106.7029
Q Predictions Std            1111.5198
Q Predictions Max            3931.006
Q Predictions Min            515.82495
V Predictions Mean           1107.3689
V Predictions Std            1111.3822
V Predictions Max            3916.4011
V Predictions Min            520.30457
Log Pis Mean                 -0.6646637
Log Pis Std                  3.3591914
Log Pis Max                  11.680065
Log Pis Min                  -8.9846525
Policy mu Mean               0.059820037
Policy mu Std                0.846148
Policy mu Max                2.658929
Policy mu Min                -2.3936138
Policy log std Mean          -0.5142879
Policy log std Std           0.2466024
Policy log std Max           -0.031241536
Policy log std Min           -2.1553342
Z mean eval                  1.7075217
Z variance eval              0.09866415
total_rewards                [8667.54094963 2007.01678196 8769.71225676 8387.94578415 7955.34924932
 8181.82273449 8718.43459239 8195.27034475 8292.11266287 8110.82876064]
total_rewards_mean           7728.6034116968485
total_rewards_std            1924.962372848213
total_rewards_max            8769.712256763962
total_rewards_min            2007.016781955846
Number of train steps total  772000
Number of env steps total    2318000
Number of rollouts total     0
Train Time (s)               146.4284183094278
(Previous) Eval Time (s)     17.65025059087202
Sample Time (s)              6.390867673326284
Epoch Time (s)               170.4695365736261
Total Train Time (s)         32736.881064675283
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:59:15.700638 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #192 | Epoch Duration: 170.5517373085022
2020-01-12 16:59:15.700818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7113688
Z variance train             0.098663405
KL Divergence                42.053387
KL Loss                      4.205339
QF Loss                      2416.602
VF Loss                      126.08724
Policy Loss                  -1095.1356
Q Predictions Mean           1092.9553
Q Predictions Std            1130.604
Q Predictions Max            3909.1145
Q Predictions Min            508.8816
V Predictions Mean           1088.1948
V Predictions Std            1122.0159
V Predictions Max            3873.28
V Predictions Min            511.42462
Log Pis Mean                 -0.4339831
Log Pis Std                  3.5144646
Log Pis Max                  9.88088
Log Pis Min                  -7.5665216
Policy mu Mean               0.032218274
Policy mu Std                0.86186385
Policy mu Max                2.7161193
Policy mu Min                -2.4632177
Policy log std Mean          -0.5085588
Policy log std Std           0.2539084
Policy log std Max           -0.07049793
Policy log std Min           -2.5394394
Z mean eval                  1.6939878
Z variance eval              0.09998199
total_rewards                [8863.46816519 8971.66166663 9121.9370417  8719.17578061 8961.05348493
 8976.56614979 8960.71069964 9074.09421537 8864.30037384 9004.72990286]
total_rewards_mean           8951.76974805636
total_rewards_std            108.37419163692454
total_rewards_max            9121.937041702251
total_rewards_min            8719.175780609427
Number of train steps total  776000
Number of env steps total    2330000
Number of rollouts total     0
Train Time (s)               146.1112747597508
(Previous) Eval Time (s)     17.79670001938939
Sample Time (s)              6.5550921922549605
Epoch Time (s)               170.46306697139516
Total Train Time (s)         32907.42897571856
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:02:06.251603 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #193 | Epoch Duration: 170.55057764053345
2020-01-12 17:02:06.251878 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #193 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6941035
Z variance train             0.10006094
KL Divergence                41.76322
KL Loss                      4.1763225
QF Loss                      146.84152
VF Loss                      78.51757
Policy Loss                  -1092.3801
Q Predictions Mean           1089.6675
Q Predictions Std            1116.3761
Q Predictions Max            3844.5835
Q Predictions Min            509.43054
V Predictions Mean           1090.3726
V Predictions Std            1113.3141
V Predictions Max            3827.8677
V Predictions Min            510.29926
Log Pis Mean                 -0.6024409
Log Pis Std                  3.4898708
Log Pis Max                  14.074636
Log Pis Min                  -6.2672963
Policy mu Mean               0.04730612
Policy mu Std                0.83883363
Policy mu Max                3.1972768
Policy mu Min                -2.6674995
Policy log std Mean          -0.519337
Policy log std Std           0.27979717
Policy log std Max           -0.07951045
Policy log std Min           -2.7826838
Z mean eval                  1.687499
Z variance eval              0.09934179
total_rewards                [8948.24573182 9311.46456939 9349.55976587 9249.90585742 9321.7475005
 8986.36302182 9233.56369099 9122.57513271  940.2629385  9054.11324564]
total_rewards_mean           8351.780145463623
total_rewards_std            2474.2275092983887
total_rewards_max            9349.55976586637
total_rewards_min            940.2629384956426
Number of train steps total  780000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               146.29665383836254
(Previous) Eval Time (s)     20.944590090774
Sample Time (s)              6.55358438519761
Epoch Time (s)               173.79482831433415
Total Train Time (s)         33081.30736576766
Epoch                        194
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:05:00.131973 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #194 | Epoch Duration: 173.879900932312
2020-01-12 17:05:00.132162 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6905864
Z variance train             0.09944467
KL Divergence                42.120075
KL Loss                      4.2120075
QF Loss                      131.38678
VF Loss                      150.87064
Policy Loss                  -1126.9905
Q Predictions Mean           1123.0107
Q Predictions Std            1117.5967
Q Predictions Max            3954.2698
Q Predictions Min            522.7745
V Predictions Mean           1121.9597
V Predictions Std            1113.3804
V Predictions Max            3896.791
V Predictions Min            509.06122
Log Pis Mean                 -0.33159247
Log Pis Std                  3.605218
Log Pis Max                  12.687901
Log Pis Min                  -7.418553
Policy mu Mean               0.044152368
Policy mu Std                0.85397077
Policy mu Max                2.7186706
Policy mu Min                -3.1039262
Policy log std Mean          -0.5266972
Policy log std Std           0.26946068
Policy log std Max           -0.10856207
Policy log std Min           -2.5221846
Z mean eval                  1.6858763
Z variance eval              0.09752665
total_rewards                [8598.15088834 8791.00557521 8514.59404653 8650.23633292 8925.93605988
 8882.93467989 8755.42190292 8783.56037741 8841.11109079 8696.02344304]
total_rewards_mean           8743.897439692844
total_rewards_std            122.77274595711228
total_rewards_max            8925.936059875186
total_rewards_min            8514.594046525977
Number of train steps total  784000
Number of env steps total    2354000
Number of rollouts total     0
Train Time (s)               145.39813102781773
(Previous) Eval Time (s)     20.768622654955834
Sample Time (s)              6.4320673337206244
Epoch Time (s)               172.59882101649418
Total Train Time (s)         33254.1308147884
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:07:52.968422 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #195 | Epoch Duration: 172.8360824584961
2020-01-12 17:07:52.968644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6869322
Z variance train             0.09857558
KL Divergence                41.740486
KL Loss                      4.174049
QF Loss                      2655.0027
VF Loss                      236.94188
Policy Loss                  -994.03394
Q Predictions Mean           990.6623
Q Predictions Std            1011.4478
Q Predictions Max            3822.3179
Q Predictions Min            508.60336
V Predictions Mean           983.782
V Predictions Std            1001.33344
V Predictions Max            3789.1675
V Predictions Min            504.4289
Log Pis Mean                 -0.41232193
Log Pis Std                  3.2441995
Log Pis Max                  14.015472
Log Pis Min                  -5.7023067
Policy mu Mean               0.065329485
Policy mu Std                0.8528315
Policy mu Max                2.5796323
Policy mu Min                -2.3421009
Policy log std Mean          -0.51113415
Policy log std Std           0.25445306
Policy log std Max           -0.06577748
Policy log std Min           -2.3574493
Z mean eval                  1.6972668
Z variance eval              0.072154336
total_rewards                [9084.05034776 9289.10403729 9106.24619919 9036.86696754 8879.08527931
 8804.35633206 8997.89068029 9159.0003147  9311.77155369 8876.99261705]
total_rewards_mean           9054.536432886644
total_rewards_std            162.50092002550923
total_rewards_max            9311.771553689257
total_rewards_min            8804.35633205933
Number of train steps total  788000
Number of env steps total    2366000
Number of rollouts total     0
Train Time (s)               145.12612400529906
(Previous) Eval Time (s)     20.77337004803121
Sample Time (s)              6.528977301903069
Epoch Time (s)               172.42847135523334
Total Train Time (s)         33426.66569200717
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:10:45.501788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #196 | Epoch Duration: 172.5330033302307
2020-01-12 17:10:45.501984 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #196 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.697056
Z variance train             0.0721449
KL Divergence                42.3384
KL Loss                      4.2338405
QF Loss                      127.26834
VF Loss                      49.471657
Policy Loss                  -1068.5692
Q Predictions Mean           1069.5156
Q Predictions Std            1107.2277
Q Predictions Max            3961.0647
Q Predictions Min            508.89404
V Predictions Mean           1073.2957
V Predictions Std            1105.42
V Predictions Max            3974.995
V Predictions Min            529.3073
Log Pis Mean                 -0.36789978
Log Pis Std                  3.3500416
Log Pis Max                  10.806175
Log Pis Min                  -6.775489
Policy mu Mean               0.06737876
Policy mu Std                0.8642825
Policy mu Max                2.5811691
Policy mu Min                -2.7266467
Policy log std Mean          -0.504394
Policy log std Std           0.25166667
Policy log std Max           0.14978456
Policy log std Min           -2.1345081
Z mean eval                  1.7132845
Z variance eval              0.046563752
total_rewards                [9400.63277713 9239.78458436 9127.05388018 9475.27252825 9140.4557224
 9390.94268946 9268.3348912  9313.07617424 9484.31704902 9369.31508886]
total_rewards_mean           9320.918538510361
total_rewards_std            119.86817339661017
total_rewards_max            9484.317049021536
total_rewards_min            9127.053880182466
Number of train steps total  792000
Number of env steps total    2378000
Number of rollouts total     0
Train Time (s)               146.23433418991044
(Previous) Eval Time (s)     17.264515683054924
Sample Time (s)              6.498865949455649
Epoch Time (s)               169.99771582242101
Total Train Time (s)         33596.77547014784
Epoch                        197
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:13:35.605472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #197 | Epoch Duration: 170.10334062576294
2020-01-12 17:13:35.605644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7101166
Z variance train             0.046656154
KL Divergence                43.33781
KL Loss                      4.3337812
QF Loss                      155.17923
VF Loss                      67.90176
Policy Loss                  -1132.5665
Q Predictions Mean           1129.8606
Q Predictions Std            1136.9994
Q Predictions Max            3843.9482
Q Predictions Min            523.76807
V Predictions Mean           1134.732
V Predictions Std            1139.3578
V Predictions Max            3858.0635
V Predictions Min            518.5453
Log Pis Mean                 -0.20544933
Log Pis Std                  3.8032186
Log Pis Max                  16.528885
Log Pis Min                  -7.123689
Policy mu Mean               0.04097895
Policy mu Std                0.8869602
Policy mu Max                2.7028778
Policy mu Min                -3.1180735
Policy log std Mean          -0.50919896
Policy log std Std           0.25642294
Policy log std Max           -0.016150653
Policy log std Min           -2.4187155
Z mean eval                  1.7298286
Z variance eval              0.034972824
total_rewards                [8885.23527284 9062.23051812 8762.77357894 9080.35799275 8959.74715058
 9061.72889101 9076.00596579 9088.36798266 8815.36808447 8881.20348039]
total_rewards_mean           8967.30189175462
total_rewards_std            116.74922328420581
total_rewards_max            9088.36798265947
total_rewards_min            8762.773578941942
Number of train steps total  796000
Number of env steps total    2390000
Number of rollouts total     0
Train Time (s)               146.79004019405693
(Previous) Eval Time (s)     17.642449305858463
Sample Time (s)              5.566497159190476
Epoch Time (s)               169.99898665910587
Total Train Time (s)         33766.861504524015
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:16:25.700630 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #198 | Epoch Duration: 170.0948028564453
2020-01-12 17:16:25.700950 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #198 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.730148
Z variance train             0.03510184
KL Divergence                45.136093
KL Loss                      4.5136094
QF Loss                      2917.624
VF Loss                      51.886482
Policy Loss                  -1137.0054
Q Predictions Mean           1135.0513
Q Predictions Std            1146.0348
Q Predictions Max            3960.175
Q Predictions Min            509.89648
V Predictions Mean           1136.6287
V Predictions Std            1141.7587
V Predictions Max            3940.1152
V Predictions Min            514.72577
Log Pis Mean                 -0.1736877
Log Pis Std                  3.6384394
Log Pis Max                  12.312453
Log Pis Min                  -7.2218714
Policy mu Mean               0.09689351
Policy mu Std                0.89153004
Policy mu Max                2.5628476
Policy mu Min                -2.536098
Policy log std Mean          -0.51021296
Policy log std Std           0.26506257
Policy log std Max           0.101284266
Policy log std Min           -2.5537746
Z mean eval                  1.6934904
Z variance eval              0.06726597
total_rewards                [9035.13707719 9060.57770612 9034.11948595 8896.19638665 8929.130574
 8953.68668346 9145.33438515 9123.97715044 9074.90246392 9182.21775596]
total_rewards_mean           9043.527966883248
total_rewards_std            89.64946680287748
total_rewards_max            9182.217755956162
total_rewards_min            8896.196386653877
Number of train steps total  800000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               147.95308530004695
(Previous) Eval Time (s)     20.543671780265868
Sample Time (s)              6.628586707636714
Epoch Time (s)               175.12534378794953
Total Train Time (s)         33942.07764771301
Epoch                        199
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:19:20.915157 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #199 | Epoch Duration: 175.21397614479065
2020-01-12 17:19:20.915330 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6934481
Z variance train             0.06693025
KL Divergence                42.637115
KL Loss                      4.2637115
QF Loss                      90.05505
VF Loss                      40.932335
Policy Loss                  -1032.6726
Q Predictions Mean           1031.0654
Q Predictions Std            1054.4419
Q Predictions Max            3895.7703
Q Predictions Min            511.85114
V Predictions Mean           1030.1371
V Predictions Std            1050.9147
V Predictions Max            3871.3066
V Predictions Min            513.6952
Log Pis Mean                 -0.6363443
Log Pis Std                  3.189686
Log Pis Max                  10.824417
Log Pis Min                  -7.319549
Policy mu Mean               0.027788669
Policy mu Std                0.83063024
Policy mu Max                2.7241476
Policy mu Min                -2.7460096
Policy log std Mean          -0.5051399
Policy log std Std           0.2380272
Policy log std Max           -0.10197112
Policy log std Min           -2.2224302
Z mean eval                  1.7046881
Z variance eval              0.07738371
total_rewards                [8635.62865008 9180.35615152 8836.09541041 8560.40554791 8690.61258751
 9056.37352271 8733.50789677 8936.39478769 9041.83369063 9179.53014864]
total_rewards_mean           8885.073839388815
total_rewards_std            214.77102598417872
total_rewards_max            9180.356151517468
total_rewards_min            8560.405547914112
Number of train steps total  804000
Number of env steps total    2414000
Number of rollouts total     0
Train Time (s)               146.65308483038098
(Previous) Eval Time (s)     20.704933612141758
Sample Time (s)              6.581762968562543
Epoch Time (s)               173.93978141108528
Total Train Time (s)         34116.114224698395
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:22:14.952907 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #200 | Epoch Duration: 174.0374550819397
2020-01-12 17:22:14.953039 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #200 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7025543
Z variance train             0.077754855
KL Divergence                43.079063
KL Loss                      4.3079066
QF Loss                      262.73804
VF Loss                      115.987
Policy Loss                  -1062.7311
Q Predictions Mean           1060.2556
Q Predictions Std            1111.2787
Q Predictions Max            3966.4458
Q Predictions Min            505.7833
V Predictions Mean           1065.2811
V Predictions Std            1105.2432
V Predictions Max            3951.12
V Predictions Min            513.8231
Log Pis Mean                 -0.25854868
Log Pis Std                  3.3496912
Log Pis Max                  13.916698
Log Pis Min                  -6.3010397
Policy mu Mean               0.030226903
Policy mu Std                0.8847779
Policy mu Max                2.7222977
Policy mu Min                -2.9807284
Policy log std Mean          -0.5126122
Policy log std Std           0.25592157
Policy log std Max           0.027311087
Policy log std Min           -2.2823534
Z mean eval                  1.7027302
Z variance eval              0.08439375
total_rewards                [9256.29474799 8722.04319239 9008.89110593 9374.49495664 9181.3014047
 9123.07689693 9025.04572697 9247.19248194 9205.59880837 9356.76608279]
total_rewards_mean           9150.070540465571
total_rewards_std            183.67451625353428
total_rewards_max            9374.494956637676
total_rewards_min            8722.043192387528
Number of train steps total  808000
Number of env steps total    2426000
Number of rollouts total     0
Train Time (s)               146.6006886921823
(Previous) Eval Time (s)     20.985144505277276
Sample Time (s)              6.4868084019981325
Epoch Time (s)               174.0726415994577
Total Train Time (s)         34290.268560175784
Epoch                        201
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:25:09.109703 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #201 | Epoch Duration: 174.15656805038452
2020-01-12 17:25:09.109835 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7040704
Z variance train             0.08433118
KL Divergence                43.038284
KL Loss                      4.3038287
QF Loss                      128.56938
VF Loss                      49.131824
Policy Loss                  -969.7598
Q Predictions Mean           967.71985
Q Predictions Std            1004.434
Q Predictions Max            3947.7324
Q Predictions Min            533.07764
V Predictions Mean           967.35486
V Predictions Std            1002.2098
V Predictions Max            3940.7803
V Predictions Min            538.7566
Log Pis Mean                 -0.77706933
Log Pis Std                  3.1419814
Log Pis Max                  11.614351
Log Pis Min                  -6.813018
Policy mu Mean               0.11206687
Policy mu Std                0.8236692
Policy mu Max                2.656862
Policy mu Min                -2.6422122
Policy log std Mean          -0.4997275
Policy log std Std           0.25389695
Policy log std Max           -0.03843385
Policy log std Min           -2.3095987
Z mean eval                  1.7314816
Z variance eval              0.05944872
total_rewards                [8962.89871386 9295.11216908 9079.80439342 9319.55555777 9181.30589408
 9211.80810827 8952.34715282 9023.32113935 9223.57665005 9001.13942716]
total_rewards_mean           9125.08692058484
total_rewards_std            130.77530522034843
total_rewards_max            9319.555557773198
total_rewards_min            8952.347152816446
Number of train steps total  812000
Number of env steps total    2438000
Number of rollouts total     0
Train Time (s)               146.30680440366268
(Previous) Eval Time (s)     17.450661988928914
Sample Time (s)              6.613486037123948
Epoch Time (s)               170.37095242971554
Total Train Time (s)         34460.71851816634
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:27:59.561807 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #202 | Epoch Duration: 170.4518575668335
2020-01-12 17:27:59.561984 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7280226
Z variance train             0.059491236
KL Divergence                43.006504
KL Loss                      4.3006506
QF Loss                      218.16162
VF Loss                      49.431828
Policy Loss                  -1145.1229
Q Predictions Mean           1143.084
Q Predictions Std            1154.9609
Q Predictions Max            3938.4329
Q Predictions Min            536.3683
V Predictions Mean           1149.331
V Predictions Std            1150.6135
V Predictions Max            3932.0867
V Predictions Min            536.6733
Log Pis Mean                 -0.23706186
Log Pis Std                  3.62566
Log Pis Max                  13.337173
Log Pis Min                  -6.336797
Policy mu Mean               0.055251688
Policy mu Std                0.87684625
Policy mu Max                2.6041398
Policy mu Min                -3.2638223
Policy log std Mean          -0.5313512
Policy log std Std           0.26353863
Policy log std Max           -0.07100195
Policy log std Min           -2.4740162
Z mean eval                  1.6924375
Z variance eval              0.08173929
total_rewards                [9387.12025017 9582.17877241 9427.4809419  9147.32953664 9358.40084674
 9426.93718343 9466.81209778 9280.15773839 9455.61685981 9345.18268605]
total_rewards_mean           9387.72169133243
total_rewards_std            111.27681166472821
total_rewards_max            9582.178772406234
total_rewards_min            9147.329536635338
Number of train steps total  816000
Number of env steps total    2450000
Number of rollouts total     0
Train Time (s)               146.11444965470582
(Previous) Eval Time (s)     20.962142202071846
Sample Time (s)              6.429278474766761
Epoch Time (s)               173.50587033154443
Total Train Time (s)         34634.30784211354
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:30:53.154419 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #203 | Epoch Duration: 173.59225368499756
2020-01-12 17:30:53.154777 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6925848
Z variance train             0.08170718
KL Divergence                41.83606
KL Loss                      4.183606
QF Loss                      2798.2761
VF Loss                      37.48662
Policy Loss                  -891.8705
Q Predictions Mean           889.69214
Q Predictions Std            887.7412
Q Predictions Max            3937.3062
Q Predictions Min            508.95593
V Predictions Mean           891.961
V Predictions Std            886.7543
V Predictions Max            3937.7725
V Predictions Min            503.5324
Log Pis Mean                 -0.3690133
Log Pis Std                  3.2065904
Log Pis Max                  13.994274
Log Pis Min                  -6.6884956
Policy mu Mean               0.117606424
Policy mu Std                0.81976503
Policy mu Max                2.6123426
Policy mu Min                -2.8047683
Policy log std Mean          -0.524576
Policy log std Std           0.26558673
Policy log std Max           -0.0017889738
Policy log std Min           -2.8540447
Z mean eval                  1.6903225
Z variance eval              0.05551973
total_rewards                [8800.95313272 9230.35869249 8869.4653431  9051.99564197 8954.59150072
 9118.55430205 9139.07371282 8960.47036955 9059.11963547 9010.17206148]
total_rewards_mean           9019.47543923861
total_rewards_std            122.16973620274265
total_rewards_max            9230.358692494017
total_rewards_min            8800.953132716475
Number of train steps total  820000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               146.2352784909308
(Previous) Eval Time (s)     20.68618691712618
Sample Time (s)              5.461730735376477
Epoch Time (s)               172.38319614343345
Total Train Time (s)         34806.86846993631
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:33:45.719645 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #204 | Epoch Duration: 172.56465578079224
2020-01-12 17:33:45.719865 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6906471
Z variance train             0.055423014
KL Divergence                40.743412
KL Loss                      4.0743413
QF Loss                      65.984024
VF Loss                      41.57206
Policy Loss                  -987.5015
Q Predictions Mean           985.16815
Q Predictions Std            1008.15546
Q Predictions Max            3896.6208
Q Predictions Min            526.492
V Predictions Mean           989.71826
V Predictions Std            1005.7356
V Predictions Max            3897.4631
V Predictions Min            531.1801
Log Pis Mean                 -0.5705572
Log Pis Std                  3.1791873
Log Pis Max                  12.076463
Log Pis Min                  -6.6921935
Policy mu Mean               0.04897066
Policy mu Std                0.8237012
Policy mu Max                2.8734207
Policy mu Min                -2.9739344
Policy log std Mean          -0.51332456
Policy log std Std           0.2759577
Policy log std Max           -0.06010151
Policy log std Min           -3.0441368
Z mean eval                  1.694061
Z variance eval              0.17534448
total_rewards                [8522.28581664 8727.04272125 8744.22807007 8729.46642272 8766.65580571
 8536.74072661 8879.14772599 8606.89090823 8767.17556941 8533.12063167]
total_rewards_mean           8681.275439830473
total_rewards_std            116.55600312058928
total_rewards_max            8879.147725985078
total_rewards_min            8522.28581664432
Number of train steps total  824000
Number of env steps total    2474000
Number of rollouts total     0
Train Time (s)               145.50517260935158
(Previous) Eval Time (s)     20.992055953014642
Sample Time (s)              6.4334769560955465
Epoch Time (s)               172.93070551846176
Total Train Time (s)         34979.898139628116
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:36:38.749014 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #205 | Epoch Duration: 173.0289978981018
2020-01-12 17:36:38.749152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6941204
Z variance train             0.17628342
KL Divergence                36.657467
KL Loss                      3.6657467
QF Loss                      248.04498
VF Loss                      88.03432
Policy Loss                  -1129.4954
Q Predictions Mean           1127.0642
Q Predictions Std            1159.8922
Q Predictions Max            3984.654
Q Predictions Min            529.77014
V Predictions Mean           1126.9668
V Predictions Std            1161.3185
V Predictions Max            4002.2344
V Predictions Min            521.97003
Log Pis Mean                 0.1136894
Log Pis Std                  3.886417
Log Pis Max                  18.714848
Log Pis Min                  -7.621908
Policy mu Mean               -0.018717026
Policy mu Std                0.9463863
Policy mu Max                3.0051389
Policy mu Min                -3.1722193
Policy log std Mean          -0.4756864
Policy log std Std           0.24740605
Policy log std Max           0.0004773736
Policy log std Min           -2.314725
Z mean eval                  1.735349
Z variance eval              0.13897789
total_rewards                [8911.13167997 9168.65687446 9114.3796691  8820.8405071  9021.18266949
 9313.01805684 8943.9738834  9090.06263041 9033.5042699  9062.63102755]
total_rewards_mean           9047.938126821191
total_rewards_std            131.63103981255654
total_rewards_max            9313.018056838313
total_rewards_min            8820.840507096595
Number of train steps total  828000
Number of env steps total    2486000
Number of rollouts total     0
Train Time (s)               146.93720084009692
(Previous) Eval Time (s)     19.570022805128247
Sample Time (s)              6.476296167355031
Epoch Time (s)               172.9835198125802
Total Train Time (s)         35153.00406690873
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:39:31.866612 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #206 | Epoch Duration: 173.11733961105347
2020-01-12 17:39:31.866828 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7378677
Z variance train             0.13888685
KL Divergence                38.66286
KL Loss                      3.866286
QF Loss                      140.82191
VF Loss                      61.11139
Policy Loss                  -1081.3616
Q Predictions Mean           1080.7632
Q Predictions Std            1091.1627
Q Predictions Max            4080.2942
Q Predictions Min            542.2383
V Predictions Mean           1080.7961
V Predictions Std            1087.1604
V Predictions Max            4050.0957
V Predictions Min            548.38025
Log Pis Mean                 -0.15279005
Log Pis Std                  3.5692475
Log Pis Max                  15.352744
Log Pis Min                  -10.105234
Policy mu Mean               0.006608682
Policy mu Std                0.9063831
Policy mu Max                2.5421734
Policy mu Min                -3.4760025
Policy log std Mean          -0.49777377
Policy log std Std           0.24644548
Policy log std Max           -0.021213114
Policy log std Min           -2.464424
Z mean eval                  1.7130544
Z variance eval              0.18530285
total_rewards                [8880.91843699 8741.02966101 8657.50834887 8670.24581531 8858.28912114
 8723.54448849 8954.19656741 8704.649761   8796.88256958 8773.91148641]
total_rewards_mean           8776.117625620971
total_rewards_std            91.79503288819103
total_rewards_max            8954.19656741343
total_rewards_min            8657.508348874024
Number of train steps total  832000
Number of env steps total    2498000
Number of rollouts total     0
Train Time (s)               143.655111821834
(Previous) Eval Time (s)     21.95609152689576
Sample Time (s)              6.91140774730593
Epoch Time (s)               172.5226110960357
Total Train Time (s)         35325.61553229997
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:42:24.472613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #207 | Epoch Duration: 172.60564851760864
2020-01-12 17:42:24.472745 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7113113
Z variance train             0.1855948
KL Divergence                37.94906
KL Loss                      3.794906
QF Loss                      234.90213
VF Loss                      29.879597
Policy Loss                  -1166.9312
Q Predictions Mean           1164.167
Q Predictions Std            1187.9684
Q Predictions Max            4133.4634
Q Predictions Min            522.7659
V Predictions Mean           1167.4124
V Predictions Std            1188.6041
V Predictions Max            4139.5127
V Predictions Min            533.93787
Log Pis Mean                 -0.3580705
Log Pis Std                  3.3955433
Log Pis Max                  12.93464
Log Pis Min                  -5.9884186
Policy mu Mean               0.02292051
Policy mu Std                0.8771618
Policy mu Max                2.8516917
Policy mu Min                -2.748975
Policy log std Mean          -0.5326974
Policy log std Std           0.2819091
Policy log std Max           -0.0036711395
Policy log std Min           -2.811674
Z mean eval                  1.7142677
Z variance eval              0.12710182
total_rewards                [9064.49360866 9084.86728605 9062.13478498 9135.35405517 9364.88434989
 9213.11309527 9145.08137325 8970.06269472 8951.31974702 9118.00178156]
total_rewards_mean           9110.931277657304
total_rewards_std            112.81961916722486
total_rewards_max            9364.88434989149
total_rewards_min            8951.319747024985
Number of train steps total  836000
Number of env steps total    2510000
Number of rollouts total     0
Train Time (s)               144.3762525380589
(Previous) Eval Time (s)     20.815607185009867
Sample Time (s)              6.896891946904361
Epoch Time (s)               172.08875166997313
Total Train Time (s)         35497.7839936642
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:45:16.652090 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #208 | Epoch Duration: 172.17924904823303
2020-01-12 17:45:16.652224 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.712814
Z variance train             0.12687448
KL Divergence                38.77152
KL Loss                      3.877152
QF Loss                      2749.7139
VF Loss                      191.15712
Policy Loss                  -1258.1925
Q Predictions Mean           1257.766
Q Predictions Std            1267.8527
Q Predictions Max            4044.3735
Q Predictions Min            502.2954
V Predictions Mean           1268.1592
V Predictions Std            1272.1788
V Predictions Max            4039.4033
V Predictions Min            507.65613
Log Pis Mean                 0.22878888
Log Pis Std                  3.8011475
Log Pis Max                  14.200465
Log Pis Min                  -5.9273806
Policy mu Mean               0.025564425
Policy mu Std                0.9287778
Policy mu Max                2.9686956
Policy mu Min                -3.2209122
Policy log std Mean          -0.5344067
Policy log std Std           0.26013207
Policy log std Max           0.24928093
Policy log std Min           -2.3762124
Z mean eval                  1.7091122
Z variance eval              0.07407548
total_rewards                [9232.34369818 9508.05845685 9397.01060684 9285.29081517 9258.66877188
 9305.32651157 9258.16365039 9274.1542535  9234.30268099 9300.95193063]
total_rewards_mean           9305.427137599567
total_rewards_std            81.03736494843014
total_rewards_max            9508.058456851146
total_rewards_min            9232.343698178307
Number of train steps total  840000
Number of env steps total    2522000
Number of rollouts total     0
Train Time (s)               143.91588306613266
(Previous) Eval Time (s)     21.111531027127057
Sample Time (s)              6.59813128085807
Epoch Time (s)               171.6255453741178
Total Train Time (s)         35669.50284263771
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:48:08.365283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #209 | Epoch Duration: 171.71294379234314
2020-01-12 17:48:08.365472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7082949
Z variance train             0.074122146
KL Divergence                40.026768
KL Loss                      4.002677
QF Loss                      222.36508
VF Loss                      56.87302
Policy Loss                  -1327.4528
Q Predictions Mean           1321.2494
Q Predictions Std            1299.1411
Q Predictions Max            4117.9688
Q Predictions Min            507.92996
V Predictions Mean           1329.4716
V Predictions Std            1304.4058
V Predictions Max            4104.146
V Predictions Min            525.1413
Log Pis Mean                 0.28042114
Log Pis Std                  3.8466322
Log Pis Max                  12.965671
Log Pis Min                  -6.301421
Policy mu Mean               0.05829531
Policy mu Std                0.94377303
Policy mu Max                2.7349207
Policy mu Min                -2.735943
Policy log std Mean          -0.543623
Policy log std Std           0.28455487
Policy log std Max           -0.07125291
Policy log std Min           -2.5396104
Z mean eval                  1.7066746
Z variance eval              0.089258716
total_rewards                [8553.54979952 9172.39667209 9105.98260973 9221.72387024 9149.98970937
 9216.49968053 8931.03345228 9181.8790011  6384.38570599 9275.86589511]
total_rewards_mean           8819.3306395954
total_rewards_std            835.9284366400548
total_rewards_max            9275.865895107858
total_rewards_min            6384.385705986135
Number of train steps total  844000
Number of env steps total    2534000
Number of rollouts total     0
Train Time (s)               146.73322032624856
(Previous) Eval Time (s)     21.078335050027817
Sample Time (s)              6.955166131723672
Epoch Time (s)               174.76672150800005
Total Train Time (s)         35844.34945812123
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:51:03.219392 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #210 | Epoch Duration: 174.8537561893463
2020-01-12 17:51:03.219650 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #210 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7074264
Z variance train             0.08898366
KL Divergence                40.92733
KL Loss                      4.092733
QF Loss                      2491.755
VF Loss                      110.99331
Policy Loss                  -1177.7621
Q Predictions Mean           1178.3198
Q Predictions Std            1211.4381
Q Predictions Max            4103.5386
Q Predictions Min            542.0405
V Predictions Mean           1186.2219
V Predictions Std            1211.5927
V Predictions Max            4108.407
V Predictions Min            550.6748
Log Pis Mean                 -0.07719603
Log Pis Std                  3.733366
Log Pis Max                  13.53549
Log Pis Min                  -5.7263837
Policy mu Mean               0.038000587
Policy mu Std                0.8846872
Policy mu Max                2.6210961
Policy mu Min                -3.0157094
Policy log std Mean          -0.51465064
Policy log std Std           0.2735969
Policy log std Max           -0.04598683
Policy log std Min           -2.4612968
Z mean eval                  1.7068379
Z variance eval              0.12312776
total_rewards                [8894.56475638 6886.04382312 9000.5356847  9434.36435095 8900.3604714
 9006.67538998 9334.43005959 9099.6112185  8797.17300654 8849.34654117]
total_rewards_mean           8820.31053023305
total_rewards_std            673.890988162474
total_rewards_max            9434.364350952283
total_rewards_min            6886.043823123855
Number of train steps total  848000
Number of env steps total    2546000
Number of rollouts total     0
Train Time (s)               145.24092021817341
(Previous) Eval Time (s)     20.682845467701554
Sample Time (s)              5.637660083826631
Epoch Time (s)               171.5614257697016
Total Train Time (s)         36016.002434975
Epoch                        211
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:53:54.871604 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #211 | Epoch Duration: 171.6517791748047
2020-01-12 17:53:54.871736 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7070545
Z variance train             0.12288682
KL Divergence                40.02068
KL Loss                      4.002068
QF Loss                      120.987816
VF Loss                      79.65114
Policy Loss                  -1173.1714
Q Predictions Mean           1165.3821
Q Predictions Std            1176.556
Q Predictions Max            4043.4602
Q Predictions Min            540.2183
V Predictions Mean           1172.3157
V Predictions Std            1175.8816
V Predictions Max            4009.4634
V Predictions Min            549.72455
Log Pis Mean                 -0.17129433
Log Pis Std                  3.7941308
Log Pis Max                  17.011341
Log Pis Min                  -6.879841
Policy mu Mean               0.028044812
Policy mu Std                0.9055751
Policy mu Max                2.6297326
Policy mu Min                -3.126706
Policy log std Mean          -0.5433321
Policy log std Std           0.30177808
Policy log std Max           -0.047489226
Policy log std Min           -2.7552564
Z mean eval                  1.7146492
Z variance eval              0.13211767
total_rewards                [8551.15927249 8415.28481405 8732.34627108 8643.96811575 8274.45933953
 8531.59150431 8380.38709562 8478.87014943 8168.72043922 8640.78691337]
total_rewards_mean           8481.75739148475
total_rewards_std            166.5428013437008
total_rewards_max            8732.346271083727
total_rewards_min            8168.720439217954
Number of train steps total  852000
Number of env steps total    2558000
Number of rollouts total     0
Train Time (s)               145.87384576303884
(Previous) Eval Time (s)     21.23324052011594
Sample Time (s)              6.437002129852772
Epoch Time (s)               173.54408841300756
Total Train Time (s)         36189.64059030777
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:56:48.512446 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #212 | Epoch Duration: 173.64060735702515
2020-01-12 17:56:48.512581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7150263
Z variance train             0.13211247
KL Divergence                39.828327
KL Loss                      3.9828327
QF Loss                      307.25977
VF Loss                      66.07424
Policy Loss                  -1168.8378
Q Predictions Mean           1167.8677
Q Predictions Std            1181.1508
Q Predictions Max            4096.4756
Q Predictions Min            517.50977
V Predictions Mean           1169.2595
V Predictions Std            1182.7305
V Predictions Max            4113.2373
V Predictions Min            534.58997
Log Pis Mean                 -0.23663333
Log Pis Std                  3.7575884
Log Pis Max                  11.7329235
Log Pis Min                  -6.7338905
Policy mu Mean               0.078871004
Policy mu Std                0.87999105
Policy mu Max                2.7403817
Policy mu Min                -2.4625795
Policy log std Mean          -0.5067051
Policy log std Std           0.29411194
Policy log std Max           -0.08375268
Policy log std Min           -2.782281
Z mean eval                  1.7337275
Z variance eval              0.10577212
total_rewards                [8916.59303144 9238.50155427 9571.39541518 9264.87420882 9192.14958397
 9426.19027467 9597.29501517 9240.11104867 9433.77334602 9187.53577301]
total_rewards_mean           9306.841925122211
total_rewards_std            193.71999282871909
total_rewards_max            9597.295015172485
total_rewards_min            8916.593031439448
Number of train steps total  856000
Number of env steps total    2570000
Number of rollouts total     0
Train Time (s)               146.41540854191408
(Previous) Eval Time (s)     21.058708952274173
Sample Time (s)              6.57752860058099
Epoch Time (s)               174.05164609476924
Total Train Time (s)         36363.778908691835
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:59:42.652401 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #213 | Epoch Duration: 174.13972449302673
2020-01-12 17:59:42.652539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7348278
Z variance train             0.10549116
KL Divergence                40.596256
KL Loss                      4.0596256
QF Loss                      198.89307
VF Loss                      40.78517
Policy Loss                  -1215.588
Q Predictions Mean           1212.1553
Q Predictions Std            1233.6992
Q Predictions Max            4108.7866
Q Predictions Min            545.6882
V Predictions Mean           1212.9707
V Predictions Std            1228.0247
V Predictions Max            4095.9084
V Predictions Min            557.4882
Log Pis Mean                 -0.09313153
Log Pis Std                  3.4710288
Log Pis Max                  12.637717
Log Pis Min                  -6.3797736
Policy mu Mean               0.04520963
Policy mu Std                0.8905494
Policy mu Max                3.1741407
Policy mu Min                -3.1147223
Policy log std Mean          -0.55406576
Policy log std Std           0.29840013
Policy log std Max           -0.0071983337
Policy log std Min           -2.7259367
Z mean eval                  1.7440834
Z variance eval              0.08302575
total_rewards                [8835.95622926 9009.54854272 9158.50252556 8993.98975441 9146.51888748
 9102.74506122 8974.82661368 9026.06162089 9195.34471502 9087.04941907]
total_rewards_mean           9053.05433693032
total_rewards_std            101.5320042541595
total_rewards_max            9195.344715015613
total_rewards_min            8835.956229255318
Number of train steps total  860000
Number of env steps total    2582000
Number of rollouts total     0
Train Time (s)               144.70381261780858
(Previous) Eval Time (s)     17.53740318212658
Sample Time (s)              6.401593696791679
Epoch Time (s)               168.64280949672684
Total Train Time (s)         36532.50011877203
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:02:31.376324 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #214 | Epoch Duration: 168.7236704826355
2020-01-12 18:02:31.376504 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7405058
Z variance train             0.08323489
KL Divergence                41.356907
KL Loss                      4.1356907
QF Loss                      153.21512
VF Loss                      140.55891
Policy Loss                  -1111.5717
Q Predictions Mean           1109.4501
Q Predictions Std            1120.4004
Q Predictions Max            4071.3918
Q Predictions Min            544.2443
V Predictions Mean           1119.488
V Predictions Std            1122.305
V Predictions Max            4074.3552
V Predictions Min            549.02386
Log Pis Mean                 -0.24720432
Log Pis Std                  3.732569
Log Pis Max                  18.396563
Log Pis Min                  -6.6269283
Policy mu Mean               0.05669087
Policy mu Std                0.8855157
Policy mu Max                3.0319145
Policy mu Min                -3.100356
Policy log std Mean          -0.5090282
Policy log std Std           0.26792294
Policy log std Max           0.094299436
Policy log std Min           -2.3758526
Z mean eval                  1.7308394
Z variance eval              0.091580875
total_rewards                [9320.91184197 2306.67961979 9562.71235828 9268.84243093 9329.81950442
 9317.22616764 9555.80835372 9562.94373746 9396.69951908 9399.72290879]
total_rewards_mean           8702.136644208244
total_rewards_std            2134.4228405562753
total_rewards_max            9562.9437374616
total_rewards_min            2306.679619786884
Number of train steps total  864000
Number of env steps total    2594000
Number of rollouts total     0
Train Time (s)               145.283290815074
(Previous) Eval Time (s)     17.57725627301261
Sample Time (s)              6.358042251318693
Epoch Time (s)               169.2185893394053
Total Train Time (s)         36701.800054891966
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:05:20.679280 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #215 | Epoch Duration: 169.3025827407837
2020-01-12 18:05:20.679546 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7320902
Z variance train             0.0917941
KL Divergence                41.661938
KL Loss                      4.166194
QF Loss                      2823.598
VF Loss                      62.986244
Policy Loss                  -1113.7609
Q Predictions Mean           1111.5627
Q Predictions Std            1156.464
Q Predictions Max            4132.8486
Q Predictions Min            554.82104
V Predictions Mean           1108.206
V Predictions Std            1154.1094
V Predictions Max            4103.759
V Predictions Min            548.26825
Log Pis Mean                 -0.47848547
Log Pis Std                  3.5919642
Log Pis Max                  15.486395
Log Pis Min                  -14.318243
Policy mu Mean               0.048854876
Policy mu Std                0.8603003
Policy mu Max                2.5131588
Policy mu Min                -3.0673249
Policy log std Mean          -0.51427984
Policy log std Std           0.24143334
Policy log std Max           -0.054030776
Policy log std Min           -2.2676907
Z mean eval                  1.7344316
Z variance eval              0.056700993
total_rewards                [8668.95076803 8914.08250795 8895.26767973 9005.45436789 8854.61857508
 8949.29154215 8882.9589069  8764.82608151 8984.49647435 8954.31646033]
total_rewards_mean           8887.426336392335
total_rewards_std            98.12520675774869
total_rewards_max            9005.454367894064
total_rewards_min            8668.950768029092
Number of train steps total  868000
Number of env steps total    2606000
Number of rollouts total     0
Train Time (s)               146.5494204950519
(Previous) Eval Time (s)     18.015554320067167
Sample Time (s)              6.43099557608366
Epoch Time (s)               170.99597039120272
Total Train Time (s)         36872.90420361003
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:08:11.788456 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #216 | Epoch Duration: 171.10870504379272
2020-01-12 18:08:11.788754 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #216 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7344086
Z variance train             0.05665636
KL Divergence                42.19182
KL Loss                      4.219182
QF Loss                      133.87013
VF Loss                      42.56513
Policy Loss                  -1124.4424
Q Predictions Mean           1123.1086
Q Predictions Std            1147.007
Q Predictions Max            4140.9395
Q Predictions Min            519.14075
V Predictions Mean           1123.8475
V Predictions Std            1145.4094
V Predictions Max            4131.249
V Predictions Min            539.28845
Log Pis Mean                 -0.54363096
Log Pis Std                  3.2404122
Log Pis Max                  13.445564
Log Pis Min                  -6.8485513
Policy mu Mean               0.0694134
Policy mu Std                0.8622231
Policy mu Max                3.4180315
Policy mu Min                -2.6643555
Policy log std Mean          -0.5281289
Policy log std Std           0.2767771
Policy log std Max           -0.0069844723
Policy log std Min           -2.5401232
Z mean eval                  1.7413776
Z variance eval              0.047825627
total_rewards                [8646.80651683 8717.64366056 8869.58023822 8797.03192554 8759.3615188
 8798.38624986 8808.21618762 8721.00784428 8685.8200649  8792.29331896]
total_rewards_mean           8759.614752557707
total_rewards_std            63.126186403097414
total_rewards_max            8869.580238222145
total_rewards_min            8646.806516831384
Number of train steps total  872000
Number of env steps total    2618000
Number of rollouts total     0
Train Time (s)               147.90211744373664
(Previous) Eval Time (s)     17.89165558340028
Sample Time (s)              5.546857584733516
Epoch Time (s)               171.34063061187044
Total Train Time (s)         37044.32610475365
Epoch                        217
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:11:03.210284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #217 | Epoch Duration: 171.42124843597412
2020-01-12 18:11:03.210531 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #217 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7388332
Z variance train             0.047776576
KL Divergence                44.256176
KL Loss                      4.4256177
QF Loss                      112.94303
VF Loss                      51.68519
Policy Loss                  -1123.3486
Q Predictions Mean           1116.9231
Q Predictions Std            1124.514
Q Predictions Max            4135.0024
Q Predictions Min            544.9842
V Predictions Mean           1121.873
V Predictions Std            1126.1941
V Predictions Max            4132.7183
V Predictions Min            552.2422
Log Pis Mean                 -0.4307107
Log Pis Std                  3.3801324
Log Pis Max                  12.81058
Log Pis Min                  -6.9925246
Policy mu Mean               0.032443017
Policy mu Std                0.8582877
Policy mu Max                2.8030849
Policy mu Min                -2.7362616
Policy log std Mean          -0.53426725
Policy log std Std           0.28124565
Policy log std Max           -0.08821416
Policy log std Min           -2.596902
Z mean eval                  1.7331879
Z variance eval              0.108204916
total_rewards                [9200.4955946  9424.80574845 9545.93730405 9250.47652441 9524.7845507
 9494.16262625 9310.17511646 9521.27006028 9232.42721353 9479.03598904]
total_rewards_mean           9398.357072776811
total_rewards_std            128.67997323850554
total_rewards_max            9545.937304049627
total_rewards_min            9200.49559460044
Number of train steps total  876000
Number of env steps total    2630000
Number of rollouts total     0
Train Time (s)               147.73535219440237
(Previous) Eval Time (s)     17.86169846728444
Sample Time (s)              5.670122170355171
Epoch Time (s)               171.26717283204198
Total Train Time (s)         37215.87718870584
Epoch                        218
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:13:54.774038 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #218 | Epoch Duration: 171.56331539154053
2020-01-12 18:13:54.774260 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7368336
Z variance train             0.10780551
KL Divergence                42.722286
KL Loss                      4.2722287
QF Loss                      129.6864
VF Loss                      34.506783
Policy Loss                  -1157.266
Q Predictions Mean           1157.8423
Q Predictions Std            1169.1244
Q Predictions Max            4143.842
Q Predictions Min            555.6381
V Predictions Mean           1155.6472
V Predictions Std            1167.3868
V Predictions Max            4136.0806
V Predictions Min            556.227
Log Pis Mean                 -0.13102593
Log Pis Std                  3.599447
Log Pis Max                  13.926161
Log Pis Min                  -7.1640854
Policy mu Mean               0.08641704
Policy mu Std                0.8779761
Policy mu Max                2.8490057
Policy mu Min                -2.7902083
Policy log std Mean          -0.5205469
Policy log std Std           0.27353662
Policy log std Max           -0.066838145
Policy log std Min           -2.5102797
Z mean eval                  1.7473152
Z variance eval              0.09340286
total_rewards                [9102.44138012 9342.58838559 9319.38115992 9441.57692619 9357.78238133
 9463.29032523 9271.46674768 9462.7461194  9320.88561769 9127.82493478]
total_rewards_mean           9320.998397793466
total_rewards_std            120.09868819147518
total_rewards_max            9463.290325232436
total_rewards_min            9102.441380119068
Number of train steps total  880000
Number of env steps total    2642000
Number of rollouts total     0
Train Time (s)               147.67492049420252
(Previous) Eval Time (s)     21.013349410146475
Sample Time (s)              6.477473234757781
Epoch Time (s)               175.16574313910678
Total Train Time (s)         37391.136818909086
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:16:50.025487 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #219 | Epoch Duration: 175.25107955932617
2020-01-12 18:16:50.025632 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #219 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7456518
Z variance train             0.093389526
KL Divergence                42.469055
KL Loss                      4.246906
QF Loss                      995.8814
VF Loss                      54.68829
Policy Loss                  -1096.7024
Q Predictions Mean           1095.2302
Q Predictions Std            1123.4882
Q Predictions Max            4176.9004
Q Predictions Min            558.17584
V Predictions Mean           1096.7048
V Predictions Std            1124.7234
V Predictions Max            4190.842
V Predictions Min            555.93744
Log Pis Mean                 -0.19406271
Log Pis Std                  3.7757962
Log Pis Max                  14.645822
Log Pis Min                  -6.7036743
Policy mu Mean               -0.002334457
Policy mu Std                0.8808056
Policy mu Max                2.8049762
Policy mu Min                -3.2355862
Policy log std Mean          -0.51563966
Policy log std Std           0.27644503
Policy log std Max           0.047933698
Policy log std Min           -2.6880848
Z mean eval                  1.7373024
Z variance eval              0.062100053
total_rewards                [8809.26623912 9453.60707178 9066.05352854 9030.58209656 8994.4538219
 9190.03717804 9134.52650181 9367.97689305 9234.17423791 9114.4527067 ]
total_rewards_mean           9139.51302754126
total_rewards_std            176.17732153889614
total_rewards_max            9453.60707178083
total_rewards_min            8809.266239120792
Number of train steps total  884000
Number of env steps total    2654000
Number of rollouts total     0
Train Time (s)               146.5731981229037
(Previous) Eval Time (s)     20.892029155045748
Sample Time (s)              6.519253885373473
Epoch Time (s)               173.98448116332293
Total Train Time (s)         37565.207145153545
Epoch                        220
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:19:44.096377 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #220 | Epoch Duration: 174.07064819335938
2020-01-12 18:19:44.096509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7348568
Z variance train             0.0620976
KL Divergence                43.858837
KL Loss                      4.385884
QF Loss                      707.4806
VF Loss                      100.89576
Policy Loss                  -1258.1005
Q Predictions Mean           1257.1205
Q Predictions Std            1278.9785
Q Predictions Max            4120.485
Q Predictions Min            558.5902
V Predictions Mean           1263.0017
V Predictions Std            1275.6284
V Predictions Max            4119.1895
V Predictions Min            569.12885
Log Pis Mean                 -0.041989423
Log Pis Std                  3.9353745
Log Pis Max                  14.601633
Log Pis Min                  -7.766538
Policy mu Mean               0.045465697
Policy mu Std                0.9088295
Policy mu Max                3.1055262
Policy mu Min                -2.7380679
Policy log std Mean          -0.52947336
Policy log std Std           0.28855664
Policy log std Max           0.1442141
Policy log std Min           -2.5155253
Z mean eval                  1.7403877
Z variance eval              0.047440834
total_rewards                [9286.43463098 9381.21734733 2029.96967168 9257.85473855 9612.25750513
 9549.75305771  872.48441073 9374.88014815 9278.49699619 9473.5511263 ]
total_rewards_mean           7811.6899632762115
total_rewards_std            3192.6528088123155
total_rewards_max            9612.257505127687
total_rewards_min            872.4844107347177
Number of train steps total  888000
Number of env steps total    2666000
Number of rollouts total     0
Train Time (s)               145.6638389849104
(Previous) Eval Time (s)     20.999510334804654
Sample Time (s)              6.590334984008223
Epoch Time (s)               173.25368430372328
Total Train Time (s)         37738.54252606537
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:22:37.435818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #221 | Epoch Duration: 173.33921432495117
2020-01-12 18:22:37.435958 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7409805
Z variance train             0.04738955
KL Divergence                44.12509
KL Loss                      4.4125094
QF Loss                      2853.586
VF Loss                      35.14002
Policy Loss                  -1144.3342
Q Predictions Mean           1142.5901
Q Predictions Std            1148.481
Q Predictions Max            4134.9663
Q Predictions Min            560.5719
V Predictions Mean           1147.1244
V Predictions Std            1148.4631
V Predictions Max            4123.899
V Predictions Min            564.4657
Log Pis Mean                 -0.050237328
Log Pis Std                  3.4449527
Log Pis Max                  14.599347
Log Pis Min                  -4.893965
Policy mu Mean               0.08853513
Policy mu Std                0.8889648
Policy mu Max                3.0229454
Policy mu Min                -3.0891948
Policy log std Mean          -0.5340837
Policy log std Std           0.28502297
Policy log std Max           0.02693218
Policy log std Min           -2.4930644
Z mean eval                  1.7346628
Z variance eval              0.06294651
total_rewards                [9011.58172406 9142.80656285 9277.89389209 8958.07022517 9041.77773304
 8903.77149503 9167.88586858 9081.22019237 9112.13567648 9302.34354202]
total_rewards_mean           9099.94869117068
total_rewards_std            122.22408900996489
total_rewards_max            9302.34354202078
total_rewards_min            8903.771495032874
Number of train steps total  892000
Number of env steps total    2678000
Number of rollouts total     0
Train Time (s)               146.19566773297265
(Previous) Eval Time (s)     19.112906740047038
Sample Time (s)              6.541603402700275
Epoch Time (s)               171.85017787571996
Total Train Time (s)         37910.491256489884
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:25:29.385648 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #222 | Epoch Duration: 171.94957041740417
2020-01-12 18:25:29.385862 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.734588
Z variance train             0.06307542
KL Divergence                43.322453
KL Loss                      4.3322453
QF Loss                      454.2215
VF Loss                      67.70894
Policy Loss                  -1243.0261
Q Predictions Mean           1237.0781
Q Predictions Std            1237.4043
Q Predictions Max            4152.567
Q Predictions Min            547.9941
V Predictions Mean           1243.6855
V Predictions Std            1238.2136
V Predictions Max            4183.9165
V Predictions Min            553.2627
Log Pis Mean                 0.12458263
Log Pis Std                  3.7505465
Log Pis Max                  15.854021
Log Pis Min                  -5.886406
Policy mu Mean               -0.045920044
Policy mu Std                0.90747976
Policy mu Max                3.0666893
Policy mu Min                -3.2222378
Policy log std Mean          -0.54185194
Policy log std Std           0.30201715
Policy log std Max           0.015821755
Policy log std Min           -2.7274556
Z mean eval                  1.7352676
Z variance eval              0.057144053
total_rewards                [9352.52880642 9532.33267849 9158.16015439 9553.24912026 9301.28781379
 9454.17920284 9404.65200372 9430.22953327 9354.09449553 9802.42348034]
total_rewards_mean           9434.313728905428
total_rewards_std            163.59396575140144
total_rewards_max            9802.423480341635
total_rewards_min            9158.160154394103
Number of train steps total  896000
Number of env steps total    2690000
Number of rollouts total     0
Train Time (s)               146.20417060982436
(Previous) Eval Time (s)     17.482033308129758
Sample Time (s)              6.623651725240052
Epoch Time (s)               170.30985564319417
Total Train Time (s)         38080.88241394982
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:28:19.783135 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #223 | Epoch Duration: 170.39707827568054
2020-01-12 18:28:19.783450 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7347504
Z variance train             0.05713568
KL Divergence                44.00722
KL Loss                      4.400722
QF Loss                      178.30365
VF Loss                      52.678497
Policy Loss                  -1315.291
Q Predictions Mean           1315.101
Q Predictions Std            1305.0913
Q Predictions Max            4148.9346
Q Predictions Min            540.81903
V Predictions Mean           1319.1067
V Predictions Std            1301.4744
V Predictions Max            4154.439
V Predictions Min            554.98944
Log Pis Mean                 0.033200577
Log Pis Std                  3.5297515
Log Pis Max                  12.622372
Log Pis Min                  -7.220719
Policy mu Mean               0.02448482
Policy mu Std                0.905386
Policy mu Max                2.9434915
Policy mu Min                -3.154326
Policy log std Mean          -0.52323157
Policy log std Std           0.26793393
Policy log std Max           0.06387758
Policy log std Min           -2.5005622
Z mean eval                  1.732228
Z variance eval              0.07489728
total_rewards                [9167.61554037 9533.55880279 9290.33207363 9593.72116368 9605.48768787
 9498.27269107 9691.98735833 9475.53959216 9690.20336244 9751.05080709]
total_rewards_mean           9529.776907944299
total_rewards_std            174.14798180800537
total_rewards_max            9751.050807089063
total_rewards_min            9167.615540370152
Number of train steps total  900000
Number of env steps total    2702000
Number of rollouts total     0
Train Time (s)               147.3471515593119
(Previous) Eval Time (s)     17.273735930677503
Sample Time (s)              6.456083071418107
Epoch Time (s)               171.0769705614075
Total Train Time (s)         38252.03774689231
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:31:10.938358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #224 | Epoch Duration: 171.15468049049377
2020-01-12 18:31:10.938479 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7317854
Z variance train             0.07505366
KL Divergence                43.43254
KL Loss                      4.343254
QF Loss                      94.86341
VF Loss                      67.61196
Policy Loss                  -1180.0935
Q Predictions Mean           1178.055
Q Predictions Std            1186.9836
Q Predictions Max            4136.199
Q Predictions Min            561.72784
V Predictions Mean           1181.8562
V Predictions Std            1186.8021
V Predictions Max            4154.106
V Predictions Min            560.41284
Log Pis Mean                 -0.31564635
Log Pis Std                  3.7436576
Log Pis Max                  15.6778145
Log Pis Min                  -6.7635264
Policy mu Mean               -0.062924005
Policy mu Std                0.87938917
Policy mu Max                2.5894885
Policy mu Min                -3.1219425
Policy log std Mean          -0.54010886
Policy log std Std           0.27498668
Policy log std Max           0.02078098
Policy log std Min           -2.4431295
Z mean eval                  1.7287709
Z variance eval              0.12516762
total_rewards                [9446.92507837 9641.32046158 9522.16916285 9396.11798105 9411.92366726
 9291.44842741 9577.15828963 9394.52242494 9639.57441913 9396.07645585]
total_rewards_mean           9471.723636805464
total_rewards_std            111.66336887279942
total_rewards_max            9641.320461578503
total_rewards_min            9291.448427406607
Number of train steps total  904000
Number of env steps total    2714000
Number of rollouts total     0
Train Time (s)               145.65713091334328
(Previous) Eval Time (s)     18.61435656901449
Sample Time (s)              5.470973840914667
Epoch Time (s)               169.74246132327244
Total Train Time (s)         38421.99140059156
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:34:00.898090 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #225 | Epoch Duration: 169.95948004722595
2020-01-12 18:34:00.898360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7279022
Z variance train             0.1254052
KL Divergence                42.500145
KL Loss                      4.250015
QF Loss                      190.71034
VF Loss                      56.2739
Policy Loss                  -1224.2383
Q Predictions Mean           1221.4641
Q Predictions Std            1227.067
Q Predictions Max            4148.8193
Q Predictions Min            565.1195
V Predictions Mean           1226.3818
V Predictions Std            1226.3177
V Predictions Max            4156.393
V Predictions Min            562.9021
Log Pis Mean                 0.030081153
Log Pis Std                  3.8749244
Log Pis Max                  17.484325
Log Pis Min                  -6.5489945
Policy mu Mean               0.032415796
Policy mu Std                0.907481
Policy mu Max                3.1310263
Policy mu Min                -3.5178688
Policy log std Mean          -0.5342701
Policy log std Std           0.2635269
Policy log std Max           0.009602547
Policy log std Min           -2.5536835
Z mean eval                  1.7263105
Z variance eval              0.17240453
total_rewards                [8151.57351941 9196.42199524 9300.35903866 9389.53975655 9396.32073677
 8983.56155851 1285.37440942 9106.0420717  9178.15244705 9467.85530694]
total_rewards_mean           8345.520084024101
total_rewards_std            2380.1593731998737
total_rewards_max            9467.85530693801
total_rewards_min            1285.3744094154495
Number of train steps total  908000
Number of env steps total    2726000
Number of rollouts total     0
Train Time (s)               147.9310075440444
(Previous) Eval Time (s)     20.89479874400422
Sample Time (s)              6.4804739584214985
Epoch Time (s)               175.30628024647012
Total Train Time (s)         38597.3795314203
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:36:56.286639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #226 | Epoch Duration: 175.38808798789978
2020-01-12 18:36:56.286775 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.728002
Z variance train             0.17203687
KL Divergence                40.608387
KL Loss                      4.0608387
QF Loss                      173.9826
VF Loss                      43.22136
Policy Loss                  -1060.3564
Q Predictions Mean           1057.0684
Q Predictions Std            1061.9441
Q Predictions Max            4199.1987
Q Predictions Min            565.7418
V Predictions Mean           1060.812
V Predictions Std            1062.9591
V Predictions Max            4179.9346
V Predictions Min            560.80505
Log Pis Mean                 -0.66325784
Log Pis Std                  3.5938666
Log Pis Max                  14.732559
Log Pis Min                  -7.1234794
Policy mu Mean               0.07207286
Policy mu Std                0.829344
Policy mu Max                3.1592574
Policy mu Min                -2.8284945
Policy log std Mean          -0.5081424
Policy log std Std           0.2660056
Policy log std Max           0.053049266
Policy log std Min           -2.4508228
Z mean eval                  1.742232
Z variance eval              0.12382053
total_rewards                [9003.98699302 9463.0752053  9071.99383043 9204.77081659 9395.75616289
 9404.42019817 9351.96949829 9051.24177459 9246.56554275 9289.30164453]
total_rewards_mean           9248.308166657034
total_rewards_std            153.68024508198442
total_rewards_max            9463.075205302306
total_rewards_min            9003.986993020868
Number of train steps total  912000
Number of env steps total    2738000
Number of rollouts total     0
Train Time (s)               148.06949076615274
(Previous) Eval Time (s)     20.544507113751024
Sample Time (s)              6.418978095520288
Epoch Time (s)               175.03297597542405
Total Train Time (s)         38772.50317056617
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:39:51.413158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #227 | Epoch Duration: 175.12628364562988
2020-01-12 18:39:51.413297 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7428453
Z variance train             0.12372893
KL Divergence                39.701035
KL Loss                      3.9701035
QF Loss                      168.67313
VF Loss                      74.73437
Policy Loss                  -1046.229
Q Predictions Mean           1045.1187
Q Predictions Std            1067.871
Q Predictions Max            4221.2437
Q Predictions Min            581.0396
V Predictions Mean           1043.3152
V Predictions Std            1068.0007
V Predictions Max            4196.2373
V Predictions Min            577.33746
Log Pis Mean                 -0.67825913
Log Pis Std                  3.2403164
Log Pis Max                  15.539333
Log Pis Min                  -7.391143
Policy mu Mean               0.04459518
Policy mu Std                0.821991
Policy mu Max                2.755582
Policy mu Min                -2.716633
Policy log std Mean          -0.52300924
Policy log std Std           0.26348233
Policy log std Max           -0.043105185
Policy log std Min           -2.5566974
Z mean eval                  1.7345755
Z variance eval              0.08687471
total_rewards                [9270.258524   9634.61108181 9421.9881397  9667.83166078 9602.55240328
 9449.21851497 9422.16615531 9693.15065019 9415.54805213 9753.26946549]
total_rewards_mean           9533.05946476427
total_rewards_std            148.9845337882129
total_rewards_max            9753.269465489813
total_rewards_min            9270.2585239982
Number of train steps total  916000
Number of env steps total    2750000
Number of rollouts total     0
Train Time (s)               147.97868695715442
(Previous) Eval Time (s)     21.202125573996454
Sample Time (s)              6.532635123934597
Epoch Time (s)               175.71344765508547
Total Train Time (s)         38948.29604360927
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:42:47.209275 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #228 | Epoch Duration: 175.7958824634552
2020-01-12 18:42:47.209410 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7329403
Z variance train             0.08697151
KL Divergence                41.474995
KL Loss                      4.1474996
QF Loss                      98.18147
VF Loss                      46.926987
Policy Loss                  -1216.5331
Q Predictions Mean           1216.9927
Q Predictions Std            1239.4768
Q Predictions Max            4182.011
Q Predictions Min            553.54315
V Predictions Mean           1218.147
V Predictions Std            1237.1798
V Predictions Max            4185.131
V Predictions Min            563.8026
Log Pis Mean                 -0.23346005
Log Pis Std                  3.5403967
Log Pis Max                  15.606242
Log Pis Min                  -7.4487367
Policy mu Mean               0.024799736
Policy mu Std                0.8846811
Policy mu Max                2.5019279
Policy mu Min                -2.3767595
Policy log std Mean          -0.5260937
Policy log std Std           0.27044204
Policy log std Max           0.1608805
Policy log std Min           -2.5790057
Z mean eval                  1.7503252
Z variance eval              0.10696536
total_rewards                [9207.90544216 9487.74680912 9511.26679107 9505.94987673 9729.46959204
 9648.86387838 9680.23009002 9409.92156539 9623.70436964 9555.96651572]
total_rewards_mean           9536.102493027973
total_rewards_std            143.68249462942052
total_rewards_max            9729.469592043322
total_rewards_min            9207.90544216405
Number of train steps total  920000
Number of env steps total    2762000
Number of rollouts total     0
Train Time (s)               145.2490284726955
(Previous) Eval Time (s)     20.835194481071085
Sample Time (s)              6.273639798630029
Epoch Time (s)               172.3578627523966
Total Train Time (s)         39120.73272788152
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:45:39.649641 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #229 | Epoch Duration: 172.44012689590454
2020-01-12 18:45:39.649812 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7517197
Z variance train             0.10741804
KL Divergence                42.40929
KL Loss                      4.240929
QF Loss                      6025.464
VF Loss                      107.76045
Policy Loss                  -1270.0327
Q Predictions Mean           1270.5259
Q Predictions Std            1297.525
Q Predictions Max            4294.4517
Q Predictions Min            581.3585
V Predictions Mean           1267.9736
V Predictions Std            1291.3539
V Predictions Max            4277.3037
V Predictions Min            577.047
Log Pis Mean                 -0.01717591
Log Pis Std                  4.178217
Log Pis Max                  23.108671
Log Pis Min                  -6.8245525
Policy mu Mean               0.07322227
Policy mu Std                0.91099846
Policy mu Max                2.8523219
Policy mu Min                -3.4056435
Policy log std Mean          -0.5416176
Policy log std Std           0.2909687
Policy log std Max           0.25326994
Policy log std Min           -2.4957438
Z mean eval                  1.7426989
Z variance eval              0.107905686
total_rewards                [9293.2566713  9679.55460087 9786.63545593 9484.16954614 9523.87561276
 9396.57965246 9361.11713293 9509.43898198 9845.60312941 9632.71466286]
total_rewards_mean           9551.294544664514
total_rewards_std            172.8525112667496
total_rewards_max            9845.603129407218
total_rewards_min            9293.256671300447
Number of train steps total  924000
Number of env steps total    2774000
Number of rollouts total     0
Train Time (s)               147.00769191095605
(Previous) Eval Time (s)     20.69810054684058
Sample Time (s)              5.529124544002116
Epoch Time (s)               173.23491700179875
Total Train Time (s)         39294.20506564481
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:48:33.131074 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #230 | Epoch Duration: 173.48111820220947
2020-01-12 18:48:33.131305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7423942
Z variance train             0.1080873
KL Divergence                42.356632
KL Loss                      4.2356634
QF Loss                      94.617165
VF Loss                      37.713036
Policy Loss                  -1225.9305
Q Predictions Mean           1225.6372
Q Predictions Std            1224.393
Q Predictions Max            4208.8174
Q Predictions Min            570.45276
V Predictions Mean           1224.7067
V Predictions Std            1224.5012
V Predictions Max            4201.8345
V Predictions Min            568.3288
Log Pis Mean                 -0.26418442
Log Pis Std                  3.2905486
Log Pis Max                  12.295668
Log Pis Min                  -8.650687
Policy mu Mean               0.084849976
Policy mu Std                0.87890416
Policy mu Max                2.9874017
Policy mu Min                -2.532746
Policy log std Mean          -0.52380365
Policy log std Std           0.27189288
Policy log std Max           0.11979866
Policy log std Min           -2.7888055
Z mean eval                  1.7498701
Z variance eval              0.09255205
total_rewards                [9008.2601144  9303.59784349 9013.16786825 1644.05372538 9135.02064473
 9246.88013125 9264.8818557  8986.02193975 9276.12080242 9003.47475397]
total_rewards_mean           8388.147967934301
total_rewards_std            2251.3223382101737
total_rewards_max            9303.597843487916
total_rewards_min            1644.053725382966
Number of train steps total  928000
Number of env steps total    2786000
Number of rollouts total     0
Train Time (s)               146.1963987420313
(Previous) Eval Time (s)     20.745109593030065
Sample Time (s)              6.474832345265895
Epoch Time (s)               173.41634068032727
Total Train Time (s)         39467.71258625435
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:51:26.632772 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #231 | Epoch Duration: 173.50130987167358
2020-01-12 18:51:26.632908 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7487938
Z variance train             0.0926595
KL Divergence                43.00201
KL Loss                      4.300201
QF Loss                      350.2469
VF Loss                      43.850082
Policy Loss                  -1195.9232
Q Predictions Mean           1194.956
Q Predictions Std            1238.4318
Q Predictions Max            4179.4575
Q Predictions Min            562.7443
V Predictions Mean           1197.873
V Predictions Std            1233.6091
V Predictions Max            4170.4736
V Predictions Min            566.7016
Log Pis Mean                 -0.14405349
Log Pis Std                  3.66165
Log Pis Max                  17.244137
Log Pis Min                  -8.479563
Policy mu Mean               0.032286804
Policy mu Std                0.897355
Policy mu Max                3.7077136
Policy mu Min                -4.3373084
Policy log std Mean          -0.5245798
Policy log std Std           0.2713786
Policy log std Max           0.07187992
Policy log std Min           -2.5840917
Z mean eval                  1.7665517
Z variance eval              0.1031481
total_rewards                [9214.54697287 9458.2385275  9314.44763444 9549.95816129 9537.05153606
 9565.16667197 9558.05281282 9501.69448585 9494.47787359 9446.06045156]
total_rewards_mean           9463.96951279312
total_rewards_std            109.13453625333202
total_rewards_max            9565.166671966519
total_rewards_min            9214.546972865517
Number of train steps total  932000
Number of env steps total    2798000
Number of rollouts total     0
Train Time (s)               148.198510334827
(Previous) Eval Time (s)     21.23102974984795
Sample Time (s)              6.339035422541201
Epoch Time (s)               175.76857550721616
Total Train Time (s)         39643.57230284158
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:54:22.494578 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #232 | Epoch Duration: 175.86157298088074
2020-01-12 18:54:22.494719 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #232 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7655274
Z variance train             0.10298546
KL Divergence                43.541187
KL Loss                      4.354119
QF Loss                      173.24835
VF Loss                      120.766685
Policy Loss                  -1132.9915
Q Predictions Mean           1129.9528
Q Predictions Std            1144.9039
Q Predictions Max            4266.0005
Q Predictions Min            567.93256
V Predictions Mean           1133.9313
V Predictions Std            1145.6917
V Predictions Max            4224.6763
V Predictions Min            574.4705
Log Pis Mean                 -0.08891168
Log Pis Std                  3.328378
Log Pis Max                  12.422525
Log Pis Min                  -10.282532
Policy mu Mean               0.061582685
Policy mu Std                0.9073549
Policy mu Max                2.9748201
Policy mu Min                -3.1489732
Policy log std Mean          -0.5313754
Policy log std Std           0.28692243
Policy log std Max           0.047224402
Policy log std Min           -2.6113405
Z mean eval                  1.7548879
Z variance eval              0.08302106
total_rewards                [9172.80931983 9720.20065287 9683.54129359 9440.97692733 9382.5788131
 9540.74638425 9387.23987381 9644.40710222 9531.5643767  9281.55169434]
total_rewards_mean           9478.561643804269
total_rewards_std            169.07081339697888
total_rewards_max            9720.200652870479
total_rewards_min            9172.809319826792
Number of train steps total  936000
Number of env steps total    2810000
Number of rollouts total     0
Train Time (s)               148.6798719149083
(Previous) Eval Time (s)     20.74681560182944
Sample Time (s)              6.6336586670950055
Epoch Time (s)               176.06034618383273
Total Train Time (s)         39819.89907279983
Epoch                        233
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:57:18.822276 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #233 | Epoch Duration: 176.32745790481567
2020-01-12 18:57:18.822411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #233 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.752677
Z variance train             0.08309738
KL Divergence                43.716423
KL Loss                      4.3716426
QF Loss                      99.53604
VF Loss                      49.029163
Policy Loss                  -1178.7112
Q Predictions Mean           1173.8575
Q Predictions Std            1170.5176
Q Predictions Max            4285.006
Q Predictions Min            561.45465
V Predictions Mean           1179.4847
V Predictions Std            1173.0594
V Predictions Max            4309.1733
V Predictions Min            560.47656
Log Pis Mean                 -0.12801524
Log Pis Std                  4.0513916
Log Pis Max                  19.523445
Log Pis Min                  -6.470353
Policy mu Mean               0.107124746
Policy mu Std                0.892818
Policy mu Max                3.1027708
Policy mu Min                -3.1790104
Policy log std Mean          -0.5179596
Policy log std Std           0.28534266
Policy log std Max           -0.026420712
Policy log std Min           -2.593227
Z mean eval                  1.7594588
Z variance eval              0.08703445
total_rewards                [ 9539.02149287 10050.98960938  9553.66870993  9898.88562137
  9555.78183174  9579.65578771  9723.40205507  9691.234594
  9678.09191168  9725.06813334]
total_rewards_mean           9699.579974709948
total_rewards_std            157.19059511682528
total_rewards_max            10050.989609379543
total_rewards_min            9539.021492872032
Number of train steps total  940000
Number of env steps total    2822000
Number of rollouts total     0
Train Time (s)               147.90465028211474
(Previous) Eval Time (s)     20.81265427498147
Sample Time (s)              6.415562524925917
Epoch Time (s)               175.13286708202213
Total Train Time (s)         39995.11731131049
Epoch                        234
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:00:14.042858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #234 | Epoch Duration: 175.22034907341003
2020-01-12 19:00:14.042993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7623447
Z variance train             0.08708357
KL Divergence                43.99018
KL Loss                      4.3990183
QF Loss                      114.339584
VF Loss                      130.00156
Policy Loss                  -1159.3489
Q Predictions Mean           1157.7021
Q Predictions Std            1176.1127
Q Predictions Max            4245.1665
Q Predictions Min            552.63416
V Predictions Mean           1152.67
V Predictions Std            1166.9955
V Predictions Max            4202.7295
V Predictions Min            546.29596
Log Pis Mean                 -0.6427915
Log Pis Std                  3.1261394
Log Pis Max                  12.506096
Log Pis Min                  -6.222555
Policy mu Mean               0.09209762
Policy mu Std                0.82864094
Policy mu Max                2.7166004
Policy mu Min                -2.9933534
Policy log std Mean          -0.52754605
Policy log std Std           0.26871333
Policy log std Max           -0.07734382
Policy log std Min           -2.8941498
Z mean eval                  1.7440736
Z variance eval              0.13200095
total_rewards                [9197.5816714  9223.79259047 9442.62525237 9209.46944807 9363.44985902
 9365.63529339 9379.52090326 9333.29152972 9263.85595581 9257.35298605]
total_rewards_mean           9303.657548956366
total_rewards_std            79.74458363306351
total_rewards_max            9442.62525237448
total_rewards_min            9197.581671402873
Number of train steps total  944000
Number of env steps total    2834000
Number of rollouts total     0
Train Time (s)               146.26748043624684
(Previous) Eval Time (s)     20.765130613930523
Sample Time (s)              6.399905517697334
Epoch Time (s)               173.4325165678747
Total Train Time (s)         40168.6305154711
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:03:07.558337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #235 | Epoch Duration: 173.5152485370636
2020-01-12 19:03:07.558471 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7443731
Z variance train             0.13182107
KL Divergence                42.1919
KL Loss                      4.21919
QF Loss                      173.69598
VF Loss                      82.743324
Policy Loss                  -1338.9216
Q Predictions Mean           1334.9371
Q Predictions Std            1316.5126
Q Predictions Max            4224.2007
Q Predictions Min            577.79395
V Predictions Mean           1336.5875
V Predictions Std            1318.5104
V Predictions Max            4227.4814
V Predictions Min            579.1403
Log Pis Mean                 0.33510742
Log Pis Std                  3.978442
Log Pis Max                  17.412214
Log Pis Min                  -6.6421447
Policy mu Mean               0.051074352
Policy mu Std                0.94190073
Policy mu Max                3.1814303
Policy mu Min                -3.3937378
Policy log std Mean          -0.5386979
Policy log std Std           0.28472272
Policy log std Max           0.036548615
Policy log std Min           -2.9593387
Z mean eval                  1.7415183
Z variance eval              0.14029428
total_rewards                [9307.38261075 9444.2589238  9742.81776089 9235.56989138 9736.74401577
 9533.11919059 9518.2645387  9630.22741579 9696.67235001 9456.26254725]
total_rewards_mean           9530.13192449389
total_rewards_std            165.84429620926548
total_rewards_max            9742.817760892094
total_rewards_min            9235.569891377156
Number of train steps total  948000
Number of env steps total    2846000
Number of rollouts total     0
Train Time (s)               147.1857724711299
(Previous) Eval Time (s)     20.94881410524249
Sample Time (s)              6.424197501968592
Epoch Time (s)               174.55878407834098
Total Train Time (s)         40343.272571347654
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:06:02.201454 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #236 | Epoch Duration: 174.64288997650146
2020-01-12 19:06:02.201586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7409378
Z variance train             0.13979453
KL Divergence                42.04451
KL Loss                      4.204451
QF Loss                      179.87332
VF Loss                      62.000004
Policy Loss                  -1258.4338
Q Predictions Mean           1254.8398
Q Predictions Std            1235.7494
Q Predictions Max            4200.8193
Q Predictions Min            577.191
V Predictions Mean           1259.7344
V Predictions Std            1238.4583
V Predictions Max            4220.7427
V Predictions Min            579.4726
Log Pis Mean                 -0.064141296
Log Pis Std                  4.358242
Log Pis Max                  26.584398
Log Pis Min                  -5.892085
Policy mu Mean               -0.012388381
Policy mu Std                0.9302486
Policy mu Max                3.2856598
Policy mu Min                -4.382543
Policy log std Mean          -0.52080554
Policy log std Std           0.29007852
Policy log std Max           0.12649095
Policy log std Min           -3.0279634
Z mean eval                  1.7555393
Z variance eval              0.13308448
total_rewards                [8527.57484698 4164.5601825  8065.3162996  2073.39731536 8776.91508098
 7663.0807435  8745.04739764 8902.09271567 8075.17012076 8140.8812634 ]
total_rewards_mean           7313.4035966408355
total_rewards_std            2179.7970043241266
total_rewards_max            8902.092715673678
total_rewards_min            2073.397315361418
Number of train steps total  952000
Number of env steps total    2858000
Number of rollouts total     0
Train Time (s)               146.25779404724017
(Previous) Eval Time (s)     20.880973808001727
Sample Time (s)              6.53899160772562
Epoch Time (s)               173.67775946296751
Total Train Time (s)         40517.02848346345
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:08:55.960502 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #237 | Epoch Duration: 173.75880217552185
2020-01-12 19:08:55.960687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7550852
Z variance train             0.1328868
KL Divergence                40.875683
KL Loss                      4.0875683
QF Loss                      114.63052
VF Loss                      91.18154
Policy Loss                  -1148.7448
Q Predictions Mean           1149.1184
Q Predictions Std            1168.0715
Q Predictions Max            4311.929
Q Predictions Min            581.18854
V Predictions Mean           1154.7177
V Predictions Std            1172.4915
V Predictions Max            4324.1245
V Predictions Min            584.9489
Log Pis Mean                 -0.28310633
Log Pis Std                  3.4506326
Log Pis Max                  21.639008
Log Pis Min                  -6.637509
Policy mu Mean               0.03856479
Policy mu Std                0.8903793
Policy mu Max                2.7534466
Policy mu Min                -3.1301932
Policy log std Mean          -0.5144677
Policy log std Std           0.2734825
Policy log std Max           0.14652205
Policy log std Min           -2.4577131
Z mean eval                  1.7403314
Z variance eval              0.11732908
total_rewards                [6218.30140692 7400.5442076  8038.56561523 2968.33348393 3171.31999737
 5455.91808553 1614.54268978 2636.30375564 2847.84012573 7683.9041207 ]
total_rewards_mean           4803.557348843454
total_rewards_std            2294.710655628425
total_rewards_max            8038.565615233906
total_rewards_min            1614.5426897805185
Number of train steps total  956000
Number of env steps total    2870000
Number of rollouts total     0
Train Time (s)               146.9847324108705
(Previous) Eval Time (s)     17.378817431163043
Sample Time (s)              6.570080150850117
Epoch Time (s)               170.93362999288365
Total Train Time (s)         40688.04016756918
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:11:46.977190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #238 | Epoch Duration: 171.01626467704773
2020-01-12 19:11:46.977562 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7397734
Z variance train             0.117521666
KL Divergence                41.023403
KL Loss                      4.10234
QF Loss                      132.9189
VF Loss                      122.29071
Policy Loss                  -1251.8754
Q Predictions Mean           1245.7798
Q Predictions Std            1241.8401
Q Predictions Max            4221.3394
Q Predictions Min            564.8528
V Predictions Mean           1245.6187
V Predictions Std            1233.9236
V Predictions Max            4216.3706
V Predictions Min            573.5452
Log Pis Mean                 0.12590367
Log Pis Std                  3.9320297
Log Pis Max                  23.240826
Log Pis Min                  -6.7249384
Policy mu Mean               0.047979075
Policy mu Std                0.947397
Policy mu Max                5.4012117
Policy mu Min                -3.4870517
Policy log std Mean          -0.51210856
Policy log std Std           0.26960713
Policy log std Max           -0.040112257
Policy log std Min           -2.7522287
Z mean eval                  1.769359
Z variance eval              0.20383437
total_rewards                [9595.26468561 9463.80449176 9427.5703037  9688.35994229 9604.57532457
 9467.38053348 9613.95361562 9641.13476819 9748.06900711 9477.86637852]
total_rewards_mean           9572.797905086165
total_rewards_std            102.4930538907365
total_rewards_max            9748.0690071096
total_rewards_min            9427.570303696835
Number of train steps total  960000
Number of env steps total    2882000
Number of rollouts total     0
Train Time (s)               146.19603704707697
(Previous) Eval Time (s)     17.364326817449182
Sample Time (s)              6.656008009798825
Epoch Time (s)               170.21637187432498
Total Train Time (s)         40858.33538107155
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:14:37.273561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #239 | Epoch Duration: 170.29577136039734
2020-01-12 19:14:37.273706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7697443
Z variance train             0.20442705
KL Divergence                41.321583
KL Loss                      4.1321583
QF Loss                      161.51642
VF Loss                      95.096565
Policy Loss                  -1230.995
Q Predictions Mean           1227.3522
Q Predictions Std            1252.1006
Q Predictions Max            4370.191
Q Predictions Min            583.1786
V Predictions Mean           1228.5244
V Predictions Std            1243.479
V Predictions Max            4365.515
V Predictions Min            587.69617
Log Pis Mean                 -0.2040827
Log Pis Std                  3.8038342
Log Pis Max                  18.976147
Log Pis Min                  -5.813304
Policy mu Mean               0.036249157
Policy mu Std                0.8824146
Policy mu Max                3.4418783
Policy mu Min                -3.2778163
Policy log std Mean          -0.51396054
Policy log std Std           0.29290837
Policy log std Max           -0.027433693
Policy log std Min           -2.7066567
Z mean eval                  1.753783
Z variance eval              0.14757663
total_rewards                [9489.60749546 9717.59752625 9604.09264267 9611.74751001 9450.56241673
 9487.35941706 9851.47894701 9643.59456292 9522.55935442 9600.38984621]
total_rewards_mean           9597.898971872366
total_rewards_std            115.01527648717123
total_rewards_max            9851.478947010726
total_rewards_min            9450.562416729397
Number of train steps total  964000
Number of env steps total    2894000
Number of rollouts total     0
Train Time (s)               145.28915762668476
(Previous) Eval Time (s)     20.005855911877006
Sample Time (s)              12.263744393829256
Epoch Time (s)               177.55875793239102
Total Train Time (s)         41035.97555930726
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:17:34.915721 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #240 | Epoch Duration: 177.64188957214355
2020-01-12 19:17:34.915923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7535717
Z variance train             0.1478019
KL Divergence                41.283367
KL Loss                      4.128337
QF Loss                      85.24814
VF Loss                      59.295425
Policy Loss                  -1270.4902
Q Predictions Mean           1268.8276
Q Predictions Std            1285.6353
Q Predictions Max            4247.918
Q Predictions Min            553.3007
V Predictions Mean           1270.0411
V Predictions Std            1281.6582
V Predictions Max            4228.981
V Predictions Min            560.83905
Log Pis Mean                 -0.27866906
Log Pis Std                  3.2091324
Log Pis Max                  10.760291
Log Pis Min                  -8.796211
Policy mu Mean               0.01185518
Policy mu Std                0.88623947
Policy mu Max                2.5212872
Policy mu Min                -2.309916
Policy log std Mean          -0.5322993
Policy log std Std           0.27702394
Policy log std Max           0.03683579
Policy log std Min           -2.7036183
Z mean eval                  1.7555279
Z variance eval              0.11521077
total_rewards                [9368.46827921 9614.31496543 9957.35103509 9622.20331845 9722.32130851
 9518.36011407 9895.83114822 9686.60492376 9922.53296118 9735.81724786]
total_rewards_mean           9704.380530176826
total_rewards_std            176.68320384945196
total_rewards_max            9957.351035086973
total_rewards_min            9368.468279207476
Number of train steps total  968000
Number of env steps total    2906000
Number of rollouts total     0
Train Time (s)               147.4575348799117
(Previous) Eval Time (s)     21.027356008067727
Sample Time (s)              6.273262531496584
Epoch Time (s)               174.758153419476
Total Train Time (s)         41210.81481294893
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:20:29.762653 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #241 | Epoch Duration: 174.84649562835693
2020-01-12 19:20:29.762950 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7553165
Z variance train             0.11537477
KL Divergence                41.670174
KL Loss                      4.1670175
QF Loss                      95.99848
VF Loss                      42.348133
Policy Loss                  -1139.9138
Q Predictions Mean           1136.996
Q Predictions Std            1154.4907
Q Predictions Max            4280.847
Q Predictions Min            577.4439
V Predictions Mean           1141.137
V Predictions Std            1151.7992
V Predictions Max            4265.4053
V Predictions Min            581.39465
Log Pis Mean                 -0.10442451
Log Pis Std                  3.786532
Log Pis Max                  15.370172
Log Pis Min                  -8.657416
Policy mu Mean               0.077679984
Policy mu Std                0.8768772
Policy mu Max                2.5687475
Policy mu Min                -3.121379
Policy log std Mean          -0.5185261
Policy log std Std           0.29285476
Policy log std Max           -0.027443111
Policy log std Min           -2.7237647
Z mean eval                  1.7434313
Z variance eval              0.090328015
total_rewards                [9541.31272588 9622.82065607 9512.86409943 9709.71468569 9633.22243041
 9771.81552948 9720.80388474 9668.58886183 9818.02926137 9645.18831803]
total_rewards_mean           9664.436045294771
total_rewards_std            90.31941987685117
total_rewards_max            9818.029261374239
total_rewards_min            9512.864099432445
Number of train steps total  972000
Number of env steps total    2918000
Number of rollouts total     0
Train Time (s)               147.83431280078366
(Previous) Eval Time (s)     20.820023346226662
Sample Time (s)              6.342322268057615
Epoch Time (s)               174.99665841506794
Total Train Time (s)         41385.96210625628
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:23:24.908200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #242 | Epoch Duration: 175.14505815505981
2020-01-12 19:23:24.908448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.743277
Z variance train             0.090263925
KL Divergence                41.020523
KL Loss                      4.102052
QF Loss                      235.07556
VF Loss                      62.001694
Policy Loss                  -1051.2185
Q Predictions Mean           1048.563
Q Predictions Std            1068.6287
Q Predictions Max            4343.218
Q Predictions Min            581.14996
V Predictions Mean           1053.446
V Predictions Std            1070.2213
V Predictions Max            4356.4375
V Predictions Min            590.197
Log Pis Mean                 -0.29338676
Log Pis Std                  3.1654117
Log Pis Max                  14.731068
Log Pis Min                  -7.6059847
Policy mu Mean               0.0745933
Policy mu Std                0.8578729
Policy mu Max                2.7099662
Policy mu Min                -2.5289176
Policy log std Mean          -0.5217146
Policy log std Std           0.2903483
Policy log std Max           0.06759566
Policy log std Min           -2.4162245
Z mean eval                  1.7405046
Z variance eval              0.10184844
total_rewards                [9449.82976642 9617.67911817 9533.49903967 9400.18933113 9161.35954457
 1329.40227026 9256.75277929 9328.33718015 9582.00776033 9203.58912218]
total_rewards_mean           8586.264591217221
total_rewards_std            2423.5282635955355
total_rewards_max            9617.679118167634
total_rewards_min            1329.4022702603393
Number of train steps total  976000
Number of env steps total    2930000
Number of rollouts total     0
Train Time (s)               147.0014761062339
(Previous) Eval Time (s)     20.64854386402294
Sample Time (s)              6.428846076596528
Epoch Time (s)               174.07886604685336
Total Train Time (s)         41560.12688823696
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:26:19.073468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #243 | Epoch Duration: 174.16484022140503
2020-01-12 19:26:19.073601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7400625
Z variance train             0.10216812
KL Divergence                41.26239
KL Loss                      4.1262393
QF Loss                      86.1644
VF Loss                      94.77193
Policy Loss                  -1053.2701
Q Predictions Mean           1050.8701
Q Predictions Std            1047.8953
Q Predictions Max            4321.281
Q Predictions Min            573.4082
V Predictions Mean           1058.206
V Predictions Std            1051.2747
V Predictions Max            4307.122
V Predictions Min            582.78674
Log Pis Mean                 -0.38569644
Log Pis Std                  3.4732554
Log Pis Max                  13.311855
Log Pis Min                  -6.989979
Policy mu Mean               0.06256003
Policy mu Std                0.864404
Policy mu Max                3.1574893
Policy mu Min                -3.1732137
Policy log std Mean          -0.5021481
Policy log std Std           0.2733402
Policy log std Max           -0.008643925
Policy log std Min           -2.51032
Z mean eval                  1.746245
Z variance eval              0.12272687
total_rewards                [8675.39151923 8557.95395327 8576.71654798 8662.24498571 8814.13968461
 8540.32764168 8577.13554502 8420.73578825 8776.7660787  8510.22845774]
total_rewards_mean           8611.164020218954
total_rewards_std            114.89219611982645
total_rewards_max            8814.13968461366
total_rewards_min            8420.73578824751
Number of train steps total  980000
Number of env steps total    2942000
Number of rollouts total     0
Train Time (s)               145.63153187185526
(Previous) Eval Time (s)     20.76222208607942
Sample Time (s)              6.432944263797253
Epoch Time (s)               172.82669822173193
Total Train Time (s)         41733.038160453085
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:29:11.986403 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #244 | Epoch Duration: 172.9127061367035
2020-01-12 19:29:11.986535 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #244 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7465522
Z variance train             0.12290241
KL Divergence                41.473034
KL Loss                      4.1473036
QF Loss                      63.876736
VF Loss                      28.068262
Policy Loss                  -1125.5853
Q Predictions Mean           1123.0966
Q Predictions Std            1142.3922
Q Predictions Max            4383.3125
Q Predictions Min            586.70917
V Predictions Mean           1124.6482
V Predictions Std            1137.6709
V Predictions Max            4364.7256
V Predictions Min            592.40564
Log Pis Mean                 -0.41343692
Log Pis Std                  3.7192342
Log Pis Max                  16.857246
Log Pis Min                  -6.8796806
Policy mu Mean               0.06790906
Policy mu Std                0.84742105
Policy mu Max                3.071768
Policy mu Min                -2.9213562
Policy log std Mean          -0.52660465
Policy log std Std           0.28679767
Policy log std Max           0.044259965
Policy log std Min           -2.7207499
Z mean eval                  1.7536799
Z variance eval              0.09292577
total_rewards                [ 9401.82031761  9743.06000706  9641.73144054  9684.43789165
  9792.63591848  9688.89156939  9631.79731749  9494.9398502
  8511.23113671 10004.45109694]
total_rewards_mean           9559.499654606238
total_rewards_std            381.8726467276882
total_rewards_max            10004.451096936282
total_rewards_min            8511.231136713779
Number of train steps total  984000
Number of env steps total    2954000
Number of rollouts total     0
Train Time (s)               147.13269118079916
(Previous) Eval Time (s)     20.84032960794866
Sample Time (s)              6.546165274921805
Epoch Time (s)               174.51918606366962
Total Train Time (s)         41907.63729048194
Epoch                        245
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:32:06.588874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #245 | Epoch Duration: 174.60221147537231
2020-01-12 19:32:06.589124 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.757605
Z variance train             0.09310536
KL Divergence                41.985695
KL Loss                      4.19857
QF Loss                      168.50597
VF Loss                      180.81978
Policy Loss                  -1298.4866
Q Predictions Mean           1295.0479
Q Predictions Std            1276.7852
Q Predictions Max            4271.6494
Q Predictions Min            563.2525
V Predictions Mean           1291.0063
V Predictions Std            1266.802
V Predictions Max            4246.6514
V Predictions Min            588.1915
Log Pis Mean                 0.053647757
Log Pis Std                  3.7410457
Log Pis Max                  22.350365
Log Pis Min                  -7.799821
Policy mu Mean               0.027179683
Policy mu Std                0.9035577
Policy mu Max                3.401928
Policy mu Min                -4.3787894
Policy log std Mean          -0.53548014
Policy log std Std           0.28902376
Policy log std Max           0.18270916
Policy log std Min           -2.343298
Z mean eval                  1.741952
Z variance eval              0.1255991
total_rewards                [9349.87380785 9647.21075538 9652.24171928 9986.90827054 9778.96219524
 9694.90596303 8262.72522524 9959.44548285 9839.52627217 9696.98482609]
total_rewards_mean           9586.878451767969
total_rewards_std            473.3725597484358
total_rewards_max            9986.90827054001
total_rewards_min            8262.725225241616
Number of train steps total  988000
Number of env steps total    2966000
Number of rollouts total     0
Train Time (s)               148.28509284881875
(Previous) Eval Time (s)     20.013280373997986
Sample Time (s)              6.608933925628662
Epoch Time (s)               174.9073071484454
Total Train Time (s)         42082.63267545588
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:35:01.589070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #246 | Epoch Duration: 174.99973845481873
2020-01-12 19:35:01.589337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.742396
Z variance train             0.12574041
KL Divergence                42.18763
KL Loss                      4.218763
QF Loss                      249.04099
VF Loss                      122.4818
Policy Loss                  -1134.4979
Q Predictions Mean           1132.6044
Q Predictions Std            1142.4135
Q Predictions Max            4294.5356
Q Predictions Min            594.22003
V Predictions Mean           1132.384
V Predictions Std            1137.6532
V Predictions Max            4297.891
V Predictions Min            600.22125
Log Pis Mean                 -0.24487051
Log Pis Std                  3.3126407
Log Pis Max                  10.053282
Log Pis Min                  -6.6233916
Policy mu Mean               0.10837755
Policy mu Std                0.84246606
Policy mu Max                2.6497948
Policy mu Min                -2.4111938
Policy log std Mean          -0.5315239
Policy log std Std           0.2939661
Policy log std Max           -0.025124907
Policy log std Min           -2.565117
Z mean eval                  1.7761278
Z variance eval              0.21891162
total_rewards                [9327.07459755 6943.99354212 9795.29654445 9457.85499822 9508.01460198
 9582.14422624 9831.87033275 9840.46733598 9746.66037073 9640.24391505]
total_rewards_mean           9367.362046506332
total_rewards_std            823.9840846390379
total_rewards_max            9840.467335978165
total_rewards_min            6943.993542118503
Number of train steps total  992000
Number of env steps total    2978000
Number of rollouts total     0
Train Time (s)               144.99456060910597
(Previous) Eval Time (s)     20.642044589389116
Sample Time (s)              6.4396892176009715
Epoch Time (s)               172.07629441609606
Total Train Time (s)         42254.856095574796
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:37:53.838012 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #247 | Epoch Duration: 172.24846172332764
2020-01-12 19:37:53.838247 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7808367
Z variance train             0.21946359
KL Divergence                41.646427
KL Loss                      4.164643
QF Loss                      3137.4502
VF Loss                      71.614
Policy Loss                  -1249.729
Q Predictions Mean           1247.2704
Q Predictions Std            1268.4957
Q Predictions Max            4341.874
Q Predictions Min            553.904
V Predictions Mean           1249.7037
V Predictions Std            1263.8331
V Predictions Max            4333.7554
V Predictions Min            582.7824
Log Pis Mean                 0.13475206
Log Pis Std                  3.945512
Log Pis Max                  13.038726
Log Pis Min                  -6.367713
Policy mu Mean               0.057308603
Policy mu Std                0.9101018
Policy mu Max                3.0814364
Policy mu Min                -3.2372906
Policy log std Mean          -0.5317345
Policy log std Std           0.31471327
Policy log std Max           -0.0015593469
Policy log std Min           -2.7365646
Z mean eval                  1.7895944
Z variance eval              0.20777074
total_rewards                [9285.11854296 9741.3798338  9641.53032895 9551.89385633 9602.09142616
 9423.22838334 8901.55215058 9752.73051394 9654.35256234 9649.21632879]
total_rewards_mean           9520.30939271924
total_rewards_std            246.4663596926194
total_rewards_max            9752.73051394028
total_rewards_min            8901.552150584128
Number of train steps total  996000
Number of env steps total    2990000
Number of rollouts total     0
Train Time (s)               147.26645398605615
(Previous) Eval Time (s)     20.95986649999395
Sample Time (s)              6.370590458158404
Epoch Time (s)               174.5969109442085
Total Train Time (s)         42429.557815935
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:40:48.521030 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #248 | Epoch Duration: 174.68256545066833
2020-01-12 19:40:48.521355 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7857702
Z variance train             0.20802024
KL Divergence                41.312172
KL Loss                      4.1312175
QF Loss                      3491.8516
VF Loss                      86.253624
Policy Loss                  -1291.3575
Q Predictions Mean           1290.3569
Q Predictions Std            1306.7186
Q Predictions Max            4359.3237
Q Predictions Min            575.464
V Predictions Mean           1295.1721
V Predictions Std            1309.8551
V Predictions Max            4366.727
V Predictions Min            578.3418
Log Pis Mean                 -0.4919771
Log Pis Std                  3.702838
Log Pis Max                  11.06343
Log Pis Min                  -8.361116
Policy mu Mean               0.0042738332
Policy mu Std                0.88259333
Policy mu Max                2.7075617
Policy mu Min                -3.3106897
Policy log std Mean          -0.52201027
Policy log std Std           0.28866777
Policy log std Max           -0.020443559
Policy log std Min           -2.7537513
Z mean eval                  1.7741749
Z variance eval              0.19469921
total_rewards                [8953.59386701 9078.20746522 9082.6129015  9184.80300371 9140.97529638
 9161.61964361 9225.32541587 9043.93005791 9106.4554853  9179.93103352]
total_rewards_mean           9115.745417002716
total_rewards_std            75.94817080568373
total_rewards_max            9225.325415871645
total_rewards_min            8953.593867008452
Number of train steps total  1000000
Number of env steps total    3002000
Number of rollouts total     0
Train Time (s)               144.73458814807236
(Previous) Eval Time (s)     20.888639369048178
Sample Time (s)              5.518612444866449
Epoch Time (s)               171.141839961987
Total Train Time (s)         42600.78605386708
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:43:39.751512 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #249 | Epoch Duration: 171.22993779182434
2020-01-12 19:43:39.751645 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7708296
Z variance train             0.19426517
KL Divergence                41.50176
KL Loss                      4.150176
QF Loss                      312.63577
VF Loss                      79.54883
Policy Loss                  -1214.9336
Q Predictions Mean           1212.8563
Q Predictions Std            1199.0344
Q Predictions Max            4320.982
Q Predictions Min            566.72766
V Predictions Mean           1216.3716
V Predictions Std            1199.1665
V Predictions Max            4318.967
V Predictions Min            584.54297
Log Pis Mean                 -0.09262577
Log Pis Std                  3.9762115
Log Pis Max                  14.427551
Log Pis Min                  -6.418995
Policy mu Mean               0.010030989
Policy mu Std                0.9012278
Policy mu Max                3.8242
Policy mu Min                -3.318738
Policy log std Mean          -0.51690495
Policy log std Std           0.3031114
Policy log std Max           -0.0356839
Policy log std Min           -2.5228927
Z mean eval                  1.779094
Z variance eval              0.16788673
total_rewards                [9293.24347319 9320.62791688 8982.58661267 9102.22969245 9626.58224729
 9579.82159245 9651.96357395 9203.52862491 9475.62391751 5204.51161802]
total_rewards_mean           8944.07192693135
total_rewards_std            1264.7330786139976
total_rewards_max            9651.963573947622
total_rewards_min            5204.511618020752
Number of train steps total  1004000
Number of env steps total    3014000
Number of rollouts total     0
Train Time (s)               147.85446588508785
(Previous) Eval Time (s)     20.90647173067555
Sample Time (s)              6.4679902866482735
Epoch Time (s)               175.22892790241167
Total Train Time (s)         42776.143607934006
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:46:35.132242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #250 | Epoch Duration: 175.38044667243958
2020-01-12 19:46:35.132575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.781633
Z variance train             0.16794653
KL Divergence                42.087605
KL Loss                      4.2087607
QF Loss                      162.08014
VF Loss                      90.7452
Policy Loss                  -1182.178
Q Predictions Mean           1179.3741
Q Predictions Std            1190.5563
Q Predictions Max            4399.238
Q Predictions Min            568.9331
V Predictions Mean           1177.9407
V Predictions Std            1183.6565
V Predictions Max            4365.2056
V Predictions Min            569.1673
Log Pis Mean                 0.036378667
Log Pis Std                  3.9523475
Log Pis Max                  16.46635
Log Pis Min                  -7.4223256
Policy mu Mean               0.1192106
Policy mu Std                0.8995898
Policy mu Max                3.3675923
Policy mu Min                -2.8045778
Policy log std Mean          -0.53068477
Policy log std Std           0.29475403
Policy log std Max           0.07542354
Policy log std Min           -2.8296185
Z mean eval                  1.7824188
Z variance eval              0.08480109
total_rewards                [9561.63311355 9911.994618   9585.5584945  9769.39539689 9518.80373113
 9730.77940212 9621.22299616 9466.27733852 9639.09516555 9737.44180413]
total_rewards_mean           9654.220206055687
total_rewards_std            126.79299787697703
total_rewards_max            9911.994617998691
total_rewards_min            9466.277338519903
Number of train steps total  1008000
Number of env steps total    3026000
Number of rollouts total     0
Train Time (s)               146.4372411747463
(Previous) Eval Time (s)     20.998735588043928
Sample Time (s)              6.387659186962992
Epoch Time (s)               173.82363594975322
Total Train Time (s)         42950.06826605741
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:49:29.037606 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #251 | Epoch Duration: 173.90480995178223
2020-01-12 19:49:29.037741 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.779948
Z variance train             0.08494794
KL Divergence                42.98838
KL Loss                      4.298838
QF Loss                      115.548996
VF Loss                      40.357155
Policy Loss                  -1172.4442
Q Predictions Mean           1169.6829
Q Predictions Std            1194.9348
Q Predictions Max            4375.903
Q Predictions Min            580.5599
V Predictions Mean           1173.3706
V Predictions Std            1197.6575
V Predictions Max            4377.232
V Predictions Min            584.6308
Log Pis Mean                 -0.47764584
Log Pis Std                  3.542006
Log Pis Max                  12.724888
Log Pis Min                  -6.3510075
Policy mu Mean               0.060035665
Policy mu Std                0.85212046
Policy mu Max                2.9897208
Policy mu Min                -3.0786083
Policy log std Mean          -0.53258693
Policy log std Std           0.2844259
Policy log std Max           -0.03864561
Policy log std Min           -2.686901
Z mean eval                  1.7742409
Z variance eval              0.069273874
total_rewards                [7918.3108124  8404.26100453 1993.11720653 8637.12196374 8686.91210689
 1241.89127459 9086.00930346 9261.13435885 8897.57452191 8543.00803974]
total_rewards_mean           7266.934059262074
total_rewards_std            2851.2990768885734
total_rewards_max            9261.134358845975
total_rewards_min            1241.8912745857501
Number of train steps total  1012000
Number of env steps total    3038000
Number of rollouts total     0
Train Time (s)               145.87022060807794
(Previous) Eval Time (s)     20.873014727141708
Sample Time (s)              6.406892157159746
Epoch Time (s)               173.1501274923794
Total Train Time (s)         43123.30724194879
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:52:22.278305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #252 | Epoch Duration: 173.24047088623047
2020-01-12 19:52:22.278442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7725197
Z variance train             0.06935481
KL Divergence                42.754585
KL Loss                      4.275459
QF Loss                      116.50628
VF Loss                      61.664944
Policy Loss                  -1372.1632
Q Predictions Mean           1370.2963
Q Predictions Std            1348.9945
Q Predictions Max            4335.462
Q Predictions Min            584.12866
V Predictions Mean           1374.6292
V Predictions Std            1346.0734
V Predictions Max            4324.6953
V Predictions Min            581.8322
Log Pis Mean                 0.16490975
Log Pis Std                  4.2498426
Log Pis Max                  24.896267
Log Pis Min                  -7.650147
Policy mu Mean               0.07763508
Policy mu Std                0.9504339
Policy mu Max                4.084854
Policy mu Min                -4.3351984
Policy log std Mean          -0.5551511
Policy log std Std           0.29576644
Policy log std Max           -0.078214645
Policy log std Min           -2.6446655
Z mean eval                  1.7733316
Z variance eval              0.1054492
total_rewards                [9297.31855359 9524.66210388 9736.58595865 9376.52987659 9495.91938876
 9495.36825022 9577.36126132 9375.93736886 9560.2794408  9671.36630047]
total_rewards_mean           9511.132850312875
total_rewards_std            128.8723389020426
total_rewards_max            9736.58595864641
total_rewards_min            9297.318553588626
Number of train steps total  1016000
Number of env steps total    3050000
Number of rollouts total     0
Train Time (s)               147.20895784022287
(Previous) Eval Time (s)     20.903329230844975
Sample Time (s)              6.391632665414363
Epoch Time (s)               174.5039197364822
Total Train Time (s)         43297.8927455768
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:55:16.865866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #253 | Epoch Duration: 174.58732438087463
2020-01-12 19:55:16.865999 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.772883
Z variance train             0.10536511
KL Divergence                42.610783
KL Loss                      4.2610784
QF Loss                      314.62955
VF Loss                      47.436485
Policy Loss                  -1174.5073
Q Predictions Mean           1174.7141
Q Predictions Std            1197.613
Q Predictions Max            4362.861
Q Predictions Min            596.42957
V Predictions Mean           1174.3839
V Predictions Std            1198.0925
V Predictions Max            4344.783
V Predictions Min            596.0866
Log Pis Mean                 -0.22037485
Log Pis Std                  3.5147452
Log Pis Max                  14.948996
Log Pis Min                  -5.9011946
Policy mu Mean               0.037654866
Policy mu Std                0.8659603
Policy mu Max                2.5179725
Policy mu Min                -2.5017154
Policy log std Mean          -0.52178925
Policy log std Std           0.2663274
Policy log std Max           0.020970047
Policy log std Min           -2.5639024
Z mean eval                  1.7574002
Z variance eval              0.083392896
total_rewards                [9436.59517697 7645.52392509 9888.78148295 9283.85671157 9772.65494797
 9625.66442201 9476.33448268 9675.11230832 9727.43305852 8940.84725862]
total_rewards_mean           9347.280377469391
total_rewards_std            623.9769262334604
total_rewards_max            9888.781482949382
total_rewards_min            7645.523925085676
Number of train steps total  1020000
Number of env steps total    3062000
Number of rollouts total     0
Train Time (s)               146.61939822230488
(Previous) Eval Time (s)     20.885880242101848
Sample Time (s)              6.405118784401566
Epoch Time (s)               173.9103972488083
Total Train Time (s)         43471.880744062364
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:58:10.857068 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #254 | Epoch Duration: 173.99095678329468
2020-01-12 19:58:10.857262 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7567291
Z variance train             0.083589815
KL Divergence                42.660053
KL Loss                      4.2660055
QF Loss                      110.299545
VF Loss                      58.03016
Policy Loss                  -1345.028
Q Predictions Mean           1344.6294
Q Predictions Std            1344.6343
Q Predictions Max            4363.851
Q Predictions Min            570.07184
V Predictions Mean           1344.8416
V Predictions Std            1338.7618
V Predictions Max            4375.342
V Predictions Min            573.71094
Log Pis Mean                 0.19450305
Log Pis Std                  4.052311
Log Pis Max                  16.350153
Log Pis Min                  -6.6292815
Policy mu Mean               0.031369675
Policy mu Std                0.92569155
Policy mu Max                2.7624369
Policy mu Min                -3.1202905
Policy log std Mean          -0.54127717
Policy log std Std           0.287054
Policy log std Max           0.060705245
Policy log std Min           -2.9605079
Z mean eval                  1.7736576
Z variance eval              0.124440074
total_rewards                [9543.0524522  9568.09634856 9348.12763431 9788.60165247 9472.89849871
 9547.89491777 9827.39908861 9432.49402028 9562.72839157 9663.41812542]
total_rewards_mean           9575.471112989708
total_rewards_std            141.8815831949464
total_rewards_max            9827.39908861006
total_rewards_min            9348.127634314687
Number of train steps total  1024000
Number of env steps total    3074000
Number of rollouts total     0
Train Time (s)               146.66588221257553
(Previous) Eval Time (s)     21.13049812288955
Sample Time (s)              6.607282637152821
Epoch Time (s)               174.4036629726179
Total Train Time (s)         43646.37151093315
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:01:05.350325 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #255 | Epoch Duration: 174.4929323196411
2020-01-12 20:01:05.350468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7696536
Z variance train             0.12433443
KL Divergence                42.53275
KL Loss                      4.253275
QF Loss                      137.61432
VF Loss                      200.22217
Policy Loss                  -1205.2664
Q Predictions Mean           1207.1848
Q Predictions Std            1244.0605
Q Predictions Max            4375.4473
Q Predictions Min            596.6173
V Predictions Mean           1213.2854
V Predictions Std            1244.6924
V Predictions Max            4366.8154
V Predictions Min            603.7684
Log Pis Mean                 -0.05770106
Log Pis Std                  3.5814118
Log Pis Max                  13.804436
Log Pis Min                  -6.3363624
Policy mu Mean               0.07291773
Policy mu Std                0.8686205
Policy mu Max                2.6653752
Policy mu Min                -2.5074222
Policy log std Mean          -0.5305609
Policy log std Std           0.27696538
Policy log std Max           0.04726708
Policy log std Min           -2.407583
Z mean eval                  1.7659814
Z variance eval              0.14784692
total_rewards                [9482.0832671  9526.10796027 9586.63965771 9076.85540055 9432.76884432
 9425.94774397 9457.84490658 9236.0533262  9300.11439827 5282.76617061]
total_rewards_mean           8980.71816755669
total_rewards_std            1240.8661608371513
total_rewards_max            9586.639657705757
total_rewards_min            5282.766170613876
Number of train steps total  1028000
Number of env steps total    3086000
Number of rollouts total     0
Train Time (s)               144.8586970884353
(Previous) Eval Time (s)     20.92569271288812
Sample Time (s)              6.48561123246327
Epoch Time (s)               172.27000103378668
Total Train Time (s)         43818.71970782569
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:03:57.699361 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #256 | Epoch Duration: 172.34879088401794
2020-01-12 20:03:57.699493 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7671797
Z variance train             0.14730713
KL Divergence                41.99893
KL Loss                      4.1998935
QF Loss                      3088.1333
VF Loss                      79.66611
Policy Loss                  -1119.6488
Q Predictions Mean           1117.0925
Q Predictions Std            1146.0569
Q Predictions Max            4369.577
Q Predictions Min            533.8716
V Predictions Mean           1116.3622
V Predictions Std            1140.1249
V Predictions Max            4337.3555
V Predictions Min            562.38873
Log Pis Mean                 -0.24003728
Log Pis Std                  3.6565027
Log Pis Max                  15.823721
Log Pis Min                  -6.151873
Policy mu Mean               0.047149498
Policy mu Std                0.8578993
Policy mu Max                2.84176
Policy mu Min                -2.6344876
Policy log std Mean          -0.51927334
Policy log std Std           0.28049564
Policy log std Max           0.22885507
Policy log std Min           -2.368062
Z mean eval                  1.7467384
Z variance eval              0.07817599
total_rewards                [9360.25716485 9156.6142327  9418.1786055  9062.56081975 9038.25587707
 9232.31632545 9223.43472996 9450.11777444 9547.63202213 9116.12260379]
total_rewards_mean           9260.549015562578
total_rewards_std            166.0094326399013
total_rewards_max            9547.632022130394
total_rewards_min            9038.255877073909
Number of train steps total  1032000
Number of env steps total    3098000
Number of rollouts total     0
Train Time (s)               148.3286285973154
(Previous) Eval Time (s)     17.352066116873175
Sample Time (s)              6.619578615296632
Epoch Time (s)               172.3002733294852
Total Train Time (s)         43991.103924071416
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:06:50.087909 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #257 | Epoch Duration: 172.3882999420166
2020-01-12 20:06:50.088097 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7466068
Z variance train             0.078112744
KL Divergence                43.106705
KL Loss                      4.3106704
QF Loss                      113.54188
VF Loss                      40.66529
Policy Loss                  -1205.5977
Q Predictions Mean           1206.2733
Q Predictions Std            1198.4668
Q Predictions Max            4369.998
Q Predictions Min            589.5702
V Predictions Mean           1204.4309
V Predictions Std            1195.4578
V Predictions Max            4353.837
V Predictions Min            590.47095
Log Pis Mean                 -0.5620737
Log Pis Std                  3.5955713
Log Pis Max                  14.956507
Log Pis Min                  -7.457562
Policy mu Mean               0.058630973
Policy mu Std                0.86694425
Policy mu Max                3.1030345
Policy mu Min                -3.631264
Policy log std Mean          -0.5288134
Policy log std Std           0.26747486
Policy log std Max           0.02033484
Policy log std Min           -2.7380586
Z mean eval                  1.7535006
Z variance eval              0.101828896
total_rewards                [9014.4994191  8955.6178815  9112.27310852 9230.61919304 9226.20428257
 9150.81280974 9030.58887528 9155.16566097 9182.65525363 9303.63480021]
total_rewards_mean           9136.207128455524
total_rewards_std            103.4062988981088
total_rewards_max            9303.634800207385
total_rewards_min            8955.617881498874
Number of train steps total  1036000
Number of env steps total    3110000
Number of rollouts total     0
Train Time (s)               146.43617687094957
(Previous) Eval Time (s)     20.645288208965212
Sample Time (s)              6.701856094412506
Epoch Time (s)               173.78332117432728
Total Train Time (s)         44164.97197356913
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:09:43.956227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #258 | Epoch Duration: 173.8679940700531
2020-01-12 20:09:43.956369 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #258 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.757515
Z variance train             0.102180645
KL Divergence                42.70831
KL Loss                      4.270831
QF Loss                      118.2476
VF Loss                      114.67954
Policy Loss                  -1116.6198
Q Predictions Mean           1114.4193
Q Predictions Std            1153.6993
Q Predictions Max            4426.0
Q Predictions Min            592.1076
V Predictions Mean           1110.6354
V Predictions Std            1145.0475
V Predictions Max            4377.2983
V Predictions Min            599.01117
Log Pis Mean                 -0.254673
Log Pis Std                  3.5463016
Log Pis Max                  12.619457
Log Pis Min                  -6.426708
Policy mu Mean               0.10736949
Policy mu Std                0.85020524
Policy mu Max                2.7074182
Policy mu Min                -2.3784518
Policy log std Mean          -0.5272296
Policy log std Std           0.27173275
Policy log std Max           -0.010414362
Policy log std Min           -2.3654675
Z mean eval                  1.7456992
Z variance eval              0.11958937
total_rewards                [ 9582.03346982  9992.80349231  9806.89539839  9841.1413341
  9952.94112694  9750.0695819   9844.52247665 10217.08594831
  9650.18901719  9727.11601141]
total_rewards_mean           9836.479785701767
total_rewards_std            173.98200587888314
total_rewards_max            10217.085948311493
total_rewards_min            9582.033469821065
Number of train steps total  1040000
Number of env steps total    3122000
Number of rollouts total     0
Train Time (s)               144.62589588807896
(Previous) Eval Time (s)     20.62823871569708
Sample Time (s)              6.520058323163539
Epoch Time (s)               171.77419292693958
Total Train Time (s)         44336.82399552921
Epoch                        259
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:12:35.810516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #259 | Epoch Duration: 171.85404872894287
2020-01-12 20:12:35.810658 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7392038
Z variance train             0.11992015
KL Divergence                42.237
KL Loss                      4.2237
QF Loss                      173.88284
VF Loss                      218.82959
Policy Loss                  -1194.1675
Q Predictions Mean           1191.1134
Q Predictions Std            1205.2891
Q Predictions Max            4360.028
Q Predictions Min            601.7235
V Predictions Mean           1202.6624
V Predictions Std            1212.2273
V Predictions Max            4361.2905
V Predictions Min            601.97485
Log Pis Mean                 -0.076390214
Log Pis Std                  3.6655471
Log Pis Max                  12.557689
Log Pis Min                  -7.4810295
Policy mu Mean               0.08533436
Policy mu Std                0.8968728
Policy mu Max                2.8948433
Policy mu Min                -3.3117871
Policy log std Mean          -0.53730637
Policy log std Std           0.29991594
Policy log std Max           0.20123446
Policy log std Min           -2.766329
Z mean eval                  1.7346836
Z variance eval              0.09075831
total_rewards                [8582.13087516 9500.02280516 9639.52496233 9386.68534673 9185.10237711
 9644.74223414 9198.08859355 9127.5286929  9467.13042529 9617.0004374 ]
total_rewards_mean           9334.795674976314
total_rewards_std            310.9070885407209
total_rewards_max            9644.74223414028
total_rewards_min            8582.130875159151
Number of train steps total  1044000
Number of env steps total    3134000
Number of rollouts total     0
Train Time (s)               147.3854846721515
(Previous) Eval Time (s)     17.361706456169486
Sample Time (s)              7.163505083415657
Epoch Time (s)               171.91069621173665
Total Train Time (s)         44508.81322113611
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:15:27.812279 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #260 | Epoch Duration: 172.0015058517456
2020-01-12 20:15:27.812466 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7356094
Z variance train             0.090810955
KL Divergence                41.900925
KL Loss                      4.1900926
QF Loss                      128.53183
VF Loss                      121.72565
Policy Loss                  -1248.1598
Q Predictions Mean           1248.9766
Q Predictions Std            1258.8635
Q Predictions Max            4340.17
Q Predictions Min            593.4023
V Predictions Mean           1239.8278
V Predictions Std            1251.0731
V Predictions Max            4293.5386
V Predictions Min            592.1569
Log Pis Mean                 -0.38945076
Log Pis Std                  3.8229377
Log Pis Max                  11.162537
Log Pis Min                  -10.818248
Policy mu Mean               0.0821761
Policy mu Std                0.86427796
Policy mu Max                2.6682222
Policy mu Min                -2.6191435
Policy log std Mean          -0.51123875
Policy log std Std           0.27295086
Policy log std Max           0.022065043
Policy log std Min           -2.7542558
Z mean eval                  1.7592528
Z variance eval              0.115919426
total_rewards                [8733.29606113 9129.99931395 8882.51067484 9690.71167706 9382.29636179
 9319.7893472  9174.00853016 8779.24326081 9368.36617903 9185.75061213]
total_rewards_mean           9164.597201809138
total_rewards_std            283.8344516791523
total_rewards_max            9690.711677056248
total_rewards_min            8733.296061128049
Number of train steps total  1048000
Number of env steps total    3146000
Number of rollouts total     0
Train Time (s)               146.63168477499858
(Previous) Eval Time (s)     20.716114414855838
Sample Time (s)              6.353921830654144
Epoch Time (s)               173.70172102050856
Total Train Time (s)         44682.61376539664
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:18:21.614518 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #261 | Epoch Duration: 173.80190205574036
2020-01-12 20:18:21.614765 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7592831
Z variance train             0.11545143
KL Divergence                40.196453
KL Loss                      4.019645
QF Loss                      94.97003
VF Loss                      149.12033
Policy Loss                  -1268.4645
Q Predictions Mean           1265.7703
Q Predictions Std            1264.2429
Q Predictions Max            4391.273
Q Predictions Min            603.3117
V Predictions Mean           1272.4617
V Predictions Std            1271.0067
V Predictions Max            4393.1777
V Predictions Min            600.84204
Log Pis Mean                 -0.3984337
Log Pis Std                  3.463973
Log Pis Max                  10.35025
Log Pis Min                  -7.520997
Policy mu Mean               0.0481486
Policy mu Std                0.90044373
Policy mu Max                2.6502335
Policy mu Min                -2.714939
Policy log std Mean          -0.5165883
Policy log std Std           0.2921982
Policy log std Max           0.043790698
Policy log std Min           -2.896711
Z mean eval                  1.745047
Z variance eval              0.08715452
total_rewards                [9280.48230629 9383.77209041 9353.4571532  8884.89910416 8916.26078091
 9359.3328798  9383.23904886 9219.88198348 9455.93200074 9036.15902022]
total_rewards_mean           9227.3416368059
total_rewards_std            196.93232675694512
total_rewards_max            9455.93200073663
total_rewards_min            8884.899104160253
Number of train steps total  1052000
Number of env steps total    3158000
Number of rollouts total     0
Train Time (s)               146.6336931148544
(Previous) Eval Time (s)     20.84137403825298
Sample Time (s)              6.371843389701098
Epoch Time (s)               173.84691054280847
Total Train Time (s)         44856.765758476686
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:21:15.765526 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #262 | Epoch Duration: 174.15058064460754
2020-01-12 20:21:15.765764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #262 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7452042
Z variance train             0.0868842
KL Divergence                41.589752
KL Loss                      4.158975
QF Loss                      180.93974
VF Loss                      126.100494
Policy Loss                  -1238.6925
Q Predictions Mean           1235.9426
Q Predictions Std            1263.0867
Q Predictions Max            4398.207
Q Predictions Min            602.05054
V Predictions Mean           1234.561
V Predictions Std            1256.9209
V Predictions Max            4383.42
V Predictions Min            603.8504
Log Pis Mean                 0.017342582
Log Pis Std                  3.693031
Log Pis Max                  16.862032
Log Pis Min                  -8.191497
Policy mu Mean               -0.00019532256
Policy mu Std                0.8909035
Policy mu Max                2.7036388
Policy mu Min                -2.4853492
Policy log std Mean          -0.524471
Policy log std Std           0.29293114
Policy log std Max           0.0033568144
Policy log std Min           -2.9662037
Z mean eval                  1.7660414
Z variance eval              0.092907295
total_rewards                [9246.33412308 9880.27072724 9510.18602029 9725.82068277 9821.2008116
 9919.45869741 9718.74481617 9807.52747678 9934.84722089 9840.51884968]
total_rewards_mean           9740.490942591063
total_rewards_std            202.05820955649847
total_rewards_max            9934.847220892663
total_rewards_min            9246.334123076897
Number of train steps total  1056000
Number of env steps total    3170000
Number of rollouts total     0
Train Time (s)               145.5090962871909
(Previous) Eval Time (s)     20.74479079199955
Sample Time (s)              6.479285418521613
Epoch Time (s)               172.73317249771208
Total Train Time (s)         45029.58179012034
Epoch                        263
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:24:08.580833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #263 | Epoch Duration: 172.81490421295166
2020-01-12 20:24:08.580970 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7674544
Z variance train             0.09268341
KL Divergence                42.820137
KL Loss                      4.282014
QF Loss                      142.76653
VF Loss                      50.05094
Policy Loss                  -1257.801
Q Predictions Mean           1251.8201
Q Predictions Std            1260.7694
Q Predictions Max            4382.842
Q Predictions Min            579.8911
V Predictions Mean           1256.5542
V Predictions Std            1258.1921
V Predictions Max            4379.6216
V Predictions Min            582.98804
Log Pis Mean                 -0.054270566
Log Pis Std                  3.787392
Log Pis Max                  13.063032
Log Pis Min                  -10.751216
Policy mu Mean               0.07265356
Policy mu Std                0.88973165
Policy mu Max                2.4966269
Policy mu Min                -2.8431544
Policy log std Mean          -0.54232186
Policy log std Std           0.3004154
Policy log std Max           -0.016217709
Policy log std Min           -2.8722336
Z mean eval                  1.7454135
Z variance eval              0.09278419
total_rewards                [9609.03153428 9702.18040305 9696.43015969 9879.92615209 9975.52721157
 9807.92252283 9884.29342294 9895.78264647 9853.73068436 9609.89229134]
total_rewards_mean           9791.471702862966
total_rewards_std            121.90381608184126
total_rewards_max            9975.527211566443
total_rewards_min            9609.031534284286
Number of train steps total  1060000
Number of env steps total    3182000
Number of rollouts total     0
Train Time (s)               147.2457104199566
(Previous) Eval Time (s)     20.704821993596852
Sample Time (s)              6.552130613476038
Epoch Time (s)               174.50266302702948
Total Train Time (s)         45204.166069444735
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:27:03.168274 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #264 | Epoch Duration: 174.58720660209656
2020-01-12 20:27:03.168411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7463608
Z variance train             0.092796125
KL Divergence                43.294846
KL Loss                      4.3294845
QF Loss                      143.43774
VF Loss                      62.886543
Policy Loss                  -1269.644
Q Predictions Mean           1268.9779
Q Predictions Std            1298.0004
Q Predictions Max            4372.104
Q Predictions Min            590.20905
V Predictions Mean           1270.8508
V Predictions Std            1291.8638
V Predictions Max            4331.3604
V Predictions Min            600.31635
Log Pis Mean                 0.019742236
Log Pis Std                  4.2634945
Log Pis Max                  24.542145
Log Pis Min                  -6.686059
Policy mu Mean               0.06087004
Policy mu Std                0.9288629
Policy mu Max                2.9903731
Policy mu Min                -3.6272037
Policy log std Mean          -0.52189523
Policy log std Std           0.2775352
Policy log std Max           0.039422452
Policy log std Min           -2.6491127
Z mean eval                  1.7472773
Z variance eval              0.05981777
total_rewards                [9459.28721303 9735.37377131 9738.73380732 9765.99337355 9759.78076077
 9602.01404775 9704.2133714  9543.49027655 9790.50147059 9757.21633363]
total_rewards_mean           9685.660442589618
total_rewards_std            105.89873033555946
total_rewards_max            9790.501470589665
total_rewards_min            9459.287213026506
Number of train steps total  1064000
Number of env steps total    3194000
Number of rollouts total     0
Train Time (s)               144.91787139233202
(Previous) Eval Time (s)     17.46636558091268
Sample Time (s)              6.586990963667631
Epoch Time (s)               168.97122793691233
Total Train Time (s)         45373.21807850432
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:29:52.224693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #265 | Epoch Duration: 169.0561661720276
2020-01-12 20:29:52.224878 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7451235
Z variance train             0.059518296
KL Divergence                44.472107
KL Loss                      4.447211
QF Loss                      120.551575
VF Loss                      55.106342
Policy Loss                  -1218.0856
Q Predictions Mean           1219.495
Q Predictions Std            1254.5999
Q Predictions Max            4359.777
Q Predictions Min            564.6509
V Predictions Mean           1221.447
V Predictions Std            1255.6483
V Predictions Max            4348.4106
V Predictions Min            555.7788
Log Pis Mean                 -0.2760762
Log Pis Std                  3.6505923
Log Pis Max                  12.610852
Log Pis Min                  -8.276613
Policy mu Mean               0.09583279
Policy mu Std                0.856386
Policy mu Max                2.6970887
Policy mu Min                -2.9787123
Policy log std Mean          -0.5191657
Policy log std Std           0.2841953
Policy log std Max           0.057383537
Policy log std Min           -2.9506981
Z mean eval                  1.7385772
Z variance eval              0.035187196
total_rewards                [9660.143292   9644.99637509 9689.20299252 9679.1998455  9780.75601008
 9926.06666626 9694.02714043 9675.89592774 9911.27479518 9903.64086707]
total_rewards_mean           9756.520391187005
total_rewards_std            108.429066881898
total_rewards_max            9926.066666255521
total_rewards_min            9644.996375090208
Number of train steps total  1068000
Number of env steps total    3206000
Number of rollouts total     0
Train Time (s)               145.79407923389226
(Previous) Eval Time (s)     21.038610205985606
Sample Time (s)              6.791314459405839
Epoch Time (s)               173.6240038992837
Total Train Time (s)         45546.93370489543
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:32:45.940665 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #266 | Epoch Duration: 173.71564984321594
2020-01-12 20:32:45.940807 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #266 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7365135
Z variance train             0.035247542
KL Divergence                45.664352
KL Loss                      4.5664353
QF Loss                      93.18532
VF Loss                      30.372679
Policy Loss                  -1159.3887
Q Predictions Mean           1155.7102
Q Predictions Std            1149.6685
Q Predictions Max            4335.1514
Q Predictions Min            607.82104
V Predictions Mean           1160.4246
V Predictions Std            1148.7865
V Predictions Max            4327.755
V Predictions Min            613.9379
Log Pis Mean                 0.015656546
Log Pis Std                  3.2932482
Log Pis Max                  14.532477
Log Pis Min                  -8.064541
Policy mu Mean               0.12966149
Policy mu Std                0.8757177
Policy mu Max                2.6650927
Policy mu Min                -2.182673
Policy log std Mean          -0.55498165
Policy log std Std           0.30463317
Policy log std Max           0.03918588
Policy log std Min           -2.670804
Z mean eval                  1.7481508
Z variance eval              0.08875714
total_rewards                [8235.15190744 5134.02705917 8943.61360524 8889.50625222 8921.0080086
 9002.74468688 9032.81428565 9189.96434883 8608.06135219 9174.89871434]
total_rewards_mean           8513.179022056202
total_rewards_std            1157.7476838752534
total_rewards_max            9189.964348828462
total_rewards_min            5134.027059169511
Number of train steps total  1072000
Number of env steps total    3218000
Number of rollouts total     0
Train Time (s)               145.32139267586172
(Previous) Eval Time (s)     21.02859862195328
Sample Time (s)              6.4026372381486
Epoch Time (s)               172.7526285359636
Total Train Time (s)         45719.7720606979
Epoch                        267
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:35:38.781981 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #267 | Epoch Duration: 172.84107661247253
2020-01-12 20:35:38.782114 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7478126
Z variance train             0.088783465
KL Divergence                42.81504
KL Loss                      4.281504
QF Loss                      3348.2485
VF Loss                      61.408363
Policy Loss                  -1160.5621
Q Predictions Mean           1160.4563
Q Predictions Std            1190.4075
Q Predictions Max            4379.071
Q Predictions Min            571.579
V Predictions Mean           1155.3696
V Predictions Std            1188.8616
V Predictions Max            4355.9033
V Predictions Min            593.9074
Log Pis Mean                 -0.26281565
Log Pis Std                  3.521033
Log Pis Max                  11.419003
Log Pis Min                  -7.0363874
Policy mu Mean               0.05872916
Policy mu Std                0.860494
Policy mu Max                3.3131218
Policy mu Min                -2.4647305
Policy log std Mean          -0.5362471
Policy log std Std           0.27901968
Policy log std Max           -0.07379049
Policy log std Min           -2.3348083
Z mean eval                  1.7501844
Z variance eval              0.104217276
total_rewards                [9658.85056241 8384.69687762 9658.45727889 9857.11345035 9822.15418681
 9992.98466659 9448.23603542 9723.75927926 9678.1243849  4806.46622039]
total_rewards_mean           9103.08429426427
total_rewards_std            1493.5496332065795
total_rewards_max            9992.98466658966
total_rewards_min            4806.4662203896605
Number of train steps total  1076000
Number of env steps total    3230000
Number of rollouts total     0
Train Time (s)               146.45349782239646
(Previous) Eval Time (s)     17.568248297087848
Sample Time (s)              6.399309926666319
Epoch Time (s)               170.42105604615062
Total Train Time (s)         45890.27335677389
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:38:29.284538 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #268 | Epoch Duration: 170.50232911109924
2020-01-12 20:38:29.284662 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7536707
Z variance train             0.104101166
KL Divergence                43.182846
KL Loss                      4.3182845
QF Loss                      173.51886
VF Loss                      121.20978
Policy Loss                  -1255.8507
Q Predictions Mean           1252.2139
Q Predictions Std            1268.9392
Q Predictions Max            4420.8623
Q Predictions Min            601.2195
V Predictions Mean           1249.9639
V Predictions Std            1260.8335
V Predictions Max            4384.191
V Predictions Min            600.04224
Log Pis Mean                 -0.22825804
Log Pis Std                  3.6361682
Log Pis Max                  15.240686
Log Pis Min                  -6.6483135
Policy mu Mean               0.019539187
Policy mu Std                0.8696629
Policy mu Max                3.1137211
Policy mu Min                -2.821637
Policy log std Mean          -0.5409538
Policy log std Std           0.29847503
Policy log std Max           0.10710096
Policy log std Min           -2.8368092
Z mean eval                  1.7342281
Z variance eval              0.12573054
total_rewards                [9540.67324403 9656.16208556 9788.00592088 9933.9485191  9717.08214636
 9770.28226797 9683.38190284 9562.14080572 9775.18004461 9727.91676694]
total_rewards_mean           9715.477370402125
total_rewards_std            108.78066931246433
total_rewards_max            9933.948519101346
total_rewards_min            9540.67324403384
Number of train steps total  1080000
Number of env steps total    3242000
Number of rollouts total     0
Train Time (s)               148.75103180482984
(Previous) Eval Time (s)     17.32146666571498
Sample Time (s)              5.594295365270227
Epoch Time (s)               171.66679383581504
Total Train Time (s)         46062.01820778148
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:41:21.032517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #269 | Epoch Duration: 171.74774074554443
2020-01-12 20:41:21.032701 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.734925
Z variance train             0.12511994
KL Divergence                40.980484
KL Loss                      4.0980487
QF Loss                      3307.3552
VF Loss                      55.60722
Policy Loss                  -1208.0804
Q Predictions Mean           1206.3738
Q Predictions Std            1205.2891
Q Predictions Max            4292.719
Q Predictions Min            577.8253
V Predictions Mean           1208.6997
V Predictions Std            1200.2239
V Predictions Max            4295.9604
V Predictions Min            586.86945
Log Pis Mean                 -0.5608056
Log Pis Std                  3.4237473
Log Pis Max                  10.542607
Log Pis Min                  -6.4412975
Policy mu Mean               0.068316646
Policy mu Std                0.82910055
Policy mu Max                2.6098995
Policy mu Min                -2.9539247
Policy log std Mean          -0.5160478
Policy log std Std           0.2799233
Policy log std Max           0.114674926
Policy log std Min           -2.5811617
Z mean eval                  1.7548397
Z variance eval              0.08945949
total_rewards                [9482.031321   9487.31077299 9736.73351149 9708.85297019 9490.92930187
 9512.8964819  9600.81628189 9768.73201264 9599.84273855 9618.40251606]
total_rewards_mean           9600.654790858329
total_rewards_std            102.68859804006739
total_rewards_max            9768.732012641207
total_rewards_min            9482.031321004146
Number of train steps total  1084000
Number of env steps total    3254000
Number of rollouts total     0
Train Time (s)               146.60268000885844
(Previous) Eval Time (s)     17.56419771630317
Sample Time (s)              6.462789782322943
Epoch Time (s)               170.62966750748456
Total Train Time (s)         46232.73623618344
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:44:11.754794 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #270 | Epoch Duration: 170.72193717956543
2020-01-12 20:44:11.755028 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7555453
Z variance train             0.08920672
KL Divergence                42.32183
KL Loss                      4.232183
QF Loss                      92.76051
VF Loss                      49.591805
Policy Loss                  -1277.0006
Q Predictions Mean           1276.3308
Q Predictions Std            1281.9404
Q Predictions Max            4400.368
Q Predictions Min            590.3804
V Predictions Mean           1275.7125
V Predictions Std            1275.9762
V Predictions Max            4385.7754
V Predictions Min            593.8369
Log Pis Mean                 -0.11393137
Log Pis Std                  3.4208694
Log Pis Max                  11.889294
Log Pis Min                  -6.542387
Policy mu Mean               0.055158526
Policy mu Std                0.8782008
Policy mu Max                2.682156
Policy mu Min                -2.535752
Policy log std Mean          -0.5436446
Policy log std Std           0.2832663
Policy log std Max           -0.020268738
Policy log std Min           -2.3069928
Z mean eval                  1.7443607
Z variance eval              0.08621048
total_rewards                [9031.98208478 5678.63847641 9170.99171008 9327.15738919 2732.51589279
 8459.21521694 9504.43467068 3694.13234766 9017.40115312 2438.14279284]
total_rewards_mean           6905.461173449983
total_rewards_std            2798.867097438392
total_rewards_max            9504.434670682898
total_rewards_min            2438.1427928446724
Number of train steps total  1088000
Number of env steps total    3266000
Number of rollouts total     0
Train Time (s)               147.19228057935834
(Previous) Eval Time (s)     17.32895897794515
Sample Time (s)              6.598547065164894
Epoch Time (s)               171.11978662246838
Total Train Time (s)         46403.93567018304
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:47:02.956403 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #271 | Epoch Duration: 171.20120930671692
2020-01-12 20:47:02.956581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7444131
Z variance train             0.085782126
KL Divergence                42.383575
KL Loss                      4.2383575
QF Loss                      180.43394
VF Loss                      81.07958
Policy Loss                  -1219.5262
Q Predictions Mean           1214.7198
Q Predictions Std            1239.7426
Q Predictions Max            4440.586
Q Predictions Min            586.17816
V Predictions Mean           1222.5881
V Predictions Std            1242.797
V Predictions Max            4459.6006
V Predictions Min            597.1973
Log Pis Mean                 -0.437898
Log Pis Std                  3.2550666
Log Pis Max                  11.165357
Log Pis Min                  -6.9576464
Policy mu Mean               0.05111481
Policy mu Std                0.8577328
Policy mu Max                3.459533
Policy mu Min                -2.8054976
Policy log std Mean          -0.52078146
Policy log std Std           0.28934747
Policy log std Max           0.11424762
Policy log std Min           -2.6555288
Z mean eval                  1.7374609
Z variance eval              0.071178116
total_rewards                [8346.9289355  8825.10455415 9442.28414192 8671.70726048 9373.76835071
 9450.36538038 9066.13371641 9307.82733755 9187.76668575 8940.24567317]
total_rewards_mean           9061.213203601312
total_rewards_std            346.9151274033055
total_rewards_max            9450.365380378673
total_rewards_min            8346.928935497464
Number of train steps total  1092000
Number of env steps total    3278000
Number of rollouts total     0
Train Time (s)               147.28848968073726
(Previous) Eval Time (s)     20.461997426114976
Sample Time (s)              6.637129923328757
Epoch Time (s)               174.387617030181
Total Train Time (s)         46578.40435325494
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:49:57.425969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #272 | Epoch Duration: 174.4692575931549
2020-01-12 20:49:57.426112 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7378273
Z variance train             0.07116778
KL Divergence                41.750343
KL Loss                      4.1750345
QF Loss                      3389.3552
VF Loss                      105.16761
Policy Loss                  -1311.3065
Q Predictions Mean           1312.6985
Q Predictions Std            1323.4949
Q Predictions Max            4330.1636
Q Predictions Min            512.96606
V Predictions Mean           1310.274
V Predictions Std            1316.8094
V Predictions Max            4315.374
V Predictions Min            549.35547
Log Pis Mean                 -0.07276502
Log Pis Std                  3.8851311
Log Pis Max                  12.640143
Log Pis Min                  -6.412588
Policy mu Mean               0.034809023
Policy mu Std                0.8857936
Policy mu Max                2.7590334
Policy mu Min                -2.4972398
Policy log std Mean          -0.5288662
Policy log std Std           0.29222944
Policy log std Max           0.05652827
Policy log std Min           -2.9337573
Z mean eval                  1.7335932
Z variance eval              0.09292992
total_rewards                [9295.81588268 9663.92786682 1853.74511099 9629.3875523  9574.30691754
 9688.14170932 9530.02228108 9299.00275534 9720.62159426 9630.18966046]
total_rewards_mean           8788.516133079927
total_rewards_std            2315.950535370803
total_rewards_max            9720.62159426111
total_rewards_min            1853.745110990957
Number of train steps total  1096000
Number of env steps total    3290000
Number of rollouts total     0
Train Time (s)               146.4547862401232
(Previous) Eval Time (s)     17.443616937845945
Sample Time (s)              6.422807740047574
Epoch Time (s)               170.32121091801673
Total Train Time (s)         46748.80904034758
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:52:47.837128 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #273 | Epoch Duration: 170.4108967781067
2020-01-12 20:52:47.837342 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7349608
Z variance train             0.0930696
KL Divergence                40.347538
KL Loss                      4.034754
QF Loss                      3335.855
VF Loss                      70.39378
Policy Loss                  -1384.7418
Q Predictions Mean           1385.7225
Q Predictions Std            1366.226
Q Predictions Max            4327.263
Q Predictions Min            585.34436
V Predictions Mean           1387.7263
V Predictions Std            1367.7933
V Predictions Max            4311.309
V Predictions Min            574.4044
Log Pis Mean                 -0.0141959265
Log Pis Std                  3.8340762
Log Pis Max                  13.839698
Log Pis Min                  -7.0351276
Policy mu Mean               0.027492968
Policy mu Std                0.88298273
Policy mu Max                2.4742856
Policy mu Min                -3.0555267
Policy log std Mean          -0.54370934
Policy log std Std           0.29239687
Policy log std Max           0.045506477
Policy log std Min           -2.806665
Z mean eval                  1.7576834
Z variance eval              0.071939364
total_rewards                [9185.53642366 9457.71836456 9543.66976431 6782.42140256 9379.53242635
 9741.23716456 9466.97250379 9609.91658317 9396.80923962 9585.30247177]
total_rewards_mean           9214.911634436756
total_rewards_std            823.3387467309844
total_rewards_max            9741.237164562492
total_rewards_min            6782.421402556816
Number of train steps total  1100000
Number of env steps total    3302000
Number of rollouts total     0
Train Time (s)               145.70883277710527
(Previous) Eval Time (s)     20.83021711418405
Sample Time (s)              6.5475135035812855
Epoch Time (s)               173.0865633948706
Total Train Time (s)         46921.98192926776
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:55:41.010111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #274 | Epoch Duration: 173.1726200580597
2020-01-12 20:55:41.010240 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7586253
Z variance train             0.07215244
KL Divergence                41.39457
KL Loss                      4.139457
QF Loss                      210.7392
VF Loss                      120.94069
Policy Loss                  -1248.6448
Q Predictions Mean           1245.3901
Q Predictions Std            1267.8595
Q Predictions Max            4345.2363
Q Predictions Min            596.62494
V Predictions Mean           1239.5889
V Predictions Std            1262.9565
V Predictions Max            4302.739
V Predictions Min            593.71545
Log Pis Mean                 -0.1491435
Log Pis Std                  3.8912091
Log Pis Max                  13.694525
Log Pis Min                  -8.179174
Policy mu Mean               0.047808483
Policy mu Std                0.90989345
Policy mu Max                3.115144
Policy mu Min                -2.7271748
Policy log std Mean          -0.53578913
Policy log std Std           0.29092962
Policy log std Max           0.2172997
Policy log std Min           -2.8345075
Z mean eval                  1.7425239
Z variance eval              0.06898398
total_rewards                [9460.55912926 9741.40318782 9724.40992924 9629.06322863 9996.45626637
 9908.08297124 9246.67077599 9527.22045183 9870.94551327 9686.4530979 ]
total_rewards_mean           9679.126455155085
total_rewards_std            213.60427463751532
total_rewards_max            9996.456266368465
total_rewards_min            9246.670775989794
Number of train steps total  1104000
Number of env steps total    3314000
Number of rollouts total     0
Train Time (s)               147.76809813501313
(Previous) Eval Time (s)     21.285306555684656
Sample Time (s)              6.407560394145548
Epoch Time (s)               175.46096508484334
Total Train Time (s)         47097.522965267766
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:58:36.553663 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #275 | Epoch Duration: 175.54332661628723
2020-01-12 20:58:36.553801 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7432768
Z variance train             0.069136225
KL Divergence                42.574093
KL Loss                      4.2574096
QF Loss                      144.89163
VF Loss                      99.689316
Policy Loss                  -1250.899
Q Predictions Mean           1247.3203
Q Predictions Std            1266.6183
Q Predictions Max            4349.0796
Q Predictions Min            574.6034
V Predictions Mean           1244.5433
V Predictions Std            1262.4752
V Predictions Max            4330.9907
V Predictions Min            573.58636
Log Pis Mean                 -0.31666213
Log Pis Std                  3.853306
Log Pis Max                  17.190506
Log Pis Min                  -6.8929353
Policy mu Mean               0.062362194
Policy mu Std                0.8660175
Policy mu Max                3.1714425
Policy mu Min                -3.5257285
Policy log std Mean          -0.5154569
Policy log std Std           0.27587366
Policy log std Max           0.11025846
Policy log std Min           -2.5508661
Z mean eval                  1.7648163
Z variance eval              0.078547604
total_rewards                [9069.72196686 7224.20710826 9450.95950634 9375.41940055 9446.15247182
 9367.92043175 9284.56373064 9437.73788319 9460.88036039 9360.32015523]
total_rewards_mean           9147.788301503802
total_rewards_std            650.6490369876992
total_rewards_max            9460.880360392268
total_rewards_min            7224.20710825721
Number of train steps total  1108000
Number of env steps total    3326000
Number of rollouts total     0
Train Time (s)               146.99340754002333
(Previous) Eval Time (s)     19.884230616968125
Sample Time (s)              6.556339040398598
Epoch Time (s)               173.43397719739005
Total Train Time (s)         47271.04510283237
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:01:30.082129 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #276 | Epoch Duration: 173.5282051563263
2020-01-12 21:01:30.082303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.764679
Z variance train             0.07856524
KL Divergence                43.226593
KL Loss                      4.3226595
QF Loss                      102.647484
VF Loss                      49.501194
Policy Loss                  -991.0964
Q Predictions Mean           987.2644
Q Predictions Std            974.0554
Q Predictions Max            4403.011
Q Predictions Min            581.80426
V Predictions Mean           988.02167
V Predictions Std            971.1892
V Predictions Max            4385.987
V Predictions Min            573.72174
Log Pis Mean                 -0.75669634
Log Pis Std                  3.3660727
Log Pis Max                  18.61289
Log Pis Min                  -8.731966
Policy mu Mean               0.06812299
Policy mu Std                0.80612123
Policy mu Max                3.753063
Policy mu Min                -4.0298357
Policy log std Mean          -0.49651837
Policy log std Std           0.26400617
Policy log std Max           -0.055824563
Policy log std Min           -2.8486624
Z mean eval                  1.740016
Z variance eval              0.09686902
total_rewards                [9337.48182007 9459.64236705 9597.34835195 9444.67462635 9667.13708007
 9612.79216978 9484.06077501 9840.65399692 9689.94141777 9632.05697035]
total_rewards_mean           9576.578957530524
total_rewards_std            138.71120927563527
total_rewards_max            9840.653996919851
total_rewards_min            9337.481820071558
Number of train steps total  1112000
Number of env steps total    3338000
Number of rollouts total     0
Train Time (s)               147.48841155134141
(Previous) Eval Time (s)     20.857713548932225
Sample Time (s)              6.50327519653365
Epoch Time (s)               174.8494002968073
Total Train Time (s)         47445.99035245087
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:04:25.030036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #277 | Epoch Duration: 174.94760537147522
2020-01-12 21:04:25.030172 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7434896
Z variance train             0.09696863
KL Divergence                41.819405
KL Loss                      4.1819406
QF Loss                      3259.271
VF Loss                      123.110275
Policy Loss                  -1240.5762
Q Predictions Mean           1237.8848
Q Predictions Std            1264.3225
Q Predictions Max            4427.5376
Q Predictions Min            591.54236
V Predictions Mean           1237.1461
V Predictions Std            1266.8448
V Predictions Max            4457.8115
V Predictions Min            583.13
Log Pis Mean                 -0.49892074
Log Pis Std                  3.5097435
Log Pis Max                  17.804604
Log Pis Min                  -7.1039195
Policy mu Mean               0.0116665
Policy mu Std                0.82776767
Policy mu Max                2.7733347
Policy mu Min                -3.5363154
Policy log std Mean          -0.5052878
Policy log std Std           0.27190188
Policy log std Max           -0.023944348
Policy log std Min           -2.4260182
Z mean eval                  1.7616742
Z variance eval              0.093697146
total_rewards                [9501.08920455 9591.35804991 9725.86415631 9681.82342503 9707.37959607
 9652.53565263 9608.08521344 9607.17007972 9534.95824684 9611.74894159]
total_rewards_mean           9622.20125661053
total_rewards_std            68.001139687494
total_rewards_max            9725.864156314981
total_rewards_min            9501.089204552223
Number of train steps total  1116000
Number of env steps total    3350000
Number of rollouts total     0
Train Time (s)               145.7023400021717
(Previous) Eval Time (s)     17.358841136097908
Sample Time (s)              6.540822580456734
Epoch Time (s)               169.60200371872634
Total Train Time (s)         47615.67494026944
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:07:14.722530 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #278 | Epoch Duration: 169.6922447681427
2020-01-12 21:07:14.722748 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7637131
Z variance train             0.09373473
KL Divergence                43.673252
KL Loss                      4.3673253
QF Loss                      85.556015
VF Loss                      39.27642
Policy Loss                  -1147.2986
Q Predictions Mean           1143.6907
Q Predictions Std            1155.2415
Q Predictions Max            4362.751
Q Predictions Min            587.3572
V Predictions Mean           1146.2986
V Predictions Std            1153.4796
V Predictions Max            4364.107
V Predictions Min            592.6431
Log Pis Mean                 -0.7190977
Log Pis Std                  3.5888562
Log Pis Max                  23.169933
Log Pis Min                  -6.155051
Policy mu Mean               0.014476043
Policy mu Std                0.8332003
Policy mu Max                4.140258
Policy mu Min                -3.460829
Policy log std Mean          -0.49355236
Policy log std Std           0.2804568
Policy log std Max           0.40330547
Policy log std Min           -2.2532296
Z mean eval                  1.7730224
Z variance eval              0.11972387
total_rewards                [9705.95421544 9645.42182052 9832.42020263 9896.81045353 9948.52727022
 9786.97817433 9906.6341873  9823.97398633 9769.11802533 9812.83329363]
total_rewards_mean           9812.86716292633
total_rewards_std            87.63596718530383
total_rewards_max            9948.527270215978
total_rewards_min            9645.421820524636
Number of train steps total  1120000
Number of env steps total    3362000
Number of rollouts total     0
Train Time (s)               145.88070540875196
(Previous) Eval Time (s)     20.724658160004765
Sample Time (s)              5.653849940747023
Epoch Time (s)               172.25921350950375
Total Train Time (s)         47788.01965285046
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:10:07.064601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #279 | Epoch Duration: 172.3417193889618
2020-01-12 21:10:07.064747 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7749875
Z variance train             0.11954923
KL Divergence                42.854637
KL Loss                      4.285464
QF Loss                      88.41647
VF Loss                      51.865326
Policy Loss                  -1262.2653
Q Predictions Mean           1259.6322
Q Predictions Std            1220.8245
Q Predictions Max            4431.6577
Q Predictions Min            602.4041
V Predictions Mean           1261.9612
V Predictions Std            1216.4175
V Predictions Max            4425.497
V Predictions Min            608.3096
Log Pis Mean                 -0.15354186
Log Pis Std                  4.1109533
Log Pis Max                  16.408554
Log Pis Min                  -8.559284
Policy mu Mean               0.058541086
Policy mu Std                0.87691885
Policy mu Max                2.9466443
Policy mu Min                -3.296139
Policy log std Mean          -0.52103764
Policy log std Std           0.28373384
Policy log std Max           0.039352298
Policy log std Min           -2.7925138
Z mean eval                  1.8014818
Z variance eval              0.07060844
total_rewards                [6513.99871498 6193.8134067  5686.04132414 4793.67195519 6438.65418359
 2073.49520946 7130.25785176 6611.32506525 7623.1469935  6357.64446678]
total_rewards_mean           5942.204917134713
total_rewards_std            1478.030014525223
total_rewards_max            7623.146993500513
total_rewards_min            2073.495209456037
Number of train steps total  1124000
Number of env steps total    3374000
Number of rollouts total     0
Train Time (s)               145.72794235078618
(Previous) Eval Time (s)     20.987641382031143
Sample Time (s)              8.109821412712336
Epoch Time (s)               174.82540514552966
Total Train Time (s)         47962.93135652132
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:13:01.978755 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #280 | Epoch Duration: 174.91390919685364
2020-01-12 21:13:01.978934 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8023672
Z variance train             0.07044431
KL Divergence                44.032
KL Loss                      4.4032
QF Loss                      3550.4016
VF Loss                      52.10685
Policy Loss                  -1318.946
Q Predictions Mean           1317.3202
Q Predictions Std            1302.7037
Q Predictions Max            4339.474
Q Predictions Min            589.56995
V Predictions Mean           1319.641
V Predictions Std            1299.5764
V Predictions Max            4334.733
V Predictions Min            602.37213
Log Pis Mean                 -0.37042367
Log Pis Std                  3.7248483
Log Pis Max                  17.331356
Log Pis Min                  -7.924635
Policy mu Mean               0.073993154
Policy mu Std                0.85528684
Policy mu Max                2.738887
Policy mu Min                -2.775319
Policy log std Mean          -0.52084285
Policy log std Std           0.29186237
Policy log std Max           0.122879624
Policy log std Min           -2.7148266
Z mean eval                  1.7584461
Z variance eval              0.07197299
total_rewards                [9654.13997413 9597.46862019 9888.61269431 9674.33487321 9591.61994637
 9774.55938802 9730.97431618 9801.56598737 9443.76450099 9621.27783347]
total_rewards_mean           9677.831813422075
total_rewards_std            120.1537327422073
total_rewards_max            9888.612694305448
total_rewards_min            9443.7645009913
Number of train steps total  1128000
Number of env steps total    3386000
Number of rollouts total     0
Train Time (s)               145.62832851102576
(Previous) Eval Time (s)     20.688161376863718
Sample Time (s)              6.406944481655955
Epoch Time (s)               172.72343436954543
Total Train Time (s)         48135.73978115199
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:15:54.789206 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #281 | Epoch Duration: 172.81012892723083
2020-01-12 21:15:54.789342 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7626944
Z variance train             0.0721272
KL Divergence                44.05497
KL Loss                      4.405497
QF Loss                      247.41498
VF Loss                      60.52787
Policy Loss                  -1328.0951
Q Predictions Mean           1325.3875
Q Predictions Std            1328.5789
Q Predictions Max            4449.159
Q Predictions Min            609.0485
V Predictions Mean           1325.9556
V Predictions Std            1325.0255
V Predictions Max            4451.638
V Predictions Min            615.00256
Log Pis Mean                 -0.055399675
Log Pis Std                  4.1445045
Log Pis Max                  16.589645
Log Pis Min                  -8.800672
Policy mu Mean               0.070227385
Policy mu Std                0.8859241
Policy mu Max                2.898926
Policy mu Min                -2.7161813
Policy log std Mean          -0.522006
Policy log std Std           0.27372086
Policy log std Max           -0.00424999
Policy log std Min           -2.5997868
Z mean eval                  1.7666109
Z variance eval              0.054257948
total_rewards                [8918.09642975 8928.5050782  8511.20000228 8834.3183625  8609.80192502
 8899.7851917  8719.71955833 8924.78093199 9159.5352537  8644.97001007]
total_rewards_mean           8815.071274354039
total_rewards_std            182.8167378462688
total_rewards_max            9159.535253697355
total_rewards_min            8511.200002278913
Number of train steps total  1132000
Number of env steps total    3398000
Number of rollouts total     0
Train Time (s)               147.3115260968916
(Previous) Eval Time (s)     20.93802823824808
Sample Time (s)              6.588734094519168
Epoch Time (s)               174.83828842965886
Total Train Time (s)         48310.65869535785
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:18:49.711083 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #282 | Epoch Duration: 174.92163515090942
2020-01-12 21:18:49.711249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7642615
Z variance train             0.054446053
KL Divergence                44.91707
KL Loss                      4.491707
QF Loss                      4088.074
VF Loss                      151.99626
Policy Loss                  -1346.1993
Q Predictions Mean           1345.9451
Q Predictions Std            1306.4268
Q Predictions Max            4420.859
Q Predictions Min            600.61816
V Predictions Mean           1351.687
V Predictions Std            1308.657
V Predictions Max            4405.1826
V Predictions Min            593.60815
Log Pis Mean                 0.119096756
Log Pis Std                  3.9447012
Log Pis Max                  15.071226
Log Pis Min                  -8.321809
Policy mu Mean               0.014877605
Policy mu Std                0.9146304
Policy mu Max                2.8977776
Policy mu Min                -2.7641842
Policy log std Mean          -0.52999157
Policy log std Std           0.29831666
Policy log std Max           0.23874247
Policy log std Min           -3.0155551
Z mean eval                  1.7678697
Z variance eval              0.06463901
total_rewards                [9475.96979313 9525.60448614 9901.90048161 9438.9898158  9589.21370132
 9525.85808696 9434.13544797 9657.89637641 9492.82555276 9717.1570933 ]
total_rewards_mean           9575.955083538893
total_rewards_std            139.24558844531285
total_rewards_max            9901.900481609688
total_rewards_min            9434.13544796952
Number of train steps total  1136000
Number of env steps total    3410000
Number of rollouts total     0
Train Time (s)               146.2355166929774
(Previous) Eval Time (s)     20.765631312970072
Sample Time (s)              5.563776773400605
Epoch Time (s)               172.56492477934808
Total Train Time (s)         48483.3029702208
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:21:42.357039 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #283 | Epoch Duration: 172.6456708908081
2020-01-12 21:21:42.357178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7714062
Z variance train             0.064855866
KL Divergence                44.592495
KL Loss                      4.4592495
QF Loss                      3598.9727
VF Loss                      96.67319
Policy Loss                  -1129.9913
Q Predictions Mean           1129.1694
Q Predictions Std            1115.6249
Q Predictions Max            4436.5986
Q Predictions Min            616.14453
V Predictions Mean           1125.8691
V Predictions Std            1109.8324
V Predictions Max            4412.624
V Predictions Min            603.9428
Log Pis Mean                 -0.5145312
Log Pis Std                  3.722901
Log Pis Max                  14.725639
Log Pis Min                  -7.173586
Policy mu Mean               0.05870053
Policy mu Std                0.8501726
Policy mu Max                3.0648584
Policy mu Min                -3.2112489
Policy log std Mean          -0.51183486
Policy log std Std           0.26213416
Policy log std Max           0.3311466
Policy log std Min           -2.7444596
Z mean eval                  1.7715778
Z variance eval              0.04864805
total_rewards                [9677.34949292 9866.20869133 9645.45035518 9786.88092109 9850.11077002
 9890.12219275 9676.35476697 9645.75229583 9558.11991468 9753.35003798]
total_rewards_mean           9734.969943874605
total_rewards_std            105.63671240066257
total_rewards_max            9890.122192751733
total_rewards_min            9558.119914677594
Number of train steps total  1140000
Number of env steps total    3422000
Number of rollouts total     0
Train Time (s)               147.28355960501358
(Previous) Eval Time (s)     20.831867817789316
Sample Time (s)              6.565144828520715
Epoch Time (s)               174.6805722513236
Total Train Time (s)         48658.06526054256
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:24:37.121258 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #284 | Epoch Duration: 174.76397323608398
2020-01-12 21:24:37.121390 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #284 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.77222
Z variance train             0.04864514
KL Divergence                45.65871
KL Loss                      4.5658712
QF Loss                      160.55875
VF Loss                      43.305023
Policy Loss                  -1109.3389
Q Predictions Mean           1107.4421
Q Predictions Std            1093.0526
Q Predictions Max            4326.0356
Q Predictions Min            606.48004
V Predictions Mean           1110.5592
V Predictions Std            1090.9778
V Predictions Max            4330.8545
V Predictions Min            611.93774
Log Pis Mean                 -0.30848944
Log Pis Std                  3.483263
Log Pis Max                  14.445216
Log Pis Min                  -6.25606
Policy mu Mean               0.032727662
Policy mu Std                0.8557903
Policy mu Max                2.699662
Policy mu Min                -2.9699984
Policy log std Mean          -0.50108755
Policy log std Std           0.2863527
Policy log std Max           0.40628546
Policy log std Min           -2.467825
Z mean eval                  1.765186
Z variance eval              0.048910514
total_rewards                [ 9976.36875733 10033.68669601 10025.64139399  9873.41960684
  6199.61143162  9983.23698398  9779.32648179  9612.06744385
  9324.76183595  9802.72775488]
total_rewards_mean           9461.084838622957
total_rewards_std            1106.8587737619903
total_rewards_max            10033.686696011615
total_rewards_min            6199.611431621401
Number of train steps total  1144000
Number of env steps total    3434000
Number of rollouts total     0
Train Time (s)               145.21202384121716
(Previous) Eval Time (s)     17.33502593776211
Sample Time (s)              6.528730419464409
Epoch Time (s)               169.07578019844368
Total Train Time (s)         48827.24020955432
Epoch                        285
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:27:26.303886 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #285 | Epoch Duration: 169.1823799610138
2020-01-12 21:27:26.304078 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7622572
Z variance train             0.048784588
KL Divergence                45.844143
KL Loss                      4.5844145
QF Loss                      112.27789
VF Loss                      223.67195
Policy Loss                  -1208.9602
Q Predictions Mean           1205.3232
Q Predictions Std            1186.396
Q Predictions Max            4348.881
Q Predictions Min            596.5533
V Predictions Mean           1198.977
V Predictions Std            1177.9926
V Predictions Max            4321.607
V Predictions Min            597.61865
Log Pis Mean                 -0.24998365
Log Pis Std                  3.778379
Log Pis Max                  18.347244
Log Pis Min                  -7.0559664
Policy mu Mean               0.046843484
Policy mu Std                0.87995225
Policy mu Max                3.374902
Policy mu Min                -2.6832795
Policy log std Mean          -0.52085525
Policy log std Std           0.28213495
Policy log std Max           0.10611987
Policy log std Min           -2.6348512
Z mean eval                  1.7837347
Z variance eval              0.04696402
total_rewards                [9559.91831182 9750.7852991  9708.60742148 9675.90519765 9786.23321677
 9603.21163466 9780.73639334 9833.3813574  9967.05721939 9949.6834471 ]
total_rewards_mean           9761.55194987138
total_rewards_std            126.39016459935154
total_rewards_max            9967.057219386854
total_rewards_min            9559.91831182262
Number of train steps total  1148000
Number of env steps total    3446000
Number of rollouts total     0
Train Time (s)               146.74777188804
(Previous) Eval Time (s)     17.25803456408903
Sample Time (s)              6.728774580638856
Epoch Time (s)               170.7345810327679
Total Train Time (s)         48998.062092122156
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:30:17.129713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #286 | Epoch Duration: 170.82545948028564
2020-01-12 21:30:17.129966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7828429
Z variance train             0.04706251
KL Divergence                47.168083
KL Loss                      4.7168083
QF Loss                      81.71923
VF Loss                      128.98077
Policy Loss                  -1289.9343
Q Predictions Mean           1288.4451
Q Predictions Std            1294.9152
Q Predictions Max            4432.225
Q Predictions Min            611.50275
V Predictions Mean           1292.9072
V Predictions Std            1296.7457
V Predictions Max            4414.4053
V Predictions Min            614.8895
Log Pis Mean                 -0.19826289
Log Pis Std                  3.9690928
Log Pis Max                  17.394192
Log Pis Min                  -6.6879907
Policy mu Mean               0.025852038
Policy mu Std                0.9019686
Policy mu Max                4.157739
Policy mu Min                -3.3095105
Policy log std Mean          -0.50180846
Policy log std Std           0.2830132
Policy log std Max           0.11397582
Policy log std Min           -2.6340885
Z mean eval                  1.7834523
Z variance eval              0.080649205
total_rewards                [10038.43382557  9834.84920853  9718.31687299  9445.30319938
  9636.91758422  9862.21348337  9740.05315127  9821.09091973
  9690.69839463  9895.70993014]
total_rewards_mean           9768.358656982131
total_rewards_std            153.67089487656648
total_rewards_max            10038.433825567823
total_rewards_min            9445.303199381227
Number of train steps total  1152000
Number of env steps total    3458000
Number of rollouts total     0
Train Time (s)               145.94240709301084
(Previous) Eval Time (s)     20.752828030847013
Sample Time (s)              6.5417518159374595
Epoch Time (s)               173.23698693979532
Total Train Time (s)         49171.381984169595
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:33:10.452389 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #287 | Epoch Duration: 173.32223844528198
2020-01-12 21:33:10.452584 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7859339
Z variance train             0.08038323
KL Divergence                46.030704
KL Loss                      4.6030707
QF Loss                      223.4495
VF Loss                      87.21871
Policy Loss                  -1275.6323
Q Predictions Mean           1273.5724
Q Predictions Std            1267.5414
Q Predictions Max            4402.998
Q Predictions Min            589.1068
V Predictions Mean           1277.4221
V Predictions Std            1266.1124
V Predictions Max            4413.3193
V Predictions Min            605.16956
Log Pis Mean                 -0.016786769
Log Pis Std                  4.2181835
Log Pis Max                  18.101841
Log Pis Min                  -7.477542
Policy mu Mean               0.07887435
Policy mu Std                0.8975007
Policy mu Max                3.2666254
Policy mu Min                -3.862086
Policy log std Mean          -0.52366203
Policy log std Std           0.30712003
Policy log std Max           0.24035239
Policy log std Min           -2.680142
Z mean eval                  1.7888119
Z variance eval              0.051549245
total_rewards                [9113.10130568 9768.55830449 3424.9632535  9965.59130853 9845.86637841
 9959.21691486 9944.5505399  9892.12633573 9555.14061522 9780.76193749]
total_rewards_mean           9124.98768937937
total_rewards_std            1915.778648345489
total_rewards_max            9965.591308526822
total_rewards_min            3424.9632535023907
Number of train steps total  1156000
Number of env steps total    3470000
Number of rollouts total     0
Train Time (s)               146.60124074714258
(Previous) Eval Time (s)     20.741818635258824
Sample Time (s)              6.524375143460929
Epoch Time (s)               173.86743452586234
Total Train Time (s)         49345.35535021592
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:36:04.425710 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #288 | Epoch Duration: 173.97299003601074
2020-01-12 21:36:04.425842 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7889764
Z variance train             0.051645886
KL Divergence                44.99638
KL Loss                      4.499638
QF Loss                      172.45413
VF Loss                      51.29037
Policy Loss                  -1360.8175
Q Predictions Mean           1359.7686
Q Predictions Std            1313.137
Q Predictions Max            4403.669
Q Predictions Min            601.1051
V Predictions Mean           1361.5461
V Predictions Std            1308.9231
V Predictions Max            4394.091
V Predictions Min            614.53076
Log Pis Mean                 -0.07416597
Log Pis Std                  3.712958
Log Pis Max                  12.903284
Log Pis Min                  -7.147926
Policy mu Mean               -0.03956072
Policy mu Std                0.88219905
Policy mu Max                2.7929633
Policy mu Min                -2.8367774
Policy log std Mean          -0.52693516
Policy log std Std           0.29014197
Policy log std Max           -9.119511e-05
Policy log std Min           -2.562913
Z mean eval                  1.8058903
Z variance eval              0.049370836
total_rewards                [9629.14162397 9793.22729356 9739.793613   9710.58672933 9205.28387522
 9361.64200311 9607.8951544  9653.84108193 9194.61140406 4621.83717445]
total_rewards_mean           9051.785995302915
total_rewards_std            1490.8585892528051
total_rewards_max            9793.227293557875
total_rewards_min            4621.837174452128
Number of train steps total  1160000
Number of env steps total    3482000
Number of rollouts total     0
Train Time (s)               146.81170956976712
(Previous) Eval Time (s)     20.86482169525698
Sample Time (s)              6.461506320163608
Epoch Time (s)               174.1380375851877
Total Train Time (s)         49519.57362927217
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:38:58.646044 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #289 | Epoch Duration: 174.2201051712036
2020-01-12 21:38:58.646174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8089777
Z variance train             0.048916142
KL Divergence                44.82688
KL Loss                      4.4826884
QF Loss                      131.16002
VF Loss                      112.154854
Policy Loss                  -1315.4913
Q Predictions Mean           1311.9846
Q Predictions Std            1297.9377
Q Predictions Max            4377.295
Q Predictions Min            599.44147
V Predictions Mean           1309.0381
V Predictions Std            1294.9409
V Predictions Max            4367.3135
V Predictions Min            602.0426
Log Pis Mean                 -0.24224955
Log Pis Std                  3.664795
Log Pis Max                  14.304645
Log Pis Min                  -6.1282697
Policy mu Mean               0.07317506
Policy mu Std                0.89600873
Policy mu Max                3.405333
Policy mu Min                -3.5420778
Policy log std Mean          -0.5114183
Policy log std Std           0.2852239
Policy log std Max           0.4066491
Policy log std Min           -2.4759617
Z mean eval                  1.7758442
Z variance eval              0.0701207
total_rewards                [9409.47094207 9457.98498487 9761.30274891 9364.4955835  9189.94982685
 9620.08599778 9564.04062573 9881.39781033 9683.68436247 9212.94416772]
total_rewards_mean           9514.535705024306
total_rewards_std            216.96698416149184
total_rewards_max            9881.397810329128
total_rewards_min            9189.949826850107
Number of train steps total  1164000
Number of env steps total    3494000
Number of rollouts total     0
Train Time (s)               145.8233518130146
(Previous) Eval Time (s)     20.80260653188452
Sample Time (s)              6.556597809307277
Epoch Time (s)               173.1825561542064
Total Train Time (s)         49692.83144956082
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:41:51.905988 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #290 | Epoch Duration: 173.25971865653992
2020-01-12 21:41:51.906117 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #290 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7741699
Z variance train             0.07043089
KL Divergence                45.463696
KL Loss                      4.5463696
QF Loss                      3643.0894
VF Loss                      49.178093
Policy Loss                  -1248.7518
Q Predictions Mean           1246.2487
Q Predictions Std            1227.3931
Q Predictions Max            4412.7046
Q Predictions Min            600.29584
V Predictions Mean           1250.2203
V Predictions Std            1224.3274
V Predictions Max            4416.487
V Predictions Min            616.2984
Log Pis Mean                 -0.37017053
Log Pis Std                  3.7967205
Log Pis Max                  15.96657
Log Pis Min                  -6.444874
Policy mu Mean               0.017505998
Policy mu Std                0.8597905
Policy mu Max                2.8887997
Policy mu Min                -3.0238023
Policy log std Mean          -0.49700746
Policy log std Std           0.279869
Policy log std Max           0.013768375
Policy log std Min           -2.4290588
Z mean eval                  1.7743847
Z variance eval              0.10184449
total_rewards                [9694.66507765 9771.46626768 9531.12292654 9677.21968224 9484.6379054
 9712.27725225 9542.31994499 9869.49695908 9641.45188215 9866.97738403]
total_rewards_mean           9679.163528200792
total_rewards_std            126.9904809578937
total_rewards_max            9869.496959077384
total_rewards_min            9484.637905398744
Number of train steps total  1168000
Number of env steps total    3506000
Number of rollouts total     0
Train Time (s)               146.10416641365737
(Previous) Eval Time (s)     21.216266134288162
Sample Time (s)              6.597804294433445
Epoch Time (s)               173.91823684237897
Total Train Time (s)         49866.83250547387
Epoch                        291
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:44:45.909126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #291 | Epoch Duration: 174.00291347503662
2020-01-12 21:44:45.909269 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #291 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7722896
Z variance train             0.101696454
KL Divergence                44.69092
KL Loss                      4.4690924
QF Loss                      3220.54
VF Loss                      65.32998
Policy Loss                  -1183.2407
Q Predictions Mean           1181.7894
Q Predictions Std            1179.8167
Q Predictions Max            4316.385
Q Predictions Min            599.09845
V Predictions Mean           1189.264
V Predictions Std            1182.0874
V Predictions Max            4339.2583
V Predictions Min            609.9986
Log Pis Mean                 -0.6406333
Log Pis Std                  3.5307643
Log Pis Max                  13.195324
Log Pis Min                  -8.9440365
Policy mu Mean               0.024223946
Policy mu Std                0.839058
Policy mu Max                2.7931514
Policy mu Min                -2.7439356
Policy log std Mean          -0.49955297
Policy log std Std           0.2681348
Policy log std Max           0.007417619
Policy log std Min           -2.5651085
Z mean eval                  1.7606472
Z variance eval              0.07049555
total_rewards                [ 9554.58440381  9665.94559024  9790.56374431  9886.40581116
  9730.99293983  9792.32737444 10087.52878071  9816.38340068
  9931.31944268  9877.94154911]
total_rewards_mean           9813.399303698334
total_rewards_std            139.65698462704322
total_rewards_max            10087.528780712108
total_rewards_min            9554.584403813999
Number of train steps total  1172000
Number of env steps total    3518000
Number of rollouts total     0
Train Time (s)               148.37834131438285
(Previous) Eval Time (s)     19.66342899063602
Sample Time (s)              6.466103165410459
Epoch Time (s)               174.50787347042933
Total Train Time (s)         50041.42384757474
Epoch                        292
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:47:40.505499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #292 | Epoch Duration: 174.59609937667847
2020-01-12 21:47:40.505694 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7573166
Z variance train             0.07048865
KL Divergence                45.945652
KL Loss                      4.5945654
QF Loss                      212.19734
VF Loss                      85.1691
Policy Loss                  -1316.2229
Q Predictions Mean           1313.4551
Q Predictions Std            1317.6665
Q Predictions Max            4366.346
Q Predictions Min            606.2456
V Predictions Mean           1321.6592
V Predictions Std            1321.1127
V Predictions Max            4387.2334
V Predictions Min            607.0357
Log Pis Mean                 -0.28230304
Log Pis Std                  3.7044344
Log Pis Max                  13.419886
Log Pis Min                  -6.5579886
Policy mu Mean               0.08874122
Policy mu Std                0.8476482
Policy mu Max                2.7775476
Policy mu Min                -2.4866803
Policy log std Mean          -0.51742643
Policy log std Std           0.30340925
Policy log std Max           0.1490221
Policy log std Min           -2.6783462
Z mean eval                  1.7835901
Z variance eval              0.13394883
total_rewards                [ 9786.35484164  9785.96812964  9777.39709259  9816.59265174
  9969.45230246 10150.46247233 10334.6011771   9936.16617803
  9761.73991914 10092.1154927 ]
total_rewards_mean           9941.085025737515
total_rewards_std            185.68586783888816
total_rewards_max            10334.601177101635
total_rewards_min            9761.739919144442
Number of train steps total  1176000
Number of env steps total    3530000
Number of rollouts total     0
Train Time (s)               146.2617495143786
(Previous) Eval Time (s)     20.898657848127186
Sample Time (s)              6.493871899787337
Epoch Time (s)               173.65427926229313
Total Train Time (s)         50215.16054207785
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:50:34.243481 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #293 | Epoch Duration: 173.73765325546265
2020-01-12 21:50:34.243617 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7843113
Z variance train             0.13446955
KL Divergence                44.747395
KL Loss                      4.4747396
QF Loss                      83.30455
VF Loss                      36.7655
Policy Loss                  -1234.2246
Q Predictions Mean           1230.7877
Q Predictions Std            1210.2255
Q Predictions Max            4471.8696
Q Predictions Min            623.23755
V Predictions Mean           1235.4695
V Predictions Std            1211.5885
V Predictions Max            4484.7383
V Predictions Min            630.5162
Log Pis Mean                 -0.6223146
Log Pis Std                  3.4817421
Log Pis Max                  12.162188
Log Pis Min                  -8.301773
Policy mu Mean               0.03249288
Policy mu Std                0.83581555
Policy mu Max                2.498312
Policy mu Min                -2.7058034
Policy log std Mean          -0.5012674
Policy log std Std           0.2842324
Policy log std Max           0.22878253
Policy log std Min           -2.6395016
Z mean eval                  1.7871363
Z variance eval              0.065643474
total_rewards                [9711.39282932 9714.65557264 9891.68954528 9494.70129223 9741.4650806
 9718.0149579  9765.81474027 9697.64697162 9928.85709072 9754.50471153]
total_rewards_mean           9741.874279211408
total_rewards_std            111.09896979963305
total_rewards_max            9928.857090715148
total_rewards_min            9494.701292228763
Number of train steps total  1180000
Number of env steps total    3542000
Number of rollouts total     0
Train Time (s)               147.8722472260706
(Previous) Eval Time (s)     20.883575363084674
Sample Time (s)              6.362222519237548
Epoch Time (s)               175.11804510839283
Total Train Time (s)         50390.36641819356
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:53:29.451227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #294 | Epoch Duration: 175.20751094818115
2020-01-12 21:53:29.451362 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #294 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.788945
Z variance train             0.065576024
KL Divergence                45.146732
KL Loss                      4.514673
QF Loss                      108.29137
VF Loss                      51.06169
Policy Loss                  -1107.1108
Q Predictions Mean           1106.1996
Q Predictions Std            1113.5134
Q Predictions Max            4398.0854
Q Predictions Min            614.6111
V Predictions Mean           1103.0935
V Predictions Std            1110.1309
V Predictions Max            4382.3247
V Predictions Min            615.15515
Log Pis Mean                 -0.8189488
Log Pis Std                  3.685084
Log Pis Max                  14.407267
Log Pis Min                  -8.967124
Policy mu Mean               0.08752885
Policy mu Std                0.82651645
Policy mu Max                3.8015578
Policy mu Min                -3.3320742
Policy log std Mean          -0.4918108
Policy log std Std           0.28174993
Policy log std Max           0.022119045
Policy log std Min           -2.4166465
Z mean eval                  1.7972469
Z variance eval              0.06322133
total_rewards                [9221.39165948 9437.65608062 9399.93686065 9377.85099416 9462.402452
 9432.97173694 9132.94382333 9099.79385166 9114.69673406 9401.45719687]
total_rewards_mean           9308.11013897778
total_rewards_std            140.4265103178095
total_rewards_max            9462.402451998738
total_rewards_min            9099.793851658735
Number of train steps total  1184000
Number of env steps total    3554000
Number of rollouts total     0
Train Time (s)               146.6431085160002
(Previous) Eval Time (s)     20.5017858450301
Sample Time (s)              6.431200892664492
Epoch Time (s)               173.5760952536948
Total Train Time (s)         50564.11758754775
Epoch                        295
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:56:23.204506 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #295 | Epoch Duration: 173.75304746627808
2020-01-12 21:56:23.204642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8022372
Z variance train             0.06285991
KL Divergence                44.913536
KL Loss                      4.4913535
QF Loss                      147.71423
VF Loss                      57.36821
Policy Loss                  -1329.5085
Q Predictions Mean           1326.4216
Q Predictions Std            1307.8597
Q Predictions Max            4489.7817
Q Predictions Min            621.85944
V Predictions Mean           1326.5116
V Predictions Std            1308.5009
V Predictions Max            4485.5186
V Predictions Min            606.2001
Log Pis Mean                 -0.24486737
Log Pis Std                  4.2440224
Log Pis Max                  21.710302
Log Pis Min                  -7.3248873
Policy mu Mean               0.06422213
Policy mu Std                0.90940714
Policy mu Max                3.7979743
Policy mu Min                -3.21097
Policy log std Mean          -0.49762344
Policy log std Std           0.28703263
Policy log std Max           0.23438823
Policy log std Min           -2.8057988
Z mean eval                  1.8225048
Z variance eval              0.08786689
total_rewards                [9070.95118039 8594.54958323 8290.01829468 7777.7018734  7861.37185387
 8513.73749539 8087.50512516 7832.12661752 8168.11673373 7686.31779673]
total_rewards_mean           8188.2396554111165
total_rewards_std            415.3616959571746
total_rewards_max            9070.951180386957
total_rewards_min            7686.317796730912
Number of train steps total  1188000
Number of env steps total    3566000
Number of rollouts total     0
Train Time (s)               146.73075282294303
(Previous) Eval Time (s)     20.711064288858324
Sample Time (s)              6.4352643811143935
Epoch Time (s)               173.87708149291575
Total Train Time (s)         50738.07854477409
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:59:17.167475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #296 | Epoch Duration: 173.96273517608643
2020-01-12 21:59:17.167610 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8256531
Z variance train             0.08727001
KL Divergence                44.771996
KL Loss                      4.4771996
QF Loss                      245.21277
VF Loss                      41.50163
Policy Loss                  -1157.0105
Q Predictions Mean           1155.0613
Q Predictions Std            1143.9895
Q Predictions Max            4397.577
Q Predictions Min            620.24414
V Predictions Mean           1154.8293
V Predictions Std            1141.114
V Predictions Max            4369.067
V Predictions Min            624.5424
Log Pis Mean                 -0.87420774
Log Pis Std                  3.2204695
Log Pis Max                  12.514687
Log Pis Min                  -5.734761
Policy mu Mean               0.061504263
Policy mu Std                0.8073748
Policy mu Max                2.9221423
Policy mu Min                -2.8248937
Policy log std Mean          -0.48920342
Policy log std Std           0.26607257
Policy log std Max           0.17148864
Policy log std Min           -2.3700798
Z mean eval                  1.776922
Z variance eval              0.06602446
total_rewards                [9600.82018182 9947.89001377 9599.93637229 9881.22717991 9854.74122976
 4146.41931455 9903.87656295 9837.98179263 9811.69236048 9933.41037082]
total_rewards_mean           9251.799537898942
total_rewards_std            1705.8449244836427
total_rewards_max            9947.890013767907
total_rewards_min            4146.419314554901
Number of train steps total  1192000
Number of env steps total    3578000
Number of rollouts total     0
Train Time (s)               146.6342815309763
(Previous) Eval Time (s)     20.826059431303293
Sample Time (s)              6.3957953420467675
Epoch Time (s)               173.85613630432636
Total Train Time (s)         50912.01461682981
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:02:11.105282 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #297 | Epoch Duration: 173.93757677078247
2020-01-12 22:02:11.105412 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #297 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7753452
Z variance train             0.065744184
KL Divergence                44.130074
KL Loss                      4.4130073
QF Loss                      307.713
VF Loss                      34.060604
Policy Loss                  -1162.9637
Q Predictions Mean           1161.2026
Q Predictions Std            1129.9381
Q Predictions Max            4482.8896
Q Predictions Min            620.6795
V Predictions Mean           1165.2446
V Predictions Std            1128.4967
V Predictions Max            4477.49
V Predictions Min            627.9984
Log Pis Mean                 -0.37792534
Log Pis Std                  3.6560495
Log Pis Max                  20.710644
Log Pis Min                  -6.492455
Policy mu Mean               0.10623851
Policy mu Std                0.853081
Policy mu Max                3.331889
Policy mu Min                -2.9735067
Policy log std Mean          -0.49464807
Policy log std Std           0.26936847
Policy log std Max           0.41083807
Policy log std Min           -2.5652418
Z mean eval                  1.7654731
Z variance eval              0.044286896
total_rewards                [ 9384.25880016  9753.5399584   9847.49533552 10007.83528499
 10024.44678988  9809.22567345  9945.52184422  9803.53835929
  9840.68375081  9993.82449937]
total_rewards_mean           9841.03702960959
total_rewards_std            177.3369451359737
total_rewards_max            10024.446789877977
total_rewards_min            9384.258800163625
Number of train steps total  1196000
Number of env steps total    3590000
Number of rollouts total     0
Train Time (s)               147.7659698203206
(Previous) Eval Time (s)     17.441839011851698
Sample Time (s)              6.526860641781241
Epoch Time (s)               171.73466947395355
Total Train Time (s)         51083.82687009359
Epoch                        298
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:05:02.920889 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #298 | Epoch Duration: 171.81536436080933
2020-01-12 22:05:02.921065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7662363
Z variance train             0.04419474
KL Divergence                45.45102
KL Loss                      4.545102
QF Loss                      131.35718
VF Loss                      96.74388
Policy Loss                  -1403.6234
Q Predictions Mean           1397.6633
Q Predictions Std            1336.9595
Q Predictions Max            4412.6494
Q Predictions Min            619.3424
V Predictions Mean           1398.6206
V Predictions Std            1337.1694
V Predictions Max            4419.769
V Predictions Min            624.2218
Log Pis Mean                 -0.14102449
Log Pis Std                  3.6180964
Log Pis Max                  13.570574
Log Pis Min                  -7.01133
Policy mu Mean               0.06840125
Policy mu Std                0.86914355
Policy mu Max                2.9084024
Policy mu Min                -2.4072957
Policy log std Mean          -0.53438693
Policy log std Std           0.31011233
Policy log std Max           -0.05377698
Policy log std Min           -2.9317627
Z mean eval                  1.7752209
Z variance eval              0.074220166
total_rewards                [9456.19410912 9197.45600563 9598.99930434 6147.55755811 9555.02273058
 9367.18184026 9748.29580897 9017.31043123 9500.89703187 9656.47116388]
total_rewards_mean           9124.538598398864
total_rewards_std            1013.5187514260117
total_rewards_max            9748.295808968158
total_rewards_min            6147.557558106802
Number of train steps total  1200000
Number of env steps total    3602000
Number of rollouts total     0
Train Time (s)               145.35767476214096
(Previous) Eval Time (s)     20.77295720623806
Sample Time (s)              6.585640623234212
Epoch Time (s)               172.71627259161323
Total Train Time (s)         51256.62433876749
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:07:55.720166 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #299 | Epoch Duration: 172.798969745636
2020-01-12 22:07:55.720308 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7747421
Z variance train             0.07423786
KL Divergence                45.09706
KL Loss                      4.509706
QF Loss                      3782.5654
VF Loss                      37.434273
Policy Loss                  -1223.245
Q Predictions Mean           1221.0337
Q Predictions Std            1199.2335
Q Predictions Max            4395.873
Q Predictions Min            627.30524
V Predictions Mean           1224.8499
V Predictions Std            1197.0975
V Predictions Max            4389.018
V Predictions Min            621.3709
Log Pis Mean                 -0.43736666
Log Pis Std                  3.8200774
Log Pis Max                  16.496737
Log Pis Min                  -9.028261
Policy mu Mean               0.08393634
Policy mu Std                0.8633996
Policy mu Max                3.2865548
Policy mu Min                -2.7072902
Policy log std Mean          -0.48977718
Policy log std Std           0.2749999
Policy log std Max           0.23198771
Policy log std Min           -2.5429761
Z mean eval                  1.7961047
Z variance eval              0.07271739
total_rewards                [9231.6628517  9760.06165774 9729.40477773 9752.67934466 9766.16304675
 9397.42942754 9620.16833119 9690.16395916 9669.11655925 9570.04129935]
total_rewards_mean           9618.689125506615
total_rewards_std            167.5445171626156
total_rewards_max            9766.163046746362
total_rewards_min            9231.662851698567
Number of train steps total  1204000
Number of env steps total    3614000
Number of rollouts total     0
Train Time (s)               146.76977785630152
(Previous) Eval Time (s)     20.73562667891383
Sample Time (s)              8.129041645675898
Epoch Time (s)               175.63444618089125
Total Train Time (s)         51432.343228037935
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:10:51.441893 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #300 | Epoch Duration: 175.72148418426514
2020-01-12 22:10:51.442030 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #300 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7955515
Z variance train             0.07270336
KL Divergence                43.782867
KL Loss                      4.378287
QF Loss                      332.877
VF Loss                      148.72339
Policy Loss                  -1280.014
Q Predictions Mean           1278.2876
Q Predictions Std            1267.7418
Q Predictions Max            4482.2227
Q Predictions Min            640.1394
V Predictions Mean           1280.8284
V Predictions Std            1271.0627
V Predictions Max            4521.483
V Predictions Min            634.00073
Log Pis Mean                 -0.25972697
Log Pis Std                  3.56801
Log Pis Max                  14.651103
Log Pis Min                  -6.765519
Policy mu Mean               -0.021065215
Policy mu Std                0.8717477
Policy mu Max                3.1865072
Policy mu Min                -2.6083379
Policy log std Mean          -0.5109462
Policy log std Std           0.2921282
Policy log std Max           0.12725812
Policy log std Min           -2.390552
Z mean eval                  1.7961328
Z variance eval              0.069618575
total_rewards                [ 9802.0151278   9699.44526854  9847.73951123 10020.70913508
  9838.01395219  9831.83875143  9984.58770199  9722.35988993
  9974.62458473  9733.63245409]
total_rewards_mean           9845.496637701484
total_rewards_std            108.56575306784231
total_rewards_max            10020.709135082709
total_rewards_min            9699.445268539595
Number of train steps total  1208000
Number of env steps total    3626000
Number of rollouts total     0
Train Time (s)               147.13537891115993
(Previous) Eval Time (s)     20.9792550932616
Sample Time (s)              6.3891238565556705
Epoch Time (s)               174.5037578609772
Total Train Time (s)         51606.979694562964
Epoch                        301
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:13:46.087242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #301 | Epoch Duration: 174.6450638771057
2020-01-12 22:13:46.087574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #301 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7977053
Z variance train             0.06952851
KL Divergence                44.68281
KL Loss                      4.4682813
QF Loss                      96.74396
VF Loss                      74.89988
Policy Loss                  -1304.4158
Q Predictions Mean           1300.3242
Q Predictions Std            1271.2744
Q Predictions Max            4392.5957
Q Predictions Min            621.89844
V Predictions Mean           1299.4531
V Predictions Std            1267.7158
V Predictions Max            4386.294
V Predictions Min            623.01434
Log Pis Mean                 -0.03864701
Log Pis Std                  3.8446121
Log Pis Max                  17.71598
Log Pis Min                  -6.0567646
Policy mu Mean               0.01314159
Policy mu Std                0.9226242
Policy mu Max                2.8907664
Policy mu Min                -3.2848103
Policy log std Mean          -0.4882224
Policy log std Std           0.2770315
Policy log std Max           0.26449448
Policy log std Min           -2.7558799
Z mean eval                  1.7999731
Z variance eval              0.07085535
total_rewards                [ 9545.90370966 10054.27444372  9735.02181911  9842.6018181
  9762.99802044  9774.73040487  9816.34222279  9701.40066011
 10117.18525593  9936.78480857]
total_rewards_mean           9828.724316330126
total_rewards_std            160.7233027116543
total_rewards_max            10117.18525592806
total_rewards_min            9545.903709655604
Number of train steps total  1212000
Number of env steps total    3638000
Number of rollouts total     0
Train Time (s)               148.6941445628181
(Previous) Eval Time (s)     20.83903538901359
Sample Time (s)              6.476941705681384
Epoch Time (s)               176.01012165751308
Total Train Time (s)         51783.152066549286
Epoch                        302
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:16:42.265884 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #302 | Epoch Duration: 176.17805218696594
2020-01-12 22:16:42.266148 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7997215
Z variance train             0.07057479
KL Divergence                44.20946
KL Loss                      4.420946
QF Loss                      202.38177
VF Loss                      72.1368
Policy Loss                  -1174.714
Q Predictions Mean           1166.4226
Q Predictions Std            1120.7981
Q Predictions Max            4449.744
Q Predictions Min            626.19763
V Predictions Mean           1171.1782
V Predictions Std            1122.1384
V Predictions Max            4445.9766
V Predictions Min            627.487
Log Pis Mean                 -0.5434498
Log Pis Std                  4.022326
Log Pis Max                  18.898846
Log Pis Min                  -6.964944
Policy mu Mean               -0.0013154013
Policy mu Std                0.8760498
Policy mu Max                3.4486058
Policy mu Min                -3.5043552
Policy log std Mean          -0.48827
Policy log std Std           0.2763987
Policy log std Max           0.11077744
Policy log std Min           -2.9110389
Z mean eval                  1.7733183
Z variance eval              0.05421058
total_rewards                [ 9589.92368579 10085.72682977 10010.06086752  9926.49256446
  9813.28564654 10132.43847789  9844.61800543  9923.97897051
  9935.02809259  9916.08133771]
total_rewards_mean           9917.763447822004
total_rewards_std            143.86673827494698
total_rewards_max            10132.438477890926
total_rewards_min            9589.923685790814
Number of train steps total  1216000
Number of env steps total    3650000
Number of rollouts total     0
Train Time (s)               146.55261725513265
(Previous) Eval Time (s)     20.812600024975836
Sample Time (s)              6.391945228911936
Epoch Time (s)               173.75716250902042
Total Train Time (s)         51956.99492629757
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:19:36.109118 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #303 | Epoch Duration: 173.84278774261475
2020-01-12 22:19:36.109250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7736838
Z variance train             0.05427807
KL Divergence                44.290207
KL Loss                      4.429021
QF Loss                      148.28806
VF Loss                      40.375397
Policy Loss                  -1291.0541
Q Predictions Mean           1289.9509
Q Predictions Std            1265.8804
Q Predictions Max            4539.987
Q Predictions Min            625.1691
V Predictions Mean           1291.0734
V Predictions Std            1265.9443
V Predictions Max            4540.906
V Predictions Min            620.0627
Log Pis Mean                 -0.3320163
Log Pis Std                  3.5391076
Log Pis Max                  12.459843
Log Pis Min                  -5.988287
Policy mu Mean               0.00015985407
Policy mu Std                0.86376137
Policy mu Max                2.874387
Policy mu Min                -2.7309039
Policy log std Mean          -0.4864192
Policy log std Std           0.27105284
Policy log std Max           0.18617451
Policy log std Min           -2.270648
Z mean eval                  1.765756
Z variance eval              0.08573645
total_rewards                [9526.98556361 9281.7873082  9793.15958492 9674.86047983 9387.54424556
 9665.21957479 9579.99852525 9464.85367618 9657.97899156 8952.43231187]
total_rewards_mean           9498.482026176764
total_rewards_std            231.7773186228015
total_rewards_max            9793.159584920659
total_rewards_min            8952.432311868688
Number of train steps total  1220000
Number of env steps total    3662000
Number of rollouts total     0
Train Time (s)               148.6317911730148
(Previous) Eval Time (s)     17.584219795186073
Sample Time (s)              6.461607371922582
Epoch Time (s)               172.67761834012344
Total Train Time (s)         52129.75681212917
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:22:28.874214 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #304 | Epoch Duration: 172.76485109329224
2020-01-12 22:22:28.874391 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7672135
Z variance train             0.085728295
KL Divergence                42.719284
KL Loss                      4.2719283
QF Loss                      160.20615
VF Loss                      227.56012
Policy Loss                  -1288.1722
Q Predictions Mean           1284.4457
Q Predictions Std            1278.941
Q Predictions Max            4516.4644
Q Predictions Min            624.93274
V Predictions Mean           1277.1361
V Predictions Std            1268.9524
V Predictions Max            4475.447
V Predictions Min            619.6817
Log Pis Mean                 -0.40369207
Log Pis Std                  4.228481
Log Pis Max                  20.997288
Log Pis Min                  -9.429037
Policy mu Mean               0.0030029186
Policy mu Std                0.88400215
Policy mu Max                3.2972324
Policy mu Min                -3.2785535
Policy log std Mean          -0.49148598
Policy log std Std           0.2947284
Policy log std Max           0.037620485
Policy log std Min           -2.578416
Z mean eval                  1.7990776
Z variance eval              0.06866924
total_rewards                [9325.963591   9639.38866346 6745.52607816 9762.14836396 9771.25947909
 9706.86257459 9754.64025295 9406.77695136 9572.01764549 9561.93045086]
total_rewards_mean           9324.651405093642
total_rewards_std            871.609021958248
total_rewards_max            9771.259479094118
total_rewards_min            6745.52607816466
Number of train steps total  1224000
Number of env steps total    3674000
Number of rollouts total     0
Train Time (s)               146.85900598904118
(Previous) Eval Time (s)     18.307155821938068
Sample Time (s)              6.697442340198904
Epoch Time (s)               171.86360415117815
Total Train Time (s)         52301.79360276507
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:25:20.917739 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #305 | Epoch Duration: 172.04320073127747
2020-01-12 22:25:20.917941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7985992
Z variance train             0.06862789
KL Divergence                44.439327
KL Loss                      4.443933
QF Loss                      149.81592
VF Loss                      61.45254
Policy Loss                  -1275.624
Q Predictions Mean           1274.5049
Q Predictions Std            1242.9208
Q Predictions Max            4466.6357
Q Predictions Min            627.2416
V Predictions Mean           1276.2631
V Predictions Std            1242.7554
V Predictions Max            4467.7573
V Predictions Min            631.0571
Log Pis Mean                 -0.53933144
Log Pis Std                  3.6731443
Log Pis Max                  12.492868
Log Pis Min                  -7.893554
Policy mu Mean               0.016283752
Policy mu Std                0.8467416
Policy mu Max                2.8555837
Policy mu Min                -2.816742
Policy log std Mean          -0.49351645
Policy log std Std           0.28944808
Policy log std Max           0.09078914
Policy log std Min           -2.6196077
Z mean eval                  1.7916797
Z variance eval              0.082396366
total_rewards                [8962.23615838 9242.78010083 3491.92814336 9329.1191469  9318.22380099
 8938.8725333  9250.1670199  9105.814003   9324.23574955 9408.35786359]
total_rewards_mean           8637.173451979668
total_rewards_std            1721.6788404980134
total_rewards_max            9408.357863591304
total_rewards_min            3491.9281433610345
Number of train steps total  1228000
Number of env steps total    3686000
Number of rollouts total     0
Train Time (s)               146.0020103752613
(Previous) Eval Time (s)     20.445565198082477
Sample Time (s)              6.563765593338758
Epoch Time (s)               173.01134116668254
Total Train Time (s)         52474.89129066048
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:28:14.023278 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #306 | Epoch Duration: 173.10515308380127
2020-01-12 22:28:14.023587 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7935026
Z variance train             0.08210872
KL Divergence                45.301624
KL Loss                      4.5301623
QF Loss                      126.600945
VF Loss                      109.258865
Policy Loss                  -1360.3292
Q Predictions Mean           1359.252
Q Predictions Std            1331.8873
Q Predictions Max            4483.1133
Q Predictions Min            632.4388
V Predictions Mean           1355.7297
V Predictions Std            1321.9446
V Predictions Max            4447.3325
V Predictions Min            631.5299
Log Pis Mean                 -0.22178736
Log Pis Std                  4.007602
Log Pis Max                  13.244955
Log Pis Min                  -7.4860396
Policy mu Mean               0.044446904
Policy mu Std                0.87862676
Policy mu Max                2.9192147
Policy mu Min                -2.5026824
Policy log std Mean          -0.50762725
Policy log std Std           0.29433048
Policy log std Max           0.2171309
Policy log std Min           -2.6851153
Z mean eval                  1.8043737
Z variance eval              0.09714695
total_rewards                [9555.79185273 9395.63616525 9424.58607337 9617.6100549  9474.72424989
 9710.55395606 9302.84174249 9396.79067392 9348.02786456 9344.90489961]
total_rewards_mean           9457.146753277662
total_rewards_std            125.22192866942453
total_rewards_max            9710.553956058711
total_rewards_min            9302.841742487195
Number of train steps total  1232000
Number of env steps total    3698000
Number of rollouts total     0
Train Time (s)               144.75072347419336
(Previous) Eval Time (s)     21.07744924305007
Sample Time (s)              6.600636965595186
Epoch Time (s)               172.42880968283862
Total Train Time (s)         52647.415347011294
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:31:06.550259 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #307 | Epoch Duration: 172.52644515037537
2020-01-12 22:31:06.550482 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #307 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8041741
Z variance train             0.09759934
KL Divergence                44.115425
KL Loss                      4.4115424
QF Loss                      137.72667
VF Loss                      230.26747
Policy Loss                  -1259.7378
Q Predictions Mean           1259.7448
Q Predictions Std            1228.326
Q Predictions Max            4476.597
Q Predictions Min            619.0707
V Predictions Mean           1268.7869
V Predictions Std            1233.8253
V Predictions Max            4503.5537
V Predictions Min            627.6394
Log Pis Mean                 -0.3053261
Log Pis Std                  4.115492
Log Pis Max                  23.373491
Log Pis Min                  -7.684518
Policy mu Mean               0.077526174
Policy mu Std                0.90920836
Policy mu Max                3.1731331
Policy mu Min                -4.452347
Policy log std Mean          -0.4875659
Policy log std Std           0.26642326
Policy log std Max           -0.029409587
Policy log std Min           -2.582425
Z mean eval                  1.7777439
Z variance eval              0.07455977
total_rewards                [ 9773.70786804  9611.25395373  9964.7744772   9886.11167285
  9817.17194562  9686.74196867  9882.3952756   9603.61940974
 10065.42856989  9967.31649711]
total_rewards_mean           9825.852163844049
total_rewards_std            148.70190380076596
total_rewards_max            10065.428569892583
total_rewards_min            9603.619409737952
Number of train steps total  1236000
Number of env steps total    3710000
Number of rollouts total     0
Train Time (s)               145.16040387609974
(Previous) Eval Time (s)     17.534940616227686
Sample Time (s)              6.563863026443869
Epoch Time (s)               169.2592075187713
Total Train Time (s)         52816.75679601403
Epoch                        308
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:33:55.897369 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #308 | Epoch Duration: 169.34673309326172
2020-01-12 22:33:55.897535 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #308 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7768011
Z variance train             0.074453175
KL Divergence                44.801502
KL Loss                      4.48015
QF Loss                      290.2929
VF Loss                      61.198494
Policy Loss                  -1148.8304
Q Predictions Mean           1142.4834
Q Predictions Std            1108.9772
Q Predictions Max            4462.8354
Q Predictions Min            617.6345
V Predictions Mean           1153.1287
V Predictions Std            1110.8193
V Predictions Max            4466.1387
V Predictions Min            627.57837
Log Pis Mean                 -0.4166856
Log Pis Std                  3.6811256
Log Pis Max                  14.333782
Log Pis Min                  -7.595539
Policy mu Mean               0.04888575
Policy mu Std                0.832394
Policy mu Max                2.7515152
Policy mu Min                -3.2707703
Policy log std Mean          -0.51266605
Policy log std Std           0.29559457
Policy log std Max           0.050203264
Policy log std Min           -2.5651765
Z mean eval                  1.776811
Z variance eval              0.08908029
total_rewards                [ 9425.96184676  9835.67890575 10091.90724705  9767.092064
  9807.49120338  9977.75562138  9614.5010228   9787.30537355
  9680.1883365   9832.19003332]
total_rewards_mean           9782.007165449737
total_rewards_std            174.88513735424436
total_rewards_max            10091.907247052937
total_rewards_min            9425.961846757484
Number of train steps total  1240000
Number of env steps total    3722000
Number of rollouts total     0
Train Time (s)               147.19403685769066
(Previous) Eval Time (s)     20.675275477115065
Sample Time (s)              6.410454101394862
Epoch Time (s)               174.2797664362006
Total Train Time (s)         52991.12078478327
Epoch                        309
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:36:50.264561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #309 | Epoch Duration: 174.3669068813324
2020-01-12 22:36:50.264693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #309 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7767203
Z variance train             0.08894973
KL Divergence                43.74858
KL Loss                      4.3748584
QF Loss                      322.93994
VF Loss                      30.20936
Policy Loss                  -1160.7787
Q Predictions Mean           1156.9486
Q Predictions Std            1165.4595
Q Predictions Max            4451.756
Q Predictions Min            613.729
V Predictions Mean           1158.9637
V Predictions Std            1166.575
V Predictions Max            4444.6987
V Predictions Min            619.3392
Log Pis Mean                 -0.79207695
Log Pis Std                  3.5484397
Log Pis Max                  15.273776
Log Pis Min                  -7.2679873
Policy mu Mean               0.04810205
Policy mu Std                0.8409586
Policy mu Max                2.934445
Policy mu Min                -3.3897822
Policy log std Mean          -0.50179464
Policy log std Std           0.27869108
Policy log std Max           0.09431815
Policy log std Min           -2.494413
Z mean eval                  1.80108
Z variance eval              0.07824404
total_rewards                [10011.95211126  9943.93387989 10097.50991435 10029.56487999
  9979.15105968  9992.76087659  9742.30399858  9720.52169664
  9694.31935735  2978.36951377]
total_rewards_mean           9219.038728809957
total_rewards_std            2084.6198989802697
total_rewards_max            10097.509914351767
total_rewards_min            2978.3695137661334
Number of train steps total  1244000
Number of env steps total    3734000
Number of rollouts total     0
Train Time (s)               145.65282604005188
(Previous) Eval Time (s)     20.65744609804824
Sample Time (s)              6.576770623214543
Epoch Time (s)               172.88704276131466
Total Train Time (s)         53164.091541513335
Epoch                        310
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:39:43.237107 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #310 | Epoch Duration: 172.97231674194336
2020-01-12 22:39:43.237243 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8007901
Z variance train             0.07823266
KL Divergence                44.869946
KL Loss                      4.4869947
QF Loss                      82.2359
VF Loss                      42.612663
Policy Loss                  -1144.7765
Q Predictions Mean           1145.5264
Q Predictions Std            1139.6516
Q Predictions Max            4436.485
Q Predictions Min            609.04565
V Predictions Mean           1146.7864
V Predictions Std            1134.7092
V Predictions Max            4423.4824
V Predictions Min            623.0147
Log Pis Mean                 -0.43932512
Log Pis Std                  3.4313643
Log Pis Max                  12.650631
Log Pis Min                  -8.274021
Policy mu Mean               0.021535635
Policy mu Std                0.845201
Policy mu Max                2.4625788
Policy mu Min                -2.5442915
Policy log std Mean          -0.504466
Policy log std Std           0.2530017
Policy log std Max           0.26568323
Policy log std Min           -2.425052
Z mean eval                  1.7963327
Z variance eval              0.08562441
total_rewards                [ 9371.58872134  9877.19368266  9796.50796289  9871.70083544
  9549.70862587  9839.08544931 10162.2133726   9905.19537302
  9945.56424738  9591.30051594]
total_rewards_mean           9791.005878646127
total_rewards_std            215.6436442676122
total_rewards_max            10162.213372598844
total_rewards_min            9371.588721342006
Number of train steps total  1248000
Number of env steps total    3746000
Number of rollouts total     0
Train Time (s)               144.85634472128004
(Previous) Eval Time (s)     20.859417208936065
Sample Time (s)              6.444515200331807
Epoch Time (s)               172.1602771305479
Total Train Time (s)         53336.332650802564
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:42:35.480498 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #311 | Epoch Duration: 172.24315810203552
2020-01-12 22:42:35.480637 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #311 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7962716
Z variance train             0.08567779
KL Divergence                44.773045
KL Loss                      4.4773045
QF Loss                      270.1863
VF Loss                      33.942
Policy Loss                  -1123.3965
Q Predictions Mean           1118.6387
Q Predictions Std            1114.3601
Q Predictions Max            4618.031
Q Predictions Min            626.9934
V Predictions Mean           1124.553
V Predictions Std            1119.2251
V Predictions Max            4632.068
V Predictions Min            639.48
Log Pis Mean                 -0.7689757
Log Pis Std                  3.5272124
Log Pis Max                  18.776539
Log Pis Min                  -7.0568686
Policy mu Mean               0.060161244
Policy mu Std                0.8401822
Policy mu Max                4.3152504
Policy mu Min                -3.3407934
Policy log std Mean          -0.49474764
Policy log std Std           0.274777
Policy log std Max           0.21635121
Policy log std Min           -2.8879366
Z mean eval                  1.7841647
Z variance eval              0.093428455
total_rewards                [9202.71395987 9557.58793418 8985.58758087 9307.58643076 9382.3437324
 8143.77627286 9306.26527999 9073.49810118 9341.28350261 8967.03476419]
total_rewards_mean           9126.767755891191
total_rewards_std            371.7769591979031
total_rewards_max            9557.587934179573
total_rewards_min            8143.776272856632
Number of train steps total  1252000
Number of env steps total    3758000
Number of rollouts total     0
Train Time (s)               147.1140506430529
(Previous) Eval Time (s)     17.55216360092163
Sample Time (s)              6.460114154964685
Epoch Time (s)               171.12632839893922
Total Train Time (s)         53507.53807624988
Epoch                        312
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:45:26.689614 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #312 | Epoch Duration: 171.20886301994324
2020-01-12 22:45:26.689782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7855997
Z variance train             0.093419604
KL Divergence                44.21741
KL Loss                      4.421741
QF Loss                      116.75348
VF Loss                      143.56061
Policy Loss                  -1299.3881
Q Predictions Mean           1297.6934
Q Predictions Std            1300.0734
Q Predictions Max            4489.277
Q Predictions Min            636.1987
V Predictions Mean           1293.2192
V Predictions Std            1288.1655
V Predictions Max            4446.8374
V Predictions Min            635.7293
Log Pis Mean                 -0.6721461
Log Pis Std                  3.6448812
Log Pis Max                  15.823763
Log Pis Min                  -11.856018
Policy mu Mean               -0.024462253
Policy mu Std                0.85921603
Policy mu Max                3.2763436
Policy mu Min                -3.1205933
Policy log std Mean          -0.4841137
Policy log std Std           0.2656746
Policy log std Max           0.30590367
Policy log std Min           -2.514464
Z mean eval                  1.8006792
Z variance eval              0.092416614
total_rewards                [9595.48847177 9812.53663929 9635.07906561 9552.98700666 9786.02892557
 9549.46843    9664.55489219 9599.50034457 9584.84508508 9819.4144142 ]
total_rewards_mean           9659.99032749554
total_rewards_std            101.16555069122911
total_rewards_max            9819.41441420254
total_rewards_min            9549.468429997436
Number of train steps total  1256000
Number of env steps total    3770000
Number of rollouts total     0
Train Time (s)               146.49051501322538
(Previous) Eval Time (s)     20.790774310939014
Sample Time (s)              6.514025928452611
Epoch Time (s)               173.795315252617
Total Train Time (s)         53681.432074513286
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:48:20.585292 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #313 | Epoch Duration: 173.8953833580017
2020-01-12 22:48:20.585440 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #313 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.799708
Z variance train             0.09247057
KL Divergence                44.444786
KL Loss                      4.4444785
QF Loss                      202.6352
VF Loss                      63.65096
Policy Loss                  -1426.0076
Q Predictions Mean           1426.8375
Q Predictions Std            1367.022
Q Predictions Max            4487.449
Q Predictions Min            631.5592
V Predictions Mean           1427.9951
V Predictions Std            1366.9971
V Predictions Max            4473.785
V Predictions Min            623.2108
Log Pis Mean                 -0.053217262
Log Pis Std                  4.021117
Log Pis Max                  13.648204
Log Pis Min                  -8.327703
Policy mu Mean               0.023064354
Policy mu Std                0.8970868
Policy mu Max                2.4380906
Policy mu Min                -2.751778
Policy log std Mean          -0.5148533
Policy log std Std           0.31370705
Policy log std Max           0.009624362
Policy log std Min           -2.8126454
Z mean eval                  1.7752241
Z variance eval              0.068423524
total_rewards                [ 9282.87524261  9920.04625788  9765.68718994  9934.40145568
 10091.94764953  9742.32679589  9993.826551    9885.11271757
 10029.76252079  9738.6155431 ]
total_rewards_mean           9838.460192398943
total_rewards_std            218.22231269309887
total_rewards_max            10091.947649526808
total_rewards_min            9282.875242614244
Number of train steps total  1260000
Number of env steps total    3782000
Number of rollouts total     0
Train Time (s)               145.7166095469147
(Previous) Eval Time (s)     17.284411718137562
Sample Time (s)              6.648063201922923
Epoch Time (s)               169.64908446697518
Total Train Time (s)         53851.16395285772
Epoch                        314
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:51:10.322240 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #314 | Epoch Duration: 169.73668003082275
2020-01-12 22:51:10.322419 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7749426
Z variance train             0.06850171
KL Divergence                44.03917
KL Loss                      4.403917
QF Loss                      68.12311
VF Loss                      27.99068
Policy Loss                  -1170.3198
Q Predictions Mean           1170.6338
Q Predictions Std            1165.3677
Q Predictions Max            4478.541
Q Predictions Min            639.9777
V Predictions Mean           1169.7449
V Predictions Std            1162.5529
V Predictions Max            4429.2773
V Predictions Min            643.8294
Log Pis Mean                 -0.48028436
Log Pis Std                  3.6581159
Log Pis Max                  12.617698
Log Pis Min                  -6.233508
Policy mu Mean               0.034611553
Policy mu Std                0.83962697
Policy mu Max                2.4909465
Policy mu Min                -3.3860748
Policy log std Mean          -0.4972725
Policy log std Std           0.26124924
Policy log std Max           0.027370632
Policy log std Min           -2.662407
Z mean eval                  1.7949635
Z variance eval              0.08724328
total_rewards                [9335.60425739 9680.77576791 9490.36091915 9499.225024   9612.46711993
 9638.29412838 9409.16427803 9725.75469371 9510.86079607 9254.70256503]
total_rewards_mean           9515.720954959335
total_rewards_std            144.43236627959647
total_rewards_max            9725.754693710238
total_rewards_min            9254.702565025953
Number of train steps total  1264000
Number of env steps total    3794000
Number of rollouts total     0
Train Time (s)               145.1270740358159
(Previous) Eval Time (s)     20.919906778261065
Sample Time (s)              5.716656708158553
Epoch Time (s)               171.7636375222355
Total Train Time (s)         54023.00660692435
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:54:02.167779 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #315 | Epoch Duration: 171.84522557258606
2020-01-12 22:54:02.167919 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #315 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7947447
Z variance train             0.08734233
KL Divergence                44.14329
KL Loss                      4.414329
QF Loss                      86.03195
VF Loss                      59.7796
Policy Loss                  -1238.3792
Q Predictions Mean           1237.2092
Q Predictions Std            1211.3815
Q Predictions Max            4437.7544
Q Predictions Min            640.6839
V Predictions Mean           1234.8733
V Predictions Std            1208.2854
V Predictions Max            4414.7266
V Predictions Min            637.2332
Log Pis Mean                 -0.6166153
Log Pis Std                  3.1903954
Log Pis Max                  14.598618
Log Pis Min                  -7.440077
Policy mu Mean               -0.024926012
Policy mu Std                0.82863426
Policy mu Max                2.2870686
Policy mu Min                -2.44068
Policy log std Mean          -0.5010974
Policy log std Std           0.27332196
Policy log std Max           0.0016109943
Policy log std Min           -2.628548
Z mean eval                  1.7905957
Z variance eval              0.086955115
total_rewards                [ 9792.54153828 10003.92943057  6632.4814116   9808.34272664
  9901.01542641  9919.68597167 10123.69386013  9715.67304113
  9787.7896183  10146.98086906]
total_rewards_mean           9583.213389378898
total_rewards_std            993.0702150906137
total_rewards_max            10146.98086906192
total_rewards_min            6632.481411597136
Number of train steps total  1268000
Number of env steps total    3806000
Number of rollouts total     0
Train Time (s)               145.14495570305735
(Previous) Eval Time (s)     20.871004222426564
Sample Time (s)              6.404998062644154
Epoch Time (s)               172.42095798812807
Total Train Time (s)         54195.51261004293
Epoch                        316
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:56:54.676754 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #316 | Epoch Duration: 172.50873684883118
2020-01-12 22:56:54.676892 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #316 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7953287
Z variance train             0.08687654
KL Divergence                42.795906
KL Loss                      4.2795906
QF Loss                      111.549576
VF Loss                      129.90356
Policy Loss                  -1228.9694
Q Predictions Mean           1229.7441
Q Predictions Std            1210.5975
Q Predictions Max            4412.45
Q Predictions Min            397.1112
V Predictions Mean           1236.1638
V Predictions Std            1207.8668
V Predictions Max            4431.8853
V Predictions Min            420.666
Log Pis Mean                 -0.58089465
Log Pis Std                  3.7102644
Log Pis Max                  17.666498
Log Pis Min                  -6.52494
Policy mu Mean               0.04804148
Policy mu Std                0.84052885
Policy mu Max                2.7786055
Policy mu Min                -3.0895662
Policy log std Mean          -0.49979028
Policy log std Std           0.30293205
Policy log std Max           0.13399714
Policy log std Min           -2.7357616
Z mean eval                  1.7866462
Z variance eval              0.08098515
total_rewards                [ 9679.8280732   9984.20153326 10154.36403974  9664.09656082
  9679.46115331 10169.06354437  9724.1910651   9886.92768345
  9946.15768536 10127.31384342]
total_rewards_mean           9901.560518204406
total_rewards_std            195.3988426007276
total_rewards_max            10169.063544371005
total_rewards_min            9664.096560823726
Number of train steps total  1272000
Number of env steps total    3818000
Number of rollouts total     0
Train Time (s)               147.50106215197593
(Previous) Eval Time (s)     21.048378004692495
Sample Time (s)              6.4849837962538
Epoch Time (s)               175.03442395292222
Total Train Time (s)         54370.63554027304
Epoch                        317
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:59:49.803693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #317 | Epoch Duration: 175.1267008781433
2020-01-12 22:59:49.803853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7888424
Z variance train             0.08096676
KL Divergence                43.924664
KL Loss                      4.3924665
QF Loss                      100.5616
VF Loss                      66.96734
Policy Loss                  -1303.5632
Q Predictions Mean           1302.7944
Q Predictions Std            1272.3824
Q Predictions Max            4485.6377
Q Predictions Min            637.55023
V Predictions Mean           1299.0492
V Predictions Std            1266.7603
V Predictions Max            4483.229
V Predictions Min            637.519
Log Pis Mean                 -0.22578041
Log Pis Std                  3.7003188
Log Pis Max                  15.616499
Log Pis Min                  -6.8604527
Policy mu Mean               -0.026461527
Policy mu Std                0.8778995
Policy mu Max                2.752522
Policy mu Min                -2.5294917
Policy log std Mean          -0.5049451
Policy log std Std           0.27467513
Policy log std Max           0.033811867
Policy log std Min           -2.72507
Z mean eval                  1.8149059
Z variance eval              0.07224999
total_rewards                [9468.0434454  9634.42008977 9432.54877685 9560.13970554 9695.20447001
 9461.60074088 9496.40337415 9562.52945348 9444.99957729 9464.19452372]
total_rewards_mean           9522.008415710177
total_rewards_std            83.79854717986417
total_rewards_max            9695.204470013055
total_rewards_min            9432.548776851441
Number of train steps total  1276000
Number of env steps total    3830000
Number of rollouts total     0
Train Time (s)               147.04323120880872
(Previous) Eval Time (s)     20.58857871964574
Sample Time (s)              6.4745201715268195
Epoch Time (s)               174.10633009998128
Total Train Time (s)         54544.82632547151
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:02:43.999959 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #318 | Epoch Duration: 174.1959934234619
2020-01-12 23:02:44.000158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8142198
Z variance train             0.07217006
KL Divergence                45.56876
KL Loss                      4.556876
QF Loss                      130.74384
VF Loss                      45.9796
Policy Loss                  -1171.2893
Q Predictions Mean           1168.4698
Q Predictions Std            1142.2971
Q Predictions Max            4515.466
Q Predictions Min            631.99524
V Predictions Mean           1173.1011
V Predictions Std            1139.6653
V Predictions Max            4487.333
V Predictions Min            650.7112
Log Pis Mean                 -0.8331382
Log Pis Std                  3.4860277
Log Pis Max                  18.116556
Log Pis Min                  -10.735769
Policy mu Mean               0.00092520687
Policy mu Std                0.8391631
Policy mu Max                3.3855193
Policy mu Min                -2.88572
Policy log std Mean          -0.49852487
Policy log std Std           0.2731121
Policy log std Max           0.0077904463
Policy log std Min           -2.586977
Z mean eval                  1.8191893
Z variance eval              0.061810352
total_rewards                [9401.33962409 9873.19163202 9609.56025157 9674.01141173 9583.6622926
 9539.0607231  9870.08431981 9624.66075486 9753.39679708 9628.77076237]
total_rewards_mean           9655.773856922451
total_rewards_std            138.00507671496285
total_rewards_max            9873.19163201501
total_rewards_min            9401.339624085032
Number of train steps total  1280000
Number of env steps total    3842000
Number of rollouts total     0
Train Time (s)               146.27230041194707
(Previous) Eval Time (s)     20.824665712192655
Sample Time (s)              6.44978565024212
Epoch Time (s)               173.54675177438185
Total Train Time (s)         54718.458419310395
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:05:37.633829 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #319 | Epoch Duration: 173.6335334777832
2020-01-12 23:05:37.633956 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #319 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8184685
Z variance train             0.06187564
KL Divergence                46.237034
KL Loss                      4.6237035
QF Loss                      133.29282
VF Loss                      46.932415
Policy Loss                  -1355.2161
Q Predictions Mean           1350.6199
Q Predictions Std            1327.2208
Q Predictions Max            4524.739
Q Predictions Min            652.7664
V Predictions Mean           1355.2233
V Predictions Std            1325.4136
V Predictions Max            4517.929
V Predictions Min            650.91406
Log Pis Mean                 -0.1624864
Log Pis Std                  3.9193969
Log Pis Max                  15.417389
Log Pis Min                  -6.569827
Policy mu Mean               0.013450739
Policy mu Std                0.892372
Policy mu Max                3.3218932
Policy mu Min                -3.0201838
Policy log std Mean          -0.510017
Policy log std Std           0.29690346
Policy log std Max           0.020125628
Policy log std Min           -2.7273316
Z mean eval                  1.7931359
Z variance eval              0.06180688
total_rewards                [ 9886.73211423  9772.62332223  2618.94262588 10038.78099806
 10310.4763645   9983.69036037 10110.51527547  6453.70948912
 10301.02820458  9958.26526597]
total_rewards_mean           8943.476402041368
total_rewards_std            2369.8318911249385
total_rewards_max            10310.476364503573
total_rewards_min            2618.9426258784806
Number of train steps total  1284000
Number of env steps total    3854000
Number of rollouts total     0
Train Time (s)               146.6990394545719
(Previous) Eval Time (s)     20.929202146828175
Sample Time (s)              9.112991851754487
Epoch Time (s)               176.74123345315456
Total Train Time (s)         54895.27982244687
Epoch                        320
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:08:34.459470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #320 | Epoch Duration: 176.82540345191956
2020-01-12 23:08:34.459668 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7915913
Z variance train             0.06177526
KL Divergence                46.325565
KL Loss                      4.6325564
QF Loss                      128.34099
VF Loss                      50.620792
Policy Loss                  -1388.82
Q Predictions Mean           1386.7906
Q Predictions Std            1350.8788
Q Predictions Max            4482.2075
Q Predictions Min            648.28625
V Predictions Mean           1391.5123
V Predictions Std            1351.5094
V Predictions Max            4479.8633
V Predictions Min            639.86523
Log Pis Mean                 -0.17547199
Log Pis Std                  3.85754
Log Pis Max                  19.854832
Log Pis Min                  -7.4209986
Policy mu Mean               0.035516363
Policy mu Std                0.8911105
Policy mu Max                3.8539643
Policy mu Min                -3.1948836
Policy log std Mean          -0.5160196
Policy log std Std           0.29072127
Policy log std Max           0.091507375
Policy log std Min           -2.7668412
Z mean eval                  1.8179731
Z variance eval              0.03804742
total_rewards                [9945.8806471  9874.97436651 9465.54198735 9763.76761406 9819.5391115
 9812.33818263 9703.61615315 9785.79274391 9802.25489227 9614.38479763]
total_rewards_mean           9758.809049612424
total_rewards_std            129.4581440029693
total_rewards_max            9945.880647102043
total_rewards_min            9465.541987351919
Number of train steps total  1288000
Number of env steps total    3866000
Number of rollouts total     0
Train Time (s)               146.68735046684742
(Previous) Eval Time (s)     20.63172680605203
Sample Time (s)              6.613966029603034
Epoch Time (s)               173.93304330250248
Total Train Time (s)         55069.29437848274
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:11:28.476901 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #321 | Epoch Duration: 174.01710486412048
2020-01-12 23:11:28.477043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #321 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8166513
Z variance train             0.038317334
KL Divergence                46.796886
KL Loss                      4.679689
QF Loss                      162.21094
VF Loss                      57.69388
Policy Loss                  -1267.4938
Q Predictions Mean           1264.154
Q Predictions Std            1229.0376
Q Predictions Max            4502.2944
Q Predictions Min            627.0964
V Predictions Mean           1269.1566
V Predictions Std            1232.9266
V Predictions Max            4494.0605
V Predictions Min            634.14105
Log Pis Mean                 -0.46615365
Log Pis Std                  3.753073
Log Pis Max                  18.552597
Log Pis Min                  -7.2546434
Policy mu Mean               0.035747185
Policy mu Std                0.8575909
Policy mu Max                3.3654106
Policy mu Min                -3.264254
Policy log std Mean          -0.4954169
Policy log std Std           0.28197476
Policy log std Max           0.123829424
Policy log std Min           -2.4824643
Z mean eval                  1.8378938
Z variance eval              0.035229467
total_rewards                [10324.57758033  9747.52261899 10119.68082762  9944.67272504
  9906.82975509  9918.00824619  9890.95708219 10080.13762785
  9993.69216219  9859.33627466]
total_rewards_mean           9978.541490015134
total_rewards_std            153.43310494035367
total_rewards_max            10324.57758033226
total_rewards_min            9747.522618988236
Number of train steps total  1292000
Number of env steps total    3878000
Number of rollouts total     0
Train Time (s)               146.63254825398326
(Previous) Eval Time (s)     20.88586122682318
Sample Time (s)              6.348956322297454
Epoch Time (s)               173.8673658031039
Total Train Time (s)         55243.24179429794
Epoch                        322
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:14:22.426554 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #322 | Epoch Duration: 173.94941449165344
2020-01-12 23:14:22.426706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #322 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8354524
Z variance train             0.035291873
KL Divergence                46.701706
KL Loss                      4.670171
QF Loss                      3749.7876
VF Loss                      121.99382
Policy Loss                  -1243.1213
Q Predictions Mean           1243.5635
Q Predictions Std            1204.2931
Q Predictions Max            4582.2383
Q Predictions Min            651.9841
V Predictions Mean           1250.9438
V Predictions Std            1209.0864
V Predictions Max            4561.851
V Predictions Min            660.2693
Log Pis Mean                 -0.64009196
Log Pis Std                  3.8796325
Log Pis Max                  18.694765
Log Pis Min                  -7.5491266
Policy mu Mean               0.004742379
Policy mu Std                0.8411301
Policy mu Max                2.8816638
Policy mu Min                -2.8058934
Policy log std Mean          -0.49778786
Policy log std Std           0.24876657
Policy log std Max           -0.08993882
Policy log std Min           -2.8222978
Z mean eval                  1.8086367
Z variance eval              0.062253065
total_rewards                [ 9364.36959992  9673.79740586  9690.45054656 10092.37258081
 10087.32805781  9950.09617363  9561.96115514  9586.88468048
  9896.14996053  9609.19845112]
total_rewards_mean           9751.260861186918
total_rewards_std            230.70450009913333
total_rewards_max            10092.372580810903
total_rewards_min            9364.369599920608
Number of train steps total  1296000
Number of env steps total    3890000
Number of rollouts total     0
Train Time (s)               147.6890561892651
(Previous) Eval Time (s)     20.829177561216056
Sample Time (s)              6.518782259896398
Epoch Time (s)               175.03701601037756
Total Train Time (s)         55418.384355042595
Epoch                        323
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:17:17.571668 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #323 | Epoch Duration: 175.14485335350037
2020-01-12 23:17:17.571819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8083346
Z variance train             0.062205404
KL Divergence                45.60729
KL Loss                      4.560729
QF Loss                      219.96854
VF Loss                      90.42331
Policy Loss                  -1169.7908
Q Predictions Mean           1165.4143
Q Predictions Std            1136.1155
Q Predictions Max            4488.367
Q Predictions Min            624.08887
V Predictions Mean           1172.4409
V Predictions Std            1137.0585
V Predictions Max            4499.5356
V Predictions Min            644.8678
Log Pis Mean                 -0.62989783
Log Pis Std                  3.765229
Log Pis Max                  15.310375
Log Pis Min                  -9.1012745
Policy mu Mean               0.027270874
Policy mu Std                0.83733624
Policy mu Max                2.8599894
Policy mu Min                -2.9920173
Policy log std Mean          -0.48343506
Policy log std Std           0.27185768
Policy log std Max           0.05000502
Policy log std Min           -2.7499425
Z mean eval                  1.8248799
Z variance eval              0.0763
total_rewards                [ 9892.4092187   9971.35117857  9853.27197143  9828.57580705
  9900.41909857  9911.41938252 10035.90893349  9865.60999454
  9741.51747475  9533.69501514]
total_rewards_mean           9853.417807475016
total_rewards_std            130.31311115648865
total_rewards_max            10035.908933488208
total_rewards_min            9533.695015139674
Number of train steps total  1300000
Number of env steps total    3902000
Number of rollouts total     0
Train Time (s)               146.7134806108661
(Previous) Eval Time (s)     20.559383395127952
Sample Time (s)              6.516948052216321
Epoch Time (s)               173.78981205821037
Total Train Time (s)         55592.26152543817
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:20:11.456507 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #324 | Epoch Duration: 173.88453364372253
2020-01-12 23:20:11.456836 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.824578
Z variance train             0.07611875
KL Divergence                44.313255
KL Loss                      4.4313254
QF Loss                      4079.2651
VF Loss                      40.483707
Policy Loss                  -1346.5663
Q Predictions Mean           1344.0398
Q Predictions Std            1286.3104
Q Predictions Max            4565.155
Q Predictions Min            655.9565
V Predictions Mean           1348.6931
V Predictions Std            1291.4928
V Predictions Max            4569.228
V Predictions Min            655.8736
Log Pis Mean                 -0.3258282
Log Pis Std                  3.8476388
Log Pis Max                  16.461363
Log Pis Min                  -6.07214
Policy mu Mean               -0.015268292
Policy mu Std                0.8731474
Policy mu Max                2.870411
Policy mu Min                -2.8070865
Policy log std Mean          -0.4968016
Policy log std Std           0.2829678
Policy log std Max           0.009041667
Policy log std Min           -2.5800118
Z mean eval                  1.8339853
Z variance eval              0.048369553
total_rewards                [7655.44047983 5752.84510276 8559.55563506 7890.42663897 3040.70451243
 7870.0596186  7569.77741771 7917.78743226 8532.0049641  8137.33023499]
total_rewards_mean           7292.593203670394
total_rewards_std            1599.8289582962095
total_rewards_max            8559.55563505779
total_rewards_min            3040.7045124277797
Number of train steps total  1304000
Number of env steps total    3914000
Number of rollouts total     0
Train Time (s)               146.01165640726686
(Previous) Eval Time (s)     20.78400301700458
Sample Time (s)              6.601574673783034
Epoch Time (s)               173.39723409805447
Total Train Time (s)         55766.02625609469
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:23:05.224548 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #325 | Epoch Duration: 173.7674684524536
2020-01-12 23:23:05.224745 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #325 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.83335
Z variance train             0.048315912
KL Divergence                46.083607
KL Loss                      4.608361
QF Loss                      272.6649
VF Loss                      57.4078
Policy Loss                  -1392.077
Q Predictions Mean           1388.9653
Q Predictions Std            1345.9608
Q Predictions Max            4531.745
Q Predictions Min            637.5959
V Predictions Mean           1388.9434
V Predictions Std            1342.5558
V Predictions Max            4516.3325
V Predictions Min            640.2321
Log Pis Mean                 -0.2535825
Log Pis Std                  3.7412157
Log Pis Max                  14.947681
Log Pis Min                  -5.9983234
Policy mu Mean               0.07919838
Policy mu Std                0.87431127
Policy mu Max                3.9232395
Policy mu Min                -2.6082172
Policy log std Mean          -0.50824887
Policy log std Std           0.28710547
Policy log std Max           0.22171384
Policy log std Min           -2.534364
Z mean eval                  1.8194473
Z variance eval              0.07984494
total_rewards                [10063.14229088  9940.3528517  10046.05435381  9908.10160264
  9960.34000501 10107.06768307 10185.11390055 10397.75163036
 10187.67057373 10104.26286518]
total_rewards_mean           10089.985775691639
total_rewards_std            137.38178946202942
total_rewards_max            10397.751630356837
total_rewards_min            9908.101602641507
Number of train steps total  1308000
Number of env steps total    3926000
Number of rollouts total     0
Train Time (s)               146.93553664395586
(Previous) Eval Time (s)     20.508644022978842
Sample Time (s)              6.509763809386641
Epoch Time (s)               173.95394447632134
Total Train Time (s)         55940.234440295026
Epoch                        326
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:25:59.438673 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #326 | Epoch Duration: 174.21376419067383
2020-01-12 23:25:59.438873 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8189042
Z variance train             0.07992017
KL Divergence                45.821995
KL Loss                      4.5821996
QF Loss                      146.47086
VF Loss                      42.22112
Policy Loss                  -1228.2992
Q Predictions Mean           1226.2246
Q Predictions Std            1174.9176
Q Predictions Max            4474.378
Q Predictions Min            661.18445
V Predictions Mean           1230.5381
V Predictions Std            1176.1594
V Predictions Max            4475.9336
V Predictions Min            668.0647
Log Pis Mean                 -0.56933665
Log Pis Std                  3.4682748
Log Pis Max                  13.844731
Log Pis Min                  -7.5461383
Policy mu Mean               0.0020708367
Policy mu Std                0.8483383
Policy mu Max                2.5388198
Policy mu Min                -2.4788399
Policy log std Mean          -0.5099029
Policy log std Std           0.27827972
Policy log std Max           0.07713896
Policy log std Min           -2.617006
Z mean eval                  1.8621187
Z variance eval              0.10776566
total_rewards                [9241.51869715 3750.86294603 9006.04338385 8891.87885532 8894.85209663
 9009.60803255 9293.76660356 9310.69979682 8829.51996668 8875.65679257]
total_rewards_mean           8510.440717116897
total_rewards_std            1595.7857354363714
total_rewards_max            9310.699796821307
total_rewards_min            3750.862946033172
Number of train steps total  1312000
Number of env steps total    3938000
Number of rollouts total     0
Train Time (s)               146.30824392288923
(Previous) Eval Time (s)     18.241675504948944
Sample Time (s)              6.395097536034882
Epoch Time (s)               170.94501696387306
Total Train Time (s)         56111.26459609019
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:28:50.474419 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #327 | Epoch Duration: 171.0354037284851
2020-01-12 23:28:50.474589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #327 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8620383
Z variance train             0.10790123
KL Divergence                45.431343
KL Loss                      4.543134
QF Loss                      3862.7185
VF Loss                      117.93612
Policy Loss                  -1409.451
Q Predictions Mean           1407.2874
Q Predictions Std            1346.8794
Q Predictions Max            4481.8667
Q Predictions Min            654.284
V Predictions Mean           1402.6877
V Predictions Std            1339.959
V Predictions Max            4457.3203
V Predictions Min            659.0607
Log Pis Mean                 -0.29728281
Log Pis Std                  3.7960358
Log Pis Max                  13.533589
Log Pis Min                  -8.252262
Policy mu Mean               -0.026726743
Policy mu Std                0.88632685
Policy mu Max                2.708605
Policy mu Min                -3.2168474
Policy log std Mean          -0.5095651
Policy log std Std           0.27818924
Policy log std Max           -0.0018121004
Policy log std Min           -2.2883432
Z mean eval                  1.8313675
Z variance eval              0.07746356
total_rewards                [ 9838.81789946  9850.49985032  9562.76617602  9785.03172767
  9922.33499537  9945.62468608  9931.15896608  9958.00504511
 10205.32443795  9784.17587104]
total_rewards_mean           9878.373965510118
total_rewards_std            155.5683733692212
total_rewards_max            10205.324437951118
total_rewards_min            9562.766176021874
Number of train steps total  1316000
Number of env steps total    3950000
Number of rollouts total     0
Train Time (s)               147.5890951338224
(Previous) Eval Time (s)     20.83732996881008
Sample Time (s)              6.566782809328288
Epoch Time (s)               174.99320791196078
Total Train Time (s)         56286.33895621169
Epoch                        328
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:31:45.552509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #328 | Epoch Duration: 175.07779264450073
2020-01-12 23:31:45.552643 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #328 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8293676
Z variance train             0.077918395
KL Divergence                46.89896
KL Loss                      4.689896
QF Loss                      138.33032
VF Loss                      128.92958
Policy Loss                  -1319.5686
Q Predictions Mean           1314.9475
Q Predictions Std            1260.4956
Q Predictions Max            4476.746
Q Predictions Min            639.8118
V Predictions Mean           1325.3961
V Predictions Std            1262.5817
V Predictions Max            4491.972
V Predictions Min            631.5764
Log Pis Mean                 0.08046979
Log Pis Std                  3.886015
Log Pis Max                  15.821927
Log Pis Min                  -7.590043
Policy mu Mean               0.09035381
Policy mu Std                0.8972683
Policy mu Max                4.14953
Policy mu Min                -3.5200028
Policy log std Mean          -0.54867506
Policy log std Std           0.31237826
Policy log std Max           -0.03648019
Policy log std Min           -2.7964916
Z mean eval                  1.8025023
Z variance eval              0.110143624
total_rewards                [ 9909.14046996 10338.47805041 10087.04965074 10208.8109192
  9973.00429657 10130.07544009 10150.05962816  9641.31886906
 10140.02985021  9621.06639731]
total_rewards_mean           10019.903357169329
total_rewards_std            224.06662362382178
total_rewards_max            10338.478050408634
total_rewards_min            9621.066397310584
Number of train steps total  1320000
Number of env steps total    3962000
Number of rollouts total     0
Train Time (s)               146.94836933119223
(Previous) Eval Time (s)     17.24934294912964
Sample Time (s)              6.405183338560164
Epoch Time (s)               170.60289561888203
Total Train Time (s)         56457.02025509672
Epoch                        329
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:34:36.237303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #329 | Epoch Duration: 170.68454885482788
2020-01-12 23:34:36.237476 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8021635
Z variance train             0.110085115
KL Divergence                46.6348
KL Loss                      4.6634803
QF Loss                      3838.9453
VF Loss                      60.507942
Policy Loss                  -1221.7848
Q Predictions Mean           1216.9954
Q Predictions Std            1161.827
Q Predictions Max            4548.9717
Q Predictions Min            519.55835
V Predictions Mean           1218.295
V Predictions Std            1161.3622
V Predictions Max            4540.39
V Predictions Min            526.74536
Log Pis Mean                 -0.5185359
Log Pis Std                  3.8059914
Log Pis Max                  12.619298
Log Pis Min                  -6.8114953
Policy mu Mean               0.07273104
Policy mu Std                0.83797127
Policy mu Max                3.2814226
Policy mu Min                -2.7174768
Policy log std Mean          -0.5144411
Policy log std Std           0.30123442
Policy log std Max           0.038885415
Policy log std Min           -2.8665273
Z mean eval                  1.8286982
Z variance eval              0.07674527
total_rewards                [9049.59526166 9527.78907598 9320.7703519  9524.09966737 9393.69055367
 9638.03030938 9565.3394443  9260.89437662 9318.62315743 9506.10269979]
total_rewards_mean           9410.493489810211
total_rewards_std            167.61747429416508
total_rewards_max            9638.030309378453
total_rewards_min            9049.595261660394
Number of train steps total  1324000
Number of env steps total    3974000
Number of rollouts total     0
Train Time (s)               146.55700511205941
(Previous) Eval Time (s)     20.7774381400086
Sample Time (s)              6.404016450513154
Epoch Time (s)               173.73845970258117
Total Train Time (s)         56630.84298846731
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:37:30.064240 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #330 | Epoch Duration: 173.82656383514404
2020-01-12 23:37:30.064531 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #330 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8327217
Z variance train             0.07668658
KL Divergence                47.327793
KL Loss                      4.7327795
QF Loss                      131.69771
VF Loss                      118.96875
Policy Loss                  -1238.0488
Q Predictions Mean           1235.5544
Q Predictions Std            1173.2623
Q Predictions Max            4517.8545
Q Predictions Min            652.6937
V Predictions Mean           1232.993
V Predictions Std            1166.9231
V Predictions Max            4506.5273
V Predictions Min            642.2624
Log Pis Mean                 -0.6541594
Log Pis Std                  3.5114238
Log Pis Max                  14.2097435
Log Pis Min                  -8.389521
Policy mu Mean               -0.008253339
Policy mu Std                0.8160523
Policy mu Max                2.4989476
Policy mu Min                -2.8821933
Policy log std Mean          -0.50788605
Policy log std Std           0.2767612
Policy log std Max           0.00046658516
Policy log std Min           -2.44751
Z mean eval                  1.8329633
Z variance eval              0.07045446
total_rewards                [ 9399.23851361 10194.91122584 10156.42956264  9849.88943468
  9927.27515143  9871.94254234  9801.21662823 10060.54163895
  9786.2688524  10018.52121967]
total_rewards_mean           9906.623476979918
total_rewards_std            216.7044445528123
total_rewards_max            10194.91122584031
total_rewards_min            9399.23851361444
Number of train steps total  1328000
Number of env steps total    3986000
Number of rollouts total     0
Train Time (s)               146.25544716976583
(Previous) Eval Time (s)     20.822639302816242
Sample Time (s)              6.446203996427357
Epoch Time (s)               173.52429046900943
Total Train Time (s)         56804.452338489704
Epoch                        331
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:40:23.674884 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #331 | Epoch Duration: 173.61017775535583
2020-01-12 23:40:23.675067 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #331 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8351854
Z variance train             0.07059305
KL Divergence                46.512833
KL Loss                      4.6512833
QF Loss                      241.54883
VF Loss                      36.29786
Policy Loss                  -1485.35
Q Predictions Mean           1481.7775
Q Predictions Std            1384.3191
Q Predictions Max            4472.8604
Q Predictions Min            656.1197
V Predictions Mean           1484.6603
V Predictions Std            1380.6879
V Predictions Max            4462.073
V Predictions Min            653.49884
Log Pis Mean                 -0.13280942
Log Pis Std                  3.8704088
Log Pis Max                  14.194908
Log Pis Min                  -5.9922967
Policy mu Mean               0.06215481
Policy mu Std                0.91108334
Policy mu Max                3.771106
Policy mu Min                -3.0158763
Policy log std Mean          -0.5221524
Policy log std Std           0.30045345
Policy log std Max           -0.09355542
Policy log std Min           -2.6785421
Z mean eval                  1.8152514
Z variance eval              0.074680954
total_rewards                [ 9963.77490107  9777.47015837  9964.98752385 10008.18482827
  9874.83367309  9843.0457182  10226.85463583  9677.31024158
 10123.99944561  9720.46463652]
total_rewards_mean           9918.092576239893
total_rewards_std            165.66388753727935
total_rewards_max            10226.854635834668
total_rewards_min            9677.310241581643
Number of train steps total  1332000
Number of env steps total    3998000
Number of rollouts total     0
Train Time (s)               147.5805674381554
(Previous) Eval Time (s)     20.908862388692796
Sample Time (s)              6.411856855265796
Epoch Time (s)               174.901286682114
Total Train Time (s)         56979.43693455914
Epoch                        332
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:43:18.662911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #332 | Epoch Duration: 174.98767066001892
2020-01-12 23:43:18.663145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8155787
Z variance train             0.074708626
KL Divergence                45.998295
KL Loss                      4.5998297
QF Loss                      4199.7236
VF Loss                      67.31695
Policy Loss                  -1139.9938
Q Predictions Mean           1137.4448
Q Predictions Std            1102.211
Q Predictions Max            4524.96
Q Predictions Min            663.6632
V Predictions Mean           1134.7856
V Predictions Std            1098.5431
V Predictions Max            4503.7886
V Predictions Min            659.7857
Log Pis Mean                 -0.95836425
Log Pis Std                  3.4024549
Log Pis Max                  12.790806
Log Pis Min                  -7.2361484
Policy mu Mean               0.05909562
Policy mu Std                0.8093788
Policy mu Max                2.4893606
Policy mu Min                -2.5540988
Policy log std Mean          -0.49387464
Policy log std Std           0.2612322
Policy log std Max           0.051922023
Policy log std Min           -2.625378
Z mean eval                  1.8061682
Z variance eval              0.09122591
total_rewards                [8656.18276164 9305.82778496 8930.2450811  9255.37823156 9185.96769367
 8978.52340445 9263.97839126 9063.84823882 9305.93179412 8970.64600582]
total_rewards_mean           9091.652938739786
total_rewards_std            200.27092675845572
total_rewards_max            9305.931794122962
total_rewards_min            8656.182761637829
Number of train steps total  1336000
Number of env steps total    4010000
Number of rollouts total     0
Train Time (s)               146.27871873276308
(Previous) Eval Time (s)     21.430413161870092
Sample Time (s)              6.606893048156053
Epoch Time (s)               174.31602494278923
Total Train Time (s)         57153.83585699415
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:46:13.063789 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #333 | Epoch Duration: 174.4005160331726
2020-01-12 23:46:13.063923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8060621
Z variance train             0.090751484
KL Divergence                43.99221
KL Loss                      4.399221
QF Loss                      189.6778
VF Loss                      225.8501
Policy Loss                  -1379.4615
Q Predictions Mean           1381.2661
Q Predictions Std            1322.3804
Q Predictions Max            4603.777
Q Predictions Min            679.93726
V Predictions Mean           1390.5798
V Predictions Std            1322.4695
V Predictions Max            4624.897
V Predictions Min            678.6757
Log Pis Mean                 -0.04936929
Log Pis Std                  4.065462
Log Pis Max                  14.215408
Log Pis Min                  -7.295275
Policy mu Mean               -0.023982817
Policy mu Std                0.89597714
Policy mu Max                2.9063976
Policy mu Min                -2.9195757
Policy log std Mean          -0.49305758
Policy log std Std           0.30590767
Policy log std Max           -0.013739824
Policy log std Min           -2.6469064
Z mean eval                  1.8217099
Z variance eval              0.0866249
total_rewards                [9580.36897603 9594.23251819 9605.31125362 9773.97632217 9496.26255874
 9665.75294844 9629.98851816 9721.04508397 9869.70411517 9507.01992551]
total_rewards_mean           9644.366222000903
total_rewards_std            110.9291345903558
total_rewards_max            9869.704115172895
total_rewards_min            9496.26255873641
Number of train steps total  1340000
Number of env steps total    4022000
Number of rollouts total     0
Train Time (s)               145.47550945496187
(Previous) Eval Time (s)     17.272665590047836
Sample Time (s)              6.3704776600934565
Epoch Time (s)               169.11865270510316
Total Train Time (s)         57323.03227137448
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:49:02.263382 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #334 | Epoch Duration: 169.19934558868408
2020-01-12 23:49:02.263566 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #334 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8212506
Z variance train             0.08680912
KL Divergence                44.48769
KL Loss                      4.448769
QF Loss                      2997.9644
VF Loss                      93.59709
Policy Loss                  -1387.5334
Q Predictions Mean           1386.2847
Q Predictions Std            1320.0217
Q Predictions Max            4632.7114
Q Predictions Min            662.24976
V Predictions Mean           1389.9861
V Predictions Std            1316.5831
V Predictions Max            4630.9185
V Predictions Min            665.3816
Log Pis Mean                 -0.08654553
Log Pis Std                  4.1824265
Log Pis Max                  19.767733
Log Pis Min                  -9.237613
Policy mu Mean               -0.016641228
Policy mu Std                0.90480673
Policy mu Max                3.6595688
Policy mu Min                -3.7621388
Policy log std Mean          -0.5036669
Policy log std Std           0.30933473
Policy log std Max           0.10315621
Policy log std Min           -2.5682952
Z mean eval                  1.8208838
Z variance eval              0.09730226
total_rewards                [10076.68707859  9842.32336811 10144.07154159  9807.73536395
 10094.99276842  9938.99162073 10109.12612744  9698.63475731
 10026.61918312  9779.66698719]
total_rewards_mean           9951.884879643836
total_rewards_std            151.67230023900407
total_rewards_max            10144.071541586107
total_rewards_min            9698.634757309357
Number of train steps total  1344000
Number of env steps total    4034000
Number of rollouts total     0
Train Time (s)               150.32923045614734
(Previous) Eval Time (s)     20.636019038967788
Sample Time (s)              6.561267789918929
Epoch Time (s)               177.52651728503406
Total Train Time (s)         57500.636335468385
Epoch                        335
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:51:59.869575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #335 | Epoch Duration: 177.605877161026
2020-01-12 23:51:59.869716 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #335 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8201965
Z variance train             0.09715905
KL Divergence                45.08085
KL Loss                      4.508085
QF Loss                      3876.1233
VF Loss                      54.064537
Policy Loss                  -1275.8412
Q Predictions Mean           1273.0046
Q Predictions Std            1224.116
Q Predictions Max            4494.3647
Q Predictions Min            640.3293
V Predictions Mean           1276.7845
V Predictions Std            1222.8495
V Predictions Max            4481.308
V Predictions Min            635.97455
Log Pis Mean                 -0.3021875
Log Pis Std                  3.926213
Log Pis Max                  13.239311
Log Pis Min                  -6.6824846
Policy mu Mean               -0.0022186302
Policy mu Std                0.8739285
Policy mu Max                2.9330559
Policy mu Min                -2.74411
Policy log std Mean          -0.50017446
Policy log std Std           0.29791358
Policy log std Max           0.046095908
Policy log std Min           -2.6930082
Z mean eval                  1.8246889
Z variance eval              0.07085391
total_rewards                [ 9730.15613255  9812.13415365  9857.57735841 10323.45587015
 10065.36047988 10176.73462023 10126.22136555  9812.27137845
  9922.87451305 10046.41530766]
total_rewards_mean           9987.320117959995
total_rewards_std            180.60817036202104
total_rewards_max            10323.455870148886
total_rewards_min            9730.156132553591
Number of train steps total  1348000
Number of env steps total    4046000
Number of rollouts total     0
Train Time (s)               145.4739891490899
(Previous) Eval Time (s)     20.769424594007432
Sample Time (s)              6.486803446430713
Epoch Time (s)               172.73021718952805
Total Train Time (s)         57673.643714384176
Epoch                        336
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:54:52.884071 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #336 | Epoch Duration: 173.014244556427
2020-01-12 23:54:52.884253 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #336 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.824501
Z variance train             0.07071011
KL Divergence                45.61443
KL Loss                      4.561443
QF Loss                      85.25052
VF Loss                      48.875824
Policy Loss                  -1370.4395
Q Predictions Mean           1368.4302
Q Predictions Std            1328.7148
Q Predictions Max            4577.7383
Q Predictions Min            669.1449
V Predictions Mean           1371.7151
V Predictions Std            1328.5729
V Predictions Max            4549.5093
V Predictions Min            672.7522
Log Pis Mean                 -0.400388
Log Pis Std                  3.6268806
Log Pis Max                  12.760285
Log Pis Min                  -6.7662034
Policy mu Mean               -0.0032765232
Policy mu Std                0.8468688
Policy mu Max                3.3513446
Policy mu Min                -2.7041373
Policy log std Mean          -0.5001902
Policy log std Std           0.27603158
Policy log std Max           0.05202961
Policy log std Min           -2.622629
Z mean eval                  1.8296293
Z variance eval              0.094293915
total_rewards                [ 9631.65818954  9928.71277106  9845.66783413 10031.04288806
 10065.93011192  9775.85204384 10113.9492131   9946.52752081
 10057.86276787  9785.65739573]
total_rewards_mean           9918.286073606843
total_rewards_std            147.81462918669575
total_rewards_max            10113.949213101807
total_rewards_min            9631.658189540587
Number of train steps total  1352000
Number of env steps total    4058000
Number of rollouts total     0
Train Time (s)               148.26231301994994
(Previous) Eval Time (s)     20.64838545070961
Sample Time (s)              6.387514457572252
Epoch Time (s)               175.2982129282318
Total Train Time (s)         57849.02417322993
Epoch                        337
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:57:48.268345 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #337 | Epoch Duration: 175.38394713401794
2020-01-12 23:57:48.268534 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #337 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8250828
Z variance train             0.094017506
KL Divergence                44.817734
KL Loss                      4.4817734
QF Loss                      4183.844
VF Loss                      72.870056
Policy Loss                  -1231.5205
Q Predictions Mean           1232.4106
Q Predictions Std            1214.4067
Q Predictions Max            4522.7876
Q Predictions Min            658.5801
V Predictions Mean           1236.3867
V Predictions Std            1213.8818
V Predictions Max            4519.9517
V Predictions Min            654.58514
Log Pis Mean                 -0.69964486
Log Pis Std                  3.683207
Log Pis Max                  14.469589
Log Pis Min                  -7.6673164
Policy mu Mean               0.039348017
Policy mu Std                0.8262759
Policy mu Max                2.5949953
Policy mu Min                -2.9042504
Policy log std Mean          -0.48851028
Policy log std Std           0.2957867
Policy log std Max           0.16578472
Policy log std Min           -2.82328
Z mean eval                  1.8247025
Z variance eval              0.062182963
total_rewards                [ 9539.86456534  9697.00914038  9626.64320358  9529.56695084
 10016.31351664  9869.92514756  9563.22733402  9802.43377464
  9701.08057946  9410.98855929]
total_rewards_mean           9675.705277176205
total_rewards_std            171.9987291747585
total_rewards_max            10016.313516643248
total_rewards_min            9410.98855929051
Number of train steps total  1356000
Number of env steps total    4070000
Number of rollouts total     0
Train Time (s)               147.1937460140325
(Previous) Eval Time (s)     20.916537881828845
Sample Time (s)              6.33578815497458
Epoch Time (s)               174.44607205083594
Total Train Time (s)         58023.614666817244
Epoch                        338
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:00:42.861713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #338 | Epoch Duration: 174.59305262565613
2020-01-13 00:00:42.861861 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8255999
Z variance train             0.0622875
KL Divergence                45.940117
KL Loss                      4.594012
QF Loss                      1009.62006
VF Loss                      67.70579
Policy Loss                  -1332.5548
Q Predictions Mean           1329.6956
Q Predictions Std            1272.8235
Q Predictions Max            4699.8286
Q Predictions Min            647.429
V Predictions Mean           1332.437
V Predictions Std            1270.4755
V Predictions Max            4676.386
V Predictions Min            672.6284
Log Pis Mean                 -0.11108866
Log Pis Std                  3.7952259
Log Pis Max                  20.280216
Log Pis Min                  -5.350403
Policy mu Mean               0.021614274
Policy mu Std                0.88503253
Policy mu Max                5.219601
Policy mu Min                -2.9790115
Policy log std Mean          -0.5124027
Policy log std Std           0.2880978
Policy log std Max           0.037814856
Policy log std Min           -2.7916653
Z mean eval                  1.8409512
Z variance eval              0.06553675
total_rewards                [9624.70690371 9884.88730146 9916.69437527 9872.98334827 9952.02085798
 9862.52642801 9925.1325537  9872.14114155 9627.83233539 9877.86008259]
total_rewards_mean           9841.678532792164
total_rewards_std            110.94726761029656
total_rewards_max            9952.020857981466
total_rewards_min            9624.70690370725
Number of train steps total  1360000
Number of env steps total    4082000
Number of rollouts total     0
Train Time (s)               147.41266050515696
(Previous) Eval Time (s)     17.556980613153428
Sample Time (s)              6.339962052181363
Epoch Time (s)               171.30960317049176
Total Train Time (s)         58194.998364359606
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:03:34.248746 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #339 | Epoch Duration: 171.3867838382721
2020-01-13 00:03:34.248865 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8405278
Z variance train             0.065351084
KL Divergence                46.034184
KL Loss                      4.6034184
QF Loss                      138.38667
VF Loss                      70.109726
Policy Loss                  -1401.8776
Q Predictions Mean           1400.2915
Q Predictions Std            1347.1049
Q Predictions Max            4559.214
Q Predictions Min            650.71814
V Predictions Mean           1396.9766
V Predictions Std            1342.2205
V Predictions Max            4536.4253
V Predictions Min            655.40533
Log Pis Mean                 -0.23670647
Log Pis Std                  4.1280675
Log Pis Max                  15.618782
Log Pis Min                  -8.191832
Policy mu Mean               0.065535516
Policy mu Std                0.8892071
Policy mu Max                2.897707
Policy mu Min                -3.1344872
Policy log std Mean          -0.5033185
Policy log std Std           0.30009052
Policy log std Max           0.14634961
Policy log std Min           -2.7476664
Z mean eval                  1.8498852
Z variance eval              0.07301996
total_rewards                [8023.06173584 8156.78576302 8288.87301534 8330.54136651 8104.12629644
 8371.20349841 8174.80098978 8153.93947439 8255.33552314 8419.98045885]
total_rewards_mean           8227.864812170876
total_rewards_std            119.60852506659585
total_rewards_max            8419.980458845694
total_rewards_min            8023.061735839242
Number of train steps total  1364000
Number of env steps total    4094000
Number of rollouts total     0
Train Time (s)               146.22127603320405
(Previous) Eval Time (s)     20.8803131300956
Sample Time (s)              8.344155779574066
Epoch Time (s)               175.44574494287372
Total Train Time (s)         58370.52180456743
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:06:29.774582 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #340 | Epoch Duration: 175.52561902999878
2020-01-13 00:06:29.774756 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.852677
Z variance train             0.07317206
KL Divergence                46.112698
KL Loss                      4.61127
QF Loss                      221.73683
VF Loss                      47.9816
Policy Loss                  -1299.4442
Q Predictions Mean           1295.6025
Q Predictions Std            1249.2568
Q Predictions Max            4577.008
Q Predictions Min            661.2148
V Predictions Mean           1297.1434
V Predictions Std            1245.9032
V Predictions Max            4561.2017
V Predictions Min            674.25726
Log Pis Mean                 -0.38822836
Log Pis Std                  3.896987
Log Pis Max                  15.256684
Log Pis Min                  -7.558311
Policy mu Mean               -0.011467062
Policy mu Std                0.86836106
Policy mu Max                2.660948
Policy mu Min                -2.9300728
Policy log std Mean          -0.50153524
Policy log std Std           0.29677328
Policy log std Max           -0.05904159
Policy log std Min           -2.5435028
Z mean eval                  1.8404335
Z variance eval              0.11922457
total_rewards                [ 9949.17734456  9749.32314102  9965.42005497  9922.84195161
 10090.88565048 10042.02506564  9715.36662084  9884.44602747
  9915.32501267  9990.74855602]
total_rewards_mean           9922.555942527808
total_rewards_std            111.4655902011986
total_rewards_max            10090.885650483751
total_rewards_min            9715.366620836106
Number of train steps total  1368000
Number of env steps total    4106000
Number of rollouts total     0
Train Time (s)               148.3010449227877
(Previous) Eval Time (s)     20.393329040147364
Sample Time (s)              6.4877264546230435
Epoch Time (s)               175.1821004175581
Total Train Time (s)         58545.78569179773
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:09:25.045006 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #341 | Epoch Duration: 175.2701325416565
2020-01-13 00:09:25.045171 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8391638
Z variance train             0.1193429
KL Divergence                45.02854
KL Loss                      4.5028543
QF Loss                      4055.372
VF Loss                      72.47125
Policy Loss                  -1606.7693
Q Predictions Mean           1604.4607
Q Predictions Std            1460.5403
Q Predictions Max            4598.351
Q Predictions Min            657.5799
V Predictions Mean           1609.1652
V Predictions Std            1458.1654
V Predictions Max            4597.1987
V Predictions Min            663.2641
Log Pis Mean                 -0.00095997006
Log Pis Std                  4.153386
Log Pis Max                  16.298584
Log Pis Min                  -7.849018
Policy mu Mean               -0.056151617
Policy mu Std                0.9105393
Policy mu Max                2.6859853
Policy mu Min                -2.9017134
Policy log std Mean          -0.53383493
Policy log std Std           0.31036174
Policy log std Max           0.19569308
Policy log std Min           -2.6190486
Z mean eval                  1.8432564
Z variance eval              0.069820076
total_rewards                [ 9739.77145273  9634.20961977 10036.87528429  9630.93634981
  9791.43967253  9562.07171998  9804.04636005  9821.64637661
  9862.06044876  9856.17183853]
total_rewards_mean           9773.92291230462
total_rewards_std            131.59827514617575
total_rewards_max            10036.875284287935
total_rewards_min            9562.071719977088
Number of train steps total  1372000
Number of env steps total    4118000
Number of rollouts total     0
Train Time (s)               146.87822971399873
(Previous) Eval Time (s)     18.241755773779005
Sample Time (s)              6.427176746539772
Epoch Time (s)               171.5471622343175
Total Train Time (s)         58717.42795168236
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:12:16.691863 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #342 | Epoch Duration: 171.6465549468994
2020-01-13 00:12:16.692070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #342 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8436859
Z variance train             0.06977452
KL Divergence                47.05431
KL Loss                      4.705431
QF Loss                      216.69626
VF Loss                      33.445423
Policy Loss                  -1271.9297
Q Predictions Mean           1268.6332
Q Predictions Std            1242.551
Q Predictions Max            4512.7534
Q Predictions Min            650.5856
V Predictions Mean           1271.3823
V Predictions Std            1240.1438
V Predictions Max            4501.913
V Predictions Min            659.3523
Log Pis Mean                 -0.7987901
Log Pis Std                  3.4466445
Log Pis Max                  11.477796
Log Pis Min                  -6.851809
Policy mu Mean               -0.008658107
Policy mu Std                0.8267645
Policy mu Max                2.8384542
Policy mu Min                -2.871006
Policy log std Mean          -0.48863062
Policy log std Std           0.28352392
Policy log std Max           0.005528748
Policy log std Min           -2.7160075
Z mean eval                  1.8291639
Z variance eval              0.10008357
total_rewards                [ 9918.42413959 10198.88004905 10074.01287068  9736.97627757
 10131.57418062  9895.28044424  9968.31054893 10008.13868258
  9970.85469948  9993.90350788]
total_rewards_mean           9989.635540061408
total_rewards_std            122.48595176056602
total_rewards_max            10198.880049045581
total_rewards_min            9736.976277569733
Number of train steps total  1376000
Number of env steps total    4130000
Number of rollouts total     0
Train Time (s)               146.69321072567254
(Previous) Eval Time (s)     20.772946750279516
Sample Time (s)              6.493485406041145
Epoch Time (s)               173.9596428819932
Total Train Time (s)         58891.47322723316
Epoch                        343
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:15:10.739983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #343 | Epoch Duration: 174.047771692276
2020-01-13 00:15:10.740114 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8286438
Z variance train             0.10022275
KL Divergence                46.168427
KL Loss                      4.6168427
QF Loss                      189.30765
VF Loss                      56.32193
Policy Loss                  -1362.183
Q Predictions Mean           1360.7943
Q Predictions Std            1323.7476
Q Predictions Max            4488.953
Q Predictions Min            674.7807
V Predictions Mean           1364.8024
V Predictions Std            1321.1168
V Predictions Max            4502.7417
V Predictions Min            660.0426
Log Pis Mean                 -0.15203883
Log Pis Std                  3.9195986
Log Pis Max                  16.629911
Log Pis Min                  -7.454934
Policy mu Mean               0.02080444
Policy mu Std                0.90160733
Policy mu Max                3.1080942
Policy mu Min                -3.4374814
Policy log std Mean          -0.5110834
Policy log std Std           0.30277073
Policy log std Max           -0.042701185
Policy log std Min           -2.8012547
Z mean eval                  1.833217
Z variance eval              0.093521655
total_rewards                [9256.60445543 9246.75927937 9640.34548032 9391.84179435 9391.94449892
 9265.15321437 9375.99236938 9342.3712048  9525.39571121 9264.99054682]
total_rewards_mean           9370.139855497135
total_rewards_std            122.08966069483756
total_rewards_max            9640.345480315169
total_rewards_min            9246.759279371354
Number of train steps total  1380000
Number of env steps total    4142000
Number of rollouts total     0
Train Time (s)               146.74374176608399
(Previous) Eval Time (s)     17.42936285911128
Sample Time (s)              6.314222876448184
Epoch Time (s)               170.48732750164345
Total Train Time (s)         59062.28018979821
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:18:01.569327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #344 | Epoch Duration: 170.82907724380493
2020-01-13 00:18:01.569579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8334459
Z variance train             0.09328767
KL Divergence                46.81523
KL Loss                      4.6815233
QF Loss                      121.86545
VF Loss                      60.815144
Policy Loss                  -1323.2635
Q Predictions Mean           1318.1304
Q Predictions Std            1193.3145
Q Predictions Max            4491.0635
Q Predictions Min            678.69885
V Predictions Mean           1325.1672
V Predictions Std            1191.5223
V Predictions Max            4475.6978
V Predictions Min            678.47534
Log Pis Mean                 -0.36271286
Log Pis Std                  3.7822237
Log Pis Max                  19.356867
Log Pis Min                  -6.2234683
Policy mu Mean               -0.03377303
Policy mu Std                0.8807373
Policy mu Max                3.0925176
Policy mu Min                -4.3731294
Policy log std Mean          -0.5054669
Policy log std Std           0.2856803
Policy log std Max           0.48508108
Policy log std Min           -2.4486349
Z mean eval                  1.8328295
Z variance eval              0.0922366
total_rewards                [9736.86242955 9878.57574357 9904.59337075 9699.81917271 9730.37970448
 9722.66113182 9864.93294729 9855.3821113  9746.37018483 9875.98186864]
total_rewards_mean           9801.555866492736
total_rewards_std            76.0745804122873
total_rewards_max            9904.593370746583
total_rewards_min            9699.81917270711
Number of train steps total  1384000
Number of env steps total    4154000
Number of rollouts total     0
Train Time (s)               146.60409619892016
(Previous) Eval Time (s)     20.888385785743594
Sample Time (s)              6.488904841244221
Epoch Time (s)               173.98138682590798
Total Train Time (s)         59236.375948396046
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:20:55.649698 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #345 | Epoch Duration: 174.07993912696838
2020-01-13 00:20:55.649839 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8321819
Z variance train             0.092349485
KL Divergence                46.684517
KL Loss                      4.668452
QF Loss                      169.61911
VF Loss                      57.880905
Policy Loss                  -1352.8619
Q Predictions Mean           1348.4375
Q Predictions Std            1304.598
Q Predictions Max            4542.7603
Q Predictions Min            681.9153
V Predictions Mean           1353.8079
V Predictions Std            1300.7972
V Predictions Max            4522.7026
V Predictions Min            679.6164
Log Pis Mean                 -0.39963818
Log Pis Std                  4.2549896
Log Pis Max                  19.321692
Log Pis Min                  -8.390442
Policy mu Mean               0.015077568
Policy mu Std                0.8698117
Policy mu Max                3.1122491
Policy mu Min                -3.1848516
Policy log std Mean          -0.48184335
Policy log std Std           0.2779943
Policy log std Max           0.078504264
Policy log std Min           -2.5302434
Z mean eval                  1.8561354
Z variance eval              0.082350455
total_rewards                [10048.48832518 10088.67384354 10421.99805828  9844.36663651
 10063.9817483  10402.79759365 10108.34191363 10403.22093857
  9862.44634161 10388.49198999]
total_rewards_mean           10163.28073892526
total_rewards_std            213.6408136376865
total_rewards_max            10421.998058275145
total_rewards_min            9844.366636511548
Number of train steps total  1388000
Number of env steps total    4166000
Number of rollouts total     0
Train Time (s)               147.08229421125725
(Previous) Eval Time (s)     20.716909378767014
Sample Time (s)              6.587531710974872
Epoch Time (s)               174.38673530099913
Total Train Time (s)         59410.84829856083
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:23:50.125172 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #346 | Epoch Duration: 174.4752335548401
2020-01-13 00:23:50.125306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #346 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8578688
Z variance train             0.08221245
KL Divergence                47.59751
KL Loss                      4.7597513
QF Loss                      221.94824
VF Loss                      143.76259
Policy Loss                  -1492.6504
Q Predictions Mean           1485.0426
Q Predictions Std            1366.2386
Q Predictions Max            4558.7456
Q Predictions Min            668.2183
V Predictions Mean           1487.175
V Predictions Std            1357.773
V Predictions Max            4521.3438
V Predictions Min            700.5715
Log Pis Mean                 0.17247921
Log Pis Std                  4.612528
Log Pis Max                  18.49457
Log Pis Min                  -7.9665833
Policy mu Mean               0.08923557
Policy mu Std                0.93457013
Policy mu Max                3.3448257
Policy mu Min                -3.331242
Policy log std Mean          -0.5322592
Policy log std Std           0.32736325
Policy log std Max           0.054721594
Policy log std Min           -2.793089
Z mean eval                  1.8566797
Z variance eval              0.13749304
total_rewards                [ 9789.68933703  9669.31464109 10171.33931157 10157.0955964
  9833.07937579  9939.17239313  9860.84328966  9798.09725865
  9935.32733124 10105.55670162]
total_rewards_mean           9925.951523618442
total_rewards_std            161.1844812601454
total_rewards_max            10171.3393115735
total_rewards_min            9669.314641091987
Number of train steps total  1392000
Number of env steps total    4178000
Number of rollouts total     0
Train Time (s)               146.39732149569318
(Previous) Eval Time (s)     17.516058631706983
Sample Time (s)              6.571978659834713
Epoch Time (s)               170.48535878723487
Total Train Time (s)         59581.41064221552
Epoch                        347
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:26:40.689612 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #347 | Epoch Duration: 170.56421089172363
2020-01-13 00:26:40.689729 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #347 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8562987
Z variance train             0.13777256
KL Divergence                47.027695
KL Loss                      4.7027698
QF Loss                      139.17206
VF Loss                      61.147087
Policy Loss                  -1377.6332
Q Predictions Mean           1372.8462
Q Predictions Std            1276.6189
Q Predictions Max            4536.1426
Q Predictions Min            676.6622
V Predictions Mean           1378.5878
V Predictions Std            1278.0819
V Predictions Max            4529.1567
V Predictions Min            678.01465
Log Pis Mean                 -0.21583363
Log Pis Std                  3.905712
Log Pis Max                  16.519909
Log Pis Min                  -7.9273834
Policy mu Mean               0.0069204415
Policy mu Std                0.90333414
Policy mu Max                3.944686
Policy mu Min                -2.9716158
Policy log std Mean          -0.50323313
Policy log std Std           0.30059195
Policy log std Max           0.16491002
Policy log std Min           -2.562983
Z mean eval                  1.8476801
Z variance eval              0.08796762
total_rewards                [ 9893.6326677  10314.17808352 10074.3805561   9897.14385363
  9928.25860642 10027.88660459 10043.41771597  9896.35844381
 10101.21600856  9848.60103678]
total_rewards_mean           10002.507357708011
total_rewards_std            133.33729787174616
total_rewards_max            10314.178083517045
total_rewards_min            9848.601036783615
Number of train steps total  1396000
Number of env steps total    4190000
Number of rollouts total     0
Train Time (s)               144.3998355390504
(Previous) Eval Time (s)     20.72651378484443
Sample Time (s)              5.65494659403339
Epoch Time (s)               170.78129591792822
Total Train Time (s)         59752.27984481864
Epoch                        348
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:29:31.561868 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #348 | Epoch Duration: 170.87204551696777
2020-01-13 00:29:31.562000 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #348 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.847317
Z variance train             0.0878471
KL Divergence                48.395638
KL Loss                      4.839564
QF Loss                      364.64505
VF Loss                      36.31974
Policy Loss                  -1256.8934
Q Predictions Mean           1255.617
Q Predictions Std            1194.6049
Q Predictions Max            4570.4443
Q Predictions Min            688.3916
V Predictions Mean           1257.1515
V Predictions Std            1188.8682
V Predictions Max            4552.7935
V Predictions Min            692.2869
Log Pis Mean                 -0.7506112
Log Pis Std                  3.6249874
Log Pis Max                  14.195293
Log Pis Min                  -10.3397455
Policy mu Mean               0.0717719
Policy mu Std                0.83563757
Policy mu Max                3.0358732
Policy mu Min                -3.126992
Policy log std Mean          -0.48148933
Policy log std Std           0.2722331
Policy log std Max           0.01765585
Policy log std Min           -2.6362927
Z mean eval                  1.8624494
Z variance eval              0.06141011
total_rewards                [ 9881.43255477 10171.29720186  9772.88319347 10010.63195647
 10057.95672567  9826.93811936 10179.25716946  9851.81571753
 10115.16513393  9874.61113506]
total_rewards_mean           9974.198890757221
total_rewards_std            143.11728296888913
total_rewards_max            10179.25716946413
total_rewards_min            9772.883193465861
Number of train steps total  1400000
Number of env steps total    4202000
Number of rollouts total     0
Train Time (s)               145.86519985971972
(Previous) Eval Time (s)     20.902857689652592
Sample Time (s)              6.479375948663801
Epoch Time (s)               173.24743349803612
Total Train Time (s)         59925.61039251974
Epoch                        349
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:32:24.893986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #349 | Epoch Duration: 173.33189129829407
2020-01-13 00:32:24.894119 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #349 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8612331
Z variance train             0.0613809
KL Divergence                48.939754
KL Loss                      4.8939757
QF Loss                      201.48355
VF Loss                      169.38062
Policy Loss                  -1380.9829
Q Predictions Mean           1379.2739
Q Predictions Std            1312.5623
Q Predictions Max            4607.2163
Q Predictions Min            681.7146
V Predictions Mean           1389.8884
V Predictions Std            1315.8057
V Predictions Max            4635.7124
V Predictions Min            695.2076
Log Pis Mean                 -0.12871502
Log Pis Std                  3.897133
Log Pis Max                  14.942531
Log Pis Min                  -7.6354218
Policy mu Mean               0.07304492
Policy mu Std                0.91413623
Policy mu Max                3.0418255
Policy mu Min                -2.800838
Policy log std Mean          -0.51091576
Policy log std Std           0.2985345
Policy log std Max           0.04423046
Policy log std Min           -2.7122142
Z mean eval                  1.849289
Z variance eval              0.07283457
total_rewards                [ 9575.07457336  9911.81803409  9764.07129512 10263.62059012
 10031.05259721 10091.10105023  9978.61951248 10189.22572734
 10232.19481941 10036.07713881]
total_rewards_mean           10007.285533816232
total_rewards_std            203.39818509340697
total_rewards_max            10263.620590121665
total_rewards_min            9575.074573362768
Number of train steps total  1404000
Number of env steps total    4214000
Number of rollouts total     0
Train Time (s)               146.51579332724214
(Previous) Eval Time (s)     20.802566334605217
Sample Time (s)              6.556663405150175
Epoch Time (s)               173.87502306699753
Total Train Time (s)         60099.566186717246
Epoch                        350
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:35:18.853347 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #350 | Epoch Duration: 173.9591302871704
2020-01-13 00:35:18.853479 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #350 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8497334
Z variance train             0.072962254
KL Divergence                49.548218
KL Loss                      4.954822
QF Loss                      175.31404
VF Loss                      74.50957
Policy Loss                  -1515.1267
Q Predictions Mean           1512.0448
Q Predictions Std            1375.5514
Q Predictions Max            4550.8916
Q Predictions Min            685.2018
V Predictions Mean           1518.4492
V Predictions Std            1375.366
V Predictions Max            4551.167
V Predictions Min            687.09033
Log Pis Mean                 0.45178097
Log Pis Std                  4.450904
Log Pis Max                  18.46
Log Pis Min                  -6.643337
Policy mu Mean               0.02468059
Policy mu Std                0.9767721
Policy mu Max                3.108381
Policy mu Min                -3.3104708
Policy log std Mean          -0.5204467
Policy log std Std           0.30388638
Policy log std Max           -0.044879615
Policy log std Min           -2.8399036
Z mean eval                  1.8619545
Z variance eval              0.07303933
total_rewards                [ 9979.10349783 10264.60921311  9662.38602866 10071.94888796
 10076.36003757 10059.36458107  9989.6812923  10184.77317964
 10163.29496566 10095.15153305]
total_rewards_mean           10054.66732168357
total_rewards_std            154.61275739747015
total_rewards_max            10264.6092131054
total_rewards_min            9662.386028659937
Number of train steps total  1408000
Number of env steps total    4226000
Number of rollouts total     0
Train Time (s)               149.47894290694967
(Previous) Eval Time (s)     20.69077391922474
Sample Time (s)              6.454261219128966
Epoch Time (s)               176.62397804530337
Total Train Time (s)         60276.27410187572
Epoch                        351
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:38:15.564746 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #351 | Epoch Duration: 176.71116828918457
2020-01-13 00:38:15.564888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #351 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8631217
Z variance train             0.073069274
KL Divergence                49.00699
KL Loss                      4.900699
QF Loss                      142.3876
VF Loss                      73.71319
Policy Loss                  -1366.8645
Q Predictions Mean           1363.7317
Q Predictions Std            1278.6663
Q Predictions Max            4601.0967
Q Predictions Min            687.04645
V Predictions Mean           1365.3843
V Predictions Std            1273.3303
V Predictions Max            4593.2095
V Predictions Min            692.2533
Log Pis Mean                 -0.08354321
Log Pis Std                  4.1205335
Log Pis Max                  17.510796
Log Pis Min                  -8.025678
Policy mu Mean               0.083417766
Policy mu Std                0.9105896
Policy mu Max                3.5714743
Policy mu Min                -3.2962334
Policy log std Mean          -0.52076554
Policy log std Std           0.30777198
Policy log std Max           0.013059527
Policy log std Min           -2.819493
Z mean eval                  1.8504517
Z variance eval              0.07553662
total_rewards                [ 9692.10201096  9969.87007202  9715.89969848  9815.3044551
  9739.58471661  9613.31581595 10017.35727552  9919.87746519
  9818.65449238  9796.29686839]
total_rewards_mean           9809.826287058997
total_rewards_std            121.37414530727435
total_rewards_max            10017.35727552313
total_rewards_min            9613.31581595248
Number of train steps total  1412000
Number of env steps total    4238000
Number of rollouts total     0
Train Time (s)               146.28346044383943
(Previous) Eval Time (s)     20.740760545246303
Sample Time (s)              6.457725353073329
Epoch Time (s)               173.48194634215906
Total Train Time (s)         60449.85863009794
Epoch                        352
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:41:09.159346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #352 | Epoch Duration: 173.5943579673767
2020-01-13 00:41:09.159484 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #352 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8483646
Z variance train             0.07544076
KL Divergence                47.94437
KL Loss                      4.794437
QF Loss                      122.53633
VF Loss                      91.2699
Policy Loss                  -1531.867
Q Predictions Mean           1531.8639
Q Predictions Std            1408.1052
Q Predictions Max            4578.7666
Q Predictions Min            682.3524
V Predictions Mean           1526.6578
V Predictions Std            1399.3855
V Predictions Max            4558.5127
V Predictions Min            678.58826
Log Pis Mean                 0.080535874
Log Pis Std                  3.8680766
Log Pis Max                  14.609116
Log Pis Min                  -7.5763226
Policy mu Mean               0.016443362
Policy mu Std                0.9041299
Policy mu Max                2.6854074
Policy mu Min                -2.6100526
Policy log std Mean          -0.52228695
Policy log std Std           0.3077607
Policy log std Max           -0.018633366
Policy log std Min           -2.866218
Z mean eval                  1.8480438
Z variance eval              0.10293715
total_rewards                [ 9749.29482221 10152.89426882 10029.66766913  9801.08822929
  9926.55501404 10303.59222372 10051.18159903 10277.44994168
  9759.82820295 10214.72483577]
total_rewards_mean           10026.627680664235
total_rewards_std            200.13374294095095
total_rewards_max            10303.592223724412
total_rewards_min            9749.294822207728
Number of train steps total  1416000
Number of env steps total    4250000
Number of rollouts total     0
Train Time (s)               147.1821274808608
(Previous) Eval Time (s)     20.9338300623931
Sample Time (s)              6.5439105136319995
Epoch Time (s)               174.6598680568859
Total Train Time (s)         60624.602142375894
Epoch                        353
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:44:03.903043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #353 | Epoch Duration: 174.74346256256104
2020-01-13 00:44:03.903178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #353 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.848726
Z variance train             0.10251161
KL Divergence                47.63917
KL Loss                      4.7639174
QF Loss                      178.12326
VF Loss                      95.31075
Policy Loss                  -1442.6187
Q Predictions Mean           1439.0608
Q Predictions Std            1351.3805
Q Predictions Max            4561.414
Q Predictions Min            665.60114
V Predictions Mean           1438.8865
V Predictions Std            1350.205
V Predictions Max            4562.9106
V Predictions Min            689.83905
Log Pis Mean                 0.27439058
Log Pis Std                  4.2074466
Log Pis Max                  18.740677
Log Pis Min                  -8.208524
Policy mu Mean               0.11083261
Policy mu Std                0.9305595
Policy mu Max                3.0914378
Policy mu Min                -3.489496
Policy log std Mean          -0.5177876
Policy log std Std           0.29663217
Policy log std Max           0.11405349
Policy log std Min           -2.904211
Z mean eval                  1.881594
Z variance eval              0.06506904
total_rewards                [ 9775.58560389  9946.42181755 10018.1874166   9569.40172085
  9851.79930825 10098.20192068  9980.370648    9840.53365642
 10021.8291443   9954.22374534]
total_rewards_mean           9905.655498187816
total_rewards_std            144.90104147726095
total_rewards_max            10098.20192068184
total_rewards_min            9569.401720847662
Number of train steps total  1420000
Number of env steps total    4262000
Number of rollouts total     0
Train Time (s)               146.25058292178437
(Previous) Eval Time (s)     20.748722524847835
Sample Time (s)              6.500010514631867
Epoch Time (s)               173.49931596126407
Total Train Time (s)         60798.182764337864
Epoch                        354
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:46:57.485258 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #354 | Epoch Duration: 173.58198308944702
2020-01-13 00:46:57.485392 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #354 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.881538
Z variance train             0.06492968
KL Divergence                49.040997
KL Loss                      4.9041
QF Loss                      124.8899
VF Loss                      173.06395
Policy Loss                  -1229.473
Q Predictions Mean           1225.2249
Q Predictions Std            1172.5316
Q Predictions Max            4591.919
Q Predictions Min            655.1089
V Predictions Mean           1228.7463
V Predictions Std            1170.1934
V Predictions Max            4561.577
V Predictions Min            697.51636
Log Pis Mean                 -0.36916476
Log Pis Std                  3.876764
Log Pis Max                  18.25143
Log Pis Min                  -6.772699
Policy mu Mean               0.058277216
Policy mu Std                0.86661
Policy mu Max                3.0480905
Policy mu Min                -4.089854
Policy log std Mean          -0.52049613
Policy log std Std           0.29545557
Policy log std Max           -0.06434187
Policy log std Min           -2.8631225
Z mean eval                  1.8537203
Z variance eval              0.06058227
total_rewards                [ 9892.78693415  9750.10655888 10007.58970216 10324.3781215
 10204.16504838 10063.0023127  10169.78499054  9883.53248682
 10218.18426989 10045.08894906]
total_rewards_mean           10055.861937407806
total_rewards_std            169.0255170560671
total_rewards_max            10324.378121500093
total_rewards_min            9750.10655887887
Number of train steps total  1424000
Number of env steps total    4274000
Number of rollouts total     0
Train Time (s)               147.11119894869626
(Previous) Eval Time (s)     19.31167462375015
Sample Time (s)              6.345767810475081
Epoch Time (s)               172.7686413829215
Total Train Time (s)         60971.03306262847
Epoch                        355
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:49:50.341769 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #355 | Epoch Duration: 172.85626339912415
2020-01-13 00:49:50.341960 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #355 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8537728
Z variance train             0.06055795
KL Divergence                48.08824
KL Loss                      4.808824
QF Loss                      167.72624
VF Loss                      103.606026
Policy Loss                  -1349.9442
Q Predictions Mean           1347.8163
Q Predictions Std            1270.4658
Q Predictions Max            4644.329
Q Predictions Min            701.39075
V Predictions Mean           1347.0519
V Predictions Std            1269.458
V Predictions Max            4650.618
V Predictions Min            703.61804
Log Pis Mean                 -0.5167564
Log Pis Std                  3.748653
Log Pis Max                  18.7029
Log Pis Min                  -7.2248955
Policy mu Mean               0.03163379
Policy mu Std                0.8548907
Policy mu Max                3.020635
Policy mu Min                -2.6186583
Policy log std Mean          -0.50243783
Policy log std Std           0.2804168
Policy log std Max           0.075195074
Policy log std Min           -2.5525265
Z mean eval                  1.8609943
Z variance eval              0.07598624
total_rewards                [ 9635.35765255  9945.89512493 10219.18388148 10097.3103237
 10359.51130764  9982.73988636 10064.82170716  1493.34001155
  9988.05244381  9989.74257633]
total_rewards_mean           9177.595491550785
total_rewards_std            2567.6286873372906
total_rewards_max            10359.511307635656
total_rewards_min            1493.3400115500292
Number of train steps total  1428000
Number of env steps total    4286000
Number of rollouts total     0
Train Time (s)               144.66256770538166
(Previous) Eval Time (s)     20.904944290407002
Sample Time (s)              6.385996394790709
Epoch Time (s)               171.95350839057937
Total Train Time (s)         61143.07343854988
Epoch                        356
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:52:42.386135 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #356 | Epoch Duration: 172.04404473304749
2020-01-13 00:52:42.386267 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #356 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8611896
Z variance train             0.07605184
KL Divergence                47.679867
KL Loss                      4.767987
QF Loss                      102.41341
VF Loss                      44.615925
Policy Loss                  -1351.1964
Q Predictions Mean           1346.0148
Q Predictions Std            1272.4662
Q Predictions Max            4552.6587
Q Predictions Min            692.18475
V Predictions Mean           1348.2103
V Predictions Std            1270.2443
V Predictions Max            4552.68
V Predictions Min            693.6235
Log Pis Mean                 -0.16995054
Log Pis Std                  4.2517753
Log Pis Max                  20.572536
Log Pis Min                  -7.159783
Policy mu Mean               0.07527397
Policy mu Std                0.8977369
Policy mu Max                3.5874307
Policy mu Min                -3.1016245
Policy log std Mean          -0.51815176
Policy log std Std           0.30474165
Policy log std Max           0.27702963
Policy log std Min           -2.7268133
Z mean eval                  1.8264391
Z variance eval              0.08286072
total_rewards                [ 9563.60775766  9571.12015623  9977.07050095  9869.33029534
  9726.23734422  9838.94996982  9853.38106536  9772.00856347
  9580.40896966 10013.41900545]
total_rewards_mean           9776.553362817434
total_rewards_std            155.977389391517
total_rewards_max            10013.419005450085
total_rewards_min            9563.607757663869
Number of train steps total  1432000
Number of env steps total    4298000
Number of rollouts total     0
Train Time (s)               145.15819940716028
(Previous) Eval Time (s)     17.74588004918769
Sample Time (s)              6.478155167773366
Epoch Time (s)               169.38223462412134
Total Train Time (s)         61312.53783490928
Epoch                        357
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:55:31.854200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #357 | Epoch Duration: 169.4678177833557
2020-01-13 00:55:31.854380 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #357 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8244965
Z variance train             0.08283038
KL Divergence                45.287586
KL Loss                      4.5287585
QF Loss                      565.8202
VF Loss                      198.26428
Policy Loss                  -1375.8119
Q Predictions Mean           1373.8086
Q Predictions Std            1288.2517
Q Predictions Max            4712.8315
Q Predictions Min            713.46686
V Predictions Mean           1373.4158
V Predictions Std            1286.5881
V Predictions Max            4707.641
V Predictions Min            706.75323
Log Pis Mean                 -0.2391325
Log Pis Std                  4.014742
Log Pis Max                  17.647861
Log Pis Min                  -6.113115
Policy mu Mean               0.14753209
Policy mu Std                0.90652937
Policy mu Max                3.3243134
Policy mu Min                -2.7243736
Policy log std Mean          -0.50081897
Policy log std Std           0.3179667
Policy log std Max           0.020028293
Policy log std Min           -3.0257497
Z mean eval                  1.8421446
Z variance eval              0.0826164
total_rewards                [ 9669.86430105  9734.03042479  9992.33192812  9928.24122598
  9791.60967291  9957.0152517   9869.64994211  9860.45286806
 10022.95394319 10001.3248589 ]
total_rewards_mean           9882.747441680021
total_rewards_std            113.89613105986167
total_rewards_max            10022.953943187596
total_rewards_min            9669.864301047337
Number of train steps total  1436000
Number of env steps total    4310000
Number of rollouts total     0
Train Time (s)               146.02048127399758
(Previous) Eval Time (s)     20.861144644673914
Sample Time (s)              6.463406052440405
Epoch Time (s)               173.3450319711119
Total Train Time (s)         61486.077863588
Epoch                        358
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:58:25.414847 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #358 | Epoch Duration: 173.56033635139465
2020-01-13 00:58:25.415109 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #358 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8453735
Z variance train             0.082847096
KL Divergence                45.6274
KL Loss                      4.56274
QF Loss                      144.40259
VF Loss                      33.046715
Policy Loss                  -1242.2997
Q Predictions Mean           1239.3613
Q Predictions Std            1147.5435
Q Predictions Max            4612.604
Q Predictions Min            692.2751
V Predictions Mean           1243.0227
V Predictions Std            1149.7834
V Predictions Max            4602.748
V Predictions Min            700.3417
Log Pis Mean                 -0.4797287
Log Pis Std                  3.483205
Log Pis Max                  17.585466
Log Pis Min                  -7.358797
Policy mu Mean               0.010662545
Policy mu Std                0.84263384
Policy mu Max                3.5719917
Policy mu Min                -3.1559563
Policy log std Mean          -0.4629661
Policy log std Std           0.27142653
Policy log std Max           0.30314738
Policy log std Min           -2.6692352
Z mean eval                  1.8548696
Z variance eval              0.0680264
total_rewards                [ 9701.18640983  9850.2866486   9818.77297475  9761.97032535
  9817.44027499  9539.35563946  9882.56401639  9933.75798989
 10071.13100509  9777.0935673 ]
total_rewards_mean           9815.355885164772
total_rewards_std            133.68541819667448
total_rewards_max            10071.131005088248
total_rewards_min            9539.355639464899
Number of train steps total  1440000
Number of env steps total    4322000
Number of rollouts total     0
Train Time (s)               148.36556641198695
(Previous) Eval Time (s)     20.98266609897837
Sample Time (s)              6.348034780006856
Epoch Time (s)               175.69626729097217
Total Train Time (s)         61661.88767816126
Epoch                        359
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:01:21.209103 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #359 | Epoch Duration: 175.79378366470337
2020-01-13 01:01:21.209237 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8570051
Z variance train             0.06794588
KL Divergence                46.47085
KL Loss                      4.647085
QF Loss                      271.49536
VF Loss                      38.072727
Policy Loss                  -1279.5435
Q Predictions Mean           1278.6025
Q Predictions Std            1184.7512
Q Predictions Max            4488.761
Q Predictions Min            687.24774
V Predictions Mean           1279.2676
V Predictions Std            1183.8655
V Predictions Max            4477.689
V Predictions Min            694.147
Log Pis Mean                 -0.57549506
Log Pis Std                  3.497228
Log Pis Max                  12.042032
Log Pis Min                  -9.439621
Policy mu Mean               0.053488106
Policy mu Std                0.8236874
Policy mu Max                2.7926624
Policy mu Min                -2.3891802
Policy log std Mean          -0.49153543
Policy log std Std           0.29494715
Policy log std Max           0.15815002
Policy log std Min           -2.7477162
Z mean eval                  1.8577036
Z variance eval              0.077561885
total_rewards                [9909.57666816 9834.86818363 9949.27741223 9879.30276137 9597.68890918
 9641.7788345  9821.77746795 9907.42684598 9687.71375456 9810.16437416]
total_rewards_mean           9803.957521171833
total_rewards_std            115.03430179874155
total_rewards_max            9949.277412226642
total_rewards_min            9597.688909179962
Number of train steps total  1444000
Number of env steps total    4334000
Number of rollouts total     0
Train Time (s)               145.26331496797502
(Previous) Eval Time (s)     20.701958978082985
Sample Time (s)              8.133673972915858
Epoch Time (s)               174.09894791897386
Total Train Time (s)         61836.07495500101
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:04:15.398303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #360 | Epoch Duration: 174.18896770477295
2020-01-13 01:04:15.398437 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #360 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8587701
Z variance train             0.0776149
KL Divergence                47.738262
KL Loss                      4.773826
QF Loss                      8217.021
VF Loss                      88.303185
Policy Loss                  -1339.2173
Q Predictions Mean           1337.9532
Q Predictions Std            1272.3597
Q Predictions Max            4601.986
Q Predictions Min            681.8224
V Predictions Mean           1333.7246
V Predictions Std            1268.4474
V Predictions Max            4592.4478
V Predictions Min            690.299
Log Pis Mean                 -0.5095546
Log Pis Std                  3.242269
Log Pis Max                  13.790972
Log Pis Min                  -6.340557
Policy mu Mean               0.021975951
Policy mu Std                0.8417512
Policy mu Max                2.8337297
Policy mu Min                -2.7334628
Policy log std Mean          -0.49032807
Policy log std Std           0.27623418
Policy log std Max           -0.006203145
Policy log std Min           -2.6114874
Z mean eval                  1.8440173
Z variance eval              0.07079522
total_rewards                [10095.58359704  9892.28554026 10096.86166888  9783.58384837
 10153.03301476  9916.31845991  9908.50525524  9852.9577162
  9844.40684351 10094.41179203]
total_rewards_mean           9963.794773619033
total_rewards_std            125.45350548942909
total_rewards_max            10153.033014763696
total_rewards_min            9783.583848368264
Number of train steps total  1448000
Number of env steps total    4346000
Number of rollouts total     0
Train Time (s)               148.2155560622923
(Previous) Eval Time (s)     20.930695451330394
Sample Time (s)              6.528435806278139
Epoch Time (s)               175.67468731990084
Total Train Time (s)         62011.83573226398
Epoch                        361
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:07:11.162423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #361 | Epoch Duration: 175.7638909816742
2020-01-13 01:07:11.162556 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #361 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.845287
Z variance train             0.0708726
KL Divergence                47.243793
KL Loss                      4.7243795
QF Loss                      4779.64
VF Loss                      69.33417
Policy Loss                  -1353.4777
Q Predictions Mean           1349.2417
Q Predictions Std            1250.9185
Q Predictions Max            4650.763
Q Predictions Min            707.69324
V Predictions Mean           1352.9016
V Predictions Std            1248.5706
V Predictions Max            4632.3057
V Predictions Min            707.77527
Log Pis Mean                 -0.19530661
Log Pis Std                  3.6174672
Log Pis Max                  14.914707
Log Pis Min                  -8.072503
Policy mu Mean               0.013597135
Policy mu Std                0.8715546
Policy mu Max                3.0605924
Policy mu Min                -3.0696988
Policy log std Mean          -0.51542026
Policy log std Std           0.31585848
Policy log std Max           -0.02049321
Policy log std Min           -2.6551943
Z mean eval                  1.8383939
Z variance eval              0.10216625
total_rewards                [ 9747.25100703  9477.15740065 10080.50213657 10002.80695326
  9595.31095892  9947.56212868  9993.724023    9759.21599835
  9863.02002541 10096.05924423]
total_rewards_mean           9856.260987608945
total_rewards_std            197.3970716057565
total_rewards_max            10096.059244227885
total_rewards_min            9477.157400653656
Number of train steps total  1452000
Number of env steps total    4358000
Number of rollouts total     0
Train Time (s)               145.76617284491658
(Previous) Eval Time (s)     20.75638945400715
Sample Time (s)              6.541879638563842
Epoch Time (s)               173.06444193748757
Total Train Time (s)         62184.97846966004
Epoch                        362
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:10:04.308707 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #362 | Epoch Duration: 173.14603900909424
2020-01-13 01:10:04.308899 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8384529
Z variance train             0.1024044
KL Divergence                45.58058
KL Loss                      4.5580583
QF Loss                      133.00044
VF Loss                      42.49553
Policy Loss                  -1277.5936
Q Predictions Mean           1277.7207
Q Predictions Std            1247.397
Q Predictions Max            4627.6733
Q Predictions Min            653.8135
V Predictions Mean           1280.8682
V Predictions Std            1242.5782
V Predictions Max            4620.4062
V Predictions Min            668.04974
Log Pis Mean                 -0.5225414
Log Pis Std                  3.6151755
Log Pis Max                  15.953471
Log Pis Min                  -7.02795
Policy mu Mean               0.05737573
Policy mu Std                0.83457536
Policy mu Max                2.5235531
Policy mu Min                -2.6683047
Policy log std Mean          -0.4840764
Policy log std Std           0.27171406
Policy log std Max           0.03287661
Policy log std Min           -2.657131
Z mean eval                  1.8566902
Z variance eval              0.08506473
total_rewards                [8565.79282715 8302.88343846 9576.6493326  9109.76396899 3827.33942707
 8875.78086326 8969.05545795 9237.03507038 9378.76822853 8523.63027381]
total_rewards_mean           8436.669888820754
total_rewards_std            1582.5629934469673
total_rewards_max            9576.649332601366
total_rewards_min            3827.339427074365
Number of train steps total  1456000
Number of env steps total    4370000
Number of rollouts total     0
Train Time (s)               146.9422320551239
(Previous) Eval Time (s)     20.92936616158113
Sample Time (s)              6.510731665417552
Epoch Time (s)               174.38232988212258
Total Train Time (s)         62359.44496897096
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:12:58.779834 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #363 | Epoch Duration: 174.470805644989
2020-01-13 01:12:58.779978 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8551229
Z variance train             0.085217856
KL Divergence                46.51379
KL Loss                      4.651379
QF Loss                      342.4103
VF Loss                      83.01464
Policy Loss                  -1222.1837
Q Predictions Mean           1220.5872
Q Predictions Std            1195.9498
Q Predictions Max            4631.477
Q Predictions Min            680.1671
V Predictions Mean           1224.0249
V Predictions Std            1195.1599
V Predictions Max            4642.9175
V Predictions Min            684.22656
Log Pis Mean                 -0.61169064
Log Pis Std                  3.6577814
Log Pis Max                  17.333158
Log Pis Min                  -7.150735
Policy mu Mean               0.101583205
Policy mu Std                0.83461004
Policy mu Max                3.2144675
Policy mu Min                -3.449287
Policy log std Mean          -0.4916632
Policy log std Std           0.2684664
Policy log std Max           -0.07861376
Policy log std Min           -2.6627352
Z mean eval                  1.859567
Z variance eval              0.05522721
total_rewards                [9943.27879746 9670.63923683 9434.23258038 9687.51489152 9405.72400417
 9669.77246602 9489.11061962 9162.34213496 9512.58697135 9830.29684905]
total_rewards_mean           9580.549855136498
total_rewards_std            214.78238852540355
total_rewards_max            9943.278797462268
total_rewards_min            9162.34213496021
Number of train steps total  1460000
Number of env steps total    4382000
Number of rollouts total     0
Train Time (s)               145.78922959789634
(Previous) Eval Time (s)     17.723533776123077
Sample Time (s)              6.45414467016235
Epoch Time (s)               169.96690804418176
Total Train Time (s)         62529.49612938007
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:15:48.835190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #364 | Epoch Duration: 170.05509638786316
2020-01-13 01:15:48.835367 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #364 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8588616
Z variance train             0.05528129
KL Divergence                48.011845
KL Loss                      4.8011847
QF Loss                      74.914795
VF Loss                      40.457592
Policy Loss                  -1324.7317
Q Predictions Mean           1323.5712
Q Predictions Std            1271.4158
Q Predictions Max            4671.691
Q Predictions Min            682.2637
V Predictions Mean           1323.008
V Predictions Std            1268.6141
V Predictions Max            4662.07
V Predictions Min            686.58325
Log Pis Mean                 -0.7338573
Log Pis Std                  3.607448
Log Pis Max                  13.718275
Log Pis Min                  -6.3713765
Policy mu Mean               0.06573415
Policy mu Std                0.7943346
Policy mu Max                2.5968304
Policy mu Min                -2.9405835
Policy log std Mean          -0.4861773
Policy log std Std           0.30225545
Policy log std Max           0.055418193
Policy log std Min           -2.6381109
Z mean eval                  1.8443062
Z variance eval              0.08299732
total_rewards                [ 9930.12872019 10239.78987481 10144.94801141  9965.56291844
  9792.03097339  9969.65365723 10062.30892762 10152.05947373
  9679.74134765 10268.05087242]
total_rewards_mean           10020.427477688234
total_rewards_std            180.5540298975575
total_rewards_max            10268.05087242068
total_rewards_min            9679.741347654981
Number of train steps total  1464000
Number of env steps total    4394000
Number of rollouts total     0
Train Time (s)               145.89375209994614
(Previous) Eval Time (s)     20.67879368085414
Sample Time (s)              6.563134719617665
Epoch Time (s)               173.13568050041795
Total Train Time (s)         62702.712294443976
Epoch                        365
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:18:42.053651 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #365 | Epoch Duration: 173.2181534767151
2020-01-13 01:18:42.053797 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #365 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8471782
Z variance train             0.0830139
KL Divergence                45.155277
KL Loss                      4.5155277
QF Loss                      160.79004
VF Loss                      298.30127
Policy Loss                  -1340.8502
Q Predictions Mean           1338.4514
Q Predictions Std            1262.0308
Q Predictions Max            4639.7285
Q Predictions Min            684.7921
V Predictions Mean           1340.4144
V Predictions Std            1255.2847
V Predictions Max            4623.1646
V Predictions Min            686.80914
Log Pis Mean                 -0.55714285
Log Pis Std                  3.9847658
Log Pis Max                  16.713001
Log Pis Min                  -7.876581
Policy mu Mean               0.058192234
Policy mu Std                0.8638374
Policy mu Max                3.255702
Policy mu Min                -3.4209325
Policy log std Mean          -0.47455287
Policy log std Std           0.2927251
Policy log std Max           0.06737888
Policy log std Min           -2.9541752
Z mean eval                  1.8577582
Z variance eval              0.06824687
total_rewards                [ 9771.84841364  9999.29257337  9893.23563407  9651.81948039
  9967.93187405 10219.06262493  9688.88594541 10057.35887486
 10051.29446174 10041.67127106]
total_rewards_mean           9934.240115353618
total_rewards_std            171.72790601951488
total_rewards_max            10219.062624934408
total_rewards_min            9651.819480393657
Number of train steps total  1468000
Number of env steps total    4406000
Number of rollouts total     0
Train Time (s)               145.9803829290904
(Previous) Eval Time (s)     20.722102309111506
Sample Time (s)              6.420011936221272
Epoch Time (s)               173.1224971744232
Total Train Time (s)         62875.92160390457
Epoch                        366
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:21:35.265212 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #366 | Epoch Duration: 173.21131491661072
2020-01-13 01:21:35.265347 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8582951
Z variance train             0.06823022
KL Divergence                46.25193
KL Loss                      4.625193
QF Loss                      175.5272
VF Loss                      67.889244
Policy Loss                  -1338.0399
Q Predictions Mean           1333.0883
Q Predictions Std            1257.9575
Q Predictions Max            4650.99
Q Predictions Min            687.28876
V Predictions Mean           1341.875
V Predictions Std            1262.0939
V Predictions Max            4639.9214
V Predictions Min            697.07153
Log Pis Mean                 -0.4382679
Log Pis Std                  3.9304254
Log Pis Max                  15.590043
Log Pis Min                  -7.5465384
Policy mu Mean               0.04437824
Policy mu Std                0.88996184
Policy mu Max                3.4268847
Policy mu Min                -2.6872616
Policy log std Mean          -0.48115337
Policy log std Std           0.28200895
Policy log std Max           -0.037985682
Policy log std Min           -2.8382342
Z mean eval                  1.8727022
Z variance eval              0.08660668
total_rewards                [ 9608.18074917 10091.81295236  9559.31662289 10017.17175172
  9497.90592955  9681.165552    9796.67286717  9960.37888116
  9417.4091444   9394.09950056]
total_rewards_mean           9702.41139509777
total_rewards_std            239.5938252220751
total_rewards_max            10091.812952355658
total_rewards_min            9394.099500563332
Number of train steps total  1472000
Number of env steps total    4418000
Number of rollouts total     0
Train Time (s)               145.94146282412112
(Previous) Eval Time (s)     20.794119416736066
Sample Time (s)              6.479675690177828
Epoch Time (s)               173.215257931035
Total Train Time (s)         63049.21640000399
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:24:28.563087 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #367 | Epoch Duration: 173.29764342308044
2020-01-13 01:24:28.563222 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8661268
Z variance train             0.08657605
KL Divergence                46.37815
KL Loss                      4.637815
QF Loss                      456.0761
VF Loss                      257.0418
Policy Loss                  -1237.6528
Q Predictions Mean           1237.3054
Q Predictions Std            1191.8408
Q Predictions Max            4593.918
Q Predictions Min            688.1935
V Predictions Mean           1248.4353
V Predictions Std            1196.6211
V Predictions Max            4622.269
V Predictions Min            691.36316
Log Pis Mean                 -0.59966975
Log Pis Std                  3.5812612
Log Pis Max                  12.187182
Log Pis Min                  -6.73626
Policy mu Mean               0.14193697
Policy mu Std                0.82664454
Policy mu Max                2.723677
Policy mu Min                -2.5621188
Policy log std Mean          -0.47991106
Policy log std Std           0.27289647
Policy log std Max           0.089524806
Policy log std Min           -2.7199678
Z mean eval                  1.8745295
Z variance eval              0.06753503
total_rewards                [9668.54571457 9624.70882031 9744.41060742 9701.50706788 9351.1273502
 9722.06458535 9719.97601224 9662.11569554 9431.84647722 9759.89445358]
total_rewards_mean           9638.619678429579
total_rewards_std            130.56958259908316
total_rewards_max            9759.89445358119
total_rewards_min            9351.127350200124
Number of train steps total  1476000
Number of env steps total    4430000
Number of rollouts total     0
Train Time (s)               146.59506458230317
(Previous) Eval Time (s)     20.712419072631747
Sample Time (s)              6.599893202073872
Epoch Time (s)               173.90737685700879
Total Train Time (s)         63223.208734185435
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:27:22.561034 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #368 | Epoch Duration: 173.99771571159363
2020-01-13 01:27:22.561174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8746071
Z variance train             0.067481205
KL Divergence                48.04349
KL Loss                      4.8043494
QF Loss                      90.842575
VF Loss                      28.949436
Policy Loss                  -1336.3514
Q Predictions Mean           1331.6907
Q Predictions Std            1275.9974
Q Predictions Max            4610.5044
Q Predictions Min            695.4032
V Predictions Mean           1335.9102
V Predictions Std            1272.3864
V Predictions Max            4601.1685
V Predictions Min            704.2146
Log Pis Mean                 -0.6051181
Log Pis Std                  3.6131175
Log Pis Max                  12.57281
Log Pis Min                  -7.0333786
Policy mu Mean               0.015791018
Policy mu Std                0.82429963
Policy mu Max                2.682476
Policy mu Min                -2.714042
Policy log std Mean          -0.5013218
Policy log std Std           0.29751766
Policy log std Max           -0.10248256
Policy log std Min           -2.640863
Z mean eval                  1.856795
Z variance eval              0.07131281
total_rewards                [9411.26545504 9895.06028922 9484.65731087 9659.20155837 9828.95663506
 5093.93967665 9600.89659503 9930.14684252 9727.34973159 9622.25828911]
total_rewards_mean           9225.37323834521
total_rewards_std            1386.3170583669153
total_rewards_max            9930.146842517439
total_rewards_min            5093.939676650215
Number of train steps total  1480000
Number of env steps total    4442000
Number of rollouts total     0
Train Time (s)               147.3023287258111
(Previous) Eval Time (s)     17.24756547017023
Sample Time (s)              6.497730576898903
Epoch Time (s)               171.04762477288023
Total Train Time (s)         63394.33408117015
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:30:13.690867 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #369 | Epoch Duration: 171.12958002090454
2020-01-13 01:30:13.691052 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #369 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8598144
Z variance train             0.07161415
KL Divergence                49.136944
KL Loss                      4.9136944
QF Loss                      98.16275
VF Loss                      92.626656
Policy Loss                  -1349.4565
Q Predictions Mean           1349.793
Q Predictions Std            1296.2275
Q Predictions Max            4578.64
Q Predictions Min            690.5608
V Predictions Mean           1352.8489
V Predictions Std            1299.2585
V Predictions Max            4563.395
V Predictions Min            688.2837
Log Pis Mean                 -0.9120597
Log Pis Std                  3.541335
Log Pis Max                  11.619145
Log Pis Min                  -6.994156
Policy mu Mean               0.04050609
Policy mu Std                0.84388053
Policy mu Max                3.0287564
Policy mu Min                -2.5214
Policy log std Mean          -0.4578903
Policy log std Std           0.2654365
Policy log std Max           0.14870101
Policy log std Min           -2.6645093
Z mean eval                  1.854358
Z variance eval              0.06874547
total_rewards                [ 9425.68511575 10257.69891977  9961.69950342 10111.46737541
 10202.35788256 10011.80773666 10110.55359934 10055.75321787
  2884.66001391  9899.44992654]
total_rewards_mean           9292.113329123937
total_rewards_std            2146.94422203026
total_rewards_max            10257.698919772032
total_rewards_min            2884.660013912916
Number of train steps total  1484000
Number of env steps total    4454000
Number of rollouts total     0
Train Time (s)               147.83454036479816
(Previous) Eval Time (s)     20.411029533017427
Sample Time (s)              6.528864238411188
Epoch Time (s)               174.77443413622677
Total Train Time (s)         63569.193658747245
Epoch                        370
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:33:08.553021 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #370 | Epoch Duration: 174.861829996109
2020-01-13 01:33:08.553174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8541634
Z variance train             0.06893162
KL Divergence                46.917095
KL Loss                      4.6917095
QF Loss                      4683.848
VF Loss                      58.310852
Policy Loss                  -1551.3397
Q Predictions Mean           1547.6241
Q Predictions Std            1417.0452
Q Predictions Max            4532.076
Q Predictions Min            670.7988
V Predictions Mean           1548.2786
V Predictions Std            1411.2917
V Predictions Max            4523.0396
V Predictions Min            683.11926
Log Pis Mean                 -0.3023495
Log Pis Std                  4.0676756
Log Pis Max                  15.839283
Log Pis Min                  -8.670622
Policy mu Mean               0.05018246
Policy mu Std                0.8867885
Policy mu Max                2.9913054
Policy mu Min                -3.1964545
Policy log std Mean          -0.51132244
Policy log std Std           0.2960332
Policy log std Max           0.20096171
Policy log std Min           -2.6050892
Z mean eval                  1.8763683
Z variance eval              0.07306431
total_rewards                [8244.61842996 5073.83805833 8764.74729385 8767.07577321 1629.51881748
 8892.32131145 8259.2769084  8428.3062154  8750.48970293 8349.66927419]
total_rewards_mean           7515.98617851958
total_rewards_std            2230.8799542155757
total_rewards_max            8892.321311451113
total_rewards_min            1629.518817480986
Number of train steps total  1488000
Number of env steps total    4466000
Number of rollouts total     0
Train Time (s)               147.39492608513683
(Previous) Eval Time (s)     20.9735300228931
Sample Time (s)              6.406075118109584
Epoch Time (s)               174.77453122613952
Total Train Time (s)         63744.33805178199
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:36:03.700751 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #371 | Epoch Duration: 175.14745569229126
2020-01-13 01:36:03.700971 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8720888
Z variance train             0.073074535
KL Divergence                47.69825
KL Loss                      4.769825
QF Loss                      331.6851
VF Loss                      108.66548
Policy Loss                  -1352.3418
Q Predictions Mean           1351.0457
Q Predictions Std            1301.351
Q Predictions Max            4626.189
Q Predictions Min            671.53815
V Predictions Mean           1353.5793
V Predictions Std            1295.0857
V Predictions Max            4585.764
V Predictions Min            700.2465
Log Pis Mean                 -0.36471152
Log Pis Std                  3.7204103
Log Pis Max                  21.732737
Log Pis Min                  -8.568241
Policy mu Mean               0.08448354
Policy mu Std                0.88928103
Policy mu Max                3.6636395
Policy mu Min                -3.0022204
Policy log std Mean          -0.5035999
Policy log std Std           0.26188946
Policy log std Max           0.05197537
Policy log std Min           -2.683847
Z mean eval                  1.9058424
Z variance eval              0.06104355
total_rewards                [9753.58612202 9333.77489575 9486.86455093 9367.65327141 9486.12817034
 9397.77186115 9452.98021453 9394.73211707 9688.05736486 9852.59965197]
total_rewards_mean           9521.414822002083
total_rewards_std            169.90181035573443
total_rewards_max            9852.599651970617
total_rewards_min            9333.774895745524
Number of train steps total  1492000
Number of env steps total    4478000
Number of rollouts total     0
Train Time (s)               146.59874951420352
(Previous) Eval Time (s)     20.981097446754575
Sample Time (s)              6.522314988542348
Epoch Time (s)               174.10216194950044
Total Train Time (s)         63918.51693839207
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:38:57.882557 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #372 | Epoch Duration: 174.1814386844635
2020-01-13 01:38:57.882708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9049795
Z variance train             0.0607522
KL Divergence                48.642387
KL Loss                      4.8642387
QF Loss                      91.0038
VF Loss                      214.60056
Policy Loss                  -1233.3805
Q Predictions Mean           1231.8986
Q Predictions Std            1141.8549
Q Predictions Max            4566.988
Q Predictions Min            705.5357
V Predictions Mean           1232.3484
V Predictions Std            1140.3953
V Predictions Max            4551.835
V Predictions Min            710.21094
Log Pis Mean                 -0.39557493
Log Pis Std                  3.5991518
Log Pis Max                  14.736191
Log Pis Min                  -8.40066
Policy mu Mean               0.0778608
Policy mu Std                0.85922694
Policy mu Max                2.7416258
Policy mu Min                -2.3560505
Policy log std Mean          -0.46265492
Policy log std Std           0.26083586
Policy log std Max           0.16277283
Policy log std Min           -2.577678
Z mean eval                  1.8623168
Z variance eval              0.058080144
total_rewards                [9443.40970657 9766.75244381 9655.70725521 9918.20865009 9550.06125299
 9741.52534271 9651.22224449 9589.77093432 9759.91473567 9705.1500342 ]
total_rewards_mean           9678.172260006422
total_rewards_std            125.48259800309691
total_rewards_max            9918.208650092116
total_rewards_min            9443.409706570092
Number of train steps total  1496000
Number of env steps total    4490000
Number of rollouts total     0
Train Time (s)               146.01743032922968
(Previous) Eval Time (s)     20.649838144890964
Sample Time (s)              6.465938136447221
Epoch Time (s)               173.13320661056787
Total Train Time (s)         64091.74090041593
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:41:51.108636 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #373 | Epoch Duration: 173.22582721710205
2020-01-13 01:41:51.108773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #373 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8645595
Z variance train             0.058060437
KL Divergence                49.232185
KL Loss                      4.9232187
QF Loss                      113.167465
VF Loss                      126.327354
Policy Loss                  -1428.1129
Q Predictions Mean           1425.0156
Q Predictions Std            1345.8099
Q Predictions Max            4581.4663
Q Predictions Min            681.4493
V Predictions Mean           1434.5802
V Predictions Std            1349.5704
V Predictions Max            4597.5034
V Predictions Min            688.4541
Log Pis Mean                 -0.57074857
Log Pis Std                  3.6628945
Log Pis Max                  11.933704
Log Pis Min                  -7.974207
Policy mu Mean               -0.008136186
Policy mu Std                0.872685
Policy mu Max                3.2477179
Policy mu Min                -3.2476995
Policy log std Mean          -0.47760853
Policy log std Std           0.28437066
Policy log std Max           0.074451864
Policy log std Min           -2.5244699
Z mean eval                  1.8720691
Z variance eval              0.05864207
total_rewards                [ 9228.82554547 10100.39399054  9878.93817079  9795.15052845
  9610.96302845 10101.76195003  9746.20920291  9963.08387714
 10144.30837407  9845.33522547]
total_rewards_mean           9841.496989333416
total_rewards_std            261.2278984076381
total_rewards_max            10144.308374074217
total_rewards_min            9228.82554547207
Number of train steps total  1500000
Number of env steps total    4502000
Number of rollouts total     0
Train Time (s)               145.9852113253437
(Previous) Eval Time (s)     18.915250062942505
Sample Time (s)              6.517569481860846
Epoch Time (s)               171.41803087014705
Total Train Time (s)         64263.241047421936
Epoch                        374
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:44:42.614874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #374 | Epoch Duration: 171.50599217414856
2020-01-13 01:44:42.615054 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #374 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8733565
Z variance train             0.058594126
KL Divergence                48.069878
KL Loss                      4.806988
QF Loss                      487.33093
VF Loss                      70.43212
Policy Loss                  -1362.6978
Q Predictions Mean           1359.4316
Q Predictions Std            1282.5581
Q Predictions Max            4546.3716
Q Predictions Min            684.4458
V Predictions Mean           1365.4731
V Predictions Std            1282.1063
V Predictions Max            4537.2036
V Predictions Min            681.5605
Log Pis Mean                 -0.046076875
Log Pis Std                  4.1570277
Log Pis Max                  19.397678
Log Pis Min                  -6.298489
Policy mu Mean               0.045988362
Policy mu Std                0.87617815
Policy mu Max                3.0377815
Policy mu Min                -2.3313034
Policy log std Mean          -0.52103645
Policy log std Std           0.31902114
Policy log std Max           0.011676669
Policy log std Min           -2.7963984
Z mean eval                  1.8519018
Z variance eval              0.051588416
total_rewards                [ 9759.25579558  9952.82258957  9855.29699376  9822.78864855
  9746.84980753 10261.80299203  9739.36913308  9764.17843707
  9824.38198439 10047.8364642 ]
total_rewards_mean           9877.458284576824
total_rewards_std            158.6372221626767
total_rewards_max            10261.802992032495
total_rewards_min            9739.369133079592
Number of train steps total  1504000
Number of env steps total    4514000
Number of rollouts total     0
Train Time (s)               147.46908017387614
(Previous) Eval Time (s)     20.74203820992261
Sample Time (s)              6.422376410569996
Epoch Time (s)               174.63349479436874
Total Train Time (s)         64437.95572407404
Epoch                        375
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:47:37.333249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #375 | Epoch Duration: 174.71807503700256
2020-01-13 01:47:37.333382 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8527569
Z variance train             0.05146869
KL Divergence                48.920998
KL Loss                      4.8921
QF Loss                      4283.911
VF Loss                      61.36199
Policy Loss                  -1177.6538
Q Predictions Mean           1177.2274
Q Predictions Std            1134.8536
Q Predictions Max            4563.5015
Q Predictions Min            692.9888
V Predictions Mean           1181.5487
V Predictions Std            1133.6555
V Predictions Max            4566.878
V Predictions Min            691.4291
Log Pis Mean                 -0.818128
Log Pis Std                  3.5149739
Log Pis Max                  13.045515
Log Pis Min                  -7.363297
Policy mu Mean               0.06544609
Policy mu Std                0.7996116
Policy mu Max                2.5946445
Policy mu Min                -2.6598012
Policy log std Mean          -0.4785782
Policy log std Std           0.29886204
Policy log std Max           0.06389916
Policy log std Min           -2.9975765
Z mean eval                  1.8877121
Z variance eval              0.05429084
total_rewards                [9775.4859337  9663.36033872 9821.13861025 9899.8259116  9635.38882195
 9725.60534284 9584.71623649 9605.6960997  9839.84463366 9796.58132513]
total_rewards_mean           9734.76432540506
total_rewards_std            102.69286692628799
total_rewards_max            9899.825911599646
total_rewards_min            9584.71623649335
Number of train steps total  1508000
Number of env steps total    4526000
Number of rollouts total     0
Train Time (s)               146.5798662211746
(Previous) Eval Time (s)     20.766570428851992
Sample Time (s)              6.353318152949214
Epoch Time (s)               173.6997548029758
Total Train Time (s)         64611.73657546425
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:50:31.118058 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #376 | Epoch Duration: 173.7845802307129
2020-01-13 01:50:31.118191 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8891817
Z variance train             0.05412261
KL Divergence                49.278618
KL Loss                      4.9278617
QF Loss                      188.60461
VF Loss                      221.97289
Policy Loss                  -1403.4576
Q Predictions Mean           1401.602
Q Predictions Std            1351.9827
Q Predictions Max            4605.5884
Q Predictions Min            690.7526
V Predictions Mean           1396.1794
V Predictions Std            1344.0605
V Predictions Max            4598.462
V Predictions Min            691.0826
Log Pis Mean                 -0.5086727
Log Pis Std                  3.7280076
Log Pis Max                  12.025011
Log Pis Min                  -7.0365314
Policy mu Mean               0.04438859
Policy mu Std                0.86374885
Policy mu Max                2.689698
Policy mu Min                -2.6745632
Policy log std Mean          -0.4914128
Policy log std Std           0.3011539
Policy log std Max           0.004956007
Policy log std Min           -2.700985
Z mean eval                  1.8784506
Z variance eval              0.07369449
total_rewards                [9830.23066763 9873.88504108 9982.62502551 9911.54331345 9564.99325842
 9867.2771766  9535.86820532 9491.88751294 9524.77640956 9785.01468792]
total_rewards_mean           9736.81012984239
total_rewards_std            176.82278908869893
total_rewards_max            9982.625025512074
total_rewards_min            9491.887512936335
Number of train steps total  1512000
Number of env steps total    4538000
Number of rollouts total     0
Train Time (s)               145.9759434047155
(Previous) Eval Time (s)     18.780366893857718
Sample Time (s)              6.5756055768579245
Epoch Time (s)               171.33191587543115
Total Train Time (s)         64783.15810635267
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:53:22.543880 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #377 | Epoch Duration: 171.42557621002197
2020-01-13 01:53:22.544076 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #377 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8783257
Z variance train             0.073640004
KL Divergence                49.98961
KL Loss                      4.998961
QF Loss                      107.15909
VF Loss                      88.775986
Policy Loss                  -1311.6166
Q Predictions Mean           1309.2953
Q Predictions Std            1250.8107
Q Predictions Max            4567.1045
Q Predictions Min            692.26373
V Predictions Mean           1316.243
V Predictions Std            1253.2958
V Predictions Max            4585.7837
V Predictions Min            695.0303
Log Pis Mean                 -0.34927756
Log Pis Std                  4.07571
Log Pis Max                  22.59872
Log Pis Min                  -9.336418
Policy mu Mean               0.12467283
Policy mu Std                0.8696991
Policy mu Max                3.4552784
Policy mu Min                -3.4474747
Policy log std Mean          -0.483747
Policy log std Std           0.27180234
Policy log std Max           -0.03493753
Policy log std Min           -2.430083
Z mean eval                  1.8636315
Z variance eval              0.08437241
total_rewards                [ 9884.23214215  9845.31090512  9964.26847708  9871.09781088
  9861.1540425  10172.89529209 10259.5531585  10098.89612856
 10035.48255359 10018.33527748]
total_rewards_mean           10001.122578794502
total_rewards_std            135.32379300436355
total_rewards_max            10259.553158503899
total_rewards_min            9845.310905116237
Number of train steps total  1516000
Number of env steps total    4550000
Number of rollouts total     0
Train Time (s)               145.6304522929713
(Previous) Eval Time (s)     17.486366973724216
Sample Time (s)              6.606286349706352
Epoch Time (s)               169.72310561640188
Total Train Time (s)         64952.974975013174
Epoch                        378
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:56:12.368848 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #378 | Epoch Duration: 169.82459378242493
2020-01-13 01:56:12.369155 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8648698
Z variance train             0.08427806
KL Divergence                48.81436
KL Loss                      4.8814363
QF Loss                      4143.829
VF Loss                      94.36327
Policy Loss                  -1357.0913
Q Predictions Mean           1350.7317
Q Predictions Std            1319.9967
Q Predictions Max            4572.3647
Q Predictions Min            693.63544
V Predictions Mean           1352.4526
V Predictions Std            1313.982
V Predictions Max            4542.9175
V Predictions Min            692.5985
Log Pis Mean                 -0.73985416
Log Pis Std                  3.5772917
Log Pis Max                  11.939463
Log Pis Min                  -9.071801
Policy mu Mean               0.059381362
Policy mu Std                0.8483426
Policy mu Max                3.4313107
Policy mu Min                -2.8575697
Policy log std Mean          -0.49625146
Policy log std Std           0.30080262
Policy log std Max           -0.010328352
Policy log std Min           -2.6150818
Z mean eval                  1.8911839
Z variance eval              0.09610556
total_rewards                [9154.9978098  9418.12507202 9168.1876093  9092.92055287 9346.22424731
 9272.68744628 9106.27343312 9297.29535943 9016.0494305  9345.53341038]
total_rewards_mean           9221.829437101394
total_rewards_std            125.3995112947056
total_rewards_max            9418.125072015091
total_rewards_min            9016.049430504596
Number of train steps total  1520000
Number of env steps total    4562000
Number of rollouts total     0
Train Time (s)               147.9935928718187
(Previous) Eval Time (s)     20.703739661723375
Sample Time (s)              6.0328971622511744
Epoch Time (s)               174.73022969579324
Total Train Time (s)         65127.78539409116
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:59:07.180121 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #379 | Epoch Duration: 174.8107578754425
2020-01-13 01:59:07.180254 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8903253
Z variance train             0.09679222
KL Divergence                49.513382
KL Loss                      4.9513383
QF Loss                      4212.922
VF Loss                      69.50273
Policy Loss                  -1275.4385
Q Predictions Mean           1272.2983
Q Predictions Std            1247.8866
Q Predictions Max            4517.77
Q Predictions Min            678.69867
V Predictions Mean           1279.5656
V Predictions Std            1250.463
V Predictions Max            4527.057
V Predictions Min            685.593
Log Pis Mean                 -0.7475784
Log Pis Std                  3.6823223
Log Pis Max                  14.32426
Log Pis Min                  -6.23864
Policy mu Mean               0.052413326
Policy mu Std                0.82359385
Policy mu Max                3.0384197
Policy mu Min                -2.6233156
Policy log std Mean          -0.4741056
Policy log std Std           0.27518812
Policy log std Max           0.07576728
Policy log std Min           -2.806288
Z mean eval                  1.9115146
Z variance eval              0.122425176
total_rewards                [9316.61175347 9894.82550863 9226.9385677  9357.06360616 9799.66013854
 9193.49394249 9111.40337268 9907.42773971 9859.50943572 9285.73826778]
total_rewards_mean           9495.267233289673
total_rewards_std            309.869292920655
total_rewards_max            9907.42773970602
total_rewards_min            9111.403372679206
Number of train steps total  1524000
Number of env steps total    4574000
Number of rollouts total     0
Train Time (s)               145.38703901832923
(Previous) Eval Time (s)     20.757535024080426
Sample Time (s)              9.667046279180795
Epoch Time (s)               175.81162032159045
Total Train Time (s)         65303.676605890505
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:02:03.074185 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #380 | Epoch Duration: 175.89383721351624
2020-01-13 02:02:03.074317 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #380 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9097958
Z variance train             0.122848235
KL Divergence                49.871918
KL Loss                      4.9871917
QF Loss                      104.273285
VF Loss                      55.488876
Policy Loss                  -1429.0654
Q Predictions Mean           1430.2382
Q Predictions Std            1393.8066
Q Predictions Max            4643.3467
Q Predictions Min            682.2826
V Predictions Mean           1431.7933
V Predictions Std            1389.4744
V Predictions Max            4631.1353
V Predictions Min            693.72534
Log Pis Mean                 -0.0950571
Log Pis Std                  3.9896061
Log Pis Max                  13.884285
Log Pis Min                  -6.259799
Policy mu Mean               0.044379156
Policy mu Std                0.87781304
Policy mu Max                2.80202
Policy mu Min                -2.74337
Policy log std Mean          -0.49447322
Policy log std Std           0.27528292
Policy log std Max           -0.06160289
Policy log std Min           -2.5288646
Z mean eval                  1.8902848
Z variance eval              0.09111163
total_rewards                [ 9956.37725297 10116.04604728 10160.72979594 10528.38805598
 10544.77191348 10371.61645099 10325.29314689 10319.00681739
 10080.69152425 10178.79194004]
total_rewards_mean           10258.171294519712
total_rewards_std            182.97741560931294
total_rewards_max            10544.771913479039
total_rewards_min            9956.377252967484
Number of train steps total  1528000
Number of env steps total    4586000
Number of rollouts total     0
Train Time (s)               147.17296544322744
(Previous) Eval Time (s)     20.69597431831062
Sample Time (s)              6.41876144008711
Epoch Time (s)               174.28770120162517
Total Train Time (s)         65478.06792785274
Epoch                        381
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:04:57.469283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #381 | Epoch Duration: 174.39487051963806
2020-01-13 02:04:57.469420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.889546
Z variance train             0.091347516
KL Divergence                49.574787
KL Loss                      4.957479
QF Loss                      143.38548
VF Loss                      140.23366
Policy Loss                  -1319.5021
Q Predictions Mean           1317.7166
Q Predictions Std            1276.6633
Q Predictions Max            4522.3877
Q Predictions Min            671.98706
V Predictions Mean           1328.0442
V Predictions Std            1279.332
V Predictions Max            4541.4224
V Predictions Min            699.8771
Log Pis Mean                 -0.6203114
Log Pis Std                  3.6145096
Log Pis Max                  16.266825
Log Pis Min                  -10.058009
Policy mu Mean               0.048218112
Policy mu Std                0.86379737
Policy mu Max                3.2186873
Policy mu Min                -4.3629103
Policy log std Mean          -0.48435125
Policy log std Std           0.26703313
Policy log std Max           0.0036036372
Policy log std Min           -2.324059
Z mean eval                  1.8951944
Z variance eval              0.11654963
total_rewards                [ 9919.54446449 10495.40435337 10272.70183772 10387.30945939
  7385.04395634 10272.72657506 10218.21167305 10192.46056748
 10284.64298126 10377.27125576]
total_rewards_mean           9980.531712391978
total_rewards_std            877.0901242423059
total_rewards_max            10495.404353371452
total_rewards_min            7385.043956343066
Number of train steps total  1532000
Number of env steps total    4598000
Number of rollouts total     0
Train Time (s)               147.43155474821106
(Previous) Eval Time (s)     20.827033730689436
Sample Time (s)              6.389928185380995
Epoch Time (s)               174.6485166642815
Total Train Time (s)         65652.85013167001
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:07:52.254520 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #382 | Epoch Duration: 174.78500413894653
2020-01-13 02:07:52.254667 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #382 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8971351
Z variance train             0.11596942
KL Divergence                49.559055
KL Loss                      4.9559054
QF Loss                      343.6308
VF Loss                      200.1422
Policy Loss                  -1370.5541
Q Predictions Mean           1365.8002
Q Predictions Std            1309.8289
Q Predictions Max            4621.5337
Q Predictions Min            683.55853
V Predictions Mean           1362.8613
V Predictions Std            1299.6565
V Predictions Max            4591.5747
V Predictions Min            676.0936
Log Pis Mean                 -0.295713
Log Pis Std                  3.5996482
Log Pis Max                  14.090097
Log Pis Min                  -7.3290095
Policy mu Mean               0.041946918
Policy mu Std                0.8942907
Policy mu Max                3.5028
Policy mu Min                -3.1218584
Policy log std Mean          -0.50378555
Policy log std Std           0.30407238
Policy log std Max           0.15377104
Policy log std Min           -2.7430675
Z mean eval                  1.8952847
Z variance eval              0.1369302
total_rewards                [ 9822.86032444  9932.39801591 10290.69103599  9778.02415338
  7441.35133644 10011.59007516  9407.77094011  9765.73052146
  9891.14364361 10007.46422236]
total_rewards_mean           9634.902426886349
total_rewards_std            761.6495815746009
total_rewards_max            10290.69103599409
total_rewards_min            7441.351336443568
Number of train steps total  1536000
Number of env steps total    4610000
Number of rollouts total     0
Train Time (s)               146.3406353201717
(Previous) Eval Time (s)     19.111975512001663
Sample Time (s)              6.442974720615894
Epoch Time (s)               171.89558555278927
Total Train Time (s)         65824.8221931993
Epoch                        383
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:10:44.228649 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #383 | Epoch Duration: 171.97388458251953
2020-01-13 02:10:44.228781 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.895698
Z variance train             0.1367574
KL Divergence                49.288246
KL Loss                      4.928825
QF Loss                      110.54071
VF Loss                      50.77611
Policy Loss                  -1273.8097
Q Predictions Mean           1273.229
Q Predictions Std            1227.7203
Q Predictions Max            4566.8896
Q Predictions Min            678.5529
V Predictions Mean           1271.5636
V Predictions Std            1218.4852
V Predictions Max            4548.713
V Predictions Min            687.5646
Log Pis Mean                 -0.8547034
Log Pis Std                  3.3356996
Log Pis Max                  12.310268
Log Pis Min                  -5.935505
Policy mu Mean               0.025870046
Policy mu Std                0.80943096
Policy mu Max                2.633931
Policy mu Min                -2.4321449
Policy log std Mean          -0.47138834
Policy log std Std           0.24050955
Policy log std Max           0.016303658
Policy log std Min           -2.7038317
Z mean eval                  1.9035523
Z variance eval              0.09112503
total_rewards                [9805.06780356 9605.65035664 9781.15323929 9684.56101401 9854.68923379
 9489.76015025 9895.99722315 9526.28098342 9655.7417608  9729.63897842]
total_rewards_mean           9702.85407433318
total_rewards_std            128.9355940540727
total_rewards_max            9895.997223153629
total_rewards_min            9489.760150246919
Number of train steps total  1540000
Number of env steps total    4622000
Number of rollouts total     0
Train Time (s)               147.62035322422162
(Previous) Eval Time (s)     20.74056278122589
Sample Time (s)              5.581156665459275
Epoch Time (s)               173.94207267090678
Total Train Time (s)         65998.84810821246
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:13:38.258190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #384 | Epoch Duration: 174.029314994812
2020-01-13 02:13:38.258328 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #384 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9047047
Z variance train             0.0906706
KL Divergence                48.64567
KL Loss                      4.8645673
QF Loss                      4550.5454
VF Loss                      145.57423
Policy Loss                  -1371.8453
Q Predictions Mean           1370.268
Q Predictions Std            1302.8373
Q Predictions Max            4700.114
Q Predictions Min            680.45264
V Predictions Mean           1364.4208
V Predictions Std            1293.964
V Predictions Max            4681.375
V Predictions Min            690.16986
Log Pis Mean                 -0.48252323
Log Pis Std                  3.6925607
Log Pis Max                  18.175653
Log Pis Min                  -8.225813
Policy mu Mean               0.017248712
Policy mu Std                0.8820387
Policy mu Max                2.9999309
Policy mu Min                -3.338814
Policy log std Mean          -0.4764212
Policy log std Std           0.26501012
Policy log std Max           0.097031355
Policy log std Min           -2.645468
Z mean eval                  1.8827059
Z variance eval              0.07058672
total_rewards                [ 9824.21743551  9870.06093209  9911.2823155   9850.01310712
 10057.93047434  9704.71018786  9868.13497198 10103.40336055
  9931.84338291  9621.03999895]
total_rewards_mean           9874.263616682345
total_rewards_std            136.7270443148174
total_rewards_max            10103.403360551709
total_rewards_min            9621.039998954497
Number of train steps total  1544000
Number of env steps total    4634000
Number of rollouts total     0
Train Time (s)               147.22266611177474
(Previous) Eval Time (s)     20.63532943185419
Sample Time (s)              6.489180014934391
Epoch Time (s)               174.34717555856332
Total Train Time (s)         66173.29110403499
Epoch                        385
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:16:32.704470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #385 | Epoch Duration: 174.44603204727173
2020-01-13 02:16:32.704644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #385 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8815473
Z variance train             0.07050952
KL Divergence                48.015472
KL Loss                      4.8015475
QF Loss                      88.58998
VF Loss                      77.5449
Policy Loss                  -1362.3651
Q Predictions Mean           1361.3921
Q Predictions Std            1292.3824
Q Predictions Max            4635.543
Q Predictions Min            696.75696
V Predictions Mean           1362.4426
V Predictions Std            1291.0468
V Predictions Max            4608.857
V Predictions Min            698.6242
Log Pis Mean                 -0.43609193
Log Pis Std                  3.8358235
Log Pis Max                  14.5136
Log Pis Min                  -7.046588
Policy mu Mean               0.05321659
Policy mu Std                0.87740266
Policy mu Max                2.8220086
Policy mu Min                -3.2565691
Policy log std Mean          -0.4621273
Policy log std Std           0.2684683
Policy log std Max           -0.07856831
Policy log std Min           -2.3541474
Z mean eval                  1.8741112
Z variance eval              0.08466537
total_rewards                [ 9580.65716835 10139.2922156   9975.23592676  9777.62018511
 10006.0011701   9798.5117571  10192.45956504  9296.84161637
 10094.25175073 10208.75121912]
total_rewards_mean           9906.962257427058
total_rewards_std            279.8790711116719
total_rewards_max            10208.75121912379
total_rewards_min            9296.841616368101
Number of train steps total  1548000
Number of env steps total    4646000
Number of rollouts total     0
Train Time (s)               147.02580833202228
(Previous) Eval Time (s)     21.01948000723496
Sample Time (s)              5.618510524742305
Epoch Time (s)               173.66379886399955
Total Train Time (s)         66347.03587124357
Epoch                        386
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:19:26.451574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #386 | Epoch Duration: 173.7467999458313
2020-01-13 02:19:26.451706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #386 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8752114
Z variance train             0.08471556
KL Divergence                47.04331
KL Loss                      4.704331
QF Loss                      322.9041
VF Loss                      65.78241
Policy Loss                  -1476.9084
Q Predictions Mean           1474.9913
Q Predictions Std            1412.7407
Q Predictions Max            4573.7354
Q Predictions Min            682.5473
V Predictions Mean           1478.4866
V Predictions Std            1409.7052
V Predictions Max            4562.1724
V Predictions Min            688.25574
Log Pis Mean                 -0.42684162
Log Pis Std                  3.9500926
Log Pis Max                  13.37689
Log Pis Min                  -8.024233
Policy mu Mean               0.037790466
Policy mu Std                0.9085021
Policy mu Max                3.2215068
Policy mu Min                -2.8796232
Policy log std Mean          -0.48016873
Policy log std Std           0.2891063
Policy log std Max           -0.025840938
Policy log std Min           -2.6700325
Z mean eval                  1.901823
Z variance eval              0.06951566
total_rewards                [ 9922.22070781  9737.82762957  9994.93782965  9634.72936663
  9933.59420461  8702.61407952 10099.63696185 10009.02367408
 10233.96095396  9764.34312096]
total_rewards_mean           9803.288852865753
total_rewards_std            403.63105393480583
total_rewards_max            10233.960953964099
total_rewards_min            8702.614079521925
Number of train steps total  1552000
Number of env steps total    4658000
Number of rollouts total     0
Train Time (s)               146.18365166382864
(Previous) Eval Time (s)     20.734043068718165
Sample Time (s)              6.482313010841608
Epoch Time (s)               173.40000774338841
Total Train Time (s)         66520.51829900686
Epoch                        387
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:22:19.939808 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #387 | Epoch Duration: 173.48800611495972
2020-01-13 02:22:19.939941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8999485
Z variance train             0.07017151
KL Divergence                48.295616
KL Loss                      4.8295617
QF Loss                      237.2309
VF Loss                      146.28653
Policy Loss                  -1299.7925
Q Predictions Mean           1295.333
Q Predictions Std            1239.0123
Q Predictions Max            4390.5034
Q Predictions Min            627.6116
V Predictions Mean           1291.0153
V Predictions Std            1231.6228
V Predictions Max            4357.549
V Predictions Min            653.1528
Log Pis Mean                 -0.2823229
Log Pis Std                  3.7880468
Log Pis Max                  19.842842
Log Pis Min                  -6.8442607
Policy mu Mean               0.122609295
Policy mu Std                0.8723011
Policy mu Max                3.0502315
Policy mu Min                -2.763727
Policy log std Mean          -0.5074384
Policy log std Std           0.28026125
Policy log std Max           -0.04724419
Policy log std Min           -2.578574
Z mean eval                  1.8992189
Z variance eval              0.08997854
total_rewards                [ 9992.8572176  10030.7224103  10115.92501704  9867.56256009
  9990.41605376 10382.59232251 10111.34667459 10098.00960827
 10279.62443036 10288.17370271]
total_rewards_mean           10115.722999723936
total_rewards_std            150.917743081549
total_rewards_max            10382.592322512995
total_rewards_min            9867.562560090386
Number of train steps total  1556000
Number of env steps total    4670000
Number of rollouts total     0
Train Time (s)               144.4777842978947
(Previous) Eval Time (s)     20.957605473231524
Sample Time (s)              6.340437537524849
Epoch Time (s)               171.77582730865106
Total Train Time (s)         66692.38316213572
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:25:11.805306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #388 | Epoch Duration: 171.86526727676392
2020-01-13 02:25:11.805444 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #388 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8987204
Z variance train             0.09011395
KL Divergence                48.425285
KL Loss                      4.842529
QF Loss                      221.11778
VF Loss                      36.644543
Policy Loss                  -1308.4253
Q Predictions Mean           1304.102
Q Predictions Std            1227.1985
Q Predictions Max            4589.328
Q Predictions Min            693.4028
V Predictions Mean           1306.868
V Predictions Std            1229.1643
V Predictions Max            4589.693
V Predictions Min            704.7774
Log Pis Mean                 -0.6968523
Log Pis Std                  3.6748917
Log Pis Max                  12.22304
Log Pis Min                  -7.2281013
Policy mu Mean               0.03057913
Policy mu Std                0.8518098
Policy mu Max                3.2549334
Policy mu Min                -2.8614638
Policy log std Mean          -0.4864631
Policy log std Std           0.26927108
Policy log std Max           -0.055342674
Policy log std Min           -2.3364913
Z mean eval                  1.9072285
Z variance eval              0.06950181
total_rewards                [10024.09484984 10063.98781432 10431.60488367 10109.20115255
 10307.88131007  9874.76004892 10055.8497286  10105.320112
 10230.16519795 10149.68165789]
total_rewards_mean           10135.254675582577
total_rewards_std            148.32817618368313
total_rewards_max            10431.604883669619
total_rewards_min            9874.760048918153
Number of train steps total  1560000
Number of env steps total    4682000
Number of rollouts total     0
Train Time (s)               145.51547252899036
(Previous) Eval Time (s)     20.923224737867713
Sample Time (s)              6.484979311469942
Epoch Time (s)               172.923676578328
Total Train Time (s)         66865.39026572695
Epoch                        389
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:28:04.814475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #389 | Epoch Duration: 173.00893354415894
2020-01-13 02:28:04.814606 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #389 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.903992
Z variance train             0.069136776
KL Divergence                49.289806
KL Loss                      4.928981
QF Loss                      329.67566
VF Loss                      98.13901
Policy Loss                  -1399.5602
Q Predictions Mean           1399.2511
Q Predictions Std            1331.4027
Q Predictions Max            4617.217
Q Predictions Min            677.0626
V Predictions Mean           1403.6993
V Predictions Std            1328.7468
V Predictions Max            4622.042
V Predictions Min            689.49115
Log Pis Mean                 -0.3122967
Log Pis Std                  3.9972737
Log Pis Max                  15.4096
Log Pis Min                  -6.6008863
Policy mu Mean               0.08555964
Policy mu Std                0.87432253
Policy mu Max                3.1559243
Policy mu Min                -3.170525
Policy log std Mean          -0.49958527
Policy log std Std           0.2865004
Policy log std Max           -0.0063121915
Policy log std Min           -2.7243795
Z mean eval                  1.8877227
Z variance eval              0.082491145
total_rewards                [10089.10846199 10131.84432662  9931.74355496 10299.35234109
 10105.13363692  9958.21696179 10209.37449088  9931.84899394
 10110.61231432 10219.82148397]
total_rewards_mean           10098.70565664817
total_rewards_std            120.00152256082555
total_rewards_max            10299.352341088186
total_rewards_min            9931.74355495897
Number of train steps total  1564000
Number of env steps total    4694000
Number of rollouts total     0
Train Time (s)               145.38560410775244
(Previous) Eval Time (s)     20.563520544208586
Sample Time (s)              6.488403321243823
Epoch Time (s)               172.43752797320485
Total Train Time (s)         67037.9182320172
Epoch                        390
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:30:57.344583 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #390 | Epoch Duration: 172.52986979484558
2020-01-13 02:30:57.344722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #390 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8861424
Z variance train             0.082233384
KL Divergence                48.42465
KL Loss                      4.842465
QF Loss                      1424.9521
VF Loss                      138.24815
Policy Loss                  -1476.3822
Q Predictions Mean           1477.5317
Q Predictions Std            1390.1486
Q Predictions Max            4616.67
Q Predictions Min            693.7515
V Predictions Mean           1481.3752
V Predictions Std            1391.9945
V Predictions Max            4647.0493
V Predictions Min            704.3722
Log Pis Mean                 0.09456141
Log Pis Std                  3.7611911
Log Pis Max                  13.056921
Log Pis Min                  -5.5130253
Policy mu Mean               0.107567914
Policy mu Std                0.91286236
Policy mu Max                2.8072503
Policy mu Min                -2.7117753
Policy log std Mean          -0.49535012
Policy log std Std           0.2669025
Policy log std Max           -0.0704487
Policy log std Min           -2.616741
Z mean eval                  1.8760185
Z variance eval              0.07646864
total_rewards                [ 9738.64287302  9889.6417485  10188.9473026   9990.60838944
 10022.88971496  9993.4117046  10063.37543344 10094.59637313
  9933.13147753  9959.65499271]
total_rewards_mean           9987.49000099314
total_rewards_std            115.90606508074741
total_rewards_max            10188.947302600725
total_rewards_min            9738.642873020823
Number of train steps total  1568000
Number of env steps total    4706000
Number of rollouts total     0
Train Time (s)               146.27276569698006
(Previous) Eval Time (s)     17.514762572944164
Sample Time (s)              6.617209106683731
Epoch Time (s)               170.40473737660795
Total Train Time (s)         67208.41193868872
Epoch                        391
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:33:47.842122 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #391 | Epoch Duration: 170.49728417396545
2020-01-13 02:33:47.842294 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #391 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8754389
Z variance train             0.07624092
KL Divergence                47.886322
KL Loss                      4.7886324
QF Loss                      238.96756
VF Loss                      74.49184
Policy Loss                  -1351.1353
Q Predictions Mean           1344.7388
Q Predictions Std            1265.9229
Q Predictions Max            4548.9253
Q Predictions Min            682.1016
V Predictions Mean           1350.9624
V Predictions Std            1262.4153
V Predictions Max            4524.3574
V Predictions Min            680.04584
Log Pis Mean                 -0.4002482
Log Pis Std                  3.606474
Log Pis Max                  12.189025
Log Pis Min                  -6.291816
Policy mu Mean               0.0829666
Policy mu Std                0.8625842
Policy mu Max                2.9970357
Policy mu Min                -2.7836628
Policy log std Mean          -0.49225548
Policy log std Std           0.30370212
Policy log std Max           -0.0041605234
Policy log std Min           -2.967675
Z mean eval                  1.9052607
Z variance eval              0.087996885
total_rewards                [ 9788.06876266 10051.89731148 10046.49940822 10142.60843961
  9811.15173522  9919.09869266 10010.73800214  9686.71036158
  9861.88494645  9904.82131444]
total_rewards_mean           9922.347897446916
total_rewards_std            133.57327317692543
total_rewards_max            10142.608439607238
total_rewards_min            9686.710361584199
Number of train steps total  1572000
Number of env steps total    4718000
Number of rollouts total     0
Train Time (s)               146.96382901910692
(Previous) Eval Time (s)     20.756376903038472
Sample Time (s)              6.572071221657097
Epoch Time (s)               174.2922771438025
Total Train Time (s)         67382.7918473729
Epoch                        392
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:36:42.228563 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #392 | Epoch Duration: 174.38606929779053
2020-01-13 02:36:42.228838 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #392 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9043131
Z variance train             0.08790706
KL Divergence                47.985104
KL Loss                      4.7985106
QF Loss                      198.24417
VF Loss                      40.434155
Policy Loss                  -1253.43
Q Predictions Mean           1249.044
Q Predictions Std            1178.2765
Q Predictions Max            4556.0835
Q Predictions Min            685.5494
V Predictions Mean           1254.4713
V Predictions Std            1177.8674
V Predictions Max            4535.9893
V Predictions Min            681.8884
Log Pis Mean                 -0.66509604
Log Pis Std                  3.5987546
Log Pis Max                  15.00477
Log Pis Min                  -6.4677014
Policy mu Mean               0.08104371
Policy mu Std                0.8223866
Policy mu Max                2.966594
Policy mu Min                -2.8613195
Policy log std Mean          -0.4762024
Policy log std Std           0.2738823
Policy log std Max           -0.011745423
Policy log std Min           -2.281291
Z mean eval                  1.8933156
Z variance eval              0.10633089
total_rewards                [ 9903.48893391 10199.33546354 10449.80951319 10209.93621709
 10245.68160853 10240.0583153  10091.96982588 10150.62829146
 10290.92624293 10332.41774029]
total_rewards_mean           10211.425215211919
total_rewards_std            138.82327668273743
total_rewards_max            10449.809513192737
total_rewards_min            9903.488933913202
Number of train steps total  1576000
Number of env steps total    4730000
Number of rollouts total     0
Train Time (s)               146.08845992106944
(Previous) Eval Time (s)     20.626837758813053
Sample Time (s)              5.633285072632134
Epoch Time (s)               172.34858275251463
Total Train Time (s)         67555.24207505444
Epoch                        393
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:39:34.682531 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #393 | Epoch Duration: 172.4535174369812
2020-01-13 02:39:34.682724 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #393 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.896175
Z variance train             0.10630341
KL Divergence                47.268238
KL Loss                      4.726824
QF Loss                      629.7744
VF Loss                      51.266205
Policy Loss                  -1340.2639
Q Predictions Mean           1337.0735
Q Predictions Std            1255.7408
Q Predictions Max            4570.6777
Q Predictions Min            668.98236
V Predictions Mean           1342.1182
V Predictions Std            1255.4723
V Predictions Max            4562.848
V Predictions Min            676.3086
Log Pis Mean                 -0.23062836
Log Pis Std                  3.5601318
Log Pis Max                  10.929634
Log Pis Min                  -7.9260406
Policy mu Mean               0.12932657
Policy mu Std                0.87808925
Policy mu Max                2.8067694
Policy mu Min                -2.4082968
Policy log std Mean          -0.50943774
Policy log std Std           0.29851186
Policy log std Max           -0.01970157
Policy log std Min           -2.817096
Z mean eval                  1.8851728
Z variance eval              0.07160795
total_rewards                [10054.39630099 10095.16536547 10265.74692683 10267.75460518
 10284.89928894 10256.94947546  9881.63941073 10309.45293056
 10211.17637704 10404.72210955]
total_rewards_mean           10203.190279076083
total_rewards_std            143.81338541151737
total_rewards_max            10404.72210954645
total_rewards_min            9881.639410733544
Number of train steps total  1580000
Number of env steps total    4742000
Number of rollouts total     0
Train Time (s)               147.57199665205553
(Previous) Eval Time (s)     20.550741785671562
Sample Time (s)              5.755672336090356
Epoch Time (s)               173.87841077381745
Total Train Time (s)         67729.20655962871
Epoch                        394
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:42:28.654895 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #394 | Epoch Duration: 173.97203826904297
2020-01-13 02:42:28.655043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #394 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8825204
Z variance train             0.07156132
KL Divergence                47.863907
KL Loss                      4.786391
QF Loss                      4322.563
VF Loss                      137.18787
Policy Loss                  -1342.9341
Q Predictions Mean           1340.9174
Q Predictions Std            1287.8755
Q Predictions Max            4544.294
Q Predictions Min            672.5672
V Predictions Mean           1340.375
V Predictions Std            1278.9353
V Predictions Max            4525.5913
V Predictions Min            680.2921
Log Pis Mean                 -0.6889212
Log Pis Std                  3.5366714
Log Pis Max                  11.350292
Log Pis Min                  -7.4817615
Policy mu Mean               0.0056784055
Policy mu Std                0.8474052
Policy mu Max                2.4648013
Policy mu Min                -2.412916
Policy log std Mean          -0.4945508
Policy log std Std           0.2651586
Policy log std Max           -0.026863873
Policy log std Min           -2.5784612
Z mean eval                  1.8672445
Z variance eval              0.03916168
total_rewards                [ 9884.7571182  10161.71159031 10091.74229165 10376.86198327
 10358.30245117 10475.35964844 10446.78126866 10298.65646177
 10413.37770135 10174.47619047]
total_rewards_mean           10268.202670531142
total_rewards_std            177.4897543644053
total_rewards_max            10475.359648442049
total_rewards_min            9884.757118203936
Number of train steps total  1584000
Number of env steps total    4754000
Number of rollouts total     0
Train Time (s)               147.3232988701202
(Previous) Eval Time (s)     19.657551805954427
Sample Time (s)              6.355615169741213
Epoch Time (s)               173.33646584581584
Total Train Time (s)         67902.6222065757
Epoch                        395
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:45:22.073231 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #395 | Epoch Duration: 173.4180281162262
2020-01-13 02:45:22.073441 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #395 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.867061
Z variance train             0.039123215
KL Divergence                49.350285
KL Loss                      4.9350286
QF Loss                      146.10896
VF Loss                      44.79104
Policy Loss                  -1325.3201
Q Predictions Mean           1322.6266
Q Predictions Std            1268.0208
Q Predictions Max            4630.8257
Q Predictions Min            700.7541
V Predictions Mean           1324.1895
V Predictions Std            1264.7229
V Predictions Max            4624.9614
V Predictions Min            700.9733
Log Pis Mean                 -0.3264502
Log Pis Std                  4.063251
Log Pis Max                  22.486332
Log Pis Min                  -6.8523273
Policy mu Mean               0.033119325
Policy mu Std                0.89072263
Policy mu Max                3.27666
Policy mu Min                -3.0869071
Policy log std Mean          -0.4890343
Policy log std Std           0.26420406
Policy log std Max           0.29679108
Policy log std Min           -2.7463543
Z mean eval                  1.8766603
Z variance eval              0.0410124
total_rewards                [10162.02317076 10183.25542795 10424.68273847 10359.3737206
 10080.95985627 10208.11717868 10384.93439864 10433.71066426
 10414.64633713 10251.2773055 ]
total_rewards_mean           10290.298079826014
total_rewards_std            121.58444256599867
total_rewards_max            10433.710664262491
total_rewards_min            10080.959856265967
Number of train steps total  1588000
Number of env steps total    4766000
Number of rollouts total     0
Train Time (s)               144.67909861914814
(Previous) Eval Time (s)     20.825641923118383
Sample Time (s)              5.394221387337893
Epoch Time (s)               170.8989619296044
Total Train Time (s)         68073.60068234382
Epoch                        396
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:48:13.053722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #396 | Epoch Duration: 170.98016047477722
2020-01-13 02:48:13.053856 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #396 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8772275
Z variance train             0.041085124
KL Divergence                48.85475
KL Loss                      4.885475
QF Loss                      147.3132
VF Loss                      117.58589
Policy Loss                  -1357.0221
Q Predictions Mean           1354.6329
Q Predictions Std            1268.3251
Q Predictions Max            4611.677
Q Predictions Min            664.9964
V Predictions Mean           1359.9358
V Predictions Std            1265.9365
V Predictions Max            4578.183
V Predictions Min            676.8047
Log Pis Mean                 -0.1168339
Log Pis Std                  4.183656
Log Pis Max                  16.460957
Log Pis Min                  -11.871697
Policy mu Mean               0.06628954
Policy mu Std                0.89998406
Policy mu Max                3.685719
Policy mu Min                -2.757251
Policy log std Mean          -0.5114947
Policy log std Std           0.28447354
Policy log std Max           0.18368179
Policy log std Min           -2.7951095
Z mean eval                  1.8909365
Z variance eval              0.05186034
total_rewards                [10023.98830982 10596.89281975 10473.77646032  9987.74993344
 10277.17060274  9937.68708112 10069.68785204 10083.9259122
 10310.52935858 10424.69955197]
total_rewards_mean           10218.610788196322
total_rewards_std            217.47838948455043
total_rewards_max            10596.892819752682
total_rewards_min            9937.68708111611
Number of train steps total  1592000
Number of env steps total    4778000
Number of rollouts total     0
Train Time (s)               147.92868971591815
(Previous) Eval Time (s)     20.861705656629056
Sample Time (s)              6.400278631132096
Epoch Time (s)               175.1906740036793
Total Train Time (s)         68248.87812365964
Epoch                        397
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:51:08.333739 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #397 | Epoch Duration: 175.2797863483429
2020-01-13 02:51:08.333879 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #397 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8907467
Z variance train             0.051840723
KL Divergence                49.261124
KL Loss                      4.9261127
QF Loss                      4376.8154
VF Loss                      46.741604
Policy Loss                  -1356.5066
Q Predictions Mean           1356.567
Q Predictions Std            1305.5358
Q Predictions Max            4617.6553
Q Predictions Min            681.7818
V Predictions Mean           1353.1069
V Predictions Std            1301.7406
V Predictions Max            4588.977
V Predictions Min            680.7207
Log Pis Mean                 -0.04543773
Log Pis Std                  3.9766803
Log Pis Max                  17.971598
Log Pis Min                  -7.990786
Policy mu Mean               0.06239305
Policy mu Std                0.9122026
Policy mu Max                2.8414156
Policy mu Min                -2.833856
Policy log std Mean          -0.49133205
Policy log std Std           0.28893113
Policy log std Max           -0.055936456
Policy log std Min           -2.9678657
Z mean eval                  1.9103525
Z variance eval              0.079182066
total_rewards                [ 9835.0883486  10242.98875589 10299.72696914 10424.02645012
 10234.71972628 10163.13316062 10502.45548794 10308.4341195
 10134.5280055  10325.00608797]
total_rewards_mean           10247.01071115569
total_rewards_std            172.84582822229805
total_rewards_max            10502.455487940464
total_rewards_min            9835.08834860254
Number of train steps total  1596000
Number of env steps total    4790000
Number of rollouts total     0
Train Time (s)               147.34677468892187
(Previous) Eval Time (s)     20.978184663690627
Sample Time (s)              6.457738631870598
Epoch Time (s)               174.7826979844831
Total Train Time (s)         68423.73816756858
Epoch                        398
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:54:03.196241 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #398 | Epoch Duration: 174.86226391792297
2020-01-13 02:54:03.196374 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #398 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9073935
Z variance train             0.079215325
KL Divergence                48.960293
KL Loss                      4.8960295
QF Loss                      183.23956
VF Loss                      34.27533
Policy Loss                  -1261.4558
Q Predictions Mean           1262.0872
Q Predictions Std            1206.3676
Q Predictions Max            4674.51
Q Predictions Min            671.10754
V Predictions Mean           1264.2981
V Predictions Std            1203.9199
V Predictions Max            4654.2974
V Predictions Min            684.9982
Log Pis Mean                 -0.7786428
Log Pis Std                  3.5198557
Log Pis Max                  11.9752
Log Pis Min                  -7.0705013
Policy mu Mean               0.036928397
Policy mu Std                0.8224587
Policy mu Max                2.5638378
Policy mu Min                -2.84967
Policy log std Mean          -0.46785152
Policy log std Std           0.27113998
Policy log std Max           0.02387768
Policy log std Min           -2.4173791
Z mean eval                  1.9394159
Z variance eval              0.07506261
total_rewards                [10136.97303095 10479.08104253 10388.31105129 10260.4150996
 10305.3330965   9985.18368427 10315.61136304  9919.82697182
 10116.45980959 10180.12083983]
total_rewards_mean           10208.731598941926
total_rewards_std            166.33863752927164
total_rewards_max            10479.081042526643
total_rewards_min            9919.82697181788
Number of train steps total  1600000
Number of env steps total    4802000
Number of rollouts total     0
Train Time (s)               145.57254185900092
(Previous) Eval Time (s)     17.791263420134783
Sample Time (s)              6.505859424825758
Epoch Time (s)               169.86966470396146
Total Train Time (s)         68593.68638642877
Epoch                        399
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:56:53.148063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #399 | Epoch Duration: 169.95157957077026
2020-01-13 02:56:53.148225 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9404914
Z variance train             0.075068824
KL Divergence                49.514652
KL Loss                      4.951465
QF Loss                      298.41324
VF Loss                      95.846375
Policy Loss                  -1362.9908
Q Predictions Mean           1362.7937
Q Predictions Std            1325.5211
Q Predictions Max            4625.2534
Q Predictions Min            689.18164
V Predictions Mean           1368.6948
V Predictions Std            1323.6149
V Predictions Max            4643.391
V Predictions Min            699.0817
Log Pis Mean                 -0.5438384
Log Pis Std                  3.662629
Log Pis Max                  16.383741
Log Pis Min                  -8.572298
Policy mu Mean               0.032556053
Policy mu Std                0.87408143
Policy mu Max                2.653739
Policy mu Min                -2.9973626
Policy log std Mean          -0.47978005
Policy log std Std           0.29913327
Policy log std Max           0.010383248
Policy log std Min           -2.6812658
Z mean eval                  1.8975118
Z variance eval              0.08046272
total_rewards                [10455.7329956  10491.3390127  10625.92697884 10501.68698817
 10494.55973583 10505.56412011 10403.99038304 10378.10642102
 10472.99106497 10446.55331257]
total_rewards_mean           10477.645101285198
total_rewards_std            63.73389472241659
total_rewards_max            10625.926978844653
total_rewards_min            10378.106421021039
Number of train steps total  1604000
Number of env steps total    4814000
Number of rollouts total     0
Train Time (s)               147.54965612711385
(Previous) Eval Time (s)     20.726361530832946
Sample Time (s)              7.856264054309577
Epoch Time (s)               176.13228171225637
Total Train Time (s)         68769.90114028193
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:59:49.372402 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #400 | Epoch Duration: 176.22403979301453
2020-01-13 02:59:49.372601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #400 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8959926
Z variance train             0.08060728
KL Divergence                49.043262
KL Loss                      4.9043264
QF Loss                      268.07703
VF Loss                      54.187744
Policy Loss                  -1392.2711
Q Predictions Mean           1386.0889
Q Predictions Std            1364.6765
Q Predictions Max            4764.547
Q Predictions Min            707.3445
V Predictions Mean           1392.8737
V Predictions Std            1365.1265
V Predictions Max            4758.2
V Predictions Min            711.6903
Log Pis Mean                 -0.34766886
Log Pis Std                  3.823209
Log Pis Max                  16.607677
Log Pis Min                  -8.138903
Policy mu Mean               0.0417417
Policy mu Std                0.85917664
Policy mu Max                2.822535
Policy mu Min                -2.4961216
Policy log std Mean          -0.5044164
Policy log std Std           0.28639013
Policy log std Max           0.0030941367
Policy log std Min           -2.7194276
Z mean eval                  1.8907025
Z variance eval              0.07908176
total_rewards                [10181.13560882 10634.45164651 10583.8271003  10628.47556263
 10380.98344822 10429.38348584 10494.38948414 10508.51010645
 10451.60816255 10658.85153375]
total_rewards_mean           10495.161613920476
total_rewards_std            137.79757237536944
total_rewards_max            10658.851533746281
total_rewards_min            10181.135608824967
Number of train steps total  1608000
Number of env steps total    4826000
Number of rollouts total     0
Train Time (s)               146.24460635427386
(Previous) Eval Time (s)     20.84005969297141
Sample Time (s)              5.436967414338142
Epoch Time (s)               172.5216334615834
Total Train Time (s)         68942.50756613119
Epoch                        401
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:02:41.981393 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #401 | Epoch Duration: 172.60865473747253
2020-01-13 03:02:41.981527 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #401 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8914257
Z variance train             0.07958003
KL Divergence                49.156322
KL Loss                      4.9156322
QF Loss                      144.6893
VF Loss                      71.054504
Policy Loss                  -1442.1516
Q Predictions Mean           1439.4854
Q Predictions Std            1354.0951
Q Predictions Max            4672.2397
Q Predictions Min            654.2663
V Predictions Mean           1445.7979
V Predictions Std            1356.6324
V Predictions Max            4662.3774
V Predictions Min            636.99146
Log Pis Mean                 0.0688279
Log Pis Std                  3.8911655
Log Pis Max                  15.387388
Log Pis Min                  -5.5450206
Policy mu Mean               0.1214571
Policy mu Std                0.9058417
Policy mu Max                2.89713
Policy mu Min                -2.6584604
Policy log std Mean          -0.50110143
Policy log std Std           0.29672113
Policy log std Max           -0.029788017
Policy log std Min           -3.006113
Z mean eval                  1.9087007
Z variance eval              0.04927544
total_rewards                [10020.70742393 10454.5346494   9973.21762765 10294.8074457
 10469.3633284  10253.60824097 10293.83901451 10424.46012263
 10239.88335794 10065.7624949 ]
total_rewards_mean           10249.018370604685
total_rewards_std            169.57398051487638
total_rewards_max            10469.363328402946
total_rewards_min            9973.217627652788
Number of train steps total  1612000
Number of env steps total    4838000
Number of rollouts total     0
Train Time (s)               147.01670192694291
(Previous) Eval Time (s)     17.268064606003463
Sample Time (s)              6.365338065195829
Epoch Time (s)               170.6501045981422
Total Train Time (s)         69113.23715629894
Epoch                        402
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:05:32.715181 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #402 | Epoch Duration: 170.73354125022888
2020-01-13 03:05:32.715357 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9093287
Z variance train             0.04923575
KL Divergence                50.174175
KL Loss                      5.0174174
QF Loss                      130.29462
VF Loss                      37.90901
Policy Loss                  -1413.2888
Q Predictions Mean           1412.3329
Q Predictions Std            1371.0259
Q Predictions Max            4663.105
Q Predictions Min            698.7093
V Predictions Mean           1416.2777
V Predictions Std            1368.8014
V Predictions Max            4666.217
V Predictions Min            705.22375
Log Pis Mean                 0.020787477
Log Pis Std                  3.697312
Log Pis Max                  11.540907
Log Pis Min                  -7.9941416
Policy mu Mean               0.016952919
Policy mu Std                0.92344886
Policy mu Max                2.7234552
Policy mu Min                -2.5282722
Policy log std Mean          -0.50719875
Policy log std Std           0.27393925
Policy log std Max           -0.06504363
Policy log std Min           -2.7799015
Z mean eval                  1.9020351
Z variance eval              0.08188798
total_rewards                [10007.84151399 10614.85266385 10094.26223764 10242.07418013
 10403.6013173  10487.15937296 10377.75813903 10472.34304095
 10439.91042286 10056.50760039]
total_rewards_mean           10319.63104890899
total_rewards_std            196.64491308272758
total_rewards_max            10614.852663852991
total_rewards_min            10007.841513985688
Number of train steps total  1616000
Number of env steps total    4850000
Number of rollouts total     0
Train Time (s)               147.07247551577166
(Previous) Eval Time (s)     20.87780385883525
Sample Time (s)              6.531084469053894
Epoch Time (s)               174.4813638436608
Total Train Time (s)         69288.06970913243
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:08:27.581230 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #403 | Epoch Duration: 174.86558175086975
2020-01-13 03:08:27.581730 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #403 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9019037
Z variance train             0.0818142
KL Divergence                50.639668
KL Loss                      5.0639668
QF Loss                      88.938576
VF Loss                      66.23644
Policy Loss                  -1551.7
Q Predictions Mean           1547.9917
Q Predictions Std            1460.049
Q Predictions Max            4646.807
Q Predictions Min            704.4257
V Predictions Mean           1546.9537
V Predictions Std            1455.52
V Predictions Max            4628.9937
V Predictions Min            708.3448
Log Pis Mean                 0.123206556
Log Pis Std                  4.027325
Log Pis Max                  13.753431
Log Pis Min                  -7.54463
Policy mu Mean               0.116163135
Policy mu Std                0.93766564
Policy mu Max                2.8512459
Policy mu Min                -2.7034023
Policy log std Mean          -0.51527065
Policy log std Std           0.29420364
Policy log std Max           -0.07583785
Policy log std Min           -2.6284375
Z mean eval                  1.9048783
Z variance eval              0.045196317
total_rewards                [ 9853.45148005 10458.6067557  10681.29294056 10422.30578566
  9992.68060252 10487.70317458 10473.59654123 10334.78775473
 10483.45138259 10573.59633811]
total_rewards_mean           10376.147275571167
total_rewards_std            244.22400095114963
total_rewards_max            10681.292940562615
total_rewards_min            9853.451480046451
Number of train steps total  1620000
Number of env steps total    4862000
Number of rollouts total     0
Train Time (s)               147.56863400200382
(Previous) Eval Time (s)     18.257526158355176
Sample Time (s)              5.612033978104591
Epoch Time (s)               171.4381941384636
Total Train Time (s)         69459.62204274116
Epoch                        404
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:11:19.112996 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #404 | Epoch Duration: 171.53094005584717
2020-01-13 03:11:19.113278 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #404 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9035791
Z variance train             0.045097522
KL Divergence                51.89647
KL Loss                      5.189647
QF Loss                      62.448708
VF Loss                      56.872597
Policy Loss                  -1257.701
Q Predictions Mean           1254.8469
Q Predictions Std            1191.9884
Q Predictions Max            4626.693
Q Predictions Min            691.5789
V Predictions Mean           1257.6493
V Predictions Std            1193.6772
V Predictions Max            4629.8423
V Predictions Min            693.3224
Log Pis Mean                 -0.4249233
Log Pis Std                  3.9518464
Log Pis Max                  15.262182
Log Pis Min                  -7.9909487
Policy mu Mean               0.119920574
Policy mu Std                0.8579678
Policy mu Max                2.7288961
Policy mu Min                -2.9017231
Policy log std Mean          -0.47444698
Policy log std Std           0.28718987
Policy log std Max           -0.03533888
Policy log std Min           -2.5285473
Z mean eval                  1.9271549
Z variance eval              0.04545523
total_rewards                [ 9040.36581613 10410.81695893 10068.99932588 10149.08265198
 10351.85605264 10059.15801608 10149.79738909 10524.50109978
 10437.13109981 10131.39816965]
total_rewards_mean           10132.310657996222
total_rewards_std            396.835718402072
total_rewards_max            10524.501099779998
total_rewards_min            9040.365816128613
Number of train steps total  1624000
Number of env steps total    4874000
Number of rollouts total     0
Train Time (s)               145.59316671732813
(Previous) Eval Time (s)     20.78404233790934
Sample Time (s)              6.371390086598694
Epoch Time (s)               172.74859914183617
Total Train Time (s)         69632.66144053452
Epoch                        405
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:14:12.156340 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #405 | Epoch Duration: 173.04278588294983
2020-01-13 03:14:12.156680 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #405 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9306023
Z variance train             0.045355685
KL Divergence                50.717556
KL Loss                      5.071756
QF Loss                      143.01958
VF Loss                      45.46712
Policy Loss                  -1531.0287
Q Predictions Mean           1530.2045
Q Predictions Std            1459.9777
Q Predictions Max            4650.2153
Q Predictions Min            692.61646
V Predictions Mean           1527.9799
V Predictions Std            1455.456
V Predictions Max            4634.5786
V Predictions Min            695.5101
Log Pis Mean                 -0.2509101
Log Pis Std                  3.544971
Log Pis Max                  13.789306
Log Pis Min                  -5.608187
Policy mu Mean               0.06766143
Policy mu Std                0.8921502
Policy mu Max                2.7028346
Policy mu Min                -2.6613083
Policy log std Mean          -0.50934815
Policy log std Std           0.292061
Policy log std Max           0.22581631
Policy log std Min           -2.540585
Z mean eval                  1.9113026
Z variance eval              0.08933032
total_rewards                [ 9761.91476524 10010.41458741 10270.51801116 10328.67489336
 10347.02692754 10356.99700205 10338.74287618 10512.5149663
 10399.43254536 10310.53518988]
total_rewards_mean           10263.677176447924
total_rewards_std            205.91625140606521
total_rewards_max            10512.514966299592
total_rewards_min            9761.914765244146
Number of train steps total  1628000
Number of env steps total    4886000
Number of rollouts total     0
Train Time (s)               146.05503563396633
(Previous) Eval Time (s)     17.530388582963496
Sample Time (s)              6.448921694420278
Epoch Time (s)               170.0343459113501
Total Train Time (s)         69802.78374348581
Epoch                        406
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:17:02.282554 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #406 | Epoch Duration: 170.12565636634827
2020-01-13 03:17:02.282780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9119383
Z variance train             0.089284636
KL Divergence                49.54314
KL Loss                      4.954314
QF Loss                      157.936
VF Loss                      52.6373
Policy Loss                  -1454.8331
Q Predictions Mean           1450.8176
Q Predictions Std            1381.1001
Q Predictions Max            4662.2383
Q Predictions Min            680.4296
V Predictions Mean           1456.5164
V Predictions Std            1381.1368
V Predictions Max            4666.107
V Predictions Min            702.14764
Log Pis Mean                 -0.13694774
Log Pis Std                  4.0394444
Log Pis Max                  19.566591
Log Pis Min                  -7.128259
Policy mu Mean               0.1017443
Policy mu Std                0.88972336
Policy mu Max                4.0167212
Policy mu Min                -3.9662228
Policy log std Mean          -0.4972858
Policy log std Std           0.28805614
Policy log std Max           0.0031924248
Policy log std Min           -2.7353864
Z mean eval                  1.9184656
Z variance eval              0.047562502
total_rewards                [9021.55353495 6900.03137473 9729.35908047 9466.39622991 9685.21852307
 9504.84158563 9458.07763539 9735.17372541 9643.30610432 9683.70311934]
total_rewards_mean           9282.76609132259
total_rewards_std            819.5275435459471
total_rewards_max            9735.173725410787
total_rewards_min            6900.031374726737
Number of train steps total  1632000
Number of env steps total    4898000
Number of rollouts total     0
Train Time (s)               145.95770594710484
(Previous) Eval Time (s)     20.674642940983176
Sample Time (s)              6.458085722755641
Epoch Time (s)               173.09043461084366
Total Train Time (s)         69975.98031010525
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:19:55.481938 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #407 | Epoch Duration: 173.19901204109192
2020-01-13 03:19:55.482072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9198542
Z variance train             0.047561683
KL Divergence                51.408974
KL Loss                      5.1408973
QF Loss                      96.77911
VF Loss                      187.27856
Policy Loss                  -1518.1522
Q Predictions Mean           1517.7821
Q Predictions Std            1472.9191
Q Predictions Max            4738.781
Q Predictions Min            693.8588
V Predictions Mean           1525.6038
V Predictions Std            1474.5701
V Predictions Max            4770.2017
V Predictions Min            694.8026
Log Pis Mean                 -0.6332035
Log Pis Std                  3.698829
Log Pis Max                  14.706481
Log Pis Min                  -8.317611
Policy mu Mean               0.06600802
Policy mu Std                0.86539733
Policy mu Max                3.2599237
Policy mu Min                -3.059905
Policy log std Mean          -0.50233513
Policy log std Std           0.29137227
Policy log std Max           -0.05104947
Policy log std Min           -2.734068
Z mean eval                  1.9040403
Z variance eval              0.03472104
total_rewards                [10152.06355342 10122.14515676 10233.30280918 10111.63739746
 10521.9490896  10700.99210519 10579.2912821  10337.13915585
 10645.89598697 10548.57732447]
total_rewards_mean           10395.299386100949
total_rewards_std            217.60067023640474
total_rewards_max            10700.992105191368
total_rewards_min            10111.637397455697
Number of train steps total  1636000
Number of env steps total    4910000
Number of rollouts total     0
Train Time (s)               144.6892712879926
(Previous) Eval Time (s)     20.71940801013261
Sample Time (s)              6.486786783207208
Epoch Time (s)               171.89546608133242
Total Train Time (s)         70147.95798850898
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:22:47.462829 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #408 | Epoch Duration: 171.9806604385376
2020-01-13 03:22:47.462966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #408 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9032748
Z variance train             0.034642346
KL Divergence                51.761208
KL Loss                      5.1761208
QF Loss                      104.74103
VF Loss                      95.21057
Policy Loss                  -1260.4647
Q Predictions Mean           1259.0157
Q Predictions Std            1239.2526
Q Predictions Max            4615.688
Q Predictions Min            687.251
V Predictions Mean           1264.0597
V Predictions Std            1241.2789
V Predictions Max            4634.2075
V Predictions Min            688.8315
Log Pis Mean                 -0.40070802
Log Pis Std                  3.6125154
Log Pis Max                  13.137016
Log Pis Min                  -6.237115
Policy mu Mean               0.10500238
Policy mu Std                0.852738
Policy mu Max                3.1923788
Policy mu Min                -2.959377
Policy log std Mean          -0.47051883
Policy log std Std           0.27973184
Policy log std Max           -0.061506122
Policy log std Min           -2.6840854
Z mean eval                  1.8972183
Z variance eval              0.060329385
total_rewards                [10195.38218519 10174.75402601 10508.35572272 10060.4427909
 10131.16641144 10338.56199815  2537.62374708 10559.44402788
 10329.98891393  9897.65084255]
total_rewards_mean           9473.337066583337
total_rewards_std            2319.661342378474
total_rewards_max            10559.444027883215
total_rewards_min            2537.6237470791493
Number of train steps total  1640000
Number of env steps total    4922000
Number of rollouts total     0
Train Time (s)               149.62660721875727
(Previous) Eval Time (s)     20.683767335955054
Sample Time (s)              6.628593503963202
Epoch Time (s)               176.93896805867553
Total Train Time (s)         70324.97663286468
Epoch                        409
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:25:44.484660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #409 | Epoch Duration: 177.02158951759338
2020-01-13 03:25:44.484827 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #409 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.898361
Z variance train             0.06061256
KL Divergence                50.95791
KL Loss                      5.095791
QF Loss                      580.7645
VF Loss                      47.348183
Policy Loss                  -1438.6224
Q Predictions Mean           1437.777
Q Predictions Std            1358.7539
Q Predictions Max            4689.0454
Q Predictions Min            693.52045
V Predictions Mean           1438.1655
V Predictions Std            1355.6604
V Predictions Max            4654.231
V Predictions Min            688.8895
Log Pis Mean                 0.0021902397
Log Pis Std                  3.784885
Log Pis Max                  15.419238
Log Pis Min                  -7.8187304
Policy mu Mean               0.04670159
Policy mu Std                0.90317976
Policy mu Max                3.212234
Policy mu Min                -2.8004475
Policy log std Mean          -0.5012701
Policy log std Std           0.28457695
Policy log std Max           0.04518783
Policy log std Min           -2.761546
Z mean eval                  1.9216158
Z variance eval              0.06236539
total_rewards                [10022.64123292 10038.89546783 10047.19971788 10186.22987949
 10238.73484746 10241.2308908  10461.76211658 10444.33594291
 10288.71633908  4367.73002242]
total_rewards_mean           9633.747645737843
total_rewards_std            1761.5105611830609
total_rewards_max            10461.762116584921
total_rewards_min            4367.730022415902
Number of train steps total  1644000
Number of env steps total    4934000
Number of rollouts total     0
Train Time (s)               146.64515613717958
(Previous) Eval Time (s)     20.76957193063572
Sample Time (s)              5.4242078815586865
Epoch Time (s)               172.838935949374
Total Train Time (s)         70497.90971040679
Epoch                        410
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:28:37.419859 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #410 | Epoch Duration: 172.9349136352539
2020-01-13 03:28:37.419993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #410 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9217046
Z variance train             0.062167536
KL Divergence                50.92323
KL Loss                      5.092323
QF Loss                      175.8577
VF Loss                      58.330154
Policy Loss                  -1362.3218
Q Predictions Mean           1361.1067
Q Predictions Std            1339.69
Q Predictions Max            4733.2837
Q Predictions Min            695.8612
V Predictions Mean           1362.2195
V Predictions Std            1333.0293
V Predictions Max            4724.6846
V Predictions Min            700.52045
Log Pis Mean                 -0.3443896
Log Pis Std                  3.6539109
Log Pis Max                  10.355797
Log Pis Min                  -8.437069
Policy mu Mean               0.09024197
Policy mu Std                0.8729348
Policy mu Max                2.748036
Policy mu Min                -2.7594228
Policy log std Mean          -0.48251942
Policy log std Std           0.28990763
Policy log std Max           -0.06692338
Policy log std Min           -2.789962
Z mean eval                  1.8893859
Z variance eval              0.059290547
total_rewards                [10137.45131425 10207.89222409 10451.94323063 10088.34109845
 10351.68973896 10551.80174229 10329.90292221 10122.36233376
 10376.69305231 10847.73137168]
total_rewards_mean           10346.580902862454
total_rewards_std            220.34316417667227
total_rewards_max            10847.731371677062
total_rewards_min            10088.34109844847
Number of train steps total  1648000
Number of env steps total    4946000
Number of rollouts total     0
Train Time (s)               146.55383007135242
(Previous) Eval Time (s)     17.470764236990362
Sample Time (s)              6.364544781856239
Epoch Time (s)               170.38913909019902
Total Train Time (s)         70668.39760744246
Epoch                        411
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:31:27.914958 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #411 | Epoch Duration: 170.4948501586914
2020-01-13 03:31:27.915147 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #411 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8896393
Z variance train             0.05889716
KL Divergence                49.90686
KL Loss                      4.990686
QF Loss                      69.42998
VF Loss                      34.356316
Policy Loss                  -1242.4695
Q Predictions Mean           1242.7384
Q Predictions Std            1214.2166
Q Predictions Max            4677.659
Q Predictions Min            675.4875
V Predictions Mean           1243.9016
V Predictions Std            1213.8802
V Predictions Max            4675.113
V Predictions Min            686.46515
Log Pis Mean                 -0.457246
Log Pis Std                  3.6575263
Log Pis Max                  12.163237
Log Pis Min                  -7.83512
Policy mu Mean               0.09167
Policy mu Std                0.84581834
Policy mu Max                2.6422222
Policy mu Min                -2.52305
Policy log std Mean          -0.47864732
Policy log std Std           0.2753019
Policy log std Max           -0.06319037
Policy log std Min           -2.9306457
Z mean eval                  1.9081268
Z variance eval              0.055146944
total_rewards                [ 9848.33846484 10292.50883623 10028.20097492 10089.21525888
  9517.09762357 10369.75066999 10026.41766858 10370.56570939
 10027.27065446  9888.68974276]
total_rewards_mean           10045.805560361478
total_rewards_std            248.4746601945126
total_rewards_max            10370.565709386727
total_rewards_min            9517.097623573798
Number of train steps total  1652000
Number of env steps total    4958000
Number of rollouts total     0
Train Time (s)               147.36103295581415
(Previous) Eval Time (s)     20.875341047067195
Sample Time (s)              6.434187808539718
Epoch Time (s)               174.67056181142107
Total Train Time (s)         70843.17032394651
Epoch                        412
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:34:22.693947 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #412 | Epoch Duration: 174.77866458892822
2020-01-13 03:34:22.694092 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #412 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9079773
Z variance train             0.05508669
KL Divergence                50.664608
KL Loss                      5.066461
QF Loss                      136.69135
VF Loss                      113.4421
Policy Loss                  -1325.5526
Q Predictions Mean           1324.5194
Q Predictions Std            1288.1747
Q Predictions Max            4674.022
Q Predictions Min            659.9891
V Predictions Mean           1331.2811
V Predictions Std            1290.5143
V Predictions Max            4694.6235
V Predictions Min            676.55066
Log Pis Mean                 -0.6195383
Log Pis Std                  3.7897599
Log Pis Max                  14.223317
Log Pis Min                  -12.076387
Policy mu Mean               0.03737031
Policy mu Std                0.87058735
Policy mu Max                3.2809937
Policy mu Min                -3.1132305
Policy log std Mean          -0.48413816
Policy log std Std           0.27450758
Policy log std Max           0.08145416
Policy log std Min           -2.9153934
Z mean eval                  1.8864071
Z variance eval              0.051914968
total_rewards                [10580.00491185 10118.82530119 10666.94815985 10183.22600935
 10531.34490025 10748.34644654 10324.94926125 10384.12463992
 10712.05620115 10317.45854227]
total_rewards_mean           10456.728437362563
total_rewards_std            211.23580225983247
total_rewards_max            10748.346446542624
total_rewards_min            10118.825301186498
Number of train steps total  1656000
Number of env steps total    4970000
Number of rollouts total     0
Train Time (s)               148.456434473861
(Previous) Eval Time (s)     20.48492588987574
Sample Time (s)              6.3358022519387305
Epoch Time (s)               175.27716261567548
Total Train Time (s)         71018.52901811246
Epoch                        413
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:37:18.056480 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #413 | Epoch Duration: 175.36228942871094
2020-01-13 03:37:18.056617 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8858938
Z variance train             0.051822376
KL Divergence                50.775673
KL Loss                      5.0775676
QF Loss                      4485.117
VF Loss                      64.52556
Policy Loss                  -1490.6953
Q Predictions Mean           1491.9856
Q Predictions Std            1442.7046
Q Predictions Max            4629.524
Q Predictions Min            670.9963
V Predictions Mean           1494.7422
V Predictions Std            1436.3093
V Predictions Max            4623.161
V Predictions Min            689.27954
Log Pis Mean                 -0.32219306
Log Pis Std                  3.6351945
Log Pis Max                  14.979469
Log Pis Min                  -8.619598
Policy mu Mean               0.065692045
Policy mu Std                0.8824567
Policy mu Max                3.0950818
Policy mu Min                -2.8651373
Policy log std Mean          -0.4962966
Policy log std Std           0.28560624
Policy log std Max           0.051529706
Policy log std Min           -2.706001
Z mean eval                  1.9047245
Z variance eval              0.049020458
total_rewards                [10072.19847103 10370.01947789 10360.97302424 10315.86294732
 10229.49907985 10288.96337508 10559.46132728 10265.31797594
 10351.71114117 10360.88567238]
total_rewards_mean           10317.489249217893
total_rewards_std            117.34700059451615
total_rewards_max            10559.461327275943
total_rewards_min            10072.19847102722
Number of train steps total  1660000
Number of env steps total    4982000
Number of rollouts total     0
Train Time (s)               146.4452155227773
(Previous) Eval Time (s)     17.613607332110405
Sample Time (s)              6.5380096337758005
Epoch Time (s)               170.5968324886635
Total Train Time (s)         71189.20772393327
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:40:08.742268 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #414 | Epoch Duration: 170.68549585342407
2020-01-13 03:40:08.742588 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #414 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9030335
Z variance train             0.049007714
KL Divergence                51.117786
KL Loss                      5.1117787
QF Loss                      4479.4785
VF Loss                      88.2288
Policy Loss                  -1353.4705
Q Predictions Mean           1351.0798
Q Predictions Std            1318.5839
Q Predictions Max            4616.165
Q Predictions Min            683.39874
V Predictions Mean           1355.4924
V Predictions Std            1323.6558
V Predictions Max            4643.148
V Predictions Min            679.95953
Log Pis Mean                 -0.33871046
Log Pis Std                  3.7094655
Log Pis Max                  13.109023
Log Pis Min                  -7.0882816
Policy mu Mean               0.028483475
Policy mu Std                0.8574167
Policy mu Max                3.1066918
Policy mu Min                -2.6727235
Policy log std Mean          -0.49156967
Policy log std Std           0.31515914
Policy log std Max           0.040480673
Policy log std Min           -2.799239
Z mean eval                  1.9117801
Z variance eval              0.047973588
total_rewards                [10077.03456934 10158.32913838 10236.51563998  9917.54576903
 10272.09990461 10564.78818909 10304.47774205 10251.84277101
 10334.63319189 10392.38527851]
total_rewards_mean           10250.965219388254
total_rewards_std            167.0348732766465
total_rewards_max            10564.788189088142
total_rewards_min            9917.545769028582
Number of train steps total  1664000
Number of env steps total    4994000
Number of rollouts total     0
Train Time (s)               145.84422278031707
(Previous) Eval Time (s)     20.85423147585243
Sample Time (s)              6.639511271379888
Epoch Time (s)               173.3379655275494
Total Train Time (s)         71362.6301852935
Epoch                        415
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:43:02.164233 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #415 | Epoch Duration: 173.42139196395874
2020-01-13 03:43:02.164369 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9090321
Z variance train             0.048072636
KL Divergence                49.95606
KL Loss                      4.995606
QF Loss                      318.5901
VF Loss                      28.482796
Policy Loss                  -1249.6987
Q Predictions Mean           1249.278
Q Predictions Std            1200.3038
Q Predictions Max            4674.6636
Q Predictions Min            678.27954
V Predictions Mean           1251.0793
V Predictions Std            1199.079
V Predictions Max            4694.9233
V Predictions Min            681.37836
Log Pis Mean                 -0.37968627
Log Pis Std                  3.4127333
Log Pis Max                  17.227453
Log Pis Min                  -6.808982
Policy mu Mean               0.07913401
Policy mu Std                0.85954875
Policy mu Max                2.8972535
Policy mu Min                -3.759299
Policy log std Mean          -0.47546014
Policy log std Std           0.2672964
Policy log std Max           0.061985493
Policy log std Min           -2.9416418
Z mean eval                  1.9202328
Z variance eval              0.09039552
total_rewards                [ 9993.91765485 10566.68320112 10196.55062133 10384.13437764
 10134.2606386  10565.42222314 10461.37687632 10085.54778094
 10337.67582365 10389.53666379]
total_rewards_mean           10311.510586137098
total_rewards_std            189.9075533160327
total_rewards_max            10566.683201115393
total_rewards_min            9993.91765484697
Number of train steps total  1668000
Number of env steps total    5006000
Number of rollouts total     0
Train Time (s)               145.22856312105432
(Previous) Eval Time (s)     17.817012610845268
Sample Time (s)              6.609399145934731
Epoch Time (s)               169.65497487783432
Total Train Time (s)         71532.36522533651
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:45:51.903394 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #416 | Epoch Duration: 169.73891472816467
2020-01-13 03:45:51.903576 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #416 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9192501
Z variance train             0.09033766
KL Divergence                49.96923
KL Loss                      4.996923
QF Loss                      217.94226
VF Loss                      67.3744
Policy Loss                  -1413.004
Q Predictions Mean           1409.77
Q Predictions Std            1384.7948
Q Predictions Max            4738.61
Q Predictions Min            670.6586
V Predictions Mean           1416.2336
V Predictions Std            1379.1298
V Predictions Max            4704.6855
V Predictions Min            683.3442
Log Pis Mean                 -0.4071174
Log Pis Std                  3.849716
Log Pis Max                  19.150265
Log Pis Min                  -6.771483
Policy mu Mean               0.05351563
Policy mu Std                0.8955893
Policy mu Max                2.9305935
Policy mu Min                -2.8508265
Policy log std Mean          -0.49699935
Policy log std Std           0.29463968
Policy log std Max           -0.08809477
Policy log std Min           -2.9315991
Z mean eval                  1.8951561
Z variance eval              0.052683067
total_rewards                [ 9727.27015001 10176.86886251 10121.20768424  9867.93726966
 10190.17784999 10019.09770919 10055.09683776 10108.17784449
 10195.10561784 10183.04586313]
total_rewards_mean           10064.398568882605
total_rewards_std            148.04280162705882
total_rewards_max            10195.105617840225
total_rewards_min            9727.2701500129
Number of train steps total  1672000
Number of env steps total    5018000
Number of rollouts total     0
Train Time (s)               145.67443236894906
(Previous) Eval Time (s)     20.715956420172006
Sample Time (s)              6.584896146319807
Epoch Time (s)               172.97528493544087
Total Train Time (s)         71705.42732709227
Epoch                        417
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:48:44.968321 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #417 | Epoch Duration: 173.06461453437805
2020-01-13 03:48:44.968467 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #417 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8953774
Z variance train             0.052962057
KL Divergence                49.511055
KL Loss                      4.9511056
QF Loss                      147.67294
VF Loss                      52.705566
Policy Loss                  -1439.3813
Q Predictions Mean           1438.3054
Q Predictions Std            1395.9504
Q Predictions Max            4737.3696
Q Predictions Min            680.9345
V Predictions Mean           1436.2761
V Predictions Std            1387.0684
V Predictions Max            4721.2246
V Predictions Min            682.11176
Log Pis Mean                 -0.29648617
Log Pis Std                  3.687315
Log Pis Max                  13.249498
Log Pis Min                  -8.209368
Policy mu Mean               0.10772133
Policy mu Std                0.8801426
Policy mu Max                2.6569192
Policy mu Min                -2.8670819
Policy log std Mean          -0.49844554
Policy log std Std           0.30773842
Policy log std Max           -0.034392744
Policy log std Min           -3.170532
Z mean eval                  1.895586
Z variance eval              0.088887885
total_rewards                [10088.34513316 10077.87525678 10521.53872767 10389.75032566
 10083.67515606 10197.44777532 10502.97726864 10217.50387416
 10444.2439429  10459.48073907]
total_rewards_mean           10298.283819942477
total_rewards_std            174.01191359615746
total_rewards_max            10521.538727670284
total_rewards_min            10077.875256780952
Number of train steps total  1676000
Number of env steps total    5030000
Number of rollouts total     0
Train Time (s)               145.51977327885106
(Previous) Eval Time (s)     20.817774121183902
Sample Time (s)              6.534645848441869
Epoch Time (s)               172.87219324847683
Total Train Time (s)         71878.37664187187
Epoch                        418
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:51:37.920300 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #418 | Epoch Duration: 172.95173263549805
2020-01-13 03:51:37.920431 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #418 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8945484
Z variance train             0.088657215
KL Divergence                48.90981
KL Loss                      4.890981
QF Loss                      110.48957
VF Loss                      58.332558
Policy Loss                  -1344.0865
Q Predictions Mean           1341.951
Q Predictions Std            1320.4264
Q Predictions Max            4679.668
Q Predictions Min            695.7211
V Predictions Mean           1342.4121
V Predictions Std            1314.1053
V Predictions Max            4659.051
V Predictions Min            697.92316
Log Pis Mean                 -0.21328449
Log Pis Std                  3.8451986
Log Pis Max                  20.92426
Log Pis Min                  -9.538202
Policy mu Mean               0.08821279
Policy mu Std                0.8951096
Policy mu Max                3.0155115
Policy mu Min                -3.3716512
Policy log std Mean          -0.48944154
Policy log std Std           0.28181142
Policy log std Max           -0.0489676
Policy log std Min           -2.5961473
Z mean eval                  1.9051679
Z variance eval              0.05230831
total_rewards                [10416.77257356 10656.82271874 10457.33151102 10798.62037093
 10824.28035009 10887.39538031 10300.35000963 10763.71902259
 10827.9754278  10887.51777466]
total_rewards_mean           10682.078513932396
total_rewards_std            203.31446523542408
total_rewards_max            10887.517774659673
total_rewards_min            10300.3500096262
Number of train steps total  1680000
Number of env steps total    5042000
Number of rollouts total     0
Train Time (s)               146.3434685477987
(Previous) Eval Time (s)     20.63211562903598
Sample Time (s)              6.596232309937477
Epoch Time (s)               173.57181648677215
Total Train Time (s)         72052.0823740419
Epoch                        419
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:54:31.648677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #419 | Epoch Duration: 173.72810888290405
2020-01-13 03:54:31.648967 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #419 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9046484
Z variance train             0.05262629
KL Divergence                49.78643
KL Loss                      4.978643
QF Loss                      120.057945
VF Loss                      71.24375
Policy Loss                  -1300.93
Q Predictions Mean           1299.4507
Q Predictions Std            1281.3684
Q Predictions Max            4729.4883
Q Predictions Min            688.50275
V Predictions Mean           1302.5768
V Predictions Std            1278.6549
V Predictions Max            4696.3623
V Predictions Min            688.43896
Log Pis Mean                 -0.56312174
Log Pis Std                  3.4269521
Log Pis Max                  11.639732
Log Pis Min                  -6.4594936
Policy mu Mean               -0.01335979
Policy mu Std                0.86223793
Policy mu Max                2.7800672
Policy mu Min                -2.7978168
Policy log std Mean          -0.4914458
Policy log std Std           0.27327588
Policy log std Max           -0.065935045
Policy log std Min           -3.060028
Z mean eval                  1.9179713
Z variance eval              0.054015595
total_rewards                [10254.34737091 10511.01109638 10620.1810199  10533.99846966
 10650.14811662 10500.47665591 10726.56947747 10432.80855638
 10542.22862795 10795.45072685]
total_rewards_mean           10556.722011803544
total_rewards_std            145.38206802569715
total_rewards_max            10795.450726851666
total_rewards_min            10254.347370908674
Number of train steps total  1684000
Number of env steps total    5054000
Number of rollouts total     0
Train Time (s)               146.03571323072538
(Previous) Eval Time (s)     20.81830655504018
Sample Time (s)              8.621596432756633
Epoch Time (s)               175.4756162185222
Total Train Time (s)         72227.6696280567
Epoch                        420
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:57:27.223142 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #420 | Epoch Duration: 175.57396984100342
2020-01-13 03:57:27.223279 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9196889
Z variance train             0.05403748
KL Divergence                50.20552
KL Loss                      5.020552
QF Loss                      106.13934
VF Loss                      79.413086
Policy Loss                  -1275.3733
Q Predictions Mean           1271.3417
Q Predictions Std            1239.26
Q Predictions Max            4706.5996
Q Predictions Min            688.83923
V Predictions Mean           1270.0295
V Predictions Std            1234.7999
V Predictions Max            4698.298
V Predictions Min            685.8922
Log Pis Mean                 -0.540437
Log Pis Std                  3.5205674
Log Pis Max                  12.268975
Log Pis Min                  -6.8160996
Policy mu Mean               0.066494934
Policy mu Std                0.8388445
Policy mu Max                3.4995947
Policy mu Min                -2.7597845
Policy log std Mean          -0.48797974
Policy log std Std           0.29075852
Policy log std Max           -0.008509815
Policy log std Min           -2.7096539
Z mean eval                  1.9067341
Z variance eval              0.04999695
total_rewards                [10333.45146788 10611.68770626 10887.40679357 10793.68170566
 10623.99611504 10718.42673641 10846.21095839 10612.01032177
 10341.50779513 10583.14073054]
total_rewards_mean           10635.152033065577
total_rewards_std            179.27927390153852
total_rewards_max            10887.406793573924
total_rewards_min            10333.451467876517
Number of train steps total  1688000
Number of env steps total    5066000
Number of rollouts total     0
Train Time (s)               147.33268348500133
(Previous) Eval Time (s)     20.714878904633224
Sample Time (s)              6.3484950377605855
Epoch Time (s)               174.39605742739514
Total Train Time (s)         72402.14744600747
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:00:21.704058 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #421 | Epoch Duration: 174.48068380355835
2020-01-13 04:00:21.704192 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #421 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9034961
Z variance train             0.049895417
KL Divergence                50.50301
KL Loss                      5.050301
QF Loss                      107.02425
VF Loss                      95.32562
Policy Loss                  -1361.4302
Q Predictions Mean           1359.0994
Q Predictions Std            1310.4183
Q Predictions Max            4746.247
Q Predictions Min            664.00146
V Predictions Mean           1362.4174
V Predictions Std            1311.7568
V Predictions Max            4756.7393
V Predictions Min            651.03265
Log Pis Mean                 -0.13518824
Log Pis Std                  3.959503
Log Pis Max                  17.24668
Log Pis Min                  -8.73677
Policy mu Mean               0.049543116
Policy mu Std                0.9002575
Policy mu Max                3.225898
Policy mu Min                -3.286909
Policy log std Mean          -0.4933783
Policy log std Std           0.27321997
Policy log std Max           -0.043605924
Policy log std Min           -2.8751194
Z mean eval                  1.8832439
Z variance eval              0.08442445
total_rewards                [10032.52220915 10406.20459433 10648.18329795 10845.52407724
 10506.48368447 10312.50778881 10656.80287969 10678.32437418
 10810.86886657 10878.07362057]
total_rewards_mean           10577.549539296473
total_rewards_std            252.92294044922812
total_rewards_max            10878.073620570245
total_rewards_min            10032.522209152547
Number of train steps total  1692000
Number of env steps total    5078000
Number of rollouts total     0
Train Time (s)               146.9567560260184
(Previous) Eval Time (s)     20.609389916993678
Sample Time (s)              6.396866306196898
Epoch Time (s)               173.963012249209
Total Train Time (s)         72576.19756108476
Epoch                        422
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:03:15.757486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #422 | Epoch Duration: 174.05319356918335
2020-01-13 04:03:15.757621 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #422 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8823969
Z variance train             0.084244385
KL Divergence                49.655647
KL Loss                      4.9655647
QF Loss                      156.62694
VF Loss                      118.66877
Policy Loss                  -1404.0399
Q Predictions Mean           1400.989
Q Predictions Std            1371.9249
Q Predictions Max            4703.492
Q Predictions Min            665.93884
V Predictions Mean           1400.9017
V Predictions Std            1362.0557
V Predictions Max            4686.586
V Predictions Min            675.0156
Log Pis Mean                 -0.6697594
Log Pis Std                  3.7378368
Log Pis Max                  14.782316
Log Pis Min                  -6.591645
Policy mu Mean               0.01472953
Policy mu Std                0.86166537
Policy mu Max                3.5941627
Policy mu Min                -2.6805322
Policy log std Mean          -0.49515995
Policy log std Std           0.29295358
Policy log std Max           0.0014413297
Policy log std Min           -2.9152918
Z mean eval                  1.8961376
Z variance eval              0.11275921
total_rewards                [ 9809.26084644 10281.70338736 10397.46283387 10173.8047025
 10145.81597742 10202.16503894 10150.49236571 10174.65949614
 10302.74507946 10063.77433644]
total_rewards_mean           10170.188406427493
total_rewards_std            150.09687150024817
total_rewards_max            10397.462833867252
total_rewards_min            9809.260846436482
Number of train steps total  1696000
Number of env steps total    5090000
Number of rollouts total     0
Train Time (s)               147.9545729327947
(Previous) Eval Time (s)     21.001318227965385
Sample Time (s)              6.574464097153395
Epoch Time (s)               175.53035525791347
Total Train Time (s)         72751.81169264344
Epoch                        423
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:06:11.375543 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #423 | Epoch Duration: 175.61781120300293
2020-01-13 04:06:11.375723 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #423 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.894201
Z variance train             0.112690076
KL Divergence                49.22386
KL Loss                      4.922386
QF Loss                      327.42172
VF Loss                      73.52609
Policy Loss                  -1551.0044
Q Predictions Mean           1543.9172
Q Predictions Std            1468.678
Q Predictions Max            4798.392
Q Predictions Min            691.71246
V Predictions Mean           1551.2965
V Predictions Std            1465.6459
V Predictions Max            4791.703
V Predictions Min            702.4459
Log Pis Mean                 -0.07596585
Log Pis Std                  4.229339
Log Pis Max                  23.620754
Log Pis Min                  -8.451209
Policy mu Mean               0.031022834
Policy mu Std                0.92968464
Policy mu Max                3.2298107
Policy mu Min                -3.572475
Policy log std Mean          -0.52026385
Policy log std Std           0.29819816
Policy log std Max           -0.049028724
Policy log std Min           -2.729099
Z mean eval                  1.9062674
Z variance eval              0.107914865
total_rewards                [10342.09043922 10620.17305676 10544.79981012 10565.63469913
 10627.95122393 10722.13909673 10739.58433593 10285.65310691
 10383.67995529 10773.05959156]
total_rewards_mean           10560.476531559934
total_rewards_std            163.17850744769967
total_rewards_max            10773.059591562493
total_rewards_min            10285.653106913234
Number of train steps total  1700000
Number of env steps total    5102000
Number of rollouts total     0
Train Time (s)               145.97968639899045
(Previous) Eval Time (s)     21.007165275048465
Sample Time (s)              6.403328616637737
Epoch Time (s)               173.39018029067665
Total Train Time (s)         72925.28572511999
Epoch                        424
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:09:04.852073 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #424 | Epoch Duration: 173.4762237071991
2020-01-13 04:09:04.852206 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9078194
Z variance train             0.108356334
KL Divergence                49.100407
KL Loss                      4.910041
QF Loss                      171.79646
VF Loss                      68.39865
Policy Loss                  -1514.0137
Q Predictions Mean           1512.9221
Q Predictions Std            1467.0681
Q Predictions Max            4695.462
Q Predictions Min            695.8809
V Predictions Mean           1509.7793
V Predictions Std            1459.8679
V Predictions Max            4678.2925
V Predictions Min            697.9403
Log Pis Mean                 -0.33023864
Log Pis Std                  4.071907
Log Pis Max                  15.026672
Log Pis Min                  -7.3767443
Policy mu Mean               0.073474
Policy mu Std                0.8790862
Policy mu Max                2.777174
Policy mu Min                -2.7942383
Policy log std Mean          -0.50430393
Policy log std Std           0.2945523
Policy log std Max           -0.051397145
Policy log std Min           -2.7429802
Z mean eval                  1.8830004
Z variance eval              0.07587813
total_rewards                [9780.32830344 9533.79953125 9794.37508154 9435.71211414 5882.20342252
 8812.7479142  9089.89911379 9788.63869989 9645.69092619 9749.88054792]
total_rewards_mean           9151.327565488007
total_rewards_std            1133.6101621210091
total_rewards_max            9794.375081542148
total_rewards_min            5882.20342252042
Number of train steps total  1704000
Number of env steps total    5114000
Number of rollouts total     0
Train Time (s)               145.18037056317553
(Previous) Eval Time (s)     20.70946630835533
Sample Time (s)              6.477448559831828
Epoch Time (s)               172.3672854313627
Total Train Time (s)         73097.72871010425
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:11:57.297420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #425 | Epoch Duration: 172.4451162815094
2020-01-13 04:11:57.297552 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8817803
Z variance train             0.07568092
KL Divergence                48.78075
KL Loss                      4.878075
QF Loss                      92.53147
VF Loss                      57.096195
Policy Loss                  -1452.8613
Q Predictions Mean           1449.2374
Q Predictions Std            1384.9773
Q Predictions Max            4741.1743
Q Predictions Min            663.6585
V Predictions Mean           1455.1782
V Predictions Std            1382.9597
V Predictions Max            4691.38
V Predictions Min            679.9805
Log Pis Mean                 -0.0023521483
Log Pis Std                  3.9969285
Log Pis Max                  13.569023
Log Pis Min                  -7.1639566
Policy mu Mean               0.08742782
Policy mu Std                0.9242485
Policy mu Max                3.2683961
Policy mu Min                -2.5247812
Policy log std Mean          -0.50161725
Policy log std Std           0.31714454
Policy log std Max           -0.0070199966
Policy log std Min           -2.8351846
Z mean eval                  1.8815165
Z variance eval              0.05259949
total_rewards                [10743.0611087  11044.86549384 10936.61725261 10889.41037995
 10719.67192232 10757.91020471 11069.61288059 10649.83768015
 10655.7289245  10802.4977244 ]
total_rewards_mean           10826.921357176443
total_rewards_std            143.83893871685893
total_rewards_max            11069.61288058858
total_rewards_min            10649.83768014959
Number of train steps total  1708000
Number of env steps total    5126000
Number of rollouts total     0
Train Time (s)               146.02187874075025
(Previous) Eval Time (s)     20.964037926401943
Sample Time (s)              6.386199675966054
Epoch Time (s)               173.37211634311825
Total Train Time (s)         73271.19776715711
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:14:50.769246 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #426 | Epoch Duration: 173.47160005569458
2020-01-13 04:14:50.769384 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #426 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8810203
Z variance train             0.05242799
KL Divergence                50.42947
KL Loss                      5.0429473
QF Loss                      12615.893
VF Loss                      78.05677
Policy Loss                  -1382.4568
Q Predictions Mean           1379.1156
Q Predictions Std            1281.0632
Q Predictions Max            4711.8535
Q Predictions Min            675.17883
V Predictions Mean           1385.1665
V Predictions Std            1278.4944
V Predictions Max            4703.565
V Predictions Min            692.48114
Log Pis Mean                 -0.0261468
Log Pis Std                  4.12001
Log Pis Max                  14.686729
Log Pis Min                  -7.691976
Policy mu Mean               0.06707336
Policy mu Std                0.9057575
Policy mu Max                2.9326742
Policy mu Min                -3.0936062
Policy log std Mean          -0.5051878
Policy log std Std           0.2848545
Policy log std Max           -0.08872169
Policy log std Min           -2.587383
Z mean eval                  1.882745
Z variance eval              0.084159344
total_rewards                [ 9899.00211365 10727.31462526 10428.35441824 10260.84465061
 10528.27344507 10556.55665729 10210.91577309 10375.40738054
 10009.64821855 10047.56173905]
total_rewards_mean           10304.387902135357
total_rewards_std            253.1391206950038
total_rewards_max            10727.314625262055
total_rewards_min            9899.002113652292
Number of train steps total  1712000
Number of env steps total    5138000
Number of rollouts total     0
Train Time (s)               147.19543016003445
(Previous) Eval Time (s)     20.69324969733134
Sample Time (s)              6.390401181764901
Epoch Time (s)               174.2790810391307
Total Train Time (s)         73445.56434388366
Epoch                        427
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:17:45.138911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #427 | Epoch Duration: 174.3694293498993
2020-01-13 04:17:45.139049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8813183
Z variance train             0.0848428
KL Divergence                50.271935
KL Loss                      5.0271935
QF Loss                      106.22778
VF Loss                      81.139114
Policy Loss                  -1438.2771
Q Predictions Mean           1436.7894
Q Predictions Std            1376.5328
Q Predictions Max            4728.0273
Q Predictions Min            694.3598
V Predictions Mean           1436.936
V Predictions Std            1380.125
V Predictions Max            4729.0063
V Predictions Min            693.0442
Log Pis Mean                 -0.36538562
Log Pis Std                  3.8452222
Log Pis Max                  14.96969
Log Pis Min                  -8.22176
Policy mu Mean               0.035875197
Policy mu Std                0.8541421
Policy mu Max                2.7181063
Policy mu Min                -2.8269384
Policy log std Mean          -0.48820877
Policy log std Std           0.29766077
Policy log std Max           0.07099354
Policy log std Min           -3.0396955
Z mean eval                  1.897753
Z variance eval              0.07532557
total_rewards                [10353.99949639 10814.12189332 10590.37630034 10602.00137884
 10570.45143868 10389.29006195 10817.77317937 10686.25663023
 10846.390428   10727.52924142]
total_rewards_mean           10639.819004853196
total_rewards_std            163.61987422745588
total_rewards_max            10846.390427995426
total_rewards_min            10353.999496387021
Number of train steps total  1716000
Number of env steps total    5150000
Number of rollouts total     0
Train Time (s)               145.45114495698363
(Previous) Eval Time (s)     17.679213162045926
Sample Time (s)              6.564122166018933
Epoch Time (s)               169.69448028504848
Total Train Time (s)         73615.35480933543
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:20:34.954350 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #428 | Epoch Duration: 169.8151569366455
2020-01-13 04:20:34.954678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #428 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8977578
Z variance train             0.075260974
KL Divergence                49.89399
KL Loss                      4.989399
QF Loss                      174.16055
VF Loss                      57.602997
Policy Loss                  -1244.3351
Q Predictions Mean           1241.0162
Q Predictions Std            1207.2877
Q Predictions Max            4721.5874
Q Predictions Min            687.12933
V Predictions Mean           1247.1249
V Predictions Std            1203.3602
V Predictions Max            4739.6123
V Predictions Min            702.47943
Log Pis Mean                 -0.32065892
Log Pis Std                  4.015864
Log Pis Max                  18.795448
Log Pis Min                  -6.8898687
Policy mu Mean               0.07331815
Policy mu Std                0.8871283
Policy mu Max                3.6560488
Policy mu Min                -2.7155125
Policy log std Mean          -0.48769593
Policy log std Std           0.27985093
Policy log std Max           0.06385577
Policy log std Min           -2.6231873
Z mean eval                  1.8989786
Z variance eval              0.05113002
total_rewards                [ 9942.5749371  10248.22241107 10190.68763715 10030.49886403
 10031.63452162 10191.29757543 10030.00001437  9828.6675321
 10311.56389378 10144.09349107]
total_rewards_mean           10094.924087771762
total_rewards_std            140.63550380268313
total_rewards_max            10311.563893775574
total_rewards_min            9828.667532098843
Number of train steps total  1720000
Number of env steps total    5162000
Number of rollouts total     0
Train Time (s)               148.3274369230494
(Previous) Eval Time (s)     20.919686214998364
Sample Time (s)              6.638114570174366
Epoch Time (s)               175.88523770822212
Total Train Time (s)         73791.33675222797
Epoch                        429
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:23:30.925713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #429 | Epoch Duration: 175.97081971168518
2020-01-13 04:23:30.925857 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.900494
Z variance train             0.051228743
KL Divergence                51.5524
KL Loss                      5.15524
QF Loss                      195.35889
VF Loss                      65.525826
Policy Loss                  -1446.9036
Q Predictions Mean           1443.7968
Q Predictions Std            1376.5957
Q Predictions Max            4755.944
Q Predictions Min            659.9003
V Predictions Mean           1450.9425
V Predictions Std            1376.2563
V Predictions Max            4760.945
V Predictions Min            681.48535
Log Pis Mean                 0.10315192
Log Pis Std                  4.2405386
Log Pis Max                  21.33192
Log Pis Min                  -6.7418203
Policy mu Mean               0.04858015
Policy mu Std                0.94248825
Policy mu Max                3.803758
Policy mu Min                -3.4389307
Policy log std Mean          -0.5024056
Policy log std Std           0.31422895
Policy log std Max           -0.020439506
Policy log std Min           -3.0640583
Z mean eval                  1.886885
Z variance eval              0.08246843
total_rewards                [10248.67103213 10821.63781382 10657.64355585 10557.51483471
 10384.94256488 10771.72299969 10350.34606744 10563.00864207
 10540.81924728 10931.02376796]
total_rewards_mean           10582.733052583873
total_rewards_std            206.6917246342968
total_rewards_max            10931.023767961393
total_rewards_min            10248.671032129674
Number of train steps total  1724000
Number of env steps total    5174000
Number of rollouts total     0
Train Time (s)               147.18829761072993
(Previous) Eval Time (s)     20.831570502836257
Sample Time (s)              6.512115796096623
Epoch Time (s)               174.5319839096628
Total Train Time (s)         73965.95450416859
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:26:25.546757 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #430 | Epoch Duration: 174.62080264091492
2020-01-13 04:26:25.546893 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #430 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8860216
Z variance train             0.082351334
KL Divergence                50.82055
KL Loss                      5.082055
QF Loss                      237.53929
VF Loss                      73.34516
Policy Loss                  -1353.3473
Q Predictions Mean           1350.1384
Q Predictions Std            1312.2878
Q Predictions Max            4756.881
Q Predictions Min            676.89197
V Predictions Mean           1354.6863
V Predictions Std            1313.1101
V Predictions Max            4775.644
V Predictions Min            678.5368
Log Pis Mean                 -0.19093198
Log Pis Std                  3.8410575
Log Pis Max                  16.573545
Log Pis Min                  -6.9224186
Policy mu Mean               0.09888067
Policy mu Std                0.86865866
Policy mu Max                3.4176552
Policy mu Min                -2.7237153
Policy log std Mean          -0.48908213
Policy log std Std           0.29003766
Policy log std Max           -0.054974318
Policy log std Min           -3.0262687
Z mean eval                  1.9241663
Z variance eval              0.106581315
total_rewards                [10435.10563475 10380.55953228 10428.51767829 10678.80818903
 10675.21848584 10617.5896902  10760.78710401 10388.84265396
 10871.87189208  5205.19939801]
total_rewards_mean           10044.250025845158
total_rewards_std            1621.0051155546655
total_rewards_max            10871.871892080017
total_rewards_min            5205.199398005823
Number of train steps total  1728000
Number of env steps total    5186000
Number of rollouts total     0
Train Time (s)               147.2366073615849
(Previous) Eval Time (s)     20.78831843007356
Sample Time (s)              6.382857249584049
Epoch Time (s)               174.4077830412425
Total Train Time (s)         74140.43988292804
Epoch                        431
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:29:20.037383 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #431 | Epoch Duration: 174.49039363861084
2020-01-13 04:29:20.037516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #431 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9280317
Z variance train             0.1061942
KL Divergence                49.39197
KL Loss                      4.939197
QF Loss                      130.10303
VF Loss                      60.506226
Policy Loss                  -1283.7834
Q Predictions Mean           1280.5907
Q Predictions Std            1260.852
Q Predictions Max            4807.0063
Q Predictions Min            696.17566
V Predictions Mean           1285.4177
V Predictions Std            1262.0133
V Predictions Max            4821.53
V Predictions Min            698.3948
Log Pis Mean                 -0.41143608
Log Pis Std                  4.047982
Log Pis Max                  17.165508
Log Pis Min                  -8.583809
Policy mu Mean               0.061752196
Policy mu Std                0.8843565
Policy mu Max                3.4753914
Policy mu Min                -3.192459
Policy log std Mean          -0.4903345
Policy log std Std           0.2812607
Policy log std Max           0.13885558
Policy log std Min           -2.9134183
Z mean eval                  1.8951963
Z variance eval              0.0868473
total_rewards                [10164.83774372 10558.32087417 10490.74836458 10404.9884343
 10470.25692796 10415.32479048 10532.21734534 10710.60369618
 10496.19744396 10599.22134983]
total_rewards_mean           10484.271697053126
total_rewards_std            136.2643786765058
total_rewards_max            10710.60369618493
total_rewards_min            10164.837743721117
Number of train steps total  1732000
Number of env steps total    5198000
Number of rollouts total     0
Train Time (s)               146.2763920542784
(Previous) Eval Time (s)     17.562435451895
Sample Time (s)              6.324753407854587
Epoch Time (s)               170.163580914028
Total Train Time (s)         74310.69605106348
Epoch                        432
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:32:10.297962 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #432 | Epoch Duration: 170.26034140586853
2020-01-13 04:32:10.298131 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #432 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8937212
Z variance train             0.08669703
KL Divergence                48.528835
KL Loss                      4.852884
QF Loss                      4459.1426
VF Loss                      58.41676
Policy Loss                  -1200.8743
Q Predictions Mean           1197.833
Q Predictions Std            1164.2252
Q Predictions Max            4870.623
Q Predictions Min            686.65094
V Predictions Mean           1200.3389
V Predictions Std            1161.6222
V Predictions Max            4848.613
V Predictions Min            691.6614
Log Pis Mean                 -0.4050876
Log Pis Std                  3.5907907
Log Pis Max                  21.558306
Log Pis Min                  -6.410951
Policy mu Mean               0.07818698
Policy mu Std                0.8494072
Policy mu Max                3.8779628
Policy mu Min                -3.2926114
Policy log std Mean          -0.46784726
Policy log std Std           0.28342587
Policy log std Max           -0.016708732
Policy log std Min           -3.0891795
Z mean eval                  1.8889297
Z variance eval              0.06489781
total_rewards                [10467.69113388 10802.85584091 10463.66676284 10684.30310003
 10577.6253947  10331.88986526 10343.82983424 10697.5382136
 10500.77258309 10793.99532206]
total_rewards_mean           10566.416805060619
total_rewards_std            163.72915810926537
total_rewards_max            10802.855840913791
total_rewards_min            10331.889865263336
Number of train steps total  1736000
Number of env steps total    5210000
Number of rollouts total     0
Train Time (s)               146.5844216630794
(Previous) Eval Time (s)     20.562145273201168
Sample Time (s)              6.312064338475466
Epoch Time (s)               173.45863127475604
Total Train Time (s)         74484.23353413166
Epoch                        433
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:35:03.840182 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #433 | Epoch Duration: 173.54191780090332
2020-01-13 04:35:03.840358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #433 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8878514
Z variance train             0.065038815
KL Divergence                48.724487
KL Loss                      4.872449
QF Loss                      4297.9946
VF Loss                      84.02727
Policy Loss                  -1369.9265
Q Predictions Mean           1369.0579
Q Predictions Std            1323.8356
Q Predictions Max            4775.8833
Q Predictions Min            676.7667
V Predictions Mean           1375.0271
V Predictions Std            1323.0685
V Predictions Max            4776.9893
V Predictions Min            676.2895
Log Pis Mean                 -0.33028796
Log Pis Std                  3.4939146
Log Pis Max                  16.93302
Log Pis Min                  -6.3316565
Policy mu Mean               0.048905477
Policy mu Std                0.8839806
Policy mu Max                3.184321
Policy mu Min                -2.6295125
Policy log std Mean          -0.49362978
Policy log std Std           0.2693448
Policy log std Max           -0.06294137
Policy log std Min           -2.8175974
Z mean eval                  1.8742397
Z variance eval              0.05191944
total_rewards                [10693.20436706 10719.23510677 10598.2336079  10772.3395106
 10400.73613767 10419.20388286 10487.38298972 10838.02673681
 10613.65001154 10761.67984085]
total_rewards_mean           10630.369219177855
total_rewards_std            145.4113241961455
total_rewards_max            10838.026736812184
total_rewards_min            10400.73613766929
Number of train steps total  1740000
Number of env steps total    5222000
Number of rollouts total     0
Train Time (s)               146.41853273799643
(Previous) Eval Time (s)     20.786485355813056
Sample Time (s)              6.325193568132818
Epoch Time (s)               173.5302116619423
Total Train Time (s)         74657.85079065152
Epoch                        434
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:37:57.459826 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #434 | Epoch Duration: 173.61934566497803
2020-01-13 04:37:57.459966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #434 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8738976
Z variance train             0.051647115
KL Divergence                48.31939
KL Loss                      4.831939
QF Loss                      191.65158
VF Loss                      70.80016
Policy Loss                  -1350.5415
Q Predictions Mean           1346.8376
Q Predictions Std            1313.7162
Q Predictions Max            4785.46
Q Predictions Min            675.0755
V Predictions Mean           1352.2319
V Predictions Std            1310.5593
V Predictions Max            4792.4004
V Predictions Min            681.351
Log Pis Mean                 -0.006816961
Log Pis Std                  4.184349
Log Pis Max                  17.582193
Log Pis Min                  -5.790014
Policy mu Mean               0.11709329
Policy mu Std                0.9169178
Policy mu Max                3.040636
Policy mu Min                -3.3898966
Policy log std Mean          -0.4933103
Policy log std Std           0.30044016
Policy log std Max           -0.010066092
Policy log std Min           -3.2357724
Z mean eval                  1.8918314
Z variance eval              0.08637954
total_rewards                [10621.74544821 10557.75178572 10786.63753525 10969.70960457
 11214.0793925  10623.30274041 10647.02921958 10418.47293142
 10419.07588078 10604.55888857]
total_rewards_mean           10686.236342700307
total_rewards_std            233.44466836461703
total_rewards_max            11214.079392495849
total_rewards_min            10418.472931420536
Number of train steps total  1744000
Number of env steps total    5234000
Number of rollouts total     0
Train Time (s)               148.96664359094575
(Previous) Eval Time (s)     20.64462794503197
Sample Time (s)              6.375989323016256
Epoch Time (s)               175.98726085899398
Total Train Time (s)         74833.92304163845
Epoch                        435
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:40:53.540986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #435 | Epoch Duration: 176.08088660240173
2020-01-13 04:40:53.541259 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.892342
Z variance train             0.08637828
KL Divergence                47.022778
KL Loss                      4.7022777
QF Loss                      496.3579
VF Loss                      58.515633
Policy Loss                  -1334.6271
Q Predictions Mean           1328.6095
Q Predictions Std            1315.3157
Q Predictions Max            4664.184
Q Predictions Min            652.9601
V Predictions Mean           1330.2986
V Predictions Std            1312.8026
V Predictions Max            4659.47
V Predictions Min            647.09094
Log Pis Mean                 -0.38539892
Log Pis Std                  3.5663652
Log Pis Max                  12.998675
Log Pis Min                  -7.275393
Policy mu Mean               0.086793415
Policy mu Std                0.85351676
Policy mu Max                3.2867332
Policy mu Min                -2.860735
Policy log std Mean          -0.5008945
Policy log std Std           0.28980342
Policy log std Max           0.060969293
Policy log std Min           -2.932266
Z mean eval                  1.9022696
Z variance eval              0.064708285
total_rewards                [10309.34900388 10860.17168144 10621.76515654 10617.93614702
 10659.37078674 10504.44135972 10573.97515621 10763.39808053
 10550.91970565 10730.04970782]
total_rewards_mean           10619.137678555287
total_rewards_std            144.44881323123596
total_rewards_max            10860.171681443737
total_rewards_min            10309.349003877876
Number of train steps total  1748000
Number of env steps total    5246000
Number of rollouts total     0
Train Time (s)               145.40669959411025
(Previous) Eval Time (s)     20.76350947888568
Sample Time (s)              6.641254153102636
Epoch Time (s)               172.81146322609857
Total Train Time (s)         75006.8224198604
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:43:46.442490 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #436 | Epoch Duration: 172.90104031562805
2020-01-13 04:43:46.442639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9033388
Z variance train             0.06450491
KL Divergence                48.147057
KL Loss                      4.814706
QF Loss                      3870.54
VF Loss                      76.30322
Policy Loss                  -1331.9419
Q Predictions Mean           1329.8254
Q Predictions Std            1342.3696
Q Predictions Max            4744.6377
Q Predictions Min            655.34265
V Predictions Mean           1334.2776
V Predictions Std            1342.9243
V Predictions Max            4735.1196
V Predictions Min            672.9894
Log Pis Mean                 -0.24181113
Log Pis Std                  3.944247
Log Pis Max                  20.157825
Log Pis Min                  -6.7531786
Policy mu Mean               0.11774423
Policy mu Std                0.88931006
Policy mu Max                3.6538706
Policy mu Min                -2.617689
Policy log std Mean          -0.50355166
Policy log std Std           0.28469872
Policy log std Max           -0.08490078
Policy log std Min           -3.0811844
Z mean eval                  1.8996906
Z variance eval              0.067385815
total_rewards                [10079.69902094 10759.930695   10502.30997988 10876.47850755
 10622.90385638 10592.25382656 10929.98497135 10515.42788543
 10482.4738373  10822.41681558]
total_rewards_mean           10618.387939596385
total_rewards_std            236.38998084635406
total_rewards_max            10929.984971345204
total_rewards_min            10079.69902093693
Number of train steps total  1752000
Number of env steps total    5258000
Number of rollouts total     0
Train Time (s)               149.061324252747
(Previous) Eval Time (s)     20.915003903210163
Sample Time (s)              6.511465047951788
Epoch Time (s)               176.48779320390895
Total Train Time (s)         75183.404877414
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:46:43.026990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #437 | Epoch Duration: 176.5842502117157
2020-01-13 04:46:43.027123 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #437 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8989229
Z variance train             0.06747687
KL Divergence                48.550888
KL Loss                      4.8550887
QF Loss                      123.74895
VF Loss                      101.10213
Policy Loss                  -1285.7838
Q Predictions Mean           1283.9177
Q Predictions Std            1306.2596
Q Predictions Max            4858.434
Q Predictions Min            681.3532
V Predictions Mean           1292.3
V Predictions Std            1306.0327
V Predictions Max            4861.191
V Predictions Min            687.7664
Log Pis Mean                 -0.47562033
Log Pis Std                  4.046032
Log Pis Max                  14.194849
Log Pis Min                  -7.817528
Policy mu Mean               0.031137249
Policy mu Std                0.8884835
Policy mu Max                3.3620358
Policy mu Min                -2.9690905
Policy log std Mean          -0.4630272
Policy log std Std           0.2623892
Policy log std Max           0.0016680956
Policy log std Min           -2.753735
Z mean eval                  1.905318
Z variance eval              0.08134098
total_rewards                [10786.30556562 10680.37062064 10880.47166279 10533.5718247
 10923.92870649 10570.06670466 10443.91587996 10884.41479802
 10546.40489628 10620.20482344]
total_rewards_mean           10686.965548260981
total_rewards_std            162.16556343828782
total_rewards_max            10923.928706494398
total_rewards_min            10443.915879964276
Number of train steps total  1756000
Number of env steps total    5270000
Number of rollouts total     0
Train Time (s)               147.59594786912203
(Previous) Eval Time (s)     20.43109474517405
Sample Time (s)              6.4354451284743845
Epoch Time (s)               174.46248774277046
Total Train Time (s)         75358.04490848258
Epoch                        438
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:49:37.673911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #438 | Epoch Duration: 174.64667510986328
2020-01-13 04:49:37.674099 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #438 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9083488
Z variance train             0.081280716
KL Divergence                48.426056
KL Loss                      4.8426056
QF Loss                      72.46973
VF Loss                      36.948334
Policy Loss                  -1282.8861
Q Predictions Mean           1282.9004
Q Predictions Std            1301.1752
Q Predictions Max            4811.3643
Q Predictions Min            685.94336
V Predictions Mean           1283.9363
V Predictions Std            1295.4712
V Predictions Max            4778.2075
V Predictions Min            692.682
Log Pis Mean                 -0.6052912
Log Pis Std                  3.619214
Log Pis Max                  13.373043
Log Pis Min                  -8.147602
Policy mu Mean               0.064528584
Policy mu Std                0.8250993
Policy mu Max                2.7022896
Policy mu Min                -2.6291642
Policy log std Mean          -0.45895162
Policy log std Std           0.25049204
Policy log std Max           -0.025914252
Policy log std Min           -2.837773
Z mean eval                  1.9105585
Z variance eval              0.043925
total_rewards                [10833.68614578 10482.66998607 10902.07557484 10830.14884825
 10889.07091943 11047.54123837 10987.33387407 11160.84979895
 11093.97231891 11058.77508747]
total_rewards_mean           10928.612379215967
total_rewards_std            183.20784662889136
total_rewards_max            11160.849798954565
total_rewards_min            10482.66998606699
Number of train steps total  1760000
Number of env steps total    5282000
Number of rollouts total     0
Train Time (s)               146.88190671615303
(Previous) Eval Time (s)     17.41251872293651
Sample Time (s)              6.520229780115187
Epoch Time (s)               170.81465521920472
Total Train Time (s)         75528.94158150302
Epoch                        439
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:52:28.572821 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #439 | Epoch Duration: 170.89857649803162
2020-01-13 04:52:28.572998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9111761
Z variance train             0.04381271
KL Divergence                50.921337
KL Loss                      5.092134
QF Loss                      154.80547
VF Loss                      51.667023
Policy Loss                  -1271.0724
Q Predictions Mean           1264.302
Q Predictions Std            1260.3855
Q Predictions Max            4887.1167
Q Predictions Min            701.1659
V Predictions Mean           1269.2085
V Predictions Std            1260.1168
V Predictions Max            4883.755
V Predictions Min            697.8492
Log Pis Mean                 -0.36198288
Log Pis Std                  4.0197854
Log Pis Max                  21.104958
Log Pis Min                  -6.8494473
Policy mu Mean               0.056986142
Policy mu Std                0.8832137
Policy mu Max                3.7293394
Policy mu Min                -2.537609
Policy log std Mean          -0.48903608
Policy log std Std           0.30122378
Policy log std Max           0.011072338
Policy log std Min           -2.546293
Z mean eval                  1.9137408
Z variance eval              0.03418284
total_rewards                [10416.81348523 10855.37606623 10699.12427737 10856.73129808
 10539.56236767 10783.14183274 10744.75988081 10861.66035602
 10969.3356756  10771.47706672]
total_rewards_mean           10749.798230646466
total_rewards_std            155.73828884183746
total_rewards_max            10969.335675598577
total_rewards_min            10416.813485227065
Number of train steps total  1764000
Number of env steps total    5294000
Number of rollouts total     0
Train Time (s)               147.89311720291153
(Previous) Eval Time (s)     20.657317908946425
Sample Time (s)              7.583876258227974
Epoch Time (s)               176.13431137008592
Total Train Time (s)         75705.16471066
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:55:24.798219 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #440 | Epoch Duration: 176.22509241104126
2020-01-13 04:55:24.798363 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #440 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.914182
Z variance train             0.034205116
KL Divergence                51.3877
KL Loss                      5.13877
QF Loss                      68.580185
VF Loss                      94.7126
Policy Loss                  -1319.5542
Q Predictions Mean           1316.1873
Q Predictions Std            1290.5023
Q Predictions Max            4810.6567
Q Predictions Min            676.2456
V Predictions Mean           1320.4882
V Predictions Std            1292.2347
V Predictions Max            4806.079
V Predictions Min            669.5284
Log Pis Mean                 -0.51541317
Log Pis Std                  3.7319255
Log Pis Max                  13.601404
Log Pis Min                  -9.351805
Policy mu Mean               0.09104705
Policy mu Std                0.84399176
Policy mu Max                3.1805816
Policy mu Min                -2.7973566
Policy log std Mean          -0.47984418
Policy log std Std           0.2735839
Policy log std Max           0.059610724
Policy log std Min           -2.9412837
Z mean eval                  1.887716
Z variance eval              0.05588659
total_rewards                [10342.86627061 10430.4240902  10638.69767868 10758.73327809
 10660.23308307 10503.58784914 10810.30532365 10379.822672
 10827.80792398 10916.21522971]
total_rewards_mean           10626.869339913386
total_rewards_std            192.83830723978514
total_rewards_max            10916.215229712769
total_rewards_min            10342.866270605793
Number of train steps total  1768000
Number of env steps total    5306000
Number of rollouts total     0
Train Time (s)               145.27159711020067
(Previous) Eval Time (s)     17.868515198118985
Sample Time (s)              6.4437551479786634
Epoch Time (s)               169.58386745629832
Total Train Time (s)         75874.83484175615
Epoch                        441
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:58:14.474969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #441 | Epoch Duration: 169.67648267745972
2020-01-13 04:58:14.475140 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8874075
Z variance train             0.0560924
KL Divergence                51.149185
KL Loss                      5.1149187
QF Loss                      92.6946
VF Loss                      90.6104
Policy Loss                  -1315.8386
Q Predictions Mean           1311.0427
Q Predictions Std            1268.7136
Q Predictions Max            4865.192
Q Predictions Min            671.3598
V Predictions Mean           1317.3728
V Predictions Std            1273.886
V Predictions Max            4875.0093
V Predictions Min            666.8563
Log Pis Mean                 -0.03970565
Log Pis Std                  4.261072
Log Pis Max                  18.72725
Log Pis Min                  -7.9607477
Policy mu Mean               0.06203735
Policy mu Std                0.9135028
Policy mu Max                3.7028172
Policy mu Min                -2.9338515
Policy log std Mean          -0.4888809
Policy log std Std           0.31071526
Policy log std Max           0.10440463
Policy log std Min           -2.738863
Z mean eval                  1.9056883
Z variance eval              0.03648042
total_rewards                [10311.67333826 10575.39908324 10274.32860759 10723.99733276
 10306.93000572 10651.71135817 10622.12361924 10510.01457503
 10308.94976477 10698.45852214]
total_rewards_mean           10498.358620692143
total_rewards_std            171.29512567881525
total_rewards_max            10723.997332757232
total_rewards_min            10274.328607589936
Number of train steps total  1772000
Number of env steps total    5318000
Number of rollouts total     0
Train Time (s)               146.37976440275088
(Previous) Eval Time (s)     20.992337252013385
Sample Time (s)              6.5587994256056845
Epoch Time (s)               173.93090108036995
Total Train Time (s)         76048.91744983243
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:01:08.566744 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #442 | Epoch Duration: 174.0914385318756
2020-01-13 05:01:08.567020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #442 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9019239
Z variance train             0.03643264
KL Divergence                52.11959
KL Loss                      5.2119594
QF Loss                      4348.2593
VF Loss                      51.147655
Policy Loss                  -1398.3738
Q Predictions Mean           1396.4763
Q Predictions Std            1393.856
Q Predictions Max            4870.7188
Q Predictions Min            704.8461
V Predictions Mean           1400.9666
V Predictions Std            1392.2279
V Predictions Max            4871.3145
V Predictions Min            708.0085
Log Pis Mean                 -0.25744826
Log Pis Std                  4.0351005
Log Pis Max                  16.345615
Log Pis Min                  -7.3717084
Policy mu Mean               0.048291445
Policy mu Std                0.88867754
Policy mu Max                3.288211
Policy mu Min                -2.9023492
Policy log std Mean          -0.4726895
Policy log std Std           0.28585932
Policy log std Max           -0.046676874
Policy log std Min           -3.1511214
Z mean eval                  1.8922046
Z variance eval              0.048251662
total_rewards                [10255.78457046 10540.29595992  9907.5878142   5474.54669538
  8122.7939517  10467.22767796 10404.52186518 10149.79181661
 10524.9808118  10290.68826136]
total_rewards_mean           9613.82194245751
total_rewards_std            1537.6170677552605
total_rewards_max            10540.295959919315
total_rewards_min            5474.546695378802
Number of train steps total  1776000
Number of env steps total    5330000
Number of rollouts total     0
Train Time (s)               146.48040924593806
(Previous) Eval Time (s)     20.81905736681074
Sample Time (s)              6.541000257711858
Epoch Time (s)               173.84046687046066
Total Train Time (s)         76223.01585422223
Epoch                        443
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:04:02.666870 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #443 | Epoch Duration: 174.0996744632721
2020-01-13 05:04:02.667053 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8910172
Z variance train             0.04828289
KL Divergence                51.187668
KL Loss                      5.118767
QF Loss                      198.99167
VF Loss                      80.00702
Policy Loss                  -1322.6162
Q Predictions Mean           1315.8457
Q Predictions Std            1285.898
Q Predictions Max            4768.604
Q Predictions Min            674.7879
V Predictions Mean           1324.9028
V Predictions Std            1282.2942
V Predictions Max            4757.753
V Predictions Min            679.8705
Log Pis Mean                 -0.2474423
Log Pis Std                  3.8860393
Log Pis Max                  18.17808
Log Pis Min                  -7.9646797
Policy mu Mean               0.06136781
Policy mu Std                0.9117294
Policy mu Max                3.1090693
Policy mu Min                -2.938628
Policy log std Mean          -0.49722457
Policy log std Std           0.3093273
Policy log std Max           0.18074647
Policy log std Min           -3.1005142
Z mean eval                  1.910737
Z variance eval              0.057356376
total_rewards                [10644.50502128 10574.54376932 11016.68877209 11030.89277994
 10817.19451744 10820.70963282 10763.29960598 10852.14329232
 10803.07841388 11075.21620227]
total_rewards_mean           10839.827200733565
total_rewards_std            154.90528001103868
total_rewards_max            11075.216202268039
total_rewards_min            10574.543769322048
Number of train steps total  1780000
Number of env steps total    5342000
Number of rollouts total     0
Train Time (s)               145.56446985993534
(Previous) Eval Time (s)     17.66420510970056
Sample Time (s)              6.595969972200692
Epoch Time (s)               169.8246449418366
Total Train Time (s)         76392.92377431085
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:06:52.576375 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #444 | Epoch Duration: 169.90912413597107
2020-01-13 05:06:52.576648 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.912013
Z variance train             0.057532698
KL Divergence                51.164913
KL Loss                      5.1164913
QF Loss                      134.97841
VF Loss                      27.306276
Policy Loss                  -1281.639
Q Predictions Mean           1277.6819
Q Predictions Std            1235.7252
Q Predictions Max            4750.379
Q Predictions Min            697.92163
V Predictions Mean           1279.7217
V Predictions Std            1239.3375
V Predictions Max            4753.5483
V Predictions Min            698.29736
Log Pis Mean                 -0.51191944
Log Pis Std                  3.7083616
Log Pis Max                  18.764584
Log Pis Min                  -6.5357814
Policy mu Mean               0.04001121
Policy mu Std                0.8515303
Policy mu Max                3.2724206
Policy mu Min                -3.1162517
Policy log std Mean          -0.49299923
Policy log std Std           0.27243245
Policy log std Max           0.022485375
Policy log std Min           -2.6446636
Z mean eval                  1.8955872
Z variance eval              0.054313023
total_rewards                [10459.36428551 10785.55120664 10719.42158838 10531.90261113
 10924.67497149 10498.97849752 10542.37383825 10294.68265075
 10693.47784164 10495.29502888]
total_rewards_mean           10594.572252018124
total_rewards_std            174.54847388005467
total_rewards_max            10924.674971485105
total_rewards_min            10294.68265075018
Number of train steps total  1784000
Number of env steps total    5354000
Number of rollouts total     0
Train Time (s)               147.59928074618801
(Previous) Eval Time (s)     20.730800893623382
Sample Time (s)              6.6078863511793315
Epoch Time (s)               174.93796799099073
Total Train Time (s)         76567.97256495524
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:09:47.632492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #445 | Epoch Duration: 175.05564141273499
2020-01-13 05:09:47.632768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8980078
Z variance train             0.05428972
KL Divergence                51.275143
KL Loss                      5.1275144
QF Loss                      175.93661
VF Loss                      100.27701
Policy Loss                  -1362.6761
Q Predictions Mean           1358.5466
Q Predictions Std            1330.2316
Q Predictions Max            4865.887
Q Predictions Min            688.1488
V Predictions Mean           1357.9152
V Predictions Std            1321.862
V Predictions Max            4837.6313
V Predictions Min            685.6066
Log Pis Mean                 0.00753811
Log Pis Std                  4.1276298
Log Pis Max                  25.271465
Log Pis Min                  -6.018547
Policy mu Mean               0.06628395
Policy mu Std                0.90696996
Policy mu Max                3.3074
Policy mu Min                -3.2903125
Policy log std Mean          -0.48785368
Policy log std Std           0.30070966
Policy log std Max           0.024104297
Policy log std Min           -2.8990614
Z mean eval                  1.8815918
Z variance eval              0.064834476
total_rewards                [10608.94736119  9974.27285855 10871.57131704 10842.80761947
 10930.16765344 10909.86930368 10651.84961494 10591.16593103
 10979.2526439  11079.93300478]
total_rewards_mean           10743.98373080193
total_rewards_std            299.828655875769
total_rewards_max            11079.933004779734
total_rewards_min            9974.27285855108
Number of train steps total  1788000
Number of env steps total    5366000
Number of rollouts total     0
Train Time (s)               146.93666121084243
(Previous) Eval Time (s)     20.51930050039664
Sample Time (s)              6.365057336166501
Epoch Time (s)               173.82101904740557
Total Train Time (s)         76741.88534819335
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:12:41.549082 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #446 | Epoch Duration: 173.9160599708557
2020-01-13 05:12:41.549353 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8830054
Z variance train             0.06504502
KL Divergence                50.771446
KL Loss                      5.0771446
QF Loss                      144.78186
VF Loss                      34.18989
Policy Loss                  -1286.0836
Q Predictions Mean           1283.5444
Q Predictions Std            1261.1454
Q Predictions Max            4851.6113
Q Predictions Min            682.4289
V Predictions Mean           1284.0747
V Predictions Std            1262.5505
V Predictions Max            4877.705
V Predictions Min            684.0425
Log Pis Mean                 -0.6893713
Log Pis Std                  3.9249666
Log Pis Max                  21.303701
Log Pis Min                  -7.318077
Policy mu Mean               0.032436416
Policy mu Std                0.8562693
Policy mu Max                3.369184
Policy mu Min                -3.496525
Policy log std Mean          -0.49797186
Policy log std Std           0.27690062
Policy log std Max           -0.06941146
Policy log std Min           -2.9823616
Z mean eval                  1.8981116
Z variance eval              0.14356716
total_rewards                [10415.24480199 10531.73197384 10661.93732599 10443.93321698
 10736.18612382 10474.81501017 10767.4266886  10709.80203214
 10194.3089911  10380.8591541 ]
total_rewards_mean           10531.624531872914
total_rewards_std            175.25697208575423
total_rewards_max            10767.42668859883
total_rewards_min            10194.308991096243
Number of train steps total  1792000
Number of env steps total    5378000
Number of rollouts total     0
Train Time (s)               146.16488880105317
(Previous) Eval Time (s)     20.63489160174504
Sample Time (s)              5.462374303024262
Epoch Time (s)               172.26215470582247
Total Train Time (s)         76914.2359900428
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:15:33.902833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #447 | Epoch Duration: 172.3533263206482
2020-01-13 05:15:33.902969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #447 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8982611
Z variance train             0.14389266
KL Divergence                50.12352
KL Loss                      5.012352
QF Loss                      8737.493
VF Loss                      46.80094
Policy Loss                  -1320.727
Q Predictions Mean           1318.852
Q Predictions Std            1309.6154
Q Predictions Max            4768.844
Q Predictions Min            644.6998
V Predictions Mean           1323.3721
V Predictions Std            1311.0338
V Predictions Max            4774.263
V Predictions Min            649.8079
Log Pis Mean                 -0.4441889
Log Pis Std                  3.7995276
Log Pis Max                  15.66493
Log Pis Min                  -7.6932
Policy mu Mean               0.039350316
Policy mu Std                0.84439826
Policy mu Max                2.5861745
Policy mu Min                -2.9854774
Policy log std Mean          -0.49059796
Policy log std Std           0.28611732
Policy log std Max           0.05222091
Policy log std Min           -2.9233792
Z mean eval                  1.9184468
Z variance eval              0.10065961
total_rewards                [10648.66897765 11042.97375689  8291.51855557 11119.85390359
 10711.9183323  10633.88145575 10649.73290553 10826.93188866
 10848.18284901 10917.59688857]
total_rewards_mean           10569.125951351683
total_rewards_std            775.790218455531
total_rewards_max            11119.853903587875
total_rewards_min            8291.518555574845
Number of train steps total  1796000
Number of env steps total    5390000
Number of rollouts total     0
Train Time (s)               146.48958264896646
(Previous) Eval Time (s)     20.81534635089338
Sample Time (s)              6.334420608356595
Epoch Time (s)               173.63934960821643
Total Train Time (s)         77087.95536437398
Epoch                        448
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:18:27.627249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #448 | Epoch Duration: 173.72416019439697
2020-01-13 05:18:27.627456 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9158598
Z variance train             0.100943014
KL Divergence                49.03042
KL Loss                      4.903042
QF Loss                      8349.672
VF Loss                      88.23596
Policy Loss                  -1393.0292
Q Predictions Mean           1395.1072
Q Predictions Std            1399.8668
Q Predictions Max            4911.713
Q Predictions Min            680.71265
V Predictions Mean           1396.0779
V Predictions Std            1401.0039
V Predictions Max            4901.075
V Predictions Min            685.6511
Log Pis Mean                 -0.3000125
Log Pis Std                  3.9829884
Log Pis Max                  21.834137
Log Pis Min                  -6.225214
Policy mu Mean               0.013732982
Policy mu Std                0.8941395
Policy mu Max                3.3193917
Policy mu Min                -3.3831735
Policy log std Mean          -0.50687784
Policy log std Std           0.28820494
Policy log std Max           0.18306679
Policy log std Min           -3.062467
Z mean eval                  1.8972889
Z variance eval              0.082726315
total_rewards                [10715.60118651 11041.01081421 10935.4271895  10923.55339117
 11002.69891993 10738.31470287 11057.99250846 10270.16417564
 10953.23368181 10950.41927973]
total_rewards_mean           10858.841584983673
total_rewards_std            224.15989814164064
total_rewards_max            11057.99250845567
total_rewards_min            10270.164175640937
Number of train steps total  1800000
Number of env steps total    5402000
Number of rollouts total     0
Train Time (s)               146.13015120103955
(Previous) Eval Time (s)     18.852964421734214
Sample Time (s)              6.491886574309319
Epoch Time (s)               171.47500219708309
Total Train Time (s)         77259.53402850451
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:21:19.213508 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #449 | Epoch Duration: 171.58589339256287
2020-01-13 05:21:19.213684 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #449 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8978183
Z variance train             0.082758754
KL Divergence                48.727913
KL Loss                      4.8727913
QF Loss                      4241.573
VF Loss                      80.904274
Policy Loss                  -1426.2838
Q Predictions Mean           1425.1796
Q Predictions Std            1404.8323
Q Predictions Max            4825.5977
Q Predictions Min            687.8501
V Predictions Mean           1433.4036
V Predictions Std            1406.3484
V Predictions Max            4826.961
V Predictions Min            701.7157
Log Pis Mean                 -0.43500116
Log Pis Std                  3.7521777
Log Pis Max                  10.644165
Log Pis Min                  -6.7002707
Policy mu Mean               0.10187882
Policy mu Std                0.85305965
Policy mu Max                2.7893357
Policy mu Min                -2.6546197
Policy log std Mean          -0.5227662
Policy log std Std           0.30821192
Policy log std Max           0.01823324
Policy log std Min           -3.068052
Z mean eval                  1.8917307
Z variance eval              0.12818784
total_rewards                [10749.24143854  4303.0296123  10724.73676068  3437.7230329
 10584.58479335 11056.611835   10767.77905433  6521.74270363
 10708.73608734 11083.0278908 ]
total_rewards_mean           8993.72132088726
total_rewards_std            2868.81110560702
total_rewards_max            11083.027890799212
total_rewards_min            3437.7230329042573
Number of train steps total  1804000
Number of env steps total    5414000
Number of rollouts total     0
Train Time (s)               146.49587798304856
(Previous) Eval Time (s)     18.981058911420405
Sample Time (s)              6.496600104030222
Epoch Time (s)               171.97353699849918
Total Train Time (s)         77431.59048984153
Epoch                        450
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:24:11.277843 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #450 | Epoch Duration: 172.06400656700134
2020-01-13 05:24:11.278072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #450 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.89077
Z variance train             0.12800337
KL Divergence                48.6845
KL Loss                      4.86845
QF Loss                      109.3065
VF Loss                      113.22561
Policy Loss                  -1336.994
Q Predictions Mean           1336.8479
Q Predictions Std            1311.5807
Q Predictions Max            4827.2334
Q Predictions Min            687.435
V Predictions Mean           1345.2522
V Predictions Std            1311.9183
V Predictions Max            4836.5845
V Predictions Min            674.9966
Log Pis Mean                 -0.23987766
Log Pis Std                  4.0880795
Log Pis Max                  13.666697
Log Pis Min                  -7.990329
Policy mu Mean               0.05307922
Policy mu Std                0.9010162
Policy mu Max                3.1495557
Policy mu Min                -2.6854901
Policy log std Mean          -0.49094367
Policy log std Std           0.27096292
Policy log std Max           0.023384154
Policy log std Min           -2.71782
Z mean eval                  1.8944464
Z variance eval              0.14666024
total_rewards                [10920.6367918   7656.8306622  10649.35440036 11177.20275182
 10985.95136605 10907.25496397 10950.22431196 11048.87804517
 10770.0541391  10928.83351824]
total_rewards_mean           10599.522095066448
total_rewards_std            990.2127460181099
total_rewards_max            11177.202751823472
total_rewards_min            7656.830662196094
Number of train steps total  1808000
Number of env steps total    5426000
Number of rollouts total     0
Train Time (s)               147.23455089796335
(Previous) Eval Time (s)     20.69714109832421
Sample Time (s)              6.514999872073531
Epoch Time (s)               174.44669186836109
Total Train Time (s)         77606.11908712797
Epoch                        451
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:27:05.809539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #451 | Epoch Duration: 174.53130793571472
2020-01-13 05:27:05.809674 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #451 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8943882
Z variance train             0.14622995
KL Divergence                48.014416
KL Loss                      4.8014417
QF Loss                      4222.1074
VF Loss                      50.046844
Policy Loss                  -1453.191
Q Predictions Mean           1452.0205
Q Predictions Std            1435.664
Q Predictions Max            4857.5693
Q Predictions Min            680.723
V Predictions Mean           1454.7223
V Predictions Std            1432.1332
V Predictions Max            4836.9873
V Predictions Min            683.7331
Log Pis Mean                 0.13178068
Log Pis Std                  4.3225107
Log Pis Max                  18.835323
Log Pis Min                  -9.06859
Policy mu Mean               0.03512877
Policy mu Std                0.94179773
Policy mu Max                3.1803744
Policy mu Min                -2.7786782
Policy log std Mean          -0.5080428
Policy log std Std           0.29039884
Policy log std Max           0.0040914416
Policy log std Min           -3.0901425
Z mean eval                  1.8963821
Z variance eval              0.11797075
total_rewards                [10347.73731484 10671.38040502 10690.19835391 10901.89040432
 10255.77891918 11011.76485768  2495.77854759  9993.30750538
 10726.20607542 10134.18659405]
total_rewards_mean           9722.822897738904
total_rewards_std            2429.8361710689887
total_rewards_max            11011.764857682589
total_rewards_min            2495.7785475912815
Number of train steps total  1812000
Number of env steps total    5438000
Number of rollouts total     0
Train Time (s)               145.68957131821662
(Previous) Eval Time (s)     20.556891046930104
Sample Time (s)              6.450925251469016
Epoch Time (s)               172.69738761661574
Total Train Time (s)         77778.90839222632
Epoch                        452
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:29:58.606539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #452 | Epoch Duration: 172.7967348098755
2020-01-13 05:29:58.606819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #452 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8955473
Z variance train             0.117573895
KL Divergence                48.19087
KL Loss                      4.819087
QF Loss                      311.1854
VF Loss                      70.43654
Policy Loss                  -1280.6964
Q Predictions Mean           1278.8259
Q Predictions Std            1267.1512
Q Predictions Max            4870.552
Q Predictions Min            676.8642
V Predictions Mean           1286.2631
V Predictions Std            1264.8483
V Predictions Max            4885.5635
V Predictions Min            682.19525
Log Pis Mean                 -0.012343243
Log Pis Std                  3.9236643
Log Pis Max                  13.995291
Log Pis Min                  -5.708015
Policy mu Mean               0.017927554
Policy mu Std                0.9158984
Policy mu Max                3.713221
Policy mu Min                -3.0017295
Policy log std Mean          -0.49508798
Policy log std Std           0.2762162
Policy log std Max           -0.0020994544
Policy log std Min           -2.5531352
Z mean eval                  1.8964208
Z variance eval              0.14979401
total_rewards                [10693.36122858 10834.68894599 10681.14720698 10778.60976148
 10666.34310902 10766.30020047 10942.38518892 10775.53395541
 10853.29216118 10689.80466816]
total_rewards_mean           10768.146642617043
total_rewards_std            84.77461380103364
total_rewards_max            10942.385188918402
total_rewards_min            10666.343109016023
Number of train steps total  1816000
Number of env steps total    5450000
Number of rollouts total     0
Train Time (s)               145.38865894498304
(Previous) Eval Time (s)     20.66732067707926
Sample Time (s)              6.550375580321997
Epoch Time (s)               172.6063552023843
Total Train Time (s)         77951.59479331179
Epoch                        453
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:32:51.294993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #453 | Epoch Duration: 172.68799352645874
2020-01-13 05:32:51.295134 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8918955
Z variance train             0.15021011
KL Divergence                46.90715
KL Loss                      4.6907153
QF Loss                      161.27039
VF Loss                      86.84529
Policy Loss                  -1338.571
Q Predictions Mean           1333.7098
Q Predictions Std            1312.5156
Q Predictions Max            4909.813
Q Predictions Min            680.4733
V Predictions Mean           1343.8818
V Predictions Std            1314.1578
V Predictions Max            4943.104
V Predictions Min            678.55084
Log Pis Mean                 -0.18238865
Log Pis Std                  3.6568203
Log Pis Max                  16.152554
Log Pis Min                  -6.3587513
Policy mu Mean               0.09187934
Policy mu Std                0.87300795
Policy mu Max                3.483766
Policy mu Min                -3.2025573
Policy log std Mean          -0.51262087
Policy log std Std           0.29463425
Policy log std Max           -0.079093575
Policy log std Min           -2.8090026
Z mean eval                  1.8811651
Z variance eval              0.1372255
total_rewards                [10363.49093845 10677.6515986  10988.45790726 10833.34468372
 10475.5264934  11115.6078236  10765.93082573 10437.32058648
 10431.69238942 10677.31608509]
total_rewards_mean           10676.633933174657
total_rewards_std            240.46536920384807
total_rewards_max            11115.607823599774
total_rewards_min            10363.49093844964
Number of train steps total  1820000
Number of env steps total    5462000
Number of rollouts total     0
Train Time (s)               146.54011026583612
(Previous) Eval Time (s)     20.660541265737265
Sample Time (s)              6.566249906085432
Epoch Time (s)               173.76690143765882
Total Train Time (s)         78125.43942013616
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:35:45.141708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #454 | Epoch Duration: 173.84647822380066
2020-01-13 05:35:45.141842 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #454 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8790417
Z variance train             0.1369888
KL Divergence                46.78776
KL Loss                      4.6787763
QF Loss                      98.96087
VF Loss                      50.109
Policy Loss                  -1332.4108
Q Predictions Mean           1332.7222
Q Predictions Std            1371.244
Q Predictions Max            4861.3716
Q Predictions Min            680.93646
V Predictions Mean           1334.9214
V Predictions Std            1370.3728
V Predictions Max            4852.997
V Predictions Min            682.72473
Log Pis Mean                 -0.4637345
Log Pis Std                  3.5903194
Log Pis Max                  13.402579
Log Pis Min                  -6.307931
Policy mu Mean               0.08214142
Policy mu Std                0.8590985
Policy mu Max                2.806993
Policy mu Min                -2.341168
Policy log std Mean          -0.4803585
Policy log std Std           0.29724845
Policy log std Max           0.07613391
Policy log std Min           -2.9432585
Z mean eval                  1.87703
Z variance eval              0.15928957
total_rewards                [10959.91572464 10976.37502352  7227.5303118  11011.56082108
 10805.81121522 11209.76997883 10901.65473577  4326.86288276
  2460.2643896  10972.84964354]
total_rewards_mean           9085.259472676971
total_rewards_std            3084.177007919418
total_rewards_max            11209.769978833805
total_rewards_min            2460.264389601882
Number of train steps total  1824000
Number of env steps total    5474000
Number of rollouts total     0
Train Time (s)               146.1452081790194
(Previous) Eval Time (s)     20.601239568088204
Sample Time (s)              6.431381857488304
Epoch Time (s)               173.1778296045959
Total Train Time (s)         78298.70160811488
Epoch                        455
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:38:38.408406 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #455 | Epoch Duration: 173.2664520740509
2020-01-13 05:38:38.408591 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8777726
Z variance train             0.15933585
KL Divergence                47.263508
KL Loss                      4.726351
QF Loss                      125.079315
VF Loss                      40.09571
Policy Loss                  -1261.7798
Q Predictions Mean           1260.7919
Q Predictions Std            1261.1749
Q Predictions Max            4971.253
Q Predictions Min            683.11725
V Predictions Mean           1261.7075
V Predictions Std            1256.1936
V Predictions Max            4958.583
V Predictions Min            689.77014
Log Pis Mean                 -0.52714264
Log Pis Std                  3.7150524
Log Pis Max                  16.401615
Log Pis Min                  -6.846851
Policy mu Mean               0.031161392
Policy mu Std                0.8463659
Policy mu Max                2.8162966
Policy mu Min                -2.8058
Policy log std Mean          -0.4699054
Policy log std Std           0.26088306
Policy log std Max           0.17681256
Policy log std Min           -3.2440238
Z mean eval                  1.9102137
Z variance eval              0.15005085
total_rewards                [10584.85034936 11195.06561429 11336.89161477 11169.19238675
 10758.25482179 10737.23234443 10976.17289572 10982.49500014
 11072.28472195 10717.64831306]
total_rewards_mean           10953.00880622636
total_rewards_std            233.1843500936559
total_rewards_max            11336.891614771814
total_rewards_min            10584.850349356162
Number of train steps total  1828000
Number of env steps total    5486000
Number of rollouts total     0
Train Time (s)               146.28025486227125
(Previous) Eval Time (s)     17.553029103204608
Sample Time (s)              5.7747227172367275
Epoch Time (s)               169.60800668271258
Total Train Time (s)         78468.39501549723
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:41:28.106412 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #456 | Epoch Duration: 169.69767141342163
2020-01-13 05:41:28.106613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.909819
Z variance train             0.15012941
KL Divergence                48.25519
KL Loss                      4.825519
QF Loss                      244.11487
VF Loss                      93.050125
Policy Loss                  -1598.3359
Q Predictions Mean           1596.7449
Q Predictions Std            1561.0327
Q Predictions Max            4961.64
Q Predictions Min            707.5679
V Predictions Mean           1595.84
V Predictions Std            1558.231
V Predictions Max            4950.899
V Predictions Min            705.87177
Log Pis Mean                 0.20288816
Log Pis Std                  4.0837383
Log Pis Max                  14.077455
Log Pis Min                  -7.8017006
Policy mu Mean               0.105428346
Policy mu Std                0.9247552
Policy mu Max                3.438371
Policy mu Min                -2.7180946
Policy log std Mean          -0.5253412
Policy log std Std           0.33297235
Policy log std Max           0.011527926
Policy log std Min           -2.9251113
Z mean eval                  1.8834327
Z variance eval              0.08861502
total_rewards                [10361.69436735 10272.90539492  4647.75341183 10521.38748608
 10442.7852674  10600.45001418 10572.46800704 10576.15796406
 10590.46418712 10516.0419514 ]
total_rewards_mean           9910.210805136705
total_rewards_std            1757.1081784891603
total_rewards_max            10600.450014178412
total_rewards_min            4647.753411825078
Number of train steps total  1832000
Number of env steps total    5498000
Number of rollouts total     0
Train Time (s)               145.38320007221773
(Previous) Eval Time (s)     20.823622571770102
Sample Time (s)              6.38406097702682
Epoch Time (s)               172.59088362101465
Total Train Time (s)         78641.07281193044
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:44:20.789516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #457 | Epoch Duration: 172.6827392578125
2020-01-13 05:44:20.789705 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #457 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8832384
Z variance train             0.088624954
KL Divergence                48.310436
KL Loss                      4.8310437
QF Loss                      131.0792
VF Loss                      58.17727
Policy Loss                  -1505.8469
Q Predictions Mean           1502.4905
Q Predictions Std            1491.0674
Q Predictions Max            4960.8926
Q Predictions Min            686.80975
V Predictions Mean           1510.8397
V Predictions Std            1489.2134
V Predictions Max            4945.905
V Predictions Min            696.7612
Log Pis Mean                 -0.08536706
Log Pis Std                  3.7779837
Log Pis Max                  23.878967
Log Pis Min                  -6.218171
Policy mu Mean               0.07701835
Policy mu Std                0.9120711
Policy mu Max                3.441033
Policy mu Min                -2.924437
Policy log std Mean          -0.52007365
Policy log std Std           0.29019082
Policy log std Max           -0.053328693
Policy log std Min           -2.938697
Z mean eval                  1.8892654
Z variance eval              0.061988372
total_rewards                [ 9970.07490403 10564.59030287  8980.36106314 10530.92290263
 10040.49268718 10424.25685543  2541.72238901  8455.86149775
 10896.81119249 10342.41868945]
total_rewards_mean           9274.75124839736
total_rewards_std            2355.732708568687
total_rewards_max            10896.81119248925
total_rewards_min            2541.722389011683
Number of train steps total  1836000
Number of env steps total    5510000
Number of rollouts total     0
Train Time (s)               147.29853372601792
(Previous) Eval Time (s)     21.004796106833965
Sample Time (s)              6.472396778874099
Epoch Time (s)               174.775726611726
Total Train Time (s)         78815.9547014148
Epoch                        458
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:47:15.675147 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #458 | Epoch Duration: 174.8853099346161
2020-01-13 05:47:15.675288 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8876864
Z variance train             0.06198298
KL Divergence                49.57578
KL Loss                      4.957578
QF Loss                      190.00531
VF Loss                      27.493376
Policy Loss                  -1362.2667
Q Predictions Mean           1361.4912
Q Predictions Std            1367.6449
Q Predictions Max            4930.997
Q Predictions Min            686.28827
V Predictions Mean           1364.1172
V Predictions Std            1363.9231
V Predictions Max            4923.9775
V Predictions Min            690.0906
Log Pis Mean                 -0.068887964
Log Pis Std                  4.197683
Log Pis Max                  24.448935
Log Pis Min                  -7.1302576
Policy mu Mean               0.08237127
Policy mu Std                0.91370416
Policy mu Max                3.6378846
Policy mu Min                -4.0116067
Policy log std Mean          -0.50880325
Policy log std Std           0.29413784
Policy log std Max           0.017705888
Policy log std Min           -2.9697964
Z mean eval                  1.904365
Z variance eval              0.054545116
total_rewards                [10672.74211336 10716.52945824 10877.63837607 10843.29637805
 11283.18000984 10846.98328148 10751.82693402 10828.42843197
 10773.78505584 10881.07912332]
total_rewards_mean           10847.54891621803
total_rewards_std            159.5353937912421
total_rewards_max            11283.180009836538
total_rewards_min            10672.742113357011
Number of train steps total  1840000
Number of env steps total    5522000
Number of rollouts total     0
Train Time (s)               146.54742319323123
(Previous) Eval Time (s)     20.73665491119027
Sample Time (s)              6.575991722755134
Epoch Time (s)               173.86006982717663
Total Train Time (s)         78989.91084654769
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:50:09.638567 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #459 | Epoch Duration: 173.96316480636597
2020-01-13 05:50:09.638781 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #459 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9026988
Z variance train             0.05444293
KL Divergence                51.012215
KL Loss                      5.1012216
QF Loss                      90.80066
VF Loss                      63.72102
Policy Loss                  -1429.9531
Q Predictions Mean           1429.1816
Q Predictions Std            1452.7177
Q Predictions Max            4995.831
Q Predictions Min            704.8311
V Predictions Mean           1434.6053
V Predictions Std            1452.2661
V Predictions Max            4994.632
V Predictions Min            713.534
Log Pis Mean                 -0.23260084
Log Pis Std                  3.6518412
Log Pis Max                  15.43363
Log Pis Min                  -7.658534
Policy mu Mean               0.03326461
Policy mu Std                0.9052829
Policy mu Max                3.139291
Policy mu Min                -2.7270865
Policy log std Mean          -0.49945745
Policy log std Std           0.28360137
Policy log std Max           0.040359944
Policy log std Min           -2.7884793
Z mean eval                  1.8909731
Z variance eval              0.07918452
total_rewards                [10589.33270108 10970.54728556 11125.99401537 11002.35714765
 10922.56758013 10934.84307904 10758.05343323 10930.17687738
 11022.30606691 10669.09531265]
total_rewards_mean           10892.527349900036
total_rewards_std            159.22987219599264
total_rewards_max            11125.994015365113
total_rewards_min            10589.332701080077
Number of train steps total  1844000
Number of env steps total    5534000
Number of rollouts total     0
Train Time (s)               146.4363874271512
(Previous) Eval Time (s)     20.760548822116107
Sample Time (s)              12.687214400619268
Epoch Time (s)               179.88415064988658
Total Train Time (s)         79169.88309581764
Epoch                        460
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:53:09.616429 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #460 | Epoch Duration: 179.97750234603882
2020-01-13 05:53:09.616620 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8904483
Z variance train             0.0793394
KL Divergence                50.73609
KL Loss                      5.0736094
QF Loss                      192.78552
VF Loss                      69.25722
Policy Loss                  -1437.6821
Q Predictions Mean           1436.305
Q Predictions Std            1414.0869
Q Predictions Max            4972.3613
Q Predictions Min            698.5021
V Predictions Mean           1437.1917
V Predictions Std            1412.1343
V Predictions Max            4971.539
V Predictions Min            696.3659
Log Pis Mean                 -0.06304833
Log Pis Std                  4.39167
Log Pis Max                  16.87181
Log Pis Min                  -6.5205264
Policy mu Mean               0.037630454
Policy mu Std                0.917547
Policy mu Max                2.5744562
Policy mu Min                -2.8532643
Policy log std Mean          -0.51636344
Policy log std Std           0.29636282
Policy log std Max           0.0014389753
Policy log std Min           -3.166156
Z mean eval                  1.9063431
Z variance eval              0.03828411
total_rewards                [10250.90083104 10752.99785637 10763.17763427 10217.82142663
 11005.52652676 10763.51021614 10439.14459066 10081.26004834
 11068.42760135 10401.92277121]
total_rewards_mean           10574.468950278038
total_rewards_std            325.00147572040515
total_rewards_max            11068.427601347676
total_rewards_min            10081.26004834004
Number of train steps total  1848000
Number of env steps total    5546000
Number of rollouts total     0
Train Time (s)               147.34830001695082
(Previous) Eval Time (s)     20.778069878928363
Sample Time (s)              6.4701144327409565
Epoch Time (s)               174.59648432862014
Total Train Time (s)         79344.56088691996
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:56:04.298126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #461 | Epoch Duration: 174.68137860298157
2020-01-13 05:56:04.298263 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #461 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9046692
Z variance train             0.038234077
KL Divergence                52.27316
KL Loss                      5.227316
QF Loss                      102.883415
VF Loss                      90.60936
Policy Loss                  -1412.1487
Q Predictions Mean           1409.0074
Q Predictions Std            1419.3037
Q Predictions Max            4935.3154
Q Predictions Min            699.7846
V Predictions Mean           1418.489
V Predictions Std            1420.2362
V Predictions Max            4949.3755
V Predictions Min            702.2342
Log Pis Mean                 -0.011594322
Log Pis Std                  3.9127812
Log Pis Max                  12.062646
Log Pis Min                  -7.459061
Policy mu Mean               0.08613498
Policy mu Std                0.8917188
Policy mu Max                3.3490036
Policy mu Min                -2.8154528
Policy log std Mean          -0.5309709
Policy log std Std           0.3258561
Policy log std Max           -0.04775229
Policy log std Min           -2.9782064
Z mean eval                  1.9299333
Z variance eval              0.0711736
total_rewards                [10277.81813232 10770.39362387 10424.22071918 11014.47688519
 10903.88412963 10976.83027241 11011.49018371 11025.66633353
 10793.86799797 10926.74147333]
total_rewards_mean           10812.5389751125
total_rewards_std            247.58914267075536
total_rewards_max            11025.666333525218
total_rewards_min            10277.818132315668
Number of train steps total  1852000
Number of env steps total    5558000
Number of rollouts total     0
Train Time (s)               146.7788669941947
(Previous) Eval Time (s)     21.09874525759369
Sample Time (s)              6.3334707682952285
Epoch Time (s)               174.2110830200836
Total Train Time (s)         79518.85822705505
Epoch                        462
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:58:58.599196 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #462 | Epoch Duration: 174.3008270263672
2020-01-13 05:58:58.599371 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.92852
Z variance train             0.07164474
KL Divergence                50.76503
KL Loss                      5.0765033
QF Loss                      196.98402
VF Loss                      38.523994
Policy Loss                  -1413.8032
Q Predictions Mean           1409.1824
Q Predictions Std            1403.0155
Q Predictions Max            5023.701
Q Predictions Min            705.69073
V Predictions Mean           1414.9557
V Predictions Std            1401.9265
V Predictions Max            4997.3545
V Predictions Min            703.36035
Log Pis Mean                 -0.047372043
Log Pis Std                  3.9818876
Log Pis Max                  14.611339
Log Pis Min                  -6.646678
Policy mu Mean               0.11129713
Policy mu Std                0.9098279
Policy mu Max                3.3784711
Policy mu Min                -3.1366887
Policy log std Mean          -0.52653104
Policy log std Std           0.304095
Policy log std Max           0.099654555
Policy log std Min           -2.9586663
Z mean eval                  1.89444
Z variance eval              0.07753505
total_rewards                [10765.10772074 10900.91519094 10905.71146958 10786.34732199
 11079.10948368 10994.36516567 10483.29904952 10681.79227691
 10590.75606355 11057.82096984]
total_rewards_mean           10824.522471240834
total_rewards_std            188.93287118533115
total_rewards_max            11079.109483678714
total_rewards_min            10483.299049518335
Number of train steps total  1856000
Number of env steps total    5570000
Number of rollouts total     0
Train Time (s)               146.1811050591059
(Previous) Eval Time (s)     17.54022894660011
Sample Time (s)              6.330197154544294
Epoch Time (s)               170.0515311602503
Total Train Time (s)         79688.99335803138
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:48.738463 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #463 | Epoch Duration: 170.13894724845886
2020-01-13 06:01:48.738654 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #463 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8944263
Z variance train             0.077645466
KL Divergence                50.9314
KL Loss                      5.09314
QF Loss                      128.68387
VF Loss                      66.94386
Policy Loss                  -1500.0724
Q Predictions Mean           1497.6648
Q Predictions Std            1476.9108
Q Predictions Max            5004.3877
Q Predictions Min            699.3096
V Predictions Mean           1498.8702
V Predictions Std            1479.0613
V Predictions Max            5011.249
V Predictions Min            705.8989
Log Pis Mean                 0.0020401292
Log Pis Std                  4.1038446
Log Pis Max                  18.014107
Log Pis Min                  -6.342431
Policy mu Mean               0.05722438
Policy mu Std                0.92467296
Policy mu Max                3.012131
Policy mu Min                -3.4542592
Policy log std Mean          -0.50007653
Policy log std Std           0.29269984
Policy log std Max           0.078152835
Policy log std Min           -3.0819004
Z mean eval                  1.9042677
Z variance eval              0.09391199
total_rewards                [10390.72708279 10998.21463703 10790.1073516  11066.650545
 11095.99620452 10706.13787624 10540.07481073 11162.29214019
 10908.31023819 10815.2207367 ]
total_rewards_mean           10847.373162299255
total_rewards_std            237.22455699808486
total_rewards_max            11162.292140194902
total_rewards_min            10390.727082789832
Number of train steps total  1860000
Number of env steps total    5582000
Number of rollouts total     0
Train Time (s)               145.9456521049142
(Previous) Eval Time (s)     17.842334665823728
Sample Time (s)              6.429427412804216
Epoch Time (s)               170.21741418354213
Total Train Time (s)         79859.2956757322
Epoch                        464
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:04:39.045579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #464 | Epoch Duration: 170.30671525001526
2020-01-13 06:04:39.045854 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.905381
Z variance train             0.09386529
KL Divergence                50.81174
KL Loss                      5.0811744
QF Loss                      389.43597
VF Loss                      40.895363
Policy Loss                  -1342.6548
Q Predictions Mean           1339.1733
Q Predictions Std            1358.9259
Q Predictions Max            5083.173
Q Predictions Min            706.1784
V Predictions Mean           1343.1437
V Predictions Std            1356.8284
V Predictions Max            5015.5596
V Predictions Min            705.5775
Log Pis Mean                 -0.2406742
Log Pis Std                  3.9735436
Log Pis Max                  14.178722
Log Pis Min                  -7.3380065
Policy mu Mean               0.04113962
Policy mu Std                0.89572865
Policy mu Max                3.0843453
Policy mu Min                -2.7086544
Policy log std Mean          -0.49481153
Policy log std Std           0.30400616
Policy log std Max           0.059927344
Policy log std Min           -2.9820342
Z mean eval                  1.9018055
Z variance eval              0.0797833
total_rewards                [10783.43088075 11172.3539105  11145.08654901 11092.97331845
 11304.85342611 11116.89665706 11081.22177312 10946.65690658
 11214.25443114 10934.44786158]
total_rewards_mean           11079.217571430057
total_rewards_std            144.84229641133106
total_rewards_max            11304.853426114809
total_rewards_min            10783.43088074607
Number of train steps total  1864000
Number of env steps total    5594000
Number of rollouts total     0
Train Time (s)               146.326757799834
(Previous) Eval Time (s)     20.641468650195748
Sample Time (s)              6.393634412437677
Epoch Time (s)               173.36186086246744
Total Train Time (s)         80032.73647603998
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:07:32.488784 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #465 | Epoch Duration: 173.44274973869324
2020-01-13 06:07:32.488942 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #465 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9040706
Z variance train             0.07986385
KL Divergence                51.02527
KL Loss                      5.102527
QF Loss                      4555.6787
VF Loss                      118.02367
Policy Loss                  -1394.4857
Q Predictions Mean           1393.466
Q Predictions Std            1402.2827
Q Predictions Max            4990.5825
Q Predictions Min            696.2401
V Predictions Mean           1385.7753
V Predictions Std            1395.0312
V Predictions Max            4956.1665
V Predictions Min            699.82465
Log Pis Mean                 0.004979305
Log Pis Std                  3.9779332
Log Pis Max                  15.382381
Log Pis Min                  -6.991977
Policy mu Mean               0.056325775
Policy mu Std                0.9048963
Policy mu Max                2.560525
Policy mu Min                -2.861113
Policy log std Mean          -0.49192753
Policy log std Std           0.28335822
Policy log std Max           -0.01944092
Policy log std Min           -2.5022297
Z mean eval                  1.8977209
Z variance eval              0.075611606
total_rewards                [10588.32410513  3708.90409784  7319.27874311 10850.09408993
 10925.22311342 10798.31019821 11121.09821596 10869.2661335
 10452.67715619 11058.87451186]
total_rewards_mean           9769.205036516278
total_rewards_std            2283.2483398111017
total_rewards_max            11121.09821595887
total_rewards_min            3708.9040978408943
Number of train steps total  1868000
Number of env steps total    5606000
Number of rollouts total     0
Train Time (s)               146.5892332638614
(Previous) Eval Time (s)     20.991606883239
Sample Time (s)              6.4883266421966255
Epoch Time (s)               174.06916678929701
Total Train Time (s)         80206.88354482502
Epoch                        466
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:10:26.639775 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #466 | Epoch Duration: 174.15070343017578
2020-01-13 06:10:26.639957 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.898155
Z variance train             0.0754288
KL Divergence                49.319313
KL Loss                      4.9319315
QF Loss                      4203.176
VF Loss                      38.808083
Policy Loss                  -1505.8032
Q Predictions Mean           1504.226
Q Predictions Std            1521.9896
Q Predictions Max            4962.046
Q Predictions Min            698.65405
V Predictions Mean           1507.3025
V Predictions Std            1517.7719
V Predictions Max            4964.413
V Predictions Min            702.2797
Log Pis Mean                 -0.12744129
Log Pis Std                  3.7905934
Log Pis Max                  15.0334015
Log Pis Min                  -5.69446
Policy mu Mean               0.015414494
Policy mu Std                0.90964663
Policy mu Max                3.1454458
Policy mu Min                -3.4323356
Policy log std Mean          -0.5091925
Policy log std Std           0.28931844
Policy log std Max           0.019714475
Policy log std Min           -2.9405572
Z mean eval                  1.9342234
Z variance eval              0.08097483
total_rewards                [10667.91815875 10638.13026121 10047.28458706 10707.90051441
 10493.90405366 10832.23528165 10852.73554474 10397.82078123
 10765.02878424 10796.6626781 ]
total_rewards_mean           10619.96206450454
total_rewards_std            235.59940113859724
total_rewards_max            10852.735544742767
total_rewards_min            10047.284587057467
Number of train steps total  1872000
Number of env steps total    5618000
Number of rollouts total     0
Train Time (s)               149.84639490395784
(Previous) Eval Time (s)     20.69963901815936
Sample Time (s)              6.640363079961389
Epoch Time (s)               177.1863970020786
Total Train Time (s)         80384.15296738967
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:23.911478 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #467 | Epoch Duration: 177.27139401435852
2020-01-13 06:13:23.911624 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9357811
Z variance train             0.08104898
KL Divergence                50.63583
KL Loss                      5.063583
QF Loss                      141.08417
VF Loss                      46.78643
Policy Loss                  -1495.7389
Q Predictions Mean           1496.3269
Q Predictions Std            1510.9442
Q Predictions Max            5037.032
Q Predictions Min            673.054
V Predictions Mean           1493.124
V Predictions Std            1503.1544
V Predictions Max            5030.722
V Predictions Min            672.57007
Log Pis Mean                 0.040970713
Log Pis Std                  4.2209225
Log Pis Max                  22.272442
Log Pis Min                  -6.1763253
Policy mu Mean               -0.02211746
Policy mu Std                0.91754436
Policy mu Max                2.9467084
Policy mu Min                -3.1610296
Policy log std Mean          -0.4973286
Policy log std Std           0.28753284
Policy log std Max           -0.03518641
Policy log std Min           -2.794537
Z mean eval                  1.9118057
Z variance eval              0.07757226
total_rewards                [10171.51242949  9790.56138324 10390.21727852 10048.27983279
 10157.9454873   9984.36007376 10100.91636142 10418.20995358
 10055.05189563 10298.63412991]
total_rewards_mean           10141.568882564135
total_rewards_std            181.64584926376168
total_rewards_max            10418.209953578276
total_rewards_min            9790.561383244809
Number of train steps total  1876000
Number of env steps total    5630000
Number of rollouts total     0
Train Time (s)               146.93145877402276
(Previous) Eval Time (s)     20.987081818748266
Sample Time (s)              6.49509046273306
Epoch Time (s)               174.41363105550408
Total Train Time (s)         80558.64949877327
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:16:18.411527 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #468 | Epoch Duration: 174.49975180625916
2020-01-13 06:16:18.411752 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9121056
Z variance train             0.0775271
KL Divergence                49.499893
KL Loss                      4.9499893
QF Loss                      274.08038
VF Loss                      67.05533
Policy Loss                  -1524.1951
Q Predictions Mean           1519.2361
Q Predictions Std            1506.1125
Q Predictions Max            4860.576
Q Predictions Min            666.31165
V Predictions Mean           1522.4116
V Predictions Std            1508.1493
V Predictions Max            4830.562
V Predictions Min            678.25806
Log Pis Mean                 0.006069474
Log Pis Std                  3.7658951
Log Pis Max                  12.234846
Log Pis Min                  -5.89418
Policy mu Mean               0.03915518
Policy mu Std                0.9213236
Policy mu Max                2.8926644
Policy mu Min                -2.5968542
Policy log std Mean          -0.5091467
Policy log std Std           0.28292263
Policy log std Max           -0.028164208
Policy log std Min           -2.566405
Z mean eval                  1.8997482
Z variance eval              0.08620671
total_rewards                [11006.12068723 11111.92129857 11197.96943568 11255.42026759
 11201.24081931 10789.72501419 10888.87593947 11024.19426701
 11458.95964428 11211.86826934]
total_rewards_mean           11114.629564267827
total_rewards_std            184.05851119528714
total_rewards_max            11458.959644284796
total_rewards_min            10789.725014193067
Number of train steps total  1880000
Number of env steps total    5642000
Number of rollouts total     0
Train Time (s)               144.87706909375265
(Previous) Eval Time (s)     17.964134177193046
Sample Time (s)              6.313470317050815
Epoch Time (s)               169.1546735879965
Total Train Time (s)         80727.88962696819
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:19:07.658095 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #469 | Epoch Duration: 169.2462077140808
2020-01-13 06:19:07.658257 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8988708
Z variance train             0.086034335
KL Divergence                50.20752
KL Loss                      5.020752
QF Loss                      223.31522
VF Loss                      41.562107
Policy Loss                  -1391.9946
Q Predictions Mean           1388.3274
Q Predictions Std            1414.7264
Q Predictions Max            4942.7397
Q Predictions Min            701.855
V Predictions Mean           1390.396
V Predictions Std            1413.6566
V Predictions Max            4937.7344
V Predictions Min            703.9648
Log Pis Mean                 -0.08373403
Log Pis Std                  4.1959066
Log Pis Max                  19.834631
Log Pis Min                  -6.7451854
Policy mu Mean               0.04713446
Policy mu Std                0.8990403
Policy mu Max                3.1198704
Policy mu Min                -3.0776954
Policy log std Mean          -0.49410978
Policy log std Std           0.29663876
Policy log std Max           0.64274585
Policy log std Min           -2.930779
Z mean eval                  1.9465272
Z variance eval              0.10792641
total_rewards                [ 5017.78220965 10711.72362615 10108.2033531  10347.55055763
  6728.36609718  9922.25025175 10197.98157443 10646.74164294
 10655.37924646 10551.56319309]
total_rewards_mean           9488.754175237696
total_rewards_std            1864.0995102043987
total_rewards_max            10711.72362614961
total_rewards_min            5017.782209654667
Number of train steps total  1884000
Number of env steps total    5654000
Number of rollouts total     0
Train Time (s)               146.2207966791466
(Previous) Eval Time (s)     17.625145617872477
Sample Time (s)              6.338951169047505
Epoch Time (s)               170.18489346606657
Total Train Time (s)         80898.15451486176
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:21:57.929433 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #470 | Epoch Duration: 170.27103447914124
2020-01-13 06:21:57.929613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.945735
Z variance train             0.1078009
KL Divergence                50.19498
KL Loss                      5.0194983
QF Loss                      267.9864
VF Loss                      67.60443
Policy Loss                  -1310.7927
Q Predictions Mean           1311.1578
Q Predictions Std            1320.8882
Q Predictions Max            4935.015
Q Predictions Min            695.60614
V Predictions Mean           1317.6694
V Predictions Std            1320.8018
V Predictions Max            4914.177
V Predictions Min            699.9674
Log Pis Mean                 -0.6834066
Log Pis Std                  3.477547
Log Pis Max                  13.217736
Log Pis Min                  -7.7725377
Policy mu Mean               0.040283155
Policy mu Std                0.85421723
Policy mu Max                2.6063464
Policy mu Min                -2.763673
Policy log std Mean          -0.47042522
Policy log std Std           0.252242
Policy log std Max           0.014385104
Policy log std Min           -2.3408854
Z mean eval                  1.9020954
Z variance eval              0.059701808
total_rewards                [10932.4924989  11194.75862418 10774.66990052 11075.70778261
 10831.34821667 11120.80021836 10850.26428785 11005.52711471
 11029.52279879 11048.32780845]
total_rewards_mean           10986.341925103174
total_rewards_std            128.77216250600154
total_rewards_max            11194.758624176602
total_rewards_min            10774.66990051865
Number of train steps total  1888000
Number of env steps total    5666000
Number of rollouts total     0
Train Time (s)               146.51118022203445
(Previous) Eval Time (s)     20.782484869938344
Sample Time (s)              6.357478577177972
Epoch Time (s)               173.65114366915077
Total Train Time (s)         81071.88931461051
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:24:51.667366 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #471 | Epoch Duration: 173.73761916160583
2020-01-13 06:24:51.667517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #471 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9046685
Z variance train             0.059680752
KL Divergence                51.81332
KL Loss                      5.181332
QF Loss                      116.75201
VF Loss                      39.919456
Policy Loss                  -1364.4567
Q Predictions Mean           1360.9136
Q Predictions Std            1342.9758
Q Predictions Max            4939.248
Q Predictions Min            707.8516
V Predictions Mean           1363.0518
V Predictions Std            1342.2438
V Predictions Max            4937.4062
V Predictions Min            707.3256
Log Pis Mean                 -0.19136432
Log Pis Std                  3.9745934
Log Pis Max                  14.153146
Log Pis Min                  -6.765851
Policy mu Mean               0.046342343
Policy mu Std                0.88999355
Policy mu Max                3.4279509
Policy mu Min                -2.8243797
Policy log std Mean          -0.49910673
Policy log std Std           0.2805549
Policy log std Max           0.14655697
Policy log std Min           -2.82943
Z mean eval                  1.9043581
Z variance eval              0.03876396
total_rewards                [10625.13310875 11105.46812051 11120.05618114 11318.09650179
 10852.4076245  11043.6999986  11080.41829681 11298.50345706
 10352.49901757 11152.43731305]
total_rewards_mean           10994.871961978457
total_rewards_std            287.8791215277325
total_rewards_max            11318.096501785252
total_rewards_min            10352.499017570846
Number of train steps total  1892000
Number of env steps total    5678000
Number of rollouts total     0
Train Time (s)               147.6002483149059
(Previous) Eval Time (s)     20.76616905629635
Sample Time (s)              6.238984188530594
Epoch Time (s)               174.60540155973285
Total Train Time (s)         81246.58268728014
Epoch                        472
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:27:46.368494 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #472 | Epoch Duration: 174.7008557319641
2020-01-13 06:27:46.368700 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #472 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9053196
Z variance train             0.038859166
KL Divergence                53.41358
KL Loss                      5.341358
QF Loss                      2220.936
VF Loss                      108.33225
Policy Loss                  -1385.425
Q Predictions Mean           1380.7351
Q Predictions Std            1377.1395
Q Predictions Max            4969.3765
Q Predictions Min            330.04764
V Predictions Mean           1383.7319
V Predictions Std            1371.914
V Predictions Max            4956.5024
V Predictions Min            716.1331
Log Pis Mean                 -0.14858802
Log Pis Std                  4.1000395
Log Pis Max                  17.236443
Log Pis Min                  -8.057421
Policy mu Mean               0.060691725
Policy mu Std                0.90613234
Policy mu Max                3.169164
Policy mu Min                -3.2978404
Policy log std Mean          -0.51401854
Policy log std Std           0.29928002
Policy log std Max           -0.03928125
Policy log std Min           -2.773388
Z mean eval                  1.9210787
Z variance eval              0.05522249
total_rewards                [10444.05159977 10643.74112695 10848.71538242 10848.52244899
 10665.88272425 10893.5200308  10629.41340416 10807.24057546
 11036.56322511 10837.42343009]
total_rewards_mean           10765.507394797762
total_rewards_std            160.3728912438485
total_rewards_max            11036.563225106196
total_rewards_min            10444.051599769062
Number of train steps total  1896000
Number of env steps total    5690000
Number of rollouts total     0
Train Time (s)               146.02566036675125
(Previous) Eval Time (s)     20.71144007332623
Sample Time (s)              6.475900081451982
Epoch Time (s)               173.21300052152947
Total Train Time (s)         81419.88288313244
Epoch                        473
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:30:39.676841 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #473 | Epoch Duration: 173.30797410011292
2020-01-13 06:30:39.677048 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9229391
Z variance train             0.055282645
KL Divergence                52.649258
KL Loss                      5.264926
QF Loss                      178.03833
VF Loss                      84.07631
Policy Loss                  -1480.5052
Q Predictions Mean           1477.4048
Q Predictions Std            1467.6039
Q Predictions Max            5042.1836
Q Predictions Min            693.48785
V Predictions Mean           1480.7505
V Predictions Std            1466.2935
V Predictions Max            5015.8794
V Predictions Min            698.43567
Log Pis Mean                 0.1612994
Log Pis Std                  3.9319742
Log Pis Max                  16.746246
Log Pis Min                  -8.320455
Policy mu Mean               0.08616351
Policy mu Std                0.9175488
Policy mu Max                2.7740273
Policy mu Min                -3.1177535
Policy log std Mean          -0.5140763
Policy log std Std           0.30302346
Policy log std Max           0.038535744
Policy log std Min           -2.9753125
Z mean eval                  1.9100962
Z variance eval              0.061217755
total_rewards                [10473.40643426 11044.23091241 10805.43157174 11224.31751825
 11243.85701465 10784.23967781 10959.91990865 11537.44813732
 11165.74959366 11257.63597223]
total_rewards_mean           11049.623674098995
total_rewards_std            288.6402926289083
total_rewards_max            11537.448137324405
total_rewards_min            10473.406434264098
Number of train steps total  1900000
Number of env steps total    5702000
Number of rollouts total     0
Train Time (s)               146.13698118831962
(Previous) Eval Time (s)     17.55434784805402
Sample Time (s)              6.4445712878368795
Epoch Time (s)               170.13590032421052
Total Train Time (s)         81590.11779532162
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:33:29.907299 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #474 | Epoch Duration: 170.23010802268982
2020-01-13 06:33:29.907426 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.909878
Z variance train             0.06114787
KL Divergence                52.260525
KL Loss                      5.2260528
QF Loss                      4340.2476
VF Loss                      119.18564
Policy Loss                  -1608.1349
Q Predictions Mean           1603.5507
Q Predictions Std            1547.21
Q Predictions Max            5004.372
Q Predictions Min            703.65985
V Predictions Mean           1612.917
V Predictions Std            1546.969
V Predictions Max            5006.9062
V Predictions Min            712.1132
Log Pis Mean                 0.0739446
Log Pis Std                  3.845382
Log Pis Max                  13.2386265
Log Pis Min                  -7.819598
Policy mu Mean               0.036541257
Policy mu Std                0.92676437
Policy mu Max                3.1383789
Policy mu Min                -3.2900372
Policy log std Mean          -0.54351825
Policy log std Std           0.32046193
Policy log std Max           0.069793105
Policy log std Min           -3.0453513
Z mean eval                  1.9412501
Z variance eval              0.09927571
total_rewards                [10442.39026894 10883.29390644 10730.87242304 10838.01104536
 10683.57411856 11013.49603436 10830.88652971 10746.74844186
 10724.79483234 10611.21236709]
total_rewards_mean           10750.52799676799
total_rewards_std            148.591083625154
total_rewards_max            11013.49603436174
total_rewards_min            10442.390268939647
Number of train steps total  1904000
Number of env steps total    5714000
Number of rollouts total     0
Train Time (s)               144.97644892381504
(Previous) Eval Time (s)     18.946407571900636
Sample Time (s)              5.3985868049785495
Epoch Time (s)               169.32144330069423
Total Train Time (s)         81759.52181272721
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:36:19.320484 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #475 | Epoch Duration: 169.41292357444763
2020-01-13 06:36:19.320770 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9420536
Z variance train             0.0994717
KL Divergence                50.961502
KL Loss                      5.0961504
QF Loss                      364.52533
VF Loss                      177.13486
Policy Loss                  -1449.3782
Q Predictions Mean           1445.5295
Q Predictions Std            1443.6648
Q Predictions Max            4996.174
Q Predictions Min            699.0154
V Predictions Mean           1444.7388
V Predictions Std            1439.056
V Predictions Max            4977.1646
V Predictions Min            706.4408
Log Pis Mean                 0.030737206
Log Pis Std                  4.1159625
Log Pis Max                  19.502075
Log Pis Min                  -5.8206654
Policy mu Mean               0.054369193
Policy mu Std                0.93027186
Policy mu Max                3.3039904
Policy mu Min                -3.1314957
Policy log std Mean          -0.52987784
Policy log std Std           0.30634946
Policy log std Max           0.018318892
Policy log std Min           -2.9480867
Z mean eval                  1.9219061
Z variance eval              0.0644934
total_rewards                [10704.27067813 10831.99600311 11053.14782413 10969.32581858
 11131.54954544 10531.12824112 10803.93091052 10722.60587716
 10599.55473556  3779.8109137 ]
total_rewards_mean           10112.732054743869
total_rewards_std            2118.750248442419
total_rewards_max            11131.549545435022
total_rewards_min            3779.810913701394
Number of train steps total  1908000
Number of env steps total    5726000
Number of rollouts total     0
Train Time (s)               145.99292594008148
(Previous) Eval Time (s)     18.571296812966466
Sample Time (s)              6.496478038374335
Epoch Time (s)               171.06070079142228
Total Train Time (s)         81930.66845519375
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:39:10.475043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #476 | Epoch Duration: 171.1540687084198
2020-01-13 06:39:10.475220 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9215797
Z variance train             0.0644102
KL Divergence                51.76545
KL Loss                      5.176545
QF Loss                      148.6279
VF Loss                      65.55623
Policy Loss                  -1375.8143
Q Predictions Mean           1374.1105
Q Predictions Std            1374.2666
Q Predictions Max            4992.796
Q Predictions Min            709.285
V Predictions Mean           1377.5881
V Predictions Std            1373.4618
V Predictions Max            5006.9175
V Predictions Min            710.4366
Log Pis Mean                 -0.14660412
Log Pis Std                  3.8423984
Log Pis Max                  14.845793
Log Pis Min                  -7.796835
Policy mu Mean               0.056566115
Policy mu Std                0.9087318
Policy mu Max                3.3689997
Policy mu Min                -2.7435658
Policy log std Mean          -0.51040274
Policy log std Std           0.2835738
Policy log std Max           -6.812811e-05
Policy log std Min           -2.7377353
Z mean eval                  1.9382589
Z variance eval              0.07342229
total_rewards                [10494.38520104 11079.80951688 10270.20112471 11016.52913955
 11055.99616407 10727.59088454 10757.74693469  7848.54919204
 10722.86923251 11243.80190985]
total_rewards_mean           10521.747929988725
total_rewards_std            933.3572168686921
total_rewards_max            11243.80190985262
total_rewards_min            7848.54919203871
Number of train steps total  1912000
Number of env steps total    5738000
Number of rollouts total     0
Train Time (s)               146.44279421307147
(Previous) Eval Time (s)     17.49807812506333
Sample Time (s)              6.540099622681737
Epoch Time (s)               170.48097196081653
Total Train Time (s)         82101.25821323413
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:42:01.067995 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #477 | Epoch Duration: 170.5926399230957
2020-01-13 06:42:01.068163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #477 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9385636
Z variance train             0.07307295
KL Divergence                52.064342
KL Loss                      5.2064342
QF Loss                      311.86453
VF Loss                      119.08108
Policy Loss                  -1469.3341
Q Predictions Mean           1470.8298
Q Predictions Std            1479.9359
Q Predictions Max            5045.476
Q Predictions Min            708.6676
V Predictions Mean           1471.0474
V Predictions Std            1481.2026
V Predictions Max            5049.3164
V Predictions Min            711.97815
Log Pis Mean                 -0.36409104
Log Pis Std                  3.341307
Log Pis Max                  10.855498
Log Pis Min                  -7.0987706
Policy mu Mean               0.04609257
Policy mu Std                0.88407004
Policy mu Max                2.8240075
Policy mu Min                -2.295888
Policy log std Mean          -0.506406
Policy log std Std           0.2969356
Policy log std Max           0.015345156
Policy log std Min           -2.9158983
Z mean eval                  1.9299568
Z variance eval              0.10658576
total_rewards                [11073.44185022 11135.9225355  10931.74546114 11045.66647093
 11062.53188798 10763.27223995 10909.33135842 11023.6810065
 11378.18290707  3903.74672839]
total_rewards_mean           10322.752244610003
total_rewards_std            2145.053197381442
total_rewards_max            11378.182907066455
total_rewards_min            3903.7467283864407
Number of train steps total  1916000
Number of env steps total    5750000
Number of rollouts total     0
Train Time (s)               145.77133054286242
(Previous) Eval Time (s)     20.994496474973857
Sample Time (s)              5.496454646345228
Epoch Time (s)               172.2622816641815
Total Train Time (s)         82273.60583481751
Epoch                        478
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:44:53.417442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #478 | Epoch Duration: 172.34915041923523
2020-01-13 06:44:53.417579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #478 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9299237
Z variance train             0.106579706
KL Divergence                51.326534
KL Loss                      5.1326537
QF Loss                      4624.7905
VF Loss                      46.80402
Policy Loss                  -1471.5432
Q Predictions Mean           1471.9856
Q Predictions Std            1447.4788
Q Predictions Max            5030.6875
Q Predictions Min            698.8049
V Predictions Mean           1472.9326
V Predictions Std            1445.4672
V Predictions Max            5013.8296
V Predictions Min            690.9491
Log Pis Mean                 -0.4342942
Log Pis Std                  3.955201
Log Pis Max                  30.82098
Log Pis Min                  -8.323935
Policy mu Mean               -0.0025851277
Policy mu Std                0.88631725
Policy mu Max                4.9911547
Policy mu Min                -4.8986325
Policy log std Mean          -0.50897795
Policy log std Std           0.27937806
Policy log std Max           -0.03760436
Policy log std Min           -2.9815927
Z mean eval                  1.9169581
Z variance eval              0.07589391
total_rewards                [10912.57657116 11098.49832939 10449.07518703 11146.63708802
 10542.8707315  10969.94798221 10960.04839066 11075.96666963
 11132.51566476 10861.13327287]
total_rewards_mean           10914.926988722236
total_rewards_std            228.9263891838117
total_rewards_max            11146.637088020572
total_rewards_min            10449.075187027302
Number of train steps total  1920000
Number of env steps total    5762000
Number of rollouts total     0
Train Time (s)               145.67179154977202
(Previous) Eval Time (s)     20.833420569542795
Sample Time (s)              6.588676243554801
Epoch Time (s)               173.09388836286962
Total Train Time (s)         82446.8092748574
Epoch                        479
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:47:46.623639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #479 | Epoch Duration: 173.20596313476562
2020-01-13 06:47:46.623769 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #479 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9170904
Z variance train             0.075952135
KL Divergence                52.2453
KL Loss                      5.22453
QF Loss                      4823.877
VF Loss                      108.94285
Policy Loss                  -1390.6871
Q Predictions Mean           1390.1254
Q Predictions Std            1394.6223
Q Predictions Max            5087.4395
Q Predictions Min            703.66235
V Predictions Mean           1398.7285
V Predictions Std            1395.322
V Predictions Max            5087.968
V Predictions Min            712.6094
Log Pis Mean                 -0.20261204
Log Pis Std                  3.9276202
Log Pis Max                  17.113379
Log Pis Min                  -8.458815
Policy mu Mean               0.07365552
Policy mu Std                0.9090248
Policy mu Max                2.842454
Policy mu Min                -3.1087933
Policy log std Mean          -0.5027702
Policy log std Std           0.3024813
Policy log std Max           -0.0046758354
Policy log std Min           -2.944003
Z mean eval                  1.9371055
Z variance eval              0.04834003
total_rewards                [10462.87170378 10786.48675718 10735.66551991 10671.50497685
 10618.52214277 10398.26452177 10851.91329962 10725.44082392
 10733.68830939 10676.8276809 ]
total_rewards_mean           10666.118573608652
total_rewards_std            133.18932309875538
total_rewards_max            10851.91329961959
total_rewards_min            10398.264521770541
Number of train steps total  1924000
Number of env steps total    5774000
Number of rollouts total     0
Train Time (s)               145.20507576689124
(Previous) Eval Time (s)     20.543459633830935
Sample Time (s)              9.357812229543924
Epoch Time (s)               175.1063476302661
Total Train Time (s)         82622.09535995545
Epoch                        480
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:50:41.916645 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #480 | Epoch Duration: 175.29275393486023
2020-01-13 06:50:41.916884 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #480 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.937013
Z variance train             0.04834043
KL Divergence                54.550858
KL Loss                      5.4550858
QF Loss                      128.84842
VF Loss                      132.71507
Policy Loss                  -1442.434
Q Predictions Mean           1439.1498
Q Predictions Std            1427.5397
Q Predictions Max            5070.1616
Q Predictions Min            716.1996
V Predictions Mean           1435.3552
V Predictions Std            1424.9089
V Predictions Max            5042.5693
V Predictions Min            712.80804
Log Pis Mean                 -0.08497582
Log Pis Std                  3.9510744
Log Pis Max                  14.801898
Log Pis Min                  -8.917055
Policy mu Mean               0.03795256
Policy mu Std                0.9198515
Policy mu Max                3.2024722
Policy mu Min                -4.7321105
Policy log std Mean          -0.50886893
Policy log std Std           0.3076216
Policy log std Max           0.19354713
Policy log std Min           -2.882358
Z mean eval                  1.9692732
Z variance eval              0.03745597
total_rewards                [10581.52575357 10986.0354508  11138.20857527 10903.19513956
 10797.53569024 10780.07510739 10937.72946363 10969.75662728
 10814.28627298 10691.7802423 ]
total_rewards_mean           10860.012832301272
total_rewards_std            152.13956339301632
total_rewards_max            11138.208575270059
total_rewards_min            10581.525753570622
Number of train steps total  1928000
Number of env steps total    5786000
Number of rollouts total     0
Train Time (s)               146.53895801771432
(Previous) Eval Time (s)     20.80060675693676
Sample Time (s)              6.466960404999554
Epoch Time (s)               173.80652517965063
Total Train Time (s)         82795.98320999835
Epoch                        481
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:53:35.807397 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #481 | Epoch Duration: 173.89035058021545
2020-01-13 06:53:35.807532 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #481 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9693766
Z variance train             0.037395053
KL Divergence                53.976505
KL Loss                      5.3976507
QF Loss                      84.94588
VF Loss                      82.693245
Policy Loss                  -1416.0228
Q Predictions Mean           1412.0756
Q Predictions Std            1421.6146
Q Predictions Max            5019.7905
Q Predictions Min            699.7934
V Predictions Mean           1415.9609
V Predictions Std            1421.7878
V Predictions Max            5030.835
V Predictions Min            701.8262
Log Pis Mean                 -0.0464302
Log Pis Std                  3.981182
Log Pis Max                  16.694613
Log Pis Min                  -6.8252063
Policy mu Mean               0.051084857
Policy mu Std                0.9166088
Policy mu Max                3.3369873
Policy mu Min                -2.651164
Policy log std Mean          -0.48058796
Policy log std Std           0.2742504
Policy log std Max           -0.0041770935
Policy log std Min           -2.6100702
Z mean eval                  1.9761477
Z variance eval              0.042614684
total_rewards                [10412.79478474 11122.31697936 11263.68689292 10765.25121594
 10677.51969168 11076.16035287 11023.38883807 10989.80138139
 11077.08028867 10956.57526464]
total_rewards_mean           10936.457569029031
total_rewards_std            237.12967944979815
total_rewards_max            11263.686892919362
total_rewards_min            10412.794784737769
Number of train steps total  1932000
Number of env steps total    5798000
Number of rollouts total     0
Train Time (s)               146.34212571708485
(Previous) Eval Time (s)     20.615726411808282
Sample Time (s)              6.473025491926819
Epoch Time (s)               173.43087762081996
Total Train Time (s)         82969.49496896612
Epoch                        482
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:56:29.324363 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #482 | Epoch Duration: 173.51673483848572
2020-01-13 06:56:29.324496 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #482 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9789568
Z variance train             0.042562027
KL Divergence                54.525787
KL Loss                      5.452579
QF Loss                      415.30884
VF Loss                      90.72963
Policy Loss                  -1390.0847
Q Predictions Mean           1387.2959
Q Predictions Std            1414.0348
Q Predictions Max            5019.422
Q Predictions Min            699.47723
V Predictions Mean           1392.0417
V Predictions Std            1411.001
V Predictions Max            5019.1846
V Predictions Min            696.22516
Log Pis Mean                 -0.079107806
Log Pis Std                  4.091357
Log Pis Max                  17.440125
Log Pis Min                  -7.5784945
Policy mu Mean               0.016362902
Policy mu Std                0.93215674
Policy mu Max                4.23165
Policy mu Min                -3.4624796
Policy log std Mean          -0.48944935
Policy log std Std           0.29558548
Policy log std Max           0.33884355
Policy log std Min           -3.0141518
Z mean eval                  1.9454267
Z variance eval              0.04254834
total_rewards                [10715.70098637 10667.65604079 11065.85269419 10879.59185096
 10622.53924284 10373.9616072  11056.1380031  10650.78119119
 10784.70231981 10602.96571051]
total_rewards_mean           10741.988964695545
total_rewards_std            201.9681794420593
total_rewards_max            11065.85269418751
total_rewards_min            10373.961607199722
Number of train steps total  1936000
Number of env steps total    5810000
Number of rollouts total     0
Train Time (s)               146.23701600497589
(Previous) Eval Time (s)     20.69924806896597
Sample Time (s)              6.304866271559149
Epoch Time (s)               173.241130345501
Total Train Time (s)         83142.8266882482
Epoch                        483
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:59:22.659126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #483 | Epoch Duration: 173.33453249931335
2020-01-13 06:59:22.659257 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #483 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9451978
Z variance train             0.0426062
KL Divergence                54.307434
KL Loss                      5.4307437
QF Loss                      93.58286
VF Loss                      33.579403
Policy Loss                  -1385.7599
Q Predictions Mean           1384.6838
Q Predictions Std            1405.13
Q Predictions Max            5087.316
Q Predictions Min            686.1892
V Predictions Mean           1385.3654
V Predictions Std            1400.3682
V Predictions Max            5052.7607
V Predictions Min            707.45
Log Pis Mean                 -0.4753527
Log Pis Std                  3.5704572
Log Pis Max                  11.902157
Log Pis Min                  -7.3502254
Policy mu Mean               0.03301279
Policy mu Std                0.86823106
Policy mu Max                2.7155745
Policy mu Min                -2.6191165
Policy log std Mean          -0.4934486
Policy log std Std           0.26674742
Policy log std Max           -0.0540002
Policy log std Min           -2.8198137
Z mean eval                  1.95738
Z variance eval              0.054835726
total_rewards                [10356.75829916 11058.51401962 11077.00772916 11035.04407885
 10979.48302005 10937.30410438 11055.14572195 11134.61747748
 11144.16262557 11108.61672486]
total_rewards_mean           10988.665380110357
total_rewards_std            219.3518659918495
total_rewards_max            11144.162625565496
total_rewards_min            10356.758299160785
Number of train steps total  1940000
Number of env steps total    5822000
Number of rollouts total     0
Train Time (s)               146.39351431978866
(Previous) Eval Time (s)     21.153218193911016
Sample Time (s)              6.453431409783661
Epoch Time (s)               174.00016392348334
Total Train Time (s)         83316.90810581436
Epoch                        484
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:02:16.745677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #484 | Epoch Duration: 174.08632349967957
2020-01-13 07:02:16.745814 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #484 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9557072
Z variance train             0.054739468
KL Divergence                53.76587
KL Loss                      5.376587
QF Loss                      102.346924
VF Loss                      78.00208
Policy Loss                  -1572.4355
Q Predictions Mean           1566.0039
Q Predictions Std            1531.2759
Q Predictions Max            4966.7393
Q Predictions Min            695.5759
V Predictions Mean           1569.5193
V Predictions Std            1526.9531
V Predictions Max            4952.2666
V Predictions Min            700.0793
Log Pis Mean                 0.15987879
Log Pis Std                  4.252282
Log Pis Max                  22.14328
Log Pis Min                  -7.5532575
Policy mu Mean               0.024124483
Policy mu Std                0.9453691
Policy mu Max                4.5093217
Policy mu Min                -3.8601558
Policy log std Mean          -0.5027843
Policy log std Std           0.2819894
Policy log std Max           0.2391034
Policy log std Min           -2.4361587
Z mean eval                  1.9583254
Z variance eval              0.055874597
total_rewards                [11009.12229625 10871.39475379 10986.65734384 10712.36166389
 10770.65279228 11045.18750013 10966.61321259 11211.39310888
 11282.76218016  9161.91563331]
total_rewards_mean           10801.806048511973
total_rewards_std            571.4613115496348
total_rewards_max            11282.762180162412
total_rewards_min            9161.915633305362
Number of train steps total  1944000
Number of env steps total    5834000
Number of rollouts total     0
Train Time (s)               146.3954515978694
(Previous) Eval Time (s)     20.738516284618527
Sample Time (s)              6.472948368173093
Epoch Time (s)               173.60691625066102
Total Train Time (s)         83490.60799352312
Epoch                        485
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:05:10.447759 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #485 | Epoch Duration: 173.7018482685089
2020-01-13 07:05:10.447900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #485 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9594568
Z variance train             0.05595585
KL Divergence                54.853333
KL Loss                      5.4853334
QF Loss                      93.67799
VF Loss                      251.47589
Policy Loss                  -1493.9791
Q Predictions Mean           1492.3896
Q Predictions Std            1513.509
Q Predictions Max            5019.5713
Q Predictions Min            713.07666
V Predictions Mean           1496.6304
V Predictions Std            1512.919
V Predictions Max            5039.502
V Predictions Min            720.80316
Log Pis Mean                 -0.049738526
Log Pis Std                  3.9673846
Log Pis Max                  19.076355
Log Pis Min                  -7.6999006
Policy mu Mean               -0.011742544
Policy mu Std                0.9130639
Policy mu Max                4.165495
Policy mu Min                -3.399548
Policy log std Mean          -0.50905174
Policy log std Std           0.2847112
Policy log std Max           -0.06492394
Policy log std Min           -2.7844129
Z mean eval                  1.9226011
Z variance eval              0.053735264
total_rewards                [11097.25885303 11011.27930944  4318.4229068  10664.97383921
 10722.56941573  7016.23552817 10935.51691758 11112.5833255
 11015.1763217  11048.44702624]
total_rewards_mean           9894.24634433899
total_rewards_std            2202.388422199075
total_rewards_max            11112.58332549745
total_rewards_min            4318.422906797959
Number of train steps total  1948000
Number of env steps total    5846000
Number of rollouts total     0
Train Time (s)               146.76564952731133
(Previous) Eval Time (s)     21.27900206670165
Sample Time (s)              6.492278041318059
Epoch Time (s)               174.53692963533103
Total Train Time (s)         83665.22462728061
Epoch                        486
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:08:05.066744 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #486 | Epoch Duration: 174.61874914169312
2020-01-13 07:08:05.066876 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #486 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9212223
Z variance train             0.05382859
KL Divergence                53.12845
KL Loss                      5.3128448
QF Loss                      114.50653
VF Loss                      83.81926
Policy Loss                  -1292.2568
Q Predictions Mean           1287.6536
Q Predictions Std            1287.3813
Q Predictions Max            4963.4424
Q Predictions Min            710.7223
V Predictions Mean           1294.7427
V Predictions Std            1289.64
V Predictions Max            4958.143
V Predictions Min            715.3325
Log Pis Mean                 -0.59941816
Log Pis Std                  3.7429721
Log Pis Max                  15.335223
Log Pis Min                  -7.383543
Policy mu Mean               0.011817004
Policy mu Std                0.8345059
Policy mu Max                3.2484727
Policy mu Min                -2.9993284
Policy log std Mean          -0.49974445
Policy log std Std           0.25557977
Policy log std Max           -0.040153086
Policy log std Min           -2.5204318
Z mean eval                  1.9446714
Z variance eval              0.049134355
total_rewards                [10928.14771469 10816.9790382  11089.63604125 11086.88300115
 11185.3028744  10655.16679217 11018.49110733 10853.29618325
 10853.38799265 10892.06035118]
total_rewards_mean           10937.935109627693
total_rewards_std            149.65936951715716
total_rewards_max            11185.302874404384
total_rewards_min            10655.166792170658
Number of train steps total  1952000
Number of env steps total    5858000
Number of rollouts total     0
Train Time (s)               147.72733874525875
(Previous) Eval Time (s)     17.47055237693712
Sample Time (s)              6.40812756260857
Epoch Time (s)               171.60601868480444
Total Train Time (s)         83836.90765724238
Epoch                        487
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:10:56.754169 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #487 | Epoch Duration: 171.68716549873352
2020-01-13 07:10:56.754344 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9446996
Z variance train             0.049068123
KL Divergence                53.445724
KL Loss                      5.3445725
QF Loss                      305.7442
VF Loss                      66.65883
Policy Loss                  -1490.2375
Q Predictions Mean           1487.143
Q Predictions Std            1485.9208
Q Predictions Max            5002.408
Q Predictions Min            705.7877
V Predictions Mean           1490.3641
V Predictions Std            1480.8246
V Predictions Max            4986.288
V Predictions Min            708.4897
Log Pis Mean                 0.014526013
Log Pis Std                  4.227763
Log Pis Max                  22.754826
Log Pis Min                  -6.7148705
Policy mu Mean               0.07356844
Policy mu Std                0.91941
Policy mu Max                3.8309798
Policy mu Min                -3.7071712
Policy log std Mean          -0.5026904
Policy log std Std           0.31373593
Policy log std Max           -0.029058099
Policy log std Min           -3.042889
Z mean eval                  1.9381412
Z variance eval              0.06005478
total_rewards                [10468.48163604 11099.68284002 11130.36353529 11148.78269826
 10616.90396092 10869.5582145  10982.32229454 10938.68057022
 10615.96235365 11115.32122731]
total_rewards_mean           10898.605933074885
total_rewards_std            236.09445608991933
total_rewards_max            11148.782698261128
total_rewards_min            10468.48163603935
Number of train steps total  1956000
Number of env steps total    5870000
Number of rollouts total     0
Train Time (s)               146.08274261187762
(Previous) Eval Time (s)     17.419769917149097
Sample Time (s)              6.389797583222389
Epoch Time (s)               169.8923101122491
Total Train Time (s)         84006.88329979079
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:13:46.736399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #488 | Epoch Duration: 169.9819095134735
2020-01-13 07:13:46.736597 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #488 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9375412
Z variance train             0.059852958
KL Divergence                52.882275
KL Loss                      5.2882276
QF Loss                      9205.094
VF Loss                      126.374176
Policy Loss                  -1343.932
Q Predictions Mean           1340.2211
Q Predictions Std            1316.7458
Q Predictions Max            4979.33
Q Predictions Min            712.22064
V Predictions Mean           1337.8865
V Predictions Std            1312.4347
V Predictions Max            4956.414
V Predictions Min            710.1344
Log Pis Mean                 -0.31710798
Log Pis Std                  3.6837862
Log Pis Max                  17.153667
Log Pis Min                  -7.7848554
Policy mu Mean               0.057055544
Policy mu Std                0.889537
Policy mu Max                2.8416789
Policy mu Min                -3.5108619
Policy log std Mean          -0.4834763
Policy log std Std           0.2683077
Policy log std Max           0.0358842
Policy log std Min           -2.5037935
Z mean eval                  1.9335206
Z variance eval              0.04502097
total_rewards                [10279.4984387  10102.36011311 10011.87503935 10497.77784695
 10158.70099246 10294.68555273 10426.48812872 10504.52952331
  7085.33263948 10196.28866769]
total_rewards_mean           9955.753694250398
total_rewards_std            969.4960661662184
total_rewards_max            10504.529523313282
total_rewards_min            7085.332639479658
Number of train steps total  1960000
Number of env steps total    5882000
Number of rollouts total     0
Train Time (s)               146.72635693196207
(Previous) Eval Time (s)     20.985753951128572
Sample Time (s)              6.367701159790158
Epoch Time (s)               174.0798120428808
Total Train Time (s)         84181.05207213946
Epoch                        489
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:16:40.909771 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #489 | Epoch Duration: 174.17302250862122
2020-01-13 07:16:40.909976 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #489 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9343103
Z variance train             0.044902317
KL Divergence                53.374916
KL Loss                      5.3374915
QF Loss                      410.21814
VF Loss                      136.72723
Policy Loss                  -1368.079
Q Predictions Mean           1366.7825
Q Predictions Std            1391.4911
Q Predictions Max            5057.355
Q Predictions Min            703.56305
V Predictions Mean           1373.2458
V Predictions Std            1388.1617
V Predictions Max            5043.0713
V Predictions Min            712.02625
Log Pis Mean                 -0.24347012
Log Pis Std                  4.084296
Log Pis Max                  24.356047
Log Pis Min                  -8.301779
Policy mu Mean               0.028199038
Policy mu Std                0.91468996
Policy mu Max                3.6019006
Policy mu Min                -3.6024704
Policy log std Mean          -0.49217138
Policy log std Std           0.266083
Policy log std Max           -0.021850526
Policy log std Min           -2.7541308
Z mean eval                  1.9350755
Z variance eval              0.033555787
total_rewards                [10976.99257723 11001.49132812 11129.42707009 10729.05839897
 11497.68066896 11156.04488128 10718.02832826 10966.3656533
 10891.49952413 10872.95348216]
total_rewards_mean           10993.954191250175
total_rewards_std            217.00582533620235
total_rewards_max            11497.68066895682
total_rewards_min            10718.028328257642
Number of train steps total  1964000
Number of env steps total    5894000
Number of rollouts total     0
Train Time (s)               147.9416747679934
(Previous) Eval Time (s)     17.9857235760428
Sample Time (s)              6.3824056959711015
Epoch Time (s)               172.3098040400073
Total Train Time (s)         84353.448759072
Epoch                        490
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:19:33.311434 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #490 | Epoch Duration: 172.4013020992279
2020-01-13 07:19:33.311622 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #490 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9340433
Z variance train             0.03345848
KL Divergence                53.00472
KL Loss                      5.300472
QF Loss                      4360.878
VF Loss                      90.465965
Policy Loss                  -1386.9103
Q Predictions Mean           1386.6255
Q Predictions Std            1389.5698
Q Predictions Max            5035.524
Q Predictions Min            711.2699
V Predictions Mean           1383.1174
V Predictions Std            1386.9846
V Predictions Max            5027.6772
V Predictions Min            709.4045
Log Pis Mean                 -0.3000763
Log Pis Std                  3.6581514
Log Pis Max                  18.211031
Log Pis Min                  -6.398287
Policy mu Mean               0.032862693
Policy mu Std                0.8911175
Policy mu Max                3.2790208
Policy mu Min                -3.559864
Policy log std Mean          -0.5110021
Policy log std Std           0.2713104
Policy log std Max           0.12447268
Policy log std Min           -2.8964915
Z mean eval                  1.9444809
Z variance eval              0.059387065
total_rewards                [10677.87155359 10937.86790553 10769.43592864 10930.45396975
 10682.35675995 10773.01893938 10814.55661306 10895.78934051
 10827.63894164 10832.4268923 ]
total_rewards_mean           10814.141684436076
total_rewards_std            86.97485948994915
total_rewards_max            10937.867905533181
total_rewards_min            10677.87155359129
Number of train steps total  1968000
Number of env steps total    5906000
Number of rollouts total     0
Train Time (s)               146.5605505942367
(Previous) Eval Time (s)     20.715407208073884
Sample Time (s)              6.482214357238263
Epoch Time (s)               173.75817215954885
Total Train Time (s)         84527.28812773107
Epoch                        491
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:22:27.153081 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #491 | Epoch Duration: 173.84133124351501
2020-01-13 07:22:27.153213 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #491 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9447606
Z variance train             0.059369873
KL Divergence                51.16221
KL Loss                      5.116221
QF Loss                      4631.518
VF Loss                      66.615
Policy Loss                  -1372.0012
Q Predictions Mean           1371.612
Q Predictions Std            1367.8993
Q Predictions Max            4986.0195
Q Predictions Min            706.3628
V Predictions Mean           1367.3417
V Predictions Std            1363.2114
V Predictions Max            4944.6606
V Predictions Min            706.88495
Log Pis Mean                 0.01598242
Log Pis Std                  4.293718
Log Pis Max                  20.177704
Log Pis Min                  -8.025471
Policy mu Mean               -0.016672349
Policy mu Std                0.92411095
Policy mu Max                3.0789747
Policy mu Min                -4.0825872
Policy log std Mean          -0.4950594
Policy log std Std           0.2656351
Policy log std Max           -0.031531036
Policy log std Min           -2.3704424
Z mean eval                  1.9338996
Z variance eval              0.06801527
total_rewards                [10535.73710344 11303.53433008 10778.5455754  10826.84732061
 10819.93002365 11226.66975857 10734.50915949 10749.74231605
 11161.18720322 10915.07232051]
total_rewards_mean           10905.177511103504
total_rewards_std            233.85822436597962
total_rewards_max            11303.534330080794
total_rewards_min            10535.737103443967
Number of train steps total  1972000
Number of env steps total    5918000
Number of rollouts total     0
Train Time (s)               147.8821032908745
(Previous) Eval Time (s)     17.333984605968
Sample Time (s)              6.351521612145007
Epoch Time (s)               171.56760950898752
Total Train Time (s)         84698.9335016869
Epoch                        492
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:25:18.801126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #492 | Epoch Duration: 171.64781832695007
2020-01-13 07:25:18.801249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9332927
Z variance train             0.067967705
KL Divergence                50.04956
KL Loss                      5.0049562
QF Loss                      123.61888
VF Loss                      71.96081
Policy Loss                  -1379.7454
Q Predictions Mean           1374.2703
Q Predictions Std            1393.9899
Q Predictions Max            5034.424
Q Predictions Min            710.8836
V Predictions Mean           1378.1123
V Predictions Std            1389.2223
V Predictions Max            5036.7026
V Predictions Min            713.86084
Log Pis Mean                 0.02567634
Log Pis Std                  4.0299897
Log Pis Max                  16.520973
Log Pis Min                  -7.567665
Policy mu Mean               0.05566053
Policy mu Std                0.90914106
Policy mu Max                3.275959
Policy mu Min                -2.7109885
Policy log std Mean          -0.47848177
Policy log std Std           0.30573928
Policy log std Max           -0.013814092
Policy log std Min           -2.8033571
Z mean eval                  1.9287109
Z variance eval              0.046984974
total_rewards                [ 9984.92942351 10160.40369556 10211.90127334  9995.57488896
 10325.12715843  9750.86663642 10210.63015936 10264.28486565
 10121.43634555  9988.64526621]
total_rewards_mean           10101.379971300079
total_rewards_std            162.77640661482283
total_rewards_max            10325.12715842606
total_rewards_min            9750.8666364242
Number of train steps total  1976000
Number of env steps total    5930000
Number of rollouts total     0
Train Time (s)               145.5660469578579
(Previous) Eval Time (s)     17.52568938676268
Sample Time (s)              5.3674680553376675
Epoch Time (s)               168.45920439995825
Total Train Time (s)         84867.48035105085
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:28:07.351988 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #493 | Epoch Duration: 168.55064797401428
2020-01-13 07:28:07.352111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9293587
Z variance train             0.04691381
KL Divergence                51.124096
KL Loss                      5.1124096
QF Loss                      450.9043
VF Loss                      102.18129
Policy Loss                  -1572.074
Q Predictions Mean           1568.7886
Q Predictions Std            1525.6692
Q Predictions Max            5118.533
Q Predictions Min            709.25653
V Predictions Mean           1572.0203
V Predictions Std            1523.0581
V Predictions Max            5093.862
V Predictions Min            709.3226
Log Pis Mean                 0.20608917
Log Pis Std                  4.9643555
Log Pis Max                  17.942144
Log Pis Min                  -7.464965
Policy mu Mean               0.07818348
Policy mu Std                0.9880751
Policy mu Max                3.4904933
Policy mu Min                -3.679077
Policy log std Mean          -0.48626027
Policy log std Std           0.33424005
Policy log std Max           0.24560654
Policy log std Min           -2.85629
Z mean eval                  1.9441601
Z variance eval              0.047016706
total_rewards                [10264.60269134 10997.50446412 10363.28450375 10789.53524384
 10874.24331543 10932.98585968 10724.54929325 11011.00915417
  4251.69878184 10859.60728065]
total_rewards_mean           10106.902058806816
total_rewards_std            1966.4652938483482
total_rewards_max            11011.009154173325
total_rewards_min            4251.698781840886
Number of train steps total  1980000
Number of env steps total    5942000
Number of rollouts total     0
Train Time (s)               146.5278155207634
(Previous) Eval Time (s)     20.660610872786492
Sample Time (s)              5.472637462895364
Epoch Time (s)               172.66106385644525
Total Train Time (s)         85040.2244244623
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:31:00.099515 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #494 | Epoch Duration: 172.74730491638184
2020-01-13 07:31:00.099651 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #494 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9462849
Z variance train             0.04713069
KL Divergence                51.057434
KL Loss                      5.1057434
QF Loss                      395.48895
VF Loss                      49.001217
Policy Loss                  -1536.409
Q Predictions Mean           1535.6903
Q Predictions Std            1514.0067
Q Predictions Max            5112.707
Q Predictions Min            703.2636
V Predictions Mean           1533.152
V Predictions Std            1505.4829
V Predictions Max            5085.004
V Predictions Min            706.32605
Log Pis Mean                 0.3129847
Log Pis Std                  4.385354
Log Pis Max                  18.13654
Log Pis Min                  -9.528437
Policy mu Mean               0.07712681
Policy mu Std                0.9752122
Policy mu Max                3.4178593
Policy mu Min                -3.5831227
Policy log std Mean          -0.5119776
Policy log std Std           0.2923961
Policy log std Max           0.026080638
Policy log std Min           -2.831251
Z mean eval                  1.9695852
Z variance eval              0.058959454
total_rewards                [10608.69482356 11081.46955808  3945.81888488 10824.12324169
 10413.33055545 10688.50597685 10833.36193388 10980.25242261
 10833.6180529  10906.7073154 ]
total_rewards_mean           10111.58827652928
total_rewards_std            2063.1325991763597
total_rewards_max            11081.469558077617
total_rewards_min            3945.8188848825102
Number of train steps total  1984000
Number of env steps total    5954000
Number of rollouts total     0
Train Time (s)               146.55975976586342
(Previous) Eval Time (s)     18.630853567738086
Sample Time (s)              6.406934988219291
Epoch Time (s)               171.5975483218208
Total Train Time (s)         85211.91761019407
Epoch                        495
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:33:51.797876 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #495 | Epoch Duration: 171.69809985160828
2020-01-13 07:33:51.798128 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #495 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9683117
Z variance train             0.058931697
KL Divergence                50.343777
KL Loss                      5.0343776
QF Loss                      145.66403
VF Loss                      32.28474
Policy Loss                  -1315.7747
Q Predictions Mean           1315.4602
Q Predictions Std            1324.735
Q Predictions Max            5069.4946
Q Predictions Min            716.09094
V Predictions Mean           1315.8942
V Predictions Std            1322.0679
V Predictions Max            5069.3286
V Predictions Min            716.59064
Log Pis Mean                 -0.3150779
Log Pis Std                  3.6002717
Log Pis Max                  12.82064
Log Pis Min                  -6.2894506
Policy mu Mean               0.07082063
Policy mu Std                0.90497804
Policy mu Max                3.8145833
Policy mu Min                -3.034503
Policy log std Mean          -0.46858993
Policy log std Std           0.2878816
Policy log std Max           0.029656291
Policy log std Min           -2.8382206
Z mean eval                  1.9343226
Z variance eval              0.048055835
total_rewards                [10854.53066512 10834.67827645 10416.78250519 11071.16244572
 10421.87905435  3855.66428912 11051.57184703 11065.80308809
 11137.54355798 10828.52064855]
total_rewards_mean           10153.8136377594
total_rewards_std            2113.3966835624233
total_rewards_max            11137.54355798461
total_rewards_min            3855.6642891153224
Number of train steps total  1988000
Number of env steps total    5966000
Number of rollouts total     0
Train Time (s)               145.48283686721697
(Previous) Eval Time (s)     20.801163877360523
Sample Time (s)              6.496887960005552
Epoch Time (s)               172.78088870458305
Total Train Time (s)         85384.7826434793
Epoch                        496
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:36:44.665720 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #496 | Epoch Duration: 172.86741733551025
2020-01-13 07:36:44.665860 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #496 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9336386
Z variance train             0.04797704
KL Divergence                51.09329
KL Loss                      5.1093287
QF Loss                      4813.1104
VF Loss                      61.234474
Policy Loss                  -1626.9344
Q Predictions Mean           1624.384
Q Predictions Std            1559.3126
Q Predictions Max            5015.9053
Q Predictions Min            729.92285
V Predictions Mean           1627.2981
V Predictions Std            1558.1582
V Predictions Max            5011.3145
V Predictions Min            730.961
Log Pis Mean                 0.5093559
Log Pis Std                  4.4558587
Log Pis Max                  17.12281
Log Pis Min                  -7.025797
Policy mu Mean               0.013515919
Policy mu Std                0.9870281
Policy mu Max                3.3298657
Policy mu Min                -2.9134212
Policy log std Mean          -0.5230395
Policy log std Std           0.31566152
Policy log std Max           0.081062436
Policy log std Min           -2.9508858
Z mean eval                  1.9212301
Z variance eval              0.04078402
total_rewards                [10261.44805494 10693.82639448 10625.35963338 11128.96876985
 11011.67025831 10508.50958605 10862.12952648 10829.05622319
 10447.83084557 11142.86166819]
total_rewards_mean           10751.16609604388
total_rewards_std            281.46683253110604
total_rewards_max            11142.861668188125
total_rewards_min            10261.44805494406
Number of train steps total  1992000
Number of env steps total    5978000
Number of rollouts total     0
Train Time (s)               146.29631162295118
(Previous) Eval Time (s)     21.086207349784672
Sample Time (s)              6.484760878607631
Epoch Time (s)               173.86727985134348
Total Train Time (s)         85558.74689351534
Epoch                        497
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:39:38.632953 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #497 | Epoch Duration: 173.9669952392578
2020-01-13 07:39:38.633110 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #497 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.922147
Z variance train             0.04080583
KL Divergence                51.910995
KL Loss                      5.1910996
QF Loss                      195.6391
VF Loss                      128.22949
Policy Loss                  -1428.0156
Q Predictions Mean           1425.239
Q Predictions Std            1403.5796
Q Predictions Max            4986.506
Q Predictions Min            723.7554
V Predictions Mean           1422.5061
V Predictions Std            1395.3865
V Predictions Max            4973.1816
V Predictions Min            722.0271
Log Pis Mean                 0.059744097
Log Pis Std                  4.1543946
Log Pis Max                  12.816454
Log Pis Min                  -9.699412
Policy mu Mean               0.058047216
Policy mu Std                0.92973983
Policy mu Max                2.8766944
Policy mu Min                -3.0656548
Policy log std Mean          -0.5112796
Policy log std Std           0.27993947
Policy log std Max           0.048995286
Policy log std Min           -2.4944253
Z mean eval                  1.9678091
Z variance eval              0.06536892
total_rewards                [10335.00216843 10992.86569192 11126.51949252 11099.21400092
  7210.41453546 10914.30602086 10710.60427923 10709.17435236
 10808.20112206 10725.28490591]
total_rewards_mean           10463.1586569671
total_rewards_std            1106.1204013389724
total_rewards_max            11126.519492521935
total_rewards_min            7210.414535455862
Number of train steps total  1996000
Number of env steps total    5990000
Number of rollouts total     0
Train Time (s)               143.9210781501606
(Previous) Eval Time (s)     20.730806838721037
Sample Time (s)              6.5298263086006045
Epoch Time (s)               171.18171129748225
Total Train Time (s)         85730.01020016521
Epoch                        498
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:42:29.898853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #498 | Epoch Duration: 171.2656421661377
2020-01-13 07:42:29.898987 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #498 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9674351
Z variance train             0.06523304
KL Divergence                51.367996
KL Loss                      5.1368
QF Loss                      225.59964
VF Loss                      71.424446
Policy Loss                  -1469.0365
Q Predictions Mean           1468.3701
Q Predictions Std            1471.0298
Q Predictions Max            5080.473
Q Predictions Min            717.2096
V Predictions Mean           1471.218
V Predictions Std            1468.2836
V Predictions Max            5064.6714
V Predictions Min            720.6552
Log Pis Mean                 -0.12104863
Log Pis Std                  4.266109
Log Pis Max                  17.547075
Log Pis Min                  -12.351983
Policy mu Mean               -0.010652614
Policy mu Std                0.9155258
Policy mu Max                3.28209
Policy mu Min                -2.6966798
Policy log std Mean          -0.4783775
Policy log std Std           0.28886473
Policy log std Max           -0.02190137
Policy log std Min           -2.7130966
Z mean eval                  1.9334366
Z variance eval              0.06347112
total_rewards                [10707.17166018 10830.01247721 10919.39405581 10773.18910855
 10494.5456633  10773.7245833  11253.59412496 11007.18957873
 10914.24894746 10911.82638243]
total_rewards_mean           10858.489658193004
total_rewards_std            189.34283076971823
total_rewards_max            11253.594124960337
total_rewards_min            10494.54566329862
Number of train steps total  2000000
Number of env steps total    6002000
Number of rollouts total     0
Train Time (s)               143.24613559106365
(Previous) Eval Time (s)     20.925614381674677
Sample Time (s)              5.953868164215237
Epoch Time (s)               170.12561813695356
Total Train Time (s)         85900.30776325567
Epoch                        499
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:45:20.206020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #499 | Epoch Duration: 170.3068881034851
2020-01-13 07:45:20.206332 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #499 | Started Training: True
2020-01-13 07:45:21.049499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Variant:
2020-01-13 07:45:21.049849 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] {
  "env_name": "Humanoid-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0043402454
Z variance train             0.69638485
KL Divergence                0.14567924
KL Loss                      0.014567924
QF Loss                      1191.7229
VF Loss                      130.72073
Policy Loss                  -11.4011345
Q Predictions Mean           0.00764025
Q Predictions Std            0.011238864
Q Predictions Max            0.04310349
Q Predictions Min            -0.021389062
V Predictions Mean           0.0038442065
V Predictions Std            0.014050508
V Predictions Max            0.04862334
V Predictions Min            -0.03060108
Log Pis Mean                 -11.315548
Log Pis Std                  0.9056481
Log Pis Max                  -8.520826
Log Pis Min                  -13.320554
Policy mu Mean               0.0018080731
Policy mu Std                0.010425097
Policy mu Max                0.031899374
Policy mu Min                -0.032006025
Policy log std Mean          0.00021106945
Policy log std Std           0.01053859
Policy log std Max           0.03166568
Policy log std Min           -0.03848222
Z mean eval                  0.06853108
Z variance eval              0.06645299
total_rewards                [300.4675976  257.790033   270.98363495 236.65626187 227.05380714
 231.23973644 252.71536936 356.64839267 185.96261949 285.55899107]
total_rewards_mean           260.5076443587644
total_rewards_std            44.43746335918658
total_rewards_max            356.64839266778534
total_rewards_min            185.96261949305804
Number of train steps total  4000
Number of env steps total    4358
Number of rollouts total     0
Train Time (s)               606.2097322354093
(Previous) Eval Time (s)     0
Sample Time (s)              12.368887207470834
Epoch Time (s)               618.5786194428802
Total Train Time (s)         620.1729110521264
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:55:41.349556 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #0 | Epoch Duration: 620.1761212348938
2020-01-13 07:55:41.349743 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.068718895
Z variance train             0.067393266
KL Divergence                5.2058916
KL Loss                      0.5205892
QF Loss                      6777.198
VF Loss                      1792.6904
Policy Loss                  -601.4089
Q Predictions Mean           603.1009
Q Predictions Std            169.09335
Q Predictions Max            802.5871
Q Predictions Min            20.418232
V Predictions Mean           632.77515
V Predictions Std            134.73769
V Predictions Max            769.3812
V Predictions Min            92.24913
Log Pis Mean                 0.71483517
Log Pis Std                  6.145467
Log Pis Max                  26.469664
Log Pis Min                  -9.940231
Policy mu Mean               0.44704154
Policy mu Std                0.9233956
Policy mu Max                2.526168
Policy mu Min                -2.2364988
Policy log std Mean          -0.33716184
Policy log std Std           0.1432918
Policy log std Max           -0.05204345
Policy log std Min           -0.82434314
Z mean eval                  0.10080697
Z variance eval              0.058994792
total_rewards                [114.18752964 125.47376289 171.46146922 103.63078731 157.82041163
 121.95409716 126.71050532 118.95999833 117.63061637 135.24163164]
total_rewards_mean           129.30708094931867
total_rewards_std            19.57549259210832
total_rewards_max            171.46146921602096
total_rewards_min            103.63078730857983
Number of train steps total  8000
Number of env steps total    6687
Number of rollouts total     0
Train Time (s)               621.2773914118297
(Previous) Eval Time (s)     0.60490966681391
Sample Time (s)              6.418831641320139
Epoch Time (s)               628.3011327199638
Total Train Time (s)         1248.5964274378493
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:06:09.773069 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #1 | Epoch Duration: 628.4231917858124
2020-01-13 08:06:09.773210 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.102051176
Z variance train             0.05930243
KL Divergence                5.2827034
KL Loss                      0.52827036
QF Loss                      13018.764
VF Loss                      7437.596
Policy Loss                  -935.868
Q Predictions Mean           931.0088
Q Predictions Std            378.8415
Q Predictions Max            1359.8055
Q Predictions Min            -6.659147
V Predictions Mean           986.6991
V Predictions Std            351.13986
V Predictions Max            1350.7948
V Predictions Min            14.575318
Log Pis Mean                 4.4488077
Log Pis Std                  8.438391
Log Pis Max                  35.271084
Log Pis Min                  -10.270897
Policy mu Mean               0.09873951
Policy mu Std                1.1868559
Policy mu Max                2.9305441
Policy mu Min                -2.7609706
Policy log std Mean          -0.39786327
Policy log std Std           0.15558182
Policy log std Max           -0.014882941
Policy log std Min           -0.9568889
Z mean eval                  0.06126678
Z variance eval              0.025563437
total_rewards                [259.54510548 183.80486826 201.28239908 200.86372364 236.93961822
 184.11252463 233.91623847 296.77038714 259.36011262 218.30325634]
total_rewards_mean           227.48982338686042
total_rewards_std            34.99112321223254
total_rewards_max            296.77038714198045
total_rewards_min            183.80486825672162
Number of train steps total  12000
Number of env steps total    8998
Number of rollouts total     0
Train Time (s)               619.3642974817194
(Previous) Eval Time (s)     1.341297369915992
Sample Time (s)              5.351354390848428
Epoch Time (s)               626.0569492424838
Total Train Time (s)         1874.7608123244718
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:16:35.938327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #2 | Epoch Duration: 626.1650166511536
2020-01-13 08:16:35.938466 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06493211
Z variance train             0.025519526
KL Divergence                7.3594866
KL Loss                      0.7359487
QF Loss                      58942.56
VF Loss                      15497.958
Policy Loss                  -1345.8572
Q Predictions Mean           1327.2117
Q Predictions Std            658.3403
Q Predictions Max            2074.3
Q Predictions Min            -21.098286
V Predictions Mean           1416.7246
V Predictions Std            642.6211
V Predictions Max            2211.509
V Predictions Min            33.298172
Log Pis Mean                 9.309435
Log Pis Std                  8.313051
Log Pis Max                  37.723755
Log Pis Min                  -12.419032
Policy mu Mean               0.40324426
Policy mu Std                1.2953775
Policy mu Max                3.0070953
Policy mu Min                -2.8816504
Policy log std Mean          -0.46636087
Policy log std Std           0.13018054
Policy log std Max           0.00043188035
Policy log std Min           -0.94616085
Z mean eval                  0.021212643
Z variance eval              0.1529579
total_rewards                [221.52511497 175.9044675  170.05536944 220.56471166 198.50536733
 189.09909771 232.25977924  76.43009398 326.99286915 187.29509795]
total_rewards_mean           199.86319689377007
total_rewards_std            59.23107997727441
total_rewards_max            326.9928691481779
total_rewards_min            76.43009398295604
Number of train steps total  16000
Number of env steps total    11345
Number of rollouts total     0
Train Time (s)               615.2338705831207
(Previous) Eval Time (s)     0.8878098907880485
Sample Time (s)              6.087246513925493
Epoch Time (s)               622.2089269878343
Total Train Time (s)         2497.0803658282384
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:26:58.259314 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #3 | Epoch Duration: 622.3207318782806
2020-01-13 08:26:58.259518 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021797288
Z variance train             0.1520433
KL Divergence                5.32824
KL Loss                      0.532824
QF Loss                      20974.734
VF Loss                      5795.7974
Policy Loss                  -1738.1931
Q Predictions Mean           1669.3455
Q Predictions Std            687.96246
Q Predictions Max            2601.8213
Q Predictions Min            8.84386
V Predictions Mean           1740.4476
V Predictions Std            643.1283
V Predictions Max            2505.2793
V Predictions Min            70.30013
Log Pis Mean                 9.967209
Log Pis Std                  10.781316
Log Pis Max                  47.371613
Log Pis Min                  -10.9389105
Policy mu Mean               0.38502744
Policy mu Std                1.3399967
Policy mu Max                3.3200307
Policy mu Min                -3.3523917
Policy log std Mean          -0.4645298
Policy log std Std           0.14009488
Policy log std Max           -0.02723467
Policy log std Min           -0.9718349
Z mean eval                  0.026663596
Z variance eval              0.03833467
total_rewards                [314.85892437 237.41393003 257.28374416 193.34702943 297.54286261
 369.55725462 267.64377322 309.05825765 233.45200818 272.00546536]
total_rewards_mean           275.21632496234304
total_rewards_std            47.30812696549875
total_rewards_max            369.5572546165351
total_rewards_min            193.34702943326081
Number of train steps total  20000
Number of env steps total    13603
Number of rollouts total     0
Train Time (s)               617.9801468239166
(Previous) Eval Time (s)     1.3422230896539986
Sample Time (s)              5.910424160305411
Epoch Time (s)               625.232794073876
Total Train Time (s)         3122.651546710171
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:37:23.831763 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #4 | Epoch Duration: 625.5720875263214
2020-01-13 08:37:23.831941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02767297
Z variance train             0.03849287
KL Divergence                5.990398
KL Loss                      0.5990398
QF Loss                      39249.76
VF Loss                      9138.6875
Policy Loss                  -1814.7124
Q Predictions Mean           1767.6455
Q Predictions Std            870.2788
Q Predictions Max            2912.692
Q Predictions Min            -26.974016
V Predictions Mean           1848.7086
V Predictions Std            837.70776
V Predictions Max            2808.0083
V Predictions Min            33.13639
Log Pis Mean                 12.9037895
Log Pis Std                  9.802577
Log Pis Max                  60.444176
Log Pis Min                  -10.142849
Policy mu Mean               0.24262844
Policy mu Std                1.4718003
Policy mu Max                4.376961
Policy mu Min                -3.4178994
Policy log std Mean          -0.4886926
Policy log std Std           0.1296628
Policy log std Max           -0.049118176
Policy log std Min           -1.023069
Z mean eval                  0.027715033
Z variance eval              0.13027146
total_rewards                [186.30042065 295.20523914 205.18211443 191.50377249 246.64898999
 245.09564436 299.35185474 233.62132586 263.25545701 227.59786978]
total_rewards_mean           239.3762688451402
total_rewards_std            37.17482481920771
total_rewards_max            299.3518547423652
total_rewards_min            186.30042064893416
Number of train steps total  24000
Number of env steps total    15944
Number of rollouts total     0
Train Time (s)               619.455240979325
(Previous) Eval Time (s)     1.3085952731780708
Sample Time (s)              6.460244078189135
Epoch Time (s)               627.2240803306922
Total Train Time (s)         3749.984698449727
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:47:51.166593 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #5 | Epoch Duration: 627.3345062732697
2020-01-13 08:47:51.166845 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028138716
Z variance train             0.12983575
KL Divergence                4.712037
KL Loss                      0.4712037
QF Loss                      29905.0
VF Loss                      6967.1445
Policy Loss                  -1936.4899
Q Predictions Mean           1897.7264
Q Predictions Std            855.9949
Q Predictions Max            3003.773
Q Predictions Min            46.52227
V Predictions Mean           1935.6002
V Predictions Std            826.5133
V Predictions Max            2994.6328
V Predictions Min            54.80488
Log Pis Mean                 9.883849
Log Pis Std                  10.906933
Log Pis Max                  47.076954
Log Pis Min                  -11.918604
Policy mu Mean               0.2899508
Policy mu Std                1.3494184
Policy mu Max                3.4780276
Policy mu Min                -3.6446702
Policy log std Mean          -0.45804015
Policy log std Std           0.13475382
Policy log std Max           -0.053323314
Policy log std Min           -0.9933896
Z mean eval                  0.11898961
Z variance eval              0.06472856
total_rewards                [190.04223599 195.46294958 132.45811933 183.14978    178.99626263
 219.99356648 173.24807781 141.79084341 186.35684932 189.73348795]
total_rewards_mean           179.12321724871262
total_rewards_std            24.17350747264556
total_rewards_max            219.9935664767187
total_rewards_min            132.45811932722103
Number of train steps total  28000
Number of env steps total    18385
Number of rollouts total     0
Train Time (s)               584.0295012309216
(Previous) Eval Time (s)     0.9014598377980292
Sample Time (s)              6.550785182509571
Epoch Time (s)               591.4817462512292
Total Train Time (s)         4341.5734233204275
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:57:42.754589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #6 | Epoch Duration: 591.5875728130341
2020-01-13 08:57:42.754737 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1209057
Z variance train             0.06514456
KL Divergence                6.7213116
KL Loss                      0.6721312
QF Loss                      52433.156
VF Loss                      4968.0566
Policy Loss                  -1646.8671
Q Predictions Mean           1616.579
Q Predictions Std            925.62695
Q Predictions Max            2723.943
Q Predictions Min            16.300262
V Predictions Mean           1667.1323
V Predictions Std            908.6433
V Predictions Max            2675.953
V Predictions Min            69.267
Log Pis Mean                 7.768812
Log Pis Std                  9.962883
Log Pis Max                  59.01145
Log Pis Min                  -10.656872
Policy mu Mean               0.20253089
Policy mu Std                1.3078691
Policy mu Max                6.7968607
Policy mu Min                -3.3347385
Policy log std Mean          -0.45481008
Policy log std Std           0.1432427
Policy log std Max           -0.04015836
Policy log std Min           -1.177388
Z mean eval                  0.17316036
Z variance eval              0.056867123
total_rewards                [206.28011519 226.55447022 232.5201941  228.94003954 197.16059508
 203.68498887 198.49333714 258.66326076 205.91305518 211.32775282]
total_rewards_mean           216.9537808896307
total_rewards_std            18.422631595867614
total_rewards_max            258.663260764035
total_rewards_min            197.16059507673208
Number of train steps total  32000
Number of env steps total    20706
Number of rollouts total     0
Train Time (s)               617.5781462988816
(Previous) Eval Time (s)     1.016481134109199
Sample Time (s)              6.123846739530563
Epoch Time (s)               624.7184741725214
Total Train Time (s)         4966.407778648194
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:08:07.589417 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #7 | Epoch Duration: 624.8345828056335
2020-01-13 09:08:07.589563 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17249987
Z variance train             0.0565616
KL Divergence                6.345482
KL Loss                      0.6345482
QF Loss                      10694.803
VF Loss                      6274.543
Policy Loss                  -1375.7006
Q Predictions Mean           1341.3367
Q Predictions Std            923.3774
Q Predictions Max            2774.493
Q Predictions Min            9.332965
V Predictions Mean           1390.8391
V Predictions Std            917.5956
V Predictions Max            2779.2986
V Predictions Min            12.72995
Log Pis Mean                 8.320689
Log Pis Std                  10.603148
Log Pis Max                  45.699726
Log Pis Min                  -16.686047
Policy mu Mean               0.4255521
Policy mu Std                1.2598251
Policy mu Max                3.8824682
Policy mu Min                -3.5324078
Policy log std Mean          -0.4509218
Policy log std Std           0.15203983
Policy log std Max           0.09161362
Policy log std Min           -1.0150139
Z mean eval                  0.060551323
Z variance eval              0.066377476
total_rewards                [161.69709352 156.46381172 204.64885998 168.88962316 167.65850778
  86.76230851 122.04247697 161.94981767 127.83172205 187.60225178]
total_rewards_mean           154.55464731317372
total_rewards_std            32.33431944891896
total_rewards_max            204.64885997921007
total_rewards_min            86.7623085116848
Number of train steps total  36000
Number of env steps total    23047
Number of rollouts total     0
Train Time (s)               621.396258554887
(Previous) Eval Time (s)     0.7619316130876541
Sample Time (s)              5.966347928158939
Epoch Time (s)               628.1245380961336
Total Train Time (s)         5594.802220939659
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:18:35.985778 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #8 | Epoch Duration: 628.3961007595062
2020-01-13 09:18:35.985959 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060336787
Z variance train             0.06687559
KL Divergence                6.184512
KL Loss                      0.61845124
QF Loss                      11169.865
VF Loss                      5349.2803
Policy Loss                  -1408.4935
Q Predictions Mean           1354.8009
Q Predictions Std            847.45044
Q Predictions Max            2677.9392
Q Predictions Min            68.17694
V Predictions Mean           1418.9104
V Predictions Std            854.2164
V Predictions Max            2720.4727
V Predictions Min            56.06941
Log Pis Mean                 10.170301
Log Pis Std                  10.93205
Log Pis Max                  46.794537
Log Pis Min                  -10.229253
Policy mu Mean               0.348507
Policy mu Std                1.335248
Policy mu Max                3.8288553
Policy mu Min                -3.6572106
Policy log std Mean          -0.45956635
Policy log std Std           0.15415768
Policy log std Max           0.056491986
Policy log std Min           -0.9972673
Z mean eval                  0.032951258
Z variance eval              0.06757961
total_rewards                [324.27957226 307.30226223 307.66744194 289.52332976 353.50882798
 283.69995831 319.02629185 311.91148328 428.37312342 246.14641019]
total_rewards_mean           317.1438701225581
total_rewards_std            45.6999839363902
total_rewards_max            428.37312341576126
total_rewards_min            246.14641019022397
Number of train steps total  40000
Number of env steps total    25356
Number of rollouts total     0
Train Time (s)               612.2805794770829
(Previous) Eval Time (s)     1.5034568873234093
Sample Time (s)              6.281712712254375
Epoch Time (s)               620.0657490766607
Total Train Time (s)         6214.972882105503
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:28:56.156574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #9 | Epoch Duration: 620.1704912185669
2020-01-13 09:28:56.156700 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #9 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032407414
Z variance train             0.06766488
KL Divergence                6.4773817
KL Loss                      0.64773816
QF Loss                      8557.959
VF Loss                      3624.6812
Policy Loss                  -1305.0465
Q Predictions Mean           1260.3103
Q Predictions Std            821.33417
Q Predictions Max            2837.478
Q Predictions Min            -61.89819
V Predictions Mean           1300.977
V Predictions Std            817.7476
V Predictions Max            2701.2356
V Predictions Min            61.454216
Log Pis Mean                 7.0536804
Log Pis Std                  9.512706
Log Pis Max                  43.67151
Log Pis Min                  -12.779663
Policy mu Mean               0.42505425
Policy mu Std                1.2079523
Policy mu Max                3.2710211
Policy mu Min                -4.441779
Policy log std Mean          -0.4217537
Policy log std Std           0.14563207
Policy log std Max           0.10602696
Policy log std Min           -1.0630231
Z mean eval                  0.056189917
Z variance eval              0.19453037
total_rewards                [196.22890586 252.93652706 188.71756074 276.03850116 209.7050575
 196.64648767 262.14460906 222.43988646 363.89701727 469.2435939 ]
total_rewards_mean           263.79981466787467
total_rewards_std            84.76246862717096
total_rewards_max            469.24359390148993
total_rewards_min            188.71756074479177
Number of train steps total  44000
Number of env steps total    27647
Number of rollouts total     0
Train Time (s)               618.8572295266204
(Previous) Eval Time (s)     1.3120173537172377
Sample Time (s)              5.344771404750645
Epoch Time (s)               625.5140182850882
Total Train Time (s)         6840.594247744419
Epoch                        10
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:39:21.779420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #10 | Epoch Duration: 625.6226122379303
2020-01-13 09:39:21.779597 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05661316
Z variance train             0.19331387
KL Divergence                5.329618
KL Loss                      0.5329618
QF Loss                      11855.51
VF Loss                      8560.756
Policy Loss                  -1180.7913
Q Predictions Mean           1160.2617
Q Predictions Std            753.1248
Q Predictions Max            2472.4097
Q Predictions Min            -23.571358
V Predictions Mean           1191.6394
V Predictions Std            758.8483
V Predictions Max            2477.5962
V Predictions Min            34.09246
Log Pis Mean                 6.6047883
Log Pis Std                  9.836729
Log Pis Max                  47.457035
Log Pis Min                  -12.467882
Policy mu Mean               0.23817736
Policy mu Std                1.2511116
Policy mu Max                3.818815
Policy mu Min                -3.5362554
Policy log std Mean          -0.42671636
Policy log std Std           0.14698945
Policy log std Max           0.06936492
Policy log std Min           -0.98039716
Z mean eval                  0.054499447
Z variance eval              0.05580773
total_rewards                [291.38811452 407.07610509 240.88021426 449.99448765 336.49681387
 366.39087859 385.1314432  335.70792929 380.68568096 345.65179676]
total_rewards_mean           353.9403464192836
total_rewards_std            55.94085555604307
total_rewards_max            449.9944876514992
total_rewards_min            240.8802142597599
Number of train steps total  48000
Number of env steps total    30018
Number of rollouts total     0
Train Time (s)               620.0605390421115
(Previous) Eval Time (s)     1.872207717038691
Sample Time (s)              6.219058820977807
Epoch Time (s)               628.151805580128
Total Train Time (s)         7468.866510207299
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:49:50.051727 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #11 | Epoch Duration: 628.2719957828522
2020-01-13 09:49:50.051874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05481906
Z variance train             0.05573485
KL Divergence                6.559971
KL Loss                      0.6559971
QF Loss                      5064.875
VF Loss                      2579.0376
Policy Loss                  -1033.8569
Q Predictions Mean           996.5437
Q Predictions Std            701.0634
Q Predictions Max            2507.3306
Q Predictions Min            -3.1998892
V Predictions Mean           1040.162
V Predictions Std            705.7361
V Predictions Max            2486.7727
V Predictions Min            18.807013
Log Pis Mean                 4.8319154
Log Pis Std                  9.709708
Log Pis Max                  47.470924
Log Pis Min                  -12.874664
Policy mu Mean               0.29224548
Policy mu Std                1.1747607
Policy mu Max                3.4727561
Policy mu Min                -3.687754
Policy log std Mean          -0.4092916
Policy log std Std           0.14793107
Policy log std Max           0.08522509
Policy log std Min           -0.9837956
Z mean eval                  0.033894077
Z variance eval              0.06371639
total_rewards                [427.13050736 423.38508121 612.55584848 307.97190452 318.91233558
 338.8013231  353.46972649 348.52110765 278.11165278 338.57643757]
total_rewards_mean           374.7435924761023
total_rewards_std            90.72953081526688
total_rewards_max            612.5558484845305
total_rewards_min            278.1116527810985
Number of train steps total  52000
Number of env steps total    32434
Number of rollouts total     0
Train Time (s)               620.1797642619349
(Previous) Eval Time (s)     1.923002720810473
Sample Time (s)              6.20877300016582
Epoch Time (s)               628.3115399829112
Total Train Time (s)         8097.300282844808
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:00:18.486411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #12 | Epoch Duration: 628.4344372749329
2020-01-13 10:00:18.486550 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033332583
Z variance train             0.06389205
KL Divergence                5.4138527
KL Loss                      0.5413853
QF Loss                      4530.2964
VF Loss                      2940.1514
Policy Loss                  -967.0379
Q Predictions Mean           931.0617
Q Predictions Std            606.87
Q Predictions Max            1989.1193
Q Predictions Min            10.619
V Predictions Mean           948.9748
V Predictions Std            608.2521
V Predictions Max            1934.6116
V Predictions Min            7.607077
Log Pis Mean                 3.078371
Log Pis Std                  8.763756
Log Pis Max                  42.022217
Log Pis Min                  -14.538452
Policy mu Mean               0.26435548
Policy mu Std                1.0812613
Policy mu Max                3.561141
Policy mu Min                -3.680192
Policy log std Mean          -0.3788092
Policy log std Std           0.14396068
Policy log std Max           0.030031428
Policy log std Min           -0.9546957
Z mean eval                  0.010777338
Z variance eval              0.16889435
total_rewards                [242.50314856 259.38979379 220.58021955 355.57982211 305.95509276
 235.14681228 265.3737716  264.24984348 252.83194509 243.96838517]
total_rewards_mean           264.5578834372621
total_rewards_std            37.24657621862289
total_rewards_max            355.5798221147917
total_rewards_min            220.58021955184998
Number of train steps total  56000
Number of env steps total    34794
Number of rollouts total     0
Train Time (s)               615.7129907677881
(Previous) Eval Time (s)     1.5153833250515163
Sample Time (s)              6.548197476193309
Epoch Time (s)               623.776571569033
Total Train Time (s)         8721.381994694937
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:10:42.568984 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #13 | Epoch Duration: 624.0823030471802
2020-01-13 10:10:42.569119 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008941521
Z variance train             0.1698822
KL Divergence                3.6321898
KL Loss                      0.363219
QF Loss                      15527.259
VF Loss                      5002.762
Policy Loss                  -912.5708
Q Predictions Mean           887.77795
Q Predictions Std            509.1785
Q Predictions Max            1688.4668
Q Predictions Min            1.2384433
V Predictions Mean           927.02515
V Predictions Std            500.28857
V Predictions Max            1832.3231
V Predictions Min            10.503605
Log Pis Mean                 2.413116
Log Pis Std                  9.310196
Log Pis Max                  41.967873
Log Pis Min                  -16.636398
Policy mu Mean               0.2875795
Policy mu Std                1.0779662
Policy mu Max                4.2069
Policy mu Min                -3.5824509
Policy log std Mean          -0.38639307
Policy log std Std           0.14380433
Policy log std Max           0.039361924
Policy log std Min           -1.0131205
Z mean eval                  0.030892273
Z variance eval              0.0975278
total_rewards                [383.82102647 342.90040891 304.81269884 381.67489628 554.21877349
 253.15126732 294.97472568 373.99629702 349.25926541 393.26734038]
total_rewards_mean           363.207669979742
total_rewards_std            76.84805188558542
total_rewards_max            554.2187734877473
total_rewards_min            253.15126731529975
Number of train steps total  60000
Number of env steps total    37132
Number of rollouts total     0
Train Time (s)               618.4731858312152
(Previous) Eval Time (s)     1.7222810699604452
Sample Time (s)              6.210482593625784
Epoch Time (s)               626.4059494948015
Total Train Time (s)         9347.907741439994
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:21:09.096191 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #14 | Epoch Duration: 626.5269651412964
2020-01-13 10:21:09.096364 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029462436
Z variance train             0.09739886
KL Divergence                4.119316
KL Loss                      0.4119316
QF Loss                      3685.9697
VF Loss                      1377.1599
Policy Loss                  -853.8672
Q Predictions Mean           838.3723
Q Predictions Std            455.32877
Q Predictions Max            1666.1711
Q Predictions Min            27.55964
V Predictions Mean           856.83594
V Predictions Std            459.05447
V Predictions Max            1603.5948
V Predictions Min            32.51732
Log Pis Mean                 1.6620548
Log Pis Std                  7.7078204
Log Pis Max                  32.77373
Log Pis Min                  -13.13362
Policy mu Mean               0.4035405
Policy mu Std                1.0009712
Policy mu Max                3.4183106
Policy mu Min                -3.09776
Policy log std Mean          -0.38000622
Policy log std Std           0.1276395
Policy log std Max           -0.027733997
Policy log std Min           -1.0426953
Z mean eval                  0.04492682
Z variance eval              0.06851921
total_rewards                [249.07871886 301.84578341 381.84800081 284.79411333 318.53139962
 584.1512816  435.99232767 214.75655345 369.30484061 210.23452427]
total_rewards_mean           335.05375436182214
total_rewards_std            108.14146503776479
total_rewards_max            584.1512816032645
total_rewards_min            210.23452426826296
Number of train steps total  64000
Number of env steps total    39629
Number of rollouts total     0
Train Time (s)               611.6057959948666
(Previous) Eval Time (s)     1.7835876317694783
Sample Time (s)              7.052610348910093
Epoch Time (s)               620.4419939755462
Total Train Time (s)         9968.45341799967
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:31:29.642144 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #15 | Epoch Duration: 620.5456595420837
2020-01-13 10:31:29.642283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045401625
Z variance train             0.068848506
KL Divergence                5.125695
KL Loss                      0.51256955
QF Loss                      3980.7
VF Loss                      1038.4625
Policy Loss                  -853.7392
Q Predictions Mean           841.3761
Q Predictions Std            415.49136
Q Predictions Max            1391.4944
Q Predictions Min            13.481223
V Predictions Mean           859.87415
V Predictions Std            408.09122
V Predictions Max            1377.8715
V Predictions Min            24.771786
Log Pis Mean                 -0.65506625
Log Pis Std                  7.2247953
Log Pis Max                  31.819893
Log Pis Min                  -14.7767515
Policy mu Mean               0.2646987
Policy mu Std                0.94748163
Policy mu Max                2.9161146
Policy mu Min                -2.9556494
Policy log std Mean          -0.33925033
Policy log std Std           0.119088665
Policy log std Max           0.01744318
Policy log std Min           -0.9089734
Z mean eval                  0.02926143
Z variance eval              0.04325978
total_rewards                [299.54810356 365.81775039 426.78332046 367.07637527 308.26767197
 394.74262769 528.95156226 371.65184196 362.04440082 280.70028723]
total_rewards_mean           370.5583941614937
total_rewards_std            67.77895830043467
total_rewards_max            528.9515622635404
total_rewards_min            280.7002872266004
Number of train steps total  68000
Number of env steps total    42066
Number of rollouts total     0
Train Time (s)               609.6534370970912
(Previous) Eval Time (s)     1.7253268077038229
Sample Time (s)              6.4752484848722816
Epoch Time (s)               617.8540123896673
Total Train Time (s)         10586.404594317544
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:41:47.594023 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #16 | Epoch Duration: 617.9516425132751
2020-01-13 10:41:47.594159 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030014148
Z variance train             0.043344777
KL Divergence                5.89343
KL Loss                      0.589343
QF Loss                      3678.4966
VF Loss                      1301.9327
Policy Loss                  -801.92
Q Predictions Mean           784.9763
Q Predictions Std            397.9849
Q Predictions Max            1343.7847
Q Predictions Min            56.0845
V Predictions Mean           809.6121
V Predictions Std            393.48245
V Predictions Max            1352.0197
V Predictions Min            69.921776
Log Pis Mean                 -0.7260581
Log Pis Std                  7.09322
Log Pis Max                  31.664663
Log Pis Min                  -16.4595
Policy mu Mean               0.2880924
Policy mu Std                0.9284168
Policy mu Max                2.94774
Policy mu Min                -3.3786511
Policy log std Mean          -0.33781528
Policy log std Std           0.12888488
Policy log std Max           -0.046652652
Policy log std Min           -0.9360233
Z mean eval                  0.019284582
Z variance eval              0.114475295
total_rewards                [269.76165738 448.20828126 454.88339664 389.06500868 396.94077679
 333.8365008  367.98535475 335.97540554 293.08672705 310.87010322]
total_rewards_mean           360.0613212107013
total_rewards_std            59.45795574387775
total_rewards_max            454.8833966397536
total_rewards_min            269.7616573772618
Number of train steps total  72000
Number of env steps total    44503
Number of rollouts total     0
Train Time (s)               609.8853801796213
(Previous) Eval Time (s)     1.690373548772186
Sample Time (s)              5.876716621685773
Epoch Time (s)               617.4524703500792
Total Train Time (s)         11203.963494356256
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:52:05.153547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #17 | Epoch Duration: 617.5592904090881
2020-01-13 10:52:05.153684 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01884113
Z variance train             0.11447022
KL Divergence                4.819152
KL Loss                      0.4819152
QF Loss                      1706.7675
VF Loss                      859.30975
Policy Loss                  -785.56433
Q Predictions Mean           766.868
Q Predictions Std            404.27884
Q Predictions Max            1315.4604
Q Predictions Min            0.63584054
V Predictions Mean           775.4791
V Predictions Std            397.74152
V Predictions Max            1317.0824
V Predictions Min            39.621193
Log Pis Mean                 -1.2021241
Log Pis Std                  6.198236
Log Pis Max                  30.08073
Log Pis Min                  -11.653976
Policy mu Mean               0.3104961
Policy mu Std                0.8851932
Policy mu Max                3.112736
Policy mu Min                -2.9523327
Policy log std Mean          -0.3243126
Policy log std Std           0.11800627
Policy log std Max           -0.040773734
Policy log std Min           -0.89751434
Z mean eval                  0.02086604
Z variance eval              0.1116446
total_rewards                [309.4948116  478.61143575 497.98924595 459.90183392 387.67078359
 287.62511217 318.70867006 458.99390787 412.56598514 374.41771087]
total_rewards_mean           398.5979496925855
total_rewards_std            71.56986482945501
total_rewards_max            497.9892459496171
total_rewards_min            287.62511217078617
Number of train steps total  76000
Number of env steps total    46913
Number of rollouts total     0
Train Time (s)               605.0408186009154
(Previous) Eval Time (s)     1.9868756011128426
Sample Time (s)              6.551526281051338
Epoch Time (s)               613.5792204830796
Total Train Time (s)         11817.645128930453
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:02:18.836178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #18 | Epoch Duration: 613.6823813915253
2020-01-13 11:02:18.836312 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021943254
Z variance train             0.11130246
KL Divergence                4.1444
KL Loss                      0.41444
QF Loss                      1259.9016
VF Loss                      736.43945
Policy Loss                  -788.0246
Q Predictions Mean           773.9684
Q Predictions Std            399.75513
Q Predictions Max            1335.4652
Q Predictions Min            11.557592
V Predictions Mean           775.5751
V Predictions Std            398.76968
V Predictions Max            1331.7654
V Predictions Min            49.70333
Log Pis Mean                 -1.4725137
Log Pis Std                  6.5780625
Log Pis Max                  22.119844
Log Pis Min                  -15.345551
Policy mu Mean               0.2935252
Policy mu Std                0.89373255
Policy mu Max                2.7509274
Policy mu Min                -2.8177714
Policy log std Mean          -0.33053124
Policy log std Std           0.119649425
Policy log std Max           -0.056657784
Policy log std Min           -0.8468338
Z mean eval                  0.017091123
Z variance eval              0.13143946
total_rewards                [509.15168066 549.30362634 600.84002348 411.55831374 454.28878945
 439.65868181 472.40304079 448.31336773 557.57560347 445.29004242]
total_rewards_mean           488.8383169880482
total_rewards_std            58.93320837589466
total_rewards_max            600.8400234786819
total_rewards_min            411.5583137362613
Number of train steps total  80000
Number of env steps total    49400
Number of rollouts total     0
Train Time (s)               605.5517834899947
(Previous) Eval Time (s)     2.531769667286426
Sample Time (s)              6.764254912734032
Epoch Time (s)               614.8478080700152
Total Train Time (s)         12432.595210982021
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:12:33.786773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #19 | Epoch Duration: 614.9503643512726
2020-01-13 11:12:33.786907 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017399441
Z variance train             0.13100716
KL Divergence                3.9804883
KL Loss                      0.39804885
QF Loss                      1312.365
VF Loss                      565.85815
Policy Loss                  -749.9998
Q Predictions Mean           736.3123
Q Predictions Std            403.18985
Q Predictions Max            1342.3492
Q Predictions Min            -0.83727586
V Predictions Mean           751.26196
V Predictions Std            400.7347
V Predictions Max            1339.4352
V Predictions Min            -1.3809786
Log Pis Mean                 -2.0198967
Log Pis Std                  7.314555
Log Pis Max                  32.39582
Log Pis Min                  -13.283704
Policy mu Mean               0.2425232
Policy mu Std                0.8829452
Policy mu Max                2.8670433
Policy mu Min                -2.6865842
Policy log std Mean          -0.31757757
Policy log std Std           0.12041418
Policy log std Max           -0.0098653585
Policy log std Min           -1.0059648
Z mean eval                  0.035507705
Z variance eval              0.044178743
total_rewards                [359.18406121 395.74708417 354.03942334 399.32316793 430.73863611
 652.603158   500.73522971 452.17451011 390.69199933 390.12987823]
total_rewards_mean           432.53671481404444
total_rewards_std            84.27189693154476
total_rewards_max            652.6031580032809
total_rewards_min            354.03942334384686
Number of train steps total  84000
Number of env steps total    52228
Number of rollouts total     0
Train Time (s)               608.5965428240597
(Previous) Eval Time (s)     2.291784966364503
Sample Time (s)              11.465284641366452
Epoch Time (s)               622.3536124317907
Total Train Time (s)         13055.066663160454
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:22:56.259053 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #20 | Epoch Duration: 622.4720492362976
2020-01-13 11:22:56.259181 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03732509
Z variance train             0.04413726
KL Divergence                5.5811768
KL Loss                      0.5581177
QF Loss                      2523.0344
VF Loss                      1172.2198
Policy Loss                  -810.9617
Q Predictions Mean           783.75494
Q Predictions Std            433.42188
Q Predictions Max            1363.4594
Q Predictions Min            -61.115677
V Predictions Mean           810.1228
V Predictions Std            429.70837
V Predictions Max            1375.6624
V Predictions Min            -1.1654041
Log Pis Mean                 -1.6753621
Log Pis Std                  6.435284
Log Pis Max                  24.595543
Log Pis Min                  -12.277819
Policy mu Mean               0.19942604
Policy mu Std                0.9090934
Policy mu Max                3.8105614
Policy mu Min                -3.7129443
Policy log std Mean          -0.32829157
Policy log std Std           0.12038885
Policy log std Max           0.0042862594
Policy log std Min           -0.867207
Z mean eval                  0.030763399
Z variance eval              0.08460708
total_rewards                [563.22859625 388.09209782 438.25394601 317.87838869 400.10474211
 510.91171731 328.74431041 431.19139982 602.10972358 377.51792721]
total_rewards_mean           435.80328492195497
total_rewards_std            90.48725035923167
total_rewards_max            602.1097235751301
total_rewards_min            317.8783886935403
Number of train steps total  88000
Number of env steps total    55088
Number of rollouts total     0
Train Time (s)               600.618961807806
(Previous) Eval Time (s)     2.2408209280110896
Sample Time (s)              7.16003959113732
Epoch Time (s)               610.0198223269545
Total Train Time (s)         13665.187823066022
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:33:06.380771 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #21 | Epoch Duration: 610.1214964389801
2020-01-13 11:33:06.380905 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03245915
Z variance train             0.08523266
KL Divergence                4.9619026
KL Loss                      0.49619028
QF Loss                      1554.9082
VF Loss                      732.9863
Policy Loss                  -797.17834
Q Predictions Mean           781.46814
Q Predictions Std            415.95972
Q Predictions Max            1370.1582
Q Predictions Min            36.568195
V Predictions Mean           784.6194
V Predictions Std            420.53534
V Predictions Max            1376.792
V Predictions Min            8.545077
Log Pis Mean                 -1.4523785
Log Pis Std                  5.4408536
Log Pis Max                  26.968199
Log Pis Min                  -15.039082
Policy mu Mean               0.30057648
Policy mu Std                0.8649148
Policy mu Max                2.9174578
Policy mu Min                -2.6070676
Policy log std Mean          -0.33433595
Policy log std Std           0.116920285
Policy log std Max           -0.062478364
Policy log std Min           -0.8232209
Z mean eval                  0.030337611
Z variance eval              0.101013005
total_rewards                [441.09486182 446.09074616 403.33593248 482.24551871 422.00795642
 417.06243772 387.56233435 373.98933618 371.68074064 418.00658764]
total_rewards_mean           416.3076452144064
total_rewards_std            32.652948036483416
total_rewards_max            482.2455187144768
total_rewards_min            371.680740643328
Number of train steps total  92000
Number of env steps total    57954
Number of rollouts total     0
Train Time (s)               607.0199704961851
(Previous) Eval Time (s)     2.1607807306572795
Sample Time (s)              7.254433034919202
Epoch Time (s)               616.4351842617616
Total Train Time (s)         14281.732058817055
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:43:22.925790 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #22 | Epoch Duration: 616.5447890758514
2020-01-13 11:43:22.925930 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030841947
Z variance train             0.10133548
KL Divergence                4.6069703
KL Loss                      0.46069703
QF Loss                      1278.0786
VF Loss                      669.827
Policy Loss                  -784.04266
Q Predictions Mean           779.04517
Q Predictions Std            416.05978
Q Predictions Max            1391.7638
Q Predictions Min            17.408361
V Predictions Mean           778.20074
V Predictions Std            408.82877
V Predictions Max            1386.6552
V Predictions Min            11.697655
Log Pis Mean                 -2.3892436
Log Pis Std                  5.329727
Log Pis Max                  17.55904
Log Pis Min                  -14.954213
Policy mu Mean               0.26839694
Policy mu Std                0.84977144
Policy mu Max                2.905533
Policy mu Min                -2.4649675
Policy log std Mean          -0.3232534
Policy log std Std           0.1089467
Policy log std Max           0.008204788
Policy log std Min           -0.9332549
Z mean eval                  0.0477522
Z variance eval              0.110343
total_rewards                [431.00856827 547.33017223 358.26598247 353.6481415  293.01259677
 391.93671578 552.21142474 567.07759078 403.84937458 387.09438072]
total_rewards_mean           428.5434947842865
total_rewards_std            90.10358254763727
total_rewards_max            567.0775907847651
total_rewards_min            293.01259676591064
Number of train steps total  96000
Number of env steps total    60785
Number of rollouts total     0
Train Time (s)               609.236483943183
(Previous) Eval Time (s)     2.141372077167034
Sample Time (s)              6.677159772254527
Epoch Time (s)               618.0550157926045
Total Train Time (s)         14899.90920251282
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:53:41.103740 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #23 | Epoch Duration: 618.1777126789093
2020-01-13 11:53:41.103870 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048544105
Z variance train             0.11061786
KL Divergence                3.904406
KL Loss                      0.3904406
QF Loss                      1912.5381
VF Loss                      824.75104
Policy Loss                  -829.2701
Q Predictions Mean           811.35144
Q Predictions Std            418.4545
Q Predictions Max            1384.928
Q Predictions Min            17.805546
V Predictions Mean           826.61365
V Predictions Std            416.46576
V Predictions Max            1393.829
V Predictions Min            56.828606
Log Pis Mean                 -2.1269832
Log Pis Std                  5.6519737
Log Pis Max                  27.851414
Log Pis Min                  -13.196211
Policy mu Mean               0.26555544
Policy mu Std                0.8575209
Policy mu Max                3.015927
Policy mu Min                -3.0840886
Policy log std Mean          -0.32414022
Policy log std Std           0.1160506
Policy log std Max           0.025746971
Policy log std Min           -0.87429833
Z mean eval                  0.04118206
Z variance eval              0.051545672
total_rewards                [671.51083011 529.9348452  714.64301846 491.80144665 534.44384028
 486.87173765 383.55614332 437.87220261 252.78543235 417.38921498]
total_rewards_mean           492.0808711619776
total_rewards_std            127.49161700522491
total_rewards_max            714.643018455515
total_rewards_min            252.78543235486515
Number of train steps total  100000
Number of env steps total    63677
Number of rollouts total     0
Train Time (s)               612.1987726059742
(Previous) Eval Time (s)     2.5179346930235624
Sample Time (s)              6.949718456249684
Epoch Time (s)               621.6664257552475
Total Train Time (s)         15521.685531751718
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:04:02.880966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #24 | Epoch Duration: 621.7770006656647
2020-01-13 12:04:02.881104 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042155955
Z variance train             0.05168696
KL Divergence                5.5460806
KL Loss                      0.55460805
QF Loss                      1176.2163
VF Loss                      708.9727
Policy Loss                  -811.5829
Q Predictions Mean           798.23596
Q Predictions Std            428.2217
Q Predictions Max            1412.3212
Q Predictions Min            10.530852
V Predictions Mean           801.4988
V Predictions Std            422.23105
V Predictions Max            1400.6875
V Predictions Min            24.608953
Log Pis Mean                 -1.69923
Log Pis Std                  6.81837
Log Pis Max                  32.55288
Log Pis Min                  -12.278776
Policy mu Mean               0.31568062
Policy mu Std                0.85132223
Policy mu Max                2.9434896
Policy mu Min                -3.082546
Policy log std Mean          -0.3276481
Policy log std Std           0.11711932
Policy log std Max           -0.060532227
Policy log std Min           -0.87392145
Z mean eval                  0.06535418
Z variance eval              0.06617593
total_rewards                [562.21680455 414.60416185 725.66424085 457.40591398 438.89936588
 441.67617946 439.06799429 377.61106614 424.54370988 379.77695128]
total_rewards_mean           466.14663881682674
total_rewards_std            99.20455343263299
total_rewards_max            725.6642408537904
total_rewards_min            377.61106613658166
Number of train steps total  104000
Number of env steps total    66383
Number of rollouts total     0
Train Time (s)               611.543492496945
(Previous) Eval Time (s)     2.46562291495502
Sample Time (s)              6.729081969708204
Epoch Time (s)               620.7381973816082
Total Train Time (s)         16142.545939490665
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:14:23.742207 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #25 | Epoch Duration: 620.8610036373138
2020-01-13 12:14:23.742344 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0670184
Z variance train             0.06624363
KL Divergence                4.7303386
KL Loss                      0.47303388
QF Loss                      1415.1191
VF Loss                      1003.5268
Policy Loss                  -864.9739
Q Predictions Mean           857.7815
Q Predictions Std            435.95502
Q Predictions Max            1474.1246
Q Predictions Min            14.159474
V Predictions Mean           869.76117
V Predictions Std            425.60843
V Predictions Max            1450.181
V Predictions Min            44.75704
Log Pis Mean                 -2.023017
Log Pis Std                  6.801514
Log Pis Max                  33.859585
Log Pis Min                  -13.232526
Policy mu Mean               0.21327792
Policy mu Std                0.87488854
Policy mu Max                3.071818
Policy mu Min                -3.439757
Policy log std Mean          -0.3333187
Policy log std Std           0.12785724
Policy log std Max           -0.040468976
Policy log std Min           -0.9326554
Z mean eval                  0.071024805
Z variance eval              0.08132839
total_rewards                [467.21967328 394.40688479 497.84530893 509.41876144 528.08727377
 433.29605137 446.15333663 421.00080281 537.71302346 523.03126958]
total_rewards_mean           475.81723860614
total_rewards_std            47.750509540908475
total_rewards_max            537.7130234599447
total_rewards_min            394.40688479068245
Number of train steps total  108000
Number of env steps total    69159
Number of rollouts total     0
Train Time (s)               617.4211919740774
(Previous) Eval Time (s)     2.3718103682622313
Sample Time (s)              6.7871438870206475
Epoch Time (s)               626.5801462293603
Total Train Time (s)         16769.250483348034
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:24:50.451736 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #26 | Epoch Duration: 626.709242105484
2020-01-13 12:24:50.452047 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.070423655
Z variance train             0.0813449
KL Divergence                4.652231
KL Loss                      0.46522313
QF Loss                      1289.3586
VF Loss                      579.4412
Policy Loss                  -851.6979
Q Predictions Mean           842.0922
Q Predictions Std            419.8952
Q Predictions Max            1441.2498
Q Predictions Min            36.571728
V Predictions Mean           841.0561
V Predictions Std            421.1822
V Predictions Max            1438.8893
V Predictions Min            39.50779
Log Pis Mean                 -2.834858
Log Pis Std                  5.324415
Log Pis Max                  24.150787
Log Pis Min                  -14.363508
Policy mu Mean               0.2588805
Policy mu Std                0.8325554
Policy mu Max                2.9642396
Policy mu Min                -3.150439
Policy log std Mean          -0.31730956
Policy log std Std           0.11608731
Policy log std Max           -0.051335387
Policy log std Min           -0.83448285
Z mean eval                  0.06738392
Z variance eval              0.051000226
total_rewards                [455.4200753  391.10331436 528.43925183 492.4791676  538.32684086
 532.69656189 534.27730584 560.21358373 347.87088427 358.08216278]
total_rewards_mean           473.89091484544076
total_rewards_std            76.49635948505745
total_rewards_max            560.2135837334621
total_rewards_min            347.8708842707505
Number of train steps total  112000
Number of env steps total    71932
Number of rollouts total     0
Train Time (s)               606.509810521733
(Previous) Eval Time (s)     2.3446211898699403
Sample Time (s)              6.30486993258819
Epoch Time (s)               615.1593016441911
Total Train Time (s)         17384.514378423803
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:35:05.713590 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #27 | Epoch Duration: 615.261322259903
2020-01-13 12:35:05.713727 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06731297
Z variance train             0.05093476
KL Divergence                5.2412786
KL Loss                      0.5241279
QF Loss                      1380.5405
VF Loss                      700.3502
Policy Loss                  -873.9782
Q Predictions Mean           860.1001
Q Predictions Std            434.68777
Q Predictions Max            1474.7375
Q Predictions Min            14.785358
V Predictions Mean           876.5842
V Predictions Std            434.95535
V Predictions Max            1478.8612
V Predictions Min            0.8796439
Log Pis Mean                 -2.4013958
Log Pis Std                  6.0466595
Log Pis Max                  24.71059
Log Pis Min                  -12.742112
Policy mu Mean               0.23275273
Policy mu Std                0.8681949
Policy mu Max                2.757377
Policy mu Min                -3.207464
Policy log std Mean          -0.31740472
Policy log std Std           0.11995541
Policy log std Max           0.030013457
Policy log std Min           -0.81191707
Z mean eval                  0.060190298
Z variance eval              0.14171836
total_rewards                [571.78590457 455.65198454 465.82493738 411.07861138 321.01096338
 427.75339962 527.51256822 528.78083281 512.17527309 472.59766551]
total_rewards_mean           469.41721405089737
total_rewards_std            68.25166101937667
total_rewards_max            571.7859045665298
total_rewards_min            321.0109633752697
Number of train steps total  116000
Number of env steps total    74841
Number of rollouts total     0
Train Time (s)               611.1676101847552
(Previous) Eval Time (s)     2.2628547409549356
Sample Time (s)              7.0403459328226745
Epoch Time (s)               620.4708108585328
Total Train Time (s)         18005.106573668774
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:45:26.306579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #28 | Epoch Duration: 620.5927500724792
2020-01-13 12:45:26.306733 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06191771
Z variance train             0.14167456
KL Divergence                3.9860404
KL Loss                      0.39860404
QF Loss                      1382.77
VF Loss                      793.3561
Policy Loss                  -853.3927
Q Predictions Mean           841.15515
Q Predictions Std            468.417
Q Predictions Max            1498.874
Q Predictions Min            13.255581
V Predictions Mean           846.8412
V Predictions Std            467.8199
V Predictions Max            1482.9531
V Predictions Min            -5.844466
Log Pis Mean                 -1.8102661
Log Pis Std                  6.4245567
Log Pis Max                  29.935246
Log Pis Min                  -15.693123
Policy mu Mean               0.2886956
Policy mu Std                0.8496243
Policy mu Max                3.4637718
Policy mu Min                -2.989703
Policy log std Mean          -0.32865828
Policy log std Std           0.119504005
Policy log std Max           -0.021822184
Policy log std Min           -0.8985682
Z mean eval                  0.09403913
Z variance eval              0.19218169
total_rewards                [409.06816805 269.4964671  524.72832788 415.33701951 617.06467828
 734.05176156 463.39395139 425.08550593 483.24350487 508.44579296]
total_rewards_mean           484.9915177536406
total_rewards_std            119.46376168672461
total_rewards_max            734.0517615614359
total_rewards_min            269.4964671041627
Number of train steps total  120000
Number of env steps total    77858
Number of rollouts total     0
Train Time (s)               607.8083266238682
(Previous) Eval Time (s)     2.484282192774117
Sample Time (s)              7.43673289148137
Epoch Time (s)               617.7293417081237
Total Train Time (s)         18622.93221313879
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:55:44.133189 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #29 | Epoch Duration: 617.8263585567474
2020-01-13 12:55:44.133319 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09399406
Z variance train             0.19268312
KL Divergence                3.5768027
KL Loss                      0.3576803
QF Loss                      1346.8445
VF Loss                      636.35596
Policy Loss                  -847.4227
Q Predictions Mean           841.85767
Q Predictions Std            453.79742
Q Predictions Max            1493.2983
Q Predictions Min            -4.427484
V Predictions Mean           847.49475
V Predictions Std            449.3778
V Predictions Max            1489.0857
V Predictions Min            19.962395
Log Pis Mean                 -2.821162
Log Pis Std                  6.0225034
Log Pis Max                  27.485846
Log Pis Min                  -15.2020855
Policy mu Mean               0.2618389
Policy mu Std                0.8405374
Policy mu Max                3.0705476
Policy mu Min                -2.9674902
Policy log std Mean          -0.322696
Policy log std Std           0.11671467
Policy log std Max           0.038034365
Policy log std Min           -1.0393103
Z mean eval                  0.0886577
Z variance eval              0.14932445
total_rewards                [333.41642637 517.62541775 534.78507634 553.2842636  447.34635809
 499.66729544 445.20077073 421.5403276  299.03317015 511.08450776]
total_rewards_mean           456.2983613836965
total_rewards_std            80.90336822017059
total_rewards_max            553.2842636001735
total_rewards_min            299.0331701453251
Number of train steps total  124000
Number of env steps total    80685
Number of rollouts total     0
Train Time (s)               606.3360614147969
(Previous) Eval Time (s)     2.4545674389228225
Sample Time (s)              7.094578966964036
Epoch Time (s)               615.8852078206837
Total Train Time (s)         19238.91958815325
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:06:00.121265 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #30 | Epoch Duration: 615.9878516197205
2020-01-13 13:06:00.121395 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08512698
Z variance train             0.14961073
KL Divergence                3.0433538
KL Loss                      0.3043354
QF Loss                      1523.1149
VF Loss                      775.1148
Policy Loss                  -860.24835
Q Predictions Mean           859.70715
Q Predictions Std            449.62445
Q Predictions Max            1494.5829
Q Predictions Min            23.224909
V Predictions Mean           873.7372
V Predictions Std            447.12082
V Predictions Max            1501.3652
V Predictions Min            47.410816
Log Pis Mean                 -2.424923
Log Pis Std                  6.0639844
Log Pis Max                  30.893566
Log Pis Min                  -13.54823
Policy mu Mean               0.24601673
Policy mu Std                0.8477698
Policy mu Max                2.7925732
Policy mu Min                -2.8437762
Policy log std Mean          -0.32491168
Policy log std Std           0.123982124
Policy log std Max           -0.018819511
Policy log std Min           -0.9634791
Z mean eval                  0.10126662
Z variance eval              0.09654404
total_rewards                [620.73332303 374.62373114 424.4480372  447.41547338 524.73935764
 515.30639944 534.49584749 531.53525138 509.04212542 490.23320315]
total_rewards_mean           497.2572749262731
total_rewards_std            64.7314898673099
total_rewards_max            620.7333230270572
total_rewards_min            374.62373113700954
Number of train steps total  128000
Number of env steps total    83479
Number of rollouts total     0
Train Time (s)               614.769242094364
(Previous) Eval Time (s)     2.5641017141751945
Sample Time (s)              6.759815101046115
Epoch Time (s)               624.0931589095853
Total Train Time (s)         19863.113502623048
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:16:24.317250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #31 | Epoch Duration: 624.1957433223724
2020-01-13 13:16:24.317427 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #31 | Started Training: True
