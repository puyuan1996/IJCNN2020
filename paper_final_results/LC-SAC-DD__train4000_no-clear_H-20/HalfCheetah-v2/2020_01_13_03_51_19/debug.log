---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015107745
Z variance train             0.69259006
KL Divergence                0.14977556
KL Loss                      0.014977557
QF Loss                      46.331024
VF Loss                      16.467674
Policy Loss                  -4.023477
Q Predictions Mean           0.0041415626
Q Predictions Std            0.0027838328
Q Predictions Max            0.0146425795
Q Predictions Min            -0.0018293844
V Predictions Mean           0.004016267
V Predictions Std            0.0015991185
V Predictions Max            0.008371308
V Predictions Min            1.0664808e-05
Log Pis Mean                 -4.0536647
Log Pis Std                  0.55837053
Log Pis Max                  -2.2691817
Log Pis Min                  -5.739599
Policy mu Mean               -0.0007698768
Policy mu Std                0.0014816081
Policy mu Max                0.0040149908
Policy mu Min                -0.004992895
Policy log std Mean          0.00074010243
Policy log std Std           0.0011658955
Policy log std Max           0.004144796
Policy log std Min           -0.003478533
Z mean eval                  1.0256958
Z variance eval              0.03827204
total_rewards                [-142.90677729 -123.32252894 -150.12502523 -139.04942806 -156.42701259
 -139.444603   -125.99907129 -162.8277051  -123.53700147 -135.88975397]
total_rewards_mean           -139.9528906953836
total_rewards_std            12.904242331790373
total_rewards_max            -123.32252894442762
total_rewards_min            -162.82770510292605
Number of train steps total  4000
Number of env steps total    14000
Number of rollouts total     0
Train Time (s)               135.1696987678297
(Previous) Eval Time (s)     0
Sample Time (s)              20.58117772405967
Epoch Time (s)               155.75087649188936
Total Train Time (s)         184.57353916717693
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:54:23.920438 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #0 | Epoch Duration: 184.57739162445068
2020-01-13 03:54:23.920696 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0417631
Z variance train             0.03664141
KL Divergence                10.514332
KL Loss                      1.0514332
QF Loss                      59.857693
VF Loss                      9.289874
Policy Loss                  -48.22554
Q Predictions Mean           42.48163
Q Predictions Std            18.279009
Q Predictions Max            93.997505
Q Predictions Min            -11.66238
V Predictions Mean           48.38044
V Predictions Std            17.458164
V Predictions Max            98.38198
V Predictions Min            6.0290623
Log Pis Mean                 -3.4644556
Log Pis Std                  1.0639559
Log Pis Max                  -0.09244096
Log Pis Min                  -7.9761
Policy mu Mean               0.02983544
Policy mu Std                0.3474364
Policy mu Max                1.42376
Policy mu Min                -1.597566
Policy log std Mean          -0.30943048
Policy log std Std           0.069340155
Policy log std Max           -0.14784056
Policy log std Min           -0.54502374
Z mean eval                  1.2237481
Z variance eval              0.025730107
total_rewards                [-104.45898172 -104.31502126 -165.65707366 -135.52606683  -98.11510974
 -107.03961969  -99.79397038 -124.32233853 -130.99353185 -129.61461923]
total_rewards_mean           -119.98363328863495
total_rewards_std            20.249323503762618
total_rewards_max            -98.11510973767759
total_rewards_min            -165.65707365923572
Number of train steps total  8000
Number of env steps total    26000
Number of rollouts total     0
Train Time (s)               135.3266730220057
(Previous) Eval Time (s)     29.190223225858063
Sample Time (s)              9.898626110050827
Epoch Time (s)               174.4155223579146
Total Train Time (s)         359.07478751055896
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:57:18.422445 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #1 | Epoch Duration: 174.50158095359802
2020-01-13 03:57:18.422634 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2211206
Z variance train             0.025687436
KL Divergence                13.108749
KL Loss                      1.3108749
QF Loss                      73.985794
VF Loss                      10.430853
Policy Loss                  -95.1689
Q Predictions Mean           87.944305
Q Predictions Std            32.02994
Q Predictions Max            180.71939
Q Predictions Min            38.674313
V Predictions Mean           95.37352
V Predictions Std            30.76746
V Predictions Max            183.48087
V Predictions Min            45.207077
Log Pis Mean                 -3.3032477
Log Pis Std                  1.3092169
Log Pis Max                  0.22357267
Log Pis Min                  -7.995988
Policy mu Mean               0.003072439
Policy mu Std                0.42127132
Policy mu Max                1.5579543
Policy mu Min                -1.3545934
Policy log std Mean          -0.33296305
Policy log std Std           0.07548411
Policy log std Max           -0.16987516
Policy log std Min           -0.6580149
Z mean eval                  1.3173906
Z variance eval              0.025655767
total_rewards                [-28.52697784   7.81355156 -13.60704546 -55.864784   -51.99874588
 -67.28123797 -40.09576258 -41.08447268 -44.31871717 -29.26379325]
total_rewards_mean           -36.42279852827694
total_rewards_std            20.643207646122434
total_rewards_max            7.8135515570331044
total_rewards_min            -67.28123796623257
Number of train steps total  12000
Number of env steps total    38000
Number of rollouts total     0
Train Time (s)               139.58098481502384
(Previous) Eval Time (s)     28.24533577496186
Sample Time (s)              9.881705069448799
Epoch Time (s)               177.7080256594345
Total Train Time (s)         536.9230066128075
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:00:16.272219 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #2 | Epoch Duration: 177.84943437576294
2020-01-13 04:00:16.272447 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3127165
Z variance train             0.025629496
KL Divergence                14.6262
KL Loss                      1.46262
QF Loss                      73.100204
VF Loss                      19.786041
Policy Loss                  -128.82664
Q Predictions Mean           125.66351
Q Predictions Std            38.509205
Q Predictions Max            240.32428
Q Predictions Min            54.57587
V Predictions Mean           130.3121
V Predictions Std            38.382797
V Predictions Max            234.53748
V Predictions Min            55.123665
Log Pis Mean                 -3.1382446
Log Pis Std                  1.5086672
Log Pis Max                  5.7533703
Log Pis Min                  -7.577321
Policy mu Mean               0.005984696
Policy mu Std                0.43812537
Policy mu Max                1.716581
Policy mu Min                -1.3873512
Policy log std Mean          -0.33384976
Policy log std Std           0.0807139
Policy log std Max           -0.16063413
Policy log std Min           -0.67838037
Z mean eval                  1.3755088
Z variance eval              0.024776427
total_rewards                [ 19.15571105 189.16534856 -18.70612017  45.78703285  77.18448995
  12.39832166  67.83417428 182.02533129  75.58477946 175.31687172]
total_rewards_mean           82.57459406458139
total_rewards_std            71.20823724536663
total_rewards_max            189.16534855720215
total_rewards_min            -18.706120167639643
Number of train steps total  16000
Number of env steps total    50000
Number of rollouts total     0
Train Time (s)               144.92921394202858
(Previous) Eval Time (s)     29.649947706144303
Sample Time (s)              10.334115873090923
Epoch Time (s)               184.9132775212638
Total Train Time (s)         721.9183142436668
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:03:21.269201 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #3 | Epoch Duration: 184.9965717792511
2020-01-13 04:03:21.269501 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3716915
Z variance train             0.024731299
KL Divergence                16.90746
KL Loss                      1.690746
QF Loss                      169.8247
VF Loss                      23.795696
Policy Loss                  -150.97406
Q Predictions Mean           148.77383
Q Predictions Std            48.9284
Q Predictions Max            296.14877
Q Predictions Min            61.08474
V Predictions Mean           154.15846
V Predictions Std            49.035534
V Predictions Max            298.77774
V Predictions Min            66.32259
Log Pis Mean                 -3.120642
Log Pis Std                  1.424811
Log Pis Max                  1.5427815
Log Pis Min                  -6.905998
Policy mu Mean               -0.022883518
Policy mu Std                0.41397294
Policy mu Max                1.7168179
Policy mu Min                -1.530792
Policy log std Mean          -0.32380208
Policy log std Std           0.07896493
Policy log std Max           -0.15063521
Policy log std Min           -0.7356856
Z mean eval                  1.3836472
Z variance eval              0.029779803
total_rewards                [ 855.65517241 1137.63770659  447.68830521  158.83821378  973.82622981
  936.94782396 1025.05641371 1062.98334437  634.16871113  982.18773725]
total_rewards_mean           821.4989658221618
total_rewards_std            296.1688558234679
total_rewards_max            1137.6377065864108
total_rewards_min            158.83821378237644
Number of train steps total  20000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               143.4624906051904
(Previous) Eval Time (s)     30.030264096334577
Sample Time (s)              10.409957405179739
Epoch Time (s)               183.9027121067047
Total Train Time (s)         905.9051445052028
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:06:25.260349 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #4 | Epoch Duration: 183.9906153678894
2020-01-13 04:06:25.260628 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3828983
Z variance train             0.029681295
KL Divergence                15.695513
KL Loss                      1.5695513
QF Loss                      83.09689
VF Loss                      11.161845
Policy Loss                  -183.80461
Q Predictions Mean           176.54773
Q Predictions Std            60.430542
Q Predictions Max            328.97162
Q Predictions Min            61.44467
V Predictions Mean           183.47455
V Predictions Std            60.534115
V Predictions Max            332.15182
V Predictions Min            79.200066
Log Pis Mean                 -3.1222565
Log Pis Std                  1.457507
Log Pis Max                  3.825158
Log Pis Min                  -8.374736
Policy mu Mean               0.016841358
Policy mu Std                0.45043907
Policy mu Max                2.0616362
Policy mu Min                -1.9694142
Policy log std Mean          -0.33246216
Policy log std Std           0.087583154
Policy log std Max           -0.08212168
Policy log std Min           -0.7211883
Z mean eval                  1.4370174
Z variance eval              0.062488187
total_rewards                [ 640.77661363  274.76512936  445.97975978 1743.79431477 1698.25846607
 1432.87023876 1684.44298758 1335.63260216  451.48972859 1649.5760709 ]
total_rewards_mean           1135.7585911597635
total_rewards_std            575.3031447053886
total_rewards_max            1743.7943147709348
total_rewards_min            274.76512935929225
Number of train steps total  24000
Number of env steps total    74000
Number of rollouts total     0
Train Time (s)               144.5262325843796
(Previous) Eval Time (s)     31.06749932700768
Sample Time (s)              9.794116429518908
Epoch Time (s)               185.3878483409062
Total Train Time (s)         1091.379744711332
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:09:30.733965 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #5 | Epoch Duration: 185.473149061203
2020-01-13 04:09:30.734171 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4394903
Z variance train             0.06280731
KL Divergence                14.83344
KL Loss                      1.483344
QF Loss                      96.6248
VF Loss                      16.07418
Policy Loss                  -226.1052
Q Predictions Mean           220.7142
Q Predictions Std            80.07861
Q Predictions Max            451.52295
Q Predictions Min            88.428345
V Predictions Mean           225.49138
V Predictions Std            80.52923
V Predictions Max            435.49176
V Predictions Min            100.400764
Log Pis Mean                 -2.9268596
Log Pis Std                  1.6014009
Log Pis Max                  2.9643326
Log Pis Min                  -6.443238
Policy mu Mean               -0.042586714
Policy mu Std                0.48837912
Policy mu Max                1.7946221
Policy mu Min                -1.5977334
Policy log std Mean          -0.34433648
Policy log std Std           0.094233155
Policy log std Max           -0.17555693
Policy log std Min           -0.91650814
Z mean eval                  1.5428356
Z variance eval              0.049679853
total_rewards                [2011.19290184 2190.53213608 1779.9249671  2009.54261371 2043.77655428
  715.27618903 1975.0241682  1929.5674816  2180.86329292 2101.47701225]
total_rewards_mean           1893.7177317012042
total_rewards_std            409.0254216699854
total_rewards_max            2190.53213607915
total_rewards_min            715.2761890251838
Number of train steps total  28000
Number of env steps total    86000
Number of rollouts total     0
Train Time (s)               143.76087479991838
(Previous) Eval Time (s)     29.776785694994032
Sample Time (s)              9.69826276646927
Epoch Time (s)               183.23592326138169
Total Train Time (s)         1274.7033358654007
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:12:34.058867 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #6 | Epoch Duration: 183.3245232105255
2020-01-13 04:12:34.059131 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #6 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5420594
Z variance train             0.04967355
KL Divergence                16.659971
KL Loss                      1.6659971
QF Loss                      315.93787
VF Loss                      23.249805
Policy Loss                  -242.95569
Q Predictions Mean           239.06415
Q Predictions Std            98.799095
Q Predictions Max            528.3048
Q Predictions Min            115.899574
V Predictions Mean           243.40158
V Predictions Std            99.13904
V Predictions Max            526.9321
V Predictions Min            115.15481
Log Pis Mean                 -2.5185337
Log Pis Std                  1.8782654
Log Pis Max                  5.2011137
Log Pis Min                  -6.962307
Policy mu Mean               -0.015966164
Policy mu Std                0.52780694
Policy mu Max                2.0171916
Policy mu Min                -1.9548225
Policy log std Mean          -0.35512245
Policy log std Std           0.10895775
Policy log std Max           -0.09002298
Policy log std Min           -1.02182
Z mean eval                  1.6425301
Z variance eval              0.034885477
total_rewards                [2400.00136015 2401.43390219 2619.59700887 2519.51685132 2422.7933659
 2453.35009662 2503.96227283 2491.5622501  2445.75059411 2574.99173896]
total_rewards_mean           2483.2959441054
total_rewards_std            69.56998836279563
total_rewards_max            2619.597008869601
total_rewards_min            2400.001360150706
Number of train steps total  32000
Number of env steps total    98000
Number of rollouts total     0
Train Time (s)               135.1293052448891
(Previous) Eval Time (s)     29.148590783122927
Sample Time (s)              9.782862472813576
Epoch Time (s)               174.0607585008256
Total Train Time (s)         1448.8738327701576
Epoch                        7
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:15:28.230421 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #7 | Epoch Duration: 174.1710877418518
2020-01-13 04:15:28.230647 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6445417
Z variance train             0.034927085
KL Divergence                18.042824
KL Loss                      1.8042824
QF Loss                      127.019295
VF Loss                      36.175797
Policy Loss                  -303.01776
Q Predictions Mean           294.76462
Q Predictions Std            129.2916
Q Predictions Max            687.1975
Q Predictions Min            129.34276
V Predictions Mean           301.51675
V Predictions Std            130.08394
V Predictions Max            684.4927
V Predictions Min            129.86626
Log Pis Mean                 -2.163064
Log Pis Std                  2.2145302
Log Pis Max                  5.4016247
Log Pis Min                  -5.916836
Policy mu Mean               -0.043593224
Policy mu Std                0.62046224
Policy mu Max                2.062754
Policy mu Min                -2.3176289
Policy log std Mean          -0.39098796
Policy log std Std           0.14314833
Policy log std Max           -0.14937966
Policy log std Min           -1.2775968
Z mean eval                  1.7445408
Z variance eval              0.05919212
total_rewards                [2843.10600668 2663.96139459 2840.73505958 2649.92767026 2774.23326425
 2902.13440623 2738.78058471 2824.48279761 2761.5133004  2836.26318204]
total_rewards_mean           2783.513766635337
total_rewards_std            77.50261318897893
total_rewards_max            2902.1344062275057
total_rewards_min            2649.927670261687
Number of train steps total  36000
Number of env steps total    110000
Number of rollouts total     0
Train Time (s)               136.02701795333996
(Previous) Eval Time (s)     29.46350857615471
Sample Time (s)              9.812893980648369
Epoch Time (s)               175.30342051014304
Total Train Time (s)         1624.2626554192975
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:18:23.621125 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #8 | Epoch Duration: 175.39025211334229
2020-01-13 04:18:23.621390 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7468193
Z variance train             0.05931946
KL Divergence                19.001722
KL Loss                      1.9001722
QF Loss                      164.75446
VF Loss                      34.524612
Policy Loss                  -316.3597
Q Predictions Mean           310.58667
Q Predictions Std            156.90396
Q Predictions Max            756.94995
Q Predictions Min            130.48213
V Predictions Mean           315.16348
V Predictions Std            155.79672
V Predictions Max            745.4276
V Predictions Min            136.95897
Log Pis Mean                 -2.294313
Log Pis Std                  2.4314578
Log Pis Max                  5.8937774
Log Pis Min                  -8.309108
Policy mu Mean               0.030981028
Policy mu Std                0.63284576
Policy mu Max                2.2234957
Policy mu Min                -2.4730527
Policy log std Mean          -0.38885424
Policy log std Std           0.1527178
Policy log std Max           -0.1300377
Policy log std Min           -1.6185329
Z mean eval                  1.9087309
Z variance eval              0.034889363
total_rewards                [ 586.12702516 2834.0862094  1788.2150089  2952.38149097 2771.43316973
 2993.49088716 3123.57567697 2751.48458213 2942.05174323 2941.78253465]
total_rewards_mean           2568.4628328288804
total_rewards_std            748.252667496856
total_rewards_max            3123.5756769682516
total_rewards_min            586.1270251635506
Number of train steps total  40000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               139.33203822607175
(Previous) Eval Time (s)     30.45475267106667
Sample Time (s)              9.741734382230788
Epoch Time (s)               179.5285252793692
Total Train Time (s)         1803.8814905546606
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:21:23.240531 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #9 | Epoch Duration: 179.6189534664154
2020-01-13 04:21:23.240765 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #9 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9109049
Z variance train             0.034960017
KL Divergence                22.360939
KL Loss                      2.236094
QF Loss                      218.84306
VF Loss                      31.833996
Policy Loss                  -381.51318
Q Predictions Mean           372.70822
Q Predictions Std            209.43826
Q Predictions Max            942.408
Q Predictions Min            136.9262
V Predictions Mean           379.15616
V Predictions Std            210.68253
V Predictions Max            941.18915
V Predictions Min            136.1458
Log Pis Mean                 -2.0302649
Log Pis Std                  2.654279
Log Pis Max                  6.3034534
Log Pis Min                  -7.7427616
Policy mu Mean               -0.056155074
Policy mu Std                0.65981376
Policy mu Max                2.0682673
Policy mu Min                -2.2433944
Policy log std Mean          -0.3962377
Policy log std Std           0.17061424
Policy log std Max           -0.16713831
Policy log std Min           -1.582621
Z mean eval                  2.0370061
Z variance eval              0.030260349
total_rewards                [3216.49864318 3373.03997529 3283.97297142 3160.68967044 3139.9842226
 3360.30436792 3367.34085274 3292.21871131 3376.02412653 3216.8702292 ]
total_rewards_mean           3278.6943770629587
total_rewards_std            85.99969987061766
total_rewards_max            3376.024126530642
total_rewards_min            3139.9842226032274
Number of train steps total  44000
Number of env steps total    134000
Number of rollouts total     0
Train Time (s)               145.5234956261702
(Previous) Eval Time (s)     30.005542759317905
Sample Time (s)              10.507124262861907
Epoch Time (s)               186.03616264835
Total Train Time (s)         1990.0095025063492
Epoch                        10
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:24:29.370704 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #10 | Epoch Duration: 186.12975978851318
2020-01-13 04:24:29.371029 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0360026
Z variance train             0.030228361
KL Divergence                25.421942
KL Loss                      2.5421941
QF Loss                      167.70357
VF Loss                      47.110382
Policy Loss                  -459.5985
Q Predictions Mean           451.8736
Q Predictions Std            257.75766
Q Predictions Max            1015.97626
Q Predictions Min            139.42593
V Predictions Mean           459.86664
V Predictions Std            256.99426
V Predictions Max            1007.1075
V Predictions Min            145.88136
Log Pis Mean                 -1.640378
Log Pis Std                  2.6879005
Log Pis Max                  6.6033874
Log Pis Min                  -6.999361
Policy mu Mean               -0.010499154
Policy mu Std                0.73554885
Policy mu Max                2.67506
Policy mu Min                -2.0956612
Policy log std Mean          -0.41938755
Policy log std Std           0.16956227
Policy log std Max           -0.14304288
Policy log std Min           -1.5932713
Z mean eval                  2.088719
Z variance eval              0.0333396
total_rewards                [3303.02192321 3207.89683964 3417.45803637 3255.30739892 3264.02272269
 3391.1786908   551.89985266 1944.87918999 3690.95178193 3259.29370947]
total_rewards_mean           2928.591014569056
total_rewards_std            905.3924366830859
total_rewards_max            3690.9517819316848
total_rewards_min            551.8998526588961
Number of train steps total  48000
Number of env steps total    146000
Number of rollouts total     0
Train Time (s)               144.48169105360284
(Previous) Eval Time (s)     27.671779538039118
Sample Time (s)              10.016145713627338
Epoch Time (s)               182.1696163052693
Total Train Time (s)         2172.2632115068845
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:27:31.624945 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #11 | Epoch Duration: 182.25357055664062
2020-01-13 04:27:31.625155 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.085892
Z variance train             0.033216156
KL Divergence                26.090431
KL Loss                      2.6090431
QF Loss                      291.6256
VF Loss                      61.000023
Policy Loss                  -512.66785
Q Predictions Mean           502.23526
Q Predictions Std            293.34406
Q Predictions Max            1108.88
Q Predictions Min            125.631645
V Predictions Mean           515.7207
V Predictions Std            296.8542
V Predictions Max            1129.8606
V Predictions Min            143.65698
Log Pis Mean                 -1.6002401
Log Pis Std                  2.7057092
Log Pis Max                  8.177647
Log Pis Min                  -7.414344
Policy mu Mean               -0.035372917
Policy mu Std                0.7033298
Policy mu Max                2.3424191
Policy mu Min                -2.2803743
Policy log std Mean          -0.428413
Policy log std Std           0.18532293
Policy log std Max           -0.15736386
Policy log std Min           -1.5418373
Z mean eval                  2.1781394
Z variance eval              0.0333805
total_rewards                [3627.15393226 3399.63803219 3700.7953177  3535.39134297 3622.10569688
 3687.80604704 3440.6597011  3754.21643921 3456.04171341 3532.17264194]
total_rewards_mean           3575.598086470981
total_rewards_std            114.87246774667308
total_rewards_max            3754.216439209252
total_rewards_min            3399.6380321917113
Number of train steps total  52000
Number of env steps total    158000
Number of rollouts total     0
Train Time (s)               144.84725447325036
(Previous) Eval Time (s)     30.07397956121713
Sample Time (s)              10.296244546305388
Epoch Time (s)               185.21747858077288
Total Train Time (s)         2357.5684253107756
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:30:36.931073 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #12 | Epoch Duration: 185.3057701587677
2020-01-13 04:30:36.931301 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #12 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1762526
Z variance train             0.033425134
KL Divergence                26.009548
KL Loss                      2.6009548
QF Loss                      600.0072
VF Loss                      86.35329
Policy Loss                  -530.9685
Q Predictions Mean           520.9466
Q Predictions Std            334.75516
Q Predictions Max            1230.6084
Q Predictions Min            140.67706
V Predictions Mean           536.80414
V Predictions Std            337.49582
V Predictions Max            1242.9822
V Predictions Min            152.92342
Log Pis Mean                 -1.5598468
Log Pis Std                  2.7517388
Log Pis Max                  8.482935
Log Pis Min                  -7.192613
Policy mu Mean               -0.0748916
Policy mu Std                0.72596675
Policy mu Max                2.3527985
Policy mu Min                -2.5379438
Policy log std Mean          -0.41959366
Policy log std Std           0.16837575
Policy log std Max           -0.15485859
Policy log std Min           -1.6184722
Z mean eval                  2.124622
Z variance eval              0.031225126
total_rewards                [3636.07098698 3631.87323206 3712.94370525 3962.13065355 3854.13157805
 3787.21512846 3914.40001626 3848.3629897  3750.78059012  355.64823078]
total_rewards_mean           3445.3557111209075
total_rewards_std            1035.170538894677
total_rewards_max            3962.1306535527833
total_rewards_min            355.6482307794189
Number of train steps total  56000
Number of env steps total    170000
Number of rollouts total     0
Train Time (s)               143.527571155224
(Previous) Eval Time (s)     30.46967876702547
Sample Time (s)              9.137081005610526
Epoch Time (s)               183.13433092786
Total Train Time (s)         2540.7812796384096
Epoch                        13
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:33:40.145214 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #13 | Epoch Duration: 183.21377205848694
2020-01-13 04:33:40.145393 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.227717
Z variance train             0.02874679
KL Divergence                26.188766
KL Loss                      2.6188767
QF Loss                      780.8178
VF Loss                      100.7383
Policy Loss                  -550.42816
Q Predictions Mean           542.33215
Q Predictions Std            360.23068
Q Predictions Max            1297.1665
Q Predictions Min            119.03455
V Predictions Mean           553.9824
V Predictions Std            363.2006
V Predictions Max            1303.0824
V Predictions Min            136.49727
Log Pis Mean                 -1.647366
Log Pis Std                  2.7591066
Log Pis Max                  7.939071
Log Pis Min                  -6.227255
Policy mu Mean               -0.036202524
Policy mu Std                0.70289916
Policy mu Max                2.2701442
Policy mu Min                -2.6456738
Policy log std Mean          -0.4306701
Policy log std Std           0.19197294
Policy log std Max           -0.1047246
Policy log std Min           -1.5626104
Z mean eval                  2.0834286
Z variance eval              0.04036904
total_rewards                [3912.31956699 3836.22063694 3763.45249836 3860.83554306 4003.50926297
 4106.80825461 3982.96969358 3814.56330703 4201.70617097 4007.36768032]
total_rewards_mean           3948.9752614833646
total_rewards_std            130.62715798580794
total_rewards_max            4201.706170973098
total_rewards_min            3763.4524983627116
Number of train steps total  60000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               136.17868360690773
(Previous) Eval Time (s)     29.47298334678635
Sample Time (s)              9.46779740601778
Epoch Time (s)               175.11946435971186
Total Train Time (s)         2715.978063723538
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:36:35.343209 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #14 | Epoch Duration: 175.19766283035278
2020-01-13 04:36:35.343394 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0812023
Z variance train             0.04005206
KL Divergence                24.159883
KL Loss                      2.4159884
QF Loss                      269.65912
VF Loss                      77.09909
Policy Loss                  -590.57495
Q Predictions Mean           581.2316
Q Predictions Std            375.46603
Q Predictions Max            1365.9534
Q Predictions Min            129.46933
V Predictions Mean           584.9343
V Predictions Std            375.7126
V Predictions Max            1351.6685
V Predictions Min            136.57303
Log Pis Mean                 -1.3395694
Log Pis Std                  2.8993192
Log Pis Max                  7.541504
Log Pis Min                  -6.913801
Policy mu Mean               0.017010804
Policy mu Std                0.75831497
Policy mu Max                2.560572
Policy mu Min                -2.2179778
Policy log std Mean          -0.4341651
Policy log std Std           0.18985143
Policy log std Max           0.04626164
Policy log std Min           -1.6777205
Z mean eval                  2.15639
Z variance eval              0.018573845
total_rewards                [3945.58046096 4220.94580097 4024.13684278 2458.72207811 4060.36271591
 3775.72387136 3924.19714662 4008.41502216 4268.21352796 4116.60474594]
total_rewards_mean           3880.2902212784525
total_rewards_std            492.93913717162457
total_rewards_max            4268.213527961186
total_rewards_min            2458.722078108466
Number of train steps total  64000
Number of env steps total    194000
Number of rollouts total     0
Train Time (s)               136.0381448729895
(Previous) Eval Time (s)     29.1315353740938
Sample Time (s)              9.793008456937969
Epoch Time (s)               174.96268870402128
Total Train Time (s)         2891.024079713039
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:39:30.390357 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #15 | Epoch Duration: 175.04682302474976
2020-01-13 04:39:30.390554 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #15 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1560109
Z variance train             0.018591741
KL Divergence                27.455746
KL Loss                      2.7455747
QF Loss                      256.09094
VF Loss                      51.13497
Policy Loss                  -628.5214
Q Predictions Mean           623.729
Q Predictions Std            427.99777
Q Predictions Max            1447.118
Q Predictions Min            109.91141
V Predictions Mean           628.1433
V Predictions Std            429.28458
V Predictions Max            1437.2018
V Predictions Min            111.93628
Log Pis Mean                 -1.3209217
Log Pis Std                  3.027526
Log Pis Max                  9.375058
Log Pis Min                  -6.195577
Policy mu Mean               -0.03234281
Policy mu Std                0.76144284
Policy mu Max                2.6741767
Policy mu Min                -3.0504224
Policy log std Mean          -0.44179294
Policy log std Std           0.18850854
Policy log std Max           -0.16483758
Policy log std Min           -1.8026974
Z mean eval                  2.1643376
Z variance eval              0.021905273
total_rewards                [3931.65543911 3986.29410851 3841.54039886 3979.4679843  4185.2588604
 4011.72114932 4026.50278836 4041.69620796 4028.05555706 4044.62236598]
total_rewards_mean           4007.6814859853594
total_rewards_std            83.35301982133022
total_rewards_max            4185.258860396818
total_rewards_min            3841.540398856878
Number of train steps total  68000
Number of env steps total    206000
Number of rollouts total     0
Train Time (s)               140.37818847596645
(Previous) Eval Time (s)     29.636836634017527
Sample Time (s)              9.637842336669564
Epoch Time (s)               179.65286744665354
Total Train Time (s)         3070.7604709006846
Epoch                        16
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:42:30.128631 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #16 | Epoch Duration: 179.73792266845703
2020-01-13 04:42:30.128918 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.168
Z variance train             0.022010658
KL Divergence                30.48648
KL Loss                      3.048648
QF Loss                      194.4691
VF Loss                      92.87509
Policy Loss                  -586.7053
Q Predictions Mean           577.2095
Q Predictions Std            442.55322
Q Predictions Max            1506.7148
Q Predictions Min            114.36398
V Predictions Mean           580.9556
V Predictions Std            443.63297
V Predictions Max            1496.9319
V Predictions Min            116.44871
Log Pis Mean                 -1.588352
Log Pis Std                  3.0819478
Log Pis Max                  10.096727
Log Pis Min                  -9.722386
Policy mu Mean               -0.023022177
Policy mu Std                0.7089354
Policy mu Max                2.5599248
Policy mu Min                -2.3732564
Policy log std Mean          -0.43543497
Policy log std Std           0.18922606
Policy log std Max           -0.18052675
Policy log std Min           -1.8358722
Z mean eval                  2.1376603
Z variance eval              0.010108475
total_rewards                [4323.54406317 4196.10113319 4488.89769579 4125.37215829 3976.00631517
 4314.71664031 4341.55639276 4443.34965304 4427.20118819 4317.55442791]
total_rewards_mean           4295.429966781452
total_rewards_std            148.75164278299883
total_rewards_max            4488.897695789037
total_rewards_min            3976.006315173197
Number of train steps total  72000
Number of env steps total    218000
Number of rollouts total     0
Train Time (s)               146.32717904122546
(Previous) Eval Time (s)     29.67210314096883
Sample Time (s)              8.717916850466281
Epoch Time (s)               184.71719903266057
Total Train Time (s)         3255.5569341504015
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:45:34.925936 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #17 | Epoch Duration: 184.79668378829956
2020-01-13 04:45:34.926154 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1420865
Z variance train             0.01018998
KL Divergence                30.990833
KL Loss                      3.0990834
QF Loss                      326.7068
VF Loss                      171.19576
Policy Loss                  -645.9472
Q Predictions Mean           633.59717
Q Predictions Std            478.03458
Q Predictions Max            1528.694
Q Predictions Min            108.33403
V Predictions Mean           635.39935
V Predictions Std            479.2504
V Predictions Max            1509.122
V Predictions Min            117.70548
Log Pis Mean                 -1.4966679
Log Pis Std                  3.168276
Log Pis Max                  12.573307
Log Pis Min                  -5.6261196
Policy mu Mean               0.044510394
Policy mu Std                0.7506248
Policy mu Max                2.7421257
Policy mu Min                -2.5264802
Policy log std Mean          -0.44282043
Policy log std Std           0.20217356
Policy log std Max           -0.15446725
Policy log std Min           -1.7667996
Z mean eval                  2.1536717
Z variance eval              0.012165952
total_rewards                [4006.44583234 4497.05333432 4079.63741918 4640.68642854 4450.07806226
 4803.53429324 4627.94236285 4309.71624647 4409.14310914 4599.91244478]
total_rewards_mean           4442.414953313202
total_rewards_std            239.24491365700183
total_rewards_max            4803.534293242833
total_rewards_min            4006.445832341439
Number of train steps total  76000
Number of env steps total    230000
Number of rollouts total     0
Train Time (s)               145.14398198202252
(Previous) Eval Time (s)     28.78586185723543
Sample Time (s)              10.034160948358476
Epoch Time (s)               183.96400478761643
Total Train Time (s)         3439.6087293094024
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:48:38.980159 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #18 | Epoch Duration: 184.0538375377655
2020-01-13 04:48:38.980382 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1567967
Z variance train             0.0121422
KL Divergence                30.461346
KL Loss                      3.0461347
QF Loss                      231.95047
VF Loss                      61.116776
Policy Loss                  -652.9917
Q Predictions Mean           642.42786
Q Predictions Std            470.12903
Q Predictions Max            1555.6818
Q Predictions Min            101.82293
V Predictions Mean           652.36487
V Predictions Std            473.4002
V Predictions Max            1563.0844
V Predictions Min            112.6152
Log Pis Mean                 -1.4672794
Log Pis Std                  2.771547
Log Pis Max                  9.089682
Log Pis Min                  -6.460285
Policy mu Mean               -0.005866179
Policy mu Std                0.7090728
Policy mu Max                2.524079
Policy mu Min                -2.383123
Policy log std Mean          -0.44240746
Policy log std Std           0.20956212
Policy log std Max           -0.06296131
Policy log std Min           -1.7830443
Z mean eval                  2.1302464
Z variance eval              0.021251814
total_rewards                [4363.74121888 4189.17263375 4401.1186752  4413.78017297 4511.95851607
 4251.12407394 4407.78787941 4569.43828854 4239.90288398 4507.96367541]
total_rewards_mean           4385.598801815455
total_rewards_std            120.26473057913094
total_rewards_max            4569.438288537868
total_rewards_min            4189.172633746299
Number of train steps total  80000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               145.51250000856817
(Previous) Eval Time (s)     30.985371564049274
Sample Time (s)              10.058291838504374
Epoch Time (s)               186.55616341112182
Total Train Time (s)         3626.2524492447264
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:51:45.624280 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #19 | Epoch Duration: 186.6437270641327
2020-01-13 04:51:45.624493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.130591
Z variance train             0.021382548
KL Divergence                28.324394
KL Loss                      2.8324394
QF Loss                      331.3884
VF Loss                      71.1032
Policy Loss                  -687.73627
Q Predictions Mean           683.3706
Q Predictions Std            493.80222
Q Predictions Max            1653.3263
Q Predictions Min            109.87888
V Predictions Mean           689.3702
V Predictions Std            494.74017
V Predictions Max            1621.7692
V Predictions Min            108.67218
Log Pis Mean                 -1.3409259
Log Pis Std                  3.297848
Log Pis Max                  9.738718
Log Pis Min                  -7.89439
Policy mu Mean               -0.041907463
Policy mu Std                0.76117015
Policy mu Max                3.0115852
Policy mu Min                -2.364581
Policy log std Mean          -0.45343503
Policy log std Std           0.20496918
Policy log std Max           0.09873229
Policy log std Min           -1.8285434
Z mean eval                  2.1448584
Z variance eval              0.019967139
total_rewards                [4253.45022951 4355.97794446 4295.13854697 4322.51323413 4285.26647418
 4253.52946319 4151.70789816 4289.65401263 4357.53102068 4330.50815898]
total_rewards_mean           4289.527698290418
total_rewards_std            57.83505892367004
total_rewards_max            4357.531020676772
total_rewards_min            4151.707898158287
Number of train steps total  84000
Number of env steps total    254000
Number of rollouts total     0
Train Time (s)               144.083226907067
(Previous) Eval Time (s)     30.77234004996717
Sample Time (s)              13.676509617827833
Epoch Time (s)               188.532076574862
Total Train Time (s)         3814.883813721128
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:54:54.257768 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #20 | Epoch Duration: 188.633118391037
2020-01-13 04:54:54.257991 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1436436
Z variance train             0.01993153
KL Divergence                28.53073
KL Loss                      2.853073
QF Loss                      342.41486
VF Loss                      184.85005
Policy Loss                  -681.49115
Q Predictions Mean           673.95624
Q Predictions Std            494.54364
Q Predictions Max            1662.2656
Q Predictions Min            92.576515
V Predictions Mean           670.4573
V Predictions Std            493.7701
V Predictions Max            1648.7828
V Predictions Min            99.10451
Log Pis Mean                 -1.3790026
Log Pis Std                  3.0705378
Log Pis Max                  7.560112
Log Pis Min                  -6.9278307
Policy mu Mean               0.024438642
Policy mu Std                0.7482956
Policy mu Max                2.493583
Policy mu Min                -2.6068683
Policy log std Mean          -0.44727182
Policy log std Std           0.21511582
Policy log std Max           -0.0851683
Policy log std Min           -1.7632575
Z mean eval                  2.1527429
Z variance eval              0.026894584
total_rewards                [4278.5236842  4624.15770525 4490.41587118 4352.03043083 4460.13082051
 4431.86865917 4485.96962047 4638.82115741 4257.97471884 4350.88133349]
total_rewards_mean           4437.077400135008
total_rewards_std            123.8440217441765
total_rewards_max            4638.821157406979
total_rewards_min            4257.974718835467
Number of train steps total  88000
Number of env steps total    266000
Number of rollouts total     0
Train Time (s)               135.80928570544347
(Previous) Eval Time (s)     29.26618640497327
Sample Time (s)              9.776092582382262
Epoch Time (s)               174.851564692799
Total Train Time (s)         3989.8180725253187
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:57:49.195442 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #21 | Epoch Duration: 174.93724465370178
2020-01-13 04:57:49.195769 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1489587
Z variance train             0.02699602
KL Divergence                28.67499
KL Loss                      2.867499
QF Loss                      382.85568
VF Loss                      190.84865
Policy Loss                  -696.4181
Q Predictions Mean           689.45325
Q Predictions Std            540.96655
Q Predictions Max            1691.5641
Q Predictions Min            76.65658
V Predictions Mean           705.0094
V Predictions Std            542.18335
V Predictions Max            1684.986
V Predictions Min            90.26904
Log Pis Mean                 -1.3285109
Log Pis Std                  3.2333457
Log Pis Max                  8.773729
Log Pis Min                  -6.0632634
Policy mu Mean               0.03206118
Policy mu Std                0.7571548
Policy mu Max                2.4250805
Policy mu Min                -2.6268053
Policy log std Mean          -0.45324895
Policy log std Std           0.22530477
Policy log std Max           -0.18276295
Policy log std Min           -2.0907576
Z mean eval                  2.1034696
Z variance eval              0.012544232
total_rewards                [4508.7953424  4590.00270581 4478.14366653 4689.3375336  4778.05999114
 4364.29345017 4456.02586868 4678.04087447 4705.05716615 4497.09983877]
total_rewards_mean           4574.485643771712
total_rewards_std            126.66723752908682
total_rewards_max            4778.059991143529
total_rewards_min            4364.29345016883
Number of train steps total  92000
Number of env steps total    278000
Number of rollouts total     0
Train Time (s)               136.93847764795646
(Previous) Eval Time (s)     29.659422919154167
Sample Time (s)              9.67853239690885
Epoch Time (s)               176.27643296401948
Total Train Time (s)         4166.179544260725
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:00:45.556064 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #22 | Epoch Duration: 176.36005640029907
2020-01-13 05:00:45.556261 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #22 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1014817
Z variance train             0.012486455
KL Divergence                28.906452
KL Loss                      2.8906453
QF Loss                      229.36212
VF Loss                      44.130836
Policy Loss                  -645.7749
Q Predictions Mean           637.2941
Q Predictions Std            529.80927
Q Predictions Max            1708.951
Q Predictions Min            67.01189
V Predictions Mean           646.35004
V Predictions Std            529.95575
V Predictions Max            1720.7213
V Predictions Min            71.77211
Log Pis Mean                 -1.5745406
Log Pis Std                  3.0480723
Log Pis Max                  11.487847
Log Pis Min                  -7.2893543
Policy mu Mean               0.015818255
Policy mu Std                0.71036273
Policy mu Max                2.4802086
Policy mu Min                -2.3022852
Policy log std Mean          -0.4477997
Policy log std Std           0.22469881
Policy log std Max           -0.11985628
Policy log std Min           -1.8561778
Z mean eval                  2.152614
Z variance eval              0.0064386735
total_rewards                [4386.50136399 4422.26333637 4541.62185822 4588.36982374 4620.0424404
 4531.79886835 4428.4804518  4526.60347199 4407.08605277 4514.1287171 ]
total_rewards_mean           4496.689638472763
total_rewards_std            76.44195013385107
total_rewards_max            4620.042440398259
total_rewards_min            4386.501363986796
Number of train steps total  96000
Number of env steps total    290000
Number of rollouts total     0
Train Time (s)               139.99108413187787
(Previous) Eval Time (s)     29.834366826806217
Sample Time (s)              9.704217810183764
Epoch Time (s)               179.52966876886785
Total Train Time (s)         4345.799460324924
Epoch                        23
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:03:45.178846 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #23 | Epoch Duration: 179.62241077423096
2020-01-13 05:03:45.179215 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1560915
Z variance train             0.006420909
KL Divergence                31.44335
KL Loss                      3.144335
QF Loss                      234.54868
VF Loss                      96.42402
Policy Loss                  -718.91345
Q Predictions Mean           711.1576
Q Predictions Std            558.226
Q Predictions Max            1762.4148
Q Predictions Min            82.48784
V Predictions Mean           722.9
V Predictions Std            559.8438
V Predictions Max            1755.1619
V Predictions Min            89.61056
Log Pis Mean                 -1.4393816
Log Pis Std                  3.034569
Log Pis Max                  9.084289
Log Pis Min                  -6.348898
Policy mu Mean               0.0034131955
Policy mu Std                0.7578485
Policy mu Max                2.61989
Policy mu Min                -2.4492407
Policy log std Mean          -0.45058176
Policy log std Std           0.22086625
Policy log std Max           -0.1475388
Policy log std Min           -1.8913441
Z mean eval                  2.1043952
Z variance eval              0.012276087
total_rewards                [4158.29490261 4418.41680707 4469.18038547 4407.71484567 4385.38706083
 4427.22344896 4563.33203754 4370.76581201 4344.05107295 4358.07081193]
total_rewards_mean           4390.243718504051
total_rewards_std            97.99444516326724
total_rewards_max            4563.332037542755
total_rewards_min            4158.294902608507
Number of train steps total  100000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               145.693601696752
(Previous) Eval Time (s)     30.00818700855598
Sample Time (s)              10.205019845161587
Epoch Time (s)               185.90680855046958
Total Train Time (s)         4531.793544896413
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:06:51.173631 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #24 | Epoch Duration: 185.99419045448303
2020-01-13 05:06:51.173899 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1015556
Z variance train             0.012275374
KL Divergence                30.165888
KL Loss                      3.016589
QF Loss                      270.86206
VF Loss                      152.7073
Policy Loss                  -686.7179
Q Predictions Mean           682.7369
Q Predictions Std            565.0525
Q Predictions Max            1764.8596
Q Predictions Min            69.8864
V Predictions Mean           692.0461
V Predictions Std            566.40765
V Predictions Max            1754.1198
V Predictions Min            76.27146
Log Pis Mean                 -1.3101013
Log Pis Std                  3.1710107
Log Pis Max                  12.364924
Log Pis Min                  -6.7979608
Policy mu Mean               -0.030437822
Policy mu Std                0.7459782
Policy mu Max                3.7669668
Policy mu Min                -2.5283887
Policy log std Mean          -0.43772817
Policy log std Std           0.20911577
Policy log std Max           -0.13612133
Policy log std Min           -1.961273
Z mean eval                  2.109567
Z variance eval              0.006008694
total_rewards                [4674.41131747 4706.86633592 4615.96564803 4693.39674345 4815.51554771
 4794.01590176 4827.26734046 4859.91484356 4734.45355073 4752.2211    ]
total_rewards_mean           4747.402832908334
total_rewards_std            72.9408472656618
total_rewards_max            4859.9148435589705
total_rewards_min            4615.96564803397
Number of train steps total  104000
Number of env steps total    314000
Number of rollouts total     0
Train Time (s)               145.0594505816698
(Previous) Eval Time (s)     29.29925661208108
Sample Time (s)              10.269540433771908
Epoch Time (s)               184.6282476275228
Total Train Time (s)         4716.536315409467
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:09:55.918236 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #25 | Epoch Duration: 184.74416065216064
2020-01-13 05:09:55.918580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1069324
Z variance train             0.0059761778
KL Divergence                32.467567
KL Loss                      3.2467568
QF Loss                      430.35516
VF Loss                      113.64252
Policy Loss                  -652.6116
Q Predictions Mean           642.47876
Q Predictions Std            570.6855
Q Predictions Max            1746.0643
Q Predictions Min            61.094395
V Predictions Mean           658.38696
V Predictions Std            571.68555
V Predictions Max            1751.9493
V Predictions Min            75.52189
Log Pis Mean                 -1.4582086
Log Pis Std                  3.262673
Log Pis Max                  8.994139
Log Pis Min                  -7.873481
Policy mu Mean               -0.004438695
Policy mu Std                0.7295299
Policy mu Max                2.6047447
Policy mu Min                -2.411281
Policy log std Mean          -0.44278923
Policy log std Std           0.22586991
Policy log std Max           -0.14189085
Policy log std Min           -1.9744833
Z mean eval                  2.1199965
Z variance eval              0.017043285
total_rewards                [4670.9383559  4963.41743254 4833.32986848 4644.41411435 4702.44808469
 4780.15379029 4579.02243871 4646.41647444 4722.98193126 4672.46482013]
total_rewards_mean           4721.5587310801175
total_rewards_std            105.676828886763
total_rewards_max            4963.417432538868
total_rewards_min            4579.022438713819
Number of train steps total  108000
Number of env steps total    326000
Number of rollouts total     0
Train Time (s)               145.3807795541361
(Previous) Eval Time (s)     29.825206984300166
Sample Time (s)              10.13071264559403
Epoch Time (s)               185.3366991840303
Total Train Time (s)         4901.9714841274545
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:13:01.354561 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #26 | Epoch Duration: 185.43572068214417
2020-01-13 05:13:01.354799 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1186569
Z variance train             0.016959604
KL Divergence                30.437723
KL Loss                      3.0437725
QF Loss                      248.0378
VF Loss                      99.18346
Policy Loss                  -707.2911
Q Predictions Mean           703.9597
Q Predictions Std            602.25256
Q Predictions Max            1820.4639
Q Predictions Min            68.527336
V Predictions Mean           707.2534
V Predictions Std            607.2852
V Predictions Max            1816.116
V Predictions Min            63.56658
Log Pis Mean                 -1.4303405
Log Pis Std                  3.1259248
Log Pis Max                  9.80846
Log Pis Min                  -6.4317484
Policy mu Mean               -0.053317606
Policy mu Std                0.757048
Policy mu Max                2.4817348
Policy mu Min                -2.964065
Policy log std Mean          -0.43340537
Policy log std Std           0.22247656
Policy log std Max           -0.1546616
Policy log std Min           -2.13376
Z mean eval                  2.1110215
Z variance eval              0.0215013
total_rewards                [4942.847207   4818.81870314 4786.85754587 4915.88387349  866.93114477
 4791.0969494  4994.24376896 4907.19255862 4908.89085153 4877.68052453]
total_rewards_mean           4481.044312731652
total_rewards_std            1206.36877496575
total_rewards_max            4994.243768963913
total_rewards_min            866.9311447664874
Number of train steps total  112000
Number of env steps total    338000
Number of rollouts total     0
Train Time (s)               144.18067615991458
(Previous) Eval Time (s)     30.826987565029413
Sample Time (s)              10.120251310057938
Epoch Time (s)               185.12791503500193
Total Train Time (s)         5087.17973590875
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:16:06.563983 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #27 | Epoch Duration: 185.2090072631836
2020-01-13 05:16:06.564208 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1119301
Z variance train             0.021515464
KL Divergence                29.851763
KL Loss                      2.9851763
QF Loss                      602.24805
VF Loss                      112.76834
Policy Loss                  -680.94464
Q Predictions Mean           673.10913
Q Predictions Std            593.21497
Q Predictions Max            1885.1666
Q Predictions Min            63.88822
V Predictions Mean           682.6601
V Predictions Std            595.27637
V Predictions Max            1879.8964
V Predictions Min            62.724743
Log Pis Mean                 -1.3530844
Log Pis Std                  3.280138
Log Pis Max                  12.090601
Log Pis Min                  -7.5672026
Policy mu Mean               0.0058047753
Policy mu Std                0.7358404
Policy mu Max                2.6127095
Policy mu Min                -3.117839
Policy log std Mean          -0.44839573
Policy log std Std           0.22369616
Policy log std Max           -0.10885444
Policy log std Min           -1.8908439
Z mean eval                  2.1111743
Z variance eval              0.0100240065
total_rewards                [4825.47685068 4572.37104485 5061.02095815 4676.97503541 4794.68229416
 5176.89254421 5346.16674642 5189.94592126 4962.34596905 4854.72137394]
total_rewards_mean           4946.059873811193
total_rewards_std            233.27646108741465
total_rewards_max            5346.166746415366
total_rewards_min            4572.371044848234
Number of train steps total  116000
Number of env steps total    350000
Number of rollouts total     0
Train Time (s)               136.56897647678852
(Previous) Eval Time (s)     29.90249990299344
Sample Time (s)              9.793058508541435
Epoch Time (s)               176.2645348883234
Total Train Time (s)         5263.535866845865
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:19:02.922485 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #28 | Epoch Duration: 176.35808873176575
2020-01-13 05:19:02.922811 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.111857
Z variance train             0.01001667
KL Divergence                30.850431
KL Loss                      3.0850432
QF Loss                      406.57465
VF Loss                      84.1924
Policy Loss                  -729.58185
Q Predictions Mean           724.7718
Q Predictions Std            627.0113
Q Predictions Max            1905.2603
Q Predictions Min            57.441727
V Predictions Mean           731.7296
V Predictions Std            627.35535
V Predictions Max            1906.0038
V Predictions Min            59.71011
Log Pis Mean                 -1.3786867
Log Pis Std                  3.4349482
Log Pis Max                  10.065784
Log Pis Min                  -6.592848
Policy mu Mean               0.02619291
Policy mu Std                0.73529124
Policy mu Max                2.7412038
Policy mu Min                -2.2242105
Policy log std Mean          -0.4527944
Policy log std Std           0.22347276
Policy log std Max           -0.13007146
Policy log std Min           -1.9190077
Z mean eval                  2.1680627
Z variance eval              0.016040947
total_rewards                [4807.82000717 5162.92191458 4862.63675134 4833.73281823 4992.91345187
 5060.2391279  4673.11463257 4746.20707863 4741.3568128  4870.5026323 ]
total_rewards_mean           4875.144522739092
total_rewards_std            145.84613957364127
total_rewards_max            5162.921914582679
total_rewards_min            4673.114632574176
Number of train steps total  120000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               135.70186604978517
(Previous) Eval Time (s)     29.753253877628595
Sample Time (s)              8.3936552926898
Epoch Time (s)               173.84877522010356
Total Train Time (s)         5437.576032161713
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:21:56.963072 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #29 | Epoch Duration: 174.0400424003601
2020-01-13 05:21:56.963316 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1663036
Z variance train             0.016079992
KL Divergence                30.404533
KL Loss                      3.0404534
QF Loss                      563.7984
VF Loss                      62.089672
Policy Loss                  -714.21295
Q Predictions Mean           704.1423
Q Predictions Std            616.4818
Q Predictions Max            1927.1195
Q Predictions Min            59.486504
V Predictions Mean           714.4134
V Predictions Std            620.5377
V Predictions Max            1916.7892
V Predictions Min            71.528946
Log Pis Mean                 -1.3700418
Log Pis Std                  3.3520048
Log Pis Max                  11.7546215
Log Pis Min                  -7.4433756
Policy mu Mean               -0.043243315
Policy mu Std                0.71753204
Policy mu Max                3.0051122
Policy mu Min                -2.603621
Policy log std Mean          -0.43904528
Policy log std Std           0.21353832
Policy log std Max           -0.13361132
Policy log std Min           -2.0866098
Z mean eval                  2.0805879
Z variance eval              0.011595969
total_rewards                [5113.48249276 5135.22408429 4987.15902774 5194.39066094 5030.82394674
 5047.94210136 5077.93156216 5255.90487718 4968.09959184 5242.75514117]
total_rewards_mean           5105.371348616238
total_rewards_std            96.3546198117572
total_rewards_max            5255.904877175152
total_rewards_min            4968.099591842125
Number of train steps total  124000
Number of env steps total    374000
Number of rollouts total     0
Train Time (s)               140.85038622980937
(Previous) Eval Time (s)     29.891151153016835
Sample Time (s)              9.359172977972776
Epoch Time (s)               180.10071036079898
Total Train Time (s)         5617.780532153789
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:24:57.168925 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #30 | Epoch Duration: 180.20545268058777
2020-01-13 05:24:57.169133 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0811143
Z variance train             0.011618823
KL Divergence                30.354874
KL Loss                      3.0354874
QF Loss                      280.776
VF Loss                      126.556145
Policy Loss                  -774.7683
Q Predictions Mean           769.2843
Q Predictions Std            639.33417
Q Predictions Max            1975.0485
Q Predictions Min            43.74199
V Predictions Mean           776.7469
V Predictions Std            642.0582
V Predictions Max            1951.678
V Predictions Min            59.901176
Log Pis Mean                 -1.2383507
Log Pis Std                  3.4634314
Log Pis Max                  11.389447
Log Pis Min                  -8.429118
Policy mu Mean               -0.026933393
Policy mu Std                0.76745445
Policy mu Max                2.6364625
Policy mu Min                -2.3934
Policy log std Mean          -0.45716357
Policy log std Std           0.21763717
Policy log std Max           -0.112641275
Policy log std Min           -1.7996583
Z mean eval                  2.132667
Z variance eval              0.011667515
total_rewards                [4784.90890619 4528.57320011 4889.22805569 4780.41956832 4480.03486013
 4756.62020714 4698.20453827 4687.77857377 4778.69819182 4745.00179581]
total_rewards_mean           4712.946789726059
total_rewards_std            117.11392104957731
total_rewards_max            4889.228055685549
total_rewards_min            4480.034860127498
Number of train steps total  128000
Number of env steps total    386000
Number of rollouts total     0
Train Time (s)               146.40916913514957
(Previous) Eval Time (s)     29.203535475302488
Sample Time (s)              10.153424886520952
Epoch Time (s)               185.766129496973
Total Train Time (s)         5803.640927994158
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:28:03.032544 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #31 | Epoch Duration: 185.86324071884155
2020-01-13 05:28:03.032832 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1307087
Z variance train             0.0116647165
KL Divergence                32.182602
KL Loss                      3.2182603
QF Loss                      311.78613
VF Loss                      168.12373
Policy Loss                  -663.3345
Q Predictions Mean           660.07745
Q Predictions Std            643.90356
Q Predictions Max            1969.8213
Q Predictions Min            54.821613
V Predictions Mean           662.2733
V Predictions Std            648.0559
V Predictions Max            1978.194
V Predictions Min            60.533672
Log Pis Mean                 -1.6306324
Log Pis Std                  3.2567031
Log Pis Max                  11.8490715
Log Pis Min                  -5.9382443
Policy mu Mean               -0.033399824
Policy mu Std                0.7032704
Policy mu Max                3.0315473
Policy mu Min                -3.0781054
Policy log std Mean          -0.42198253
Policy log std Std           0.20011961
Policy log std Max           -0.13612092
Policy log std Min           -1.8319712
Z mean eval                  2.11301
Z variance eval              0.014936668
total_rewards                [5433.1608387  5135.58947173 5476.30756074  361.42995491 5349.49380355
 5118.88633009 5268.01580436 5432.71259084 5206.52451457 5222.33425102]
total_rewards_mean           4800.445512051221
total_rewards_std            1484.5346498554034
total_rewards_max            5476.3075607402625
total_rewards_min            361.4299549093059
Number of train steps total  132000
Number of env steps total    398000
Number of rollouts total     0
Train Time (s)               145.38885322399437
(Previous) Eval Time (s)     30.179380156099796
Sample Time (s)              9.809914517216384
Epoch Time (s)               185.37814789731055
Total Train Time (s)         5989.124340560287
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:31:08.517136 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #32 | Epoch Duration: 185.4840636253357
2020-01-13 05:31:08.517472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #32 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1112041
Z variance train             0.014915159
KL Divergence                33.03687
KL Loss                      3.3036869
QF Loss                      256.3758
VF Loss                      249.41118
Policy Loss                  -766.58545
Q Predictions Mean           762.4038
Q Predictions Std            674.1757
Q Predictions Max            2005.0723
Q Predictions Min            -13.12916
V Predictions Mean           778.55194
V Predictions Std            679.4114
V Predictions Max            2007.1013
V Predictions Min            -21.549023
Log Pis Mean                 -1.1181793
Log Pis Std                  3.3534179
Log Pis Max                  9.639143
Log Pis Min                  -5.9578457
Policy mu Mean               0.0021903014
Policy mu Std                0.77222115
Policy mu Max                2.7209527
Policy mu Min                -2.2654984
Policy log std Mean          -0.4551076
Policy log std Std           0.24342433
Policy log std Max           -0.09902355
Policy log std Min           -2.0581264
Z mean eval                  2.127005
Z variance eval              0.01039577
total_rewards                [5300.83096513 5353.5809404  5497.65532438 5213.80424065 5350.5527771
 5277.05594688 5444.93077508 5300.55184499 5394.45409285 5168.47018729]
total_rewards_mean           5330.18870947615
total_rewards_std            95.16526482731577
total_rewards_max            5497.655324380367
total_rewards_min            5168.470187293002
Number of train steps total  136000
Number of env steps total    410000
Number of rollouts total     0
Train Time (s)               144.64169518183917
(Previous) Eval Time (s)     31.07165264338255
Sample Time (s)              10.133738869801164
Epoch Time (s)               185.84708669502288
Total Train Time (s)         6175.058829740621
Epoch                        33
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:34:14.453183 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #33 | Epoch Duration: 185.93549919128418
2020-01-13 05:34:14.453462 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1236777
Z variance train             0.010397362
KL Divergence                34.706795
KL Loss                      3.4706795
QF Loss                      347.06653
VF Loss                      144.34308
Policy Loss                  -725.11383
Q Predictions Mean           713.9959
Q Predictions Std            667.07324
Q Predictions Max            2025.7898
Q Predictions Min            42.64721
V Predictions Mean           730.64124
V Predictions Std            670.2611
V Predictions Max            2018.187
V Predictions Min            42.875153
Log Pis Mean                 -1.1803313
Log Pis Std                  3.6233332
Log Pis Max                  15.080845
Log Pis Min                  -5.1907196
Policy mu Mean               -0.06262204
Policy mu Std                0.7540308
Policy mu Max                2.3648534
Policy mu Min                -2.5772035
Policy log std Mean          -0.4431738
Policy log std Std           0.22888418
Policy log std Max           -0.1306504
Policy log std Min           -1.9986396
Z mean eval                  2.1250343
Z variance eval              0.008559846
total_rewards                [5273.91599055 5209.32288153 5293.51067445 5356.64445065 5200.54020577
 5191.52684763 5312.09851736 5336.2667891  5294.41391835 5400.30824165]
total_rewards_mean           5286.854851704283
total_rewards_std            66.05963099987049
total_rewards_max            5400.308241645335
total_rewards_min            5191.52684763333
Number of train steps total  140000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               144.823901578784
(Previous) Eval Time (s)     30.424145264085382
Sample Time (s)              10.149825940839946
Epoch Time (s)               185.39787278370932
Total Train Time (s)         6360.544444364961
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:37:19.940029 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #34 | Epoch Duration: 185.48636531829834
2020-01-13 05:37:19.940263 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.125375
Z variance train             0.008522726
KL Divergence                33.586365
KL Loss                      3.3586366
QF Loss                      457.00793
VF Loss                      76.90333
Policy Loss                  -797.9235
Q Predictions Mean           793.6618
Q Predictions Std            676.78705
Q Predictions Max            2026.4607
Q Predictions Min            34.352238
V Predictions Mean           800.93774
V Predictions Std            675.83484
V Predictions Max            2029.3434
V Predictions Min            50.302105
Log Pis Mean                 -1.2723565
Log Pis Std                  3.394568
Log Pis Max                  10.749321
Log Pis Min                  -6.1693077
Policy mu Mean               -0.009927802
Policy mu Std                0.77478814
Policy mu Max                3.0453033
Policy mu Min                -2.9576368
Policy log std Mean          -0.46181366
Policy log std Std           0.23282771
Policy log std Max           -0.14758363
Policy log std Min           -1.9649429
Z mean eval                  2.089369
Z variance eval              0.024710737
total_rewards                [5274.15073092 5277.6265512  5400.34284242 5132.29817512 5169.28050867
 5187.34027239 5047.72803838 5158.64583696 5156.78661368 5128.73778141]
total_rewards_mean           5193.29373511451
total_rewards_std            94.20288613609317
total_rewards_max            5400.342842421068
total_rewards_min            5047.728038382331
Number of train steps total  144000
Number of env steps total    434000
Number of rollouts total     0
Train Time (s)               136.50363826099783
(Previous) Eval Time (s)     29.57113266317174
Sample Time (s)              8.391968079842627
Epoch Time (s)               174.4667390040122
Total Train Time (s)         6535.091781661846
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:40:14.488496 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #35 | Epoch Duration: 174.54808020591736
2020-01-13 05:40:14.488689 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0930984
Z variance train             0.024696026
KL Divergence                30.17097
KL Loss                      3.0170972
QF Loss                      172.45114
VF Loss                      80.69656
Policy Loss                  -705.8486
Q Predictions Mean           699.07886
Q Predictions Std            676.1801
Q Predictions Max            2030.0559
Q Predictions Min            47.719612
V Predictions Mean           705.38635
V Predictions Std            679.897
V Predictions Max            2023.9681
V Predictions Min            56.16746
Log Pis Mean                 -1.8382403
Log Pis Std                  3.1650422
Log Pis Max                  8.768512
Log Pis Min                  -7.194309
Policy mu Mean               -0.02230967
Policy mu Std                0.67155063
Policy mu Max                2.4408631
Policy mu Min                -2.1666954
Policy log std Mean          -0.43884453
Policy log std Std           0.22316152
Policy log std Max           -0.13469201
Policy log std Min           -2.2042902
Z mean eval                  2.0887468
Z variance eval              0.012059931
total_rewards                [5413.81159856 5205.85019167 5218.36484802 5552.19500094 5117.67533731
 4964.18769714 5189.58329396 5320.84851921 4921.2417794  5406.32321664]
total_rewards_mean           5231.008148284702
total_rewards_std            189.1788143678505
total_rewards_max            5552.195000940107
total_rewards_min            4921.241779400807
Number of train steps total  148000
Number of env steps total    446000
Number of rollouts total     0
Train Time (s)               135.7681331699714
(Previous) Eval Time (s)     28.03786137374118
Sample Time (s)              9.4532196004875
Epoch Time (s)               173.2592141442001
Total Train Time (s)         6708.441079930868
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:43:07.839223 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #36 | Epoch Duration: 173.35036516189575
2020-01-13 05:43:07.839427 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0873275
Z variance train             0.012058547
KL Divergence                33.247093
KL Loss                      3.3247094
QF Loss                      1128.5049
VF Loss                      109.85789
Policy Loss                  -751.4971
Q Predictions Mean           742.8972
Q Predictions Std            696.0854
Q Predictions Max            2101.0364
Q Predictions Min            26.854395
V Predictions Mean           748.8655
V Predictions Std            697.5204
V Predictions Max            2096.1687
V Predictions Min            49.611507
Log Pis Mean                 -1.2866598
Log Pis Std                  3.6699426
Log Pis Max                  14.814001
Log Pis Min                  -6.015686
Policy mu Mean               0.008934085
Policy mu Std                0.770703
Policy mu Max                3.8101344
Policy mu Min                -2.626891
Policy log std Mean          -0.44958162
Policy log std Std           0.2225797
Policy log std Max           -0.115511954
Policy log std Min           -2.03924
Z mean eval                  2.0796592
Z variance eval              0.011098171
total_rewards                [5334.95663493 5137.06467131 5305.51999883 5304.98581315 5205.28929179
 5398.36318466 5326.17878741 5179.74984137 5415.36462827 5242.2251229 ]
total_rewards_mean           5284.969797462492
total_rewards_std            87.18024104325632
total_rewards_max            5415.364628267873
total_rewards_min            5137.064671312709
Number of train steps total  152000
Number of env steps total    458000
Number of rollouts total     0
Train Time (s)               141.29155340697616
(Previous) Eval Time (s)     29.704610521905124
Sample Time (s)              9.959739256184548
Epoch Time (s)               180.95590318506584
Total Train Time (s)         6889.479961981531
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:46:08.879567 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #37 | Epoch Duration: 181.03998470306396
2020-01-13 05:46:08.879799 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.08241
Z variance train             0.011104988
KL Divergence                33.25738
KL Loss                      3.3257382
QF Loss                      232.23781
VF Loss                      69.57449
Policy Loss                  -792.38257
Q Predictions Mean           782.9426
Q Predictions Std            688.2336
Q Predictions Max            2098.1836
Q Predictions Min            44.27765
V Predictions Mean           789.11664
V Predictions Std            686.8351
V Predictions Max            2081.9678
V Predictions Min            52.04581
Log Pis Mean                 -1.5241786
Log Pis Std                  3.0974643
Log Pis Max                  10.123113
Log Pis Min                  -6.7821503
Policy mu Mean               0.03577825
Policy mu Std                0.70882696
Policy mu Max                2.3377357
Policy mu Min                -2.4868283
Policy log std Mean          -0.44641578
Policy log std Std           0.22087532
Policy log std Max           -0.11658883
Policy log std Min           -2.0143352
Z mean eval                  2.0239816
Z variance eval              0.023644825
total_rewards                [5311.37461803 5491.95275994 5473.11379197 5461.74755427 5274.13830178
 5450.28773243 5352.84344463 5463.35674725 5555.57090106 5274.2170013 ]
total_rewards_mean           5410.8602852662
total_rewards_std            94.29751148752156
total_rewards_max            5555.570901056541
total_rewards_min            5274.138301780462
Number of train steps total  156000
Number of env steps total    470000
Number of rollouts total     0
Train Time (s)               145.92083815531805
(Previous) Eval Time (s)     30.142375172115862
Sample Time (s)              8.880198231432587
Epoch Time (s)               184.9434115588665
Total Train Time (s)         7074.771609743126
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:49:14.172679 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #38 | Epoch Duration: 185.2927234172821
2020-01-13 05:49:14.172885 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0242171
Z variance train             0.023517527
KL Divergence                29.768917
KL Loss                      2.9768918
QF Loss                      242.06262
VF Loss                      135.959
Policy Loss                  -721.5627
Q Predictions Mean           713.3756
Q Predictions Std            681.03906
Q Predictions Max            2063.7078
Q Predictions Min            46.594822
V Predictions Mean           717.7269
V Predictions Std            687.16626
V Predictions Max            2073.2273
V Predictions Min            46.73326
Log Pis Mean                 -1.4594488
Log Pis Std                  3.3349922
Log Pis Max                  8.617645
Log Pis Min                  -6.7347
Policy mu Mean               -0.0882413
Policy mu Std                0.7164073
Policy mu Max                2.4818325
Policy mu Min                -2.9175324
Policy log std Mean          -0.44580665
Policy log std Std           0.22036304
Policy log std Max           -0.18558769
Policy log std Min           -1.921897
Z mean eval                  2.0659957
Z variance eval              0.013402997
total_rewards                [5493.85811213 5479.77025608 5487.46470401 5627.98518818 1401.08158981
 5501.11524576 5575.36324504 5474.63890624 5472.98551158 5364.02374197]
total_rewards_mean           5087.828650080254
total_rewards_std            1230.642417467878
total_rewards_max            5627.9851881796985
total_rewards_min            1401.0815898083601
Number of train steps total  160000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               144.9335070680827
(Previous) Eval Time (s)     29.64245746191591
Sample Time (s)              10.204035125672817
Epoch Time (s)               184.77999965567142
Total Train Time (s)         7259.633317616768
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:52:19.036262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #39 | Epoch Duration: 184.86322021484375
2020-01-13 05:52:19.036497 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0619087
Z variance train             0.013420628
KL Divergence                32.927216
KL Loss                      3.2927215
QF Loss                      432.8795
VF Loss                      69.76184
Policy Loss                  -755.7325
Q Predictions Mean           743.81085
Q Predictions Std            689.38525
Q Predictions Max            2126.041
Q Predictions Min            42.328392
V Predictions Mean           755.6765
V Predictions Std            688.52423
V Predictions Max            2110.7336
V Predictions Min            46.544228
Log Pis Mean                 -1.2135423
Log Pis Std                  3.58145
Log Pis Max                  18.754414
Log Pis Min                  -6.35511
Policy mu Mean               -0.02385517
Policy mu Std                0.7419053
Policy mu Max                3.1129413
Policy mu Min                -3.2565775
Policy log std Mean          -0.4567825
Policy log std Std           0.24729285
Policy log std Max           -0.17240947
Policy log std Min           -2.0791461
Z mean eval                  2.046611
Z variance eval              0.01066195
total_rewards                [5529.94467473 5710.50265451 5483.81300358 5212.03384876 5455.19799368
 5298.76837771 5038.14248341 5384.20853456 5639.82622532 5307.03173254]
total_rewards_mean           5405.946952879515
total_rewards_std            191.29672179803694
total_rewards_max            5710.502654511004
total_rewards_min            5038.142483407778
Number of train steps total  164000
Number of env steps total    494000
Number of rollouts total     0
Train Time (s)               145.95017660036683
(Previous) Eval Time (s)     30.924102149903774
Sample Time (s)              10.130169194191694
Epoch Time (s)               187.0044479444623
Total Train Time (s)         7446.745163288899
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:55:26.149369 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #40 | Epoch Duration: 187.1126971244812
2020-01-13 05:55:26.149601 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0459092
Z variance train             0.010700364
KL Divergence                34.749542
KL Loss                      3.4749544
QF Loss                      330.9669
VF Loss                      162.09317
Policy Loss                  -825.4133
Q Predictions Mean           809.49207
Q Predictions Std            727.688
Q Predictions Max            2180.005
Q Predictions Min            48.849503
V Predictions Mean           817.70374
V Predictions Std            726.067
V Predictions Max            2183.1904
V Predictions Min            52.15864
Log Pis Mean                 -1.3157625
Log Pis Std                  3.472956
Log Pis Max                  15.361692
Log Pis Min                  -6.770859
Policy mu Mean               0.0033701009
Policy mu Std                0.7615785
Policy mu Max                3.378579
Policy mu Min                -2.7804766
Policy log std Mean          -0.47537985
Policy log std Std           0.23499778
Policy log std Max           -0.19121401
Policy log std Min           -2.1054826
Z mean eval                  2.0245106
Z variance eval              0.013568342
total_rewards                [5569.97933644 5289.78454067 5341.23824577 5739.04796749 5439.13624062
 5766.06998646 1863.40697228 5771.21655172 5899.66477882 5460.67905476]
total_rewards_mean           5214.022367502885
total_rewards_std            1133.4790595155189
total_rewards_max            5899.664778822243
total_rewards_min            1863.4069722804672
Number of train steps total  168000
Number of env steps total    506000
Number of rollouts total     0
Train Time (s)               144.16163227893412
(Previous) Eval Time (s)     30.401015628129244
Sample Time (s)              9.78693269053474
Epoch Time (s)               184.3495805975981
Total Train Time (s)         7631.172810378019
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:58:30.578314 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #41 | Epoch Duration: 184.4285604953766
2020-01-13 05:58:30.578521 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0223992
Z variance train             0.013627904
KL Divergence                34.138607
KL Loss                      3.4138608
QF Loss                      351.7688
VF Loss                      111.29303
Policy Loss                  -744.191
Q Predictions Mean           737.3537
Q Predictions Std            725.1245
Q Predictions Max            2174.7258
Q Predictions Min            29.611792
V Predictions Mean           746.2742
V Predictions Std            728.67725
V Predictions Max            2177.8867
V Predictions Min            48.65062
Log Pis Mean                 -1.445747
Log Pis Std                  3.5766366
Log Pis Max                  9.892241
Log Pis Min                  -7.48555
Policy mu Mean               0.015087773
Policy mu Std                0.7478343
Policy mu Max                3.2389936
Policy mu Min                -2.3513424
Policy log std Mean          -0.43230143
Policy log std Std           0.23825783
Policy log std Max           -0.11919823
Policy log std Min           -2.1189148
Z mean eval                  2.0257082
Z variance eval              0.013302381
total_rewards                [5389.82703121 5632.84405194 5748.95998634 5415.69896913 5602.08546265
 5643.4935983  5300.92257808 5457.77165824 5400.71454473 5629.55573936]
total_rewards_mean           5522.187361998166
total_rewards_std            138.93155577335028
total_rewards_max            5748.959986336664
total_rewards_min            5300.922578084906
Number of train steps total  172000
Number of env steps total    518000
Number of rollouts total     0
Train Time (s)               136.38128370186314
(Previous) Eval Time (s)     29.56881877500564
Sample Time (s)              9.726124956738204
Epoch Time (s)               175.67622743360698
Total Train Time (s)         7807.0858525079675
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:26.492609 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #42 | Epoch Duration: 175.91394424438477
2020-01-13 06:01:26.492797 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.028072
Z variance train             0.0133163165
KL Divergence                33.51174
KL Loss                      3.351174
QF Loss                      167.13824
VF Loss                      67.8954
Policy Loss                  -626.7362
Q Predictions Mean           618.28705
Q Predictions Std            666.8469
Q Predictions Max            2276.362
Q Predictions Min            37.0786
V Predictions Mean           621.95013
V Predictions Std            665.74725
V Predictions Max            2279.5066
V Predictions Min            41.056465
Log Pis Mean                 -1.9568083
Log Pis Std                  3.1081111
Log Pis Max                  12.2612
Log Pis Min                  -7.6645765
Policy mu Mean               0.009987526
Policy mu Std                0.65283734
Policy mu Max                2.6159077
Policy mu Min                -2.9470804
Policy log std Mean          -0.40909562
Policy log std Std           0.20550963
Policy log std Max           -0.09007484
Policy log std Min           -2.2105868
Z mean eval                  1.9998331
Z variance eval              0.015191587
total_rewards                [5333.46985972 5620.06031599 5338.95435507 5007.98680638 2902.99968361
 5422.14880173 5123.28270024 5195.33759645 5121.50982454 2591.87261752]
total_rewards_mean           4765.762256125842
total_rewards_std            1024.9280485186036
total_rewards_max            5620.060315992689
total_rewards_min            2591.872617517799
Number of train steps total  176000
Number of env steps total    530000
Number of rollouts total     0
Train Time (s)               136.66602864395827
(Previous) Eval Time (s)     28.56791253387928
Sample Time (s)              9.697803395800292
Epoch Time (s)               174.93174457363784
Total Train Time (s)         7982.102426167112
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:04:21.510934 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #43 | Epoch Duration: 175.01798248291016
2020-01-13 06:04:21.511226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0013242
Z variance train             0.015229998
KL Divergence                33.781242
KL Loss                      3.3781242
QF Loss                      2346.8125
VF Loss                      102.80548
Policy Loss                  -755.1904
Q Predictions Mean           753.85345
Q Predictions Std            739.6439
Q Predictions Max            2225.803
Q Predictions Min            42.663425
V Predictions Mean           757.31335
V Predictions Std            741.23224
V Predictions Max            2224.4165
V Predictions Min            44.712395
Log Pis Mean                 -1.3382711
Log Pis Std                  3.4608383
Log Pis Max                  12.64476
Log Pis Min                  -7.0084515
Policy mu Mean               -0.00047723143
Policy mu Std                0.7108425
Policy mu Max                2.4458432
Policy mu Min                -2.4688253
Policy log std Mean          -0.4501547
Policy log std Std           0.23968478
Policy log std Max           -0.15693119
Policy log std Min           -1.9646797
Z mean eval                  1.9579818
Z variance eval              0.013540564
total_rewards                [6046.26768063 6083.1590032  5770.64077372 5636.30462868 5701.48935783
 5801.07523684 3539.73521096 6071.73362264 5959.66180835 5948.87849363]
total_rewards_mean           5655.894581648079
total_rewards_std            721.1670745600624
total_rewards_max            6083.15900319873
total_rewards_min            3539.735210962765
Number of train steps total  180000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               140.2927076742053
(Previous) Eval Time (s)     29.36977302795276
Sample Time (s)              9.674066637642682
Epoch Time (s)               179.33654733980075
Total Train Time (s)         8161.725898680277
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:07:21.136968 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #44 | Epoch Duration: 179.62553310394287
2020-01-13 06:07:21.137309 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9547112
Z variance train             0.013472214
KL Divergence                35.073185
KL Loss                      3.5073185
QF Loss                      299.46506
VF Loss                      174.56305
Policy Loss                  -776.86426
Q Predictions Mean           766.5794
Q Predictions Std            739.317
Q Predictions Max            2184.7747
Q Predictions Min            44.77331
V Predictions Mean           783.205
V Predictions Std            743.0344
V Predictions Max            2187.8677
V Predictions Min            38.266518
Log Pis Mean                 -1.187521
Log Pis Std                  3.8141181
Log Pis Max                  15.618246
Log Pis Min                  -9.7429
Policy mu Mean               -0.033216614
Policy mu Std                0.77083015
Policy mu Max                3.0505178
Policy mu Min                -3.2505
Policy log std Mean          -0.45530033
Policy log std Std           0.22809207
Policy log std Max           -0.1685845
Policy log std Min           -2.0226736
Z mean eval                  1.9959366
Z variance eval              0.011198312
total_rewards                [5136.6288537  5121.92056295 5185.09741802 5225.39496705 5070.79400524
 5254.81550699 5180.04705121 5205.42855253 5074.29492644 5227.75627187]
total_rewards_mean           5168.217811600034
total_rewards_std            61.300009268274074
total_rewards_max            5254.815506992342
total_rewards_min            5070.794005240026
Number of train steps total  184000
Number of env steps total    554000
Number of rollouts total     0
Train Time (s)               146.38729037716985
(Previous) Eval Time (s)     29.891559289302677
Sample Time (s)              10.316315712872893
Epoch Time (s)               186.59516537934542
Total Train Time (s)         8348.406463594642
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:10:27.820561 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #45 | Epoch Duration: 186.68300938606262
2020-01-13 06:10:27.820948 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9951019
Z variance train             0.011227387
KL Divergence                35.187634
KL Loss                      3.5187633
QF Loss                      177.42548
VF Loss                      75.05576
Policy Loss                  -779.0234
Q Predictions Mean           770.44763
Q Predictions Std            765.7434
Q Predictions Max            2302.1384
Q Predictions Min            35.769066
V Predictions Mean           781.68274
V Predictions Std            766.5565
V Predictions Max            2289.6772
V Predictions Min            44.110893
Log Pis Mean                 -1.101001
Log Pis Std                  3.7829368
Log Pis Max                  14.134817
Log Pis Min                  -7.4491644
Policy mu Mean               -0.055205733
Policy mu Std                0.75155884
Policy mu Max                2.3074992
Policy mu Min                -2.757326
Policy log std Mean          -0.45108792
Policy log std Std           0.24164055
Policy log std Max           -0.12751514
Policy log std Min           -2.287738
Z mean eval                  2.0252297
Z variance eval              0.010684384
total_rewards                [5586.96404037 5647.94146236 5657.92902475 5511.71519512 5593.56276381
 5481.37669242 5473.60572403 5644.93123478 5507.73958869 5453.95803264]
total_rewards_mean           5555.972375896872
total_rewards_std            74.95430447337071
total_rewards_max            5657.929024753799
total_rewards_min            5453.958032636678
Number of train steps total  188000
Number of env steps total    566000
Number of rollouts total     0
Train Time (s)               145.38473775284365
(Previous) Eval Time (s)     29.79464071802795
Sample Time (s)              10.364772672299296
Epoch Time (s)               185.5441511431709
Total Train Time (s)         8534.033692013007
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:33.449701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #46 | Epoch Duration: 185.6285116672516
2020-01-13 06:13:33.450022 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #46 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.022629
Z variance train             0.010740251
KL Divergence                35.947765
KL Loss                      3.5947766
QF Loss                      663.33624
VF Loss                      237.8605
Policy Loss                  -767.93353
Q Predictions Mean           762.2193
Q Predictions Std            735.24316
Q Predictions Max            2291.898
Q Predictions Min            36.065548
V Predictions Mean           761.3637
V Predictions Std            737.35
V Predictions Max            2268.31
V Predictions Min            34.546623
Log Pis Mean                 -1.4086276
Log Pis Std                  3.276019
Log Pis Max                  9.829756
Log Pis Min                  -6.0065937
Policy mu Mean               -0.009749838
Policy mu Std                0.7359832
Policy mu Max                2.714432
Policy mu Min                -3.1117702
Policy log std Mean          -0.44244492
Policy log std Std           0.2232737
Policy log std Max           -0.12022716
Policy log std Min           -2.0728297
Z mean eval                  2.0227783
Z variance eval              0.0122182965
total_rewards                [5905.37153623 5995.27921646 5741.05884778 6012.52774576 6206.1421376
 5906.27981982 6132.20205308 5979.78647092 5996.63591432 5998.34250131]
total_rewards_mean           5987.362624327927
total_rewards_std            119.9021897555574
total_rewards_max            6206.142137600635
total_rewards_min            5741.058847775811
Number of train steps total  192000
Number of env steps total    578000
Number of rollouts total     0
Train Time (s)               145.88038295600563
(Previous) Eval Time (s)     30.094539104029536
Sample Time (s)              8.615548849571496
Epoch Time (s)               184.59047090960667
Total Train Time (s)         8718.716361828614
Epoch                        47
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:16:38.133565 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #47 | Epoch Duration: 184.68335437774658
2020-01-13 06:16:38.133795 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.020514
Z variance train             0.012190766
KL Divergence                36.49637
KL Loss                      3.649637
QF Loss                      672.4306
VF Loss                      82.735016
Policy Loss                  -701.0707
Q Predictions Mean           688.7511
Q Predictions Std            708.65735
Q Predictions Max            2271.6125
Q Predictions Min            32.854378
V Predictions Mean           704.5564
V Predictions Std            711.8039
V Predictions Max            2281.5364
V Predictions Min            41.600475
Log Pis Mean                 -1.7622938
Log Pis Std                  3.2515333
Log Pis Max                  8.603565
Log Pis Min                  -9.376663
Policy mu Mean               0.02100342
Policy mu Std                0.6964792
Policy mu Max                2.602166
Policy mu Min                -4.0878415
Policy log std Mean          -0.43501893
Policy log std Std           0.21704914
Policy log std Max           -0.13475406
Policy log std Min           -2.1087604
Z mean eval                  2.0214353
Z variance eval              0.007575405
total_rewards                [5704.76426025 6042.72244848 5708.00278718 6018.5094497  6160.12235388
 5910.37081751 6006.93089241 5874.50881057 5951.32345422 5828.25646094]
total_rewards_mean           5920.5511735145465
total_rewards_std            138.8549765502233
total_rewards_max            6160.122353877564
total_rewards_min            5704.764260251925
Number of train steps total  196000
Number of env steps total    590000
Number of rollouts total     0
Train Time (s)               145.1507929409854
(Previous) Eval Time (s)     29.680855418089777
Sample Time (s)              9.939929692540318
Epoch Time (s)               184.7715780516155
Total Train Time (s)         8903.561380140949
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:19:42.986853 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #48 | Epoch Duration: 184.8529052734375
2020-01-13 06:19:42.987039 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #48 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.020366
Z variance train             0.0075940983
KL Divergence                37.225876
KL Loss                      3.7225876
QF Loss                      138.6568
VF Loss                      118.63945
Policy Loss                  -791.9998
Q Predictions Mean           784.7882
Q Predictions Std            780.82
Q Predictions Max            2317.0781
Q Predictions Min            29.061998
V Predictions Mean           791.0008
V Predictions Std            784.4512
V Predictions Max            2323.135
V Predictions Min            39.230427
Log Pis Mean                 -1.5225763
Log Pis Std                  3.376581
Log Pis Max                  10.226857
Log Pis Min                  -6.3134823
Policy mu Mean               0.02187184
Policy mu Std                0.7207163
Policy mu Max                2.457533
Policy mu Min                -2.486671
Policy log std Mean          -0.4383665
Policy log std Std           0.23262133
Policy log std Max           -0.06257227
Policy log std Min           -2.234241
Z mean eval                  1.9986794
Z variance eval              0.012147497
total_rewards                [4937.57589549 5424.41366842 5397.53097908 5603.00829508 5552.2801411
 5740.14147581 5427.60769725 5542.55120591 5375.32751268 5485.64379448]
total_rewards_mean           5448.608066530147
total_rewards_std            199.98379674786847
total_rewards_max            5740.14147581393
total_rewards_min            4937.575895488668
Number of train steps total  200000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               136.84946279413998
(Previous) Eval Time (s)     28.259859466925263
Sample Time (s)              9.960918233729899
Epoch Time (s)               175.07024049479514
Total Train Time (s)         9078.709592363331
Epoch                        49
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:22:38.136452 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #49 | Epoch Duration: 175.1492691040039
2020-01-13 06:22:38.136651 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9997886
Z variance train             0.012166022
KL Divergence                34.557003
KL Loss                      3.4557004
QF Loss                      300.1447
VF Loss                      117.547714
Policy Loss                  -709.0722
Q Predictions Mean           699.94525
Q Predictions Std            744.76697
Q Predictions Max            2273.5496
Q Predictions Min            39.53849
V Predictions Mean           707.1188
V Predictions Std            743.399
V Predictions Max            2262.2986
V Predictions Min            39.582207
Log Pis Mean                 -1.5905968
Log Pis Std                  3.557801
Log Pis Max                  18.643559
Log Pis Min                  -7.3986583
Policy mu Mean               -0.022298692
Policy mu Std                0.72428006
Policy mu Max                3.5669618
Policy mu Min                -3.6168427
Policy log std Mean          -0.43313673
Policy log std Std           0.22697999
Policy log std Max           -0.1456872
Policy log std Min           -2.1493595
Z mean eval                  2.0200567
Z variance eval              0.022085
total_rewards                [6196.12090309 6327.35218959 6192.16531401 6374.31732235 6415.13280655
 6425.11530134 6509.86579824 6401.25520093 6241.30025099 3649.88368891]
total_rewards_mean           6073.25087760102
total_rewards_std            813.8984298711019
total_rewards_max            6509.8657982385575
total_rewards_min            3649.883688909649
Number of train steps total  204000
Number of env steps total    614000
Number of rollouts total     0
Train Time (s)               136.49422949412838
(Previous) Eval Time (s)     28.590703245718032
Sample Time (s)              9.858901346568018
Epoch Time (s)               174.94383408641443
Total Train Time (s)         9253.73437367659
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:25:33.162655 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #50 | Epoch Duration: 175.0258595943451
2020-01-13 06:25:33.162842 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0228329
Z variance train             0.022205295
KL Divergence                34.83658
KL Loss                      3.4836578
QF Loss                      238.09766
VF Loss                      134.26517
Policy Loss                  -773.56476
Q Predictions Mean           765.28455
Q Predictions Std            775.1428
Q Predictions Max            2357.061
Q Predictions Min            29.248209
V Predictions Mean           770.372
V Predictions Std            771.3907
V Predictions Max            2362.0613
V Predictions Min            31.201408
Log Pis Mean                 -1.1980177
Log Pis Std                  3.9365504
Log Pis Max                  21.077526
Log Pis Min                  -7.0957804
Policy mu Mean               -0.04984587
Policy mu Std                0.76138204
Policy mu Max                4.1796007
Policy mu Min                -3.1591907
Policy log std Mean          -0.45645896
Policy log std Std           0.23393579
Policy log std Max           -0.061897874
Policy log std Min           -2.0190425
Z mean eval                  2.0216248
Z variance eval              0.012937794
total_rewards                [5616.30520717 5802.79707214 5698.42690402 5974.3138509  5605.38547804
 1193.45023746 6100.34024832 6094.67375726 5705.02182129 5626.82307114]
total_rewards_mean           5341.7537647744575
total_rewards_std            1394.588878844147
total_rewards_max            6100.34024831757
total_rewards_min            1193.4502374642677
Number of train steps total  208000
Number of env steps total    626000
Number of rollouts total     0
Train Time (s)               141.50344343297184
(Previous) Eval Time (s)     30.107366323005408
Sample Time (s)              8.209112584590912
Epoch Time (s)               179.81992234056816
Total Train Time (s)         9433.635950988159
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:28:33.065871 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #51 | Epoch Duration: 179.9028856754303
2020-01-13 06:28:33.066070 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.020715
Z variance train             0.012893537
KL Divergence                36.347546
KL Loss                      3.6347547
QF Loss                      264.14468
VF Loss                      131.97061
Policy Loss                  -793.7319
Q Predictions Mean           785.55115
Q Predictions Std            778.5765
Q Predictions Max            2386.1743
Q Predictions Min            39.65179
V Predictions Mean           802.04895
V Predictions Std            778.99536
V Predictions Max            2394.6665
V Predictions Min            26.23598
Log Pis Mean                 -1.36414
Log Pis Std                  3.4621432
Log Pis Max                  15.368341
Log Pis Min                  -8.164765
Policy mu Mean               4.2557716e-05
Policy mu Std                0.733253
Policy mu Max                2.6704123
Policy mu Min                -3.1985502
Policy log std Mean          -0.45124778
Policy log std Std           0.24137267
Policy log std Max           -0.14931118
Policy log std Min           -2.226027
Z mean eval                  2.011811
Z variance eval              0.024778197
total_rewards                [6255.57402531 6350.06137658 6383.70941585 6458.70815181 6144.06044722
 6326.90801051 6264.44217686 6635.03739276 6368.93525968 6388.10820033]
total_rewards_mean           6357.554445690354
total_rewards_std            124.34666609675156
total_rewards_max            6635.03739275713
total_rewards_min            6144.060447219421
Number of train steps total  212000
Number of env steps total    638000
Number of rollouts total     0
Train Time (s)               146.00531670963392
(Previous) Eval Time (s)     30.054063067305833
Sample Time (s)              10.064983546268195
Epoch Time (s)               186.12436332320794
Total Train Time (s)         9619.853362502996
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:31:39.285283 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #52 | Epoch Duration: 186.21905398368835
2020-01-13 06:31:39.285522 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0130982
Z variance train             0.024825275
KL Divergence                36.523193
KL Loss                      3.6523194
QF Loss                      177.52187
VF Loss                      65.01386
Policy Loss                  -719.1867
Q Predictions Mean           710.6627
Q Predictions Std            766.6698
Q Predictions Max            2394.4631
Q Predictions Min            28.318262
V Predictions Mean           719.22375
V Predictions Std            769.8434
V Predictions Max            2401.3123
V Predictions Min            37.287132
Log Pis Mean                 -1.4834121
Log Pis Std                  3.5309596
Log Pis Max                  23.326643
Log Pis Min                  -5.845746
Policy mu Mean               0.012658595
Policy mu Std                0.7435501
Policy mu Max                3.588356
Policy mu Min                -3.3916745
Policy log std Mean          -0.4346198
Policy log std Std           0.21300694
Policy log std Max           -0.14701214
Policy log std Min           -1.9203289
Z mean eval                  2.0847006
Z variance eval              0.015446501
total_rewards                [6025.52523882 5983.95081071 6296.63738066 6105.82708826 6011.73232854
 6152.8257387  6061.46131356 6280.25019008 6105.77763339 6104.7717107 ]
total_rewards_mean           6112.875943343587
total_rewards_std            100.33417752075411
total_rewards_max            6296.637380658303
total_rewards_min            5983.950810714743
Number of train steps total  216000
Number of env steps total    650000
Number of rollouts total     0
Train Time (s)               145.7795650921762
(Previous) Eval Time (s)     27.729448957834393
Sample Time (s)              10.250517348293215
Epoch Time (s)               183.7595313983038
Total Train Time (s)         9803.918827573303
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:34:43.351919 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #53 | Epoch Duration: 184.06622123718262
2020-01-13 06:34:43.352123 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.079867
Z variance train             0.015394999
KL Divergence                35.514133
KL Loss                      3.5514133
QF Loss                      537.34106
VF Loss                      83.23999
Policy Loss                  -715.6819
Q Predictions Mean           713.14355
Q Predictions Std            740.8512
Q Predictions Max            2413.464
Q Predictions Min            37.475346
V Predictions Mean           718.9589
V Predictions Std            742.64606
V Predictions Max            2404.3345
V Predictions Min            29.783394
Log Pis Mean                 -1.3223438
Log Pis Std                  3.7855055
Log Pis Max                  16.112503
Log Pis Min                  -8.583845
Policy mu Mean               0.014840692
Policy mu Std                0.743543
Policy mu Max                2.9102461
Policy mu Min                -2.5136375
Policy log std Mean          -0.4404409
Policy log std Std           0.23722972
Policy log std Max           -0.13505581
Policy log std Min           -2.199373
Z mean eval                  2.0024207
Z variance eval              0.015083341
total_rewards                [6009.66442587 6092.00307437 6009.16927719 6124.67009831 5935.03373819
 5964.27323624 5841.73725813 5781.12302662 5912.0799988  5958.66268148]
total_rewards_mean           5962.841681520826
total_rewards_std            99.12981984924888
total_rewards_max            6124.670098313331
total_rewards_min            5781.123026622072
Number of train steps total  220000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               146.5333203957416
(Previous) Eval Time (s)     30.662334742955863
Sample Time (s)              10.043531232513487
Epoch Time (s)               187.23918637121096
Total Train Time (s)         9991.322638502344
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:37:50.757399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #54 | Epoch Duration: 187.40513134002686
2020-01-13 06:37:50.757597 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.001494
Z variance train             0.015063735
KL Divergence                35.826508
KL Loss                      3.582651
QF Loss                      588.49646
VF Loss                      95.29492
Policy Loss                  -750.9711
Q Predictions Mean           742.3648
Q Predictions Std            772.2203
Q Predictions Max            2526.168
Q Predictions Min            23.207182
V Predictions Mean           752.2582
V Predictions Std            780.677
V Predictions Max            2521.678
V Predictions Min            29.817118
Log Pis Mean                 -1.3247252
Log Pis Std                  3.7245533
Log Pis Max                  17.207088
Log Pis Min                  -6.634151
Policy mu Mean               -0.024117835
Policy mu Std                0.74851793
Policy mu Max                3.1816857
Policy mu Min                -2.7364032
Policy log std Mean          -0.45783707
Policy log std Std           0.25216967
Policy log std Max           -0.14771533
Policy log std Min           -2.2913451
Z mean eval                  2.0410383
Z variance eval              0.010049472
total_rewards                [5607.26902556 5644.62454966 2118.43142305 2211.704396   5642.01568762
 5734.70921207 5941.78518451 5570.69501941 5462.08998715 5887.03560918]
total_rewards_mean           4982.036009421957
total_rewards_std            1415.0658113794118
total_rewards_max            5941.785184507168
total_rewards_min            2118.4314230524674
Number of train steps total  224000
Number of env steps total    674000
Number of rollouts total     0
Train Time (s)               144.9160492317751
(Previous) Eval Time (s)     29.940693771932274
Sample Time (s)              10.105729040689766
Epoch Time (s)               184.96247204439715
Total Train Time (s)         10176.36445143586
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:40:55.800550 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #55 | Epoch Duration: 185.04280805587769
2020-01-13 06:40:55.800744 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0399833
Z variance train             0.010072621
KL Divergence                37.29926
KL Loss                      3.7299259
QF Loss                      211.71658
VF Loss                      38.691998
Policy Loss                  -782.91907
Q Predictions Mean           774.9159
Q Predictions Std            794.50305
Q Predictions Max            2414.2388
Q Predictions Min            23.070051
V Predictions Mean           783.19855
V Predictions Std            798.3661
V Predictions Max            2421.9614
V Predictions Min            40.185593
Log Pis Mean                 -1.7102668
Log Pis Std                  3.2495668
Log Pis Max                  13.61177
Log Pis Min                  -7.509185
Policy mu Mean               -0.054950777
Policy mu Std                0.7219232
Policy mu Max                2.9777331
Policy mu Min                -2.9590662
Policy log std Mean          -0.43351316
Policy log std Std           0.20816247
Policy log std Max           -0.15943322
Policy log std Min           -2.354859
Z mean eval                  2.0726452
Z variance eval              0.011493018
total_rewards                [6213.39579829 6324.62065921 6359.92668939 6333.07425372 6195.67253832
 6127.12646183 6513.2713117  6203.19302294 6370.03561885 6209.13818508]
total_rewards_mean           6284.945453930175
total_rewards_std            109.2299251039626
total_rewards_max            6513.2713116959685
total_rewards_min            6127.126461826021
Number of train steps total  228000
Number of env steps total    686000
Number of rollouts total     0
Train Time (s)               136.65489468770102
(Previous) Eval Time (s)     29.311760658863932
Sample Time (s)              9.249615291599184
Epoch Time (s)               175.21627063816413
Total Train Time (s)         10351.663042532746
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:43:51.101207 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #56 | Epoch Duration: 175.30029845237732
2020-01-13 06:43:51.101513 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0752823
Z variance train             0.011493772
KL Divergence                37.084053
KL Loss                      3.7084053
QF Loss                      320.82874
VF Loss                      91.77863
Policy Loss                  -731.3432
Q Predictions Mean           724.66394
Q Predictions Std            782.56775
Q Predictions Max            2488.246
Q Predictions Min            12.080773
V Predictions Mean           733.37854
V Predictions Std            789.5003
V Predictions Max            2488.1099
V Predictions Min            27.999922
Log Pis Mean                 -1.5012782
Log Pis Std                  3.4209752
Log Pis Max                  10.709225
Log Pis Min                  -8.692492
Policy mu Mean               0.02107889
Policy mu Std                0.7494929
Policy mu Max                2.923206
Policy mu Min                -3.4715009
Policy log std Mean          -0.43566823
Policy log std Std           0.22600444
Policy log std Max           -0.1626581
Policy log std Min           -2.1621392
Z mean eval                  2.0319107
Z variance eval              0.011216151
total_rewards                [6323.27529509 6233.79883859 6426.09091679 6376.95310045 6175.77442611
 6253.84257941 6189.84438361 6216.26680382 6310.02100532 6291.14173983]
total_rewards_mean           6279.700908901015
total_rewards_std            77.14363167085715
total_rewards_max            6426.090916786859
total_rewards_min            6175.7744261058015
Number of train steps total  232000
Number of env steps total    698000
Number of rollouts total     0
Train Time (s)               136.54908023308963
(Previous) Eval Time (s)     29.112394374795258
Sample Time (s)              9.713238656055182
Epoch Time (s)               175.37471326394007
Total Train Time (s)         10527.118064801209
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:46:46.557518 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #57 | Epoch Duration: 175.45578575134277
2020-01-13 06:46:46.557734 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0309176
Z variance train             0.011210425
KL Divergence                37.552868
KL Loss                      3.755287
QF Loss                      765.89966
VF Loss                      113.75896
Policy Loss                  -870.97235
Q Predictions Mean           864.92725
Q Predictions Std            830.0247
Q Predictions Max            2484.472
Q Predictions Min            1.4011962
V Predictions Mean           875.3922
V Predictions Std            830.66425
V Predictions Max            2474.3567
V Predictions Min            5.7734723
Log Pis Mean                 -0.49818736
Log Pis Std                  4.3156123
Log Pis Max                  22.120754
Log Pis Min                  -5.668517
Policy mu Mean               -0.0032747108
Policy mu Std                0.85680974
Policy mu Max                3.2178266
Policy mu Min                -3.9606266
Policy log std Mean          -0.4664111
Policy log std Std           0.24193934
Policy log std Max           -0.09159917
Policy log std Min           -2.087293
Z mean eval                  2.0310092
Z variance eval              0.101059236
total_rewards                [6245.2245674  6348.32517433 6341.11839365 6332.01283946 6395.87450023
 6334.89580136 6289.00459752 6202.61758663 6251.49971547 6226.43935613]
total_rewards_mean           6296.7012532182125
total_rewards_std            59.765971385092044
total_rewards_max            6395.874500234962
total_rewards_min            6202.617586634584
Number of train steps total  236000
Number of env steps total    710000
Number of rollouts total     0
Train Time (s)               141.60514053795487
(Previous) Eval Time (s)     30.621792658697814
Sample Time (s)              9.757855520118028
Epoch Time (s)               181.9847887167707
Total Train Time (s)         10709.18862709403
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:49:48.629377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #58 | Epoch Duration: 182.07149171829224
2020-01-13 06:49:48.629576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0341835
Z variance train             0.100820564
KL Divergence                32.55957
KL Loss                      3.2559571
QF Loss                      215.61174
VF Loss                      85.60598
Policy Loss                  -900.8065
Q Predictions Mean           890.8659
Q Predictions Std            880.4361
Q Predictions Max            2577.471
Q Predictions Min            7.570378
V Predictions Mean           896.32605
V Predictions Std            879.7057
V Predictions Max            2581.0115
V Predictions Min            21.164135
Log Pis Mean                 -1.2818806
Log Pis Std                  3.4292347
Log Pis Max                  17.136395
Log Pis Min                  -6.3677235
Policy mu Mean               -0.10774199
Policy mu Std                0.77872866
Policy mu Max                3.4362895
Policy mu Min                -4.063019
Policy log std Mean          -0.45525658
Policy log std Std           0.23672932
Policy log std Max           -0.094130754
Policy log std Min           -2.107652
Z mean eval                  2.0841107
Z variance eval              0.019792726
total_rewards                [5995.95094864 6304.12952301 6265.00543231 5991.71055564 6204.25930113
 6233.23377586 6441.06292188 6240.76505834 6203.43652506 6401.27111282]
total_rewards_mean           6228.08251546927
total_rewards_std            139.1475883332303
total_rewards_max            6441.062921881841
total_rewards_min            5991.710555637286
Number of train steps total  240000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               146.80725737893954
(Previous) Eval Time (s)     30.090622069779783
Sample Time (s)              9.617476588115096
Epoch Time (s)               186.51535603683442
Total Train Time (s)         10895.783924493473
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:52:55.226191 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #59 | Epoch Duration: 186.5964720249176
2020-01-13 06:52:55.226382 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0853515
Z variance train             0.019811848
KL Divergence                34.170506
KL Loss                      3.4170506
QF Loss                      751.3261
VF Loss                      62.373405
Policy Loss                  -771.0377
Q Predictions Mean           765.3185
Q Predictions Std            806.8498
Q Predictions Max            2498.7222
Q Predictions Min            14.610027
V Predictions Mean           770.515
V Predictions Std            807.965
V Predictions Max            2498.4827
V Predictions Min            23.997192
Log Pis Mean                 -1.2919998
Log Pis Std                  3.6155052
Log Pis Max                  16.01455
Log Pis Min                  -7.4917984
Policy mu Mean               0.040800486
Policy mu Std                0.76959974
Policy mu Max                2.6661005
Policy mu Min                -2.931451
Policy log std Mean          -0.44043204
Policy log std Std           0.24020322
Policy log std Max           -0.06021738
Policy log std Min           -2.3952565
Z mean eval                  2.0630558
Z variance eval              0.026995635
total_rewards                [6370.1920269  6146.16146701 6249.23076618 6164.1191507  5848.06748432
 6191.88025358 5754.76411196 6168.98222234 6300.02597081 6119.03227351]
total_rewards_mean           6131.24557272978
total_rewards_std            181.10322929855212
total_rewards_max            6370.192026897823
total_rewards_min            5754.764111957032
Number of train steps total  244000
Number of env steps total    734000
Number of rollouts total     0
Train Time (s)               146.3035283833742
(Previous) Eval Time (s)     29.670186700765043
Sample Time (s)              10.22651551431045
Epoch Time (s)               186.2002305984497
Total Train Time (s)         11082.146471789572
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:56:01.589267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #60 | Epoch Duration: 186.36274981498718
2020-01-13 06:56:01.589416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.067231
Z variance train             0.026877647
KL Divergence                34.368607
KL Loss                      3.4368608
QF Loss                      225.0141
VF Loss                      157.39056
Policy Loss                  -780.4479
Q Predictions Mean           774.26764
Q Predictions Std            816.712
Q Predictions Max            2592.868
Q Predictions Min            8.497872
V Predictions Mean           771.391
V Predictions Std            815.8172
V Predictions Max            2572.148
V Predictions Min            24.295061
Log Pis Mean                 -1.123083
Log Pis Std                  3.7649522
Log Pis Max                  22.64935
Log Pis Min                  -7.9086943
Policy mu Mean               -0.028985629
Policy mu Std                0.76789945
Policy mu Max                3.153464
Policy mu Min                -3.719109
Policy log std Mean          -0.42850134
Policy log std Std           0.22554928
Policy log std Max           -0.07855612
Policy log std Min           -2.2403002
Z mean eval                  2.0211747
Z variance eval              0.018558025
total_rewards                [6433.3849868  6360.93778705 6417.65578558 6349.74203388 6542.80815699
 6311.56601459 6285.4622675  6301.87403421 6690.16385276 6407.95818502]
total_rewards_mean           6410.155310437165
total_rewards_std            118.18097622325108
total_rewards_max            6690.16385275586
total_rewards_min            6285.462267498598
Number of train steps total  248000
Number of env steps total    746000
Number of rollouts total     0
Train Time (s)               147.1963484417647
(Previous) Eval Time (s)     30.253149345051497
Sample Time (s)              10.38230992294848
Epoch Time (s)               187.8318077097647
Total Train Time (s)         11270.05816411553
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:59:09.504453 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #61 | Epoch Duration: 187.91487550735474
2020-01-13 06:59:09.504700 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0219684
Z variance train             0.018581294
KL Divergence                34.45094
KL Loss                      3.4450939
QF Loss                      878.1045
VF Loss                      85.503685
Policy Loss                  -731.6569
Q Predictions Mean           726.3269
Q Predictions Std            777.0303
Q Predictions Max            2540.7393
Q Predictions Min            13.938679
V Predictions Mean           730.9416
V Predictions Std            782.4795
V Predictions Max            2550.2869
V Predictions Min            22.52729
Log Pis Mean                 -1.5788031
Log Pis Std                  3.2153296
Log Pis Max                  10.207809
Log Pis Min                  -7.1961718
Policy mu Mean               0.0153930085
Policy mu Std                0.6979507
Policy mu Max                3.0012193
Policy mu Min                -2.6345224
Policy log std Mean          -0.43904033
Policy log std Std           0.22110085
Policy log std Max           -0.12390125
Policy log std Min           -2.2432415
Z mean eval                  2.0845323
Z variance eval              0.022334734
total_rewards                [6366.61701621 6384.11024446 6568.73303968 6295.42817957 6102.76233589
 6183.61101141 6330.61750433 6171.23505039 6264.14353238 6184.54369322]
total_rewards_mean           6285.180160754356
total_rewards_std            128.89422545269178
total_rewards_max            6568.733039680914
total_rewards_min            6102.762335892759
Number of train steps total  252000
Number of env steps total    758000
Number of rollouts total     0
Train Time (s)               145.5235785022378
(Previous) Eval Time (s)     29.591422019992024
Sample Time (s)              9.253565735649318
Epoch Time (s)               184.36856625787914
Total Train Time (s)         11454.50898807589
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:02:13.956100 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #62 | Epoch Duration: 184.45122504234314
2020-01-13 07:02:13.956302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0824246
Z variance train             0.022309205
KL Divergence                36.19129
KL Loss                      3.6191292
QF Loss                      322.16986
VF Loss                      70.66058
Policy Loss                  -807.82043
Q Predictions Mean           798.75244
Q Predictions Std            850.1262
Q Predictions Max            2629.7883
Q Predictions Min            15.207573
V Predictions Mean           810.43176
V Predictions Std            849.1843
V Predictions Max            2633.8652
V Predictions Min            23.480202
Log Pis Mean                 -1.3488173
Log Pis Std                  3.5960279
Log Pis Max                  16.258965
Log Pis Min                  -8.409865
Policy mu Mean               0.038637545
Policy mu Std                0.771289
Policy mu Max                3.528965
Policy mu Min                -3.12379
Policy log std Mean          -0.44522572
Policy log std Std           0.2243221
Policy log std Max           -0.16598448
Policy log std Min           -1.9016123
Z mean eval                  2.0575664
Z variance eval              0.010132386
total_rewards                [6132.84645368 6366.42455312 6116.25993302 6399.38152619 6435.38697597
 6074.41544407 6125.11308572 6290.26757432 6428.52856672 6094.38175663]
total_rewards_mean           6246.300586945788
total_rewards_std            143.4747337144928
total_rewards_max            6435.386975974041
total_rewards_min            6074.415444071763
Number of train steps total  256000
Number of env steps total    770000
Number of rollouts total     0
Train Time (s)               137.21608006302267
(Previous) Eval Time (s)     29.720430211164057
Sample Time (s)              9.89917317731306
Epoch Time (s)               176.8356834514998
Total Train Time (s)         11631.435193000827
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:05:10.884768 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #63 | Epoch Duration: 176.92829942703247
2020-01-13 07:05:10.884971 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0587547
Z variance train             0.010155772
KL Divergence                36.21942
KL Loss                      3.6219423
QF Loss                      350.5406
VF Loss                      69.47083
Policy Loss                  -849.3924
Q Predictions Mean           842.1324
Q Predictions Std            860.4691
Q Predictions Max            2566.3105
Q Predictions Min            27.225986
V Predictions Mean           850.25104
V Predictions Std            855.89294
V Predictions Max            2549.6206
V Predictions Min            18.834291
Log Pis Mean                 -1.4086952
Log Pis Std                  3.2453396
Log Pis Max                  14.813059
Log Pis Min                  -6.4579306
Policy mu Mean               -0.0577248
Policy mu Std                0.7476513
Policy mu Max                2.4120786
Policy mu Min                -2.8667145
Policy log std Mean          -0.44939974
Policy log std Std           0.22550818
Policy log std Max           -0.1722877
Policy log std Min           -2.1234238
Z mean eval                  2.0970235
Z variance eval              0.009141954
total_rewards                [6813.19063628 6496.18668873 6573.46624873 6507.26001662 6440.65337778
 6462.32074609 6370.5955731  6446.04585438 6593.72901707 6757.03985634]
total_rewards_mean           6546.048801512634
total_rewards_std            134.83356852011465
total_rewards_max            6813.190636281009
total_rewards_min            6370.59557309754
Number of train steps total  260000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               136.8551266877912
(Previous) Eval Time (s)     28.946287341881543
Sample Time (s)              9.329092440195382
Epoch Time (s)               175.13050646986812
Total Train Time (s)         11806.647242192179
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:08:06.098032 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #64 | Epoch Duration: 175.21290016174316
2020-01-13 07:08:06.098255 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.097899
Z variance train             0.009149035
KL Divergence                37.78331
KL Loss                      3.778331
QF Loss                      731.89276
VF Loss                      70.59705
Policy Loss                  -836.2
Q Predictions Mean           829.17035
Q Predictions Std            858.44446
Q Predictions Max            2690.2883
Q Predictions Min            11.755645
V Predictions Mean           836.34296
V Predictions Std            861.8573
V Predictions Max            2688.2659
V Predictions Min            19.816572
Log Pis Mean                 -1.4623241
Log Pis Std                  3.2128038
Log Pis Max                  11.183438
Log Pis Min                  -6.821582
Policy mu Mean               -0.09639517
Policy mu Std                0.7436377
Policy mu Max                2.5424304
Policy mu Min                -3.4023108
Policy log std Mean          -0.44705358
Policy log std Std           0.23831262
Policy log std Max           -0.17251745
Policy log std Min           -1.8957052
Z mean eval                  2.0977204
Z variance eval              0.008191605
total_rewards                [5612.61133237 5857.92466128 5997.70710036 5853.44185776 5771.17277938
 5807.62818952 5911.30532305 5990.87683841 5808.12703633 5913.56048911]
total_rewards_mean           5852.435560757928
total_rewards_std            107.51423265077445
total_rewards_max            5997.707100363842
total_rewards_min            5612.611332372267
Number of train steps total  264000
Number of env steps total    794000
Number of rollouts total     0
Train Time (s)               142.88722837343812
(Previous) Eval Time (s)     30.58816342614591
Sample Time (s)              9.553132633678615
Epoch Time (s)               183.02852443326265
Total Train Time (s)         11989.77243155893
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:11:09.225288 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #65 | Epoch Duration: 183.1268548965454
2020-01-13 07:11:09.225522 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0980892
Z variance train             0.008169186
KL Divergence                37.021835
KL Loss                      3.7021835
QF Loss                      242.921
VF Loss                      101.806595
Policy Loss                  -808.25806
Q Predictions Mean           801.36475
Q Predictions Std            844.2115
Q Predictions Max            2601.8503
Q Predictions Min            27.310837
V Predictions Mean           803.95905
V Predictions Std            845.62274
V Predictions Max            2587.27
V Predictions Min            25.614859
Log Pis Mean                 -1.4002728
Log Pis Std                  3.3946464
Log Pis Max                  11.336259
Log Pis Min                  -5.9935427
Policy mu Mean               -0.053187817
Policy mu Std                0.74165964
Policy mu Max                2.9654157
Policy mu Min                -2.8074777
Policy log std Mean          -0.43778172
Policy log std Std           0.22546455
Policy log std Max           -0.11639367
Policy log std Min           -2.2684927
Z mean eval                  2.0876184
Z variance eval              0.016662026
total_rewards                [6360.07636812 6505.3540382  6449.05345397 6699.85198675 6458.85734186
 6452.14763292 6344.38639216 6404.10236575 6427.14408154 6687.89964141]
total_rewards_mean           6478.887330268617
total_rewards_std            116.48819084300024
total_rewards_max            6699.851986745947
total_rewards_min            6344.386392160023
Number of train steps total  268000
Number of env steps total    806000
Number of rollouts total     0
Train Time (s)               146.8734187236987
(Previous) Eval Time (s)     30.47038916684687
Sample Time (s)              10.475639813113958
Epoch Time (s)               187.81944770365953
Total Train Time (s)         12177.674428273924
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:14:17.128399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #66 | Epoch Duration: 187.9026997089386
2020-01-13 07:14:17.128601 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #66 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0879111
Z variance train             0.016592646
KL Divergence                35.975502
KL Loss                      3.5975502
QF Loss                      394.7705
VF Loss                      212.69884
Policy Loss                  -781.58484
Q Predictions Mean           775.0259
Q Predictions Std            826.3335
Q Predictions Max            2626.0715
Q Predictions Min            1.3439921
V Predictions Mean           789.65076
V Predictions Std            830.18256
V Predictions Max            2642.961
V Predictions Min            -1.2743202
Log Pis Mean                 -1.0049441
Log Pis Std                  4.1029935
Log Pis Max                  29.4178
Log Pis Min                  -6.3625846
Policy mu Mean               -0.037278686
Policy mu Std                0.7849453
Policy mu Max                3.766023
Policy mu Min                -4.378941
Policy log std Mean          -0.4545412
Policy log std Std           0.23014368
Policy log std Max           -0.16515332
Policy log std Min           -2.2658677
Z mean eval                  2.1196606
Z variance eval              0.030474503
total_rewards                [6484.79431641 6443.5368431  6531.01526325 6247.27149829 6260.2987938
 6400.69096296 6723.45823186 6621.85864955 6545.54292361 6588.96921251]
total_rewards_mean           6484.743669534025
total_rewards_std            144.22798981346327
total_rewards_max            6723.45823185709
total_rewards_min            6247.271498287647
Number of train steps total  272000
Number of env steps total    818000
Number of rollouts total     0
Train Time (s)               146.02240215800703
(Previous) Eval Time (s)     28.665760532952845
Sample Time (s)              10.138199139852077
Epoch Time (s)               184.82636183081195
Total Train Time (s)         12362.581625858322
Epoch                        67
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:17:22.037375 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #67 | Epoch Duration: 184.90862584114075
2020-01-13 07:17:22.037582 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.123031
Z variance train             0.030573254
KL Divergence                34.447403
KL Loss                      3.4447403
QF Loss                      308.62152
VF Loss                      321.8829
Policy Loss                  -856.62836
Q Predictions Mean           845.5367
Q Predictions Std            843.5463
Q Predictions Max            2630.4436
Q Predictions Min            18.243519
V Predictions Mean           864.38586
V Predictions Std            853.7292
V Predictions Max            2671.7188
V Predictions Min            29.57282
Log Pis Mean                 -0.82533944
Log Pis Std                  4.4015236
Log Pis Max                  27.680353
Log Pis Min                  -7.2369275
Policy mu Mean               -0.027511457
Policy mu Std                0.8367875
Policy mu Max                3.466505
Policy mu Min                -3.752751
Policy log std Mean          -0.45784363
Policy log std Std           0.22754945
Policy log std Max           -0.17017949
Policy log std Min           -2.1027927
Z mean eval                  2.0819879
Z variance eval              0.03330638
total_rewards                [6574.58632018 6595.58962956 6799.62688276 6643.38593174 6637.76132859
 6530.70301412 6619.98852944 6800.95030599 6877.44161103 6348.59684261]
total_rewards_mean           6642.863039603161
total_rewards_std            145.3313759312994
total_rewards_max            6877.441611033236
total_rewards_min            6348.596842605074
Number of train steps total  276000
Number of env steps total    830000
Number of rollouts total     0
Train Time (s)               147.89630915923044
(Previous) Eval Time (s)     30.448077380657196
Sample Time (s)              10.302103366702795
Epoch Time (s)               188.64648990659043
Total Train Time (s)         12551.310798921622
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:20:30.773052 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #68 | Epoch Duration: 188.73532056808472
2020-01-13 07:20:30.773334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0812538
Z variance train             0.033280134
KL Divergence                33.456295
KL Loss                      3.3456295
QF Loss                      353.64917
VF Loss                      95.30408
Policy Loss                  -779.6816
Q Predictions Mean           773.2162
Q Predictions Std            830.7581
Q Predictions Max            2661.9802
Q Predictions Min            18.905039
V Predictions Mean           785.7062
V Predictions Std            831.7262
V Predictions Max            2656.8967
V Predictions Min            19.61838
Log Pis Mean                 -0.99311787
Log Pis Std                  3.9309545
Log Pis Max                  24.429218
Log Pis Min                  -6.563342
Policy mu Mean               -0.01312505
Policy mu Std                0.7650897
Policy mu Max                3.1983604
Policy mu Min                -4.321917
Policy log std Mean          -0.45243225
Policy log std Std           0.2481923
Policy log std Max           -0.12100753
Policy log std Min           -2.205553
Z mean eval                  2.1139324
Z variance eval              0.011336083
total_rewards                [6608.76528687 6593.85894023 6341.15303118 6488.10640037 6673.50829262
 6489.17226835 6328.09197035 6442.03726463 6730.65654861 6453.46375924]
total_rewards_mean           6514.881376244128
total_rewards_std            127.39746220389581
total_rewards_max            6730.6565486055
total_rewards_min            6328.0919703521695
Number of train steps total  280000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               145.71024894108996
(Previous) Eval Time (s)     28.347351814154536
Sample Time (s)              10.079691198654473
Epoch Time (s)               184.13729195389897
Total Train Time (s)         12735.533161858562
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:23:34.992235 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #69 | Epoch Duration: 184.21867203712463
2020-01-13 07:23:34.992440 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #69 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1124444
Z variance train             0.011336419
KL Divergence                37.875526
KL Loss                      3.7875526
QF Loss                      276.01514
VF Loss                      94.648834
Policy Loss                  -864.4716
Q Predictions Mean           855.6941
Q Predictions Std            884.8962
Q Predictions Max            2686.0486
Q Predictions Min            -22.247665
V Predictions Mean           861.6914
V Predictions Std            885.81714
V Predictions Max            2677.923
V Predictions Min            -4.853763
Log Pis Mean                 -0.8568133
Log Pis Std                  3.9086823
Log Pis Max                  17.933487
Log Pis Min                  -6.284458
Policy mu Mean               0.029262086
Policy mu Std                0.80626285
Policy mu Max                3.0108733
Policy mu Min                -3.509879
Policy log std Mean          -0.4636415
Policy log std Std           0.22356936
Policy log std Max           -0.15024126
Policy log std Min           -1.9933683
Z mean eval                  2.0911803
Z variance eval              0.012289772
total_rewards                [6203.38445153 6482.69394202 6399.91858511 6347.11918706 6489.9626014
 6421.59437013 6430.93969376 6340.91328639 6362.4993399  6495.93792081]
total_rewards_mean           6397.49633781233
total_rewards_std            84.76328256675062
total_rewards_max            6495.937920809328
total_rewards_min            6203.384451530085
Number of train steps total  284000
Number of env steps total    854000
Number of rollouts total     0
Train Time (s)               136.9689394137822
(Previous) Eval Time (s)     28.54556140722707
Sample Time (s)              9.672037093434483
Epoch Time (s)               175.18653791444376
Total Train Time (s)         12910.810417836998
Epoch                        70
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:26:30.271698 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #70 | Epoch Duration: 175.27910327911377
2020-01-13 07:26:30.271918 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0899749
Z variance train             0.012307909
KL Divergence                38.619167
KL Loss                      3.8619168
QF Loss                      232.86732
VF Loss                      108.915855
Policy Loss                  -903.5672
Q Predictions Mean           897.1828
Q Predictions Std            922.0072
Q Predictions Max            2724.7188
Q Predictions Min            -9.4624
V Predictions Mean           903.60724
V Predictions Std            923.8631
V Predictions Max            2747.462
V Predictions Min            0.38629067
Log Pis Mean                 -1.0423926
Log Pis Std                  3.5040038
Log Pis Max                  10.858874
Log Pis Min                  -6.455991
Policy mu Mean               -0.031762745
Policy mu Std                0.80567884
Policy mu Max                2.7344728
Policy mu Min                -3.0028439
Policy log std Mean          -0.47408858
Policy log std Std           0.24076946
Policy log std Max           -0.14937961
Policy log std Min           -2.10766
Z mean eval                  2.110599
Z variance eval              0.012153321
total_rewards                [6150.29913438 5852.29309285 5986.84198943 5972.75356448 5960.02535079
 6073.42077258 4364.24970351  801.68215146 5812.72922746 5773.51656389]
total_rewards_mean           5274.781155083609
total_rewards_std            1567.7193655078597
total_rewards_max            6150.299134382287
total_rewards_min            801.6821514613205
Number of train steps total  288000
Number of env steps total    866000
Number of rollouts total     0
Train Time (s)               137.14946652762592
(Previous) Eval Time (s)     29.63227978302166
Sample Time (s)              9.713988360017538
Epoch Time (s)               176.49573467066512
Total Train Time (s)         13087.38766539609
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:29:26.849933 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #71 | Epoch Duration: 176.57785654067993
2020-01-13 07:29:26.850128 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1086354
Z variance train             0.012157956
KL Divergence                38.719612
KL Loss                      3.8719614
QF Loss                      436.4615
VF Loss                      96.89441
Policy Loss                  -751.9231
Q Predictions Mean           742.3923
Q Predictions Std            845.91693
Q Predictions Max            2778.2952
Q Predictions Min            13.757522
V Predictions Mean           752.8681
V Predictions Std            852.3013
V Predictions Max            2789.9126
V Predictions Min            13.964774
Log Pis Mean                 -1.1267648
Log Pis Std                  3.6889517
Log Pis Max                  20.19771
Log Pis Min                  -6.084217
Policy mu Mean               -0.07314942
Policy mu Std                0.7564247
Policy mu Max                2.9918113
Policy mu Min                -3.3133438
Policy log std Mean          -0.44740438
Policy log std Std           0.21413617
Policy log std Max           -0.13953781
Policy log std Min           -1.9615941
Z mean eval                  2.1063764
Z variance eval              0.0114703765
total_rewards                [6384.61311199 6313.08888656 6090.02418263 6405.65340391 2538.25239238
 6391.77191916 6179.58686901 6373.68625657 6167.08784955 6490.53658773]
total_rewards_mean           5933.430145948703
total_rewards_std            1138.0647859613425
total_rewards_max            6490.536587731553
total_rewards_min            2538.252392376063
Number of train steps total  292000
Number of env steps total    878000
Number of rollouts total     0
Train Time (s)               142.91108814440668
(Previous) Eval Time (s)     28.806983451824635
Sample Time (s)              9.76675279578194
Epoch Time (s)               181.48482439201325
Total Train Time (s)         13268.967613958754
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:32:28.432586 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #72 | Epoch Duration: 181.58228158950806
2020-01-13 07:32:28.432935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.103329
Z variance train             0.011470596
KL Divergence                39.949986
KL Loss                      3.9949987
QF Loss                      299.96375
VF Loss                      46.19597
Policy Loss                  -780.39355
Q Predictions Mean           772.00476
Q Predictions Std            860.889
Q Predictions Max            2736.397
Q Predictions Min            13.141107
V Predictions Mean           778.73145
V Predictions Std            860.34906
V Predictions Max            2738.055
V Predictions Min            10.566427
Log Pis Mean                 -1.5203233
Log Pis Std                  3.2201877
Log Pis Max                  10.739794
Log Pis Min                  -6.266714
Policy mu Mean               0.03097452
Policy mu Std                0.72115916
Policy mu Max                2.6327868
Policy mu Min                -2.38406
Policy log std Mean          -0.446349
Policy log std Std           0.23033412
Policy log std Max           -0.07541394
Policy log std Min           -2.0123277
Z mean eval                  2.2019203
Z variance eval              0.006598731
total_rewards                [5685.33022337 5752.43233413 5746.61372629 6120.38280041 5594.96967253
 5863.12899693 5843.73921492 5656.52283544 6078.00148747 6082.30178236]
total_rewards_mean           5842.342307385193
total_rewards_std            181.23989848999764
total_rewards_max            6120.3828004148145
total_rewards_min            5594.969672534106
Number of train steps total  296000
Number of env steps total    890000
Number of rollouts total     0
Train Time (s)               147.21350488904864
(Previous) Eval Time (s)     29.390954123344272
Sample Time (s)              9.87610414205119
Epoch Time (s)               186.4805631544441
Total Train Time (s)         13455.533374398481
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:35:34.999999 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #73 | Epoch Duration: 186.56684565544128
2020-01-13 07:35:35.000226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.209863
Z variance train             0.0065701036
KL Divergence                41.257305
KL Loss                      4.1257305
QF Loss                      494.68982
VF Loss                      82.483734
Policy Loss                  -833.2441
Q Predictions Mean           832.93164
Q Predictions Std            875.6959
Q Predictions Max            2761.9998
Q Predictions Min            6.910645
V Predictions Mean           833.2639
V Predictions Std            877.1724
V Predictions Max            2727.815
V Predictions Min            13.022754
Log Pis Mean                 -1.0802882
Log Pis Std                  3.791965
Log Pis Max                  20.252258
Log Pis Min                  -8.098682
Policy mu Mean               -0.09928683
Policy mu Std                0.7807346
Policy mu Max                2.7686079
Policy mu Min                -3.0948822
Policy log std Mean          -0.4460752
Policy log std Std           0.21414821
Policy log std Max           -0.05368632
Policy log std Min           -1.7591075
Z mean eval                  2.0730557
Z variance eval              0.01591972
total_rewards                [6608.70319722 6700.53359986 6691.97239184 6617.70517186 6561.22800561
 6655.18526714 6240.93455113 6667.174275   6614.32987328 6464.25433616]
total_rewards_mean           6582.202066907799
total_rewards_std            131.3045207358823
total_rewards_max            6700.533599855802
total_rewards_min            6240.934551134966
Number of train steps total  300000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               145.8157407878898
(Previous) Eval Time (s)     29.4497754490003
Sample Time (s)              10.13529523415491
Epoch Time (s)               185.40081147104502
Total Train Time (s)         13641.206930060871
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:38:40.675126 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #74 | Epoch Duration: 185.67473220825195
2020-01-13 07:38:40.675378 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0720563
Z variance train             0.015931606
KL Divergence                39.25828
KL Loss                      3.9258282
QF Loss                      768.62946
VF Loss                      107.2471
Policy Loss                  -797.45734
Q Predictions Mean           795.4379
Q Predictions Std            871.58325
Q Predictions Max            2750.6804
Q Predictions Min            5.0575905
V Predictions Mean           796.62946
V Predictions Std            874.47656
V Predictions Max            2749.2815
V Predictions Min            9.657604
Log Pis Mean                 -1.3079457
Log Pis Std                  3.2226787
Log Pis Max                  10.540916
Log Pis Min                  -6.4716883
Policy mu Mean               0.03928903
Policy mu Std                0.74910116
Policy mu Max                2.6906693
Policy mu Min                -2.3988044
Policy log std Mean          -0.4526156
Policy log std Std           0.23830636
Policy log std Max           -0.14509493
Policy log std Min           -2.0055928
Z mean eval                  2.143462
Z variance eval              0.016688589
total_rewards                [6620.28095832 6771.85029657 6769.25175108 6577.25861626 6908.34864686
 6691.70096844 6857.7844319  6868.67820502 6851.25722309 7083.35809743]
total_rewards_mean           6799.976919497541
total_rewards_std            140.74568323231924
total_rewards_max            7083.358097429029
total_rewards_min            6577.2586162588395
Number of train steps total  304000
Number of env steps total    914000
Number of rollouts total     0
Train Time (s)               148.00684638507664
(Previous) Eval Time (s)     29.34542348328978
Sample Time (s)              10.326973338611424
Epoch Time (s)               187.67924320697784
Total Train Time (s)         13828.968359329738
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:41:48.438248 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #75 | Epoch Duration: 187.76271796226501
2020-01-13 07:41:48.438454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1395898
Z variance train             0.016732372
KL Divergence                38.970016
KL Loss                      3.8970017
QF Loss                      877.72095
VF Loss                      82.382034
Policy Loss                  -837.6265
Q Predictions Mean           827.8145
Q Predictions Std            898.2625
Q Predictions Max            2726.7603
Q Predictions Min            10.481644
V Predictions Mean           834.7314
V Predictions Std            898.7692
V Predictions Max            2730.8262
V Predictions Min            -1.3769736
Log Pis Mean                 -1.127365
Log Pis Std                  3.7420564
Log Pis Max                  17.902077
Log Pis Min                  -8.899679
Policy mu Mean               0.073464006
Policy mu Std                0.788701
Policy mu Max                3.1921813
Policy mu Min                -2.9769986
Policy log std Mean          -0.45739627
Policy log std Std           0.2331701
Policy log std Max           -0.09977648
Policy log std Min           -2.1605384
Z mean eval                  2.0641928
Z variance eval              0.06708085
total_rewards                [6214.36897143 5669.39823858 5765.49412968 5832.8219851  5852.78544472
 6364.67133025 5883.30894144 5837.10794745 6041.61427083 6074.70498434]
total_rewards_mean           5953.627624380475
total_rewards_std            204.64838401163718
total_rewards_max            6364.671330249783
total_rewards_min            5669.398238581793
Number of train steps total  308000
Number of env steps total    926000
Number of rollouts total     0
Train Time (s)               146.52410517586395
(Previous) Eval Time (s)     28.66956129297614
Sample Time (s)              9.95577214146033
Epoch Time (s)               185.14943861030042
Total Train Time (s)         14014.204332933761
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:44:53.676132 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #76 | Epoch Duration: 185.23752117156982
2020-01-13 07:44:53.676359 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #76 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0644054
Z variance train             0.066518344
KL Divergence                35.79416
KL Loss                      3.579416
QF Loss                      171.58041
VF Loss                      50.042686
Policy Loss                  -726.89386
Q Predictions Mean           721.94104
Q Predictions Std            819.93304
Q Predictions Max            2721.839
Q Predictions Min            2.5528169
V Predictions Mean           724.61365
V Predictions Std            819.848
V Predictions Max            2721.6008
V Predictions Min            4.0663843
Log Pis Mean                 -1.6259139
Log Pis Std                  3.5123205
Log Pis Max                  18.46413
Log Pis Min                  -6.4318104
Policy mu Mean               -0.028187266
Policy mu Std                0.72614163
Policy mu Max                2.910152
Policy mu Min                -2.9961596
Policy log std Mean          -0.44800767
Policy log std Std           0.20380548
Policy log std Max           -0.12269321
Policy log std Min           -2.0781476
Z mean eval                  2.1072514
Z variance eval              0.015229335
total_rewards                [6768.98923571 6817.78914042 6929.05379255 7041.63428851 6890.5130514
 6659.74979526 7025.77260893 6902.78564708 7065.6143337  6851.65417242]
total_rewards_mean           6895.35560659754
total_rewards_std            121.66069006327372
total_rewards_max            7065.6143336975565
total_rewards_min            6659.749795255695
Number of train steps total  312000
Number of env steps total    938000
Number of rollouts total     0
Train Time (s)               137.5395537437871
(Previous) Eval Time (s)     28.78566810907796
Sample Time (s)              9.78655539918691
Epoch Time (s)               176.11177725205198
Total Train Time (s)         14190.404832569417
Epoch                        77
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:47:49.879403 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #77 | Epoch Duration: 176.20281863212585
2020-01-13 07:47:49.879726 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.107661
Z variance train             0.015274493
KL Divergence                37.65572
KL Loss                      3.765572
QF Loss                      181.3273
VF Loss                      89.70382
Policy Loss                  -914.85864
Q Predictions Mean           906.50146
Q Predictions Std            924.31604
Q Predictions Max            2795.6897
Q Predictions Min            -22.110786
V Predictions Mean           912.4735
V Predictions Std            922.78845
V Predictions Max            2783.6497
V Predictions Min            1.1185127
Log Pis Mean                 -0.77952594
Log Pis Std                  4.045228
Log Pis Max                  14.842594
Log Pis Min                  -9.918242
Policy mu Mean               0.037626714
Policy mu Std                0.8306497
Policy mu Max                2.819519
Policy mu Min                -2.546375
Policy log std Mean          -0.4650805
Policy log std Std           0.22881065
Policy log std Max           -0.12167463
Policy log std Min           -2.2754438
Z mean eval                  2.0753872
Z variance eval              0.040185064
total_rewards                [5803.57520441 5966.75826069 5956.83319298 5880.86742794 6059.51509992
 5855.99083142 6183.19682482 6104.92850497 5837.64320624 6003.51029711]
total_rewards_mean           5965.28188504977
total_rewards_std            117.86177821871243
total_rewards_max            6183.196824818563
total_rewards_min            5803.575204410383
Number of train steps total  316000
Number of env steps total    950000
Number of rollouts total     0
Train Time (s)               137.6191544481553
(Previous) Eval Time (s)     28.547579146921635
Sample Time (s)              10.003092363476753
Epoch Time (s)               176.1698259585537
Total Train Time (s)         14366.656896264758
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:50:46.133109 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #78 | Epoch Duration: 176.25318360328674
2020-01-13 07:50:46.133354 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.075023
Z variance train             0.04035277
KL Divergence                34.725437
KL Loss                      3.4725437
QF Loss                      256.9309
VF Loss                      139.7943
Policy Loss                  -858.60016
Q Predictions Mean           856.4757
Q Predictions Std            913.4222
Q Predictions Max            2845.8606
Q Predictions Min            -5.727179
V Predictions Mean           863.5735
V Predictions Std            911.33044
V Predictions Max            2831.8708
V Predictions Min            -10.161127
Log Pis Mean                 -1.1151247
Log Pis Std                  3.5725782
Log Pis Max                  11.242191
Log Pis Min                  -6.9923887
Policy mu Mean               -0.016199965
Policy mu Std                0.77404904
Policy mu Max                2.9752784
Policy mu Min                -2.544873
Policy log std Mean          -0.46372736
Policy log std Std           0.2517232
Policy log std Max           -0.11322236
Policy log std Min           -2.2262397
Z mean eval                  2.1234295
Z variance eval              0.028355395
total_rewards                [6402.81937198 6947.56546644 7035.77767899 6706.96743263 6625.81093428
 7040.94206924 6974.44433398 6872.53979186 6689.49328334 6702.60963842]
total_rewards_mean           6799.897000116094
total_rewards_std            197.37235366918458
total_rewards_max            7040.942069237025
total_rewards_min            6402.819371982405
Number of train steps total  320000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               143.87163301184773
(Previous) Eval Time (s)     31.03043479193002
Sample Time (s)              9.789462517015636
Epoch Time (s)               184.6915303207934
Total Train Time (s)         14551.705746451393
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:53:51.184632 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #79 | Epoch Duration: 185.051020860672
2020-01-13 07:53:51.184981 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1226258
Z variance train             0.028382689
KL Divergence                35.845955
KL Loss                      3.5845954
QF Loss                      190.48853
VF Loss                      48.90324
Policy Loss                  -894.4213
Q Predictions Mean           892.14014
Q Predictions Std            914.0419
Q Predictions Max            2864.5193
Q Predictions Min            -22.006582
V Predictions Mean           893.37585
V Predictions Std            912.39575
V Predictions Max            2847.3186
V Predictions Min            -19.865715
Log Pis Mean                 -1.010568
Log Pis Std                  3.3458807
Log Pis Max                  12.43478
Log Pis Min                  -6.000437
Policy mu Mean               0.014524044
Policy mu Std                0.7957377
Policy mu Max                2.4158564
Policy mu Min                -2.430751
Policy log std Mean          -0.47428903
Policy log std Std           0.21037886
Policy log std Max           0.10106343
Policy log std Min           -1.7857852
Z mean eval                  2.1216083
Z variance eval              0.017464476
total_rewards                [6602.20704266 6572.65354004 6762.0458665  6566.67012461 6207.67577564
 6590.84794882 6765.7775252  6923.97348763 6727.19029189 6546.1354046 ]
total_rewards_mean           6626.517700757911
total_rewards_std            180.72420684969654
total_rewards_max            6923.973487626854
total_rewards_min            6207.675775642939
Number of train steps total  324000
Number of env steps total    974000
Number of rollouts total     0
Train Time (s)               146.3639643918723
(Previous) Eval Time (s)     29.45736665278673
Sample Time (s)              9.355880638118833
Epoch Time (s)               185.17721168277785
Total Train Time (s)         14736.965306313708
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:56:56.445137 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #80 | Epoch Duration: 185.25994229316711
2020-01-13 07:56:56.445338 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1216648
Z variance train             0.017448038
KL Divergence                36.828815
KL Loss                      3.6828816
QF Loss                      344.6653
VF Loss                      71.737724
Policy Loss                  -871.1462
Q Predictions Mean           862.0591
Q Predictions Std            887.08295
Q Predictions Max            2811.7422
Q Predictions Min            -16.467
V Predictions Mean           869.47327
V Predictions Std            892.29266
V Predictions Max            2808.5542
V Predictions Min            -2.2316785
Log Pis Mean                 -1.19888
Log Pis Std                  3.7101643
Log Pis Max                  22.482307
Log Pis Min                  -8.784005
Policy mu Mean               0.03867738
Policy mu Std                0.7993944
Policy mu Max                3.6879964
Policy mu Min                -3.1515384
Policy log std Mean          -0.4596672
Policy log std Std           0.23741831
Policy log std Max           -0.07823227
Policy log std Min           -2.0651965
Z mean eval                  2.1415844
Z variance eval              0.020922218
total_rewards                [6996.4425789  6949.29640345 6723.05136449 6953.84236433 7014.61045066
 6969.66433945 6795.00308255 6810.96162126 7077.3095489  6902.5360303 ]
total_rewards_mean           6919.271778427581
total_rewards_std            105.17275337230262
total_rewards_max            7077.30954889602
total_rewards_min            6723.051364487596
Number of train steps total  328000
Number of env steps total    986000
Number of rollouts total     0
Train Time (s)               146.5783069645986
(Previous) Eval Time (s)     29.705738943070173
Sample Time (s)              10.142988996580243
Epoch Time (s)               186.427034904249
Total Train Time (s)         14923.472778168973
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:00:02.955334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #81 | Epoch Duration: 186.5098376274109
2020-01-13 08:00:02.955559 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1385903
Z variance train             0.020840166
KL Divergence                38.191593
KL Loss                      3.8191593
QF Loss                      301.6637
VF Loss                      201.78592
Policy Loss                  -938.6257
Q Predictions Mean           933.34937
Q Predictions Std            965.8454
Q Predictions Max            2803.867
Q Predictions Min            212.04608
V Predictions Mean           943.14844
V Predictions Std            973.2076
V Predictions Max            2817.1025
V Predictions Min            224.27473
Log Pis Mean                 -0.7894893
Log Pis Std                  3.7080758
Log Pis Max                  17.465088
Log Pis Min                  -7.4430103
Policy mu Mean               -0.08491242
Policy mu Std                0.815066
Policy mu Max                3.6227384
Policy mu Min                -3.5572686
Policy log std Mean          -0.48050177
Policy log std Std           0.23806494
Policy log std Max           -0.16177145
Policy log std Min           -2.2461364
Z mean eval                  2.1197398
Z variance eval              0.012035527
total_rewards                [6827.15052324 6663.65946145 6977.37095269 6740.52078231 6735.57066738
 6633.30794612 6769.89049036 6471.24163853 6632.44932568 6753.43980066]
total_rewards_mean           6720.460158842526
total_rewards_std            127.36772174006553
total_rewards_max            6977.370952693733
total_rewards_min            6471.241638526632
Number of train steps total  332000
Number of env steps total    998000
Number of rollouts total     0
Train Time (s)               147.92764376895502
(Previous) Eval Time (s)     29.64452743716538
Sample Time (s)              9.964282738044858
Epoch Time (s)               187.53645394416526
Total Train Time (s)         15111.094883355778
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:03:10.578939 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #82 | Epoch Duration: 187.6232078075409
2020-01-13 08:03:10.579139 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1182537
Z variance train             0.011981698
KL Divergence                39.790783
KL Loss                      3.9790783
QF Loss                      160.92587
VF Loss                      68.45426
Policy Loss                  -697.1734
Q Predictions Mean           689.7821
Q Predictions Std            778.19977
Q Predictions Max            2776.0764
Q Predictions Min            -9.571152
V Predictions Mean           697.35864
V Predictions Std            781.98096
V Predictions Max            2760.876
V Predictions Min            1.2414672
Log Pis Mean                 -1.5832491
Log Pis Std                  3.035222
Log Pis Max                  11.2933035
Log Pis Min                  -8.788147
Policy mu Mean               0.014168147
Policy mu Std                0.7278374
Policy mu Max                2.8008378
Policy mu Min                -2.4588666
Policy log std Mean          -0.44744968
Policy log std Std           0.21207964
Policy log std Max           -0.16043182
Policy log std Min           -2.0622003
Z mean eval                  2.109975
Z variance eval              0.010242576
total_rewards                [5734.20343909 5474.66967979 6420.02040381 6159.00268084 5525.19729515
 6159.72393784 5470.41125458 5802.34217127 6103.89223156 6262.39720046]
total_rewards_mean           5911.186029437973
total_rewards_std            334.5994057918568
total_rewards_max            6420.020403807021
total_rewards_min            5470.411254575778
Number of train steps total  336000
Number of env steps total    1010000
Number of rollouts total     0
Train Time (s)               146.25258690817282
(Previous) Eval Time (s)     28.68271677568555
Sample Time (s)              10.177431489806622
Epoch Time (s)               185.112735173665
Total Train Time (s)         15296.286340100225
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:06:15.772033 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #83 | Epoch Duration: 185.19273400306702
2020-01-13 08:06:15.772227 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1084397
Z variance train             0.010212548
KL Divergence                40.43563
KL Loss                      4.0435634
QF Loss                      897.2361
VF Loss                      70.74095
Policy Loss                  -867.486
Q Predictions Mean           860.54944
Q Predictions Std            898.9669
Q Predictions Max            2871.3274
Q Predictions Min            5.695102
V Predictions Mean           869.2261
V Predictions Std            899.2529
V Predictions Max            2865.252
V Predictions Min            1.4953486
Log Pis Mean                 -1.0312836
Log Pis Std                  3.6679192
Log Pis Max                  18.604095
Log Pis Min                  -8.241976
Policy mu Mean               -0.048197523
Policy mu Std                0.8103704
Policy mu Max                3.876639
Policy mu Min                -4.00885
Policy log std Mean          -0.4684472
Policy log std Std           0.22988404
Policy log std Max           -0.14874804
Policy log std Min           -2.1250706
Z mean eval                  2.1369581
Z variance eval              0.016321678
total_rewards                [6836.21575625 6880.85842947 7015.23551172 6823.89357003 6696.15423733
 6946.51118131 7275.34876948 7014.45433019 7012.48330028 7010.96090499]
total_rewards_mean           6951.211599104031
total_rewards_std            148.306323250736
total_rewards_max            7275.348769477548
total_rewards_min            6696.154237328006
Number of train steps total  340000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               137.40736260218546
(Previous) Eval Time (s)     28.615891305729747
Sample Time (s)              9.719627189449966
Epoch Time (s)               175.74288109736517
Total Train Time (s)         15472.110885482747
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:09:11.598192 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #84 | Epoch Duration: 175.82582998275757
2020-01-13 08:09:11.598371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1338294
Z variance train             0.016360752
KL Divergence                38.32895
KL Loss                      3.832895
QF Loss                      1862.0471
VF Loss                      262.69125
Policy Loss                  -923.9741
Q Predictions Mean           915.4725
Q Predictions Std            921.4901
Q Predictions Max            2809.2964
Q Predictions Min            -10.709495
V Predictions Mean           927.8811
V Predictions Std            924.6102
V Predictions Max            2818.6338
V Predictions Min            2.1767378
Log Pis Mean                 -0.5816431
Log Pis Std                  3.9373446
Log Pis Max                  20.615225
Log Pis Min                  -6.5302267
Policy mu Mean               -7.990593e-05
Policy mu Std                0.8264314
Policy mu Max                2.7736273
Policy mu Min                -3.870148
Policy log std Mean          -0.48921403
Policy log std Std           0.23188251
Policy log std Max           -0.13026576
Policy log std Min           -2.2231758
Z mean eval                  2.168918
Z variance eval              0.013807083
total_rewards                [6978.07765734 6776.51978848 6795.56337341 6863.01494642 6860.04579974
 6811.89162482 6639.8372295  6697.84733067 7049.4402147  6822.05698843]
total_rewards_mean           6829.429495349478
total_rewards_std            114.07616258427103
total_rewards_max            7049.440214699176
total_rewards_min            6639.837229500642
Number of train steps total  344000
Number of env steps total    1034000
Number of rollouts total     0
Train Time (s)               137.90662700822577
(Previous) Eval Time (s)     28.86975440196693
Sample Time (s)              9.748807264026254
Epoch Time (s)               176.52518867421895
Total Train Time (s)         15648.717366035096
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:12:08.208135 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #85 | Epoch Duration: 176.6096019744873
2020-01-13 08:12:08.208437 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.171674
Z variance train             0.013835764
KL Divergence                39.17444
KL Loss                      3.917444
QF Loss                      436.05994
VF Loss                      81.8331
Policy Loss                  -740.81586
Q Predictions Mean           734.6778
Q Predictions Std            863.06635
Q Predictions Max            2844.4124
Q Predictions Min            1.6617168
V Predictions Mean           741.424
V Predictions Std            861.75006
V Predictions Max            2823.7427
V Predictions Min            10.274017
Log Pis Mean                 -1.4432409
Log Pis Std                  3.1989067
Log Pis Max                  13.319553
Log Pis Min                  -7.650645
Policy mu Mean               -0.012385174
Policy mu Std                0.73886806
Policy mu Max                2.9070382
Policy mu Min                -2.585845
Policy log std Mean          -0.44474602
Policy log std Std           0.22066075
Policy log std Max           -0.154584
Policy log std Min           -2.2033162
Z mean eval                  2.1572373
Z variance eval              0.011007262
total_rewards                [4887.73730186 4793.55914394 4557.09011792 5575.98292293 5189.97839945
 4662.33818539 4782.8255905  5174.67742085 1149.41279729 5245.43552819]
total_rewards_mean           4601.903740831568
total_rewards_std            1187.9976657783843
total_rewards_max            5575.982922927902
total_rewards_min            1149.4127972865256
Number of train steps total  348000
Number of env steps total    1046000
Number of rollouts total     0
Train Time (s)               144.6358111090958
(Previous) Eval Time (s)     28.72180488705635
Sample Time (s)              9.555418741423637
Epoch Time (s)               182.9130347375758
Total Train Time (s)         15831.710077526513
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:15:11.201313 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #86 | Epoch Duration: 182.992693901062
2020-01-13 08:15:11.201467 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #86 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1598763
Z variance train             0.010987815
KL Divergence                39.18953
KL Loss                      3.918953
QF Loss                      326.682
VF Loss                      109.606705
Policy Loss                  -826.69867
Q Predictions Mean           817.6255
Q Predictions Std            884.91547
Q Predictions Max            2856.5112
Q Predictions Min            -13.055023
V Predictions Mean           821.452
V Predictions Std            885.272
V Predictions Max            2839.4236
V Predictions Min            1.7300992
Log Pis Mean                 -1.1384351
Log Pis Std                  3.1626904
Log Pis Max                  11.743075
Log Pis Min                  -6.2654033
Policy mu Mean               -0.07074263
Policy mu Std                0.7696405
Policy mu Max                2.648986
Policy mu Min                -2.3790786
Policy log std Mean          -0.46211067
Policy log std Std           0.20692372
Policy log std Max           -0.17911112
Policy log std Min           -2.0891018
Z mean eval                  2.1379528
Z variance eval              0.017911403
total_rewards                [6310.76729872 5924.17167274 5544.07142647 5983.89202361 5920.3459984
 5992.03628072 5936.79647409 6044.83854255 5853.810492   6533.73788779]
total_rewards_mean           6004.446809708288
total_rewards_std            250.78271582436304
total_rewards_max            6533.737887790943
total_rewards_min            5544.071426468975
Number of train steps total  352000
Number of env steps total    1058000
Number of rollouts total     0
Train Time (s)               146.68573481589556
(Previous) Eval Time (s)     30.516102810855955
Sample Time (s)              10.559965161141008
Epoch Time (s)               187.76180278789252
Total Train Time (s)         16019.561457824428
Epoch                        87
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:18:19.055366 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #87 | Epoch Duration: 187.85377311706543
2020-01-13 08:18:19.055597 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1386607
Z variance train             0.017831381
KL Divergence                37.763424
KL Loss                      3.7763424
QF Loss                      282.00436
VF Loss                      127.74231
Policy Loss                  -844.9407
Q Predictions Mean           837.93176
Q Predictions Std            917.1455
Q Predictions Max            2848.1787
Q Predictions Min            7.4304175
V Predictions Mean           842.7115
V Predictions Std            915.7265
V Predictions Max            2830.4111
V Predictions Min            5.429343
Log Pis Mean                 -0.7708367
Log Pis Std                  3.9747198
Log Pis Max                  17.395409
Log Pis Min                  -7.302376
Policy mu Mean               0.011534912
Policy mu Std                0.83221835
Policy mu Max                3.2145493
Policy mu Min                -3.407707
Policy log std Mean          -0.48480198
Policy log std Std           0.24387099
Policy log std Max           -0.1726312
Policy log std Min           -2.409352
Z mean eval                  2.1508892
Z variance eval              0.013806468
total_rewards                [6925.65874547 7364.69096567 6988.98311765 6945.28778225 7352.53377367
 6958.50251423 7011.55919971 7056.43211887 7142.99352774 7123.93733755]
total_rewards_mean           7087.05790828099
total_rewards_std            151.97961762894417
total_rewards_max            7364.690965667184
total_rewards_min            6925.658745467878
Number of train steps total  356000
Number of env steps total    1070000
Number of rollouts total     0
Train Time (s)               146.8011883702129
(Previous) Eval Time (s)     30.274173467885703
Sample Time (s)              9.494975087232888
Epoch Time (s)               186.5703369253315
Total Train Time (s)         16206.212696733419
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:21:25.709067 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #88 | Epoch Duration: 186.65330338478088
2020-01-13 08:21:25.709283 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.151824
Z variance train             0.013827667
KL Divergence                39.204407
KL Loss                      3.9204407
QF Loss                      645.071
VF Loss                      201.73352
Policy Loss                  -786.49243
Q Predictions Mean           774.5729
Q Predictions Std            891.9523
Q Predictions Max            2786.0803
Q Predictions Min            0.15568978
V Predictions Mean           777.1234
V Predictions Std            889.7269
V Predictions Max            2774.6106
V Predictions Min            9.530337
Log Pis Mean                 -1.0299344
Log Pis Std                  3.657962
Log Pis Max                  13.3240185
Log Pis Min                  -7.6611466
Policy mu Mean               -0.008356319
Policy mu Std                0.79738975
Policy mu Max                2.9893312
Policy mu Min                -3.5325544
Policy log std Mean          -0.46186915
Policy log std Std           0.2177811
Policy log std Max           -0.099464804
Policy log std Min           -1.8418865
Z mean eval                  2.16768
Z variance eval              0.0068011954
total_rewards                [6960.83601041 6937.72564689 7043.93048779 6986.43408723 7131.79656546
 6996.45175634 6873.46045076 7044.20799741 6906.59396595 6798.60198155]
total_rewards_mean           6968.003894979532
total_rewards_std            90.51171515686276
total_rewards_max            7131.7965654612135
total_rewards_min            6798.601981554777
Number of train steps total  360000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               148.12755434261635
(Previous) Eval Time (s)     30.120596444234252
Sample Time (s)              10.270863976795226
Epoch Time (s)               188.51901476364583
Total Train Time (s)         16394.840090105776
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:24:34.338527 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #89 | Epoch Duration: 188.62905144691467
2020-01-13 08:24:34.338817 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #89 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1668532
Z variance train             0.0068083317
KL Divergence                41.099834
KL Loss                      4.1099834
QF Loss                      364.66406
VF Loss                      285.66946
Policy Loss                  -816.9397
Q Predictions Mean           809.7075
Q Predictions Std            906.44293
Q Predictions Max            2863.0542
Q Predictions Min            -6.3987455
V Predictions Mean           820.44995
V Predictions Std            912.0888
V Predictions Max            2884.876
V Predictions Min            -0.10938877
Log Pis Mean                 -1.0049229
Log Pis Std                  3.310014
Log Pis Max                  13.308472
Log Pis Min                  -7.98476
Policy mu Mean               0.01475931
Policy mu Std                0.7848655
Policy mu Max                3.3948786
Policy mu Min                -3.490846
Policy log std Mean          -0.46094832
Policy log std Std           0.21848713
Policy log std Max           -0.1586433
Policy log std Min           -2.2828865
Z mean eval                  2.1345382
Z variance eval              0.012528298
total_rewards                [7085.42798699 7103.37531195 7329.76854166 6952.98157225 7148.3228971
 7097.27037763 7040.95037432 7196.7974443  7202.05135806 7275.11130073]
total_rewards_mean           7143.205716499884
total_rewards_std            105.94432585538485
total_rewards_max            7329.7685416585355
total_rewards_min            6952.981572253309
Number of train steps total  364000
Number of env steps total    1094000
Number of rollouts total     0
Train Time (s)               144.69379201019183
(Previous) Eval Time (s)     29.30580636765808
Sample Time (s)              10.274700044188648
Epoch Time (s)               184.27429842203856
Total Train Time (s)         16579.195167525206
Epoch                        90
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:27:38.695197 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #90 | Epoch Duration: 184.35618019104004
2020-01-13 08:27:38.695424 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.138411
Z variance train             0.012501249
KL Divergence                40.487377
KL Loss                      4.048738
QF Loss                      276.9211
VF Loss                      87.644966
Policy Loss                  -804.57904
Q Predictions Mean           802.58093
Q Predictions Std            902.3791
Q Predictions Max            2856.3003
Q Predictions Min            -19.35761
V Predictions Mean           804.3336
V Predictions Std            901.41895
V Predictions Max            2836.0928
V Predictions Min            -13.099412
Log Pis Mean                 -0.9297917
Log Pis Std                  3.389282
Log Pis Max                  20.230879
Log Pis Min                  -7.311487
Policy mu Mean               -0.042041466
Policy mu Std                0.80900997
Policy mu Max                3.7501395
Policy mu Min                -3.701105
Policy log std Mean          -0.47735092
Policy log std Std           0.22686651
Policy log std Max           -0.13402021
Policy log std Min           -2.250983
Z mean eval                  2.1857212
Z variance eval              0.055604927
total_rewards                [6937.5337121  6875.66141863 7020.71995699 6930.23561153 6983.42251508
 7111.37589811 7279.01367092 7171.01548756 7119.39004132 6955.89643425]
total_rewards_mean           7038.426474648465
total_rewards_std            120.77499850087408
total_rewards_max            7279.0136709210265
total_rewards_min            6875.661418628235
Number of train steps total  368000
Number of env steps total    1106000
Number of rollouts total     0
Train Time (s)               137.98790862364694
(Previous) Eval Time (s)     29.742380713112652
Sample Time (s)              9.477267762646079
Epoch Time (s)               177.20755709940568
Total Train Time (s)         16756.48143596109
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:30:35.983089 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #91 | Epoch Duration: 177.28750324249268
2020-01-13 08:30:35.983302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1846573
Z variance train             0.055136513
KL Divergence                38.37542
KL Loss                      3.837542
QF Loss                      135.26628
VF Loss                      38.963406
Policy Loss                  -658.5161
Q Predictions Mean           651.61395
Q Predictions Std            789.0112
Q Predictions Max            2965.503
Q Predictions Min            -9.541314
V Predictions Mean           658.6643
V Predictions Std            791.47595
V Predictions Max            2960.3972
V Predictions Min            -5.4580736
Log Pis Mean                 -1.1080592
Log Pis Std                  3.7707863
Log Pis Max                  13.166012
Log Pis Min                  -7.4634247
Policy mu Mean               0.02935552
Policy mu Std                0.7731495
Policy mu Max                2.8673892
Policy mu Min                -2.4333496
Policy log std Mean          -0.45267895
Policy log std Std           0.20616364
Policy log std Max           -0.15514876
Policy log std Min           -2.3126714
Z mean eval                  2.191526
Z variance eval              0.022609407
total_rewards                [7141.90851416 7259.24869322 7355.56017724 7160.39183817 7209.98816067
 7012.83256864 7026.38848544 7076.46386673 7509.79976675 7177.27503462]
total_rewards_mean           7192.985710564292
total_rewards_std            144.6328681522298
total_rewards_max            7509.799766751789
total_rewards_min            7012.832568635219
Number of train steps total  372000
Number of env steps total    1118000
Number of rollouts total     0
Train Time (s)               137.29667988512665
(Previous) Eval Time (s)     29.788107856176794
Sample Time (s)              9.44582693791017
Epoch Time (s)               176.5306146792136
Total Train Time (s)         16933.117551984265
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:33:32.621171 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #92 | Epoch Duration: 176.6377203464508
2020-01-13 08:33:32.621373 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #92 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1919131
Z variance train             0.022719514
KL Divergence                38.569588
KL Loss                      3.8569589
QF Loss                      289.72598
VF Loss                      67.08942
Policy Loss                  -780.08685
Q Predictions Mean           776.72253
Q Predictions Std            904.9005
Q Predictions Max            3008.444
Q Predictions Min            -20.92029
V Predictions Mean           775.7489
V Predictions Std            904.14465
V Predictions Max            3002.8552
V Predictions Min            -24.526348
Log Pis Mean                 -1.1202036
Log Pis Std                  3.6495695
Log Pis Max                  13.801452
Log Pis Min                  -6.590475
Policy mu Mean               0.013944048
Policy mu Std                0.7895491
Policy mu Max                2.9705224
Policy mu Min                -3.3228776
Policy log std Mean          -0.46897343
Policy log std Std           0.22618952
Policy log std Max           -0.09771299
Policy log std Min           -2.18535
Z mean eval                  2.153774
Z variance eval              0.014937038
total_rewards                [7195.55806288 7513.21930672 7336.97534537 7310.26055201 7301.5804041
 7322.92983398 7404.19521699 7372.29985199 7554.05333195 7356.3562823 ]
total_rewards_mean           7366.742818828321
total_rewards_std            98.80704441526524
total_rewards_max            7554.053331948682
total_rewards_min            7195.558062876313
Number of train steps total  376000
Number of env steps total    1130000
Number of rollouts total     0
Train Time (s)               145.7833464546129
(Previous) Eval Time (s)     31.05979442410171
Sample Time (s)              10.034471673890948
Epoch Time (s)               186.87761255260557
Total Train Time (s)         17120.077132986393
Epoch                        93
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:36:39.582730 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #93 | Epoch Duration: 186.96121168136597
2020-01-13 08:36:39.582945 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #93 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1531005
Z variance train             0.014880342
KL Divergence                39.65573
KL Loss                      3.965573
QF Loss                      1097.2878
VF Loss                      159.76454
Policy Loss                  -815.99976
Q Predictions Mean           810.032
Q Predictions Std            898.5083
Q Predictions Max            2979.1936
Q Predictions Min            246.65099
V Predictions Mean           822.1813
V Predictions Std            900.81506
V Predictions Max            2956.529
V Predictions Min            250.95323
Log Pis Mean                 -1.0668304
Log Pis Std                  3.2828248
Log Pis Max                  14.348874
Log Pis Min                  -6.2275834
Policy mu Mean               -0.050406378
Policy mu Std                0.79259175
Policy mu Max                3.0481238
Policy mu Min                -2.393388
Policy log std Mean          -0.47353974
Policy log std Std           0.2171418
Policy log std Max           -0.175056
Policy log std Min           -2.2492409
Z mean eval                  2.1828783
Z variance eval              0.015224342
total_rewards                [6977.23364124 7181.35101805 7356.37125076 7239.29318885 7271.9943446
 7087.59131892 7053.01286546 7156.17463574 7165.75533497 7306.6888123 ]
total_rewards_mean           7179.546641089219
total_rewards_std            112.10938240522542
total_rewards_max            7356.3712507556365
total_rewards_min            6977.233641235661
Number of train steps total  380000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               146.34396222420037
(Previous) Eval Time (s)     28.854121081065387
Sample Time (s)              10.28339993627742
Epoch Time (s)               185.48148324154317
Total Train Time (s)         17305.63843659032
Epoch                        94
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:39:45.146658 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #94 | Epoch Duration: 185.56355500221252
2020-01-13 08:39:45.146877 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1849082
Z variance train             0.015224462
KL Divergence                40.93875
KL Loss                      4.0938754
QF Loss                      1050.1091
VF Loss                      68.793655
Policy Loss                  -764.3312
Q Predictions Mean           760.76514
Q Predictions Std            872.5721
Q Predictions Max            2924.3645
Q Predictions Min            -20.299065
V Predictions Mean           766.9523
V Predictions Std            870.5845
V Predictions Max            2905.0059
V Predictions Min            -21.862305
Log Pis Mean                 -1.1259516
Log Pis Std                  3.9065607
Log Pis Max                  21.30284
Log Pis Min                  -7.9842544
Policy mu Mean               -0.042863205
Policy mu Std                0.7734029
Policy mu Max                3.656938
Policy mu Min                -3.4012666
Policy log std Mean          -0.4516324
Policy log std Std           0.22190492
Policy log std Max           -0.109794065
Policy log std Min           -2.1031191
Z mean eval                  2.1902707
Z variance eval              0.017510008
total_rewards                [7150.85700833 7223.44901481 7353.49370356 7368.3566138  7212.79850984
 6975.43559089 7210.64991407 7231.43332126 7031.06499198 7226.80244959]
total_rewards_mean           7198.434111812911
total_rewards_std            116.53175301025975
total_rewards_max            7368.356613803927
total_rewards_min            6975.435590891781
Number of train steps total  384000
Number of env steps total    1154000
Number of rollouts total     0
Train Time (s)               145.83098520012572
(Previous) Eval Time (s)     30.52102330699563
Sample Time (s)              10.298401455394924
Epoch Time (s)               186.65040996251628
Total Train Time (s)         17492.38800918497
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:42:51.898504 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #95 | Epoch Duration: 186.75145483016968
2020-01-13 08:42:51.898741 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1905258
Z variance train             0.017493378
KL Divergence                39.696484
KL Loss                      3.9696484
QF Loss                      156.6101
VF Loss                      52.827465
Policy Loss                  -777.69226
Q Predictions Mean           773.507
Q Predictions Std            867.2593
Q Predictions Max            2933.1978
Q Predictions Min            -9.068343
V Predictions Mean           773.50385
V Predictions Std            866.9157
V Predictions Max            2899.343
V Predictions Min            -15.252382
Log Pis Mean                 -1.4247267
Log Pis Std                  3.4304366
Log Pis Max                  15.536846
Log Pis Min                  -8.037222
Policy mu Mean               -0.061797272
Policy mu Std                0.7626139
Policy mu Max                2.9012685
Policy mu Min                -3.2370641
Policy log std Mean          -0.4534743
Policy log std Std           0.2156979
Policy log std Max           -0.1475393
Policy log std Min           -2.1520262
Z mean eval                  2.1863163
Z variance eval              0.02975117
total_rewards                [6917.15598702 7339.34704826 7360.86374627 7325.37573188 7216.73673882
 7283.29814052 7255.77600022 7234.91442383 7250.46871913 7309.88501204]
total_rewards_mean           7249.382154799186
total_rewards_std            119.4985638972134
total_rewards_max            7360.863746273129
total_rewards_min            6917.155987017881
Number of train steps total  388000
Number of env steps total    1166000
Number of rollouts total     0
Train Time (s)               147.54212893825024
(Previous) Eval Time (s)     29.38499680440873
Sample Time (s)              10.177734774071723
Epoch Time (s)               187.1048605167307
Total Train Time (s)         17679.573612894863
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:45:59.086108 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #96 | Epoch Duration: 187.18721556663513
2020-01-13 08:45:59.086304 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.191056
Z variance train             0.029570187
KL Divergence                38.86869
KL Loss                      3.8868692
QF Loss                      1001.3581
VF Loss                      91.10362
Policy Loss                  -885.7645
Q Predictions Mean           881.67163
Q Predictions Std            949.9729
Q Predictions Max            2967.6536
Q Predictions Min            -24.541798
V Predictions Mean           881.58887
V Predictions Std            952.91656
V Predictions Max            2952.1628
V Predictions Min            -15.492004
Log Pis Mean                 -0.71399426
Log Pis Std                  3.6957922
Log Pis Max                  15.342832
Log Pis Min                  -8.227686
Policy mu Mean               0.0024136566
Policy mu Std                0.83975935
Policy mu Max                3.410483
Policy mu Min                -3.2070956
Policy log std Mean          -0.48269382
Policy log std Std           0.22257803
Policy log std Max           -0.12552464
Policy log std Min           -2.141197
Z mean eval                  2.1938977
Z variance eval              0.02061842
total_rewards                [7143.1566521  7337.93429805 7268.91715046 7242.4762717  7111.44202929
 7222.76768273 7211.34613492 7252.90639142 7366.48184157 7294.71389353]
total_rewards_mean           7245.214234576893
total_rewards_std            75.06210879307986
total_rewards_max            7366.481841574325
total_rewards_min            7111.442029289855
Number of train steps total  392000
Number of env steps total    1178000
Number of rollouts total     0
Train Time (s)               143.51547492016107
(Previous) Eval Time (s)     29.810646147001535
Sample Time (s)              9.7128892573528
Epoch Time (s)               183.0390103245154
Total Train Time (s)         17862.715399510693
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:49:02.229747 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #97 | Epoch Duration: 183.1432933807373
2020-01-13 08:49:02.229957 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.196473
Z variance train             0.020694159
KL Divergence                39.26442
KL Loss                      3.926442
QF Loss                      114.76902
VF Loss                      71.83162
Policy Loss                  -820.6816
Q Predictions Mean           817.3686
Q Predictions Std            948.8011
Q Predictions Max            3122.1255
Q Predictions Min            -12.958345
V Predictions Mean           815.02216
V Predictions Std            947.7155
V Predictions Max            3081.0837
V Predictions Min            -7.743105
Log Pis Mean                 -1.3031343
Log Pis Std                  3.3698668
Log Pis Max                  13.028511
Log Pis Min                  -6.842313
Policy mu Mean               -0.008379918
Policy mu Std                0.7837248
Policy mu Max                2.6699462
Policy mu Min                -2.710268
Policy log std Mean          -0.4662417
Policy log std Std           0.22629222
Policy log std Max           -0.09551525
Policy log std Min           -2.4126985
Z mean eval                  2.1930175
Z variance eval              0.053611856
total_rewards                [6409.48859902 6684.45320408 6717.42589068 6594.20266426 6623.21176915
 6459.16858691 6459.78424338 6360.74939188 6427.58725551 6640.33405667]
total_rewards_mean           6537.640566154243
total_rewards_std            121.2390086597826
total_rewards_max            6717.425890677888
total_rewards_min            6360.7493918813525
Number of train steps total  396000
Number of env steps total    1190000
Number of rollouts total     0
Train Time (s)               137.92322055995464
(Previous) Eval Time (s)     29.46925922203809
Sample Time (s)              9.720700500532985
Epoch Time (s)               177.11318028252572
Total Train Time (s)         18039.91165467864
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:51:59.428000 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #98 | Epoch Duration: 177.19789338111877
2020-01-13 08:51:59.428194 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2014155
Z variance train             0.05348625
KL Divergence                38.211323
KL Loss                      3.8211324
QF Loss                      1277.3934
VF Loss                      255.74005
Policy Loss                  -826.03546
Q Predictions Mean           822.6831
Q Predictions Std            932.7851
Q Predictions Max            2987.728
Q Predictions Min            -6.812786
V Predictions Mean           819.1771
V Predictions Std            929.5567
V Predictions Max            2978.907
V Predictions Min            -16.381464
Log Pis Mean                 -0.36795303
Log Pis Std                  4.2309384
Log Pis Max                  15.991217
Log Pis Min                  -5.545556
Policy mu Mean               0.033419076
Policy mu Std                0.86983913
Policy mu Max                3.3337493
Policy mu Min                -2.9415267
Policy log std Mean          -0.45215666
Policy log std Std           0.2330683
Policy log std Max           -0.14094937
Policy log std Min           -2.2541516
Z mean eval                  2.1529553
Z variance eval              0.03471035
total_rewards                [7426.27877432 7244.27957433 7574.11292395 7508.52541491 7439.46392018
 7818.91212769 7282.59658782 7580.87970493 7454.28607947 7374.9656393 ]
total_rewards_mean           7470.430074690999
total_rewards_std            156.38032002708817
total_rewards_max            7818.9121276938595
total_rewards_min            7244.279574333321
Number of train steps total  400000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               137.1593086067587
(Previous) Eval Time (s)     28.355185375083238
Sample Time (s)              9.764369353652
Epoch Time (s)               175.27886333549395
Total Train Time (s)         18215.35665887827
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:54:54.875413 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #99 | Epoch Duration: 175.44705152511597
2020-01-13 08:54:54.875701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1502762
Z variance train             0.03484256
KL Divergence                37.893417
KL Loss                      3.7893417
QF Loss                      892.2882
VF Loss                      166.67255
Policy Loss                  -844.48065
Q Predictions Mean           841.2219
Q Predictions Std            959.17615
Q Predictions Max            2963.6938
Q Predictions Min            268.00235
V Predictions Mean           842.31116
V Predictions Std            959.70966
V Predictions Max            2966.2869
V Predictions Min            263.87488
Log Pis Mean                 -1.0378156
Log Pis Std                  3.358537
Log Pis Max                  10.517792
Log Pis Min                  -7.4165945
Policy mu Mean               0.040102523
Policy mu Std                0.82633674
Policy mu Max                2.9638283
Policy mu Min                -2.53134
Policy log std Mean          -0.47501302
Policy log std Std           0.22287256
Policy log std Max           -0.10600354
Policy log std Min           -1.9854656
Z mean eval                  2.183825
Z variance eval              0.022083445
total_rewards                [7388.64816447 7528.6378229  7563.24480917 7611.81243515 7414.80069125
 7446.62234939 7404.3221184  7657.03511448 7639.08140209 7583.15675635]
total_rewards_mean           7523.73616636388
total_rewards_std            97.09185821685243
total_rewards_max            7657.0351144837705
total_rewards_min            7388.648164466697
Number of train steps total  404000
Number of env steps total    1214000
Number of rollouts total     0
Train Time (s)               145.3866060078144
(Previous) Eval Time (s)     30.986039170995355
Sample Time (s)              8.417126053012908
Epoch Time (s)               184.78977123182267
Total Train Time (s)         18400.24097031355
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:57:59.761197 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #100 | Epoch Duration: 184.8853030204773
2020-01-13 08:57:59.761421 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1850836
Z variance train             0.022031613
KL Divergence                39.41105
KL Loss                      3.941105
QF Loss                      255.42673
VF Loss                      101.56149
Policy Loss                  -818.3731
Q Predictions Mean           818.40656
Q Predictions Std            946.024
Q Predictions Max            2954.5078
Q Predictions Min            -14.13798
V Predictions Mean           817.1457
V Predictions Std            945.81366
V Predictions Max            2933.232
V Predictions Min            -15.145747
Log Pis Mean                 -0.86168593
Log Pis Std                  3.4820106
Log Pis Max                  12.008327
Log Pis Min                  -6.654962
Policy mu Mean               0.043342784
Policy mu Std                0.8157829
Policy mu Max                2.5499098
Policy mu Min                -2.5734963
Policy log std Mean          -0.47231174
Policy log std Std           0.22794463
Policy log std Max           -0.16691908
Policy log std Min           -1.8895938
Z mean eval                  2.1929119
Z variance eval              0.025793135
total_rewards                [6944.02166907 7125.0191041  7103.17314255 7456.7855614  7041.91999455
 7006.2152085  7095.35148727 7195.84563464 7146.29641172 7125.54760612]
total_rewards_mean           7124.017581992664
total_rewards_std            130.63906954601964
total_rewards_max            7456.785561400118
total_rewards_min            6944.021669065823
Number of train steps total  408000
Number of env steps total    1226000
Number of rollouts total     0
Train Time (s)               146.32866420783103
(Previous) Eval Time (s)     30.182315890677273
Sample Time (s)              10.541102498304099
Epoch Time (s)               187.0520825968124
Total Train Time (s)         18587.382559809834
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:01:06.905678 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #101 | Epoch Duration: 187.14409041404724
2020-01-13 09:01:06.905937 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #101 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1919062
Z variance train             0.025789088
KL Divergence                40.347797
KL Loss                      4.03478
QF Loss                      243.56398
VF Loss                      36.777428
Policy Loss                  -815.84845
Q Predictions Mean           813.5459
Q Predictions Std            915.0013
Q Predictions Max            3044.2314
Q Predictions Min            -25.393776
V Predictions Mean           814.6905
V Predictions Std            918.3212
V Predictions Max            3056.6885
V Predictions Min            -21.18024
Log Pis Mean                 -0.7618853
Log Pis Std                  3.718732
Log Pis Max                  16.128119
Log Pis Min                  -8.5450325
Policy mu Mean               -0.08163043
Policy mu Std                0.8218756
Policy mu Max                3.1442566
Policy mu Min                -3.4204652
Policy log std Mean          -0.47068226
Policy log std Std           0.21736822
Policy log std Max           -0.15842035
Policy log std Min           -2.3529162
Z mean eval                  2.259646
Z variance eval              0.029343063
total_rewards                [7535.49672783 7688.76621612 7593.08880542 7561.48912045 7593.222375
 7518.95406399 7839.66860144 7494.65662088 7703.76887407 7473.3007837 ]
total_rewards_mean           7600.241218890429
total_rewards_std            107.49125567116444
total_rewards_max            7839.668601444021
total_rewards_min            7473.30078369943
Number of train steps total  412000
Number of env steps total    1238000
Number of rollouts total     0
Train Time (s)               145.55661057680845
(Previous) Eval Time (s)     29.352758693974465
Sample Time (s)              8.314478011336178
Epoch Time (s)               183.2238472821191
Total Train Time (s)         18770.68556644628
Epoch                        102
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:04:10.210157 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #102 | Epoch Duration: 183.3040497303009
2020-01-13 09:04:10.210342 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.263139
Z variance train             0.029141447
KL Divergence                40.79373
KL Loss                      4.0793734
QF Loss                      1691.0225
VF Loss                      71.98889
Policy Loss                  -778.4118
Q Predictions Mean           777.7716
Q Predictions Std            921.9068
Q Predictions Max            3140.9656
Q Predictions Min            -20.376003
V Predictions Mean           777.16113
V Predictions Std            916.06964
V Predictions Max            3104.9976
V Predictions Min            -21.230757
Log Pis Mean                 -0.9564443
Log Pis Std                  3.6666825
Log Pis Max                  20.13485
Log Pis Min                  -9.965647
Policy mu Mean               0.0312063
Policy mu Std                0.82235074
Policy mu Max                3.1271636
Policy mu Min                -2.614649
Policy log std Mean          -0.4719391
Policy log std Std           0.21007198
Policy log std Max           -0.06748626
Policy log std Min           -1.7785454
Z mean eval                  2.204769
Z variance eval              0.027566269
total_rewards                [7439.85330332 7398.2247965  7446.94849599 7455.28942532 7290.51625299
 7539.77896398 7297.89671372 7553.32379108 7318.09884571 7482.20213905]
total_rewards_mean           7422.213272765584
total_rewards_std            89.91180703216322
total_rewards_max            7553.323791075037
total_rewards_min            7290.516252994274
Number of train steps total  416000
Number of env steps total    1250000
Number of rollouts total     0
Train Time (s)               148.26390442810953
(Previous) Eval Time (s)     30.400100947823375
Sample Time (s)              10.245551762636751
Epoch Time (s)               188.90955713856965
Total Train Time (s)         18959.68132229848
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:07:19.209158 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #103 | Epoch Duration: 188.99865770339966
2020-01-13 09:07:19.209445 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1984546
Z variance train             0.027702082
KL Divergence                40.44167
KL Loss                      4.044167
QF Loss                      196.23099
VF Loss                      65.70462
Policy Loss                  -797.94714
Q Predictions Mean           795.8574
Q Predictions Std            914.2229
Q Predictions Max            3082.6106
Q Predictions Min            226.483
V Predictions Mean           798.1433
V Predictions Std            917.8869
V Predictions Max            3075.4392
V Predictions Min            212.81161
Log Pis Mean                 -0.8689893
Log Pis Std                  3.5523927
Log Pis Max                  14.472754
Log Pis Min                  -6.5236573
Policy mu Mean               -0.007673913
Policy mu Std                0.8098498
Policy mu Max                2.7159975
Policy mu Min                -2.8328636
Policy log std Mean          -0.47057378
Policy log std Std           0.20891596
Policy log std Max           -0.1503135
Policy log std Min           -1.9735777
Z mean eval                  2.2237992
Z variance eval              0.017811975
total_rewards                [7333.77209059 7350.89861319 7383.57216173 7285.19845133 7316.83726004
 7178.95597178 7314.48978356 7316.90911616 7220.71291774 7100.51554444]
total_rewards_mean           7280.186191055136
total_rewards_std            82.77696315437979
total_rewards_max            7383.572161729575
total_rewards_min            7100.515544442881
Number of train steps total  420000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               144.32140888180584
(Previous) Eval Time (s)     28.514428025111556
Sample Time (s)              10.103233359754086
Epoch Time (s)               182.93907026667148
Total Train Time (s)         19142.75573984068
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:10:22.285366 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #104 | Epoch Duration: 183.07573556900024
2020-01-13 09:10:22.285636 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2245371
Z variance train             0.017855674
KL Divergence                42.084305
KL Loss                      4.208431
QF Loss                      1148.3152
VF Loss                      58.9529
Policy Loss                  -785.4485
Q Predictions Mean           779.98615
Q Predictions Std            895.99603
Q Predictions Max            3054.9607
Q Predictions Min            284.68222
V Predictions Mean           784.38367
V Predictions Std            898.19324
V Predictions Max            3034.8286
V Predictions Min            293.9151
Log Pis Mean                 -0.88675064
Log Pis Std                  3.520896
Log Pis Max                  14.961544
Log Pis Min                  -5.9191985
Policy mu Mean               -0.0047612847
Policy mu Std                0.78379387
Policy mu Max                2.9623442
Policy mu Min                -3.2791002
Policy log std Mean          -0.46971747
Policy log std Std           0.2230571
Policy log std Max           0.030361772
Policy log std Min           -2.0982814
Z mean eval                  2.2226036
Z variance eval              0.014225401
total_rewards                [6984.55358881 6978.92058664 7378.73637546 7071.55571916 7083.04296682
 7222.21336818 7025.83750282 7221.65638927 7346.22344531 7008.63389089]
total_rewards_mean           7132.137383336716
total_rewards_std            141.654784784276
total_rewards_max            7378.736375458924
total_rewards_min            6978.920586640403
Number of train steps total  424000
Number of env steps total    1274000
Number of rollouts total     0
Train Time (s)               137.21192203788087
(Previous) Eval Time (s)     28.78846654901281
Sample Time (s)              9.847833341918886
Epoch Time (s)               175.84822192881256
Total Train Time (s)         19318.6850092588
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:13:18.216411 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #105 | Epoch Duration: 175.93058443069458
2020-01-13 09:13:18.216643 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.223888
Z variance train             0.014249936
KL Divergence                43.604893
KL Loss                      4.3604894
QF Loss                      119.22039
VF Loss                      123.562645
Policy Loss                  -818.7313
Q Predictions Mean           816.048
Q Predictions Std            954.95825
Q Predictions Max            3114.7327
Q Predictions Min            272.23706
V Predictions Mean           824.18396
V Predictions Std            952.8415
V Predictions Max            3114.1677
V Predictions Min            284.96216
Log Pis Mean                 -1.1399887
Log Pis Std                  3.2087357
Log Pis Max                  17.010223
Log Pis Min                  -6.6473255
Policy mu Mean               0.023059288
Policy mu Std                0.7718747
Policy mu Max                3.4011762
Policy mu Min                -2.8211477
Policy log std Mean          -0.47199073
Policy log std Std           0.24302234
Policy log std Max           -0.13219649
Policy log std Min           -2.2195084
Z mean eval                  2.2237446
Z variance eval              0.014580054
total_rewards                [7234.90297435 7551.87095078 7772.33348516 7614.04364118 7581.51061724
 7688.33225248 7383.45445348 7565.29983211 7436.03802203 7332.20195845]
total_rewards_mean           7515.998818725359
total_rewards_std            158.0462443957316
total_rewards_max            7772.333485156508
total_rewards_min            7234.902974349169
Number of train steps total  428000
Number of env steps total    1286000
Number of rollouts total     0
Train Time (s)               138.0795650910586
(Previous) Eval Time (s)     29.787486935034394
Sample Time (s)              9.87748417025432
Epoch Time (s)               177.74453619634733
Total Train Time (s)         19496.517926813103
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:16:16.051348 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #106 | Epoch Duration: 177.83454298973083
2020-01-13 09:16:16.051556 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.22356
Z variance train             0.014562368
KL Divergence                43.5185
KL Loss                      4.35185
QF Loss                      412.80026
VF Loss                      282.21124
Policy Loss                  -836.15985
Q Predictions Mean           830.34906
Q Predictions Std            952.9315
Q Predictions Max            3113.8728
Q Predictions Min            283.39996
V Predictions Mean           835.5029
V Predictions Std            949.4398
V Predictions Max            3099.179
V Predictions Min            283.22678
Log Pis Mean                 -1.0782642
Log Pis Std                  3.1824517
Log Pis Max                  10.119001
Log Pis Min                  -7.1467476
Policy mu Mean               0.020529972
Policy mu Std                0.8144505
Policy mu Max                2.6802542
Policy mu Min                -2.575575
Policy log std Mean          -0.47437778
Policy log std Std           0.22575618
Policy log std Max           -0.12841745
Policy log std Min           -2.0889475
Z mean eval                  2.2172346
Z variance eval              0.019844595
total_rewards                [7392.64613414 7583.45180553 7503.45847779 7593.41394636 7677.69811664
 7507.30470949 7430.94194425 7434.11000066 7464.62566835 7828.25192325]
total_rewards_mean           7541.590272644295
total_rewards_std            126.3609235437965
total_rewards_max            7828.251923246445
total_rewards_min            7392.64613413828
Number of train steps total  432000
Number of env steps total    1298000
Number of rollouts total     0
Train Time (s)               145.92928672209382
(Previous) Eval Time (s)     30.048463243991137
Sample Time (s)              10.151229731272906
Epoch Time (s)               186.12897969735786
Total Train Time (s)         19682.733186606318
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:19:22.269277 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #107 | Epoch Duration: 186.21757197380066
2020-01-13 09:19:22.269455 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2196183
Z variance train             0.020238416
KL Divergence                44.225666
KL Loss                      4.422567
QF Loss                      251.97511
VF Loss                      58.042374
Policy Loss                  -842.5406
Q Predictions Mean           837.40436
Q Predictions Std            970.10333
Q Predictions Max            3155.1536
Q Predictions Min            -64.84943
V Predictions Mean           842.4465
V Predictions Std            971.5691
V Predictions Max            3167.6118
V Predictions Min            -60.730648
Log Pis Mean                 -0.90478235
Log Pis Std                  3.630805
Log Pis Max                  22.175795
Log Pis Min                  -6.1283817
Policy mu Mean               0.030934637
Policy mu Std                0.81717294
Policy mu Max                3.535415
Policy mu Min                -3.025215
Policy log std Mean          -0.484557
Policy log std Std           0.22372088
Policy log std Max           -0.0036236346
Policy log std Min           -2.296067
Z mean eval                  2.2063746
Z variance eval              0.008482935
total_rewards                [7625.03471435 7901.71217036 7829.1941674  7424.79142972 7955.7734466
 7521.22570804 7946.15454319 8083.66940076 7786.58653679 7852.9501378 ]
total_rewards_mean           7792.709225501009
total_rewards_std            197.19381925200744
total_rewards_max            8083.6694007613205
total_rewards_min            7424.791429717124
Number of train steps total  436000
Number of env steps total    1310000
Number of rollouts total     0
Train Time (s)               146.43708127271384
(Previous) Eval Time (s)     30.298924059141427
Sample Time (s)              10.313030926976353
Epoch Time (s)               187.04903625883162
Total Train Time (s)         19869.862418119796
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:22:29.401778 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #108 | Epoch Duration: 187.1321403980255
2020-01-13 09:22:29.402069 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2075906
Z variance train             0.008486632
KL Divergence                45.00098
KL Loss                      4.500098
QF Loss                      136.34128
VF Loss                      36.408005
Policy Loss                  -751.5427
Q Predictions Mean           747.4059
Q Predictions Std            905.4206
Q Predictions Max            3145.8506
Q Predictions Min            -67.94037
V Predictions Mean           753.10095
V Predictions Std            902.0452
V Predictions Max            3133.3948
V Predictions Min            -70.80477
Log Pis Mean                 -1.1784468
Log Pis Std                  3.3054292
Log Pis Max                  21.485918
Log Pis Min                  -8.1268215
Policy mu Mean               -0.02761712
Policy mu Std                0.79171777
Policy mu Max                3.1536665
Policy mu Min                -3.206079
Policy log std Mean          -0.47303608
Policy log std Std           0.20731479
Policy log std Max           -0.09937996
Policy log std Min           -2.035439
Z mean eval                  2.1967258
Z variance eval              0.045300983
total_rewards                [7390.70098817 7728.98897094 7567.34715269 7723.65148983 7484.15158065
 7613.24092501 7606.76861862 7385.8246864  7424.23490251 7688.65773353]
total_rewards_mean           7561.356704836724
total_rewards_std            126.54394828016187
total_rewards_max            7728.9889709390145
total_rewards_min            7385.824686403929
Number of train steps total  440000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               145.47276504104957
(Previous) Eval Time (s)     30.64741423819214
Sample Time (s)              10.235449726227671
Epoch Time (s)               186.35562900546938
Total Train Time (s)         20056.334754546173
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:25:35.876538 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #109 | Epoch Duration: 186.47426748275757
2020-01-13 09:25:35.876847 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1926265
Z variance train             0.04509055
KL Divergence                42.14749
KL Loss                      4.2147493
QF Loss                      178.88013
VF Loss                      60.85398
Policy Loss                  -747.7448
Q Predictions Mean           744.765
Q Predictions Std            873.9301
Q Predictions Max            3019.1396
Q Predictions Min            -84.481026
V Predictions Mean           747.4973
V Predictions Std            872.36194
V Predictions Max            3013.4282
V Predictions Min            -82.41804
Log Pis Mean                 -1.1979858
Log Pis Std                  3.1440835
Log Pis Max                  11.63908
Log Pis Min                  -7.3957887
Policy mu Mean               0.017356055
Policy mu Std                0.7686747
Policy mu Max                2.557853
Policy mu Min                -2.612749
Policy log std Mean          -0.4786397
Policy log std Std           0.21117504
Policy log std Max           -0.09445757
Policy log std Min           -1.9690275
Z mean eval                  2.2523656
Z variance eval              0.04678189
total_rewards                [7558.67054958 7622.77197527 7660.2293128  7475.63314769 7742.94664503
 7848.62212787 7720.47501395 7634.93959142 7730.79486743 7609.63097832]
total_rewards_mean           7660.471420934594
total_rewards_std            99.96759766052118
total_rewards_max            7848.622127868885
total_rewards_min            7475.633147685608
Number of train steps total  444000
Number of env steps total    1334000
Number of rollouts total     0
Train Time (s)               147.2752164406702
(Previous) Eval Time (s)     29.641784945037216
Sample Time (s)              10.456611029803753
Epoch Time (s)               187.37361241551116
Total Train Time (s)         20243.81676131999
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:28:43.360923 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #110 | Epoch Duration: 187.48386549949646
2020-01-13 09:28:43.361268 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.246756
Z variance train             0.046766482
KL Divergence                42.58892
KL Loss                      4.258892
QF Loss                      172.90765
VF Loss                      150.24132
Policy Loss                  -765.20483
Q Predictions Mean           762.8902
Q Predictions Std            892.2823
Q Predictions Max            3100.761
Q Predictions Min            -71.55751
V Predictions Mean           771.29895
V Predictions Std            898.7847
V Predictions Max            3102.3909
V Predictions Min            -87.76018
Log Pis Mean                 -1.2011342
Log Pis Std                  3.1162112
Log Pis Max                  10.5549965
Log Pis Min                  -6.605483
Policy mu Mean               0.04201593
Policy mu Std                0.7780863
Policy mu Max                2.9121737
Policy mu Min                -2.3909698
Policy log std Mean          -0.46497333
Policy log std Std           0.23464017
Policy log std Max           -0.056801602
Policy log std Min           -2.2883332
Z mean eval                  2.183273
Z variance eval              0.018677097
total_rewards                [7707.03665228 7585.5895378  7539.58311453 7446.13333816 7596.21452555
 7465.71760138 7669.01753506 7353.12927679 7592.6555317  7175.66145051]
total_rewards_mean           7513.0738563761815
total_rewards_std            150.76469211667938
total_rewards_max            7707.036652275068
total_rewards_min            7175.661450512589
Number of train steps total  448000
Number of env steps total    1346000
Number of rollouts total     0
Train Time (s)               143.8184125390835
(Previous) Eval Time (s)     28.20409240014851
Sample Time (s)              10.219197491183877
Epoch Time (s)               182.2417024304159
Total Train Time (s)         20426.141498050652
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:31:45.687714 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #111 | Epoch Duration: 182.32617783546448
2020-01-13 09:31:45.687940 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1826348
Z variance train             0.01879129
KL Divergence                42.22451
KL Loss                      4.222451
QF Loss                      206.06401
VF Loss                      95.76503
Policy Loss                  -882.7896
Q Predictions Mean           883.3083
Q Predictions Std            999.9417
Q Predictions Max            3271.894
Q Predictions Min            287.31995
V Predictions Mean           887.8906
V Predictions Std            999.5885
V Predictions Max            3283.94
V Predictions Min            297.58414
Log Pis Mean                 -0.9252335
Log Pis Std                  3.0141208
Log Pis Max                  12.473076
Log Pis Min                  -8.697085
Policy mu Mean               0.037422102
Policy mu Std                0.8005461
Policy mu Max                2.3322036
Policy mu Min                -2.2429545
Policy log std Mean          -0.5067703
Policy log std Std           0.21344991
Policy log std Max           -0.1438653
Policy log std Min           -1.840647
Z mean eval                  2.2359657
Z variance eval              0.013674935
total_rewards                [7494.53446305 7825.58279254 7399.45571705 7355.78801653 7461.22832919
 7559.91191433 7619.92980231 7821.93362326 7468.64548656 7442.52709212]
total_rewards_mean           7544.953723694057
total_rewards_std            156.24827647788595
total_rewards_max            7825.582792540799
total_rewards_min            7355.788016525212
Number of train steps total  452000
Number of env steps total    1358000
Number of rollouts total     0
Train Time (s)               137.73497638199478
(Previous) Eval Time (s)     29.358930736780167
Sample Time (s)              9.85877746436745
Epoch Time (s)               176.9526845831424
Total Train Time (s)         20603.268309738953
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:34:42.816334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #112 | Epoch Duration: 177.12823104858398
2020-01-13 09:34:42.816565 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.232862
Z variance train             0.013810867
KL Divergence                45.940186
KL Loss                      4.5940185
QF Loss                      146.23193
VF Loss                      165.98283
Policy Loss                  -855.5809
Q Predictions Mean           852.97015
Q Predictions Std            975.0821
Q Predictions Max            3192.0466
Q Predictions Min            293.09326
V Predictions Mean           858.30664
V Predictions Std            981.2876
V Predictions Max            3197.4294
V Predictions Min            288.4859
Log Pis Mean                 -0.67765635
Log Pis Std                  3.6512249
Log Pis Max                  16.290539
Log Pis Min                  -7.3673573
Policy mu Mean               0.024092183
Policy mu Std                0.8620214
Policy mu Max                3.3655772
Policy mu Min                -2.4886863
Policy log std Mean          -0.4765075
Policy log std Std           0.21727757
Policy log std Max           -0.017930806
Policy log std Min           -2.0563807
Z mean eval                  2.2354367
Z variance eval              0.014173689
total_rewards                [7728.60054953 7588.29293513 7901.61980403 7798.69502798 7813.93325999
 7470.55346128 7665.18181613 7760.04975631 7770.92519219 7764.04749817]
total_rewards_mean           7726.189930074317
total_rewards_std            116.79290871396343
total_rewards_max            7901.619804025242
total_rewards_min            7470.553461282525
Number of train steps total  456000
Number of env steps total    1370000
Number of rollouts total     0
Train Time (s)               138.51774484757334
(Previous) Eval Time (s)     29.678686894942075
Sample Time (s)              9.880238896701485
Epoch Time (s)               178.0766706392169
Total Train Time (s)         20781.48799269041
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:37:41.037918 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #113 | Epoch Duration: 178.2211880683899
2020-01-13 09:37:41.038127 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2382798
Z variance train             0.0141950445
KL Divergence                45.282703
KL Loss                      4.5282702
QF Loss                      223.00438
VF Loss                      123.6035
Policy Loss                  -915.35645
Q Predictions Mean           912.7423
Q Predictions Std            1043.2008
Q Predictions Max            3237.5745
Q Predictions Min            302.98605
V Predictions Mean           915.60254
V Predictions Std            1042.3616
V Predictions Max            3226.0203
V Predictions Min            310.2083
Log Pis Mean                 -0.2796647
Log Pis Std                  3.7402773
Log Pis Max                  14.70418
Log Pis Min                  -7.5020285
Policy mu Mean               0.06090576
Policy mu Std                0.88315564
Policy mu Max                2.5759358
Policy mu Min                -3.365698
Policy log std Mean          -0.502865
Policy log std Std           0.239471
Policy log std Max           -0.12129706
Policy log std Min           -2.0866854
Z mean eval                  2.202918
Z variance eval              0.06189554
total_rewards                [7511.56257637 7607.0714765  7847.70638621 7976.78130124 7814.27519258
 7628.93309462 7788.73459796 7726.94266861 7686.65079145 7774.53888495]
total_rewards_mean           7736.319697048324
total_rewards_std            127.20909640979134
total_rewards_max            7976.7813012352835
total_rewards_min            7511.562576368229
Number of train steps total  460000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               145.87254969682544
(Previous) Eval Time (s)     30.22844075737521
Sample Time (s)              10.007150039542466
Epoch Time (s)               186.10814049374312
Total Train Time (s)         20967.675118437503
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:40:47.227076 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #114 | Epoch Duration: 186.18880152702332
2020-01-13 09:40:47.227317 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.20611
Z variance train             0.061774034
KL Divergence                40.942013
KL Loss                      4.0942016
QF Loss                      1148.5571
VF Loss                      72.34895
Policy Loss                  -804.75146
Q Predictions Mean           801.9972
Q Predictions Std            944.69763
Q Predictions Max            3252.1523
Q Predictions Min            313.61273
V Predictions Mean           799.75195
V Predictions Std            942.6725
V Predictions Max            3235.6584
V Predictions Min            309.6569
Log Pis Mean                 -0.77399164
Log Pis Std                  3.0164137
Log Pis Max                  10.959011
Log Pis Min                  -6.2076983
Policy mu Mean               0.021607125
Policy mu Std                0.8124362
Policy mu Max                2.450832
Policy mu Min                -2.5266252
Policy log std Mean          -0.45426953
Policy log std Std           0.21829264
Policy log std Max           -0.13017642
Policy log std Min           -2.041825
Z mean eval                  2.2222943
Z variance eval              0.041331984
total_rewards                [7370.28384971 7771.83718736 7855.38567701 7412.58632627 7403.62991997
 7421.8344045  7589.80536112 7726.08431048 7685.31464939 7207.54550362]
total_rewards_mean           7544.430718942972
total_rewards_std            199.84201277731185
total_rewards_max            7855.385677008821
total_rewards_min            7207.54550361864
Number of train steps total  464000
Number of env steps total    1394000
Number of rollouts total     0
Train Time (s)               146.33459432702512
(Previous) Eval Time (s)     30.293746382929385
Sample Time (s)              10.652891591191292
Epoch Time (s)               187.2812323011458
Total Train Time (s)         21155.038578430656
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:43:54.592384 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #115 | Epoch Duration: 187.36491870880127
2020-01-13 09:43:54.592566 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2223012
Z variance train             0.041321408
KL Divergence                42.414623
KL Loss                      4.241462
QF Loss                      811.1994
VF Loss                      56.575455
Policy Loss                  -917.7302
Q Predictions Mean           915.9201
Q Predictions Std            1029.9489
Q Predictions Max            3160.3271
Q Predictions Min            -112.02828
V Predictions Mean           915.5137
V Predictions Std            1029.6766
V Predictions Max            3150.0085
V Predictions Min            -112.02686
Log Pis Mean                 -0.71007264
Log Pis Std                  3.667181
Log Pis Max                  14.464552
Log Pis Min                  -8.135126
Policy mu Mean               0.05764766
Policy mu Std                0.8082468
Policy mu Max                2.5641637
Policy mu Min                -2.3831358
Policy log std Mean          -0.503859
Policy log std Std           0.2393854
Policy log std Max           -0.08500105
Policy log std Min           -2.182989
Z mean eval                  2.354433
Z variance eval              0.12821388
total_rewards                [7084.42188004 7313.84136155 7048.13110526 7190.93751214 7093.15711718
 7052.04578811 7055.77019996 7055.15425171 7225.06688846 7101.03789046]
total_rewards_mean           7121.956399486985
total_rewards_std            86.06197531247801
total_rewards_max            7313.841361553938
total_rewards_min            7048.131105256373
Number of train steps total  468000
Number of env steps total    1406000
Number of rollouts total     0
Train Time (s)               145.95339677203447
(Previous) Eval Time (s)     30.83973478106782
Sample Time (s)              10.55989340832457
Epoch Time (s)               187.35302496142685
Total Train Time (s)         21342.479972757865
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:47:02.037594 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #116 | Epoch Duration: 187.4448537826538
2020-01-13 09:47:02.037910 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3553085
Z variance train             0.12828366
KL Divergence                39.559437
KL Loss                      3.9559438
QF Loss                      584.44946
VF Loss                      57.45391
Policy Loss                  -889.4915
Q Predictions Mean           886.16235
Q Predictions Std            1000.04956
Q Predictions Max            3101.7966
Q Predictions Min            284.6941
V Predictions Mean           891.4599
V Predictions Std            998.76654
V Predictions Max            3087.1543
V Predictions Min            300.0021
Log Pis Mean                 -0.44193038
Log Pis Std                  3.9860985
Log Pis Max                  13.381711
Log Pis Min                  -7.544877
Policy mu Mean               -0.036845937
Policy mu Std                0.880516
Policy mu Max                2.6252186
Policy mu Min                -2.7471972
Policy log std Mean          -0.47033063
Policy log std Std           0.2187872
Policy log std Max           -0.14470248
Policy log std Min           -2.1836898
Z mean eval                  2.2302983
Z variance eval              0.10639505
total_rewards                [7193.6693421  7422.44415804 7184.40550128 7491.01546555 7530.37876481
 7581.39124091 7440.41467374 7278.05133069 7617.25926832 7343.28429581]
total_rewards_mean           7408.2314041246555
total_rewards_std            146.28322271817703
total_rewards_max            7617.259268317615
total_rewards_min            7184.405501283189
Number of train steps total  472000
Number of env steps total    1418000
Number of rollouts total     0
Train Time (s)               148.14752635918558
(Previous) Eval Time (s)     30.08403381658718
Sample Time (s)              10.564242916181684
Epoch Time (s)               188.79580309195444
Total Train Time (s)         21531.357387172524
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:50:10.916351 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #117 | Epoch Duration: 188.87822222709656
2020-01-13 09:50:10.916552 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2243695
Z variance train             0.10616028
KL Divergence                38.37422
KL Loss                      3.8374221
QF Loss                      445.96738
VF Loss                      49.267654
Policy Loss                  -814.4026
Q Predictions Mean           811.2479
Q Predictions Std            953.46423
Q Predictions Max            3200.123
Q Predictions Min            283.5124
V Predictions Mean           816.7113
V Predictions Std            957.14276
V Predictions Max            3193.886
V Predictions Min            294.34763
Log Pis Mean                 -1.3894701
Log Pis Std                  3.3239179
Log Pis Max                  11.1967945
Log Pis Min                  -10.720165
Policy mu Mean               0.052517492
Policy mu Std                0.7794981
Policy mu Max                2.64321
Policy mu Min                -2.636556
Policy log std Mean          -0.4762245
Policy log std Std           0.21631187
Policy log std Max           -0.11662373
Policy log std Min           -1.9078938
Z mean eval                  2.223112
Z variance eval              0.043899477
total_rewards                [7941.69354689 7671.35828163 7879.60582898 8179.11678282 7827.70689439
 7899.23297138 7939.25148093 7430.75372185 7875.24406582 7802.72228658]
total_rewards_mean           7844.668586127531
total_rewards_std            184.0535992182523
total_rewards_max            8179.116782818698
total_rewards_min            7430.753721851927
Number of train steps total  476000
Number of env steps total    1430000
Number of rollouts total     0
Train Time (s)               142.45159365609288
(Previous) Eval Time (s)     28.714097384363413
Sample Time (s)              10.387479118071496
Epoch Time (s)               181.5531701585278
Total Train Time (s)         21712.988547781482
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:53:12.550178 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #118 | Epoch Duration: 181.6334674358368
2020-01-13 09:53:12.550397 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2259505
Z variance train             0.044067424
KL Divergence                41.14789
KL Loss                      4.114789
QF Loss                      176.48923
VF Loss                      164.78093
Policy Loss                  -835.7743
Q Predictions Mean           834.04596
Q Predictions Std            973.55023
Q Predictions Max            3280.3044
Q Predictions Min            307.57843
V Predictions Mean           824.65857
V Predictions Std            972.2909
V Predictions Max            3269.281
V Predictions Min            302.6784
Log Pis Mean                 -0.816705
Log Pis Std                  3.307246
Log Pis Max                  12.056761
Log Pis Min                  -7.325316
Policy mu Mean               0.0068968176
Policy mu Std                0.81755006
Policy mu Max                2.8611345
Policy mu Min                -2.531086
Policy log std Mean          -0.489846
Policy log std Std           0.22595014
Policy log std Max           0.0085808635
Policy log std Min           -2.0700583
Z mean eval                  2.2926939
Z variance eval              0.040789157
total_rewards                [7554.46551744 7984.63731699 7938.09826977 7803.99729262 8018.66010397
 8037.25677148 7682.97132625 7761.01967479 7840.80594729 7728.47169612]
total_rewards_mean           7835.038391672888
total_rewards_std            150.76072400005137
total_rewards_max            8037.256771480702
total_rewards_min            7554.465517437335
Number of train steps total  480000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               137.99296158691868
(Previous) Eval Time (s)     28.21878684218973
Sample Time (s)              9.47610557358712
Epoch Time (s)               175.68785400269553
Total Train Time (s)         21888.755087023135
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:56:08.318013 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #119 | Epoch Duration: 175.76744318008423
2020-01-13 09:56:08.318190 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #119 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.294119
Z variance train             0.04072555
KL Divergence                43.172577
KL Loss                      4.317258
QF Loss                      1370.9766
VF Loss                      107.45368
Policy Loss                  -817.01544
Q Predictions Mean           814.3051
Q Predictions Std            967.0383
Q Predictions Max            3317.118
Q Predictions Min            326.58057
V Predictions Mean           823.9796
V Predictions Std            971.2531
V Predictions Max            3326.713
V Predictions Min            336.1234
Log Pis Mean                 -0.8939111
Log Pis Std                  3.3166058
Log Pis Max                  13.300394
Log Pis Min                  -5.8486633
Policy mu Mean               0.083397865
Policy mu Std                0.7987623
Policy mu Max                2.7080655
Policy mu Min                -2.518773
Policy log std Mean          -0.4651324
Policy log std Std           0.21485431
Policy log std Max           -0.050148368
Policy log std Min           -2.1036713
Z mean eval                  2.200752
Z variance eval              0.03131457
total_rewards                [7068.36913751 7228.56460735 7073.23003465 7423.73973244 7068.2704855
 7196.98154038 7194.98479255 7058.67680835 7455.59028612 7477.00921901]
total_rewards_mean           7224.541664384675
total_rewards_std            160.5208567446532
total_rewards_max            7477.009219005899
total_rewards_min            7058.67680834641
Number of train steps total  484000
Number of env steps total    1454000
Number of rollouts total     0
Train Time (s)               138.91425392916426
(Previous) Eval Time (s)     28.800435048062354
Sample Time (s)              10.149996370077133
Epoch Time (s)               177.86468534730375
Total Train Time (s)         22066.70735274302
Epoch                        120
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:59:06.273204 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #120 | Epoch Duration: 177.95486640930176
2020-01-13 09:59:06.273454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2012606
Z variance train             0.031474017
KL Divergence                42.467644
KL Loss                      4.2467647
QF Loss                      243.62924
VF Loss                      78.64425
Policy Loss                  -848.9891
Q Predictions Mean           843.8964
Q Predictions Std            1003.7488
Q Predictions Max            3429.2864
Q Predictions Min            317.34286
V Predictions Mean           842.8695
V Predictions Std            1003.10974
V Predictions Max            3402.2134
V Predictions Min            316.64377
Log Pis Mean                 -0.8915557
Log Pis Std                  3.4669597
Log Pis Max                  16.71345
Log Pis Min                  -10.484776
Policy mu Mean               -0.031039672
Policy mu Std                0.81377345
Policy mu Max                2.5480478
Policy mu Min                -2.5974882
Policy log std Mean          -0.47486022
Policy log std Std           0.21498354
Policy log std Max           -0.15780336
Policy log std Min           -1.9370519
Z mean eval                  2.2257762
Z variance eval              0.03460444
total_rewards                [7398.20089046 7835.86555261 7559.08515778 7559.38312333 7461.18904434
 7589.25863375 7837.80674635 7465.52084092 7722.47426901 7612.31538384]
total_rewards_mean           7604.109964239115
total_rewards_std            144.45845177281956
total_rewards_max            7837.806746346282
total_rewards_min            7398.200890456817
Number of train steps total  488000
Number of env steps total    1466000
Number of rollouts total     0
Train Time (s)               148.02842339826748
(Previous) Eval Time (s)     31.101976403966546
Sample Time (s)              10.126758829690516
Epoch Time (s)               189.25715863192454
Total Train Time (s)         22256.050679621752
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:02:15.618525 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #121 | Epoch Duration: 189.34489941596985
2020-01-13 10:02:15.618761 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2280364
Z variance train             0.034588836
KL Divergence                43.28274
KL Loss                      4.3282743
QF Loss                      214.40416
VF Loss                      106.46232
Policy Loss                  -778.12537
Q Predictions Mean           775.9131
Q Predictions Std            928.24884
Q Predictions Max            3293.2996
Q Predictions Min            262.9043
V Predictions Mean           785.1864
V Predictions Std            930.59393
V Predictions Max            3291.8167
V Predictions Min            253.46655
Log Pis Mean                 -0.89002734
Log Pis Std                  3.440557
Log Pis Max                  12.615843
Log Pis Min                  -7.284406
Policy mu Mean               0.04450779
Policy mu Std                0.7940537
Policy mu Max                2.864062
Policy mu Min                -2.2841349
Policy log std Mean          -0.5015888
Policy log std Std           0.21707204
Policy log std Max           -0.1001277
Policy log std Min           -1.9389348
Z mean eval                  2.2327304
Z variance eval              0.09985479
total_rewards                [7528.54008052 7649.56966702 7723.56787839 7586.1512845  7608.96609009
 7701.26184584 7480.17692613 7525.59602023 7683.4931292  7447.6194226 ]
total_rewards_mean           7593.494234453528
total_rewards_std            91.11533682232651
total_rewards_max            7723.567878387103
total_rewards_min            7447.619422599521
Number of train steps total  492000
Number of env steps total    1478000
Number of rollouts total     0
Train Time (s)               146.73119621537626
(Previous) Eval Time (s)     30.634357939008623
Sample Time (s)              10.196111775003374
Epoch Time (s)               187.56166592938825
Total Train Time (s)         22443.696008553263
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:05:23.267025 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #122 | Epoch Duration: 187.64808011054993
2020-01-13 10:05:23.267435 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.237209
Z variance train             0.10053166
KL Divergence                42.284252
KL Loss                      4.2284255
QF Loss                      151.264
VF Loss                      36.29997
Policy Loss                  -880.0988
Q Predictions Mean           877.1037
Q Predictions Std            1004.6884
Q Predictions Max            3315.4814
Q Predictions Min            333.48624
V Predictions Mean           877.8091
V Predictions Std            1004.8879
V Predictions Max            3315.4622
V Predictions Min            337.13428
Log Pis Mean                 -0.99523103
Log Pis Std                  3.2112565
Log Pis Max                  12.2981415
Log Pis Min                  -7.221841
Policy mu Mean               0.039755028
Policy mu Std                0.7966065
Policy mu Max                2.5029788
Policy mu Min                -2.4983916
Policy log std Mean          -0.48848602
Policy log std Std           0.23486413
Policy log std Max           -0.027126461
Policy log std Min           -2.2743063
Z mean eval                  2.2710752
Z variance eval              0.01721206
total_rewards                [7919.44324895 7848.34887091 7899.12348199 8125.03401631 8297.57246362
 7664.52563014 7985.03186079 8049.89637137 7864.40328036 8040.88467225]
total_rewards_mean           7969.426389669473
total_rewards_std            164.26007413162029
total_rewards_max            8297.572463619532
total_rewards_min            7664.525630138718
Number of train steps total  496000
Number of env steps total    1490000
Number of rollouts total     0
Train Time (s)               145.02622993802652
(Previous) Eval Time (s)     29.844561234116554
Sample Time (s)              10.151365553960204
Epoch Time (s)               185.02215672610328
Total Train Time (s)         22628.799404986203
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:08:28.371921 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #123 | Epoch Duration: 185.10424089431763
2020-01-13 10:08:28.372107 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2748682
Z variance train             0.017124562
KL Divergence                44.67023
KL Loss                      4.4670234
QF Loss                      220.6031
VF Loss                      79.27967
Policy Loss                  -814.5572
Q Predictions Mean           810.68585
Q Predictions Std            959.0151
Q Predictions Max            3352.9482
Q Predictions Min            333.31125
V Predictions Mean           810.80634
V Predictions Std            958.11206
V Predictions Max            3331.944
V Predictions Min            331.37976
Log Pis Mean                 -0.8560496
Log Pis Std                  3.4069185
Log Pis Max                  16.303246
Log Pis Min                  -6.456212
Policy mu Mean               0.07998626
Policy mu Std                0.7941235
Policy mu Max                2.7458053
Policy mu Min                -2.9204068
Policy log std Mean          -0.5021436
Policy log std Std           0.23356274
Policy log std Max           0.037012726
Policy log std Min           -1.9449236
Z mean eval                  2.2585816
Z variance eval              0.025999596
total_rewards                [7753.59192206 8208.95093069 8131.19591821 8023.63016972 7992.71541247
 8129.16522411 8042.88769118 8034.91150147 8256.6797209  8136.57235783]
total_rewards_mean           8071.030084862667
total_rewards_std            132.6751039179846
total_rewards_max            8256.679720898825
total_rewards_min            7753.591922061082
Number of train steps total  500000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               148.04334585601464
(Previous) Eval Time (s)     30.526003857143223
Sample Time (s)              10.67124067991972
Epoch Time (s)               189.24059039307758
Total Train Time (s)         22818.131934927776
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:11:37.706287 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #124 | Epoch Duration: 189.33402848243713
2020-01-13 10:11:37.706477 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2624342
Z variance train             0.026170794
KL Divergence                45.77014
KL Loss                      4.5770144
QF Loss                      657.14087
VF Loss                      168.91217
Policy Loss                  -836.42017
Q Predictions Mean           831.5294
Q Predictions Std            966.3386
Q Predictions Max            3308.9324
Q Predictions Min            326.41168
V Predictions Mean           832.9625
V Predictions Std            965.99695
V Predictions Max            3320.8616
V Predictions Min            325.58228
Log Pis Mean                 -1.0579256
Log Pis Std                  3.305986
Log Pis Max                  11.471533
Log Pis Min                  -9.999442
Policy mu Mean               0.035107028
Policy mu Std                0.7838379
Policy mu Max                2.4771917
Policy mu Min                -3.0554087
Policy log std Mean          -0.502237
Policy log std Std           0.23946714
Policy log std Max           0.013207674
Policy log std Min           -2.3112879
Z mean eval                  2.2492874
Z variance eval              0.030723045
total_rewards                [8159.60735527 8060.96131988 8044.31621445 7988.53587793 8310.04751852
 8163.19750292 8157.17808799 7871.90936855 8034.05034534 8169.032685  ]
total_rewards_mean           8095.883627585557
total_rewards_std            115.30653384388152
total_rewards_max            8310.047518517817
total_rewards_min            7871.909368550721
Number of train steps total  504000
Number of env steps total    1514000
Number of rollouts total     0
Train Time (s)               142.488460295368
(Previous) Eval Time (s)     29.22485596500337
Sample Time (s)              8.802326050586998
Epoch Time (s)               180.51564231095836
Total Train Time (s)         22998.724657955114
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:14:38.301048 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #125 | Epoch Duration: 180.5944287776947
2020-01-13 10:14:38.301231 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.250403
Z variance train             0.030858397
KL Divergence                44.656982
KL Loss                      4.4656982
QF Loss                      1301.01
VF Loss                      67.73529
Policy Loss                  -801.20197
Q Predictions Mean           799.969
Q Predictions Std            937.1815
Q Predictions Max            3263.8357
Q Predictions Min            331.32227
V Predictions Mean           804.1586
V Predictions Std            933.9575
V Predictions Max            3256.9998
V Predictions Min            333.10242
Log Pis Mean                 -0.6704382
Log Pis Std                  3.7261765
Log Pis Max                  16.440765
Log Pis Min                  -8.83617
Policy mu Mean               0.0034507215
Policy mu Std                0.8429099
Policy mu Max                2.6916919
Policy mu Min                -3.0967789
Policy log std Mean          -0.49163032
Policy log std Std           0.22808945
Policy log std Max           -0.055211425
Policy log std Min           -2.4517074
Z mean eval                  2.252512
Z variance eval              0.05074016
total_rewards                [7624.31792345 7853.14367688 7916.65778676 8172.09932822 7702.08909019
 7889.82298552 8076.3081238  7798.70978848 8043.4153675  8021.14662673]
total_rewards_mean           7909.771069753238
total_rewards_std            163.5291853773476
total_rewards_max            8172.099328219878
total_rewards_min            7624.317923449611
Number of train steps total  508000
Number of env steps total    1526000
Number of rollouts total     0
Train Time (s)               138.2671211110428
(Previous) Eval Time (s)     29.45742355333641
Sample Time (s)              9.828351887408644
Epoch Time (s)               177.55289655178785
Total Train Time (s)         23176.362701359205
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:17:35.942441 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #126 | Epoch Duration: 177.64105367660522
2020-01-13 10:17:35.942713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2516809
Z variance train             0.050857715
KL Divergence                44.82486
KL Loss                      4.4824862
QF Loss                      81.56642
VF Loss                      61.548943
Policy Loss                  -724.8973
Q Predictions Mean           724.1273
Q Predictions Std            868.1152
Q Predictions Max            3276.8362
Q Predictions Min            330.60138
V Predictions Mean           719.63416
V Predictions Std            867.7142
V Predictions Max            3262.6865
V Predictions Min            336.53656
Log Pis Mean                 -0.7420804
Log Pis Std                  3.2507164
Log Pis Max                  12.997391
Log Pis Min                  -10.303421
Policy mu Mean               -0.007999453
Policy mu Std                0.800462
Policy mu Max                2.4126575
Policy mu Min                -2.632082
Policy log std Mean          -0.49179065
Policy log std Std           0.21896218
Policy log std Max           -0.089259
Policy log std Min           -2.0387816
Z mean eval                  2.1986432
Z variance eval              0.037109006
total_rewards                [7416.81035907 7390.097209   7191.13388486 7410.37798278 7499.11299558
 7735.19554583 7592.77434795 7312.56749462 7364.89835464 7627.00843641]
total_rewards_mean           7453.99766107412
total_rewards_std            153.20141114793756
total_rewards_max            7735.195545831496
total_rewards_min            7191.133884860905
Number of train steps total  512000
Number of env steps total    1538000
Number of rollouts total     0
Train Time (s)               140.08238823898137
(Previous) Eval Time (s)     29.05524042621255
Sample Time (s)              9.869412596803159
Epoch Time (s)               179.00704126199707
Total Train Time (s)         23355.45496279141
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:20:35.034244 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #127 | Epoch Duration: 179.09133648872375
2020-01-13 10:20:35.034371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1987245
Z variance train             0.037143204
KL Divergence                41.886612
KL Loss                      4.188661
QF Loss                      277.80237
VF Loss                      36.941612
Policy Loss                  -768.63916
Q Predictions Mean           766.6791
Q Predictions Std            918.8564
Q Predictions Max            3300.096
Q Predictions Min            323.5407
V Predictions Mean           768.67725
V Predictions Std            918.5479
V Predictions Max            3293.6104
V Predictions Min            330.42233
Log Pis Mean                 -1.0939082
Log Pis Std                  2.9786677
Log Pis Max                  13.063374
Log Pis Min                  -8.175571
Policy mu Mean               0.06512297
Policy mu Std                0.7721148
Policy mu Max                2.5810487
Policy mu Min                -3.2685199
Policy log std Mean          -0.48444724
Policy log std Std           0.21638882
Policy log std Max           -0.11996108
Policy log std Min           -1.8642559
Z mean eval                  2.1773422
Z variance eval              0.17377838
total_rewards                [7834.85826982 7844.11096145 7908.55948434 7824.81653757 8076.63823519
 7840.04310896 7891.88437537 7800.84379565 8019.39653522 7775.21095742]
total_rewards_mean           7881.636226099099
total_rewards_std            91.78350310720327
total_rewards_max            8076.638235193928
total_rewards_min            7775.210957422052
Number of train steps total  516000
Number of env steps total    1550000
Number of rollouts total     0
Train Time (s)               148.2820712979883
(Previous) Eval Time (s)     30.56023940583691
Sample Time (s)              9.623132708948106
Epoch Time (s)               188.4654434127733
Total Train Time (s)         23544.00076702563
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:23:43.581716 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #128 | Epoch Duration: 188.54724645614624
2020-01-13 10:23:43.581868 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1758435
Z variance train             0.17339633
KL Divergence                39.119293
KL Loss                      3.9119294
QF Loss                      185.79037
VF Loss                      85.88685
Policy Loss                  -1006.61285
Q Predictions Mean           1006.6796
Q Predictions Std            1143.6677
Q Predictions Max            3548.2288
Q Predictions Min            342.49402
V Predictions Mean           1000.27356
V Predictions Std            1140.5438
V Predictions Max            3522.494
V Predictions Min            345.67877
Log Pis Mean                 -0.38314897
Log Pis Std                  3.8179948
Log Pis Max                  14.218898
Log Pis Min                  -7.1466894
Policy mu Mean               -0.020120356
Policy mu Std                0.87264425
Policy mu Max                2.7448275
Policy mu Min                -3.0314007
Policy log std Mean          -0.47863698
Policy log std Std           0.24450925
Policy log std Max           -0.122178435
Policy log std Min           -2.1003258
Z mean eval                  2.264125
Z variance eval              0.051839583
total_rewards                [7485.39697394 7393.09924324 7543.83190973 7881.63377692 7736.83904088
 7388.2317725  7665.97522607 7547.49909272 7454.25451274 7577.21479786]
total_rewards_mean           7567.397634659572
total_rewards_std            148.4000561459306
total_rewards_max            7881.633776923094
total_rewards_min            7388.23177250114
Number of train steps total  520000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               146.92050045821816
(Previous) Eval Time (s)     30.05653619673103
Sample Time (s)              9.634802786167711
Epoch Time (s)               186.6118394411169
Total Train Time (s)         23730.694866571575
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:26:50.279003 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #129 | Epoch Duration: 186.6970090866089
2020-01-13 10:26:50.279275 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2610118
Z variance train             0.051816754
KL Divergence                42.589966
KL Loss                      4.2589965
QF Loss                      1341.8599
VF Loss                      120.94327
Policy Loss                  -960.3408
Q Predictions Mean           957.1363
Q Predictions Std            1066.7155
Q Predictions Max            3402.5037
Q Predictions Min            339.63815
V Predictions Mean           964.59247
V Predictions Std            1070.7018
V Predictions Max            3402.8247
V Predictions Min            339.8914
Log Pis Mean                 -0.37302676
Log Pis Std                  3.7996528
Log Pis Max                  12.652477
Log Pis Min                  -10.303897
Policy mu Mean               0.086205415
Policy mu Std                0.8765675
Policy mu Max                2.9717028
Policy mu Min                -2.8169734
Policy log std Mean          -0.49773988
Policy log std Std           0.23587744
Policy log std Max           -0.10706338
Policy log std Min           -2.2096844
Z mean eval                  2.218779
Z variance eval              0.03929327
total_rewards                [7960.46332977 8352.38485053 7990.49929262 8163.15863117 8139.00864951
 8080.241682   7986.21133466 7902.58884592 8017.19489166 8092.73387226]
total_rewards_mean           8068.4485380104725
total_rewards_std            122.44739186600135
total_rewards_max            8352.384850533177
total_rewards_min            7902.588845920879
Number of train steps total  524000
Number of env steps total    1574000
Number of rollouts total     0
Train Time (s)               144.89495957270265
(Previous) Eval Time (s)     30.92275742581114
Sample Time (s)              9.510002214461565
Epoch Time (s)               185.32771921297535
Total Train Time (s)         23916.10463733971
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:29:55.690913 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #130 | Epoch Duration: 185.41147565841675
2020-01-13 10:29:55.691127 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #130 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2172844
Z variance train             0.039256305
KL Divergence                43.249214
KL Loss                      4.3249216
QF Loss                      345.76657
VF Loss                      51.662823
Policy Loss                  -871.8397
Q Predictions Mean           867.05115
Q Predictions Std            1006.7028
Q Predictions Max            3444.228
Q Predictions Min            344.43066
V Predictions Mean           867.18506
V Predictions Std            1006.7969
V Predictions Max            3422.4763
V Predictions Min            340.59048
Log Pis Mean                 -0.842108
Log Pis Std                  3.2182646
Log Pis Max                  11.072126
Log Pis Min                  -8.768251
Policy mu Mean               -0.007700991
Policy mu Std                0.8253099
Policy mu Max                2.8761663
Policy mu Min                -3.0561838
Policy log std Mean          -0.4890224
Policy log std Std           0.24724585
Policy log std Max           -0.09940535
Policy log std Min           -2.2135785
Z mean eval                  2.2243702
Z variance eval              0.049817942
total_rewards                [7566.01226157 7674.70426005 7876.35046558 7854.81179947 7818.765653
 7698.1552299  7671.62359746 7787.40713881 7943.05095884 7720.08268782]
total_rewards_mean           7761.096405248973
total_rewards_std            108.79432692872295
total_rewards_max            7943.050958837654
total_rewards_min            7566.012261567582
Number of train steps total  528000
Number of env steps total    1586000
Number of rollouts total     0
Train Time (s)               146.8582285209559
(Previous) Eval Time (s)     29.799095917027444
Sample Time (s)              10.634241920430213
Epoch Time (s)               187.29156635841355
Total Train Time (s)         24103.47421319876
Epoch                        131
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:33:03.062523 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #131 | Epoch Duration: 187.3712077140808
2020-01-13 10:33:03.062730 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.222925
Z variance train             0.049779717
KL Divergence                42.46879
KL Loss                      4.246879
QF Loss                      360.05774
VF Loss                      119.18646
Policy Loss                  -934.2176
Q Predictions Mean           928.2705
Q Predictions Std            1071.3677
Q Predictions Max            3472.9785
Q Predictions Min            338.194
V Predictions Mean           932.64465
V Predictions Std            1070.1959
V Predictions Max            3459.0813
V Predictions Min            340.69125
Log Pis Mean                 -0.2551142
Log Pis Std                  3.7615857
Log Pis Max                  19.82215
Log Pis Min                  -7.6205163
Policy mu Mean               0.09378811
Policy mu Std                0.85993636
Policy mu Max                4.253767
Policy mu Min                -2.9740777
Policy log std Mean          -0.52100253
Policy log std Std           0.24485803
Policy log std Max           -0.15471344
Policy log std Min           -1.9833763
Z mean eval                  2.2042596
Z variance eval              0.02083245
total_rewards                [7921.07700971 8033.85743107 8067.08467784 8319.16393924 8108.93608943
 8313.80345858 8224.72937655 8035.42023921 8098.04283677 8161.99803154]
total_rewards_mean           8128.411308993118
total_rewards_std            121.16097707630759
total_rewards_max            8319.163939237475
total_rewards_min            7921.077009711422
Number of train steps total  532000
Number of env steps total    1598000
Number of rollouts total     0
Train Time (s)               140.40443410398439
(Previous) Eval Time (s)     28.904852716252208
Sample Time (s)              9.903342127799988
Epoch Time (s)               179.21262894803658
Total Train Time (s)         24282.76426912751
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:36:02.355300 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #132 | Epoch Duration: 179.29240942001343
2020-01-13 10:36:02.355537 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2039876
Z variance train             0.020796804
KL Divergence                44.56324
KL Loss                      4.456324
QF Loss                      351.67062
VF Loss                      177.11269
Policy Loss                  -832.31903
Q Predictions Mean           828.339
Q Predictions Std            963.832
Q Predictions Max            3399.5671
Q Predictions Min            331.0883
V Predictions Mean           833.19775
V Predictions Std            964.7724
V Predictions Max            3417.8977
V Predictions Min            336.7418
Log Pis Mean                 -0.510007
Log Pis Std                  3.2082074
Log Pis Max                  11.00568
Log Pis Min                  -6.6041727
Policy mu Mean               0.102952205
Policy mu Std                0.82066274
Policy mu Max                2.9617395
Policy mu Min                -2.447607
Policy log std Mean          -0.499146
Policy log std Std           0.23317185
Policy log std Max           -0.11711264
Policy log std Min           -2.1217518
Z mean eval                  2.235373
Z variance eval              0.06400778
total_rewards                [8263.20361981 8254.28298728 8267.53988725 8557.6946612  8402.96175888
 8462.32874701 8415.16895608 8409.76597457 8355.2479153  8254.26629758]
total_rewards_mean           8364.24608049531
total_rewards_std            98.50722551353907
total_rewards_max            8557.694661199537
total_rewards_min            8254.266297577227
Number of train steps total  536000
Number of env steps total    1610000
Number of rollouts total     0
Train Time (s)               137.63101284205914
(Previous) Eval Time (s)     29.31223239330575
Sample Time (s)              9.989039117936045
Epoch Time (s)               176.93228435330093
Total Train Time (s)         24459.778262368403
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:38:59.371111 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #133 | Epoch Duration: 177.01540637016296
2020-01-13 10:38:59.371325 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2387543
Z variance train             0.06350505
KL Divergence                42.68445
KL Loss                      4.268445
QF Loss                      275.10135
VF Loss                      162.93661
Policy Loss                  -957.7121
Q Predictions Mean           953.9785
Q Predictions Std            1060.7157
Q Predictions Max            3452.0903
Q Predictions Min            339.79303
V Predictions Mean           961.89825
V Predictions Std            1061.8247
V Predictions Max            3483.7297
V Predictions Min            346.99344
Log Pis Mean                 -0.33058307
Log Pis Std                  3.4093664
Log Pis Max                  12.345338
Log Pis Min                  -8.100277
Policy mu Mean               0.07611847
Policy mu Std                0.8729784
Policy mu Max                2.8931103
Policy mu Min                -3.294944
Policy log std Mean          -0.5291233
Policy log std Std           0.22619604
Policy log std Max           -0.16041738
Policy log std Min           -2.092811
Z mean eval                  2.2413545
Z variance eval              0.022229228
total_rewards                [7904.55088415 8000.02114532 8010.14201198 8198.1320224  8112.80465216
 8122.88779088 8034.67789438 7900.88438498 8102.55558142 8093.38537885]
total_rewards_mean           8048.004174652315
total_rewards_std            91.38759297348474
total_rewards_max            8198.132022402573
total_rewards_min            7900.8843849762925
Number of train steps total  540000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               141.5760863511823
(Previous) Eval Time (s)     29.353432320058346
Sample Time (s)              9.755320924334228
Epoch Time (s)               180.68483959557489
Total Train Time (s)         24640.54763538111
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:42:00.143385 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #134 | Epoch Duration: 180.77190923690796
2020-01-13 10:42:00.143576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2419848
Z variance train             0.022164118
KL Divergence                45.35719
KL Loss                      4.535719
QF Loss                      214.8299
VF Loss                      147.26575
Policy Loss                  -1040.247
Q Predictions Mean           1038.0402
Q Predictions Std            1118.1243
Q Predictions Max            3496.8503
Q Predictions Min            357.79395
V Predictions Mean           1036.942
V Predictions Std            1115.7097
V Predictions Max            3477.6257
V Predictions Min            360.81015
Log Pis Mean                 -0.049642127
Log Pis Std                  4.059059
Log Pis Max                  17.762892
Log Pis Min                  -6.6521616
Policy mu Mean               0.082284704
Policy mu Std                0.9043703
Policy mu Max                3.4069586
Policy mu Min                -3.1014822
Policy log std Mean          -0.5142433
Policy log std Std           0.25313857
Policy log std Max           -0.0024974048
Policy log std Min           -2.4505553
Z mean eval                  2.2627861
Z variance eval              0.03895054
total_rewards                [8099.87109516 7901.74002165 7961.09065601 8213.96624676 8040.86151985
 8293.67077079 8213.84473871 8067.24984837 8095.82940948 8230.79382907]
total_rewards_mean           8111.891813586514
total_rewards_std            119.30647022647767
total_rewards_max            8293.67077079333
total_rewards_min            7901.740021653855
Number of train steps total  544000
Number of env steps total    1634000
Number of rollouts total     0
Train Time (s)               148.29791210684925
(Previous) Eval Time (s)     30.361366869416088
Sample Time (s)              10.176583805121481
Epoch Time (s)               188.83586278138682
Total Train Time (s)         24829.461013182532
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:45:09.058884 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #135 | Epoch Duration: 188.91516137123108
2020-01-13 10:45:09.059074 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2623343
Z variance train             0.039047852
KL Divergence                44.98422
KL Loss                      4.498422
QF Loss                      147.15765
VF Loss                      84.82121
Policy Loss                  -868.6917
Q Predictions Mean           865.5844
Q Predictions Std            1016.29645
Q Predictions Max            3391.2915
Q Predictions Min            324.7739
V Predictions Mean           863.8078
V Predictions Std            1011.1932
V Predictions Max            3378.2437
V Predictions Min            324.55405
Log Pis Mean                 -0.9975493
Log Pis Std                  3.26175
Log Pis Max                  14.369514
Log Pis Min                  -6.6475754
Policy mu Mean               0.0424099
Policy mu Std                0.8073026
Policy mu Max                2.6989303
Policy mu Min                -2.2366452
Policy log std Mean          -0.48304585
Policy log std Std           0.21865295
Policy log std Max           -0.062424958
Policy log std Min           -1.8774002
Z mean eval                  2.2305307
Z variance eval              0.02695414
total_rewards                [8316.844475   8289.16672765 8565.89481844 8432.72538277 8422.28534991
 8167.92233219 8403.64075487 8306.56819927 8189.51629856 8222.07626107]
total_rewards_mean           8331.664059972303
total_rewards_std            118.38605184462044
total_rewards_max            8565.894818439734
total_rewards_min            8167.922332187777
Number of train steps total  548000
Number of env steps total    1646000
Number of rollouts total     0
Train Time (s)               147.804934122134
(Previous) Eval Time (s)     29.2205831669271
Sample Time (s)              9.466749873943627
Epoch Time (s)               186.49226716300473
Total Train Time (s)         25016.036421648227
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:48:15.637298 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #136 | Epoch Duration: 186.5780589580536
2020-01-13 10:48:15.637614 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #136 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.232759
Z variance train             0.027003402
KL Divergence                45.854023
KL Loss                      4.5854025
QF Loss                      265.92474
VF Loss                      52.41188
Policy Loss                  -840.68445
Q Predictions Mean           840.3934
Q Predictions Std            974.69995
Q Predictions Max            3416.5034
Q Predictions Min            349.60406
V Predictions Mean           837.3015
V Predictions Std            972.443
V Predictions Max            3424.436
V Predictions Min            347.19025
Log Pis Mean                 -0.72055364
Log Pis Std                  3.4878454
Log Pis Max                  14.943825
Log Pis Min                  -5.9655313
Policy mu Mean               0.043547194
Policy mu Std                0.8263264
Policy mu Max                2.6698658
Policy mu Min                -3.0998652
Policy log std Mean          -0.5029783
Policy log std Std           0.23037194
Policy log std Max           -0.109910816
Policy log std Min           -2.0362082
Z mean eval                  2.2184138
Z variance eval              0.02185737
total_rewards                [7682.47228683 7895.34943365 7933.41204112 7820.20262859 8162.4278468
 7817.90711752 7840.64176596 7907.6972473  7812.24095245 7715.15545916]
total_rewards_mean           7858.750677938804
total_rewards_std            126.04295753151969
total_rewards_max            8162.4278468015555
total_rewards_min            7682.472286832342
Number of train steps total  552000
Number of env steps total    1658000
Number of rollouts total     0
Train Time (s)               146.77782084513456
(Previous) Eval Time (s)     30.971691037993878
Sample Time (s)              10.110755920410156
Epoch Time (s)               187.8602678035386
Total Train Time (s)         25203.983751546126
Epoch                        137
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:51:23.587335 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #137 | Epoch Duration: 187.9494867324829
2020-01-13 10:51:23.587654 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2223227
Z variance train             0.021829333
KL Divergence                45.533234
KL Loss                      4.5533233
QF Loss                      1685.1869
VF Loss                      76.88954
Policy Loss                  -959.57306
Q Predictions Mean           955.8024
Q Predictions Std            1069.5463
Q Predictions Max            3626.6333
Q Predictions Min            369.36633
V Predictions Mean           959.9254
V Predictions Std            1067.3517
V Predictions Max            3601.6433
V Predictions Min            376.9864
Log Pis Mean                 -0.61820257
Log Pis Std                  3.6565976
Log Pis Max                  10.482538
Log Pis Min                  -8.412802
Policy mu Mean               0.071501635
Policy mu Std                0.85967153
Policy mu Max                2.427768
Policy mu Min                -3.787291
Policy log std Mean          -0.49825034
Policy log std Std           0.25443047
Policy log std Max           -0.10334617
Policy log std Min           -2.4697654
Z mean eval                  2.2030323
Z variance eval              0.02012843
total_rewards                [7753.95985801 8114.35641272 8078.32863705 8127.02543118 8096.90060109
 7839.376919   8217.51946787 8034.78134537 8133.35424102 7953.43756734]
total_rewards_mean           8034.904048066392
total_rewards_std            136.8818562479901
total_rewards_max            8217.5194678746
total_rewards_min            7753.959858008553
Number of train steps total  556000
Number of env steps total    1670000
Number of rollouts total     0
Train Time (s)               146.0535150631331
(Previous) Eval Time (s)     29.622234331909567
Sample Time (s)              10.680300275795162
Epoch Time (s)               186.35604967083782
Total Train Time (s)         25390.41871084692
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:54:30.024101 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #138 | Epoch Duration: 186.4362552165985
2020-01-13 10:54:30.024372 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2030272
Z variance train             0.020085813
KL Divergence                45.674324
KL Loss                      4.5674324
QF Loss                      181.05405
VF Loss                      44.213318
Policy Loss                  -904.63904
Q Predictions Mean           900.9701
Q Predictions Std            1024.3329
Q Predictions Max            3588.182
Q Predictions Min            366.3472
V Predictions Mean           903.1544
V Predictions Std            1021.2892
V Predictions Max            3596.6045
V Predictions Min            376.3716
Log Pis Mean                 -0.76195383
Log Pis Std                  3.1161206
Log Pis Max                  15.532793
Log Pis Min                  -6.646266
Policy mu Mean               0.037660636
Policy mu Std                0.81321603
Policy mu Max                2.687109
Policy mu Min                -3.2212913
Policy log std Mean          -0.51918024
Policy log std Std           0.2367195
Policy log std Max           -0.13080123
Policy log std Min           -2.2262893
Z mean eval                  2.188692
Z variance eval              0.033699844
total_rewards                [8094.25841502 8399.48307159 8132.46259464 8518.03093389 8195.50339183
 8332.02344895 8386.12184945 8241.06213942 8363.69852326 8424.20347961]
total_rewards_mean           8308.684784767524
total_rewards_std            130.15305980263375
total_rewards_max            8518.030933888876
total_rewards_min            8094.258415024421
Number of train steps total  560000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               139.66554106213152
(Previous) Eval Time (s)     29.48345213709399
Sample Time (s)              10.682612034026533
Epoch Time (s)               179.83160523325205
Total Train Time (s)         25570.333674478345
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:57:29.941189 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #139 | Epoch Duration: 179.91662120819092
2020-01-13 10:57:29.941399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.185077
Z variance train             0.03358511
KL Divergence                44.433517
KL Loss                      4.4433517
QF Loss                      1631.5887
VF Loss                      122.45282
Policy Loss                  -865.50134
Q Predictions Mean           859.8165
Q Predictions Std            963.99133
Q Predictions Max            3481.7114
Q Predictions Min            359.874
V Predictions Mean           865.8188
V Predictions Std            970.0924
V Predictions Max            3489.8652
V Predictions Min            373.6952
Log Pis Mean                 -0.576596
Log Pis Std                  3.249903
Log Pis Max                  14.717731
Log Pis Min                  -6.973957
Policy mu Mean               0.04694088
Policy mu Std                0.82081777
Policy mu Max                3.5345142
Policy mu Min                -2.5150368
Policy log std Mean          -0.5094299
Policy log std Std           0.25841364
Policy log std Max           -0.11281064
Policy log std Min           -2.2652235
Z mean eval                  2.1482954
Z variance eval              0.07059306
total_rewards                [8471.50928183 8263.6547208  8177.42607495 8025.28141723 8179.33415585
 8286.42456559 8153.07762902 8415.63480162 8356.02568068 8058.02019303]
total_rewards_mean           8238.638852058744
total_rewards_std            139.633236663552
total_rewards_max            8471.509281825001
total_rewards_min            8025.281417228427
Number of train steps total  564000
Number of env steps total    1694000
Number of rollouts total     0
Train Time (s)               138.6226914790459
(Previous) Eval Time (s)     28.666053956840187
Sample Time (s)              8.744897747412324
Epoch Time (s)               176.0336431832984
Total Train Time (s)         25746.46199508896
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:00:26.072390 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #140 | Epoch Duration: 176.13080620765686
2020-01-13 11:00:26.072702 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1492968
Z variance train             0.07072438
KL Divergence                42.31694
KL Loss                      4.231694
QF Loss                      257.05084
VF Loss                      94.92305
Policy Loss                  -1006.57306
Q Predictions Mean           1001.1874
Q Predictions Std            1101.5427
Q Predictions Max            3558.1743
Q Predictions Min            358.16623
V Predictions Mean           1003.59656
V Predictions Std            1103.5714
V Predictions Max            3546.2478
V Predictions Min            366.30716
Log Pis Mean                 -0.38647908
Log Pis Std                  3.6629355
Log Pis Max                  12.437338
Log Pis Min                  -8.199776
Policy mu Mean               0.04298391
Policy mu Std                0.87494457
Policy mu Max                2.9445953
Policy mu Min                -3.3016362
Policy log std Mean          -0.5155181
Policy log std Std           0.233676
Policy log std Max           -0.10855231
Policy log std Min           -2.1403918
Z mean eval                  2.1687412
Z variance eval              0.03375037
total_rewards                [7916.72939856 8205.65110638 8444.90926576 8223.74685248 8417.65334063
 8579.34228252 2130.34910722 8341.04550973 8065.78570051 8256.47812814]
total_rewards_mean           7658.169069190471
total_rewards_std            1851.4330571605312
total_rewards_max            8579.342282520893
total_rewards_min            2130.3491072195716
Number of train steps total  568000
Number of env steps total    1706000
Number of rollouts total     0
Train Time (s)               141.61712857102975
(Previous) Eval Time (s)     29.731934366282076
Sample Time (s)              9.711050622165203
Epoch Time (s)               181.06011355947703
Total Train Time (s)         25927.60590399336
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:03:27.218044 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #141 | Epoch Duration: 181.1451609134674
2020-01-13 11:03:27.218237 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1717255
Z variance train             0.033770252
KL Divergence                45.765427
KL Loss                      4.576543
QF Loss                      272.999
VF Loss                      152.81812
Policy Loss                  -1035.7562
Q Predictions Mean           1036.0215
Q Predictions Std            1125.4829
Q Predictions Max            3550.3704
Q Predictions Min            378.8138
V Predictions Mean           1037.3767
V Predictions Std            1114.8871
V Predictions Max            3526.9402
V Predictions Min            389.33932
Log Pis Mean                 0.017832547
Log Pis Std                  3.777489
Log Pis Max                  13.274071
Log Pis Min                  -6.5853105
Policy mu Mean               0.058466837
Policy mu Std                0.8929138
Policy mu Max                2.6412728
Policy mu Min                -2.7223184
Policy log std Mean          -0.511761
Policy log std Std           0.23024018
Policy log std Max           -0.16059543
Policy log std Min           -2.033002
Z mean eval                  2.1734455
Z variance eval              0.018120896
total_rewards                [8341.60203439 8434.77206791 8475.47951262 8207.20816837 8502.34960201
 8541.61621716 8195.23187068 8158.8722167  7974.33941518 8482.62919323]
total_rewards_mean           8331.410029824512
total_rewards_std            178.62170413408398
total_rewards_max            8541.61621715982
total_rewards_min            7974.339415181298
Number of train steps total  572000
Number of env steps total    1718000
Number of rollouts total     0
Train Time (s)               149.00553187727928
(Previous) Eval Time (s)     29.615966683719307
Sample Time (s)              10.348102482035756
Epoch Time (s)               188.96960104303434
Total Train Time (s)         26116.654187864624
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:06:36.269902 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #142 | Epoch Duration: 189.05148649215698
2020-01-13 11:06:36.270286 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1716118
Z variance train             0.018112982
KL Divergence                46.889503
KL Loss                      4.6889505
QF Loss                      108.66034
VF Loss                      42.176464
Policy Loss                  -917.2148
Q Predictions Mean           914.7392
Q Predictions Std            1026.0352
Q Predictions Max            3544.734
Q Predictions Min            380.39587
V Predictions Mean           920.8008
V Predictions Std            1026.6125
V Predictions Max            3547.058
V Predictions Min            392.66992
Log Pis Mean                 -0.89202577
Log Pis Std                  3.0667152
Log Pis Max                  11.075102
Log Pis Min                  -6.596294
Policy mu Mean               0.018273847
Policy mu Std                0.81233454
Policy mu Max                3.253326
Policy mu Min                -2.74833
Policy log std Mean          -0.49143758
Policy log std Std           0.224236
Policy log std Max           -0.13267028
Policy log std Min           -1.9026294
Z mean eval                  2.176345
Z variance eval              0.022573091
total_rewards                [8176.93304521 8327.15727469 8513.29628333 8449.02412729 8317.81218338
 8435.28856656 8349.75240081 8315.25745005 8475.02443027 8348.37919253]
total_rewards_mean           8370.792495410753
total_rewards_std            93.68733778136159
total_rewards_max            8513.296283328234
total_rewards_min            8176.933045214281
Number of train steps total  576000
Number of env steps total    1730000
Number of rollouts total     0
Train Time (s)               147.6482689450495
(Previous) Eval Time (s)     29.95967560634017
Sample Time (s)              10.223689344711602
Epoch Time (s)               187.83163389610127
Total Train Time (s)         26304.56645362079
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:09:44.183474 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #143 | Epoch Duration: 187.91291332244873
2020-01-13 11:09:44.183700 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1787498
Z variance train             0.022561952
KL Divergence                47.308125
KL Loss                      4.7308125
QF Loss                      140.30885
VF Loss                      81.62327
Policy Loss                  -855.3838
Q Predictions Mean           851.1732
Q Predictions Std            966.24005
Q Predictions Max            3559.3552
Q Predictions Min            384.80353
V Predictions Mean           849.1803
V Predictions Std            966.70703
V Predictions Max            3525.5916
V Predictions Min            382.78326
Log Pis Mean                 -0.6547499
Log Pis Std                  3.490593
Log Pis Max                  17.394258
Log Pis Min                  -6.6622286
Policy mu Mean               0.018473836
Policy mu Std                0.8142593
Policy mu Max                2.7029917
Policy mu Min                -3.5589645
Policy log std Mean          -0.49341562
Policy log std Std           0.22853847
Policy log std Max           -0.115179926
Policy log std Min           -2.1738548
Z mean eval                  2.2499185
Z variance eval              0.028241068
total_rewards                [7765.62180704 8004.04515866 8047.95174436 7908.60832345 7876.70410611
 8109.3539122  7926.55068242 7823.0352433  7936.40066621 7835.6893447 ]
total_rewards_mean           7923.396098844775
total_rewards_std            100.91287424689098
total_rewards_max            8109.353912199164
total_rewards_min            7765.621807039343
Number of train steps total  580000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               147.10853546392173
(Previous) Eval Time (s)     30.939175076317042
Sample Time (s)              10.136338997632265
Epoch Time (s)               188.18404953787103
Total Train Time (s)         26492.8372672759
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:12:52.457634 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #144 | Epoch Duration: 188.2737398147583
2020-01-13 11:12:52.458018 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #144 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2469194
Z variance train             0.028144618
KL Divergence                47.29487
KL Loss                      4.729487
QF Loss                      120.347275
VF Loss                      44.02611
Policy Loss                  -945.2226
Q Predictions Mean           944.47925
Q Predictions Std            1066.3464
Q Predictions Max            3571.8738
Q Predictions Min            397.65732
V Predictions Mean           943.78864
V Predictions Std            1062.8496
V Predictions Max            3542.303
V Predictions Min            393.83026
Log Pis Mean                 -0.6736293
Log Pis Std                  3.3001277
Log Pis Max                  10.797032
Log Pis Min                  -6.461631
Policy mu Mean               0.006950704
Policy mu Std                0.82083994
Policy mu Max                3.5443857
Policy mu Min                -3.2741888
Policy log std Mean          -0.49904677
Policy log std Std           0.22338507
Policy log std Max           -0.12269206
Policy log std Min           -1.8185148
Z mean eval                  2.1668143
Z variance eval              0.034760572
total_rewards                [7795.34503475 8159.70861641 7913.48361879 7797.1608207  7764.715437
 8208.39650026 8207.75385941 7954.99317465 7676.50912748 8025.87969631]
total_rewards_mean           7950.394588575511
total_rewards_std            184.58159605662226
total_rewards_max            8208.39650025795
total_rewards_min            7676.509127478919
Number of train steps total  584000
Number of env steps total    1754000
Number of rollouts total     0
Train Time (s)               146.72189998207614
(Previous) Eval Time (s)     29.47909742873162
Sample Time (s)              10.066885977983475
Epoch Time (s)               186.26788338879123
Total Train Time (s)         26679.18685878953
Epoch                        145
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:15:58.810062 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #145 | Epoch Duration: 186.35174989700317
2020-01-13 11:15:58.810370 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.16067
Z variance train             0.03491925
KL Divergence                46.195908
KL Loss                      4.6195908
QF Loss                      108.560165
VF Loss                      137.05289
Policy Loss                  -978.1629
Q Predictions Mean           977.0746
Q Predictions Std            1067.9042
Q Predictions Max            3518.857
Q Predictions Min            393.68115
V Predictions Mean           980.699
V Predictions Std            1073.6798
V Predictions Max            3514.9055
V Predictions Min            394.637
Log Pis Mean                 -0.44817752
Log Pis Std                  3.6176713
Log Pis Max                  15.72006
Log Pis Min                  -7.287092
Policy mu Mean               0.08802574
Policy mu Std                0.8803269
Policy mu Max                2.750769
Policy mu Min                -2.962512
Policy log std Mean          -0.49383286
Policy log std Std           0.23356396
Policy log std Max           -0.103658274
Policy log std Min           -2.1011124
Z mean eval                  2.2152634
Z variance eval              0.054644138
total_rewards                [6854.47414647 7718.51505692 7766.08154682 7252.39962001 7877.23409471
 7423.29879081 7468.40955098 7946.98993338 7893.06971649 7595.97527202]
total_rewards_mean           7579.644772862206
total_rewards_std            323.3924158879938
total_rewards_max            7946.989933384826
total_rewards_min            6854.474146472708
Number of train steps total  588000
Number of env steps total    1766000
Number of rollouts total     0
Train Time (s)               138.68886513682082
(Previous) Eval Time (s)     28.269139660988003
Sample Time (s)              9.371137093752623
Epoch Time (s)               176.32914189156145
Total Train Time (s)         26855.595317708794
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:18:55.219836 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #146 | Epoch Duration: 176.4092779159546
2020-01-13 11:18:55.220053 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2085633
Z variance train             0.05450545
KL Divergence                45.15218
KL Loss                      4.5152183
QF Loss                      188.5307
VF Loss                      127.48637
Policy Loss                  -992.61224
Q Predictions Mean           989.46295
Q Predictions Std            1100.0321
Q Predictions Max            3502.4219
Q Predictions Min            389.97638
V Predictions Mean           997.8947
V Predictions Std            1103.971
V Predictions Max            3529.1755
V Predictions Min            395.58096
Log Pis Mean                 -0.44736385
Log Pis Std                  3.5215902
Log Pis Max                  10.425259
Log Pis Min                  -5.7723255
Policy mu Mean               0.06753543
Policy mu Std                0.8427409
Policy mu Max                2.6122077
Policy mu Min                -2.678588
Policy log std Mean          -0.4852033
Policy log std Std           0.24644853
Policy log std Max           -0.0941357
Policy log std Min           -2.0046868
Z mean eval                  2.205701
Z variance eval              0.026103502
total_rewards                [8118.04190141 8176.71715112 8330.86549354 8249.32542379 8198.26870886
 8225.41651062 8092.53184116 8364.01192446 8430.05040504 8372.84030672]
total_rewards_mean           8255.806966671895
total_rewards_std            108.42928290616615
total_rewards_max            8430.050405044627
total_rewards_min            8092.531841158328
Number of train steps total  592000
Number of env steps total    1778000
Number of rollouts total     0
Train Time (s)               138.26249262178317
(Previous) Eval Time (s)     28.797908112872392
Sample Time (s)              9.548860437702388
Epoch Time (s)               176.60926117235795
Total Train Time (s)         27032.28604117129
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:21:51.915416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #147 | Epoch Duration: 176.6951413154602
2020-01-13 11:21:51.915769 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.206962
Z variance train             0.02603669
KL Divergence                48.490204
KL Loss                      4.8490205
QF Loss                      198.23404
VF Loss                      143.72153
Policy Loss                  -918.561
Q Predictions Mean           914.1483
Q Predictions Std            1017.66986
Q Predictions Max            3582.7717
Q Predictions Min            394.85
V Predictions Mean           916.2964
V Predictions Std            1013.29675
V Predictions Max            3538.5464
V Predictions Min            400.25714
Log Pis Mean                 -0.6952983
Log Pis Std                  3.5611858
Log Pis Max                  11.727971
Log Pis Min                  -7.294753
Policy mu Mean               -0.00819838
Policy mu Std                0.8318244
Policy mu Max                2.7766924
Policy mu Min                -2.5570283
Policy log std Mean          -0.51063573
Policy log std Std           0.24416886
Policy log std Max           -0.11204159
Policy log std Min           -2.0376244
Z mean eval                  2.102614
Z variance eval              0.12778005
total_rewards                [8220.51675014 7708.9953958  8407.85243674 8496.50574242 8348.34114174
 8580.75973488 8438.00771009 8386.58781971 8476.5118092  8645.30401626]
total_rewards_mean           8370.938255698882
total_rewards_std            247.71477118065107
total_rewards_max            8645.304016260541
total_rewards_min            7708.995395797754
Number of train steps total  596000
Number of env steps total    1790000
Number of rollouts total     0
Train Time (s)               142.27736702328548
(Previous) Eval Time (s)     30.32547368714586
Sample Time (s)              8.94315970968455
Epoch Time (s)               181.5460004201159
Total Train Time (s)         27213.925034072716
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:24:53.554449 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #148 | Epoch Duration: 181.6384313106537
2020-01-13 11:24:53.554651 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #148 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1055434
Z variance train             0.1276926
KL Divergence                43.35855
KL Loss                      4.335855
QF Loss                      245.03069
VF Loss                      133.3502
Policy Loss                  -843.82574
Q Predictions Mean           838.3596
Q Predictions Std            951.2645
Q Predictions Max            3415.147
Q Predictions Min            362.89038
V Predictions Mean           836.0829
V Predictions Std            948.92676
V Predictions Max            3406.9856
V Predictions Min            368.63504
Log Pis Mean                 -0.4627629
Log Pis Std                  3.396911
Log Pis Max                  11.131153
Log Pis Min                  -8.456253
Policy mu Mean               0.030740852
Policy mu Std                0.8462595
Policy mu Max                3.013537
Policy mu Min                -2.5468633
Policy log std Mean          -0.5043103
Policy log std Std           0.24886185
Policy log std Max           -0.070535004
Policy log std Min           -2.292109
Z mean eval                  2.1960814
Z variance eval              0.032143585
total_rewards                [8130.69564892 7992.32624735 8494.04130584 8434.84662175 8534.9343467
 8520.89829893 8410.87701062 8670.99474364 8377.5060921  8581.31991075]
total_rewards_mean           8414.844022659769
total_rewards_std            196.55542456053303
total_rewards_max            8670.994743636002
total_rewards_min            7992.326247348571
Number of train steps total  600000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               149.33736945083365
(Previous) Eval Time (s)     28.090297194197774
Sample Time (s)              10.196435452438891
Epoch Time (s)               187.6241020974703
Total Train Time (s)         27401.722536771093
Epoch                        149
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:28:01.354378 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #149 | Epoch Duration: 187.79957175254822
2020-01-13 11:28:01.354586 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1945271
Z variance train             0.03191274
KL Divergence                46.25786
KL Loss                      4.625786
QF Loss                      775.32556
VF Loss                      194.0231
Policy Loss                  -1002.09247
Q Predictions Mean           1004.39404
Q Predictions Std            1093.3777
Q Predictions Max            3574.0425
Q Predictions Min            387.03534
V Predictions Mean           1013.29126
V Predictions Std            1091.8798
V Predictions Max            3568.6072
V Predictions Min            397.01248
Log Pis Mean                 -0.41965052
Log Pis Std                  3.5642405
Log Pis Max                  11.715264
Log Pis Min                  -8.099316
Policy mu Mean               0.051492024
Policy mu Std                0.87209743
Policy mu Max                2.5454862
Policy mu Min                -2.6318808
Policy log std Mean          -0.50167084
Policy log std Std           0.22551638
Policy log std Max           -0.06813264
Policy log std Min           -1.9083257
Z mean eval                  2.155246
Z variance eval              0.022399625
total_rewards                [8607.36041003 8807.65818939 8801.42298653 8698.43524751 8681.8746652
 8867.81971521 8935.86526514 8760.13301041 8472.16116383 8897.46557614]
total_rewards_mean           8753.019622938536
total_rewards_std            134.53409296513925
total_rewards_max            8935.865265144022
total_rewards_min            8472.161163832285
Number of train steps total  604000
Number of env steps total    1814000
Number of rollouts total     0
Train Time (s)               147.3363598510623
(Previous) Eval Time (s)     29.879186275880784
Sample Time (s)              10.248502959962934
Epoch Time (s)               187.46404908690602
Total Train Time (s)         27589.281292010564
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:31:08.915377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #150 | Epoch Duration: 187.56063532829285
2020-01-13 11:31:08.915570 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1547155
Z variance train             0.022518836
KL Divergence                47.404297
KL Loss                      4.74043
QF Loss                      256.48688
VF Loss                      75.91529
Policy Loss                  -992.201
Q Predictions Mean           991.39526
Q Predictions Std            1099.2003
Q Predictions Max            3692.956
Q Predictions Min            417.94598
V Predictions Mean           993.89825
V Predictions Std            1102.1956
V Predictions Max            3700.8477
V Predictions Min            390.35043
Log Pis Mean                 -0.1663377
Log Pis Std                  4.0353765
Log Pis Max                  16.229597
Log Pis Min                  -5.8489585
Policy mu Mean               0.044575855
Policy mu Std                0.8793151
Policy mu Max                3.2494922
Policy mu Min                -2.700223
Policy log std Mean          -0.52686363
Policy log std Std           0.2522707
Policy log std Max           -0.09054983
Policy log std Min           -2.124131
Z mean eval                  2.1817386
Z variance eval              0.03514453
total_rewards                [8262.8706516  8461.60993809 8764.34912284 8540.09214642 8610.60387473
 8531.48604987 8409.32708409 8607.79765021 8705.11446669 8719.97741647]
total_rewards_mean           8561.322840100105
total_rewards_std            146.66818475925425
total_rewards_max            8764.349122837319
total_rewards_min            8262.870651604255
Number of train steps total  608000
Number of env steps total    1826000
Number of rollouts total     0
Train Time (s)               147.80432791402563
(Previous) Eval Time (s)     30.34348106570542
Sample Time (s)              10.242589383386075
Epoch Time (s)               188.39039836311713
Total Train Time (s)         27777.777761233505
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:34:17.413075 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #151 | Epoch Duration: 188.4973738193512
2020-01-13 11:34:17.413226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1868093
Z variance train             0.034972716
KL Divergence                47.25806
KL Loss                      4.725806
QF Loss                      1982.8296
VF Loss                      108.704636
Policy Loss                  -937.9909
Q Predictions Mean           935.67535
Q Predictions Std            1040.4353
Q Predictions Max            3667.7405
Q Predictions Min            415.29492
V Predictions Mean           932.8441
V Predictions Std            1036.8679
V Predictions Max            3650.461
V Predictions Min            415.92593
Log Pis Mean                 -0.092122495
Log Pis Std                  3.5978491
Log Pis Max                  12.7207365
Log Pis Min                  -7.3469033
Policy mu Mean               0.07749698
Policy mu Std                0.866819
Policy mu Max                2.6699462
Policy mu Min                -2.5000176
Policy log std Mean          -0.49992618
Policy log std Std           0.23620218
Policy log std Max           -0.10484932
Policy log std Min           -2.0615244
Z mean eval                  2.2023687
Z variance eval              0.044835307
total_rewards                [8220.69048737 8560.07784312 8437.26827609 8471.46673781 8374.44825901
 8577.26336653 8525.18554398 8535.38984726 8705.56751349 8511.38649901]
total_rewards_mean           8491.874437367327
total_rewards_std            123.17450831486124
total_rewards_max            8705.567513493192
total_rewards_min            8220.690487370637
Number of train steps total  612000
Number of env steps total    1838000
Number of rollouts total     0
Train Time (s)               148.04452622309327
(Previous) Eval Time (s)     29.118592251092196
Sample Time (s)              9.33984117442742
Epoch Time (s)               186.5029596486129
Total Train Time (s)         27964.357852202374
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:37:23.996464 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #152 | Epoch Duration: 186.58311009407043
2020-01-13 11:37:23.996675 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2060943
Z variance train             0.04463592
KL Divergence                46.811844
KL Loss                      4.6811843
QF Loss                      181.62057
VF Loss                      43.599487
Policy Loss                  -982.5604
Q Predictions Mean           981.80725
Q Predictions Std            1096.9316
Q Predictions Max            3747.7546
Q Predictions Min            423.6278
V Predictions Mean           983.92346
V Predictions Std            1094.0532
V Predictions Max            3710.9856
V Predictions Min            428.91013
Log Pis Mean                 -0.82850885
Log Pis Std                  3.372351
Log Pis Max                  12.322427
Log Pis Min                  -7.001683
Policy mu Mean               -0.011787762
Policy mu Std                0.82584757
Policy mu Max                3.1993186
Policy mu Min                -2.8255088
Policy log std Mean          -0.4845331
Policy log std Std           0.22063337
Policy log std Max           -0.12245214
Policy log std Min           -1.8984147
Z mean eval                  2.1854167
Z variance eval              0.03947995
total_rewards                [8476.67459235 8779.37246379 8450.33586675 9039.24537163 8679.18961989
 8741.95118168 8710.46935242 8769.86780349 8745.24072343 8594.23972217]
total_rewards_mean           8698.658669758594
total_rewards_std            159.3712288778828
total_rewards_max            9039.24537163152
total_rewards_min            8450.335866746138
Number of train steps total  616000
Number of env steps total    1850000
Number of rollouts total     0
Train Time (s)               139.03246581507847
(Previous) Eval Time (s)     28.980010621715337
Sample Time (s)              9.779454745352268
Epoch Time (s)               177.79193118214607
Total Train Time (s)         28142.24498588359
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:40:21.886301 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #153 | Epoch Duration: 177.88947081565857
2020-01-13 11:40:21.886514 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1830328
Z variance train             0.039579898
KL Divergence                47.93748
KL Loss                      4.7937484
QF Loss                      639.4772
VF Loss                      101.40291
Policy Loss                  -1034.8179
Q Predictions Mean           1032.1671
Q Predictions Std            1111.3291
Q Predictions Max            3729.31
Q Predictions Min            398.50317
V Predictions Mean           1040.5721
V Predictions Std            1116.2089
V Predictions Max            3747.5032
V Predictions Min            404.65588
Log Pis Mean                 -0.4237611
Log Pis Std                  3.8210914
Log Pis Max                  13.990115
Log Pis Min                  -8.398929
Policy mu Mean               0.06511638
Policy mu Std                0.8804356
Policy mu Max                3.1477387
Policy mu Min                -2.9513342
Policy log std Mean          -0.5017607
Policy log std Std           0.2612086
Policy log std Max           -0.102843165
Policy log std Min           -2.5016274
Z mean eval                  2.1402385
Z variance eval              0.029461423
total_rewards                [7460.50964465 7670.66853423 7396.00577156 7274.7702716  7483.27715655
 7723.28405145 7401.4778014  7584.5914216  7272.71692133 7382.41545989]
total_rewards_mean           7464.971703425303
total_rewards_std            145.7539455774119
total_rewards_max            7723.284051450611
total_rewards_min            7272.716921329067
Number of train steps total  620000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               138.7877790192142
(Previous) Eval Time (s)     29.494442731142044
Sample Time (s)              9.71515161730349
Epoch Time (s)               177.99737336765975
Total Train Time (s)         28320.332520689815
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:43:19.976148 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #154 | Epoch Duration: 178.0894799232483
2020-01-13 11:43:19.976369 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1396544
Z variance train             0.029382577
KL Divergence                48.257942
KL Loss                      4.825794
QF Loss                      104.7632
VF Loss                      76.090034
Policy Loss                  -956.5761
Q Predictions Mean           955.19165
Q Predictions Std            1062.946
Q Predictions Max            3762.3535
Q Predictions Min            420.196
V Predictions Mean           960.42303
V Predictions Std            1064.8745
V Predictions Max            3758.3467
V Predictions Min            427.48312
Log Pis Mean                 -0.65334487
Log Pis Std                  3.725331
Log Pis Max                  14.085333
Log Pis Min                  -6.9621763
Policy mu Mean               0.14456354
Policy mu Std                0.8585484
Policy mu Max                2.8113418
Policy mu Min                -2.8405418
Policy log std Mean          -0.4775673
Policy log std Std           0.22460005
Policy log std Max           -0.092613965
Policy log std Min           -1.850003
Z mean eval                  2.1248848
Z variance eval              0.027565112
total_rewards                [8279.18580107 8287.97668422 8666.52930888 8499.38551141 8696.84463524
 8770.27692608 8615.47956094 8579.193668   8701.23568385 8547.83225433]
total_rewards_mean           8564.394003401187
total_rewards_std            159.4263550062697
total_rewards_max            8770.276926083556
total_rewards_min            8279.185801065145
Number of train steps total  624000
Number of env steps total    1874000
Number of rollouts total     0
Train Time (s)               144.46016362681985
(Previous) Eval Time (s)     30.379987614694983
Sample Time (s)              9.718787060119212
Epoch Time (s)               184.55893830163404
Total Train Time (s)         28504.971292742994
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:46:24.616861 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #155 | Epoch Duration: 184.6403408050537
2020-01-13 11:46:24.617050 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.127646
Z variance train             0.0276617
KL Divergence                49.039196
KL Loss                      4.9039197
QF Loss                      120.23288
VF Loss                      53.347874
Policy Loss                  -957.4368
Q Predictions Mean           956.4235
Q Predictions Std            1062.9421
Q Predictions Max            3670.1978
Q Predictions Min            423.72787
V Predictions Mean           961.8767
V Predictions Std            1060.3633
V Predictions Max            3654.935
V Predictions Min            430.4898
Log Pis Mean                 -0.6219578
Log Pis Std                  3.552361
Log Pis Max                  12.152086
Log Pis Min                  -10.418669
Policy mu Mean               0.05757178
Policy mu Std                0.8665121
Policy mu Max                2.5921223
Policy mu Min                -2.8131833
Policy log std Mean          -0.4722687
Policy log std Std           0.21534915
Policy log std Max           -0.11196807
Policy log std Min           -1.9895319
Z mean eval                  2.114313
Z variance eval              0.045393478
total_rewards                [8528.81439481 8811.29682797 8802.19168307 8585.75707285 8755.91336019
 8386.51704653 8481.94388083 8514.41777361 8608.89702594 8526.13313973]
total_rewards_mean           8600.188220552642
total_rewards_std            136.922863494649
total_rewards_max            8811.296827969563
total_rewards_min            8386.517046532268
Number of train steps total  628000
Number of env steps total    1886000
Number of rollouts total     0
Train Time (s)               148.61310618184507
(Previous) Eval Time (s)     29.862470478750765
Sample Time (s)              10.408858647104353
Epoch Time (s)               188.8844353077002
Total Train Time (s)         28693.941311164293
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:49:33.589495 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #156 | Epoch Duration: 188.9722979068756
2020-01-13 11:49:33.589701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1171176
Z variance train             0.04585295
KL Divergence                48.5512
KL Loss                      4.85512
QF Loss                      106.99804
VF Loss                      126.66464
Policy Loss                  -955.689
Q Predictions Mean           952.1184
Q Predictions Std            1045.0936
Q Predictions Max            3660.8723
Q Predictions Min            424.3985
V Predictions Mean           956.6178
V Predictions Std            1047.4104
V Predictions Max            3660.3303
V Predictions Min            427.03137
Log Pis Mean                 -0.5165478
Log Pis Std                  3.7175944
Log Pis Max                  14.841507
Log Pis Min                  -7.3378897
Policy mu Mean               0.029712193
Policy mu Std                0.84549093
Policy mu Max                3.2281477
Policy mu Min                -3.241565
Policy log std Mean          -0.49266252
Policy log std Std           0.23431638
Policy log std Max           -0.102323264
Policy log std Min           -2.0229764
Z mean eval                  2.149187
Z variance eval              0.042993844
total_rewards                [8282.98240833 8667.30176043 8425.43399938 8341.45286498 8790.80728978
 8804.43525717 8661.44908625 8684.53993453 8734.29557902 8555.50871255]
total_rewards_mean           8594.820689240383
total_rewards_std            176.4143705965199
total_rewards_max            8804.435257166075
total_rewards_min            8282.982408325952
Number of train steps total  632000
Number of env steps total    1898000
Number of rollouts total     0
Train Time (s)               147.76119852624834
(Previous) Eval Time (s)     30.36403524596244
Sample Time (s)              10.12054289598018
Epoch Time (s)               188.24577666819096
Total Train Time (s)         28882.267989005893
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:52:41.919982 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #157 | Epoch Duration: 188.33009243011475
2020-01-13 11:52:41.920371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1423697
Z variance train             0.043072052
KL Divergence                48.911617
KL Loss                      4.891162
QF Loss                      1911.1869
VF Loss                      35.46434
Policy Loss                  -1033.8604
Q Predictions Mean           1038.2355
Q Predictions Std            1130.2196
Q Predictions Max            3715.772
Q Predictions Min            432.3995
V Predictions Mean           1033.136
V Predictions Std            1126.3965
V Predictions Max            3693.2556
V Predictions Min            430.75012
Log Pis Mean                 -0.48902404
Log Pis Std                  3.5732906
Log Pis Max                  12.321733
Log Pis Min                  -6.528973
Policy mu Mean               0.029267281
Policy mu Std                0.8571983
Policy mu Max                2.8353326
Policy mu Min                -2.447666
Policy log std Mean          -0.487558
Policy log std Std           0.23550117
Policy log std Max           -0.117170736
Policy log std Min           -2.3037312
Z mean eval                  2.0993862
Z variance eval              0.07513456
total_rewards                [8414.39409768 8994.42638068 8935.80223142 8956.01389585 8936.84634674
 8887.64648043 9005.63483749 8798.58253418 9055.57127066 8965.24043398]
total_rewards_mean           8895.015850911208
total_rewards_std            173.29558305956954
total_rewards_max            9055.571270660357
total_rewards_min            8414.394097678542
Number of train steps total  636000
Number of env steps total    1910000
Number of rollouts total     0
Train Time (s)               148.90919490205124
(Previous) Eval Time (s)     29.320739227347076
Sample Time (s)              10.120643921662122
Epoch Time (s)               188.35057805106044
Total Train Time (s)         29070.702752627898
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:55:50.362275 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #158 | Epoch Duration: 188.44164109230042
2020-01-13 11:55:50.362664 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1019769
Z variance train             0.07486199
KL Divergence                47.4388
KL Loss                      4.7438803
QF Loss                      131.62767
VF Loss                      78.35807
Policy Loss                  -1018.49115
Q Predictions Mean           1016.4502
Q Predictions Std            1107.6648
Q Predictions Max            3741.8596
Q Predictions Min            434.1249
V Predictions Mean           1019.6417
V Predictions Std            1101.7777
V Predictions Max            3705.251
V Predictions Min            432.8506
Log Pis Mean                 -0.718588
Log Pis Std                  3.554472
Log Pis Max                  12.983827
Log Pis Min                  -6.1694045
Policy mu Mean               0.007900869
Policy mu Std                0.84985924
Policy mu Max                3.490955
Policy mu Min                -2.9115243
Policy log std Mean          -0.48373973
Policy log std Std           0.24873488
Policy log std Max           -0.11668843
Policy log std Min           -2.4860635
Z mean eval                  2.0359313
Z variance eval              0.15866081
total_rewards                [8494.1391949  8796.14142386 8609.37908591 8732.12775843 8994.61255993
 8568.5641419  8537.20241142 8731.41484327 8701.62179888 8697.27344177]
total_rewards_mean           8686.247666027042
total_rewards_std            138.0387182396435
total_rewards_max            8994.612559928646
total_rewards_min            8494.139194901523
Number of train steps total  640000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               146.56379760801792
(Previous) Eval Time (s)     29.410056767053902
Sample Time (s)              10.108592167962343
Epoch Time (s)               186.08244654303417
Total Train Time (s)         29256.885088548996
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:58:56.540560 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #159 | Epoch Duration: 186.1775677204132
2020-01-13 11:58:56.540780 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.038518
Z variance train             0.15851434
KL Divergence                43.32673
KL Loss                      4.332673
QF Loss                      236.57748
VF Loss                      97.11302
Policy Loss                  -1056.7646
Q Predictions Mean           1054.6855
Q Predictions Std            1112.8207
Q Predictions Max            3770.092
Q Predictions Min            449.99716
V Predictions Mean           1057.4009
V Predictions Std            1115.8022
V Predictions Max            3763.8777
V Predictions Min            444.22662
Log Pis Mean                 -0.2331002
Log Pis Std                  4.0263195
Log Pis Max                  17.49754
Log Pis Min                  -7.0812306
Policy mu Mean               0.033255104
Policy mu Std                0.88721377
Policy mu Max                2.8004773
Policy mu Min                -3.2599444
Policy log std Mean          -0.4961891
Policy log std Std           0.2713414
Policy log std Max           -0.0758504
Policy log std Min           -2.1955829
Z mean eval                  2.088977
Z variance eval              0.052288257
total_rewards                [ 872.14177753 8472.07508144 8565.92208946 8570.56069249 8521.31552799
 8532.05627957 8516.28831067 8647.01374244 8282.41485526 8672.34595283]
total_rewards_mean           7765.213430967779
total_rewards_std            2299.9047611812316
total_rewards_max            8672.345952828644
total_rewards_min            872.1417775318987
Number of train steps total  644000
Number of env steps total    1934000
Number of rollouts total     0
Train Time (s)               139.19680281635374
(Previous) Eval Time (s)     29.47788847517222
Sample Time (s)              10.102482394780964
Epoch Time (s)               178.77717368630692
Total Train Time (s)         29435.74489072524
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:01:55.403155 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #160 | Epoch Duration: 178.86221027374268
2020-01-13 12:01:55.403509 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0907037
Z variance train             0.052385516
KL Divergence                47.517445
KL Loss                      4.7517447
QF Loss                      196.12802
VF Loss                      68.12969
Policy Loss                  -1187.8673
Q Predictions Mean           1186.1699
Q Predictions Std            1223.6632
Q Predictions Max            3783.9285
Q Predictions Min            450.96832
V Predictions Mean           1185.8989
V Predictions Std            1218.7838
V Predictions Max            3774.3684
V Predictions Min            455.77518
Log Pis Mean                 -0.2771459
Log Pis Std                  3.905691
Log Pis Max                  12.35335
Log Pis Min                  -8.542013
Policy mu Mean               0.032076564
Policy mu Std                0.8934086
Policy mu Max                2.7043915
Policy mu Min                -2.9539065
Policy log std Mean          -0.48482463
Policy log std Std           0.25277996
Policy log std Max           -0.06858444
Policy log std Min           -2.7407053
Z mean eval                  2.0936055
Z variance eval              0.06686712
total_rewards                [8611.32901492 8504.17820141 8521.08869644 8574.76214874 8259.36465904
 8491.60458181 8380.13546023 8553.0191832  8198.45383683 8483.37975183]
total_rewards_mean           8457.731553444519
total_rewards_std            129.205346795666
total_rewards_max            8611.32901491626
total_rewards_min            8198.453836832692
Number of train steps total  648000
Number of env steps total    1946000
Number of rollouts total     0
Train Time (s)               138.11878685979173
(Previous) Eval Time (s)     29.07811583392322
Sample Time (s)              9.654133355244994
Epoch Time (s)               176.85103604895994
Total Train Time (s)         29612.74193705665
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:04:52.404166 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #161 | Epoch Duration: 177.0005190372467
2020-01-13 12:04:52.404297 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.092524
Z variance train             0.06706377
KL Divergence                48.18185
KL Loss                      4.8181853
QF Loss                      143.26582
VF Loss                      45.129936
Policy Loss                  -1040.7449
Q Predictions Mean           1040.3982
Q Predictions Std            1130.6501
Q Predictions Max            3728.0435
Q Predictions Min            446.6929
V Predictions Mean           1037.3105
V Predictions Std            1126.7078
V Predictions Max            3719.5122
V Predictions Min            446.99216
Log Pis Mean                 -0.41796237
Log Pis Std                  3.4052596
Log Pis Max                  12.762218
Log Pis Min                  -8.659999
Policy mu Mean               0.07660728
Policy mu Std                0.8789874
Policy mu Max                2.921904
Policy mu Min                -2.8081465
Policy log std Mean          -0.49949923
Policy log std Std           0.24428444
Policy log std Max           -0.11676003
Policy log std Min           -2.192954
Z mean eval                  2.0813148
Z variance eval              0.034179825
total_rewards                [8626.3044334  8781.15844789 8574.01519872 8868.33608389 8772.92516082
 8688.74247587 8685.54100629 8909.23153121 8721.08969443 8669.31765003]
total_rewards_mean           8729.66616825309
total_rewards_std            99.11811690845755
total_rewards_max            8909.231531208652
total_rewards_min            8574.015198720972
Number of train steps total  652000
Number of env steps total    1958000
Number of rollouts total     0
Train Time (s)               146.35174747090787
(Previous) Eval Time (s)     30.569273192901164
Sample Time (s)              9.372865123208612
Epoch Time (s)               186.29388578701764
Total Train Time (s)         29799.12605552608
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:07:58.793694 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #162 | Epoch Duration: 186.38920426368713
2020-01-13 12:07:58.794071 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0804863
Z variance train             0.03419448
KL Divergence                50.39032
KL Loss                      5.039032
QF Loss                      118.69335
VF Loss                      101.9218
Policy Loss                  -1018.22284
Q Predictions Mean           1016.0299
Q Predictions Std            1092.7087
Q Predictions Max            3774.8235
Q Predictions Min            436.17014
V Predictions Mean           1018.8371
V Predictions Std            1092.9938
V Predictions Max            3780.468
V Predictions Min            445.99518
Log Pis Mean                 -0.4794345
Log Pis Std                  3.8801067
Log Pis Max                  15.348597
Log Pis Min                  -7.6340714
Policy mu Mean               0.10174144
Policy mu Std                0.86293733
Policy mu Max                3.2753627
Policy mu Min                -3.2078245
Policy log std Mean          -0.48254827
Policy log std Std           0.2439983
Policy log std Max           -0.07415205
Policy log std Min           -2.3840494
Z mean eval                  2.080271
Z variance eval              0.044998292
total_rewards                [8482.57132657 8755.24359321 8570.02004013 8699.49387683 8641.38570555
 9132.20363051 9019.37561403 8729.67898742 8636.35691457 8823.0660457 ]
total_rewards_mean           8748.939573452399
total_rewards_std            188.56941508499602
total_rewards_max            9132.203630510576
total_rewards_min            8482.571326570614
Number of train steps total  656000
Number of env steps total    1970000
Number of rollouts total     0
Train Time (s)               147.44083258556202
(Previous) Eval Time (s)     30.815295004751533
Sample Time (s)              10.51669149659574
Epoch Time (s)               188.7728190869093
Total Train Time (s)         29987.98277012864
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:11:07.651885 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #163 | Epoch Duration: 188.85756492614746
2020-01-13 12:11:07.652111 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0788012
Z variance train             0.044786803
KL Divergence                50.523678
KL Loss                      5.0523677
QF Loss                      189.00824
VF Loss                      62.05076
Policy Loss                  -1074.9923
Q Predictions Mean           1072.2725
Q Predictions Std            1128.38
Q Predictions Max            3768.2617
Q Predictions Min            441.76245
V Predictions Mean           1070.5956
V Predictions Std            1126.8524
V Predictions Max            3763.9702
V Predictions Min            441.331
Log Pis Mean                 -0.58906305
Log Pis Std                  3.7530127
Log Pis Max                  17.239937
Log Pis Min                  -6.8967333
Policy mu Mean               0.065567635
Policy mu Std                0.8683863
Policy mu Max                3.1504638
Policy mu Min                -2.958657
Policy log std Mean          -0.47259292
Policy log std Std           0.25310633
Policy log std Max           -0.074973226
Policy log std Min           -2.5040793
Z mean eval                  2.065192
Z variance eval              0.029512847
total_rewards                [8728.60839423 9123.88031343 8785.49767038 8996.59719434 8833.21091745
 9029.57233837 8751.51379763 9073.9180536  9094.66433892 9133.16273314]
total_rewards_mean           8955.062575148075
total_rewards_std            154.08597792893508
total_rewards_max            9133.16273313538
total_rewards_min            8728.608394225766
Number of train steps total  660000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               147.34508167533204
(Previous) Eval Time (s)     30.548857225105166
Sample Time (s)              10.322490381542593
Epoch Time (s)               188.2164292819798
Total Train Time (s)         30176.30661080405
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:14:15.978847 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #164 | Epoch Duration: 188.3265643119812
2020-01-13 12:14:15.979074 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0653358
Z variance train             0.029497555
KL Divergence                51.008327
KL Loss                      5.100833
QF Loss                      192.37903
VF Loss                      24.635382
Policy Loss                  -985.9562
Q Predictions Mean           987.50104
Q Predictions Std            1060.8931
Q Predictions Max            3839.9624
Q Predictions Min            407.3807
V Predictions Mean           986.5171
V Predictions Std            1060.9158
V Predictions Max            3829.36
V Predictions Min            375.559
Log Pis Mean                 -0.510213
Log Pis Std                  3.4253006
Log Pis Max                  11.3540125
Log Pis Min                  -7.5761433
Policy mu Mean               0.05341028
Policy mu Std                0.83715177
Policy mu Max                2.504739
Policy mu Min                -2.6280622
Policy log std Mean          -0.47995055
Policy log std Std           0.25422564
Policy log std Max           -0.11248653
Policy log std Min           -2.632633
Z mean eval                  2.0572486
Z variance eval              0.027313525
total_rewards                [8414.4886776  8357.18391078 8107.50615249 8328.22705949 8267.37140704
 8452.60861146 8560.04222005 8218.24790022 8492.55711032 8336.54437556]
total_rewards_mean           8353.477742499992
total_rewards_std            127.55497765967962
total_rewards_max            8560.04222004893
total_rewards_min            8107.506152487046
Number of train steps total  664000
Number of env steps total    1994000
Number of rollouts total     0
Train Time (s)               149.34385490324348
(Previous) Eval Time (s)     29.38843216560781
Sample Time (s)              10.336214213632047
Epoch Time (s)               189.06850128248334
Total Train Time (s)         30365.456127294805
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:17:25.130935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #165 | Epoch Duration: 189.14977288246155
2020-01-13 12:17:25.131371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0592177
Z variance train             0.027386133
KL Divergence                51.509186
KL Loss                      5.1509185
QF Loss                      243.35056
VF Loss                      152.94676
Policy Loss                  -1169.4037
Q Predictions Mean           1169.5459
Q Predictions Std            1197.1067
Q Predictions Max            3846.7192
Q Predictions Min            458.2905
V Predictions Mean           1165.673
V Predictions Std            1197.1488
V Predictions Max            3845.6072
V Predictions Min            455.76926
Log Pis Mean                 -0.38107604
Log Pis Std                  4.040452
Log Pis Max                  14.450258
Log Pis Min                  -6.8665442
Policy mu Mean               0.070813395
Policy mu Std                0.90103245
Policy mu Max                3.352597
Policy mu Min                -2.9588563
Policy log std Mean          -0.5023472
Policy log std Std           0.2580431
Policy log std Max           -0.09949902
Policy log std Min           -2.4583118
Z mean eval                  2.0619712
Z variance eval              0.052271686
total_rewards                [8226.14447878 8502.56639844 8717.5035838  8497.39435372 8278.60614236
 8305.79711046 8564.22811279 8467.46620158 8534.3377758  8677.13990548]
total_rewards_mean           8477.118406321753
total_rewards_std            155.41997553448772
total_rewards_max            8717.50358380224
total_rewards_min            8226.14447877769
Number of train steps total  668000
Number of env steps total    2006000
Number of rollouts total     0
Train Time (s)               146.21844824496657
(Previous) Eval Time (s)     29.044337684754282
Sample Time (s)              10.441966796759516
Epoch Time (s)               185.70475272648036
Total Train Time (s)         30551.243156235665
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:20:30.918576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #166 | Epoch Duration: 185.7870306968689
2020-01-13 12:20:30.918722 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.061555
Z variance train             0.052122883
KL Divergence                51.110584
KL Loss                      5.1110587
QF Loss                      2305.6284
VF Loss                      76.98999
Policy Loss                  -1033.9968
Q Predictions Mean           1034.1218
Q Predictions Std            1114.0656
Q Predictions Max            3846.504
Q Predictions Min            466.44806
V Predictions Mean           1038.5042
V Predictions Std            1115.5817
V Predictions Max            3854.1284
V Predictions Min            467.35068
Log Pis Mean                 -0.29161742
Log Pis Std                  3.8608086
Log Pis Max                  13.962753
Log Pis Min                  -5.6271005
Policy mu Mean               0.02971225
Policy mu Std                0.8664263
Policy mu Max                2.6862745
Policy mu Min                -3.0667257
Policy log std Mean          -0.50445455
Policy log std Std           0.26162484
Policy log std Max           -0.13356945
Policy log std Min           -2.248378
Z mean eval                  2.011781
Z variance eval              0.050130874
total_rewards                [8987.81034936 9020.74190607 9243.38878654 9083.79504363 9034.4403238
 8942.02140973 9266.76650974 9064.48232079 9171.70013617 8982.64791257]
total_rewards_mean           9079.779469839297
total_rewards_std            106.22754438750276
total_rewards_max            9266.766509735076
total_rewards_min            8942.021409727266
Number of train steps total  672000
Number of env steps total    2018000
Number of rollouts total     0
Train Time (s)               138.90807302715257
(Previous) Eval Time (s)     28.903620639815927
Sample Time (s)              9.522300300654024
Epoch Time (s)               177.33399396762252
Total Train Time (s)         30728.656737839803
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:23:28.333875 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #167 | Epoch Duration: 177.41504502296448
2020-01-13 12:23:28.334016 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0116751
Z variance train             0.05016293
KL Divergence                50.308357
KL Loss                      5.0308356
QF Loss                      118.93103
VF Loss                      68.106544
Policy Loss                  -1056.5422
Q Predictions Mean           1054.0464
Q Predictions Std            1143.218
Q Predictions Max            3868.3706
Q Predictions Min            451.56537
V Predictions Mean           1054.0314
V Predictions Std            1135.4818
V Predictions Max            3852.9734
V Predictions Min            457.7945
Log Pis Mean                 -0.39427558
Log Pis Std                  3.7918506
Log Pis Max                  14.154652
Log Pis Min                  -6.3506284
Policy mu Mean               0.024261795
Policy mu Std                0.84954107
Policy mu Max                2.9915388
Policy mu Min                -2.9648955
Policy log std Mean          -0.5058425
Policy log std Std           0.25481188
Policy log std Max           -0.13026544
Policy log std Min           -2.6480656
Z mean eval                  1.9921631
Z variance eval              0.024620848
total_rewards                [8762.5317907  9261.919872   8755.49818921 9274.93605347 8952.06999482
 6153.68428407 9157.65519715 9228.24002931 8929.00766266 9019.71386734]
total_rewards_mean           8749.525694072556
total_rewards_std            884.2611616641001
total_rewards_max            9274.93605347022
total_rewards_min            6153.684284073283
Number of train steps total  676000
Number of env steps total    2030000
Number of rollouts total     0
Train Time (s)               138.8907105117105
(Previous) Eval Time (s)     29.542864105664194
Sample Time (s)              9.589354590512812
Epoch Time (s)               178.0229292078875
Total Train Time (s)         30906.76571068773
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:26:26.447451 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #168 | Epoch Duration: 178.11330556869507
2020-01-13 12:26:26.447699 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #168 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9928373
Z variance train             0.024756106
KL Divergence                51.449814
KL Loss                      5.1449814
QF Loss                      1835.0958
VF Loss                      40.2664
Policy Loss                  -975.5558
Q Predictions Mean           973.15186
Q Predictions Std            1055.018
Q Predictions Max            3773.9263
Q Predictions Min            461.101
V Predictions Mean           978.67737
V Predictions Std            1054.8064
V Predictions Max            3767.4727
V Predictions Min            467.48196
Log Pis Mean                 -0.70400316
Log Pis Std                  3.4757066
Log Pis Max                  12.072732
Log Pis Min                  -7.1400423
Policy mu Mean               0.029558904
Policy mu Std                0.836216
Policy mu Max                2.925242
Policy mu Min                -2.5921323
Policy log std Mean          -0.47579083
Policy log std Std           0.2564754
Policy log std Max           -0.092990994
Policy log std Min           -2.5380125
Z mean eval                  2.0424314
Z variance eval              0.028655168
total_rewards                [8305.03382643 9654.91634205 9030.52344567 9060.14512969 9193.123224
 9073.20582401 9190.39759017 8695.81786359  967.32962219 9340.51895545]
total_rewards_mean           8251.101182324233
total_rewards_std            2451.92023459167
total_rewards_max            9654.916342048868
total_rewards_min            967.3296221913628
Number of train steps total  680000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               147.35599661711603
(Previous) Eval Time (s)     31.01493593584746
Sample Time (s)              9.902735934592783
Epoch Time (s)               188.27366848755628
Total Train Time (s)         31095.125047461595
Epoch                        169
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:29:34.810879 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #169 | Epoch Duration: 188.36294388771057
2020-01-13 12:29:34.811644 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0417747
Z variance train             0.0286634
KL Divergence                51.866726
KL Loss                      5.1866727
QF Loss                      153.32265
VF Loss                      113.81043
Policy Loss                  -954.59064
Q Predictions Mean           948.28674
Q Predictions Std            1014.69556
Q Predictions Max            3815.9248
Q Predictions Min            470.61414
V Predictions Mean           958.1064
V Predictions Std            1015.2483
V Predictions Max            3817.5708
V Predictions Min            474.9649
Log Pis Mean                 -0.6078588
Log Pis Std                  3.5283787
Log Pis Max                  14.541546
Log Pis Min                  -7.6056013
Policy mu Mean               0.16008733
Policy mu Std                0.850935
Policy mu Max                3.6215177
Policy mu Min                -3.1743245
Policy log std Mean          -0.49440864
Policy log std Std           0.24288784
Policy log std Max           -0.10002375
Policy log std Min           -2.3150685
Z mean eval                  2.0093029
Z variance eval              0.031214258
total_rewards                [8549.10570954 8730.71517282 9014.54035357 8946.56376616 8655.08737275
 9038.77294568 8507.87223674 8872.10956159 8991.87202497 8900.83588834]
total_rewards_mean           8820.747503216184
total_rewards_std            186.14123740693003
total_rewards_max            9038.772945681256
total_rewards_min            8507.872236744302
Number of train steps total  684000
Number of env steps total    2054000
Number of rollouts total     0
Train Time (s)               146.89505851874128
(Previous) Eval Time (s)     30.21684702625498
Sample Time (s)              9.99187989672646
Epoch Time (s)               187.10378544172272
Total Train Time (s)         31282.319178858772
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:32:42.006029 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #170 | Epoch Duration: 187.1939561367035
2020-01-13 12:32:42.006274 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0064855
Z variance train             0.031226119
KL Divergence                51.432915
KL Loss                      5.1432915
QF Loss                      114.3945
VF Loss                      45.19129
Policy Loss                  -1001.857
Q Predictions Mean           1002.36865
Q Predictions Std            1079.2767
Q Predictions Max            3881.6711
Q Predictions Min            470.9236
V Predictions Mean           1004.51025
V Predictions Std            1078.3473
V Predictions Max            3902.6091
V Predictions Min            472.53302
Log Pis Mean                 -0.6200917
Log Pis Std                  3.4119606
Log Pis Max                  12.907988
Log Pis Min                  -7.58204
Policy mu Mean               0.034051143
Policy mu Std                0.85709935
Policy mu Max                2.863758
Policy mu Min                -3.207958
Policy log std Mean          -0.47071448
Policy log std Std           0.22804256
Policy log std Max           -0.091442764
Policy log std Min           -2.1367588
Z mean eval                  1.9648384
Z variance eval              0.04554338
total_rewards                [8847.78217009 8712.28298854 8870.47886701 8934.71803446 8962.22594662
 9025.40461268 9267.97497828 8999.93763121 9044.8551606  9137.93090971]
total_rewards_mean           8980.359129917611
total_rewards_std            147.66548519632843
total_rewards_max            9267.974978279452
total_rewards_min            8712.282988535431
Number of train steps total  688000
Number of env steps total    2066000
Number of rollouts total     0
Train Time (s)               147.3518476788886
(Previous) Eval Time (s)     29.82857843581587
Sample Time (s)              10.67811676999554
Epoch Time (s)               187.8585428847
Total Train Time (s)         31470.261907854117
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:35:49.951360 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #171 | Epoch Duration: 187.9449121952057
2020-01-13 12:35:49.951583 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9676096
Z variance train             0.045858227
KL Divergence                48.77925
KL Loss                      4.8779254
QF Loss                      173.60751
VF Loss                      76.366974
Policy Loss                  -1011.24506
Q Predictions Mean           1006.8497
Q Predictions Std            1083.1375
Q Predictions Max            3850.974
Q Predictions Min            461.4361
V Predictions Mean           1006.597
V Predictions Std            1080.275
V Predictions Max            3838.498
V Predictions Min            464.43948
Log Pis Mean                 -0.39600682
Log Pis Std                  3.5285997
Log Pis Max                  18.906393
Log Pis Min                  -7.4345784
Policy mu Mean               0.045785483
Policy mu Std                0.8536841
Policy mu Max                3.3581035
Policy mu Min                -3.4611664
Policy log std Mean          -0.5053821
Policy log std Std           0.23366924
Policy log std Max           -0.13571404
Policy log std Min           -2.5069427
Z mean eval                  1.9423927
Z variance eval              0.037884925
total_rewards                [8395.00593493 8549.02962012 9061.88296279 8500.30715355 8271.18377525
 9151.87336865 8365.09516125 8622.56035803 8099.47202785 8122.39533893]
total_rewards_mean           8513.880570136458
total_rewards_std            337.7480658977902
total_rewards_max            9151.873368654617
total_rewards_min            8099.472027849242
Number of train steps total  692000
Number of env steps total    2078000
Number of rollouts total     0
Train Time (s)               148.62380821397528
(Previous) Eval Time (s)     30.341711704153568
Sample Time (s)              10.478574963286519
Epoch Time (s)               189.44409488141537
Total Train Time (s)         31659.789719273802
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:38:59.481777 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #172 | Epoch Duration: 189.53003096580505
2020-01-13 12:38:59.482014 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9430269
Z variance train             0.037840333
KL Divergence                48.610435
KL Loss                      4.8610435
QF Loss                      162.73528
VF Loss                      59.6011
Policy Loss                  -1036.9028
Q Predictions Mean           1034.1572
Q Predictions Std            1125.5632
Q Predictions Max            3881.0437
Q Predictions Min            475.47528
V Predictions Mean           1037.8306
V Predictions Std            1127.9014
V Predictions Max            3898.7031
V Predictions Min            479.79605
Log Pis Mean                 -0.51255834
Log Pis Std                  3.558608
Log Pis Max                  11.006218
Log Pis Min                  -7.129802
Policy mu Mean               0.106965184
Policy mu Std                0.85607195
Policy mu Max                3.0427248
Policy mu Min                -2.2160244
Policy log std Mean          -0.46735254
Policy log std Std           0.23061386
Policy log std Max           -0.03921634
Policy log std Min           -2.3067317
Z mean eval                  1.9647042
Z variance eval              0.064683415
total_rewards                [9040.54456897 8842.90977615 8540.85725857 8900.814265   8881.12376202
 8852.50528707 8739.56049391 8619.91879473 8990.05058118 8837.44843216]
total_rewards_mean           8824.573321975973
total_rewards_std            146.26161023522806
total_rewards_max            9040.544568966698
total_rewards_min            8540.857258570255
Number of train steps total  696000
Number of env steps total    2090000
Number of rollouts total     0
Train Time (s)               144.3755367831327
(Previous) Eval Time (s)     28.610009549185634
Sample Time (s)              10.33257382037118
Epoch Time (s)               183.31812015268952
Total Train Time (s)         31843.265702241566
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:42:02.960515 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #173 | Epoch Duration: 183.47832918167114
2020-01-13 12:42:02.960764 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9670372
Z variance train             0.06476463
KL Divergence                48.9779
KL Loss                      4.8977904
QF Loss                      119.911705
VF Loss                      30.988598
Policy Loss                  -1115.8229
Q Predictions Mean           1115.0107
Q Predictions Std            1155.6947
Q Predictions Max            3930.6052
Q Predictions Min            488.97
V Predictions Mean           1116.1906
V Predictions Std            1157.0376
V Predictions Max            3911.0432
V Predictions Min            488.26144
Log Pis Mean                 -0.41412494
Log Pis Std                  3.599601
Log Pis Max                  11.660397
Log Pis Min                  -9.209082
Policy mu Mean               0.039444033
Policy mu Std                0.8980873
Policy mu Max                2.7892418
Policy mu Min                -2.9835293
Policy log std Mean          -0.48089132
Policy log std Std           0.24042454
Policy log std Max           -0.09311283
Policy log std Min           -2.0323386
Z mean eval                  1.9533596
Z variance eval              0.041765608
total_rewards                [9146.52828445 9288.04528486 9287.88134137 9314.72617275 9465.97744975
 9451.42155093 8928.93268398 9198.17006079 9403.69084592 9239.1211002 ]
total_rewards_mean           9272.44947750025
total_rewards_std            151.48109230548775
total_rewards_max            9465.97744975406
total_rewards_min            8928.93268397701
Number of train steps total  700000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               138.9276871001348
(Previous) Eval Time (s)     29.451921520754695
Sample Time (s)              9.564154892228544
Epoch Time (s)               177.94376351311803
Total Train Time (s)         32021.330171806738
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:45:01.027313 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #174 | Epoch Duration: 178.06636786460876
2020-01-13 12:45:01.027532 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9521786
Z variance train             0.041797552
KL Divergence                51.291817
KL Loss                      5.129182
QF Loss                      192.09938
VF Loss                      73.07231
Policy Loss                  -1076.8768
Q Predictions Mean           1074.4991
Q Predictions Std            1145.4336
Q Predictions Max            3970.5522
Q Predictions Min            483.74466
V Predictions Mean           1080.1007
V Predictions Std            1143.9653
V Predictions Max            3955.6682
V Predictions Min            487.94687
Log Pis Mean                 -0.55175006
Log Pis Std                  3.3956506
Log Pis Max                  15.893473
Log Pis Min                  -6.610014
Policy mu Mean               0.044412564
Policy mu Std                0.8560575
Policy mu Max                2.8504782
Policy mu Min                -3.1650023
Policy log std Mean          -0.5039368
Policy log std Std           0.26914015
Policy log std Max           -0.11204374
Policy log std Min           -2.8798537
Z mean eval                  1.9407545
Z variance eval              0.055985563
total_rewards                [8837.51843679 8878.89440639 9030.71989035 8931.00136285 8838.28311978
 8643.19162903 8785.95207406 8989.71668174 8888.58292669 8668.64457843]
total_rewards_mean           8849.250510612172
total_rewards_std            118.79152540093764
total_rewards_max            9030.719890345516
total_rewards_min            8643.191629030449
Number of train steps total  704000
Number of env steps total    2114000
Number of rollouts total     0
Train Time (s)               139.09171475702897
(Previous) Eval Time (s)     30.094175776001066
Sample Time (s)              9.530290581285954
Epoch Time (s)               178.716181114316
Total Train Time (s)         32200.127687871456
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:47:59.827494 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #175 | Epoch Duration: 178.7997977733612
2020-01-13 12:47:59.827713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9393566
Z variance train             0.055832904
KL Divergence                50.320232
KL Loss                      5.0320234
QF Loss                      4296.388
VF Loss                      46.93524
Policy Loss                  -1060.5804
Q Predictions Mean           1059.8915
Q Predictions Std            1112.8181
Q Predictions Max            4011.789
Q Predictions Min            482.82608
V Predictions Mean           1062.5701
V Predictions Std            1113.1864
V Predictions Max            4007.9363
V Predictions Min            491.83676
Log Pis Mean                 -0.47311157
Log Pis Std                  3.1847038
Log Pis Max                  9.594635
Log Pis Min                  -5.2763834
Policy mu Mean               0.06509998
Policy mu Std                0.84872156
Policy mu Max                2.852513
Policy mu Min                -2.7651014
Policy log std Mean          -0.47645307
Policy log std Std           0.22505325
Policy log std Max           -0.07202971
Policy log std Min           -2.1265278
Z mean eval                  1.9331948
Z variance eval              0.05834096
total_rewards                [8503.19347832 8589.48907388 8892.46325628 8750.17914026 8908.30831355
 9093.27750557 8759.41102539 8334.67829388 9039.70899621 9143.1088798 ]
total_rewards_mean           8801.38179631477
total_rewards_std            251.89674212205912
total_rewards_max            9143.10887980114
total_rewards_min            8334.678293877123
Number of train steps total  708000
Number of env steps total    2126000
Number of rollouts total     0
Train Time (s)               147.63156989216805
(Previous) Eval Time (s)     30.38207650044933
Sample Time (s)              10.313375811558217
Epoch Time (s)               188.3270222041756
Total Train Time (s)         32388.535402645823
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:51:08.237654 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #176 | Epoch Duration: 188.40978121757507
2020-01-13 12:51:08.237866 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #176 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9339005
Z variance train             0.05834223
KL Divergence                50.229855
KL Loss                      5.0229855
QF Loss                      204.52425
VF Loss                      128.11517
Policy Loss                  -1003.05536
Q Predictions Mean           997.51917
Q Predictions Std            1068.8357
Q Predictions Max            3899.3225
Q Predictions Min            488.45255
V Predictions Mean           1000.7956
V Predictions Std            1065.8785
V Predictions Max            3880.2
V Predictions Min            492.42236
Log Pis Mean                 -0.72949904
Log Pis Std                  3.3396888
Log Pis Max                  13.449586
Log Pis Min                  -6.707367
Policy mu Mean               0.024607474
Policy mu Std                0.83597344
Policy mu Max                2.7199783
Policy mu Min                -2.9641297
Policy log std Mean          -0.47630802
Policy log std Std           0.23861484
Policy log std Max           -0.07149264
Policy log std Min           -2.5776117
Z mean eval                  1.9364363
Z variance eval              0.049440607
total_rewards                [8603.99464059 8819.00558038 8913.80303427 8598.02355624 8857.9484151
 9102.53641043 8641.61755579 8588.96076069 8733.15329951 9178.5405722 ]
total_rewards_mean           8803.758382518527
total_rewards_std            201.16012945759678
total_rewards_max            9178.540572197648
total_rewards_min            8588.96076068663
Number of train steps total  712000
Number of env steps total    2138000
Number of rollouts total     0
Train Time (s)               147.24362300289795
(Previous) Eval Time (s)     29.182817824184895
Sample Time (s)              9.199539371300489
Epoch Time (s)               185.62598019838333
Total Train Time (s)         32574.25195428217
Epoch                        177
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:54:13.956835 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #177 | Epoch Duration: 185.71880316734314
2020-01-13 12:54:13.957108 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9361403
Z variance train             0.04952144
KL Divergence                50.998905
KL Loss                      5.0998907
QF Loss                      122.471664
VF Loss                      46.86341
Policy Loss                  -1123.6644
Q Predictions Mean           1119.7548
Q Predictions Std            1177.932
Q Predictions Max            3946.0225
Q Predictions Min            486.47363
V Predictions Mean           1121.508
V Predictions Std            1176.6084
V Predictions Max            3928.236
V Predictions Min            486.73532
Log Pis Mean                 -0.56523764
Log Pis Std                  3.5589895
Log Pis Max                  12.658583
Log Pis Min                  -8.538107
Policy mu Mean               0.039446253
Policy mu Std                0.84595627
Policy mu Max                2.9054801
Policy mu Min                -2.788606
Policy log std Mean          -0.4908106
Policy log std Std           0.2515977
Policy log std Max           -0.048332155
Policy log std Min           -2.5367289
Z mean eval                  1.9408255
Z variance eval              0.058695506
total_rewards                [8231.13624803 8109.04264903 8225.10950982 8513.59099069 8963.15941257
 8056.83696758 8432.68250843 8569.35385626 8416.60950502 8350.68689367]
total_rewards_mean           8386.820854109621
total_rewards_std            249.45736480477737
total_rewards_max            8963.159412566474
total_rewards_min            8056.836967582703
Number of train steps total  716000
Number of env steps total    2150000
Number of rollouts total     0
Train Time (s)               146.22352354088798
(Previous) Eval Time (s)     30.276424020994455
Sample Time (s)              10.606714885681868
Epoch Time (s)               187.1066624475643
Total Train Time (s)         32761.43847739324
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:57:21.146867 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #178 | Epoch Duration: 187.18956851959229
2020-01-13 12:57:21.147219 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9418011
Z variance train             0.058627028
KL Divergence                49.030354
KL Loss                      4.9030356
QF Loss                      97.09429
VF Loss                      47.56856
Policy Loss                  -1057.3707
Q Predictions Mean           1055.7228
Q Predictions Std            1139.593
Q Predictions Max            4029.3718
Q Predictions Min            481.11252
V Predictions Mean           1060.9369
V Predictions Std            1137.5897
V Predictions Max            4015.4326
V Predictions Min            486.88736
Log Pis Mean                 -0.5348885
Log Pis Std                  3.827223
Log Pis Max                  19.504189
Log Pis Min                  -7.4101176
Policy mu Mean               0.07398491
Policy mu Std                0.8860419
Policy mu Max                3.0662193
Policy mu Min                -3.4262702
Policy log std Mean          -0.47833022
Policy log std Std           0.25796318
Policy log std Max           -0.11561161
Policy log std Min           -2.5490515
Z mean eval                  1.9412243
Z variance eval              0.037696026
total_rewards                [9018.12613881 9389.04729295 9017.64329431 9222.64448849 9185.71627475
 7601.40539873 8923.02793312 8629.86899351 9052.82669775 8744.17698593]
total_rewards_mean           8878.448349834889
total_rewards_std            474.924762416413
total_rewards_max            9389.047292952473
total_rewards_min            7601.405398725975
Number of train steps total  720000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               148.16451917402446
(Previous) Eval Time (s)     29.893246869090945
Sample Time (s)              10.557952008210123
Epoch Time (s)               188.61571805132553
Total Train Time (s)         32950.13556086831
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:00:29.845776 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #179 | Epoch Duration: 188.69835543632507
2020-01-13 13:00:29.845974 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #179 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9367956
Z variance train             0.037942886
KL Divergence                49.78205
KL Loss                      4.978205
QF Loss                      117.694664
VF Loss                      82.3996
Policy Loss                  -1021.34894
Q Predictions Mean           1019.3909
Q Predictions Std            1105.4117
Q Predictions Max            4012.132
Q Predictions Min            492.43774
V Predictions Mean           1023.9137
V Predictions Std            1103.8093
V Predictions Max            3966.5808
V Predictions Min            496.23145
Log Pis Mean                 -0.7225971
Log Pis Std                  3.477234
Log Pis Max                  12.280769
Log Pis Min                  -6.236669
Policy mu Mean               0.09823251
Policy mu Std                0.8453424
Policy mu Max                2.7182631
Policy mu Min                -2.6215374
Policy log std Mean          -0.48751318
Policy log std Std           0.2371777
Policy log std Max           -0.10988352
Policy log std Min           -2.6464076
Z mean eval                  1.9079382
Z variance eval              0.07056258
total_rewards                [8985.32081107 9507.01356089 8942.11950867 9151.68349206 9051.7434156
 9113.42337464 8950.46186629 9207.65229514 9183.37001555 9141.80944354]
total_rewards_mean           9123.459778345376
total_rewards_std            156.86405581949512
total_rewards_max            9507.01356088754
total_rewards_min            8942.119508674434
Number of train steps total  724000
Number of env steps total    2174000
Number of rollouts total     0
Train Time (s)               143.3023061589338
(Previous) Eval Time (s)     29.362628073897213
Sample Time (s)              9.718804797623307
Epoch Time (s)               182.3837390304543
Total Train Time (s)         33132.64071074175
Epoch                        180
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:03:32.353272 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #180 | Epoch Duration: 182.50715827941895
2020-01-13 13:03:32.353454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9090945
Z variance train             0.070080325
KL Divergence                49.00385
KL Loss                      4.900385
QF Loss                      213.30762
VF Loss                      167.18324
Policy Loss                  -1099.7386
Q Predictions Mean           1093.2861
Q Predictions Std            1166.8926
Q Predictions Max            4013.5623
Q Predictions Min            470.58786
V Predictions Mean           1096.4291
V Predictions Std            1159.369
V Predictions Max            3981.045
V Predictions Min            493.043
Log Pis Mean                 -0.08214054
Log Pis Std                  4.2250586
Log Pis Max                  16.084963
Log Pis Min                  -11.045612
Policy mu Mean               0.08019078
Policy mu Std                0.9050186
Policy mu Max                3.2994976
Policy mu Min                -3.9725585
Policy log std Mean          -0.5070669
Policy log std Std           0.273952
Policy log std Max           -0.08461636
Policy log std Min           -2.7833862
Z mean eval                  1.9454508
Z variance eval              0.052446842
total_rewards                [8925.17875768 8712.03749641 8575.85511486 8975.00973277 9324.11454388
 8539.21916313 9008.75589457 8428.27420141 8714.41952442 8451.9823945 ]
total_rewards_mean           8765.484682362461
total_rewards_std            272.9955040590547
total_rewards_max            9324.114543875112
total_rewards_min            8428.274201407858
Number of train steps total  728000
Number of env steps total    2186000
Number of rollouts total     0
Train Time (s)               139.15647706016898
(Previous) Eval Time (s)     29.550926784984767
Sample Time (s)              9.771641636732966
Epoch Time (s)               178.47904548188671
Total Train Time (s)         33311.28298304463
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:06:30.998329 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #181 | Epoch Duration: 178.64473009109497
2020-01-13 13:06:30.998533 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9479742
Z variance train             0.05261262
KL Divergence                51.367516
KL Loss                      5.1367517
QF Loss                      192.61458
VF Loss                      142.67879
Policy Loss                  -1115.1973
Q Predictions Mean           1109.5247
Q Predictions Std            1175.656
Q Predictions Max            3934.6567
Q Predictions Min            501.13794
V Predictions Mean           1107.7196
V Predictions Std            1171.1675
V Predictions Max            3921.7703
V Predictions Min            497.76764
Log Pis Mean                 -0.41840714
Log Pis Std                  3.876518
Log Pis Max                  21.364971
Log Pis Min                  -8.471304
Policy mu Mean               0.006785799
Policy mu Std                0.8625613
Policy mu Max                2.8059278
Policy mu Min                -3.4685175
Policy log std Mean          -0.48070726
Policy log std Std           0.24398468
Policy log std Max           -0.08523244
Policy log std Min           -2.5041075
Z mean eval                  1.925317
Z variance eval              0.078164145
total_rewards                [8701.5537345  9101.68118792 8788.9724376  8930.34879401 9016.40996717
 8970.14135815 8960.02494283 9061.8366054  9047.61445739 8956.60803861]
total_rewards_mean           8953.519152356785
total_rewards_std            117.43979875963157
total_rewards_max            9101.681187920613
total_rewards_min            8701.553734498273
Number of train steps total  732000
Number of env steps total    2198000
Number of rollouts total     0
Train Time (s)               140.0440906570293
(Previous) Eval Time (s)     30.003740685991943
Sample Time (s)              9.20689451135695
Epoch Time (s)               179.2547258543782
Total Train Time (s)         33490.61950517632
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:09:30.336485 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #182 | Epoch Duration: 179.3378026485443
2020-01-13 13:09:30.336652 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.921369
Z variance train             0.07802439
KL Divergence                50.826122
KL Loss                      5.0826125
QF Loss                      299.59686
VF Loss                      189.92339
Policy Loss                  -1030.5309
Q Predictions Mean           1025.836
Q Predictions Std            1105.8052
Q Predictions Max            3911.8152
Q Predictions Min            480.88785
V Predictions Mean           1038.8424
V Predictions Std            1109.7521
V Predictions Max            3914.9912
V Predictions Min            485.08926
Log Pis Mean                 -0.4642915
Log Pis Std                  3.4850738
Log Pis Max                  14.5157795
Log Pis Min                  -6.714938
Policy mu Mean               0.12583391
Policy mu Std                0.8531608
Policy mu Max                3.3320043
Policy mu Min                -2.8375134
Policy log std Mean          -0.4851304
Policy log std Std           0.24261391
Policy log std Max           -0.09127593
Policy log std Min           -2.5609212
Z mean eval                  1.9254701
Z variance eval              0.08996547
total_rewards                [8927.65177671 9359.78429033 9351.10748854 9631.80423924 9585.85163599
 9418.19994587 9059.52019492 9046.03548232 9343.73385404 9175.25741285]
total_rewards_mean           9289.894632082449
total_rewards_std            221.22080951849486
total_rewards_max            9631.804239242118
total_rewards_min            8927.651776713785
Number of train steps total  736000
Number of env steps total    2210000
Number of rollouts total     0
Train Time (s)               149.61264483397827
(Previous) Eval Time (s)     31.383650433272123
Sample Time (s)              10.012826483231038
Epoch Time (s)               191.00912175048143
Total Train Time (s)         33681.71343564289
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:12:41.433234 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #183 | Epoch Duration: 191.09643650054932
2020-01-13 13:12:41.433464 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9239031
Z variance train             0.09004324
KL Divergence                52.28631
KL Loss                      5.228631
QF Loss                      2574.7725
VF Loss                      51.616764
Policy Loss                  -1107.1185
Q Predictions Mean           1108.9635
Q Predictions Std            1166.8344
Q Predictions Max            4040.808
Q Predictions Min            519.4063
V Predictions Mean           1109.9285
V Predictions Std            1165.8997
V Predictions Max            4023.188
V Predictions Min            521.2471
Log Pis Mean                 0.024978474
Log Pis Std                  3.833364
Log Pis Max                  15.110693
Log Pis Min                  -6.639738
Policy mu Mean               0.06110699
Policy mu Std                0.9086543
Policy mu Max                3.0431836
Policy mu Min                -3.4720562
Policy log std Mean          -0.49914297
Policy log std Std           0.2666703
Policy log std Max           -0.08988309
Policy log std Min           -2.6452806
Z mean eval                  1.9570885
Z variance eval              0.061071627
total_rewards                [4781.59942777 9219.82226957 9618.19571416 9487.92481085 9164.55304494
 9470.51259143 9677.27034387 9507.32926776 9511.34217927 9664.57266151]
total_rewards_mean           9010.312231111635
total_rewards_std            1418.8045641858948
total_rewards_max            9677.270343869046
total_rewards_min            4781.599427770526
Number of train steps total  740000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               147.70548482099548
(Previous) Eval Time (s)     29.46096076304093
Sample Time (s)              9.629806211218238
Epoch Time (s)               186.79625179525465
Total Train Time (s)         33868.58921069559
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:15:48.311814 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #184 | Epoch Duration: 186.87818694114685
2020-01-13 13:15:48.312038 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.95275
Z variance train             0.060998697
KL Divergence                51.906155
KL Loss                      5.1906157
QF Loss                      105.72724
VF Loss                      82.007126
Policy Loss                  -1032.5393
Q Predictions Mean           1033.1185
Q Predictions Std            1085.0953
Q Predictions Max            3962.337
Q Predictions Min            513.8967
V Predictions Mean           1034.9559
V Predictions Std            1086.3969
V Predictions Max            3972.6108
V Predictions Min            514.1047
Log Pis Mean                 -0.86006814
Log Pis Std                  3.7084157
Log Pis Max                  17.966967
Log Pis Min                  -6.619138
Policy mu Mean               0.07863775
Policy mu Std                0.81172997
Policy mu Max                3.0636256
Policy mu Min                -3.3132331
Policy log std Mean          -0.45299062
Policy log std Std           0.22764637
Policy log std Max           -0.05371517
Policy log std Min           -2.3840466
Z mean eval                  1.9401417
Z variance eval              0.10120217
total_rewards                [8935.89206188 9025.46480388 8986.41690747 8804.47110284 9225.91642328
 9437.79211727 9329.17822258 9035.5328887  9439.35541408 9302.70350287]
total_rewards_mean           9152.272344483988
total_rewards_std            211.72843744272132
total_rewards_max            9439.35541407722
total_rewards_min            8804.471102843727
Number of train steps total  744000
Number of env steps total    2234000
Number of rollouts total     0
Train Time (s)               147.19213108997792
(Previous) Eval Time (s)     31.037403407972306
Sample Time (s)              10.039826205000281
Epoch Time (s)               188.2693607029505
Total Train Time (s)         34056.96176856756
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:18:56.687606 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #185 | Epoch Duration: 188.37540936470032
2020-01-13 13:18:56.687874 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9401144
Z variance train             0.10132667
KL Divergence                50.202328
KL Loss                      5.0202327
QF Loss                      121.527405
VF Loss                      35.610394
Policy Loss                  -995.97284
Q Predictions Mean           993.3054
Q Predictions Std            1050.2698
Q Predictions Max            3979.8418
Q Predictions Min            502.5866
V Predictions Mean           995.7721
V Predictions Std            1049.021
V Predictions Max            3962.6257
V Predictions Min            503.65533
Log Pis Mean                 -0.5127485
Log Pis Std                  3.2812312
Log Pis Max                  15.736429
Log Pis Min                  -6.8817043
Policy mu Mean               -0.0049005947
Policy mu Std                0.82111794
Policy mu Max                2.5955892
Policy mu Min                -3.277822
Policy log std Mean          -0.48445547
Policy log std Std           0.22502509
Policy log std Max           -0.01312539
Policy log std Min           -2.6254475
Z mean eval                  1.9359424
Z variance eval              0.05198931
total_rewards                [9163.61609877 9270.49481424 9375.97207214 9313.50232901 9359.12338433
 9316.65101532 9436.14941364 9418.07206833 9522.14142503 9044.7418427 ]
total_rewards_mean           9322.046446352293
total_rewards_std            130.88880081649398
total_rewards_max            9522.14142503067
total_rewards_min            9044.741842700574
Number of train steps total  748000
Number of env steps total    2246000
Number of rollouts total     0
Train Time (s)               147.19583628699183
(Previous) Eval Time (s)     29.715112154837698
Sample Time (s)              10.618488805368543
Epoch Time (s)               187.52943724719808
Total Train Time (s)         34244.57641534507
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:22:04.305479 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #186 | Epoch Duration: 187.61740374565125
2020-01-13 13:22:04.305807 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9344747
Z variance train             0.051930297
KL Divergence                50.700226
KL Loss                      5.0700226
QF Loss                      203.98708
VF Loss                      45.143238
Policy Loss                  -930.1241
Q Predictions Mean           928.5874
Q Predictions Std            978.7939
Q Predictions Max            3982.1345
Q Predictions Min            477.18207
V Predictions Mean           933.5711
V Predictions Std            977.20294
V Predictions Max            3975.6624
V Predictions Min            493.06418
Log Pis Mean                 -0.9660952
Log Pis Std                  3.217488
Log Pis Max                  11.186579
Log Pis Min                  -6.917834
Policy mu Mean               0.08048938
Policy mu Std                0.79021776
Policy mu Max                2.5808325
Policy mu Min                -3.0778372
Policy log std Mean          -0.4564418
Policy log std Std           0.23572214
Policy log std Max           -0.03513211
Policy log std Min           -2.4575586
Z mean eval                  1.9503477
Z variance eval              0.16381209
total_rewards                [8756.61163363 8957.5091237  9061.97525354 8884.51249983 9315.92161007
 8676.57549625 9128.42802192 9029.11688959 9006.02016989 8624.13756595]
total_rewards_mean           8944.080826436975
total_rewards_std            202.4876197869683
total_rewards_max            9315.921610071728
total_rewards_min            8624.137565946878
Number of train steps total  752000
Number of env steps total    2258000
Number of rollouts total     0
Train Time (s)               141.85815311828628
(Previous) Eval Time (s)     28.233587838709354
Sample Time (s)              10.710410868749022
Epoch Time (s)               180.80215182574466
Total Train Time (s)         34425.468005931005
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:25:05.199128 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #187 | Epoch Duration: 180.89312720298767
2020-01-13 13:25:05.199416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9519724
Z variance train             0.16328624
KL Divergence                47.198418
KL Loss                      4.719842
QF Loss                      2287.2334
VF Loss                      81.038574
Policy Loss                  -1060.4485
Q Predictions Mean           1061.7603
Q Predictions Std            1118.8125
Q Predictions Max            3802.9458
Q Predictions Min            490.18558
V Predictions Mean           1065.0203
V Predictions Std            1115.2655
V Predictions Max            3775.2458
V Predictions Min            492.72754
Log Pis Mean                 -0.4908263
Log Pis Std                  3.5915627
Log Pis Max                  14.927872
Log Pis Min                  -6.063915
Policy mu Mean               0.07165457
Policy mu Std                0.8570095
Policy mu Max                3.1576922
Policy mu Min                -3.047296
Policy log std Mean          -0.47908768
Policy log std Std           0.24016222
Policy log std Max           -0.07943389
Policy log std Min           -2.306212
Z mean eval                  1.9562546
Z variance eval              0.060431816
total_rewards                [9092.54043647 8694.33092731 8902.73287433 6843.37249749 8632.43365001
 8370.21708335 8772.26417433 8512.92706807 8523.67838061 8910.48372304]
total_rewards_mean           8525.498081501288
total_rewards_std            597.2194174757401
total_rewards_max            9092.540436474079
total_rewards_min            6843.372497493403
Number of train steps total  756000
Number of env steps total    2270000
Number of rollouts total     0
Train Time (s)               138.9614158719778
(Previous) Eval Time (s)     29.460286683868617
Sample Time (s)              9.583050356712192
Epoch Time (s)               178.00475291255862
Total Train Time (s)         34603.55752659077
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:28:03.292464 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #188 | Epoch Duration: 178.0928831100464
2020-01-13 13:28:03.292739 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9617153
Z variance train             0.060694385
KL Divergence                50.442417
KL Loss                      5.044242
QF Loss                      2628.6128
VF Loss                      187.81325
Policy Loss                  -1053.8561
Q Predictions Mean           1052.8492
Q Predictions Std            1123.6146
Q Predictions Max            4080.5293
Q Predictions Min            515.0862
V Predictions Mean           1046.3779
V Predictions Std            1116.6375
V Predictions Max            4029.9277
V Predictions Min            517.85284
Log Pis Mean                 -0.68628216
Log Pis Std                  3.6067414
Log Pis Max                  12.546151
Log Pis Min                  -6.0571365
Policy mu Mean               0.048141737
Policy mu Std                0.86803836
Policy mu Max                3.3447084
Policy mu Min                -2.7360203
Policy log std Mean          -0.47233808
Policy log std Std           0.24674255
Policy log std Max           -0.043685198
Policy log std Min           -2.540897
Z mean eval                  1.9462335
Z variance eval              0.07055757
total_rewards                [8439.33474649 8644.56717832 8655.47893924 8743.84883857 8843.04078059
 8818.10519382 9176.9826293  8962.39413427 8379.97707556 8422.58124059]
total_rewards_mean           8708.6310756747
total_rewards_std            241.72867335961058
total_rewards_max            9176.982629296945
total_rewards_min            8379.977075556106
Number of train steps total  760000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               141.90566956531256
(Previous) Eval Time (s)     30.314615163952112
Sample Time (s)              9.646109879482538
Epoch Time (s)               181.8663946087472
Total Train Time (s)         34785.50520303007
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:31:05.241537 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #189 | Epoch Duration: 181.94860887527466
2020-01-13 13:31:05.241738 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9456985
Z variance train             0.07035293
KL Divergence                51.348984
KL Loss                      5.1348987
QF Loss                      306.07367
VF Loss                      119.511
Policy Loss                  -1193.7457
Q Predictions Mean           1185.7223
Q Predictions Std            1238.2465
Q Predictions Max            4139.997
Q Predictions Min            492.55392
V Predictions Mean           1189.1663
V Predictions Std            1236.8269
V Predictions Max            4113.7847
V Predictions Min            483.12973
Log Pis Mean                 -0.2393094
Log Pis Std                  3.7883077
Log Pis Max                  15.915189
Log Pis Min                  -6.320306
Policy mu Mean               0.048405275
Policy mu Std                0.8966718
Policy mu Max                3.1036553
Policy mu Min                -2.6294768
Policy log std Mean          -0.4945986
Policy log std Std           0.23292007
Policy log std Max           0.04345548
Policy log std Min           -2.2084336
Z mean eval                  1.9307995
Z variance eval              0.056795187
total_rewards                [9215.29483    9361.87822088 9127.84295215 9215.49329897 9451.42149565
 8963.96820872 9358.12121212 9345.36934557 9298.0031742  9502.89857903]
total_rewards_mean           9284.029131729078
total_rewards_std            150.8929199634045
total_rewards_max            9502.89857902932
total_rewards_min            8963.968208718727
Number of train steps total  764000
Number of env steps total    2294000
Number of rollouts total     0
Train Time (s)               149.67412758711725
(Previous) Eval Time (s)     29.383043095935136
Sample Time (s)              9.921954871620983
Epoch Time (s)               188.97912555467337
Total Train Time (s)         34974.56567739742
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:34:14.304744 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #190 | Epoch Duration: 189.06285905838013
2020-01-13 13:34:14.304946 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9300258
Z variance train             0.05669553
KL Divergence                51.90067
KL Loss                      5.190067
QF Loss                      5027.9053
VF Loss                      117.90147
Policy Loss                  -1168.028
Q Predictions Mean           1166.8832
Q Predictions Std            1218.7452
Q Predictions Max            4081.2788
Q Predictions Min            508.39444
V Predictions Mean           1176.7773
V Predictions Std            1219.0887
V Predictions Max            4085.298
V Predictions Min            531.5977
Log Pis Mean                 -0.23755625
Log Pis Std                  3.6102555
Log Pis Max                  14.606024
Log Pis Min                  -6.9039984
Policy mu Mean               -0.019511625
Policy mu Std                0.8911327
Policy mu Max                3.2811806
Policy mu Min                -3.2023609
Policy log std Mean          -0.49672648
Policy log std Std           0.24957842
Policy log std Max           -0.079199195
Policy log std Min           -2.6177208
Z mean eval                  1.9428091
Z variance eval              0.10601845
total_rewards                [8736.32871345 8768.23471565 8890.96405809 8795.64544799 8666.67121128
 8919.37600516 8748.45710881 8957.14346723 8768.34400904 8880.46538559]
total_rewards_mean           8813.163012228937
total_rewards_std            88.58812255481624
total_rewards_max            8957.143467232207
total_rewards_min            8666.671211275347
Number of train steps total  768000
Number of env steps total    2306000
Number of rollouts total     0
Train Time (s)               147.98580936016515
(Previous) Eval Time (s)     30.85677061928436
Sample Time (s)              10.142281475942582
Epoch Time (s)               188.9848614553921
Total Train Time (s)         35163.62898254581
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:37:23.371142 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #191 | Epoch Duration: 189.06603026390076
2020-01-13 13:37:23.371418 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9387615
Z variance train             0.10630693
KL Divergence                50.809307
KL Loss                      5.0809307
QF Loss                      118.30022
VF Loss                      61.181583
Policy Loss                  -1080.9425
Q Predictions Mean           1078.7098
Q Predictions Std            1132.4766
Q Predictions Max            4047.5278
Q Predictions Min            513.8639
V Predictions Mean           1083.143
V Predictions Std            1135.9556
V Predictions Max            4044.7974
V Predictions Min            522.8601
Log Pis Mean                 -0.66124666
Log Pis Std                  3.4298294
Log Pis Max                  11.299713
Log Pis Min                  -8.905299
Policy mu Mean               0.04166239
Policy mu Std                0.84206265
Policy mu Max                3.010534
Policy mu Min                -2.71945
Policy log std Mean          -0.47401595
Policy log std Std           0.2275879
Policy log std Max           0.07689583
Policy log std Min           -2.1650681
Z mean eval                  1.918931
Z variance eval              0.11393376
total_rewards                [9142.84780547 8996.60283831 8935.95654129 9085.09253831 9294.49333138
 9329.21408687 9029.66331575 8978.66930882 9201.0632159  9087.38364347]
total_rewards_mean           9108.098662556375
total_rewards_std            126.25830598147706
total_rewards_max            9329.214086865248
total_rewards_min            8935.956541285635
Number of train steps total  772000
Number of env steps total    2318000
Number of rollouts total     0
Train Time (s)               147.42956167971715
(Previous) Eval Time (s)     30.360289896838367
Sample Time (s)              9.682514756917953
Epoch Time (s)               187.47236633347347
Total Train Time (s)         35351.19916200545
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:40:30.943917 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #192 | Epoch Duration: 187.5723021030426
2020-01-13 13:40:30.944184 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9195023
Z variance train             0.11390046
KL Divergence                49.649925
KL Loss                      4.9649925
QF Loss                      561.64514
VF Loss                      101.28495
Policy Loss                  -1077.5945
Q Predictions Mean           1071.325
Q Predictions Std            1136.6487
Q Predictions Max            4052.8237
Q Predictions Min            516.9155
V Predictions Mean           1075.6227
V Predictions Std            1135.8347
V Predictions Max            4049.3103
V Predictions Min            520.48676
Log Pis Mean                 -0.07083679
Log Pis Std                  3.8782382
Log Pis Max                  20.103315
Log Pis Min                  -6.1625805
Policy mu Mean               0.113333344
Policy mu Std                0.90616894
Policy mu Max                3.8112645
Policy mu Min                -3.4686835
Policy log std Mean          -0.51612973
Policy log std Std           0.26629844
Policy log std Max           -0.11658275
Policy log std Min           -2.3599067
Z mean eval                  1.9435542
Z variance eval              0.11032851
total_rewards                [8937.08253959 9360.59497905 9226.71875987 8989.40723916 9014.54566393
 8845.43851042 9130.63787567 7726.18835774 9085.87625377 9198.56778289]
total_rewards_mean           8951.50579620987
total_rewards_std            432.7298407397212
total_rewards_max            9360.594979051773
total_rewards_min            7726.188357740542
Number of train steps total  776000
Number of env steps total    2330000
Number of rollouts total     0
Train Time (s)               147.15452496195212
(Previous) Eval Time (s)     30.460512766148895
Sample Time (s)              10.460349612403661
Epoch Time (s)               188.07538734050468
Total Train Time (s)         35539.36076012114
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:43:39.108182 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #193 | Epoch Duration: 188.16382241249084
2020-01-13 13:43:39.108400 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9427636
Z variance train             0.10965569
KL Divergence                50.68133
KL Loss                      5.0681334
QF Loss                      2730.1313
VF Loss                      155.9462
Policy Loss                  -1032.559
Q Predictions Mean           1031.264
Q Predictions Std            1068.2673
Q Predictions Max            4028.1355
Q Predictions Min            523.1471
V Predictions Mean           1030.0464
V Predictions Std            1059.552
V Predictions Max            3985.7244
V Predictions Min            531.1125
Log Pis Mean                 -0.39940888
Log Pis Std                  3.5675356
Log Pis Max                  18.252235
Log Pis Min                  -7.616749
Policy mu Mean               0.07074633
Policy mu Std                0.86611664
Policy mu Max                3.2747002
Policy mu Min                -3.116649
Policy log std Mean          -0.49330178
Policy log std Std           0.25978726
Policy log std Max           0.059669614
Policy log std Min           -2.8088021
Z mean eval                  1.92267
Z variance eval              0.12259883
total_rewards                [8750.71359047 9051.56647048 9016.23396301 8963.67679192 9204.15545583
 8911.8621514  9111.99725791 8798.35659815 9161.22145499 9102.67382798]
total_rewards_mean           9007.245756213935
total_rewards_std            143.19433379570404
total_rewards_max            9204.155455827806
total_rewards_min            8750.713590473737
Number of train steps total  780000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               139.98271701019257
(Previous) Eval Time (s)     28.441766981966794
Sample Time (s)              10.409191261045635
Epoch Time (s)               178.833675253205
Total Train Time (s)         35718.27827368397
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:46:38.028482 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #194 | Epoch Duration: 178.91992092132568
2020-01-13 13:46:38.028684 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9224933
Z variance train             0.12232958
KL Divergence                50.84616
KL Loss                      5.084616
QF Loss                      123.44838
VF Loss                      96.84847
Policy Loss                  -1169.0312
Q Predictions Mean           1164.1637
Q Predictions Std            1211.7048
Q Predictions Max            4116.031
Q Predictions Min            521.51245
V Predictions Mean           1164.4379
V Predictions Std            1213.5419
V Predictions Max            4098.1885
V Predictions Min            482.28625
Log Pis Mean                 -0.51293516
Log Pis Std                  3.640484
Log Pis Max                  14.199648
Log Pis Min                  -8.188692
Policy mu Mean               0.009222149
Policy mu Std                0.8314469
Policy mu Max                3.1062078
Policy mu Min                -2.381795
Policy log std Mean          -0.50536305
Policy log std Std           0.2734855
Policy log std Max           -0.0717172
Policy log std Min           -2.3300753
Z mean eval                  1.9210775
Z variance eval              0.063340954
total_rewards                [8865.64564971 9018.31321877 9161.11794397 8829.70126015 9154.36379733
 9278.71146992 9186.19599332 9021.85736207 8710.11689054 9117.93277825]
total_rewards_mean           9034.395636402221
total_rewards_std            172.07900365309553
total_rewards_max            9278.711469916827
total_rewards_min            8710.116890537098
Number of train steps total  784000
Number of env steps total    2354000
Number of rollouts total     0
Train Time (s)               139.28289334382862
(Previous) Eval Time (s)     28.81902257632464
Sample Time (s)              9.97516946773976
Epoch Time (s)               178.07708538789302
Total Train Time (s)         35896.44205800537
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:49:36.194423 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #195 | Epoch Duration: 178.1655821800232
2020-01-13 13:49:36.194604 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9189848
Z variance train             0.06292677
KL Divergence                52.332985
KL Loss                      5.233299
QF Loss                      125.80103
VF Loss                      72.747574
Policy Loss                  -1072.4203
Q Predictions Mean           1068.4702
Q Predictions Std            1114.7516
Q Predictions Max            4103.64
Q Predictions Min            516.02545
V Predictions Mean           1071.5015
V Predictions Std            1119.0181
V Predictions Max            4103.415
V Predictions Min            516.0626
Log Pis Mean                 -0.42011404
Log Pis Std                  3.3485546
Log Pis Max                  11.111953
Log Pis Min                  -10.095478
Policy mu Mean               0.08594277
Policy mu Std                0.8791532
Policy mu Max                2.854633
Policy mu Min                -2.8391984
Policy log std Mean          -0.49556077
Policy log std Std           0.2535022
Policy log std Max           0.010614693
Policy log std Min           -2.931523
Z mean eval                  1.9515594
Z variance eval              0.053265452
total_rewards                [9253.28606162 9167.82462968 9145.06214187 9152.09553806 9443.66066845
 9055.41066248 9638.73885562 9192.4061363  9557.38702917 9529.16352776]
total_rewards_mean           9313.50352510071
total_rewards_std            197.29605346904327
total_rewards_max            9638.738855622643
total_rewards_min            9055.410662477432
Number of train steps total  788000
Number of env steps total    2366000
Number of rollouts total     0
Train Time (s)               142.88026617094874
(Previous) Eval Time (s)     29.308762378059328
Sample Time (s)              9.817746777553111
Epoch Time (s)               182.00677532656118
Total Train Time (s)         36078.53040954145
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:52:38.285509 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #196 | Epoch Duration: 182.09075903892517
2020-01-13 13:52:38.285713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9500291
Z variance train             0.052881457
KL Divergence                53.52311
KL Loss                      5.352311
QF Loss                      2597.6887
VF Loss                      69.01961
Policy Loss                  -1241.6599
Q Predictions Mean           1240.5027
Q Predictions Std            1268.8784
Q Predictions Max            4091.231
Q Predictions Min            533.02
V Predictions Mean           1244.7578
V Predictions Std            1270.3323
V Predictions Max            4074.3079
V Predictions Min            531.6824
Log Pis Mean                 0.062618844
Log Pis Std                  4.4379053
Log Pis Max                  24.774319
Log Pis Min                  -7.068648
Policy mu Mean               0.08423666
Policy mu Std                0.9541693
Policy mu Max                3.8277984
Policy mu Min                -4.3531466
Policy log std Mean          -0.51564354
Policy log std Std           0.26635227
Policy log std Max           -0.10147399
Policy log std Min           -2.7086196
Z mean eval                  1.9352534
Z variance eval              0.06658971
total_rewards                [8020.33741047 7987.67583175 8012.0043815  7801.73610598 8049.59470099
 7743.62813102 7952.18546967 7808.287673   7983.79287563 7747.09817852]
total_rewards_mean           7910.634075852276
total_rewards_std            114.71857113789036
total_rewards_max            8049.594700987872
total_rewards_min            7743.628131018208
Number of train steps total  792000
Number of env steps total    2378000
Number of rollouts total     0
Train Time (s)               149.37543646711856
(Previous) Eval Time (s)     29.032834679819643
Sample Time (s)              9.952666410710663
Epoch Time (s)               188.36093755764887
Total Train Time (s)         36266.989137134515
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:55:46.746894 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #197 | Epoch Duration: 188.46103310585022
2020-01-13 13:55:46.747092 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9325892
Z variance train             0.066199444
KL Divergence                53.525036
KL Loss                      5.352504
QF Loss                      139.41783
VF Loss                      104.8743
Policy Loss                  -997.25934
Q Predictions Mean           995.90454
Q Predictions Std            1062.3148
Q Predictions Max            4061.6616
Q Predictions Min            503.0579
V Predictions Mean           996.1064
V Predictions Std            1063.1467
V Predictions Max            4062.201
V Predictions Min            513.5122
Log Pis Mean                 -0.51129085
Log Pis Std                  3.7340114
Log Pis Max                  19.331663
Log Pis Min                  -11.106818
Policy mu Mean               0.06116279
Policy mu Std                0.8651717
Policy mu Max                3.2257762
Policy mu Min                -2.5460188
Policy log std Mean          -0.46992508
Policy log std Std           0.25396824
Policy log std Max           -0.06380916
Policy log std Min           -3.1272888
Z mean eval                  1.9228709
Z variance eval              0.090971395
total_rewards                [9370.5342174  9341.5834636  9535.70213526 9436.90919816 9493.25579014
 9439.77959924 9289.55329227 9385.03296149 9314.93134372 9480.49970295]
total_rewards_mean           9408.778170423258
total_rewards_std            77.26962183775557
total_rewards_max            9535.702135262023
total_rewards_min            9289.553292272843
Number of train steps total  796000
Number of env steps total    2390000
Number of rollouts total     0
Train Time (s)               148.51364031014964
(Previous) Eval Time (s)     30.363536949735135
Sample Time (s)              9.04584879707545
Epoch Time (s)               187.92302605696023
Total Train Time (s)         36454.989037261344
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:58:54.747694 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #198 | Epoch Duration: 188.00034737586975
2020-01-13 13:58:54.747828 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9254719
Z variance train             0.090458766
KL Divergence                52.815754
KL Loss                      5.2815757
QF Loss                      2809.4976
VF Loss                      130.97495
Policy Loss                  -1233.039
Q Predictions Mean           1232.0034
Q Predictions Std            1259.319
Q Predictions Max            4115.129
Q Predictions Min            510.96112
V Predictions Mean           1234.0142
V Predictions Std            1267.2384
V Predictions Max            4145.5356
V Predictions Min            497.69345
Log Pis Mean                 -0.33261153
Log Pis Std                  3.5131257
Log Pis Max                  14.094756
Log Pis Min                  -8.234149
Policy mu Mean               0.05172055
Policy mu Std                0.86616087
Policy mu Max                2.6974735
Policy mu Min                -2.5428066
Policy log std Mean          -0.5079468
Policy log std Std           0.24926259
Policy log std Max           -0.07377452
Policy log std Min           -2.3423035
Z mean eval                  1.9407803
Z variance eval              0.099203624
total_rewards                [8542.13308407 9155.37012666 9270.50217164 9201.72678888 9225.92496583
 9161.81854857 9038.11425446 9375.0443907  9183.65505285 8897.496878  ]
total_rewards_mean           9105.178626166144
total_rewards_std            223.74004331983397
total_rewards_max            9375.04439069782
total_rewards_min            8542.1330840692
Number of train steps total  800000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               149.0698187770322
(Previous) Eval Time (s)     31.432084103580564
Sample Time (s)              9.930282191373408
Epoch Time (s)               190.43218507198617
Total Train Time (s)         36645.51220532367
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:02:05.276101 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #199 | Epoch Duration: 190.52812314033508
2020-01-13 14:02:05.276429 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9362081
Z variance train             0.09923003
KL Divergence                52.307304
KL Loss                      5.2307305
QF Loss                      87.69463
VF Loss                      92.704285
Policy Loss                  -1095.5276
Q Predictions Mean           1095.9956
Q Predictions Std            1146.0215
Q Predictions Max            4124.227
Q Predictions Min            519.15765
V Predictions Mean           1100.52
V Predictions Std            1149.2357
V Predictions Max            4130.246
V Predictions Min            531.30414
Log Pis Mean                 -0.6447511
Log Pis Std                  3.4643986
Log Pis Max                  14.631707
Log Pis Min                  -7.442823
Policy mu Mean               0.069671474
Policy mu Std                0.83935773
Policy mu Max                2.7191405
Policy mu Min                -3.2054996
Policy log std Mean          -0.4868815
Policy log std Std           0.24351321
Policy log std Max           0.9527594
Policy log std Min           -2.4268622
Z mean eval                  1.9426954
Z variance eval              0.09131286
total_rewards                [9278.10008485 4766.76183818 9335.15850268 9403.94635155 9265.45781407
 9521.34249926 9296.33668043 9374.96379783 8844.80942492 9596.08741065]
total_rewards_mean           8868.29644044209
total_rewards_std            1380.2091884514014
total_rewards_max            9596.087410647848
total_rewards_min            4766.761838184379
Number of train steps total  804000
Number of env steps total    2414000
Number of rollouts total     0
Train Time (s)               147.55873491801322
(Previous) Eval Time (s)     30.486664466094226
Sample Time (s)              9.875241690315306
Epoch Time (s)               187.92064107442275
Total Train Time (s)         36833.51462975377
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:05:13.280665 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #200 | Epoch Duration: 188.00404930114746
2020-01-13 14:05:13.280864 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9415674
Z variance train             0.09162327
KL Divergence                51.591213
KL Loss                      5.1591215
QF Loss                      236.7606
VF Loss                      46.730953
Policy Loss                  -1179.3811
Q Predictions Mean           1172.0632
Q Predictions Std            1197.248
Q Predictions Max            4087.481
Q Predictions Min            533.156
V Predictions Mean           1179.353
V Predictions Std            1197.6505
V Predictions Max            4056.179
V Predictions Min            530.0548
Log Pis Mean                 -0.11229958
Log Pis Std                  3.83659
Log Pis Max                  15.074841
Log Pis Min                  -7.582695
Policy mu Mean               0.051951807
Policy mu Std                0.9115442
Policy mu Max                3.2596357
Policy mu Min                -3.1055627
Policy log std Mean          -0.5137894
Policy log std Std           0.26132664
Policy log std Max           0.055873215
Policy log std Min           -2.339084
Z mean eval                  1.9399054
Z variance eval              0.14231732
total_rewards                [8503.47789634 8648.48461777 8818.27476247 8846.12245594 8782.68609136
 8759.04323866 8594.57059431 8709.10686005 8795.91563523 8822.18756781]
total_rewards_mean           8727.986971994676
total_rewards_std            106.97371472409338
total_rewards_max            8846.122455943112
total_rewards_min            8503.477896340897
Number of train steps total  808000
Number of env steps total    2426000
Number of rollouts total     0
Train Time (s)               139.5718786478974
(Previous) Eval Time (s)     29.0769358901307
Sample Time (s)              9.797233313787729
Epoch Time (s)               178.44604785181582
Total Train Time (s)         37012.04015059816
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:08:11.807830 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #201 | Epoch Duration: 178.5268211364746
2020-01-13 14:08:11.808023 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9443077
Z variance train             0.14214186
KL Divergence                50.50872
KL Loss                      5.0508723
QF Loss                      831.7179
VF Loss                      101.344925
Policy Loss                  -1148.6542
Q Predictions Mean           1139.545
Q Predictions Std            1179.0973
Q Predictions Max            4217.98
Q Predictions Min            540.333
V Predictions Mean           1142.178
V Predictions Std            1175.7084
V Predictions Max            4203.1655
V Predictions Min            538.67993
Log Pis Mean                 -0.18785311
Log Pis Std                  3.4186864
Log Pis Max                  12.385125
Log Pis Min                  -6.6669917
Policy mu Mean               0.10608985
Policy mu Std                0.88402796
Policy mu Max                2.9896543
Policy mu Min                -2.6745691
Policy log std Mean          -0.5138413
Policy log std Std           0.23967522
Policy log std Max           -0.0478428
Policy log std Min           -2.1267533
Z mean eval                  1.9449831
Z variance eval              0.13966031
total_rewards                [9032.7091481  9267.53856709 9075.31988209 9282.22580834 8706.16780356
 9029.03865935 9252.29076656 8868.77808849 8974.99999795 9204.95243587]
total_rewards_mean           9069.402115741612
total_rewards_std            179.02113101963016
total_rewards_max            9282.225808341747
total_rewards_min            8706.167803561644
Number of train steps total  812000
Number of env steps total    2438000
Number of rollouts total     0
Train Time (s)               138.91942021017894
(Previous) Eval Time (s)     28.79077192628756
Sample Time (s)              8.989906475879252
Epoch Time (s)               176.70009861234576
Total Train Time (s)         37188.82826751005
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:11:08.599745 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #202 | Epoch Duration: 176.79155659675598
2020-01-13 14:11:08.599998 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9429811
Z variance train             0.1396425
KL Divergence                50.873478
KL Loss                      5.087348
QF Loss                      273.62527
VF Loss                      73.02226
Policy Loss                  -1225.8936
Q Predictions Mean           1226.0558
Q Predictions Std            1256.1632
Q Predictions Max            4083.4377
Q Predictions Min            528.80206
V Predictions Mean           1226.4519
V Predictions Std            1255.0413
V Predictions Max            4090.2278
V Predictions Min            530.0858
Log Pis Mean                 -0.09860372
Log Pis Std                  4.016694
Log Pis Max                  13.920986
Log Pis Min                  -6.4759045
Policy mu Mean               0.07689108
Policy mu Std                0.9047952
Policy mu Max                3.25332
Policy mu Min                -2.5961313
Policy log std Mean          -0.4986991
Policy log std Std           0.2795212
Policy log std Max           -0.059000015
Policy log std Min           -2.5264056
Z mean eval                  1.911493
Z variance eval              0.10637655
total_rewards                [7966.31697877 8420.76259329 8204.14930575 8618.50857599 8754.23128031
 8683.59674576 8213.67762749 8053.86312634 8077.70171289 7653.65589874]
total_rewards_mean           8264.646384534573
total_rewards_std            333.57891233244214
total_rewards_max            8754.231280314361
total_rewards_min            7653.65589873888
Number of train steps total  816000
Number of env steps total    2450000
Number of rollouts total     0
Train Time (s)               143.73621199605986
(Previous) Eval Time (s)     30.324889217037708
Sample Time (s)              9.867893878836185
Epoch Time (s)               183.92899509193376
Total Train Time (s)         37372.83894552244
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:14:12.613044 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #203 | Epoch Duration: 184.01287460327148
2020-01-13 14:14:12.613263 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9116657
Z variance train             0.10634655
KL Divergence                49.53976
KL Loss                      4.953976
QF Loss                      103.240105
VF Loss                      48.06118
Policy Loss                  -1124.8005
Q Predictions Mean           1122.8389
Q Predictions Std            1155.0118
Q Predictions Max            4136.9883
Q Predictions Min            552.09784
V Predictions Mean           1123.3003
V Predictions Std            1155.6232
V Predictions Max            4124.7603
V Predictions Min            533.0289
Log Pis Mean                 -0.39894345
Log Pis Std                  3.3657694
Log Pis Max                  15.364592
Log Pis Min                  -6.352662
Policy mu Mean               0.049736083
Policy mu Std                0.87164366
Policy mu Max                3.4945843
Policy mu Min                -2.3677816
Policy log std Mean          -0.49230608
Policy log std Std           0.23633836
Policy log std Max           -0.008702815
Policy log std Min           -2.463766
Z mean eval                  1.9299991
Z variance eval              0.14842735
total_rewards                [9404.55883725 9402.90524922 9637.77064626 9695.67004696 9435.75226807
 9641.19554515 9522.55243837 9483.10500816 9569.75821893 9608.81875642]
total_rewards_mean           9540.20870147862
total_rewards_std            100.5993363757846
total_rewards_max            9695.670046964759
total_rewards_min            9402.905249221674
Number of train steps total  820000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               149.16732501797378
(Previous) Eval Time (s)     30.29923932114616
Sample Time (s)              10.503651442937553
Epoch Time (s)               189.9702157820575
Total Train Time (s)         37562.88876400143
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:17:22.666388 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #204 | Epoch Duration: 190.0529272556305
2020-01-13 14:17:22.666795 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9287685
Z variance train             0.1483519
KL Divergence                49.518356
KL Loss                      4.9518356
QF Loss                      136.9489
VF Loss                      32.796455
Policy Loss                  -1006.21875
Q Predictions Mean           1004.21234
Q Predictions Std            1052.6243
Q Predictions Max            4129.9624
Q Predictions Min            519.9465
V Predictions Mean           1006.0503
V Predictions Std            1051.7286
V Predictions Max            4110.632
V Predictions Min            526.6565
Log Pis Mean                 -0.5090236
Log Pis Std                  3.4313507
Log Pis Max                  13.87512
Log Pis Min                  -5.833228
Policy mu Mean               0.05550689
Policy mu Std                0.84223276
Policy mu Max                2.897489
Policy mu Min                -2.3247685
Policy log std Mean          -0.47529995
Policy log std Std           0.24819803
Policy log std Max           -0.043984413
Policy log std Min           -3.226633
Z mean eval                  1.9147743
Z variance eval              0.15979876
total_rewards                [9332.9822096  9419.51125214 9413.74969609 9732.62843449 9591.37819524
 9450.95226192 9415.29273877 9284.2758251  9321.17430336 9433.98599272]
total_rewards_mean           9439.593090943921
total_rewards_std            126.58708920484754
total_rewards_max            9732.628434487317
total_rewards_min            9284.275825099123
Number of train steps total  824000
Number of env steps total    2474000
Number of rollouts total     0
Train Time (s)               147.9997143051587
(Previous) Eval Time (s)     28.63004002859816
Sample Time (s)              9.307038712315261
Epoch Time (s)               185.93679304607213
Total Train Time (s)         37749.047394092195
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:20:28.827020 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #205 | Epoch Duration: 186.15993857383728
2020-01-13 14:20:28.827232 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9138076
Z variance train             0.15961018
KL Divergence                50.64813
KL Loss                      5.064813
QF Loss                      104.240524
VF Loss                      42.93372
Policy Loss                  -1080.5316
Q Predictions Mean           1079.4692
Q Predictions Std            1115.2689
Q Predictions Max            4186.045
Q Predictions Min            521.75934
V Predictions Mean           1084.809
V Predictions Std            1116.6484
V Predictions Max            4206.3184
V Predictions Min            541.299
Log Pis Mean                 -0.54074305
Log Pis Std                  3.1172407
Log Pis Max                  16.615778
Log Pis Min                  -8.381828
Policy mu Mean               0.063257895
Policy mu Std                0.8564552
Policy mu Max                2.778119
Policy mu Min                -2.629708
Policy log std Mean          -0.5017125
Policy log std Std           0.24754342
Policy log std Max           0.15931845
Policy log std Min           -3.026423
Z mean eval                  1.9318631
Z variance eval              0.07157123
total_rewards                [9544.34459057 9735.19286469 9558.97493738 9278.06747168 9660.24168837
 9516.21973268 9567.95731169 9473.52074272 9303.10709755 9537.77891294]
total_rewards_mean           9517.54053502639
total_rewards_std            133.56324343942296
total_rewards_max            9735.192864685247
total_rewards_min            9278.067471682241
Number of train steps total  828000
Number of env steps total    2486000
Number of rollouts total     0
Train Time (s)               150.44682280579582
(Previous) Eval Time (s)     29.483378544915468
Sample Time (s)              10.521667430642992
Epoch Time (s)               190.45186878135428
Total Train Time (s)         37939.5802186057
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:23:39.362803 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #206 | Epoch Duration: 190.53541660308838
2020-01-13 14:23:39.363014 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9295518
Z variance train             0.07151537
KL Divergence                52.007812
KL Loss                      5.2007813
QF Loss                      2933.2566
VF Loss                      37.837395
Policy Loss                  -1169.1927
Q Predictions Mean           1166.2769
Q Predictions Std            1213.2051
Q Predictions Max            4199.28
Q Predictions Min            543.97205
V Predictions Mean           1168.3364
V Predictions Std            1213.2198
V Predictions Max            4206.1934
V Predictions Min            545.48157
Log Pis Mean                 -0.145762
Log Pis Std                  3.8582208
Log Pis Max                  11.674593
Log Pis Min                  -8.815407
Policy mu Mean               0.054141473
Policy mu Std                0.9081933
Policy mu Max                2.559002
Policy mu Min                -2.4035897
Policy log std Mean          -0.4958645
Policy log std Std           0.24358456
Policy log std Max           0.046314836
Policy log std Min           -2.6387708
Z mean eval                  1.9538462
Z variance eval              0.076336965
total_rewards                [8105.48400191 8064.25481872 8104.03750281 8163.50771293 8270.99480641
 8193.21907799 8206.12444734 8303.68743815 8154.83815182 8052.86494014]
total_rewards_mean           8161.901289823074
total_rewards_std            79.34012499530557
total_rewards_max            8303.687438153183
total_rewards_min            8052.864940142323
Number of train steps total  832000
Number of env steps total    2498000
Number of rollouts total     0
Train Time (s)               148.98280015122145
(Previous) Eval Time (s)     29.26595883211121
Sample Time (s)              10.01020886702463
Epoch Time (s)               188.2589678503573
Total Train Time (s)         38127.921015196014
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:26:47.706391 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #207 | Epoch Duration: 188.3432276248932
2020-01-13 14:26:47.706586 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9552324
Z variance train             0.076043606
KL Divergence                52.934837
KL Loss                      5.2934837
QF Loss                      146.10713
VF Loss                      45.65541
Policy Loss                  -1163.8304
Q Predictions Mean           1163.385
Q Predictions Std            1188.7119
Q Predictions Max            4227.4297
Q Predictions Min            546.9853
V Predictions Mean           1164.2991
V Predictions Std            1188.654
V Predictions Max            4235.5703
V Predictions Min            533.0841
Log Pis Mean                 -0.18051225
Log Pis Std                  3.6568773
Log Pis Max                  12.69109
Log Pis Min                  -7.078051
Policy mu Mean               0.066741824
Policy mu Std                0.87332183
Policy mu Max                2.5755112
Policy mu Min                -2.8151877
Policy log std Mean          -0.5117415
Policy log std Std           0.26949576
Policy log std Max           0.15684187
Policy log std Min           -2.5164382
Z mean eval                  1.918437
Z variance eval              0.08188987
total_rewards                [9043.74081664 9459.13843887 9550.65451698 9248.42855821 9364.62766675
 9343.01189465 9128.12189531 9239.37190732 9546.56836971 9055.13123922]
total_rewards_mean           9297.879530366688
total_rewards_std            177.88688152519876
total_rewards_max            9550.654516978837
total_rewards_min            9043.740816644002
Number of train steps total  836000
Number of env steps total    2510000
Number of rollouts total     0
Train Time (s)               140.23296953365207
(Previous) Eval Time (s)     29.129634873010218
Sample Time (s)              9.551971085369587
Epoch Time (s)               178.91457549203187
Total Train Time (s)         38306.91928400984
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:29:46.707540 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #208 | Epoch Duration: 179.00080585479736
2020-01-13 14:29:46.707750 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #208 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9183152
Z variance train             0.082028285
KL Divergence                51.33433
KL Loss                      5.1334333
QF Loss                      131.93886
VF Loss                      97.95945
Policy Loss                  -1195.5232
Q Predictions Mean           1193.1455
Q Predictions Std            1228.8022
Q Predictions Max            4246.122
Q Predictions Min            552.30634
V Predictions Mean           1191.7222
V Predictions Std            1221.3221
V Predictions Max            4230.669
V Predictions Min            550.26074
Log Pis Mean                 0.06194719
Log Pis Std                  3.8743691
Log Pis Max                  14.3864975
Log Pis Min                  -7.3136616
Policy mu Mean               0.057453275
Policy mu Std                0.914818
Policy mu Max                3.672671
Policy mu Min                -2.7966852
Policy log std Mean          -0.50703996
Policy log std Std           0.26547423
Policy log std Max           -0.10620612
Policy log std Min           -2.9549003
Z mean eval                  1.9329392
Z variance eval              0.11919711
total_rewards                [ 9568.8605473  10024.42144557  9723.42185341  9878.63175762
  9696.72355472 10037.35394614  9788.16461002  9797.35474949
  9977.61941711  9820.21267432]
total_rewards_mean           9831.276455568284
total_rewards_std            143.23499369242987
total_rewards_max            10037.353946140669
total_rewards_min            9568.860547298142
Number of train steps total  840000
Number of env steps total    2522000
Number of rollouts total     0
Train Time (s)               139.9027025923133
(Previous) Eval Time (s)     28.71034120209515
Sample Time (s)              9.734885897487402
Epoch Time (s)               178.34792969189584
Total Train Time (s)         38485.35163023509
Epoch                        209
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:32:45.143333 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #209 | Epoch Duration: 178.43542957305908
2020-01-13 14:32:45.143584 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9347332
Z variance train             0.11889541
KL Divergence                51.403515
KL Loss                      5.140352
QF Loss                      220.21532
VF Loss                      52.254253
Policy Loss                  -1147.6403
Q Predictions Mean           1141.3215
Q Predictions Std            1174.699
Q Predictions Max            4259.8306
Q Predictions Min            524.2461
V Predictions Mean           1150.81
V Predictions Std            1173.3448
V Predictions Max            4262.103
V Predictions Min            532.06946
Log Pis Mean                 -0.15836644
Log Pis Std                  4.0502057
Log Pis Max                  27.066761
Log Pis Min                  -6.8225126
Policy mu Mean               0.097270004
Policy mu Std                0.89739597
Policy mu Max                3.4791114
Policy mu Min                -4.504195
Policy log std Mean          -0.50429267
Policy log std Std           0.26135466
Policy log std Max           -0.08489877
Policy log std Min           -2.5823617
Z mean eval                  1.9210447
Z variance eval              0.08353825
total_rewards                [9851.31847377 9682.80460059 9682.50839945 9683.40138949 9660.26856016
 9841.47180862 9389.76022714 9492.82946236 9781.18074853 9842.94465301]
total_rewards_mean           9690.84883231173
total_rewards_std            145.16256044920132
total_rewards_max            9851.318473772637
total_rewards_min            9389.760227136123
Number of train steps total  844000
Number of env steps total    2534000
Number of rollouts total     0
Train Time (s)               145.75359687628224
(Previous) Eval Time (s)     29.208491160999984
Sample Time (s)              9.78294697823003
Epoch Time (s)               184.74503501551226
Total Train Time (s)         38670.192559810355
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:35:49.987661 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #210 | Epoch Duration: 184.84387803077698
2020-01-13 14:35:49.987933 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9192111
Z variance train             0.08365404
KL Divergence                51.786255
KL Loss                      5.1786256
QF Loss                      133.82669
VF Loss                      106.919365
Policy Loss                  -1004.94824
Q Predictions Mean           1006.1362
Q Predictions Std            1039.7539
Q Predictions Max            4202.9697
Q Predictions Min            539.42487
V Predictions Mean           1007.94037
V Predictions Std            1036.4646
V Predictions Max            4208.526
V Predictions Min            564.0461
Log Pis Mean                 -0.5526866
Log Pis Std                  3.4904926
Log Pis Max                  20.85582
Log Pis Min                  -6.85252
Policy mu Mean               0.067386076
Policy mu Std                0.8453237
Policy mu Max                3.31981
Policy mu Min                -3.0496554
Policy log std Mean          -0.47586226
Policy log std Std           0.22174388
Policy log std Max           -0.030841142
Policy log std Min           -2.2395802
Z mean eval                  1.9260973
Z variance eval              0.06793933
total_rewards                [9540.84709667 9515.75812786 9299.23476843 9338.22802749 9486.28306583
 9511.68730757 9324.52690187 9441.16586136 9541.97674311 9398.00794652]
total_rewards_mean           9439.771584671636
total_rewards_std            88.80341799690024
total_rewards_max            9541.976743106043
total_rewards_min            9299.234768434999
Number of train steps total  848000
Number of env steps total    2546000
Number of rollouts total     0
Train Time (s)               148.70464604487643
(Previous) Eval Time (s)     29.454707162920386
Sample Time (s)              10.63619272178039
Epoch Time (s)               188.7955459295772
Total Train Time (s)         38859.067076409236
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:38:58.864124 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #211 | Epoch Duration: 188.87602019309998
2020-01-13 14:38:58.864315 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9293244
Z variance train             0.06807113
KL Divergence                51.80519
KL Loss                      5.180519
QF Loss                      1736.5476
VF Loss                      110.560715
Policy Loss                  -1239.255
Q Predictions Mean           1239.0491
Q Predictions Std            1258.4899
Q Predictions Max            4296.747
Q Predictions Min            546.92
V Predictions Mean           1242.5774
V Predictions Std            1252.0485
V Predictions Max            4267.734
V Predictions Min            556.6201
Log Pis Mean                 0.10810946
Log Pis Std                  3.7246904
Log Pis Max                  12.705427
Log Pis Min                  -8.677059
Policy mu Mean               0.09323698
Policy mu Std                0.92175424
Policy mu Max                2.7122645
Policy mu Min                -2.5976584
Policy log std Mean          -0.50812864
Policy log std Std           0.28601322
Policy log std Max           -0.033934534
Policy log std Min           -2.9177773
Z mean eval                  1.9338274
Z variance eval              0.09691098
total_rewards                [9518.32591614 9806.16126193 9810.41523175 9829.33985634 9684.11687997
 9611.56140253 9846.27716913 9472.56694862 9556.62821072 9571.53810396]
total_rewards_mean           9670.693098108964
total_rewards_std            135.22627478593293
total_rewards_max            9846.2771691274
total_rewards_min            9472.566948624888
Number of train steps total  852000
Number of env steps total    2558000
Number of rollouts total     0
Train Time (s)               147.98524165293202
(Previous) Eval Time (s)     30.64653137791902
Sample Time (s)              10.340893063228577
Epoch Time (s)               188.9726660940796
Total Train Time (s)         39048.12121753674
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:42:07.921164 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #212 | Epoch Duration: 189.0567066669464
2020-01-13 14:42:07.921355 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9304764
Z variance train             0.096414864
KL Divergence                50.661575
KL Loss                      5.066158
QF Loss                      129.12056
VF Loss                      62.93077
Policy Loss                  -1151.5936
Q Predictions Mean           1153.2228
Q Predictions Std            1216.8666
Q Predictions Max            4251.8853
Q Predictions Min            554.1723
V Predictions Mean           1151.2218
V Predictions Std            1218.2921
V Predictions Max            4269.5005
V Predictions Min            551.168
Log Pis Mean                 -0.30528682
Log Pis Std                  3.9164977
Log Pis Max                  13.473278
Log Pis Min                  -9.762781
Policy mu Mean               -0.009714436
Policy mu Std                0.894245
Policy mu Max                2.8634257
Policy mu Min                -3.4149516
Policy log std Mean          -0.48649225
Policy log std Std           0.24833971
Policy log std Max           -0.07504779
Policy log std Min           -2.8050401
Z mean eval                  1.9179713
Z variance eval              0.095930725
total_rewards                [9699.11598767 9548.81491976 9576.2203671  9789.01815802 9572.70457132
 9798.38352835 9353.45471097 9298.58746549 9656.28389215 9606.54827198]
total_rewards_mean           9589.91318728193
total_rewards_std            155.7773106639483
total_rewards_max            9798.383528347369
total_rewards_min            9298.587465493038
Number of train steps total  856000
Number of env steps total    2570000
Number of rollouts total     0
Train Time (s)               149.96658893115819
(Previous) Eval Time (s)     29.47786872088909
Sample Time (s)              8.361756769474596
Epoch Time (s)               187.80621442152187
Total Train Time (s)         39236.01870255917
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:45:15.821319 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #213 | Epoch Duration: 187.89982533454895
2020-01-13 14:45:15.821515 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #213 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9196908
Z variance train             0.09585227
KL Divergence                51.07483
KL Loss                      5.107483
QF Loss                      212.24072
VF Loss                      53.907574
Policy Loss                  -1365.2562
Q Predictions Mean           1357.6213
Q Predictions Std            1323.6244
Q Predictions Max            4298.836
Q Predictions Min            530.4175
V Predictions Mean           1360.9155
V Predictions Std            1324.283
V Predictions Max            4301.896
V Predictions Min            540.8876
Log Pis Mean                 -0.10252329
Log Pis Std                  3.7261527
Log Pis Max                  14.569031
Log Pis Min                  -9.700637
Policy mu Mean               0.021522975
Policy mu Std                0.8975506
Policy mu Max                3.0181737
Policy mu Min                -3.08773
Policy log std Mean          -0.5025523
Policy log std Std           0.26813632
Policy log std Max           -0.07089186
Policy log std Min           -2.8033736
Z mean eval                  1.905716
Z variance eval              0.16602518
total_rewards                [ 9438.54817578  9630.61350105  9894.94962754 10125.96288707
  8927.24984869  9733.34498151  9602.99326771  9490.18747614
  9777.87526041  9675.51098395]
total_rewards_mean           9629.723600985151
total_rewards_std            300.2639025902905
total_rewards_max            10125.962887071317
total_rewards_min            8927.249848690444
Number of train steps total  860000
Number of env steps total    2582000
Number of rollouts total     0
Train Time (s)               146.97511244518682
(Previous) Eval Time (s)     29.352663008961827
Sample Time (s)              8.945656906347722
Epoch Time (s)               185.27343236049637
Total Train Time (s)         39421.371189529076
Epoch                        214
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:48:21.182102 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #214 | Epoch Duration: 185.36041855812073
2020-01-13 14:48:21.182472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #214 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9091583
Z variance train             0.16555342
KL Divergence                49.78423
KL Loss                      4.978423
QF Loss                      3007.6206
VF Loss                      74.3548
Policy Loss                  -1282.5707
Q Predictions Mean           1277.4596
Q Predictions Std            1291.1438
Q Predictions Max            4256.723
Q Predictions Min            557.30585
V Predictions Mean           1279.6493
V Predictions Std            1287.8048
V Predictions Max            4240.9785
V Predictions Min            566.32434
Log Pis Mean                 0.09298295
Log Pis Std                  3.665581
Log Pis Max                  12.85579
Log Pis Min                  -8.647084
Policy mu Mean               0.07968327
Policy mu Std                0.89009565
Policy mu Max                2.5538106
Policy mu Min                -2.5713224
Policy log std Mean          -0.52241635
Policy log std Std           0.2766966
Policy log std Max           -0.068894684
Policy log std Min           -2.9115925
Z mean eval                  1.9080436
Z variance eval              0.108606175
total_rewards                [ 9404.32808406  9540.23853445  9593.74189058 10022.17709772
  9922.36039355  9590.73530777  9601.37917802  9268.93523214
  9927.41656229  3322.14104338]
total_rewards_mean           9019.345332396511
total_rewards_std            1912.6122370243716
total_rewards_max            10022.177097724483
total_rewards_min            3322.1410433764877
Number of train steps total  864000
Number of env steps total    2594000
Number of rollouts total     0
Train Time (s)               139.82201874721795
(Previous) Eval Time (s)     29.69185848813504
Sample Time (s)              9.445110577624291
Epoch Time (s)               178.95898781297728
Total Train Time (s)         39600.41412732517
Epoch                        215
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:51:20.222020 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #215 | Epoch Duration: 179.03924345970154
2020-01-13 14:51:20.222204 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #215 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.909105
Z variance train             0.10816292
KL Divergence                49.76926
KL Loss                      4.9769263
QF Loss                      161.76294
VF Loss                      78.400345
Policy Loss                  -1207.231
Q Predictions Mean           1204.8713
Q Predictions Std            1239.9023
Q Predictions Max            4244.7627
Q Predictions Min            564.1534
V Predictions Mean           1210.6185
V Predictions Std            1237.8695
V Predictions Max            4237.2915
V Predictions Min            562.82275
Log Pis Mean                 0.040991724
Log Pis Std                  3.7624385
Log Pis Max                  14.385835
Log Pis Min                  -6.7299433
Policy mu Mean               0.05893119
Policy mu Std                0.91903925
Policy mu Max                2.7612622
Policy mu Min                -2.8147147
Policy log std Mean          -0.5073641
Policy log std Std           0.24460621
Policy log std Max           -0.07191408
Policy log std Min           -2.702118
Z mean eval                  1.9255453
Z variance eval              0.13924262
total_rewards                [ 9934.5942164   9615.80226017 10115.30790966  9459.44225401
  9561.62396865  9795.29534162  9895.82619743   347.52015881
  9955.7620295   7258.463127  ]
total_rewards_mean           8593.963746324609
total_rewards_std            2856.9438772210365
total_rewards_max            10115.307909661376
total_rewards_min            347.5201588108901
Number of train steps total  868000
Number of env steps total    2606000
Number of rollouts total     0
Train Time (s)               139.33083628909662
(Previous) Eval Time (s)     29.60544032091275
Sample Time (s)              8.912705823313445
Epoch Time (s)               177.84898243332282
Total Train Time (s)         39778.344873013906
Epoch                        216
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:54:18.155941 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #216 | Epoch Duration: 177.93358206748962
2020-01-13 14:54:18.156265 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.930735
Z variance train             0.13849759
KL Divergence                48.09582
KL Loss                      4.809582
QF Loss                      285.90228
VF Loss                      73.93334
Policy Loss                  -1258.4989
Q Predictions Mean           1255.5818
Q Predictions Std            1303.2769
Q Predictions Max            4347.349
Q Predictions Min            556.7285
V Predictions Mean           1255.5126
V Predictions Std            1299.3595
V Predictions Max            4371.9585
V Predictions Min            560.8266
Log Pis Mean                 -0.4986483
Log Pis Std                  3.3825557
Log Pis Max                  14.832752
Log Pis Min                  -9.49201
Policy mu Mean               0.04261905
Policy mu Std                0.87176216
Policy mu Max                2.9708247
Policy mu Min                -2.476665
Policy log std Mean          -0.49443558
Policy log std Std           0.2657811
Policy log std Max           0.35633427
Policy log std Min           -2.8954477
Z mean eval                  1.9429384
Z variance eval              0.16569845
total_rewards                [9257.3850277  9197.17735906 9181.96997372 9033.69386846 9407.12136464
 9297.75682303 9408.39081319 9804.20642712 9142.84150376 9433.73520973]
total_rewards_mean           9316.427837041316
total_rewards_std            203.61150342228385
total_rewards_max            9804.206427123641
total_rewards_min            9033.693868460954
Number of train steps total  872000
Number of env steps total    2618000
Number of rollouts total     0
Train Time (s)               147.20308054378256
(Previous) Eval Time (s)     31.03030613809824
Sample Time (s)              9.927415180951357
Epoch Time (s)               188.16080186283216
Total Train Time (s)         39966.75955977989
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:57:26.573540 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #217 | Epoch Duration: 188.41701364517212
2020-01-13 14:57:26.573785 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9450204
Z variance train             0.1662611
KL Divergence                49.072678
KL Loss                      4.907268
QF Loss                      3077.188
VF Loss                      72.74443
Policy Loss                  -1125.517
Q Predictions Mean           1121.9387
Q Predictions Std            1137.0964
Q Predictions Max            4340.0957
Q Predictions Min            560.6013
V Predictions Mean           1119.6793
V Predictions Std            1136.0474
V Predictions Max            4326.3325
V Predictions Min            564.81067
Log Pis Mean                 -0.50418794
Log Pis Std                  3.7140388
Log Pis Max                  15.206155
Log Pis Min                  -9.593334
Policy mu Mean               0.08118798
Policy mu Std                0.88572764
Policy mu Max                3.3062227
Policy mu Min                -2.7872128
Policy log std Mean          -0.46367764
Policy log std Std           0.26728702
Policy log std Max           0.027726904
Policy log std Min           -2.5077095
Z mean eval                  1.900321
Z variance eval              0.16662589
total_rewards                [9341.24382998 9131.94530407 9494.76816877 9366.8862272  9241.21258628
 9496.50851938 8392.27945218 9008.25795927 9402.39252082 9132.81743105]
total_rewards_mean           9200.831199899529
total_rewards_std            310.41635609177746
total_rewards_max            9496.508519382001
total_rewards_min            8392.279452184473
Number of train steps total  876000
Number of env steps total    2630000
Number of rollouts total     0
Train Time (s)               148.31846374319866
(Previous) Eval Time (s)     30.649426562245935
Sample Time (s)              9.771263650618494
Epoch Time (s)               188.7391539560631
Total Train Time (s)         40155.59336427972
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:00:35.410588 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #218 | Epoch Duration: 188.8366403579712
2020-01-13 15:00:35.410824 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #218 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9009411
Z variance train             0.16605711
KL Divergence                45.530556
KL Loss                      4.553056
QF Loss                      242.05598
VF Loss                      103.8341
Policy Loss                  -1195.584
Q Predictions Mean           1191.1846
Q Predictions Std            1242.0983
Q Predictions Max            4185.4634
Q Predictions Min            498.13358
V Predictions Mean           1194.1539
V Predictions Std            1238.5707
V Predictions Max            4177.2847
V Predictions Min            536.49817
Log Pis Mean                 -0.08434641
Log Pis Std                  3.626273
Log Pis Max                  17.246935
Log Pis Min                  -7.0281897
Policy mu Mean               0.0990968
Policy mu Std                0.89564687
Policy mu Max                3.3933654
Policy mu Min                -2.7101529
Policy log std Mean          -0.49149394
Policy log std Std           0.25721827
Policy log std Max           0.0135425925
Policy log std Min           -3.0102546
Z mean eval                  1.8966682
Z variance eval              0.087742604
total_rewards                [8470.90966125 8627.67679888 8591.86419172 8231.41600028 9049.9322458
 9023.41094364 9143.72627146 8780.92284649 8604.84889807 8919.1567116 ]
total_rewards_mean           8744.386456919261
total_rewards_std            275.10868644948346
total_rewards_max            9143.726271463678
total_rewards_min            8231.416000278892
Number of train steps total  880000
Number of env steps total    2642000
Number of rollouts total     0
Train Time (s)               147.81217338331044
(Previous) Eval Time (s)     29.633121688850224
Sample Time (s)              10.387395872734487
Epoch Time (s)               187.83269094489515
Total Train Time (s)         40343.51045549568
Epoch                        219
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:03:43.331522 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #219 | Epoch Duration: 187.92051196098328
2020-01-13 15:03:43.331841 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.894092
Z variance train             0.08770968
KL Divergence                48.188866
KL Loss                      4.8188868
QF Loss                      243.97232
VF Loss                      217.55536
Policy Loss                  -1144.9099
Q Predictions Mean           1138.5939
Q Predictions Std            1184.1774
Q Predictions Max            4123.0083
Q Predictions Min            524.982
V Predictions Mean           1149.7181
V Predictions Std            1190.3044
V Predictions Max            4130.3022
V Predictions Min            524.47107
Log Pis Mean                 -0.25618887
Log Pis Std                  3.7654092
Log Pis Max                  18.605322
Log Pis Min                  -6.288441
Policy mu Mean               0.08640955
Policy mu Std                0.8900134
Policy mu Max                3.35507
Policy mu Min                -3.4850078
Policy log std Mean          -0.4854456
Policy log std Std           0.26204634
Policy log std Max           -0.060298473
Policy log std Min           -2.7226703
Z mean eval                  1.9086863
Z variance eval              0.1234357
total_rewards                [8053.31781687 8264.47526899 8373.90655023 8227.19844049 8157.93875931
 8190.69401694 8329.3939056  8230.75422201 8322.48804666 8226.23649516]
total_rewards_mean           8237.640352226785
total_rewards_std            88.16123575664636
total_rewards_max            8373.90655023321
total_rewards_min            8053.317816867872
Number of train steps total  884000
Number of env steps total    2654000
Number of rollouts total     0
Train Time (s)               149.13899502670392
(Previous) Eval Time (s)     30.451802972704172
Sample Time (s)              10.586676051840186
Epoch Time (s)               190.17747405124828
Total Train Time (s)         40533.777616472915
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:06:53.600955 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #220 | Epoch Duration: 190.26891946792603
2020-01-13 15:06:53.601176 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9046978
Z variance train             0.12312893
KL Divergence                47.661537
KL Loss                      4.766154
QF Loss                      138.3483
VF Loss                      85.162704
Policy Loss                  -1154.4948
Q Predictions Mean           1154.5348
Q Predictions Std            1202.1646
Q Predictions Max            4326.9165
Q Predictions Min            558.3138
V Predictions Mean           1158.0146
V Predictions Std            1204.1962
V Predictions Max            4327.0547
V Predictions Min            556.91626
Log Pis Mean                 -0.119388536
Log Pis Std                  4.028063
Log Pis Max                  14.717851
Log Pis Min                  -7.1598835
Policy mu Mean               0.038280297
Policy mu Std                0.9242225
Policy mu Max                2.7727234
Policy mu Min                -2.4070792
Policy log std Mean          -0.49235532
Policy log std Std           0.27258095
Policy log std Max           0.05201602
Policy log std Min           -2.6976044
Z mean eval                  1.9103451
Z variance eval              0.08835955
total_rewards                [9100.33472537 9873.73064792 4366.90328256 9637.99939338 9228.17259055
 9616.27976532 5984.16642879 9511.28662975 9576.88488966 9551.69451534]
total_rewards_mean           8644.745286862732
total_rewards_std            1783.5283639641584
total_rewards_max            9873.730647915092
total_rewards_min            4366.903282557767
Number of train steps total  888000
Number of env steps total    2666000
Number of rollouts total     0
Train Time (s)               145.43720931187272
(Previous) Eval Time (s)     28.77771532908082
Sample Time (s)              10.250768850091845
Epoch Time (s)               184.46569349104539
Total Train Time (s)         40718.32026531547
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:09:58.146278 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #221 | Epoch Duration: 184.54494953155518
2020-01-13 15:09:58.146482 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #221 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9084737
Z variance train             0.08852761
KL Divergence                48.45846
KL Loss                      4.845846
QF Loss                      127.993546
VF Loss                      53.82469
Policy Loss                  -1123.6248
Q Predictions Mean           1123.8035
Q Predictions Std            1151.0786
Q Predictions Max            4388.8755
Q Predictions Min            567.04767
V Predictions Mean           1125.6866
V Predictions Std            1149.8132
V Predictions Max            4407.123
V Predictions Min            579.4015
Log Pis Mean                 -0.3239221
Log Pis Std                  3.1774442
Log Pis Max                  10.016717
Log Pis Min                  -6.8757896
Policy mu Mean               0.10710702
Policy mu Std                0.8811507
Policy mu Max                2.724527
Policy mu Min                -2.59773
Policy log std Mean          -0.4983075
Policy log std Std           0.24513157
Policy log std Max           -0.1038014
Policy log std Min           -2.587487
Z mean eval                  1.9417442
Z variance eval              0.09727888
total_rewards                [9301.03921011 9896.02596132 9610.96376324 9591.18600436 9685.5181706
 9468.48520521 8923.43933634 8846.01912609 9581.04928182 9439.92024506]
total_rewards_mean           9434.364630415408
total_rewards_std            312.9970772981703
total_rewards_max            9896.025961322692
total_rewards_min            8846.019126085057
Number of train steps total  892000
Number of env steps total    2678000
Number of rollouts total     0
Train Time (s)               139.29629046283662
(Previous) Eval Time (s)     29.70750206010416
Sample Time (s)              9.676892787683755
Epoch Time (s)               178.68068531062454
Total Train Time (s)         40897.090376907494
Epoch                        222
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:12:56.922666 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #222 | Epoch Duration: 178.77600526809692
2020-01-13 15:12:56.922971 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9441086
Z variance train             0.097440735
KL Divergence                49.142197
KL Loss                      4.91422
QF Loss                      141.09593
VF Loss                      54.816814
Policy Loss                  -1236.098
Q Predictions Mean           1234.2308
Q Predictions Std            1254.4625
Q Predictions Max            4374.587
Q Predictions Min            558.20135
V Predictions Mean           1235.2222
V Predictions Std            1251.9607
V Predictions Max            4340.627
V Predictions Min            558.58466
Log Pis Mean                 -0.5891144
Log Pis Std                  3.2671683
Log Pis Max                  12.036503
Log Pis Min                  -9.024881
Policy mu Mean               0.042739082
Policy mu Std                0.8593219
Policy mu Max                2.634282
Policy mu Min                -3.238188
Policy log std Mean          -0.4921457
Policy log std Std           0.26566094
Policy log std Max           0.32867122
Policy log std Min           -2.7922802
Z mean eval                  1.954511
Z variance eval              0.08159545
total_rewards                [9062.80087913 9468.94180376 9612.64821681 9562.48521702 9536.37122985
 9712.97203066 9528.31641004 9556.10916634 9406.29548564 9500.96074434]
total_rewards_mean           9494.790118359753
total_rewards_std            163.65871383521167
total_rewards_max            9712.972030661178
total_rewards_min            9062.800879132126
Number of train steps total  896000
Number of env steps total    2690000
Number of rollouts total     0
Train Time (s)               138.73578367894515
(Previous) Eval Time (s)     29.322282088920474
Sample Time (s)              9.30510553251952
Epoch Time (s)               177.36317130038515
Total Train Time (s)         41074.53654891439
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:15:54.372429 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #223 | Epoch Duration: 177.4492495059967
2020-01-13 15:15:54.372560 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9517893
Z variance train             0.081810474
KL Divergence                49.282894
KL Loss                      4.9282894
QF Loss                      212.61761
VF Loss                      271.05637
Policy Loss                  -1134.9814
Q Predictions Mean           1134.4956
Q Predictions Std            1170.7804
Q Predictions Max            4380.4526
Q Predictions Min            546.12195
V Predictions Mean           1143.4844
V Predictions Std            1169.7052
V Predictions Max            4398.26
V Predictions Min            546.0202
Log Pis Mean                 -0.025668787
Log Pis Std                  4.1153526
Log Pis Max                  24.78497
Log Pis Min                  -6.4609985
Policy mu Mean               0.0980512
Policy mu Std                0.95106745
Policy mu Max                4.1976786
Policy mu Min                -4.6952505
Policy log std Mean          -0.5028512
Policy log std Std           0.28116646
Policy log std Max           0.3089545
Policy log std Min           -2.9500701
Z mean eval                  1.909015
Z variance eval              0.09140192
total_rewards                [9164.06923074 9503.03009502 9315.25924556 9470.26885038 9159.52977845
 9235.7919299  9210.88792191 9420.56873581 9499.92349814 9098.82808568]
total_rewards_mean           9307.815737158044
total_rewards_std            146.65733809506537
total_rewards_max            9503.030095022108
total_rewards_min            9098.828085678286
Number of train steps total  900000
Number of env steps total    2702000
Number of rollouts total     0
Train Time (s)               148.11888882610947
(Previous) Eval Time (s)     30.107702710665762
Sample Time (s)              9.92331474320963
Epoch Time (s)               188.14990627998486
Total Train Time (s)         41262.77228436014
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:19:02.612234 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #224 | Epoch Duration: 188.23955535888672
2020-01-13 15:19:02.612458 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9122236
Z variance train             0.09144524
KL Divergence                50.730736
KL Loss                      5.073074
QF Loss                      258.94623
VF Loss                      81.408
Policy Loss                  -1235.0304
Q Predictions Mean           1235.844
Q Predictions Std            1272.9136
Q Predictions Max            4307.417
Q Predictions Min            559.801
V Predictions Mean           1232.8866
V Predictions Std            1269.5938
V Predictions Max            4314.01
V Predictions Min            542.92346
Log Pis Mean                 -0.013430119
Log Pis Std                  3.9561713
Log Pis Max                  17.057402
Log Pis Min                  -6.268373
Policy mu Mean               0.05202806
Policy mu Std                0.9259464
Policy mu Max                3.691455
Policy mu Min                -2.553734
Policy log std Mean          -0.5101505
Policy log std Std           0.27366084
Policy log std Max           0.10102719
Policy log std Min           -3.0976224
Z mean eval                  1.9530264
Z variance eval              0.16770016
total_rewards                [9574.88767075 9425.93021799 9536.18608674 9262.48267005 9518.91323773
 9747.05143668 9731.3438761  9884.973749   9689.92335294 9801.36322385]
total_rewards_mean           9617.305552181675
total_rewards_std            179.22613008343953
total_rewards_max            9884.973748995337
total_rewards_min            9262.482670045652
Number of train steps total  904000
Number of env steps total    2714000
Number of rollouts total     0
Train Time (s)               148.01591640291736
(Previous) Eval Time (s)     29.77246425487101
Sample Time (s)              10.605594869703054
Epoch Time (s)               188.39397552749142
Total Train Time (s)         41451.24945698399
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:22:11.092375 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #225 | Epoch Duration: 188.47976565361023
2020-01-13 15:22:11.092573 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #225 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9526056
Z variance train             0.16812167
KL Divergence                50.294235
KL Loss                      5.0294237
QF Loss                      168.39597
VF Loss                      60.65412
Policy Loss                  -1197.7272
Q Predictions Mean           1197.4602
Q Predictions Std            1244.0128
Q Predictions Max            4454.839
Q Predictions Min            560.9053
V Predictions Mean           1195.7139
V Predictions Std            1237.4856
V Predictions Max            4424.9434
V Predictions Min            561.4135
Log Pis Mean                 -0.04766733
Log Pis Std                  3.3382638
Log Pis Max                  18.296276
Log Pis Min                  -7.0351253
Policy mu Mean               0.026946023
Policy mu Std                0.91219497
Policy mu Max                3.3230586
Policy mu Min                -3.2373943
Policy log std Mean          -0.49062124
Policy log std Std           0.27977318
Policy log std Max           -0.0919635
Policy log std Min           -2.9455037
Z mean eval                  1.905892
Z variance eval              0.07446132
total_rewards                [8937.02183083 7013.46389394 8978.4057347  8585.39091256 5624.7569927
 9049.79661113 9152.07605529 8985.13623741 8907.44945914 9750.42854733]
total_rewards_mean           8498.3926275018
total_rewards_std            1166.0343529602544
total_rewards_max            9750.428547334945
total_rewards_min            5624.756992695117
Number of train steps total  908000
Number of env steps total    2726000
Number of rollouts total     0
Train Time (s)               147.43955002073199
(Previous) Eval Time (s)     30.62112976424396
Sample Time (s)              10.562599368859082
Epoch Time (s)               188.62327915383503
Total Train Time (s)         41640.1362646888
Epoch                        226
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:25:19.983731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #226 | Epoch Duration: 188.89095902442932
2020-01-13 15:25:19.984148 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.902154
Z variance train             0.07480591
KL Divergence                51.214787
KL Loss                      5.1214786
QF Loss                      586.1003
VF Loss                      158.92816
Policy Loss                  -1218.9105
Q Predictions Mean           1219.6995
Q Predictions Std            1263.4612
Q Predictions Max            4322.287
Q Predictions Min            581.4485
V Predictions Mean           1227.3074
V Predictions Std            1263.7072
V Predictions Max            4332.092
V Predictions Min            583.9873
Log Pis Mean                 -0.34384358
Log Pis Std                  3.784019
Log Pis Max                  16.020844
Log Pis Min                  -6.9014893
Policy mu Mean               0.09425577
Policy mu Std                0.8971907
Policy mu Max                3.0333416
Policy mu Min                -2.791089
Policy log std Mean          -0.4956225
Policy log std Std           0.28502157
Policy log std Max           -0.08897883
Policy log std Min           -3.1104555
Z mean eval                  1.9333521
Z variance eval              0.071316615
total_rewards                [9682.18970417 9900.16673177 9853.75415717 9848.17897218 9743.33852391
 9712.77079599 9909.14278248 9851.56155948 9785.72811547 9800.8825085 ]
total_rewards_mean           9808.771385113416
total_rewards_std            73.44974782834728
total_rewards_max            9909.14278248381
total_rewards_min            9682.18970416762
Number of train steps total  912000
Number of env steps total    2738000
Number of rollouts total     0
Train Time (s)               148.61878886073828
(Previous) Eval Time (s)     30.158582400996238
Sample Time (s)              9.423713150899857
Epoch Time (s)               188.20108441263437
Total Train Time (s)         41828.42613275163
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:28:28.277956 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #227 | Epoch Duration: 188.29354691505432
2020-01-13 15:28:28.278422 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9321648
Z variance train             0.0713349
KL Divergence                51.031822
KL Loss                      5.1031823
QF Loss                      3392.5703
VF Loss                      160.30943
Policy Loss                  -1294.121
Q Predictions Mean           1294.7719
Q Predictions Std            1313.2241
Q Predictions Max            4465.675
Q Predictions Min            564.73663
V Predictions Mean           1292.2314
V Predictions Std            1304.0302
V Predictions Max            4426.933
V Predictions Min            576.0392
Log Pis Mean                 -0.19877641
Log Pis Std                  3.6656184
Log Pis Max                  14.371637
Log Pis Min                  -7.1389313
Policy mu Mean               0.030677224
Policy mu Std                0.8817853
Policy mu Max                3.4348254
Policy mu Min                -2.83846
Policy log std Mean          -0.5131481
Policy log std Std           0.26369777
Policy log std Max           -0.037511587
Policy log std Min           -2.7280777
Z mean eval                  1.9405785
Z variance eval              0.07346277
total_rewards                [9458.16710107 9430.31789693 9683.39049612 9201.27698127 9682.94152358
 9813.65515885 9629.15896002 9695.55635098 9601.91349689 9606.38255083]
total_rewards_mean           9580.276051654942
total_rewards_std            165.38009229355887
total_rewards_max            9813.655158852893
total_rewards_min            9201.276981270608
Number of train steps total  916000
Number of env steps total    2750000
Number of rollouts total     0
Train Time (s)               144.5825554621406
(Previous) Eval Time (s)     28.874482203274965
Sample Time (s)              10.313744500279427
Epoch Time (s)               183.77078216569498
Total Train Time (s)         42012.27802916011
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:31:32.130882 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #228 | Epoch Duration: 183.85214829444885
2020-01-13 15:31:32.131078 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #228 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9389579
Z variance train             0.073431306
KL Divergence                51.101955
KL Loss                      5.1101956
QF Loss                      176.01016
VF Loss                      67.604004
Policy Loss                  -1264.1577
Q Predictions Mean           1261.7456
Q Predictions Std            1298.3326
Q Predictions Max            4309.874
Q Predictions Min            549.4913
V Predictions Mean           1266.2119
V Predictions Std            1294.6586
V Predictions Max            4269.2607
V Predictions Min            574.3465
Log Pis Mean                 0.08014789
Log Pis Std                  4.1326094
Log Pis Max                  25.242157
Log Pis Min                  -7.054161
Policy mu Mean               0.10635811
Policy mu Std                0.91357344
Policy mu Max                4.359607
Policy mu Min                -2.9736853
Policy log std Mean          -0.52700645
Policy log std Std           0.28147215
Policy log std Max           -0.0629099
Policy log std Min           -2.51211
Z mean eval                  1.9241972
Z variance eval              0.06682502
total_rewards                [ 9525.77311457  9524.63310425 10109.38054402  9932.53556471
  9696.35234441  9722.71452414  9802.66853823  9800.56737423
  9955.66523824 10050.66997375]
total_rewards_mean           9812.096032053389
total_rewards_std            191.47756929221345
total_rewards_max            10109.380544015927
total_rewards_min            9524.633104249206
Number of train steps total  920000
Number of env steps total    2762000
Number of rollouts total     0
Train Time (s)               139.63791897892952
(Previous) Eval Time (s)     28.857108438853174
Sample Time (s)              9.886954742018133
Epoch Time (s)               178.38198215980083
Total Train Time (s)         42190.74105226109
Epoch                        229
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:34:30.597610 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #229 | Epoch Duration: 178.46637535095215
2020-01-13 15:34:30.597900 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.923579
Z variance train             0.066935256
KL Divergence                50.147408
KL Loss                      5.014741
QF Loss                      6263.8613
VF Loss                      69.7391
Policy Loss                  -1197.9738
Q Predictions Mean           1198.1401
Q Predictions Std            1244.6991
Q Predictions Max            4330.7837
Q Predictions Min            582.18866
V Predictions Mean           1196.7449
V Predictions Std            1238.4927
V Predictions Max            4324.9536
V Predictions Min            578.0298
Log Pis Mean                 -0.25986964
Log Pis Std                  3.6416266
Log Pis Max                  13.422759
Log Pis Min                  -8.450368
Policy mu Mean               0.05554055
Policy mu Std                0.8975339
Policy mu Max                2.580786
Policy mu Min                -2.5958927
Policy log std Mean          -0.5213048
Policy log std Std           0.27092472
Policy log std Max           -0.12432587
Policy log std Min           -3.0745914
Z mean eval                  1.9370235
Z variance eval              0.08173676
total_rewards                [8920.95264833 9031.08315575 9083.71929752 8913.55008815 9277.86600647
 8814.79609163 9235.50647138 9149.74175092 9035.81829788 8949.26414287]
total_rewards_mean           9041.229795091209
total_rewards_std            140.69511978122583
total_rewards_max            9277.866006471842
total_rewards_min            8814.796091630224
Number of train steps total  924000
Number of env steps total    2774000
Number of rollouts total     0
Train Time (s)               140.48945974884555
(Previous) Eval Time (s)     29.161312106996775
Sample Time (s)              9.456483906600624
Epoch Time (s)               179.10725576244295
Total Train Time (s)         42369.935872551054
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:37:29.798170 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #230 | Epoch Duration: 179.20000648498535
2020-01-13 15:37:29.798492 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #230 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9368845
Z variance train             0.081408024
KL Divergence                50.75978
KL Loss                      5.0759783
QF Loss                      3259.1226
VF Loss                      84.351074
Policy Loss                  -1227.3682
Q Predictions Mean           1228.1995
Q Predictions Std            1269.7617
Q Predictions Max            4446.2876
Q Predictions Min            559.088
V Predictions Mean           1223.414
V Predictions Std            1264.9893
V Predictions Max            4422.002
V Predictions Min            550.34564
Log Pis Mean                 -0.018032938
Log Pis Std                  3.777514
Log Pis Max                  14.474442
Log Pis Min                  -8.832639
Policy mu Mean               0.027803645
Policy mu Std                0.9151188
Policy mu Max                3.3747938
Policy mu Min                -2.7581491
Policy log std Mean          -0.5044363
Policy log std Std           0.26441672
Policy log std Max           0.08976966
Policy log std Min           -3.0041203
Z mean eval                  1.9430517
Z variance eval              0.07060936
total_rewards                [ 9542.39861696 10037.52493663 10306.78711594  9869.5537887
 10031.79691504  9879.00069921  9975.86380914  9867.41714295
  9867.90144322  9698.0123933 ]
total_rewards_mean           9907.625686109088
total_rewards_std            194.69739189425772
total_rewards_max            10306.787115944691
total_rewards_min            9542.398616961787
Number of train steps total  928000
Number of env steps total    2786000
Number of rollouts total     0
Train Time (s)               148.2139884289354
(Previous) Eval Time (s)     31.636834896169603
Sample Time (s)              9.632013741414994
Epoch Time (s)               189.48283706652
Total Train Time (s)         42559.511876739096
Epoch                        231
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:40:39.378038 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #231 | Epoch Duration: 189.5793468952179
2020-01-13 15:40:39.378266 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #231 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.942421
Z variance train             0.070304334
KL Divergence                50.693287
KL Loss                      5.069329
QF Loss                      3494.0745
VF Loss                      212.16093
Policy Loss                  -1256.9967
Q Predictions Mean           1253.6975
Q Predictions Std            1297.3807
Q Predictions Max            4458.199
Q Predictions Min            565.9247
V Predictions Mean           1262.1912
V Predictions Std            1297.5756
V Predictions Max            4465.876
V Predictions Min            597.0236
Log Pis Mean                 0.2872134
Log Pis Std                  4.4986887
Log Pis Max                  27.851006
Log Pis Min                  -6.2266316
Policy mu Mean               0.10995728
Policy mu Std                0.9450398
Policy mu Max                4.144553
Policy mu Min                -3.9949484
Policy log std Mean          -0.52812237
Policy log std Std           0.31978187
Policy log std Max           -0.06394759
Policy log std Min           -3.1396983
Z mean eval                  1.9355547
Z variance eval              0.09489147
total_rewards                [ 9601.02536856  9556.26190242  9692.90386618  9775.88688516
  9741.38575485 10013.86654046  9911.70921979  9682.98398996
  9894.04443364  9774.86171456]
total_rewards_mean           9764.492967556662
total_rewards_std            135.3754804142832
total_rewards_max            10013.866540457402
total_rewards_min            9556.26190241688
Number of train steps total  932000
Number of env steps total    2798000
Number of rollouts total     0
Train Time (s)               148.2650310327299
(Previous) Eval Time (s)     30.511944548692554
Sample Time (s)              10.073395936284214
Epoch Time (s)               188.85037151770666
Total Train Time (s)         42748.4482924263
Epoch                        232
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:43:48.317803 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #232 | Epoch Duration: 188.93937611579895
2020-01-13 15:43:48.318062 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9361267
Z variance train             0.094901316
KL Divergence                50.588806
KL Loss                      5.058881
QF Loss                      206.53252
VF Loss                      76.08205
Policy Loss                  -1398.4991
Q Predictions Mean           1393.1212
Q Predictions Std            1356.533
Q Predictions Max            4417.7227
Q Predictions Min            563.9726
V Predictions Mean           1393.08
V Predictions Std            1356.2375
V Predictions Max            4382.3926
V Predictions Min            560.4314
Log Pis Mean                 0.158292
Log Pis Std                  3.6623173
Log Pis Max                  15.757579
Log Pis Min                  -8.119008
Policy mu Mean               0.07688845
Policy mu Std                0.9236098
Policy mu Max                2.9440725
Policy mu Min                -2.4427843
Policy log std Mean          -0.54323214
Policy log std Std           0.3004803
Policy log std Max           -0.05384642
Policy log std Min           -2.8220215
Z mean eval                  1.9570324
Z variance eval              0.07679264
total_rewards                [9129.9188549  9576.73062495 9518.60975292 9522.17266779 9366.27192963
 9671.36290115 9552.83135421 9392.07311225 9652.94601683 9435.16660044]
total_rewards_mean           9481.808381507159
total_rewards_std            151.54534060004258
total_rewards_max            9671.362901150236
total_rewards_min            9129.918854903444
Number of train steps total  936000
Number of env steps total    2810000
Number of rollouts total     0
Train Time (s)               147.36943817790598
(Previous) Eval Time (s)     30.45034273713827
Sample Time (s)              10.213956092484295
Epoch Time (s)               188.03373700752854
Total Train Time (s)         42936.57121652225
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:46:56.442968 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #233 | Epoch Duration: 188.12471508979797
2020-01-13 15:46:56.443158 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #233 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9566803
Z variance train             0.07708934
KL Divergence                51.71924
KL Loss                      5.171924
QF Loss                      3139.1587
VF Loss                      53.637844
Policy Loss                  -1226.6805
Q Predictions Mean           1226.621
Q Predictions Std            1258.2676
Q Predictions Max            4469.9526
Q Predictions Min            575.21436
V Predictions Mean           1232.5968
V Predictions Std            1258.2214
V Predictions Max            4485.391
V Predictions Min            580.13416
Log Pis Mean                 -0.13513651
Log Pis Std                  3.3671122
Log Pis Max                  14.726519
Log Pis Min                  -5.737858
Policy mu Mean               -0.008514089
Policy mu Std                0.874996
Policy mu Max                2.7048051
Policy mu Min                -2.6818202
Policy log std Mean          -0.50320846
Policy log std Std           0.27941662
Policy log std Max           -0.05001363
Policy log std Min           -3.183443
Z mean eval                  1.9395323
Z variance eval              0.087065354
total_rewards                [10049.33808166 10041.94881124  9827.0989714  10133.33409567
  9945.04178349 10032.2362072  10098.16883509  9880.0712134
  9939.63400728  9920.0323927 ]
total_rewards_mean           9986.690439913124
total_rewards_std            93.92216771192588
total_rewards_max            10133.334095670727
total_rewards_min            9827.098971404444
Number of train steps total  940000
Number of env steps total    2822000
Number of rollouts total     0
Train Time (s)               148.1439884598367
(Previous) Eval Time (s)     29.29667740315199
Sample Time (s)              10.488125399686396
Epoch Time (s)               187.92879126267508
Total Train Time (s)         43124.59045614116
Epoch                        234
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:50:04.467114 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #234 | Epoch Duration: 188.0237593650818
2020-01-13 15:50:04.467395 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #234 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9402784
Z variance train             0.086752
KL Divergence                50.100056
KL Loss                      5.0100055
QF Loss                      270.85657
VF Loss                      141.97508
Policy Loss                  -1297.519
Q Predictions Mean           1297.6736
Q Predictions Std            1331.1002
Q Predictions Max            4422.6045
Q Predictions Min            560.39624
V Predictions Mean           1298.2979
V Predictions Std            1331.0719
V Predictions Max            4421.982
V Predictions Min            561.56934
Log Pis Mean                 -0.44335836
Log Pis Std                  3.4862814
Log Pis Max                  15.879322
Log Pis Min                  -6.389076
Policy mu Mean               0.048623353
Policy mu Std                0.87100106
Policy mu Max                2.8332162
Policy mu Min                -3.9590547
Policy log std Mean          -0.5091818
Policy log std Std           0.2736106
Policy log std Max           0.41378194
Policy log std Min           -2.4433315
Z mean eval                  1.9211929
Z variance eval              0.06418599
total_rewards                [ 9859.42546947  9897.74777932 10129.76319875 10044.764835
 10328.07727614 10188.11257633 10033.27187752  9777.62477031
 10357.89499781  9736.6559041 ]
total_rewards_mean           10035.333868475778
total_rewards_std            206.78298147251854
total_rewards_max            10357.894997811103
total_rewards_min            9736.655904099112
Number of train steps total  944000
Number of env steps total    2834000
Number of rollouts total     0
Train Time (s)               141.70890131918713
(Previous) Eval Time (s)     29.209428321104497
Sample Time (s)              9.74855274381116
Epoch Time (s)               180.6668823841028
Total Train Time (s)         43305.3406382259
Epoch                        235
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:53:05.221098 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #235 | Epoch Duration: 180.75351667404175
2020-01-13 15:53:05.221352 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9218194
Z variance train             0.06423936
KL Divergence                50.624195
KL Loss                      5.0624194
QF Loss                      6350.8096
VF Loss                      46.534557
Policy Loss                  -1200.4049
Q Predictions Mean           1198.959
Q Predictions Std            1246.2726
Q Predictions Max            4444.2427
Q Predictions Min            548.2394
V Predictions Mean           1201.6042
V Predictions Std            1243.4972
V Predictions Max            4426.9834
V Predictions Min            581.51807
Log Pis Mean                 -0.33508143
Log Pis Std                  3.4541633
Log Pis Max                  14.936878
Log Pis Min                  -7.783178
Policy mu Mean               0.066765286
Policy mu Std                0.87923944
Policy mu Max                3.5242064
Policy mu Min                -2.4338923
Policy log std Mean          -0.5126443
Policy log std Std           0.27870804
Policy log std Max           -0.09515506
Policy log std Min           -2.5921383
Z mean eval                  1.9610784
Z variance eval              0.09252972
total_rewards                [9826.09488593 9773.95460269 9768.42392321 9866.73056333 9701.71385232
 9778.24894889 9683.58473066 9608.24923037 9721.16559384 9634.15317812]
total_rewards_mean           9736.231950936495
total_rewards_std            77.66586202937835
total_rewards_max            9866.730563328989
total_rewards_min            9608.24923037181
Number of train steps total  948000
Number of env steps total    2846000
Number of rollouts total     0
Train Time (s)               139.01477349596098
(Previous) Eval Time (s)     28.446949918288738
Sample Time (s)              9.87043951684609
Epoch Time (s)               177.3321629310958
Total Train Time (s)         43482.75534722442
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:56:02.637899 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #236 | Epoch Duration: 177.41630840301514
2020-01-13 15:56:02.638120 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #236 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9613769
Z variance train             0.09238528
KL Divergence                49.805748
KL Loss                      4.980575
QF Loss                      261.18848
VF Loss                      91.72749
Policy Loss                  -1154.0132
Q Predictions Mean           1153.2919
Q Predictions Std            1199.2758
Q Predictions Max            4429.276
Q Predictions Min            583.9311
V Predictions Mean           1154.2725
V Predictions Std            1202.6865
V Predictions Max            4428.9336
V Predictions Min            586.7323
Log Pis Mean                 -0.37674624
Log Pis Std                  3.40177
Log Pis Max                  14.17377
Log Pis Min                  -7.87493
Policy mu Mean               0.0882388
Policy mu Std                0.8506179
Policy mu Max                2.9184763
Policy mu Min                -2.1966755
Policy log std Mean          -0.49985647
Policy log std Std           0.2808211
Policy log std Max           -0.08637288
Policy log std Min           -2.7606552
Z mean eval                  1.9308603
Z variance eval              0.116244934
total_rewards                [ 9284.2405441   9726.65466038  9638.81884558  9634.32800997
  9472.81313987  9831.96516715  9181.82443247  9644.16702619
  9470.84477884 10102.02463299]
total_rewards_mean           9598.76812375362
total_rewards_std            251.77991336758149
total_rewards_max            10102.024632985293
total_rewards_min            9181.824432466161
Number of train steps total  952000
Number of env steps total    2858000
Number of rollouts total     0
Train Time (s)               141.20018893200904
(Previous) Eval Time (s)     30.309077558107674
Sample Time (s)              9.078364455141127
Epoch Time (s)               180.58763094525784
Total Train Time (s)         43663.430805042386
Epoch                        237
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:59:03.317269 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #237 | Epoch Duration: 180.67898416519165
2020-01-13 15:59:03.317527 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #237 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9315733
Z variance train             0.116595425
KL Divergence                49.46308
KL Loss                      4.946308
QF Loss                      239.90291
VF Loss                      193.81398
Policy Loss                  -1155.679
Q Predictions Mean           1154.2681
Q Predictions Std            1196.785
Q Predictions Max            4400.112
Q Predictions Min            573.2551
V Predictions Mean           1164.746
V Predictions Std            1201.5555
V Predictions Max            4399.9204
V Predictions Min            576.0604
Log Pis Mean                 -0.32642928
Log Pis Std                  3.4568958
Log Pis Max                  14.645672
Log Pis Min                  -6.5368266
Policy mu Mean               0.044016644
Policy mu Std                0.865577
Policy mu Max                2.6201298
Policy mu Min                -2.679074
Policy log std Mean          -0.50581425
Policy log std Std           0.28859437
Policy log std Max           -0.013492942
Policy log std Min           -2.984808
Z mean eval                  1.9465554
Z variance eval              0.069466256
total_rewards                [ 9892.90818112 10417.90234185 10077.7742391   9783.89996415
 10113.78133588 10069.31035108  9970.59151279  9900.63024268
  9923.02466749  9984.54905462]
total_rewards_mean           10013.437189074084
total_rewards_std            164.83529984025992
total_rewards_max            10417.90234184612
total_rewards_min            9783.899964145703
Number of train steps total  956000
Number of env steps total    2870000
Number of rollouts total     0
Train Time (s)               149.5872400761582
(Previous) Eval Time (s)     29.326138080097735
Sample Time (s)              10.14300733897835
Epoch Time (s)               189.05638549523428
Total Train Time (s)         43852.56879114453
Epoch                        238
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:02:12.457563 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #238 | Epoch Duration: 189.13987970352173
2020-01-13 16:02:12.457760 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #238 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9425962
Z variance train             0.06971607
KL Divergence                50.827553
KL Loss                      5.0827556
QF Loss                      155.94522
VF Loss                      57.068245
Policy Loss                  -1156.1234
Q Predictions Mean           1155.4004
Q Predictions Std            1190.7684
Q Predictions Max            4343.174
Q Predictions Min            550.44934
V Predictions Mean           1155.0637
V Predictions Std            1187.1575
V Predictions Max            4355.363
V Predictions Min            566.3442
Log Pis Mean                 -0.31456512
Log Pis Std                  3.4540973
Log Pis Max                  19.81135
Log Pis Min                  -7.474758
Policy mu Mean               0.10252074
Policy mu Std                0.8797793
Policy mu Max                2.8846378
Policy mu Min                -2.7600598
Policy log std Mean          -0.5044431
Policy log std Std           0.25372297
Policy log std Max           0.61058205
Policy log std Min           -2.7387085
Z mean eval                  1.9358664
Z variance eval              0.07938371
total_rewards                [10040.86804321 10040.39190708  9960.4979786  10037.22985818
 10047.84866335 10173.54710125 10096.09474662 10053.10137893
 10147.88318991 10004.79880713]
total_rewards_mean           10060.22616742791
total_rewards_std            60.275017077628874
total_rewards_max            10173.547101251866
total_rewards_min            9960.49797860265
Number of train steps total  960000
Number of env steps total    2882000
Number of rollouts total     0
Train Time (s)               148.74597715307027
(Previous) Eval Time (s)     29.94808808201924
Sample Time (s)              9.575667146127671
Epoch Time (s)               188.26973238121718
Total Train Time (s)         44040.94191915821
Epoch                        239
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:05:20.833718 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #239 | Epoch Duration: 188.37579202651978
2020-01-13 16:05:20.833965 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #239 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.934707
Z variance train             0.079308376
KL Divergence                51.65499
KL Loss                      5.165499
QF Loss                      3191.183
VF Loss                      100.02337
Policy Loss                  -1301.0402
Q Predictions Mean           1301.4546
Q Predictions Std            1328.2356
Q Predictions Max            4408.818
Q Predictions Min            575.9959
V Predictions Mean           1305.7987
V Predictions Std            1327.5919
V Predictions Max            4406.324
V Predictions Min            593.8772
Log Pis Mean                 -0.09611817
Log Pis Std                  3.4552126
Log Pis Max                  12.228088
Log Pis Min                  -7.6755123
Policy mu Mean               0.089145124
Policy mu Std                0.8869513
Policy mu Max                2.6761277
Policy mu Min                -2.6855292
Policy log std Mean          -0.5170147
Policy log std Std           0.29801086
Policy log std Max           0.013852179
Policy log std Min           -2.9264922
Z mean eval                  1.9495357
Z variance eval              0.10187966
total_rewards                [ 9517.32309302  7111.64007251  9865.63494118  9718.86881922
  9916.72712765  9713.7188827  10017.88789858  9649.16678305
  9880.24522623  9524.61691091]
total_rewards_mean           9491.58297550633
total_rewards_std            808.7295919388145
total_rewards_max            10017.88789857836
total_rewards_min            7111.640072514644
Number of train steps total  964000
Number of env steps total    2894000
Number of rollouts total     0
Train Time (s)               148.8465216839686
(Previous) Eval Time (s)     29.58584917197004
Sample Time (s)              10.376094453968108
Epoch Time (s)               188.80846530990675
Total Train Time (s)         44229.84797177091
Epoch                        240
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:08:29.743998 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #240 | Epoch Duration: 188.90985774993896
2020-01-13 16:08:29.744245 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #240 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9492201
Z variance train             0.10262184
KL Divergence                52.377228
KL Loss                      5.237723
QF Loss                      105.731
VF Loss                      51.730316
Policy Loss                  -1220.5421
Q Predictions Mean           1217.842
Q Predictions Std            1241.0986
Q Predictions Max            4393.5894
Q Predictions Min            584.10223
V Predictions Mean           1219.8568
V Predictions Std            1241.245
V Predictions Max            4392.1665
V Predictions Min            582.2235
Log Pis Mean                 -0.5355362
Log Pis Std                  3.2757554
Log Pis Max                  13.288893
Log Pis Min                  -7.426505
Policy mu Mean               0.04525509
Policy mu Std                0.86828727
Policy mu Max                2.5632887
Policy mu Min                -2.317311
Policy log std Mean          -0.50133234
Policy log std Std           0.26495716
Policy log std Max           -0.11571042
Policy log std Min           -2.7775664
Z mean eval                  1.9537411
Z variance eval              0.07502179
total_rewards                [10121.73323593 10040.90460572 10023.54379669 10421.31870433
 10324.07764943 10088.88188489 10292.42793646 10150.80274785
 10017.23913213 10013.37796205]
total_rewards_mean           10149.430765549516
total_rewards_std            138.8950784602414
total_rewards_max            10421.318704332996
total_rewards_min            10013.37796204809
Number of train steps total  968000
Number of env steps total    2906000
Number of rollouts total     0
Train Time (s)               148.1106223440729
(Previous) Eval Time (s)     30.97706238925457
Sample Time (s)              10.655820301733911
Epoch Time (s)               189.7435050350614
Total Train Time (s)         44419.6843790859
Epoch                        241
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:11:39.582554 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #241 | Epoch Duration: 189.83813405036926
2020-01-13 16:11:39.582777 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #241 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9476162
Z variance train             0.074768946
KL Divergence                52.73751
KL Loss                      5.2737513
QF Loss                      59.64948
VF Loss                      97.84591
Policy Loss                  -1163.9138
Q Predictions Mean           1164.6914
Q Predictions Std            1216.7965
Q Predictions Max            4445.452
Q Predictions Min            575.36304
V Predictions Mean           1167.1841
V Predictions Std            1221.1929
V Predictions Max            4461.1416
V Predictions Min            579.6264
Log Pis Mean                 -0.46651652
Log Pis Std                  3.4064648
Log Pis Max                  11.422
Log Pis Min                  -8.258901
Policy mu Mean               0.031815413
Policy mu Std                0.86822146
Policy mu Max                2.698704
Policy mu Min                -2.4786267
Policy log std Mean          -0.4894655
Policy log std Std           0.2800298
Policy log std Max           -0.060647786
Policy log std Min           -3.0058284
Z mean eval                  1.9351768
Z variance eval              0.08350982
total_rewards                [10023.03045813  9922.72515023  9460.87779218  9902.12350349
  9755.5333275  10306.87731917  9964.90335693  9656.13492781
  9802.01636657  9814.65321231]
total_rewards_mean           9860.887541430966
total_rewards_std            214.51693701879987
total_rewards_max            10306.877319168809
total_rewards_min            9460.877792175786
Number of train steps total  972000
Number of env steps total    2918000
Number of rollouts total     0
Train Time (s)               140.18325160304084
(Previous) Eval Time (s)     29.53062079101801
Sample Time (s)              10.09355049021542
Epoch Time (s)               179.80742288427427
Total Train Time (s)         44599.57156802341
Epoch                        242
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:14:39.472739 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #242 | Epoch Duration: 179.88981127738953
2020-01-13 16:14:39.472942 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #242 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9351257
Z variance train             0.08353916
KL Divergence                52.486507
KL Loss                      5.248651
QF Loss                      84.392105
VF Loss                      38.227116
Policy Loss                  -1145.8145
Q Predictions Mean           1145.1729
Q Predictions Std            1166.3306
Q Predictions Max            4385.254
Q Predictions Min            576.6921
V Predictions Mean           1144.6077
V Predictions Std            1165.5671
V Predictions Max            4379.6763
V Predictions Min            580.8122
Log Pis Mean                 -0.19812922
Log Pis Std                  3.529276
Log Pis Max                  15.831729
Log Pis Min                  -5.951087
Policy mu Mean               0.011437456
Policy mu Std                0.86674625
Policy mu Max                2.5623994
Policy mu Min                -3.7239594
Policy log std Mean          -0.50504565
Policy log std Std           0.2639983
Policy log std Max           -0.11820775
Policy log std Min           -2.8530293
Z mean eval                  1.9321105
Z variance eval              0.07815598
total_rewards                [10112.49888236 10153.89057922  9969.76177138 10093.63333015
  9654.37309807  9932.11270123  9819.46083799 10147.38023672
  9727.11231233 10069.55855742]
total_rewards_mean           9967.97823068662
total_rewards_std            171.3049823117732
total_rewards_max            10153.890579219928
total_rewards_min            9654.373098072669
Number of train steps total  976000
Number of env steps total    2930000
Number of rollouts total     0
Train Time (s)               139.68253536336124
(Previous) Eval Time (s)     29.065707623027265
Sample Time (s)              9.760960114654154
Epoch Time (s)               178.50920310104266
Total Train Time (s)         44778.1601239508
Epoch                        243
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:17:38.064473 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #243 | Epoch Duration: 178.5913770198822
2020-01-13 16:17:38.064699 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9352468
Z variance train             0.07805281
KL Divergence                50.6811
KL Loss                      5.06811
QF Loss                      210.0374
VF Loss                      38.88873
Policy Loss                  -1153.2158
Q Predictions Mean           1149.1617
Q Predictions Std            1193.3839
Q Predictions Max            4494.387
Q Predictions Min            576.7071
V Predictions Mean           1149.5786
V Predictions Std            1189.2925
V Predictions Max            4487.9175
V Predictions Min            585.5772
Log Pis Mean                 -0.22597216
Log Pis Std                  3.537615
Log Pis Max                  13.554201
Log Pis Min                  -5.8292127
Policy mu Mean               0.06952412
Policy mu Std                0.884278
Policy mu Max                3.6636643
Policy mu Min                -2.6949034
Policy log std Mean          -0.49299517
Policy log std Std           0.26738793
Policy log std Max           0.31559515
Policy log std Min           -2.6055617
Z mean eval                  1.9791706
Z variance eval              0.12766126
total_rewards                [7490.18446748 7657.68187254 8281.96327066 3234.89201257 7933.88621135
 4405.44654855 6794.91643997 7922.98255183 7704.5783176  7165.59936199]
total_rewards_mean           6859.21310545282
total_rewards_std            1591.0922545627438
total_rewards_max            8281.963270655875
total_rewards_min            3234.892012566331
Number of train steps total  980000
Number of env steps total    2942000
Number of rollouts total     0
Train Time (s)               144.00262428168207
(Previous) Eval Time (s)     30.59653223771602
Sample Time (s)              9.774086670018733
Epoch Time (s)               184.37324318941683
Total Train Time (s)         44962.62765923329
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:20:42.535044 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #244 | Epoch Duration: 184.47018671035767
2020-01-13 16:20:42.535281 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #244 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9798136
Z variance train             0.12798797
KL Divergence                50.82524
KL Loss                      5.0825243
QF Loss                      198.27704
VF Loss                      99.141754
Policy Loss                  -1259.7648
Q Predictions Mean           1256.4536
Q Predictions Std            1299.1255
Q Predictions Max            4445.8726
Q Predictions Min            585.1568
V Predictions Mean           1254.1438
V Predictions Std            1294.7667
V Predictions Max            4433.4165
V Predictions Min            588.45306
Log Pis Mean                 -0.3692529
Log Pis Std                  4.191777
Log Pis Max                  15.769447
Log Pis Min                  -8.411534
Policy mu Mean               0.07425674
Policy mu Std                0.89729255
Policy mu Max                3.630735
Policy mu Min                -2.8262591
Policy log std Mean          -0.4944274
Policy log std Std           0.27598763
Policy log std Max           -0.017705977
Policy log std Min           -2.905042
Z mean eval                  1.9449186
Z variance eval              0.09311539
total_rewards                [ 9731.40231113 10054.31584395  9867.58998305  9791.04597497
 10261.68311247 10213.29939842  9808.85652108  9905.04017422
  9816.14679637  9619.9894068 ]
total_rewards_mean           9906.93695224696
total_rewards_std            196.82981282193794
total_rewards_max            10261.683112466153
total_rewards_min            9619.989406802237
Number of train steps total  984000
Number of env steps total    2954000
Number of rollouts total     0
Train Time (s)               150.50605584587902
(Previous) Eval Time (s)     29.9683289071545
Sample Time (s)              10.151923403609544
Epoch Time (s)               190.62630815664306
Total Train Time (s)         45153.3337797001
Epoch                        245
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:23:53.244482 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #245 | Epoch Duration: 190.7090368270874
2020-01-13 16:23:53.244698 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #245 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9483988
Z variance train             0.09308015
KL Divergence                51.861984
KL Loss                      5.1861987
QF Loss                      180.88962
VF Loss                      168.37918
Policy Loss                  -1283.084
Q Predictions Mean           1279.6411
Q Predictions Std            1260.8302
Q Predictions Max            4611.8193
Q Predictions Min            591.15
V Predictions Mean           1290.441
V Predictions Std            1268.4142
V Predictions Max            4618.657
V Predictions Min            596.12866
Log Pis Mean                 0.12028774
Log Pis Std                  4.0100694
Log Pis Max                  18.871382
Log Pis Min                  -7.117356
Policy mu Mean               0.08082854
Policy mu Std                0.9063003
Policy mu Max                2.973508
Policy mu Min                -3.5951543
Policy log std Mean          -0.52988434
Policy log std Std           0.30969363
Policy log std Max           -0.088652074
Policy log std Min           -2.9230661
Z mean eval                  1.943505
Z variance eval              0.13394329
total_rewards                [10261.95221002 10309.72528288  9721.46567625  9846.94641814
 10043.76716713 10189.58656038  9853.04552735 10286.65848387
 10028.09615597  9870.59525182]
total_rewards_mean           10041.183873381084
total_rewards_std            201.92985920387622
total_rewards_max            10309.725282878919
total_rewards_min            9721.465676248044
Number of train steps total  988000
Number of env steps total    2966000
Number of rollouts total     0
Train Time (s)               148.66585671994835
(Previous) Eval Time (s)     28.359709546901286
Sample Time (s)              10.39394620899111
Epoch Time (s)               187.41951247584075
Total Train Time (s)         45340.83606707398
Epoch                        246
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:27:00.750077 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #246 | Epoch Duration: 187.50522541999817
2020-01-13 16:27:00.750305 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9428447
Z variance train             0.13467732
KL Divergence                51.156124
KL Loss                      5.1156125
QF Loss                      212.59811
VF Loss                      38.26873
Policy Loss                  -1166.3276
Q Predictions Mean           1163.0356
Q Predictions Std            1228.4307
Q Predictions Max            4477.1934
Q Predictions Min            582.8365
V Predictions Mean           1164.141
V Predictions Std            1226.5111
V Predictions Max            4487.278
V Predictions Min            588.4184
Log Pis Mean                 -0.39417356
Log Pis Std                  3.7097838
Log Pis Max                  15.303744
Log Pis Min                  -9.337946
Policy mu Mean               0.11593148
Policy mu Std                0.87107515
Policy mu Max                3.6016846
Policy mu Min                -3.7522194
Policy log std Mean          -0.5074873
Policy log std Std           0.28958043
Policy log std Max           -0.10039385
Policy log std Min           -3.0936635
Z mean eval                  1.9571533
Z variance eval              0.15611249
total_rewards                [9323.04815315 9717.06531162 9606.5632425  9689.6720868  9512.04307183
 3221.37830649 9554.26706962 9697.73053871 9757.75448357 9663.93083136]
total_rewards_mean           8974.345309565319
total_rewards_std            1921.4374924233532
total_rewards_max            9757.754483574674
total_rewards_min            3221.37830648709
Number of train steps total  992000
Number of env steps total    2978000
Number of rollouts total     0
Train Time (s)               150.42880213167518
(Previous) Eval Time (s)     29.82723056897521
Sample Time (s)              10.155089418869466
Epoch Time (s)               190.41112211951986
Total Train Time (s)         45531.33654670557
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:30:11.253291 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #247 | Epoch Duration: 190.50282835960388
2020-01-13 16:30:11.253505 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9590149
Z variance train             0.15565798
KL Divergence                50.60928
KL Loss                      5.060928
QF Loss                      125.83035
VF Loss                      69.305595
Policy Loss                  -1155.734
Q Predictions Mean           1154.7019
Q Predictions Std            1187.2915
Q Predictions Max            4566.68
Q Predictions Min            573.5293
V Predictions Mean           1154.3293
V Predictions Std            1182.0991
V Predictions Max            4538.8926
V Predictions Min            590.0807
Log Pis Mean                 -0.46262735
Log Pis Std                  3.4167652
Log Pis Max                  12.014719
Log Pis Min                  -8.389885
Policy mu Mean               0.02050732
Policy mu Std                0.8782012
Policy mu Max                2.8959837
Policy mu Min                -2.9098473
Policy log std Mean          -0.4732615
Policy log std Std           0.26299492
Policy log std Max           0.036954522
Policy log std Min           -2.5279312
Z mean eval                  1.96309
Z variance eval              0.09763773
total_rewards                [9428.92353515 4573.4058188  9763.74562208 9490.44335525 9515.84593888
 9373.37685277 9338.04616045 9528.5351752  9606.39036882 9415.15694237]
total_rewards_mean           9003.386976975431
total_rewards_std            1481.2709171158344
total_rewards_max            9763.745622082375
total_rewards_min            4573.405818797543
Number of train steps total  996000
Number of env steps total    2990000
Number of rollouts total     0
Train Time (s)               149.0741340420209
(Previous) Eval Time (s)     29.16554942075163
Sample Time (s)              9.704159358981997
Epoch Time (s)               187.94384282175452
Total Train Time (s)         45719.370081912726
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:33:19.291630 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #248 | Epoch Duration: 188.0379674434662
2020-01-13 16:33:19.291840 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #248 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9641256
Z variance train             0.09833873
KL Divergence                52.76284
KL Loss                      5.276284
QF Loss                      3448.8115
VF Loss                      69.19879
Policy Loss                  -1443.0199
Q Predictions Mean           1441.4685
Q Predictions Std            1392.2493
Q Predictions Max            4604.5684
Q Predictions Min            574.30786
V Predictions Mean           1442.9905
V Predictions Std            1388.4614
V Predictions Max            4574.417
V Predictions Min            573.6102
Log Pis Mean                 -0.025812067
Log Pis Std                  3.9895072
Log Pis Max                  26.916813
Log Pis Min                  -5.768409
Policy mu Mean               0.056403425
Policy mu Std                0.91551447
Policy mu Max                3.4545023
Policy mu Min                -3.169764
Policy log std Mean          -0.515868
Policy log std Std           0.27081168
Policy log std Max           -0.073213756
Policy log std Min           -2.477751
Z mean eval                  1.9474545
Z variance eval              0.13204661
total_rewards                [ 9495.51405413  9676.96931589  9982.00258744 10080.93736037
  9972.23504462 10095.54993407  9862.50691071  9628.1469737
  9740.04108732  9817.61995169]
total_rewards_mean           9835.152321994345
total_rewards_std            190.23745948203336
total_rewards_max            10095.549934069531
total_rewards_min            9495.514054133519
Number of train steps total  1000000
Number of env steps total    3002000
Number of rollouts total     0
Train Time (s)               139.60843819612637
(Previous) Eval Time (s)     29.268058722373098
Sample Time (s)              9.883429286070168
Epoch Time (s)               178.75992620456964
Total Train Time (s)         45898.21192429727
Epoch                        249
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:36:18.134671 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #249 | Epoch Duration: 178.84268140792847
2020-01-13 16:36:18.134853 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9514567
Z variance train             0.13238463
KL Divergence                51.385532
KL Loss                      5.138553
QF Loss                      2940.169
VF Loss                      24.319273
Policy Loss                  -1243.8909
Q Predictions Mean           1243.7451
Q Predictions Std            1299.1376
Q Predictions Max            4595.8843
Q Predictions Min            578.17017
V Predictions Mean           1244.6926
V Predictions Std            1297.2711
V Predictions Max            4575.11
V Predictions Min            599.2393
Log Pis Mean                 -0.06320189
Log Pis Std                  3.9074364
Log Pis Max                  15.66254
Log Pis Min                  -9.812136
Policy mu Mean               0.059695322
Policy mu Std                0.89296174
Policy mu Max                2.6499014
Policy mu Min                -2.501178
Policy log std Mean          -0.51673853
Policy log std Std           0.2715027
Policy log std Max           -0.081174046
Policy log std Min           -2.8352058
Z mean eval                  1.9947431
Z variance eval              0.078553274
total_rewards                [8933.88122964 9401.49534969 9259.50043267 9108.04124654 9214.71386201
 9136.48115017 9246.05364833 9293.4525108  9332.50628174 9504.90153614]
total_rewards_mean           9243.10272477332
total_rewards_std            151.81111772174597
total_rewards_max            9504.901536138055
total_rewards_min            8933.881229637476
Number of train steps total  1004000
Number of env steps total    3014000
Number of rollouts total     0
Train Time (s)               139.76107388501987
(Previous) Eval Time (s)     28.510616914834827
Sample Time (s)              9.85008488362655
Epoch Time (s)               178.12177568348125
Total Train Time (s)         46076.414676554035
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:39:16.340449 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #250 | Epoch Duration: 178.20545363426208
2020-01-13 16:39:16.340649 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #250 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9929972
Z variance train             0.07827337
KL Divergence                53.15555
KL Loss                      5.315555
QF Loss                      2802.02
VF Loss                      179.9066
Policy Loss                  -1266.2455
Q Predictions Mean           1269.495
Q Predictions Std            1300.8354
Q Predictions Max            4631.285
Q Predictions Min            571.49384
V Predictions Mean           1273.7849
V Predictions Std            1299.1359
V Predictions Max            4629.0044
V Predictions Min            594.4167
Log Pis Mean                 -0.46291298
Log Pis Std                  3.7763178
Log Pis Max                  15.96968
Log Pis Min                  -9.308227
Policy mu Mean               0.122819304
Policy mu Std                0.8512747
Policy mu Max                2.8966906
Policy mu Min                -2.371368
Policy log std Mean          -0.51630616
Policy log std Std           0.304955
Policy log std Max           -0.034349322
Policy log std Min           -3.050426
Z mean eval                  1.963733
Z variance eval              0.07852166
total_rewards                [10109.42752596  9915.6844243   9984.30834939 10093.47364136
 10338.69639247  3939.99454944 10153.37230052 10060.55966145
 10040.01772366 10259.22924427]
total_rewards_mean           9489.476381282188
total_rewards_std            1853.539761056543
total_rewards_max            10338.69639246722
total_rewards_min            3939.994549436131
Number of train steps total  1008000
Number of env steps total    3026000
Number of rollouts total     0
Train Time (s)               145.28749540494755
(Previous) Eval Time (s)     29.33153246715665
Sample Time (s)              9.735940395854414
Epoch Time (s)               184.3549682679586
Total Train Time (s)         46260.85175853269
Epoch                        251
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:42:20.780379 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #251 | Epoch Duration: 184.43958401679993
2020-01-13 16:42:20.780569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #251 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9639772
Z variance train             0.0784203
KL Divergence                52.61289
KL Loss                      5.261289
QF Loss                      142.65508
VF Loss                      86.47889
Policy Loss                  -1256.1967
Q Predictions Mean           1255.7366
Q Predictions Std            1294.8688
Q Predictions Max            4440.5684
Q Predictions Min            586.76953
V Predictions Mean           1261.053
V Predictions Std            1293.7605
V Predictions Max            4447.3276
V Predictions Min            600.5695
Log Pis Mean                 -0.036393344
Log Pis Std                  3.7002828
Log Pis Max                  16.270147
Log Pis Min                  -5.8231864
Policy mu Mean               0.0974262
Policy mu Std                0.8894064
Policy mu Max                4.1540065
Policy mu Min                -2.8447604
Policy log std Mean          -0.524439
Policy log std Std           0.29359186
Policy log std Max           -0.0918262
Policy log std Min           -2.8466232
Z mean eval                  1.9489053
Z variance eval              0.05936864
total_rewards                [ 9996.02749193 10111.78091368  9926.27664504 10061.74923418
 10243.86207207 10068.94085456  9919.90720095 10007.26104399
 10100.12932771  9978.70436163]
total_rewards_mean           10041.463914575002
total_rewards_std            92.5930935208111
total_rewards_max            10243.86207206873
total_rewards_min            9919.907200947016
Number of train steps total  1012000
Number of env steps total    3038000
Number of rollouts total     0
Train Time (s)               149.2374453721568
(Previous) Eval Time (s)     29.742304145824164
Sample Time (s)              10.638763090595603
Epoch Time (s)               189.61851260857657
Total Train Time (s)         46450.56341735693
Epoch                        252
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:45:30.495064 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #252 | Epoch Duration: 189.71434783935547
2020-01-13 16:45:30.495267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #252 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9498507
Z variance train             0.05916695
KL Divergence                52.758842
KL Loss                      5.275884
QF Loss                      187.83727
VF Loss                      177.9396
Policy Loss                  -1190.0524
Q Predictions Mean           1189.1248
Q Predictions Std            1247.9867
Q Predictions Max            4593.333
Q Predictions Min            593.39685
V Predictions Mean           1184.4504
V Predictions Std            1235.4205
V Predictions Max            4568.3794
V Predictions Min            598.73914
Log Pis Mean                 -0.26234895
Log Pis Std                  3.5922604
Log Pis Max                  14.970435
Log Pis Min                  -6.208289
Policy mu Mean               0.1265747
Policy mu Std                0.8646248
Policy mu Max                2.8029947
Policy mu Min                -3.0819273
Policy log std Mean          -0.5101912
Policy log std Std           0.2740822
Policy log std Max           0.020993978
Policy log std Min           -2.836711
Z mean eval                  1.9557024
Z variance eval              0.17756967
total_rewards                [10108.22132767 10402.26913959  9928.77035638 10071.37169073
 10110.6107936  10101.88312304 10016.41065792  9723.42479213
  9991.30947444  9806.85832865]
total_rewards_mean           10026.112968415959
total_rewards_std            177.0983709036047
total_rewards_max            10402.269139587457
total_rewards_min            9723.424792133019
Number of train steps total  1016000
Number of env steps total    3050000
Number of rollouts total     0
Train Time (s)               148.51644466770813
(Previous) Eval Time (s)     30.733164200093597
Sample Time (s)              10.269358649849892
Epoch Time (s)               189.51896751765162
Total Train Time (s)         46640.161297829356
Epoch                        253
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:48:40.097755 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #253 | Epoch Duration: 189.60230565071106
2020-01-13 16:48:40.098102 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #253 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9520872
Z variance train             0.17736563
KL Divergence                50.766037
KL Loss                      5.076604
QF Loss                      134.59268
VF Loss                      52.82587
Policy Loss                  -1160.3932
Q Predictions Mean           1158.2123
Q Predictions Std            1178.6766
Q Predictions Max            4475.047
Q Predictions Min            582.6035
V Predictions Mean           1158.6396
V Predictions Std            1178.0819
V Predictions Max            4489.7617
V Predictions Min            582.9939
Log Pis Mean                 -0.24266878
Log Pis Std                  3.507964
Log Pis Max                  13.019343
Log Pis Min                  -7.0731516
Policy mu Mean               0.12707649
Policy mu Std                0.86648405
Policy mu Max                2.9896498
Policy mu Min                -2.3631194
Policy log std Mean          -0.48565462
Policy log std Std           0.27421883
Policy log std Max           0.14229041
Policy log std Min           -3.1272113
Z mean eval                  1.956605
Z variance eval              0.09000462
total_rewards                [ 9684.47261906 10073.32414425  9359.7944184  10085.54013167
  9848.49716278 10187.41846204  9920.42230043  9815.55208044
  9844.8376279  10193.5515641 ]
total_rewards_mean           9901.341051107875
total_rewards_std            241.81571117259298
total_rewards_max            10193.551564096982
total_rewards_min            9359.794418403075
Number of train steps total  1020000
Number of env steps total    3062000
Number of rollouts total     0
Train Time (s)               151.614827984944
(Previous) Eval Time (s)     30.36417240696028
Sample Time (s)              9.376497823279351
Epoch Time (s)               191.35549821518362
Total Train Time (s)         46831.59693857608
Epoch                        254
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:51:51.535615 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #254 | Epoch Duration: 191.4373230934143
2020-01-13 16:51:51.535822 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9549764
Z variance train             0.08993295
KL Divergence                52.26294
KL Loss                      5.226294
QF Loss                      194.11575
VF Loss                      53.220993
Policy Loss                  -1272.1564
Q Predictions Mean           1271.9589
Q Predictions Std            1285.6198
Q Predictions Max            4575.9146
Q Predictions Min            605.9328
V Predictions Mean           1274.5869
V Predictions Std            1282.969
V Predictions Max            4571.0835
V Predictions Min            607.4702
Log Pis Mean                 -0.28540015
Log Pis Std                  3.5152593
Log Pis Max                  14.135853
Log Pis Min                  -6.221319
Policy mu Mean               0.058604296
Policy mu Std                0.8670792
Policy mu Max                2.7812479
Policy mu Min                -3.030596
Policy log std Mean          -0.5142063
Policy log std Std           0.28720772
Policy log std Max           -0.040050954
Policy log std Min           -3.0355563
Z mean eval                  1.981396
Z variance eval              0.07026348
total_rewards                [8999.62335678 9462.12437004 9226.9116618  9278.45596765 9460.95914424
 9868.53865877 9597.92684321 8902.94944676 9199.37224326 4576.53502806]
total_rewards_mean           8857.339672058235
total_rewards_std            1451.8827678327655
total_rewards_max            9868.538658771417
total_rewards_min            4576.535028056659
Number of train steps total  1024000
Number of env steps total    3074000
Number of rollouts total     0
Train Time (s)               148.50180436624214
(Previous) Eval Time (s)     29.332409519702196
Sample Time (s)              9.9289337140508
Epoch Time (s)               187.76314759999514
Total Train Time (s)         47019.43877561251
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:54:59.383288 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #255 | Epoch Duration: 187.84723782539368
2020-01-13 16:54:59.383572 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9822953
Z variance train             0.06986396
KL Divergence                52.94225
KL Loss                      5.294225
QF Loss                      183.69188
VF Loss                      153.56546
Policy Loss                  -1118.244
Q Predictions Mean           1118.4854
Q Predictions Std            1174.3258
Q Predictions Max            4476.0664
Q Predictions Min            570.10504
V Predictions Mean           1111.388
V Predictions Std            1163.7941
V Predictions Max            4444.363
V Predictions Min            561.59656
Log Pis Mean                 -0.41972566
Log Pis Std                  3.5895848
Log Pis Max                  11.899979
Log Pis Min                  -7.127339
Policy mu Mean               0.12591527
Policy mu Std                0.85476923
Policy mu Max                3.3891454
Policy mu Min                -2.5747352
Policy log std Mean          -0.502409
Policy log std Std           0.2666631
Policy log std Max           -0.0030475557
Policy log std Min           -2.593925
Z mean eval                  1.9318562
Z variance eval              0.18161497
total_rewards                [9362.88733547 9916.69324153 9814.50965511 9485.94597424 7982.46135017
 9961.06849575 9385.60365944 9667.77444624 9742.72732588 9223.0985143 ]
total_rewards_mean           9454.276999812422
total_rewards_std            544.3321172040219
total_rewards_max            9961.068495745709
total_rewards_min            7982.461350168785
Number of train steps total  1028000
Number of env steps total    3086000
Number of rollouts total     0
Train Time (s)               139.6096893409267
(Previous) Eval Time (s)     29.680547898169607
Sample Time (s)              8.965229332447052
Epoch Time (s)               178.25546657154337
Total Train Time (s)         47197.776261141524
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:57:57.720875 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #256 | Epoch Duration: 178.33708143234253
2020-01-13 16:57:57.721074 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #256 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9332263
Z variance train             0.181074
KL Divergence                50.847363
KL Loss                      5.0847363
QF Loss                      153.72226
VF Loss                      109.22097
Policy Loss                  -1274.9865
Q Predictions Mean           1271.0233
Q Predictions Std            1303.2976
Q Predictions Max            4538.7095
Q Predictions Min            595.58246
V Predictions Mean           1274.1292
V Predictions Std            1300.2992
V Predictions Max            4529.4937
V Predictions Min            599.7329
Log Pis Mean                 0.03538741
Log Pis Std                  4.0191045
Log Pis Max                  24.665043
Log Pis Min                  -7.2924147
Policy mu Mean               0.07983474
Policy mu Std                0.91893595
Policy mu Max                4.319475
Policy mu Min                -3.0253754
Policy log std Mean          -0.49853793
Policy log std Std           0.26511046
Policy log std Max           -0.015534222
Policy log std Min           -2.6440504
Z mean eval                  1.974363
Z variance eval              0.13118896
total_rewards                [ 9717.17345649  9986.77477312  9845.46705395  9870.71367448
 10025.58991951 10086.69115674  9960.73608202  9899.42024063
  9980.36433311  9982.1913653 ]
total_rewards_mean           9935.512205534471
total_rewards_std            99.85251130680213
total_rewards_max            10086.69115673622
total_rewards_min            9717.173456491355
Number of train steps total  1032000
Number of env steps total    3098000
Number of rollouts total     0
Train Time (s)               139.59636679291725
(Previous) Eval Time (s)     29.392851753160357
Sample Time (s)              9.550183102954179
Epoch Time (s)               178.5394016490318
Total Train Time (s)         47376.39417087659
Epoch                        257
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:00:56.342596 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #257 | Epoch Duration: 178.6213641166687
2020-01-13 17:00:56.342872 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #257 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9709511
Z variance train             0.13095579
KL Divergence                51.99115
KL Loss                      5.1991153
QF Loss                      178.91713
VF Loss                      75.89595
Policy Loss                  -1166.4479
Q Predictions Mean           1164.6244
Q Predictions Std            1197.1562
Q Predictions Max            4552.002
Q Predictions Min            597.1556
V Predictions Mean           1166.429
V Predictions Std            1198.6362
V Predictions Max            4555.6567
V Predictions Min            602.11743
Log Pis Mean                 -0.5907381
Log Pis Std                  3.4700644
Log Pis Max                  12.477587
Log Pis Min                  -12.016023
Policy mu Mean               0.10277319
Policy mu Std                0.8312717
Policy mu Max                2.4802246
Policy mu Min                -2.7601414
Policy log std Mean          -0.49765548
Policy log std Std           0.3014707
Policy log std Max           -0.030546129
Policy log std Min           -3.1634831
Z mean eval                  1.9565325
Z variance eval              0.14265783
total_rewards                [10135.69595352 10171.34244796 10377.97660761 10287.84088896
 10445.02926595 10084.63262912 10256.8749278  10240.60513324
 10432.78499528  9871.63896597]
total_rewards_mean           10230.442181541335
total_rewards_std            165.92860649510823
total_rewards_max            10445.029265954143
total_rewards_min            9871.638965969438
Number of train steps total  1036000
Number of env steps total    3110000
Number of rollouts total     0
Train Time (s)               147.14141802117229
(Previous) Eval Time (s)     29.178507470991462
Sample Time (s)              9.64044051617384
Epoch Time (s)               185.9603660083376
Total Train Time (s)         47562.44275093265
Epoch                        258
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:04:02.393540 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #258 | Epoch Duration: 186.05047130584717
2020-01-13 17:04:02.393749 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #258 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9555651
Z variance train             0.14250639
KL Divergence                52.240955
KL Loss                      5.224096
QF Loss                      140.5322
VF Loss                      109.18727
Policy Loss                  -1281.106
Q Predictions Mean           1281.6718
Q Predictions Std            1291.8252
Q Predictions Max            4587.594
Q Predictions Min            592.4683
V Predictions Mean           1279.1501
V Predictions Std            1284.1434
V Predictions Max            4546.0366
V Predictions Min            594.54456
Log Pis Mean                 -0.12619807
Log Pis Std                  3.9437368
Log Pis Max                  16.002707
Log Pis Min                  -10.1231
Policy mu Mean               0.08354399
Policy mu Std                0.9057806
Policy mu Max                2.865189
Policy mu Min                -2.6700594
Policy log std Mean          -0.5075023
Policy log std Std           0.29988652
Policy log std Max           0.10132736
Policy log std Min           -2.9248376
Z mean eval                  1.9593294
Z variance eval              0.12724075
total_rewards                [10303.02268158 10421.25278084 10008.8980012  10279.01401102
 10189.5957169  10015.55101606 10157.57320615 10053.12680481
 10129.97389822  9991.23683566]
total_rewards_mean           10154.924495243311
total_rewards_std            137.11265490105856
total_rewards_max            10421.252780841816
total_rewards_min            9991.236835662825
Number of train steps total  1040000
Number of env steps total    3122000
Number of rollouts total     0
Train Time (s)               149.64030623389408
(Previous) Eval Time (s)     30.440281938761473
Sample Time (s)              10.394849063828588
Epoch Time (s)               190.47543723648414
Total Train Time (s)         47753.00681516901
Epoch                        259
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:07:12.960543 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #259 | Epoch Duration: 190.56664419174194
2020-01-13 17:07:12.960739 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #259 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9590746
Z variance train             0.12722877
KL Divergence                52.992153
KL Loss                      5.2992153
QF Loss                      170.3523
VF Loss                      41.57708
Policy Loss                  -1332.2124
Q Predictions Mean           1327.8268
Q Predictions Std            1346.3975
Q Predictions Max            4598.9106
Q Predictions Min            598.72974
V Predictions Mean           1330.8203
V Predictions Std            1346.4364
V Predictions Max            4593.06
V Predictions Min            601.7657
Log Pis Mean                 0.014792729
Log Pis Std                  3.9413142
Log Pis Max                  15.388548
Log Pis Min                  -5.942959
Policy mu Mean               0.14645337
Policy mu Std                0.92531484
Policy mu Max                3.5238512
Policy mu Min                -3.302225
Policy log std Mean          -0.51154464
Policy log std Std           0.28874612
Policy log std Max           -0.08628109
Policy log std Min           -2.8561914
Z mean eval                  1.9430662
Z variance eval              0.09347779
total_rewards                [10092.72321283 10288.14453309 10209.82525047 10088.1017843
 10359.04428334 10299.66482991 10157.34001522 10184.12811055
 10314.03682869 10241.50501661]
total_rewards_mean           10223.451386497538
total_rewards_std            88.55668070618614
total_rewards_max            10359.044283336696
total_rewards_min            10088.101784296381
Number of train steps total  1044000
Number of env steps total    3134000
Number of rollouts total     0
Train Time (s)               148.2596711497754
(Previous) Eval Time (s)     29.356601145584136
Sample Time (s)              10.378492081537843
Epoch Time (s)               187.99476437689736
Total Train Time (s)         47941.08980655391
Epoch                        260
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:10:21.047949 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #260 | Epoch Duration: 188.0870361328125
2020-01-13 17:10:21.048292 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.943725
Z variance train             0.093232155
KL Divergence                52.974403
KL Loss                      5.2974405
QF Loss                      218.24216
VF Loss                      42.02686
Policy Loss                  -1371.7958
Q Predictions Mean           1370.8142
Q Predictions Std            1403.7755
Q Predictions Max            4500.2676
Q Predictions Min            597.0169
V Predictions Mean           1374.0065
V Predictions Std            1403.202
V Predictions Max            4520.793
V Predictions Min            609.7846
Log Pis Mean                 0.117132165
Log Pis Std                  3.9352047
Log Pis Max                  13.096728
Log Pis Min                  -6.6114774
Policy mu Mean               0.0736755
Policy mu Std                0.91941756
Policy mu Max                2.9057004
Policy mu Min                -2.3877015
Policy log std Mean          -0.52533716
Policy log std Std           0.3151582
Policy log std Max           0.26289552
Policy log std Min           -3.1983514
Z mean eval                  1.986013
Z variance eval              0.17956065
total_rewards                [9812.18064375 9944.22071455 9907.66401652 9796.60215679 9762.29412446
 9785.92604    9893.82468703 9879.84790332 9870.78167251 9946.1751195 ]
total_rewards_mean           9859.95170784328
total_rewards_std            63.075173667556996
total_rewards_max            9946.17511950249
total_rewards_min            9762.294124458309
Number of train steps total  1048000
Number of env steps total    3146000
Number of rollouts total     0
Train Time (s)               149.886654403992
(Previous) Eval Time (s)     29.971428307704628
Sample Time (s)              10.53548581711948
Epoch Time (s)               190.3935685288161
Total Train Time (s)         48131.56491024932
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:13:31.526187 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #261 | Epoch Duration: 190.4776895046234
2020-01-13 17:13:31.526427 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #261 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9843174
Z variance train             0.17986625
KL Divergence                52.257217
KL Loss                      5.225722
QF Loss                      91.77335
VF Loss                      75.48465
Policy Loss                  -1201.828
Q Predictions Mean           1200.3152
Q Predictions Std            1217.2886
Q Predictions Max            4546.483
Q Predictions Min            596.0869
V Predictions Mean           1200.8419
V Predictions Std            1215.4827
V Predictions Max            4500.5986
V Predictions Min            600.7655
Log Pis Mean                 0.08252141
Log Pis Std                  4.0387716
Log Pis Max                  24.205961
Log Pis Min                  -8.521726
Policy mu Mean               0.13392894
Policy mu Std                0.90578836
Policy mu Max                4.0184293
Policy mu Min                -3.9198818
Policy log std Mean          -0.52013373
Policy log std Std           0.28816715
Policy log std Max           0.030898869
Policy log std Min           -2.8684645
Z mean eval                  1.9508765
Z variance eval              0.07981299
total_rewards                [ 9960.85512423  9853.50873296  9883.22772591  5799.44513045
  9912.42219828  9859.72554073  9687.63074645  9957.00903987
  9779.16088955 10023.97837212]
total_rewards_mean           9471.69635005451
total_rewards_std            1227.4508530614603
total_rewards_max            10023.978372124795
total_rewards_min            5799.445130446462
Number of train steps total  1052000
Number of env steps total    3158000
Number of rollouts total     0
Train Time (s)               147.25613812590018
(Previous) Eval Time (s)     29.26027019089088
Sample Time (s)              10.443169995676726
Epoch Time (s)               186.95957831246778
Total Train Time (s)         48318.61661321856
Epoch                        262
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:16:38.581047 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #262 | Epoch Duration: 187.05445981025696
2020-01-13 17:16:38.581258 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #262 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9573147
Z variance train             0.080634885
KL Divergence                54.13252
KL Loss                      5.413252
QF Loss                      301.58386
VF Loss                      144.73628
Policy Loss                  -1411.1548
Q Predictions Mean           1407.0134
Q Predictions Std            1407.0638
Q Predictions Max            4644.002
Q Predictions Min            594.31946
V Predictions Mean           1405.1903
V Predictions Std            1399.2023
V Predictions Max            4601.1064
V Predictions Min            598.0901
Log Pis Mean                 0.35693285
Log Pis Std                  4.4861774
Log Pis Max                  28.6383
Log Pis Min                  -7.1889777
Policy mu Mean               0.1016041
Policy mu Std                0.94254893
Policy mu Max                3.6127439
Policy mu Min                -3.6968663
Policy log std Mean          -0.5386949
Policy log std Std           0.29447114
Policy log std Max           -0.0987052
Policy log std Min           -2.740314
Z mean eval                  2.002247
Z variance eval              0.16517986
total_rewards                [ 9436.41796412 10045.3213572   9839.71487238  9965.49778205
 10276.36336962 10171.71192762 10170.6507684  10004.73515336
 10138.30748832 10367.98530242]
total_rewards_mean           10041.670598548977
total_rewards_std            248.74565778045996
total_rewards_max            10367.9853024218
total_rewards_min            9436.417964115779
Number of train steps total  1056000
Number of env steps total    3170000
Number of rollouts total     0
Train Time (s)               139.73196485079825
(Previous) Eval Time (s)     28.257066540885717
Sample Time (s)              9.818463179282844
Epoch Time (s)               177.8074945709668
Total Train Time (s)         48496.51551385829
Epoch                        263
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:19:36.483634 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #263 | Epoch Duration: 177.90221571922302
2020-01-13 17:19:36.483894 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #263 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9982789
Z variance train             0.1644143
KL Divergence                53.671646
KL Loss                      5.3671646
QF Loss                      133.26212
VF Loss                      74.56693
Policy Loss                  -1160.7379
Q Predictions Mean           1160.9299
Q Predictions Std            1184.7688
Q Predictions Max            4598.0947
Q Predictions Min            602.2593
V Predictions Mean           1164.2285
V Predictions Std            1185.2684
V Predictions Max            4609.5317
V Predictions Min            612.2964
Log Pis Mean                 -0.22413307
Log Pis Std                  3.7126446
Log Pis Max                  15.95997
Log Pis Min                  -8.858591
Policy mu Mean               0.10550291
Policy mu Std                0.90644526
Policy mu Max                3.1765404
Policy mu Min                -3.0681543
Policy log std Mean          -0.5086474
Policy log std Std           0.27177778
Policy log std Max           -0.012532353
Policy log std Min           -2.7394357
Z mean eval                  1.9406506
Z variance eval              0.09757313
total_rewards                [10214.78541257 10280.6761442  10391.60197681 10221.3276348
 10421.60253382 10250.72090867 10169.66665616  9894.18608446
 10197.64514555 10084.80188848]
total_rewards_mean           10212.701438551894
total_rewards_std            142.01368781770773
total_rewards_max            10421.602533822985
total_rewards_min            9894.186084459907
Number of train steps total  1060000
Number of env steps total    3182000
Number of rollouts total     0
Train Time (s)               140.52435692725703
(Previous) Eval Time (s)     30.195137112867087
Sample Time (s)              9.60282784467563
Epoch Time (s)               180.32232188479975
Total Train Time (s)         48676.92204721132
Epoch                        264
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:22:36.894131 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #264 | Epoch Duration: 180.4100067615509
2020-01-13 17:22:36.894397 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #264 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9411623
Z variance train             0.0975741
KL Divergence                54.347424
KL Loss                      5.4347425
QF Loss                      110.65353
VF Loss                      59.693756
Policy Loss                  -1260.4943
Q Predictions Mean           1257.4529
Q Predictions Std            1288.044
Q Predictions Max            4578.647
Q Predictions Min            612.70483
V Predictions Mean           1259.4565
V Predictions Std            1282.3419
V Predictions Max            4565.4404
V Predictions Min            614.5366
Log Pis Mean                 -0.15504694
Log Pis Std                  3.7274637
Log Pis Max                  12.967021
Log Pis Min                  -7.3127046
Policy mu Mean               0.015149939
Policy mu Std                0.8873447
Policy mu Max                2.67189
Policy mu Min                -2.441389
Policy log std Mean          -0.52517873
Policy log std Std           0.28327793
Policy log std Max           -0.042826295
Policy log std Min           -2.8210788
Z mean eval                  1.9552457
Z variance eval              0.10096445
total_rewards                [10402.82289905 10253.88774629  9945.04387249 10331.07162848
  9944.31970478 10525.34704767 10210.51205332 10190.02425527
  9973.00503963 10284.85448273]
total_rewards_mean           10206.088872969927
total_rewards_std            188.6830149757198
total_rewards_max            10525.347047672687
total_rewards_min            9944.319704777943
Number of train steps total  1064000
Number of env steps total    3194000
Number of rollouts total     0
Train Time (s)               148.32597569935024
(Previous) Eval Time (s)     30.709276102948934
Sample Time (s)              9.967374621890485
Epoch Time (s)               189.00262642418966
Total Train Time (s)         48866.02838275023
Epoch                        265
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:25:46.002874 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #265 | Epoch Duration: 189.10829162597656
2020-01-13 17:25:46.003095 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #265 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9550905
Z variance train             0.10101907
KL Divergence                53.64379
KL Loss                      5.3643794
QF Loss                      603.0506
VF Loss                      196.8978
Policy Loss                  -1239.7689
Q Predictions Mean           1236.5585
Q Predictions Std            1266.6381
Q Predictions Max            4549.0117
Q Predictions Min            596.39966
V Predictions Mean           1242.4265
V Predictions Std            1268.2589
V Predictions Max            4539.6646
V Predictions Min            605.2948
Log Pis Mean                 -0.3196544
Log Pis Std                  3.6800213
Log Pis Max                  14.0129385
Log Pis Min                  -7.4043283
Policy mu Mean               0.11835768
Policy mu Std                0.88140637
Policy mu Max                2.7096982
Policy mu Min                -3.1827295
Policy log std Mean          -0.49636316
Policy log std Std           0.27746046
Policy log std Max           -0.030071318
Policy log std Min           -2.8492062
Z mean eval                  1.9532503
Z variance eval              0.10718991
total_rewards                [ 9708.13717755 10282.43890326 10382.90583188  9960.19346342
 10303.40185757 10244.07451938 10062.56804956  9734.1055625
 10121.36611399 10242.62256279]
total_rewards_mean           10104.181404189148
total_rewards_std            224.60065457660738
total_rewards_max            10382.905831878963
total_rewards_min            9708.13717755405
Number of train steps total  1068000
Number of env steps total    3206000
Number of rollouts total     0
Train Time (s)               147.92923747282475
(Previous) Eval Time (s)     29.92204552097246
Sample Time (s)              10.650124087929726
Epoch Time (s)               188.50140708172694
Total Train Time (s)         49054.61050544819
Epoch                        266
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:28:54.588072 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #266 | Epoch Duration: 188.58481359481812
2020-01-13 17:28:54.588276 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #266 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9561024
Z variance train             0.10746006
KL Divergence                53.163776
KL Loss                      5.3163776
QF Loss                      176.01093
VF Loss                      42.301804
Policy Loss                  -1128.2875
Q Predictions Mean           1125.5757
Q Predictions Std            1136.084
Q Predictions Max            4640.228
Q Predictions Min            620.03986
V Predictions Mean           1127.1482
V Predictions Std            1135.3776
V Predictions Max            4634.331
V Predictions Min            618.9956
Log Pis Mean                 -0.28897548
Log Pis Std                  3.6395652
Log Pis Max                  16.84479
Log Pis Min                  -6.4983125
Policy mu Mean               0.09255215
Policy mu Std                0.84938675
Policy mu Max                2.658588
Policy mu Min                -2.8852284
Policy log std Mean          -0.5099641
Policy log std Std           0.27963164
Policy log std Max           -0.104449496
Policy log std Min           -2.8692448
Z mean eval                  1.9411188
Z variance eval              0.1553239
total_rewards                [ 9942.58790618 10291.2173137  10196.6444314  10305.65154449
 10409.64394744 10373.56998583 10243.55481254 10573.03334694
 10407.07176855 10457.32923311]
total_rewards_mean           10320.030429017721
total_rewards_std            163.0665906934029
total_rewards_max            10573.033346937136
total_rewards_min            9942.587906175488
Number of train steps total  1072000
Number of env steps total    3218000
Number of rollouts total     0
Train Time (s)               146.7633168003522
(Previous) Eval Time (s)     29.996457470115274
Sample Time (s)              10.606211284641176
Epoch Time (s)               187.36598555510864
Total Train Time (s)         49242.07156493934
Epoch                        267
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:32:02.053097 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #267 | Epoch Duration: 187.4646451473236
2020-01-13 17:32:02.053417 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #267 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9455807
Z variance train             0.15535726
KL Divergence                52.31722
KL Loss                      5.231722
QF Loss                      7487.211
VF Loss                      40.853302
Policy Loss                  -1234.311
Q Predictions Mean           1235.6743
Q Predictions Std            1284.4493
Q Predictions Max            4687.4653
Q Predictions Min            608.49194
V Predictions Mean           1238.4282
V Predictions Std            1283.9357
V Predictions Max            4677.9863
V Predictions Min            604.22504
Log Pis Mean                 -0.2888417
Log Pis Std                  3.7242215
Log Pis Max                  12.106652
Log Pis Min                  -7.371811
Policy mu Mean               0.047467288
Policy mu Std                0.8846322
Policy mu Max                2.8068702
Policy mu Min                -2.961935
Policy log std Mean          -0.5111824
Policy log std Std           0.26982242
Policy log std Max           -0.091511235
Policy log std Min           -2.7282758
Z mean eval                  1.9627364
Z variance eval              0.09242717
total_rewards                [10654.96332421 10366.47519354 10267.18187946 10556.01761596
 10390.73826151 10242.67347902 10414.20398019 10473.29171202
 10340.63395927 10629.1169163 ]
total_rewards_mean           10433.529632150687
total_rewards_std            135.38822950692193
total_rewards_max            10654.963324213959
total_rewards_min            10242.673479023835
Number of train steps total  1076000
Number of env steps total    3230000
Number of rollouts total     0
Train Time (s)               149.7460481757298
(Previous) Eval Time (s)     30.38913779705763
Sample Time (s)              9.241983769461513
Epoch Time (s)               189.37716974224895
Total Train Time (s)         49431.53834793484
Epoch                        268
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:35:11.523586 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #268 | Epoch Duration: 189.4699468612671
2020-01-13 17:35:11.523894 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #268 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9604967
Z variance train             0.0924002
KL Divergence                53.11122
KL Loss                      5.3111224
QF Loss                      146.12372
VF Loss                      56.706497
Policy Loss                  -1364.9962
Q Predictions Mean           1362.7065
Q Predictions Std            1366.1173
Q Predictions Max            4601.9536
Q Predictions Min            613.38885
V Predictions Mean           1365.2535
V Predictions Std            1361.9725
V Predictions Max            4594.3945
V Predictions Min            613.5358
Log Pis Mean                 -0.15069796
Log Pis Std                  3.9020264
Log Pis Max                  16.105032
Log Pis Min                  -8.322474
Policy mu Mean               -0.030104196
Policy mu Std                0.8853719
Policy mu Max                3.390341
Policy mu Min                -3.1752055
Policy log std Mean          -0.51898
Policy log std Std           0.30558974
Policy log std Max           -0.019648373
Policy log std Min           -2.9124537
Z mean eval                  1.9484856
Z variance eval              0.12512328
total_rewards                [10099.43905208 10204.68375201 10154.87696721 10054.87530194
 10171.96918582 10016.11738694 10309.48535882 10172.56802334
 10045.15526434 10298.30192599]
total_rewards_mean           10152.747221848713
total_rewards_std            95.85495151912137
total_rewards_max            10309.485358815535
total_rewards_min            10016.1173869442
Number of train steps total  1080000
Number of env steps total    3242000
Number of rollouts total     0
Train Time (s)               145.39985370915383
(Previous) Eval Time (s)     28.521758711431175
Sample Time (s)              9.993156720418483
Epoch Time (s)               183.9147691410035
Total Train Time (s)         49615.75490234513
Epoch                        269
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:38:15.743151 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #269 | Epoch Duration: 184.21902751922607
2020-01-13 17:38:15.743391 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9526058
Z variance train             0.12542222
KL Divergence                51.928677
KL Loss                      5.1928678
QF Loss                      141.60733
VF Loss                      120.80214
Policy Loss                  -1130.3169
Q Predictions Mean           1121.0999
Q Predictions Std            1112.9371
Q Predictions Max            4517.9873
Q Predictions Min            594.2627
V Predictions Mean           1123.8044
V Predictions Std            1109.6588
V Predictions Max            4498.9014
V Predictions Min            600.6952
Log Pis Mean                 0.015732348
Log Pis Std                  3.7868044
Log Pis Max                  16.65925
Log Pis Min                  -7.407729
Policy mu Mean               0.07622937
Policy mu Std                0.89257115
Policy mu Max                3.1468418
Policy mu Min                -2.7956443
Policy log std Mean          -0.5253474
Policy log std Std           0.2851643
Policy log std Max           -0.08221638
Policy log std Min           -2.7660918
Z mean eval                  1.9688679
Z variance eval              0.12832661
total_rewards                [9509.49938406 9505.1303126  9494.76850095 9718.91096163 9456.30794416
 9417.79418302 9608.733909   9674.45223218 9641.49313221 9814.73083966]
total_rewards_mean           9584.182139946777
total_rewards_std            121.32553462202596
total_rewards_max            9814.730839659078
total_rewards_min            9417.794183019645
Number of train steps total  1084000
Number of env steps total    3254000
Number of rollouts total     0
Train Time (s)               140.6107315402478
(Previous) Eval Time (s)     28.020306948106736
Sample Time (s)              9.878169332165271
Epoch Time (s)               178.5092078205198
Total Train Time (s)         49794.34660606552
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:41:14.337980 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #270 | Epoch Duration: 178.59443306922913
2020-01-13 17:41:14.338179 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #270 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9692829
Z variance train             0.12819065
KL Divergence                52.90217
KL Loss                      5.290217
QF Loss                      82.2018
VF Loss                      71.8457
Policy Loss                  -1294.8889
Q Predictions Mean           1293.425
Q Predictions Std            1320.6595
Q Predictions Max            4657.4243
Q Predictions Min            592.9095
V Predictions Mean           1292.3745
V Predictions Std            1314.2513
V Predictions Max            4634.8916
V Predictions Min            593.362
Log Pis Mean                 0.09747827
Log Pis Std                  3.771694
Log Pis Max                  18.886345
Log Pis Min                  -5.960614
Policy mu Mean               0.051145796
Policy mu Std                0.898225
Policy mu Max                3.082463
Policy mu Min                -3.5100782
Policy log std Mean          -0.5193891
Policy log std Std           0.29058594
Policy log std Max           0.12824571
Policy log std Min           -2.7406874
Z mean eval                  1.9582884
Z variance eval              0.1309273
total_rewards                [10204.91723419 10396.03376791 10555.4650983  10524.20319941
 10468.12786446 10606.76419612 10418.2733979  10128.92866134
 10152.69417023 10233.06069352]
total_rewards_mean           10368.846828337879
total_rewards_std            166.79297914378637
total_rewards_max            10606.764196124755
total_rewards_min            10128.928661339945
Number of train steps total  1088000
Number of env steps total    3266000
Number of rollouts total     0
Train Time (s)               141.20855596801266
(Previous) Eval Time (s)     29.080205208156258
Sample Time (s)              9.545829454436898
Epoch Time (s)               179.83459063060582
Total Train Time (s)         49974.264529689215
Epoch                        271
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:44:14.260285 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #271 | Epoch Duration: 179.9219491481781
2020-01-13 17:44:14.260506 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #271 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9585298
Z variance train             0.13126902
KL Divergence                52.31795
KL Loss                      5.2317953
QF Loss                      149.65193
VF Loss                      28.801044
Policy Loss                  -1181.6243
Q Predictions Mean           1177.624
Q Predictions Std            1216.4355
Q Predictions Max            4646.9087
Q Predictions Min            595.6607
V Predictions Mean           1182.5647
V Predictions Std            1215.1338
V Predictions Max            4649.96
V Predictions Min            589.8164
Log Pis Mean                 0.07031142
Log Pis Std                  3.9031382
Log Pis Max                  18.67012
Log Pis Min                  -7.9684734
Policy mu Mean               0.13380344
Policy mu Std                0.8790461
Policy mu Max                4.8307247
Policy mu Min                -2.961402
Policy log std Mean          -0.49859452
Policy log std Std           0.2996049
Policy log std Max           -0.04508227
Policy log std Min           -3.242481
Z mean eval                  1.9601202
Z variance eval              0.055157762
total_rewards                [ 9755.39759672  9792.18153354 10140.93797341  9459.44415581
 10002.25725826 10175.91611489  9819.89855223  9550.07689811
 10335.37098493 10017.62119946]
total_rewards_mean           9904.910226736945
total_rewards_std            265.1915236059081
total_rewards_max            10335.370984930014
total_rewards_min            9459.444155813937
Number of train steps total  1092000
Number of env steps total    3278000
Number of rollouts total     0
Train Time (s)               149.62820453569293
(Previous) Eval Time (s)     30.37955539021641
Sample Time (s)              10.325619168113917
Epoch Time (s)               190.33337909402326
Total Train Time (s)         50164.925556094386
Epoch                        272
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:47:24.925057 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #272 | Epoch Duration: 190.66436743736267
2020-01-13 17:47:24.925389 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #272 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9593878
Z variance train             0.055115223
KL Divergence                54.539604
KL Loss                      5.4539604
QF Loss                      279.7019
VF Loss                      55.506737
Policy Loss                  -1164.5004
Q Predictions Mean           1161.5167
Q Predictions Std            1187.5452
Q Predictions Max            4609.7554
Q Predictions Min            606.4186
V Predictions Mean           1158.9165
V Predictions Std            1186.215
V Predictions Max            4599.281
V Predictions Min            600.6877
Log Pis Mean                 -0.29825616
Log Pis Std                  4.1602097
Log Pis Max                  28.566233
Log Pis Min                  -6.97023
Policy mu Mean               0.0238038
Policy mu Std                0.8958431
Policy mu Max                5.5677
Policy mu Min                -3.2400281
Policy log std Mean          -0.5094337
Policy log std Std           0.2806008
Policy log std Max           0.40807146
Policy log std Min           -2.6294284
Z mean eval                  1.9804586
Z variance eval              0.059004195
total_rewards                [ 9826.54226008  9961.35524377 10356.59048531 10122.76144859
 10412.75286318 10465.73344935 10297.26033995 10306.40992385
 10420.07966485  9929.99503554]
total_rewards_mean           10209.948071446292
total_rewards_std            219.9811737558393
total_rewards_max            10465.733449347015
total_rewards_min            9826.542260079801
Number of train steps total  1096000
Number of env steps total    3290000
Number of rollouts total     0
Train Time (s)               148.28519101906568
(Previous) Eval Time (s)     30.623805679846555
Sample Time (s)              9.796540736220777
Epoch Time (s)               188.705537435133
Total Train Time (s)         50353.714128866326
Epoch                        273
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:50:33.716095 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #273 | Epoch Duration: 188.79052305221558
2020-01-13 17:50:33.716278 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #273 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9810203
Z variance train             0.05878844
KL Divergence                55.03484
KL Loss                      5.5034842
QF Loss                      3629.6423
VF Loss                      58.72224
Policy Loss                  -1160.1917
Q Predictions Mean           1160.6072
Q Predictions Std            1197.3558
Q Predictions Max            4643.9634
Q Predictions Min            613.5084
V Predictions Mean           1161.8513
V Predictions Std            1204.074
V Predictions Max            4655.107
V Predictions Min            611.94794
Log Pis Mean                 -0.6196927
Log Pis Std                  3.6754577
Log Pis Max                  14.549376
Log Pis Min                  -8.68638
Policy mu Mean               0.022861585
Policy mu Std                0.82580256
Policy mu Max                2.5359566
Policy mu Min                -2.8360126
Policy log std Mean          -0.49567804
Policy log std Std           0.27506843
Policy log std Max           -0.049618483
Policy log std Min           -2.981358
Z mean eval                  1.9562361
Z variance eval              0.06127686
total_rewards                [10194.88904054 10238.1312055  10167.64250169  5819.18264927
 10639.07054403 10218.20427035 10286.30621297 10334.48880959
 10222.79810208 10385.38323964]
total_rewards_mean           9850.609657565403
total_rewards_std            1350.0699502016632
total_rewards_max            10639.07054402651
total_rewards_min            5819.182649274915
Number of train steps total  1100000
Number of env steps total    3302000
Number of rollouts total     0
Train Time (s)               148.14769616676494
(Previous) Eval Time (s)     30.94171300670132
Sample Time (s)              9.597142568789423
Epoch Time (s)               188.6865517422557
Total Train Time (s)         50542.49103916623
Epoch                        274
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:53:42.497621 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #274 | Epoch Duration: 188.78116416931152
2020-01-13 17:53:42.497949 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9538991
Z variance train             0.061274208
KL Divergence                53.942406
KL Loss                      5.394241
QF Loss                      166.73068
VF Loss                      96.686325
Policy Loss                  -1358.419
Q Predictions Mean           1358.164
Q Predictions Std            1371.47
Q Predictions Max            4568.322
Q Predictions Min            603.74634
V Predictions Mean           1362.6572
V Predictions Std            1373.4792
V Predictions Max            4578.695
V Predictions Min            611.82733
Log Pis Mean                 0.08500078
Log Pis Std                  4.1581097
Log Pis Max                  14.030732
Log Pis Min                  -7.6049185
Policy mu Mean               0.10830713
Policy mu Std                0.90829587
Policy mu Max                2.5362644
Policy mu Min                -3.2778904
Policy log std Mean          -0.519339
Policy log std Std           0.28573057
Policy log std Max           -0.062477976
Policy log std Min           -3.0391815
Z mean eval                  2.0125535
Z variance eval              0.11018088
total_rewards                [9879.47562279 9801.37876163 9689.95366977 9770.61908645 9559.16076926
 9734.15285138 9734.6090302  9369.47290173 9871.79133188 3403.04078125]
total_rewards_mean           9081.365480634475
total_rewards_std            1898.2398733890384
total_rewards_max            9879.47562279111
total_rewards_min            3403.040781250323
Number of train steps total  1104000
Number of env steps total    3314000
Number of rollouts total     0
Train Time (s)               149.1500202640891
(Previous) Eval Time (s)     30.68168730614707
Sample Time (s)              10.0310167404823
Epoch Time (s)               189.86272431071848
Total Train Time (s)         50732.4479761878
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:56:52.458215 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #275 | Epoch Duration: 189.9600522518158
2020-01-13 17:56:52.458568 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #275 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.013554
Z variance train             0.11049329
KL Divergence                53.46285
KL Loss                      5.346285
QF Loss                      199.85318
VF Loss                      65.55887
Policy Loss                  -1341.7246
Q Predictions Mean           1339.926
Q Predictions Std            1361.4413
Q Predictions Max            4651.5874
Q Predictions Min            620.84845
V Predictions Mean           1342.7845
V Predictions Std            1358.5282
V Predictions Max            4668.4375
V Predictions Min            623.06335
Log Pis Mean                 0.13369147
Log Pis Std                  3.8721955
Log Pis Max                  18.259607
Log Pis Min                  -6.5218525
Policy mu Mean               0.05994308
Policy mu Std                0.9131372
Policy mu Max                2.7842681
Policy mu Min                -2.9418685
Policy log std Mean          -0.52692086
Policy log std Std           0.2895445
Policy log std Max           -0.0469276
Policy log std Min           -2.9212832
Z mean eval                  1.9696567
Z variance eval              0.094586775
total_rewards                [ 9678.98063012 10074.27706026  9600.18801849  9657.9874867
 10003.41115387  9385.772704   10216.79583009  9980.37433668
 10296.7883652   2964.1997693 ]
total_rewards_mean           9185.877535470969
total_rewards_std            2092.192138656919
total_rewards_max            10296.788365195167
total_rewards_min            2964.199769300677
Number of train steps total  1108000
Number of env steps total    3326000
Number of rollouts total     0
Train Time (s)               143.91455775592476
(Previous) Eval Time (s)     28.86973955994472
Sample Time (s)              10.083118852693588
Epoch Time (s)               182.86741616856307
Total Train Time (s)         50915.399770817254
Epoch                        276
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:59:55.413160 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #276 | Epoch Duration: 182.95437717437744
2020-01-13 17:59:55.413474 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #276 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9689575
Z variance train             0.09403082
KL Divergence                51.555546
KL Loss                      5.155555
QF Loss                      97.87294
VF Loss                      38.621872
Policy Loss                  -1316.2242
Q Predictions Mean           1312.1227
Q Predictions Std            1348.3523
Q Predictions Max            4674.549
Q Predictions Min            619.82056
V Predictions Mean           1316.3899
V Predictions Std            1350.271
V Predictions Max            4645.367
V Predictions Min            624.18066
Log Pis Mean                 -0.16868213
Log Pis Std                  3.7286308
Log Pis Max                  12.680599
Log Pis Min                  -8.189733
Policy mu Mean               0.07608736
Policy mu Std                0.8762169
Policy mu Max                2.7623482
Policy mu Min                -2.425021
Policy log std Mean          -0.51837856
Policy log std Std           0.27293754
Policy log std Max           -0.025806308
Policy log std Min           -2.7660716
Z mean eval                  1.9702384
Z variance eval              0.13871631
total_rewards                [ 9859.8319173   9920.34474727  9864.75959283  9839.55111085
 10051.1496722  10146.2815484  10056.76743376 10110.8339645
  9731.18429115 10222.49663017]
total_rewards_mean           9980.320090844465
total_rewards_std            150.8114059228499
total_rewards_max            10222.49663017106
total_rewards_min            9731.184291153724
Number of train steps total  1112000
Number of env steps total    3338000
Number of rollouts total     0
Train Time (s)               140.57919742027298
(Previous) Eval Time (s)     29.26454554311931
Sample Time (s)              9.165806812699884
Epoch Time (s)               179.00954977609217
Total Train Time (s)         51094.49599624472
Epoch                        277
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:02:54.512363 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #277 | Epoch Duration: 179.09865522384644
2020-01-13 18:02:54.512554 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #277 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9690516
Z variance train             0.13887215
KL Divergence                51.58334
KL Loss                      5.1583343
QF Loss                      453.78802
VF Loss                      90.207504
Policy Loss                  -1250.3066
Q Predictions Mean           1246.9148
Q Predictions Std            1261.2974
Q Predictions Max            4575.9688
Q Predictions Min            592.1746
V Predictions Mean           1246.7034
V Predictions Std            1252.8259
V Predictions Max            4546.3936
V Predictions Min            601.0868
Log Pis Mean                 0.10361521
Log Pis Std                  4.3628583
Log Pis Max                  25.903978
Log Pis Min                  -7.441284
Policy mu Mean               0.09861284
Policy mu Std                0.934837
Policy mu Max                4.869031
Policy mu Min                -3.2057664
Policy log std Mean          -0.510213
Policy log std Std           0.28321692
Policy log std Max           -0.07662022
Policy log std Min           -2.6977024
Z mean eval                  1.955355
Z variance eval              0.07649862
total_rewards                [ 9930.13672741  9894.07258248 10069.89724548 10294.46611109
 10428.27697632 10245.05415352 10020.69168435  9904.17460775
 10155.83429907 10123.19127541]
total_rewards_mean           10106.579566288137
total_rewards_std            169.30716108637284
total_rewards_max            10428.276976318897
total_rewards_min            9894.072582483619
Number of train steps total  1116000
Number of env steps total    3350000
Number of rollouts total     0
Train Time (s)               142.6911035371013
(Previous) Eval Time (s)     30.22107105096802
Sample Time (s)              9.622488006949425
Epoch Time (s)               182.53466259501874
Total Train Time (s)         51277.121823896654
Epoch                        278
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:05:57.141536 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #278 | Epoch Duration: 182.62883067131042
2020-01-13 18:05:57.141746 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #278 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9581301
Z variance train             0.07646892
KL Divergence                52.731323
KL Loss                      5.2731323
QF Loss                      105.66526
VF Loss                      50.41845
Policy Loss                  -1227.9369
Q Predictions Mean           1225.1016
Q Predictions Std            1218.2958
Q Predictions Max            4590.8237
Q Predictions Min            608.41565
V Predictions Mean           1225.3549
V Predictions Std            1213.122
V Predictions Max            4582.3125
V Predictions Min            610.67896
Log Pis Mean                 -0.3818073
Log Pis Std                  3.8998587
Log Pis Max                  19.637592
Log Pis Min                  -7.0472746
Policy mu Mean               0.065371685
Policy mu Std                0.8997739
Policy mu Max                3.4349432
Policy mu Min                -3.4820967
Policy log std Mean          -0.50136465
Policy log std Std           0.2826383
Policy log std Max           -0.040725112
Policy log std Min           -2.8909695
Z mean eval                  1.9577332
Z variance eval              0.10067099
total_rewards                [ 9739.52114233  9836.65217625  9772.56434516  9895.48823676
  6146.64038878  9815.82906644  9999.10779297  9865.34291861
 10089.32995191  9804.77167954]
total_rewards_mean           9496.52476987447
total_rewards_std            1121.1081503684347
total_rewards_max            10089.329951913636
total_rewards_min            6146.640388782033
Number of train steps total  1120000
Number of env steps total    3362000
Number of rollouts total     0
Train Time (s)               150.4938516872935
(Previous) Eval Time (s)     30.213505470659584
Sample Time (s)              10.374534611590207
Epoch Time (s)               191.0818917695433
Total Train Time (s)         51468.288729376625
Epoch                        279
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:09:08.312648 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #279 | Epoch Duration: 191.17072582244873
2020-01-13 18:09:08.312907 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #279 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.956654
Z variance train             0.10073602
KL Divergence                50.17802
KL Loss                      5.0178022
QF Loss                      3595.1577
VF Loss                      58.97863
Policy Loss                  -1249.7788
Q Predictions Mean           1247.2661
Q Predictions Std            1267.3635
Q Predictions Max            4683.403
Q Predictions Min            598.8647
V Predictions Mean           1250.0312
V Predictions Std            1264.819
V Predictions Max            4646.4517
V Predictions Min            598.8809
Log Pis Mean                 -0.25236416
Log Pis Std                  3.5309038
Log Pis Max                  13.061182
Log Pis Min                  -7.215362
Policy mu Mean               0.09398105
Policy mu Std                0.8887624
Policy mu Max                3.1745303
Policy mu Min                -3.6764436
Policy log std Mean          -0.52832294
Policy log std Std           0.27808413
Policy log std Max           -0.029432297
Policy log std Min           -2.66214
Z mean eval                  1.9224489
Z variance eval              0.10311969
total_rewards                [10151.54172987  9881.31586813  9576.68759751  9761.81964745
 10012.8329175  10578.67065459  9863.51588877  9777.25123587
 10311.09034479 10430.01871422]
total_rewards_mean           10034.474459870835
total_rewards_std            307.579556805041
total_rewards_max            10578.6706545892
total_rewards_min            9576.687597514734
Number of train steps total  1124000
Number of env steps total    3374000
Number of rollouts total     0
Train Time (s)               149.44666927773505
(Previous) Eval Time (s)     30.334571167826653
Sample Time (s)              10.458015955984592
Epoch Time (s)               190.2392564015463
Total Train Time (s)         51658.60927196406
Epoch                        280
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:12:18.636387 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #280 | Epoch Duration: 190.3233199119568
2020-01-13 18:12:18.636573 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #280 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9229208
Z variance train             0.10319452
KL Divergence                48.34501
KL Loss                      4.834501
QF Loss                      3696.9302
VF Loss                      33.462414
Policy Loss                  -1205.8243
Q Predictions Mean           1204.1079
Q Predictions Std            1246.0272
Q Predictions Max            4703.925
Q Predictions Min            618.90326
V Predictions Mean           1203.0629
V Predictions Std            1243.4651
V Predictions Max            4678.334
V Predictions Min            617.2377
Log Pis Mean                 -0.52930677
Log Pis Std                  3.4805152
Log Pis Max                  16.380985
Log Pis Min                  -7.58899
Policy mu Mean               0.10017086
Policy mu Std                0.8486977
Policy mu Max                2.69269
Policy mu Min                -2.8564394
Policy log std Mean          -0.46155563
Policy log std Std           0.24982648
Policy log std Max           -0.04609807
Policy log std Min           -2.8810148
Z mean eval                  1.9451269
Z variance eval              0.09932926
total_rewards                [10205.7712526   2869.77753693 10645.23785275 10305.41046716
 10212.81417379 10665.23824409 10074.47679636 10375.69669258
 10172.85716751 10252.17107234]
total_rewards_mean           9577.945125609394
total_rewards_std            2243.6290890760547
total_rewards_max            10665.238244091708
total_rewards_min            2869.777536925942
Number of train steps total  1128000
Number of env steps total    3386000
Number of rollouts total     0
Train Time (s)               148.5966244833544
(Previous) Eval Time (s)     31.049800038337708
Sample Time (s)              10.204391235485673
Epoch Time (s)               189.85081575717777
Total Train Time (s)         51848.54359012609
Epoch                        281
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:15:28.575106 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #281 | Epoch Duration: 189.93835020065308
2020-01-13 18:15:28.575461 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.947038
Z variance train             0.09854069
KL Divergence                50.420177
KL Loss                      5.042018
QF Loss                      133.12782
VF Loss                      40.653755
Policy Loss                  -1325.2118
Q Predictions Mean           1324.697
Q Predictions Std            1389.4957
Q Predictions Max            4834.263
Q Predictions Min            628.0632
V Predictions Mean           1326.6199
V Predictions Std            1388.3085
V Predictions Max            4838.1562
V Predictions Min            629.0837
Log Pis Mean                 -0.12414757
Log Pis Std                  3.723407
Log Pis Max                  14.646288
Log Pis Min                  -8.604159
Policy mu Mean               0.051524993
Policy mu Std                0.90616405
Policy mu Max                2.9378588
Policy mu Min                -2.7228541
Policy log std Mean          -0.51039386
Policy log std Std           0.28800818
Policy log std Max           -0.015640378
Policy log std Min           -2.973038
Z mean eval                  1.9514841
Z variance eval              0.08100485
total_rewards                [9790.11812831 9041.39676138 9329.0921757  9362.64236909 9448.22756469
 9675.93847785 9481.46825057 9236.70844468 4156.92899202 9361.95171626]
total_rewards_mean           8888.447288054154
total_rewards_std            1589.7597489538
total_rewards_max            9790.118128305261
total_rewards_min            4156.928992024918
Number of train steps total  1132000
Number of env steps total    3398000
Number of rollouts total     0
Train Time (s)               148.08066859608516
(Previous) Eval Time (s)     29.955417815130204
Sample Time (s)              10.312620921060443
Epoch Time (s)               188.3487073322758
Total Train Time (s)         52037.124595028814
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:18:37.160968 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #282 | Epoch Duration: 188.58522868156433
2020-01-13 18:18:37.161513 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #282 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9522121
Z variance train             0.08138059
KL Divergence                51.813972
KL Loss                      5.1813974
QF Loss                      75.66409
VF Loss                      50.001717
Policy Loss                  -1290.7349
Q Predictions Mean           1288.7858
Q Predictions Std            1343.5465
Q Predictions Max            4679.9556
Q Predictions Min            609.0614
V Predictions Mean           1292.7489
V Predictions Std            1342.2491
V Predictions Max            4667.1455
V Predictions Min            611.95416
Log Pis Mean                 -0.34450373
Log Pis Std                  3.6405709
Log Pis Max                  17.149897
Log Pis Min                  -6.312939
Policy mu Mean               0.09038546
Policy mu Std                0.87021035
Policy mu Max                2.8752694
Policy mu Min                -3.162225
Policy log std Mean          -0.48526514
Policy log std Std           0.26987693
Policy log std Max           -0.03723833
Policy log std Min           -2.8614016
Z mean eval                  1.9531091
Z variance eval              0.09456535
total_rewards                [ 9743.57586005 10279.40685077  9895.85731373  4975.10168316
 10315.50667061 10069.06257286 10174.19113286  9737.50387838
  9753.69911793  9933.32322261]
total_rewards_mean           9487.722830296
total_rewards_std            1518.178583549272
total_rewards_max            10315.50667060938
total_rewards_min            4975.101683156478
Number of train steps total  1136000
Number of env steps total    3410000
Number of rollouts total     0
Train Time (s)               139.88292081700638
(Previous) Eval Time (s)     29.49132832000032
Sample Time (s)              10.35784714622423
Epoch Time (s)               179.73209628323093
Total Train Time (s)         52216.94700888544
Epoch                        283
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:21:36.985168 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #283 | Epoch Duration: 179.8232672214508
2020-01-13 18:21:36.985378 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #283 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9531624
Z variance train             0.09445764
KL Divergence                52.447598
KL Loss                      5.24476
QF Loss                      76.96925
VF Loss                      54.457684
Policy Loss                  -1212.5459
Q Predictions Mean           1210.59
Q Predictions Std            1247.882
Q Predictions Max            4703.4194
Q Predictions Min            611.30444
V Predictions Mean           1214.2194
V Predictions Std            1248.9463
V Predictions Max            4714.4707
V Predictions Min            627.45776
Log Pis Mean                 -0.37405568
Log Pis Std                  4.0219383
Log Pis Max                  20.33955
Log Pis Min                  -7.4401407
Policy mu Mean               0.11957518
Policy mu Std                0.8846836
Policy mu Max                3.796488
Policy mu Min                -3.2490454
Policy log std Mean          -0.49100757
Policy log std Std           0.27597642
Policy log std Max           0.15878624
Policy log std Min           -3.1802988
Z mean eval                  1.973912
Z variance eval              0.12162163
total_rewards                [ 9870.12052368 10488.48915095 10356.49980917 10539.34706258
 10513.85626115 10691.91933269 10505.70621645 10135.10374186
 10125.91817729 10324.9220823 ]
total_rewards_mean           10355.18823581084
total_rewards_std            234.54488561102752
total_rewards_max            10691.91933268657
total_rewards_min            9870.120523676302
Number of train steps total  1140000
Number of env steps total    3422000
Number of rollouts total     0
Train Time (s)               140.4310281299986
(Previous) Eval Time (s)     29.426283770706505
Sample Time (s)              9.808551418129355
Epoch Time (s)               179.66586331883445
Total Train Time (s)         52396.692486663815
Epoch                        284
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:24:36.734101 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #284 | Epoch Duration: 179.74856853485107
2020-01-13 18:24:36.734311 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #284 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9737558
Z variance train             0.12172636
KL Divergence                52.973923
KL Loss                      5.2973924
QF Loss                      150.70349
VF Loss                      37.202545
Policy Loss                  -1257.5337
Q Predictions Mean           1250.9241
Q Predictions Std            1261.597
Q Predictions Max            4652.63
Q Predictions Min            610.4492
V Predictions Mean           1257.5176
V Predictions Std            1262.394
V Predictions Max            4652.6104
V Predictions Min            617.7759
Log Pis Mean                 -0.018087909
Log Pis Std                  3.9123156
Log Pis Max                  17.864151
Log Pis Min                  -6.203595
Policy mu Mean               0.019037032
Policy mu Std                0.9128236
Policy mu Max                3.0272527
Policy mu Min                -2.89434
Policy log std Mean          -0.50977105
Policy log std Std           0.27531403
Policy log std Max           -0.100024566
Policy log std Min           -2.6099458
Z mean eval                  1.9684588
Z variance eval              0.17217259
total_rewards                [ 9558.34859028 10162.80824991 10035.1623202   9889.47593611
  9836.90015342 10172.41185137 10200.79267182 10115.79899846
  9961.29571429  9910.74511321]
total_rewards_mean           9984.373959905655
total_rewards_std            187.64106379251112
total_rewards_max            10200.79267181759
total_rewards_min            9558.348590281148
Number of train steps total  1144000
Number of env steps total    3434000
Number of rollouts total     0
Train Time (s)               144.56260807998478
(Previous) Eval Time (s)     30.334946944843978
Sample Time (s)              9.578427231870592
Epoch Time (s)               184.47598225669935
Total Train Time (s)         52581.24991503684
Epoch                        285
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:27:41.294707 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #285 | Epoch Duration: 184.56022214889526
2020-01-13 18:27:41.294902 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #285 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9675001
Z variance train             0.17127219
KL Divergence                50.146194
KL Loss                      5.0146194
QF Loss                      838.3846
VF Loss                      130.46977
Policy Loss                  -1341.2291
Q Predictions Mean           1340.3855
Q Predictions Std            1348.3723
Q Predictions Max            4661.7295
Q Predictions Min            630.41315
V Predictions Mean           1340.0502
V Predictions Std            1350.5118
V Predictions Max            4639.5654
V Predictions Min            632.1336
Log Pis Mean                 -0.3088416
Log Pis Std                  3.8362927
Log Pis Max                  15.220209
Log Pis Min                  -8.330415
Policy mu Mean               0.12311246
Policy mu Std                0.8753837
Policy mu Max                3.0160923
Policy mu Min                -2.692084
Policy log std Mean          -0.51173085
Policy log std Std           0.2834947
Policy log std Max           0.10197896
Policy log std Min           -2.948583
Z mean eval                  1.9556087
Z variance eval              0.119963065
total_rewards                [ 9983.92472219 10212.97823839 10699.4897572  10486.84478988
 10412.58471696 10321.52254847 10260.82264276 10186.46569032
 10648.63840884 10561.67768693]
total_rewards_mean           10377.49492019323
total_rewards_std            214.36235178482815
total_rewards_max            10699.489757195994
total_rewards_min            9983.92472218677
Number of train steps total  1148000
Number of env steps total    3446000
Number of rollouts total     0
Train Time (s)               150.81254077889025
(Previous) Eval Time (s)     29.842879252973944
Sample Time (s)              9.55728207482025
Epoch Time (s)               190.21270210668445
Total Train Time (s)         52771.54100647336
Epoch                        286
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:30:51.589022 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #286 | Epoch Duration: 190.2939693927765
2020-01-13 18:30:51.589215 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9562476
Z variance train             0.12024616
KL Divergence                51.398624
KL Loss                      5.1398625
QF Loss                      141.17357
VF Loss                      44.327408
Policy Loss                  -1331.9457
Q Predictions Mean           1328.7173
Q Predictions Std            1359.6653
Q Predictions Max            4673.4766
Q Predictions Min            630.3344
V Predictions Mean           1333.6254
V Predictions Std            1357.4828
V Predictions Max            4675.4727
V Predictions Min            638.5519
Log Pis Mean                 -0.41642332
Log Pis Std                  4.2898154
Log Pis Max                  16.754128
Log Pis Min                  -7.2612004
Policy mu Mean               0.022110054
Policy mu Std                0.8941952
Policy mu Max                3.357643
Policy mu Min                -3.5649202
Policy log std Mean          -0.5006892
Policy log std Std           0.27023163
Policy log std Max           0.05830556
Policy log std Min           -3.244636
Z mean eval                  1.9772465
Z variance eval              0.10902394
total_rewards                [ 9862.34747305  9070.40095109  9561.75381787  9819.54914804
  9835.50412804  6371.38057902 10070.92322174  9831.40604874
  9950.91645122  8742.35194489]
total_rewards_mean           9311.653376370046
total_rewards_std            1057.402181607054
total_rewards_max            10070.923221741146
total_rewards_min            6371.38057901992
Number of train steps total  1152000
Number of env steps total    3458000
Number of rollouts total     0
Train Time (s)               149.35033710533753
(Previous) Eval Time (s)     29.804386818315834
Sample Time (s)              10.273902175948024
Epoch Time (s)               189.4286260996014
Total Train Time (s)         52961.053465054836
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:34:01.105126 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #287 | Epoch Duration: 189.5157425403595
2020-01-13 18:34:01.105339 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #287 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9797586
Z variance train             0.10900228
KL Divergence                51.933372
KL Loss                      5.1933374
QF Loss                      176.29428
VF Loss                      190.42964
Policy Loss                  -1295.4718
Q Predictions Mean           1294.7771
Q Predictions Std            1302.2838
Q Predictions Max            4842.292
Q Predictions Min            619.2181
V Predictions Mean           1296.8611
V Predictions Std            1300.1158
V Predictions Max            4816.2407
V Predictions Min            629.39996
Log Pis Mean                 -0.05897017
Log Pis Std                  4.1140895
Log Pis Max                  18.297516
Log Pis Min                  -8.281318
Policy mu Mean               0.09927411
Policy mu Std                0.90458477
Policy mu Max                3.2415903
Policy mu Min                -3.6194367
Policy log std Mean          -0.49933982
Policy log std Std           0.28183478
Policy log std Max           -0.054413438
Policy log std Min           -2.560303
Z mean eval                  1.9575098
Z variance eval              0.14041612
total_rewards                [10127.50133528 10359.40247416 10517.27392437 10221.21838427
 10294.82427215 10583.98861233  9988.43388199 10251.20139967
 10451.36892345 10356.4729444 ]
total_rewards_mean           10315.168615206816
total_rewards_std            170.4789985293035
total_rewards_max            10583.988612328925
total_rewards_min            9988.433881988347
Number of train steps total  1156000
Number of env steps total    3470000
Number of rollouts total     0
Train Time (s)               150.7971429307945
(Previous) Eval Time (s)     29.835321831982583
Sample Time (s)              10.30765766883269
Epoch Time (s)               190.94012243160978
Total Train Time (s)         53152.07763885753
Epoch                        288
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:37:12.133010 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #288 | Epoch Duration: 191.02747511863708
2020-01-13 18:37:12.133351 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #288 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9536011
Z variance train             0.13960487
KL Divergence                50.2552
KL Loss                      5.02552
QF Loss                      216.9591
VF Loss                      133.59366
Policy Loss                  -1237.1798
Q Predictions Mean           1231.9808
Q Predictions Std            1261.8817
Q Predictions Max            4717.971
Q Predictions Min            628.5613
V Predictions Mean           1244.6423
V Predictions Std            1266.0059
V Predictions Max            4712.129
V Predictions Min            635.2358
Log Pis Mean                 -0.27655208
Log Pis Std                  4.3176804
Log Pis Max                  22.84962
Log Pis Min                  -7.129139
Policy mu Mean               0.10227875
Policy mu Std                0.88924754
Policy mu Max                3.6492102
Policy mu Min                -3.1761208
Policy log std Mean          -0.5098632
Policy log std Std           0.27606907
Policy log std Max           -0.022463202
Policy log std Min           -3.155497
Z mean eval                  1.9301016
Z variance eval              0.10758712
total_rewards                [ 9969.68969265 10211.97197626 10348.39411341  9764.44129931
 10119.38831894  9887.94170238  9845.54089455 10165.84993306
 10244.1940802   7327.57338116]
total_rewards_mean           9788.498539190874
total_rewards_std            839.9439114701809
total_rewards_max            10348.394113413417
total_rewards_min            7327.573381157958
Number of train steps total  1160000
Number of env steps total    3482000
Number of rollouts total     0
Train Time (s)               150.4583723503165
(Previous) Eval Time (s)     27.78461948875338
Sample Time (s)              9.95607044827193
Epoch Time (s)               188.1990622873418
Total Train Time (s)         53340.35713916924
Epoch                        289
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:40:20.419425 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #289 | Epoch Duration: 188.2858283519745
2020-01-13 18:40:20.419645 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #289 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.929191
Z variance train             0.10740163
KL Divergence                49.571983
KL Loss                      4.9571986
QF Loss                      237.57953
VF Loss                      121.533485
Policy Loss                  -1401.8667
Q Predictions Mean           1401.0496
Q Predictions Std            1371.5739
Q Predictions Max            4591.034
Q Predictions Min            615.91077
V Predictions Mean           1407.4446
V Predictions Std            1375.5126
V Predictions Max            4624.573
V Predictions Min            622.10297
Log Pis Mean                 -0.10479796
Log Pis Std                  4.0590096
Log Pis Max                  17.234753
Log Pis Min                  -7.226515
Policy mu Mean               0.06397449
Policy mu Std                0.9356817
Policy mu Max                3.3802955
Policy mu Min                -2.804078
Policy log std Mean          -0.4997313
Policy log std Std           0.2964953
Policy log std Max           -0.086560816
Policy log std Min           -2.92096
Z mean eval                  1.9399344
Z variance eval              0.0824938
total_rewards                [ 9744.15241342  9958.51831321  9460.18989864  9739.22023387
 10286.33330093  9925.82163006  9813.35619846  9849.01730428
 10009.44561907 10212.14751847]
total_rewards_mean           9899.820243039783
total_rewards_std            227.25240922079115
total_rewards_max            10286.333300926264
total_rewards_min            9460.189898641733
Number of train steps total  1164000
Number of env steps total    3494000
Number of rollouts total     0
Train Time (s)               140.9165514400229
(Previous) Eval Time (s)     29.29601931711659
Sample Time (s)              9.880446784663945
Epoch Time (s)               180.09301754180342
Total Train Time (s)         53520.53879088629
Epoch                        290
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:43:20.600538 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #290 | Epoch Duration: 180.18072700500488
2020-01-13 18:43:20.600744 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #290 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9386871
Z variance train             0.082980916
KL Divergence                50.036434
KL Loss                      5.0036435
QF Loss                      215.02563
VF Loss                      102.02623
Policy Loss                  -1485.627
Q Predictions Mean           1484.2789
Q Predictions Std            1470.6709
Q Predictions Max            4606.493
Q Predictions Min            629.02844
V Predictions Mean           1483.4144
V Predictions Std            1462.3749
V Predictions Max            4582.4834
V Predictions Min            641.3696
Log Pis Mean                 -0.018933795
Log Pis Std                  4.057364
Log Pis Max                  16.251549
Log Pis Min                  -7.080653
Policy mu Mean               0.053386923
Policy mu Std                0.9355865
Policy mu Max                2.7209778
Policy mu Min                -3.59445
Policy log std Mean          -0.5012133
Policy log std Std           0.28904125
Policy log std Max           -0.0421291
Policy log std Min           -2.7545884
Z mean eval                  1.9422798
Z variance eval              0.089189
total_rewards                [10190.89483654 10108.9759516   9994.05130636 10222.31124848
 10186.42247989 10440.32383241 10033.60547868 10234.19185044
 10325.55471242  9975.39681533]
total_rewards_mean           10171.17285121456
total_rewards_std            139.9919932558
total_rewards_max            10440.32383241232
total_rewards_min            9975.396815326667
Number of train steps total  1168000
Number of env steps total    3506000
Number of rollouts total     0
Train Time (s)               141.15246850205585
(Previous) Eval Time (s)     29.378408974036574
Sample Time (s)              9.254996037576348
Epoch Time (s)               179.78587351366878
Total Train Time (s)         53700.407477473374
Epoch                        291
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:46:20.473021 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #291 | Epoch Duration: 179.87212228775024
2020-01-13 18:46:20.473226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #291 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9424347
Z variance train             0.08901442
KL Divergence                50.39037
KL Loss                      5.039037
QF Loss                      1082.9089
VF Loss                      50.18258
Policy Loss                  -1291.4447
Q Predictions Mean           1289.2263
Q Predictions Std            1297.8075
Q Predictions Max            4684.91
Q Predictions Min            630.3196
V Predictions Mean           1290.6631
V Predictions Std            1294.1475
V Predictions Max            4657.4253
V Predictions Min            628.96466
Log Pis Mean                 -0.30984715
Log Pis Std                  3.7156763
Log Pis Max                  16.014793
Log Pis Min                  -6.7573814
Policy mu Mean               0.04711142
Policy mu Std                0.8923313
Policy mu Max                3.4884148
Policy mu Min                -2.7693856
Policy log std Mean          -0.5044464
Policy log std Std           0.29025075
Policy log std Max           -0.05026616
Policy log std Min           -3.1242442
Z mean eval                  1.9637579
Z variance eval              0.06787795
total_rewards                [10113.72465324 10508.40752021 10417.62293444 10371.7607209
 10393.11505132 10574.64915958  6889.96780251 10123.48675435
 10383.67949668 10135.50782218]
total_rewards_mean           9991.192191540422
total_rewards_std            1045.042264770243
total_rewards_max            10574.649159583349
total_rewards_min            6889.967802513568
Number of train steps total  1172000
Number of env steps total    3518000
Number of rollouts total     0
Train Time (s)               147.18705863086507
(Previous) Eval Time (s)     30.966248774901032
Sample Time (s)              9.852937610819936
Epoch Time (s)               188.00624501658604
Total Train Time (s)         53888.49331177259
Epoch                        292
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:49:28.561951 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #292 | Epoch Duration: 188.08857440948486
2020-01-13 18:49:28.562145 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9642248
Z variance train             0.06796439
KL Divergence                51.945145
KL Loss                      5.1945148
QF Loss                      3910.3438
VF Loss                      93.67927
Policy Loss                  -1222.6212
Q Predictions Mean           1219.1553
Q Predictions Std            1232.156
Q Predictions Max            4692.992
Q Predictions Min            633.52185
V Predictions Mean           1222.9749
V Predictions Std            1227.0336
V Predictions Max            4668.9688
V Predictions Min            641.1623
Log Pis Mean                 -0.12466039
Log Pis Std                  4.168395
Log Pis Max                  22.721437
Log Pis Min                  -7.490596
Policy mu Mean               0.10566942
Policy mu Std                0.9076703
Policy mu Max                3.4204643
Policy mu Min                -3.2247245
Policy log std Mean          -0.4897245
Policy log std Std           0.2818107
Policy log std Max           -0.04763472
Policy log std Min           -2.4615858
Z mean eval                  1.9469669
Z variance eval              0.06307231
total_rewards                [10202.72681837 10253.76736404  9984.22842637 10398.23163027
 10458.42854662 10402.41441762 10607.08308722 10399.38491514
 10191.97024138 10413.60704413]
total_rewards_mean           10331.18424911529
total_rewards_std            166.005657981226
total_rewards_max            10607.083087220104
total_rewards_min            9984.228426370886
Number of train steps total  1176000
Number of env steps total    3530000
Number of rollouts total     0
Train Time (s)               150.09457677882165
(Previous) Eval Time (s)     30.656513712834567
Sample Time (s)              10.64593480527401
Epoch Time (s)               191.39702529693022
Total Train Time (s)         54079.97282342054
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:52:40.045184 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #293 | Epoch Duration: 191.48287224769592
2020-01-13 18:52:40.045440 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.945935
Z variance train             0.06286074
KL Divergence                52.106403
KL Loss                      5.2106404
QF Loss                      180.12575
VF Loss                      50.676506
Policy Loss                  -1372.9354
Q Predictions Mean           1370.8989
Q Predictions Std            1395.4355
Q Predictions Max            4738.387
Q Predictions Min            632.3534
V Predictions Mean           1376.125
V Predictions Std            1394.8561
V Predictions Max            4724.1763
V Predictions Min            640.2638
Log Pis Mean                 -0.5769435
Log Pis Std                  3.7133534
Log Pis Max                  16.855686
Log Pis Min                  -8.894357
Policy mu Mean               0.062011838
Policy mu Std                0.8532371
Policy mu Max                2.7143283
Policy mu Min                -2.8440666
Policy log std Mean          -0.49513555
Policy log std Std           0.2688393
Policy log std Max           -0.057550848
Policy log std Min           -2.4204357
Z mean eval                  1.9573958
Z variance eval              0.08042641
total_rewards                [6771.46327748 8374.91439428 8199.52201071 8346.62408791 8254.12082322
 8341.08266776 8504.14701425 8675.40197812 8329.50884367 8830.10693874]
total_rewards_mean           8262.689203614616
total_rewards_std            529.9683789246002
total_rewards_max            8830.106938735113
total_rewards_min            6771.463277482704
Number of train steps total  1180000
Number of env steps total    3542000
Number of rollouts total     0
Train Time (s)               148.714172644075
(Previous) Eval Time (s)     29.978632121812552
Sample Time (s)              10.161261916160583
Epoch Time (s)               188.85406668204814
Total Train Time (s)         54268.91295510344
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:55:48.988614 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #294 | Epoch Duration: 188.94301414489746
2020-01-13 18:55:48.988812 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #294 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.955837
Z variance train             0.08031238
KL Divergence                52.28892
KL Loss                      5.2288923
QF Loss                      173.27861
VF Loss                      168.37556
Policy Loss                  -1308.5088
Q Predictions Mean           1306.7615
Q Predictions Std            1328.0155
Q Predictions Max            4764.215
Q Predictions Min            628.95905
V Predictions Mean           1304.1846
V Predictions Std            1328.4246
V Predictions Max            4794.7173
V Predictions Min            630.08105
Log Pis Mean                 -0.29397714
Log Pis Std                  3.9756823
Log Pis Max                  13.47694
Log Pis Min                  -6.9090705
Policy mu Mean               0.100150585
Policy mu Std                0.8850753
Policy mu Max                3.2719734
Policy mu Min                -2.7170746
Policy log std Mean          -0.50663584
Policy log std Std           0.2903805
Policy log std Max           -0.10044217
Policy log std Min           -2.9316897
Z mean eval                  1.9440556
Z variance eval              0.06928649
total_rewards                [ 9512.48583246 10345.25937434 10222.14124063  9990.48417702
 10210.67550761 10003.12547181 10164.84438266 10012.33618003
 10164.09376154 10308.59873797]
total_rewards_mean           10093.404466606113
total_rewards_std            226.48337036940478
total_rewards_max            10345.259374335958
total_rewards_min            9512.485832460256
Number of train steps total  1184000
Number of env steps total    3554000
Number of rollouts total     0
Train Time (s)               150.71876771189272
(Previous) Eval Time (s)     29.72871030215174
Sample Time (s)              10.144878820516169
Epoch Time (s)               190.59235683456063
Total Train Time (s)         54459.5971844662
Epoch                        295
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:58:59.676178 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #295 | Epoch Duration: 190.68720817565918
2020-01-13 18:58:59.676386 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #295 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9437729
Z variance train             0.06947403
KL Divergence                52.938328
KL Loss                      5.293833
QF Loss                      136.18668
VF Loss                      121.727325
Policy Loss                  -1377.8053
Q Predictions Mean           1375.0317
Q Predictions Std            1388.016
Q Predictions Max            4794.888
Q Predictions Min            620.45703
V Predictions Mean           1381.9506
V Predictions Std            1383.2767
V Predictions Max            4800.1104
V Predictions Min            636.4428
Log Pis Mean                 -0.19483612
Log Pis Std                  3.8578577
Log Pis Max                  13.748808
Log Pis Min                  -7.342239
Policy mu Mean               0.074231006
Policy mu Std                0.89836025
Policy mu Max                3.5080347
Policy mu Min                -2.99877
Policy log std Mean          -0.5170867
Policy log std Std           0.29586747
Policy log std Max           -0.01740712
Policy log std Min           -2.5973692
Z mean eval                  1.9307001
Z variance eval              0.0529583
total_rewards                [ 9660.47254011 10566.01136342 10556.86713165 10105.81636248
 10310.08833297 10210.37255741 10150.71924895  9998.78197167
 10269.15717298 10328.25821163]
total_rewards_mean           10215.654489324897
total_rewards_std            252.03283055475617
total_rewards_max            10566.01136342247
total_rewards_min            9660.472540108352
Number of train steps total  1188000
Number of env steps total    3566000
Number of rollouts total     0
Train Time (s)               147.9620211161673
(Previous) Eval Time (s)     28.61427809810266
Sample Time (s)              10.404389842879027
Epoch Time (s)               186.980689057149
Total Train Time (s)         54646.667771837674
Epoch                        296
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:02:06.750030 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #296 | Epoch Duration: 187.07349109649658
2020-01-13 19:02:06.750222 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #296 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9303099
Z variance train             0.052928537
KL Divergence                53.847153
KL Loss                      5.3847156
QF Loss                      257.7391
VF Loss                      53.666424
Policy Loss                  -1363.0504
Q Predictions Mean           1360.2922
Q Predictions Std            1350.8163
Q Predictions Max            4711.915
Q Predictions Min            631.0935
V Predictions Mean           1358.8938
V Predictions Std            1348.087
V Predictions Max            4680.5684
V Predictions Min            621.2273
Log Pis Mean                 0.097512126
Log Pis Std                  4.0715675
Log Pis Max                  19.178265
Log Pis Min                  -10.853464
Policy mu Mean               0.024912363
Policy mu Std                0.9184747
Policy mu Max                3.0532033
Policy mu Min                -3.3638985
Policy log std Mean          -0.5132392
Policy log std Std           0.28858247
Policy log std Max           -0.08031939
Policy log std Min           -3.0221412
Z mean eval                  1.9887733
Z variance eval              0.056055672
total_rewards                [ 9826.56348451 10193.64184299 10279.51665106  9831.71719295
 10286.12329702 10152.32003892  9916.41204029 10249.41634068
 10295.52472993 10170.3900656 ]
total_rewards_mean           10120.162568395051
total_rewards_std            178.95995502177982
total_rewards_max            10295.524729934908
total_rewards_min            9826.56348451126
Number of train steps total  1192000
Number of env steps total    3578000
Number of rollouts total     0
Train Time (s)               139.97944544488564
(Previous) Eval Time (s)     29.725073830224574
Sample Time (s)              8.622325734701008
Epoch Time (s)               178.32684500981122
Total Train Time (s)         54825.07342231041
Epoch                        297
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:05:05.158941 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #297 | Epoch Duration: 178.4085705280304
2020-01-13 19:05:05.159146 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #297 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9912965
Z variance train             0.055830084
KL Divergence                53.6027
KL Loss                      5.36027
QF Loss                      3853.9912
VF Loss                      90.0488
Policy Loss                  -1263.0277
Q Predictions Mean           1259.786
Q Predictions Std            1274.0168
Q Predictions Max            4676.141
Q Predictions Min            626.2768
V Predictions Mean           1264.2205
V Predictions Std            1268.6316
V Predictions Max            4659.9976
V Predictions Min            637.39453
Log Pis Mean                 -0.37374246
Log Pis Std                  3.818373
Log Pis Max                  17.01543
Log Pis Min                  -6.718863
Policy mu Mean               0.060287844
Policy mu Std                0.8752534
Policy mu Max                3.4140408
Policy mu Min                -2.843091
Policy log std Mean          -0.48748454
Policy log std Std           0.28816462
Policy log std Max           -0.030941516
Policy log std Min           -2.8040557
Z mean eval                  1.9557884
Z variance eval              0.07344274
total_rewards                [10166.13268635 10232.98195998 10544.38441188  5068.16498431
 10105.69398225 10521.41082314 10173.86806937 10550.4968096
 10399.72031066 10485.34412466]
total_rewards_mean           9824.819816219373
total_rewards_std            1593.9260728934435
total_rewards_max            10550.496809598864
total_rewards_min            5068.164984313059
Number of train steps total  1196000
Number of env steps total    3590000
Number of rollouts total     0
Train Time (s)               140.65826711431146
(Previous) Eval Time (s)     29.999242825899273
Sample Time (s)              9.496701213996857
Epoch Time (s)               180.1542111542076
Total Train Time (s)         55005.311492234934
Epoch                        298
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:08:05.401173 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #298 | Epoch Duration: 180.24183130264282
2020-01-13 19:08:05.401362 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #298 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.954078
Z variance train             0.07323466
KL Divergence                51.95942
KL Loss                      5.195942
QF Loss                      208.97038
VF Loss                      52.094078
Policy Loss                  -1257.6301
Q Predictions Mean           1253.475
Q Predictions Std            1280.4075
Q Predictions Max            4644.363
Q Predictions Min            624.97314
V Predictions Mean           1259.2834
V Predictions Std            1279.0046
V Predictions Max            4615.9336
V Predictions Min            621.3724
Log Pis Mean                 -0.50622916
Log Pis Std                  4.084227
Log Pis Max                  19.16217
Log Pis Min                  -6.8997693
Policy mu Mean               0.067163736
Policy mu Std                0.86292756
Policy mu Max                3.3415623
Policy mu Min                -2.9612377
Policy log std Mean          -0.5042334
Policy log std Std           0.27759862
Policy log std Max           -0.08346489
Policy log std Min           -2.9535835
Z mean eval                  1.9558884
Z variance eval              0.07620375
total_rewards                [10023.81612567 10211.27964169 10732.59975343 10325.56828801
 10246.60555465 10274.78652095 10162.66174302 10369.807589
 10307.14226263  3670.000616  ]
total_rewards_mean           9632.426809503813
total_rewards_std            1994.9829547680577
total_rewards_max            10732.599753425373
total_rewards_min            3670.000615998406
Number of train steps total  1200000
Number of env steps total    3602000
Number of rollouts total     0
Train Time (s)               149.27046355372295
(Previous) Eval Time (s)     29.302363618277013
Sample Time (s)              10.01005424791947
Epoch Time (s)               188.58288141991943
Total Train Time (s)         55193.98955009226
Epoch                        299
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:11:14.084562 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #299 | Epoch Duration: 188.68303036689758
2020-01-13 19:11:14.084966 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #299 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9599125
Z variance train             0.07594506
KL Divergence                53.310165
KL Loss                      5.3310165
QF Loss                      122.97834
VF Loss                      130.05348
Policy Loss                  -1354.5609
Q Predictions Mean           1349.6404
Q Predictions Std            1347.3619
Q Predictions Max            4743.228
Q Predictions Min            639.7146
V Predictions Mean           1348.4478
V Predictions Std            1341.3156
V Predictions Max            4714.9614
V Predictions Min            640.67993
Log Pis Mean                 -0.34085378
Log Pis Std                  3.8455815
Log Pis Max                  15.015237
Log Pis Min                  -6.302355
Policy mu Mean               0.08441735
Policy mu Std                0.8618217
Policy mu Max                3.1804311
Policy mu Min                -3.3074267
Policy log std Mean          -0.4893094
Policy log std Std           0.29004544
Policy log std Max           -0.019863248
Policy log std Min           -2.918848
Z mean eval                  1.9543737
Z variance eval              0.085428774
total_rewards                [ 6245.38407918 10057.1630539   9375.81390729  9463.03861448
  7996.67914399  9090.21678538  9302.20224532  9335.31262016
  9281.44337238  8741.46109134]
total_rewards_mean           8888.871491342736
total_rewards_std            1015.0001620067134
total_rewards_max            10057.163053903214
total_rewards_min            6245.384079182671
Number of train steps total  1204000
Number of env steps total    3614000
Number of rollouts total     0
Train Time (s)               149.08757057972252
(Previous) Eval Time (s)     30.730303701013327
Sample Time (s)              11.019649385940284
Epoch Time (s)               190.83752366667613
Total Train Time (s)         55384.9103459497
Epoch                        300
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:14:25.012692 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #300 | Epoch Duration: 190.92742276191711
2020-01-13 19:14:25.013024 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #300 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9523728
Z variance train             0.08515828
KL Divergence                52.283936
KL Loss                      5.2283936
QF Loss                      290.82376
VF Loss                      124.180046
Policy Loss                  -1249.2784
Q Predictions Mean           1243.7432
Q Predictions Std            1258.7084
Q Predictions Max            4669.5176
Q Predictions Min            622.40497
V Predictions Mean           1256.3235
V Predictions Std            1263.9324
V Predictions Max            4703.6704
V Predictions Min            635.34436
Log Pis Mean                 -0.1512098
Log Pis Std                  4.295174
Log Pis Max                  18.61792
Log Pis Min                  -6.4405003
Policy mu Mean               0.06200118
Policy mu Std                0.8945111
Policy mu Max                3.2191668
Policy mu Min                -3.1604214
Policy log std Mean          -0.515276
Policy log std Std           0.2885694
Policy log std Max           -0.078573704
Policy log std Min           -2.6092095
Z mean eval                  1.9595503
Z variance eval              0.10092448
total_rewards                [10087.79893744 10320.71278381 10120.9959339  10026.84029744
 10128.58573299 10042.71073582 10199.02428226 10334.74220481
 10342.28955548 10437.07579438]
total_rewards_mean           10204.07762583307
total_rewards_std            136.99192792175194
total_rewards_max            10437.075794376633
total_rewards_min            10026.840297444925
Number of train steps total  1208000
Number of env steps total    3626000
Number of rollouts total     0
Train Time (s)               148.38505935529247
(Previous) Eval Time (s)     30.438825536053628
Sample Time (s)              10.428267213981599
Epoch Time (s)               189.2521521053277
Total Train Time (s)         55574.25064661261
Epoch                        301
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:17:34.352504 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #301 | Epoch Duration: 189.3392162322998
2020-01-13 19:17:34.352885 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #301 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9575075
Z variance train             0.10061928
KL Divergence                51.865913
KL Loss                      5.1865916
QF Loss                      87.16284
VF Loss                      36.801228
Policy Loss                  -1314.4034
Q Predictions Mean           1311.9877
Q Predictions Std            1324.2198
Q Predictions Max            4630.9946
Q Predictions Min            626.5095
V Predictions Mean           1316.9401
V Predictions Std            1323.0598
V Predictions Max            4629.0703
V Predictions Min            637.14624
Log Pis Mean                 -0.33180073
Log Pis Std                  3.9039776
Log Pis Max                  22.070513
Log Pis Min                  -7.36497
Policy mu Mean               0.04166256
Policy mu Std                0.88069427
Policy mu Max                3.3954449
Policy mu Min                -3.1733115
Policy log std Mean          -0.51123697
Policy log std Std           0.27719313
Policy log std Max           -0.073865265
Policy log std Min           -2.6727054
Z mean eval                  1.9398838
Z variance eval              0.105964065
total_rewards                [10138.11886402 10295.24330861 10277.12831754 10411.77120615
 10355.42598277 10613.08301834  8613.67110366 10345.61651507
 10392.84182472 10027.6643525 ]
total_rewards_mean           10147.056449337997
total_rewards_std            532.4464373169154
total_rewards_max            10613.083018341873
total_rewards_min            8613.671103664348
Number of train steps total  1212000
Number of env steps total    3638000
Number of rollouts total     0
Train Time (s)               149.794254809618
(Previous) Eval Time (s)     30.245385860092938
Sample Time (s)              10.36507348017767
Epoch Time (s)               190.4047141498886
Total Train Time (s)         55764.74779380346
Epoch                        302
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:20:44.852644 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #302 | Epoch Duration: 190.49949407577515
2020-01-13 19:20:44.852868 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9434769
Z variance train             0.10567784
KL Divergence                50.47972
KL Loss                      5.047972
QF Loss                      190.78218
VF Loss                      108.01901
Policy Loss                  -1312.8297
Q Predictions Mean           1307.7839
Q Predictions Std            1278.3169
Q Predictions Max            4727.3926
Q Predictions Min            634.36066
V Predictions Mean           1307.1602
V Predictions Std            1277.8375
V Predictions Max            4723.2817
V Predictions Min            642.8158
Log Pis Mean                 -0.42892563
Log Pis Std                  4.0221434
Log Pis Max                  19.894756
Log Pis Min                  -7.559224
Policy mu Mean               0.057510585
Policy mu Std                0.86737674
Policy mu Max                4.3202486
Policy mu Min                -3.053354
Policy log std Mean          -0.5038014
Policy log std Std           0.28663045
Policy log std Max           -0.0028639436
Policy log std Min           -2.836368
Z mean eval                  1.9404091
Z variance eval              0.06768825
total_rewards                [10450.6883624  10487.58166428 10264.15468165 10185.89060515
 10472.46187458 10539.56753427 10397.10072147 10278.36953113
 10362.86939287 10580.49225335]
total_rewards_mean           10401.917662115975
total_rewards_std            121.6504004802513
total_rewards_max            10580.49225335087
total_rewards_min            10185.89060515099
Number of train steps total  1216000
Number of env steps total    3650000
Number of rollouts total     0
Train Time (s)               145.42400752194226
(Previous) Eval Time (s)     28.50825553620234
Sample Time (s)              10.415970964822918
Epoch Time (s)               184.34823402296752
Total Train Time (s)         55949.17716170428
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:23:49.285600 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #303 | Epoch Duration: 184.43256521224976
2020-01-13 19:23:49.285816 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #303 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9384632
Z variance train             0.06775007
KL Divergence                51.9924
KL Loss                      5.19924
QF Loss                      128.62108
VF Loss                      74.31191
Policy Loss                  -1173.7355
Q Predictions Mean           1171.5574
Q Predictions Std            1145.9828
Q Predictions Max            4627.3213
Q Predictions Min            644.4648
V Predictions Mean           1173.0851
V Predictions Std            1147.1173
V Predictions Max            4630.5923
V Predictions Min            647.7765
Log Pis Mean                 -0.38336205
Log Pis Std                  3.857341
Log Pis Max                  21.803352
Log Pis Min                  -8.143209
Policy mu Mean               0.049952615
Policy mu Std                0.853176
Policy mu Max                3.3770235
Policy mu Min                -3.2553275
Policy log std Mean          -0.48739544
Policy log std Std           0.26643094
Policy log std Max           -0.04819256
Policy log std Min           -3.0400121
Z mean eval                  1.9324881
Z variance eval              0.08302564
total_rewards                [10213.2042959  10248.34720892 10261.03404325 10112.70680811
 10115.21455665 10204.68002237 10155.5379929  10285.64763085
 10127.3209203   9898.58614106]
total_rewards_mean           10162.227962030744
total_rewards_std            105.94584326451266
total_rewards_max            10285.64763085374
total_rewards_min            9898.586141056614
Number of train steps total  1220000
Number of env steps total    3662000
Number of rollouts total     0
Train Time (s)               140.8113657408394
(Previous) Eval Time (s)     29.331033933907747
Sample Time (s)              9.75471987389028
Epoch Time (s)               179.89711954863742
Total Train Time (s)         56129.15610481845
Epoch                        304
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:26:49.267874 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #304 | Epoch Duration: 179.98190331459045
2020-01-13 19:26:49.268071 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #304 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9294703
Z variance train             0.08289079
KL Divergence                53.152718
KL Loss                      5.315272
QF Loss                      7444.45
VF Loss                      160.0222
Policy Loss                  -1184.551
Q Predictions Mean           1183.5294
Q Predictions Std            1160.415
Q Predictions Max            4691.846
Q Predictions Min            656.06177
V Predictions Mean           1192.3784
V Predictions Std            1162.7822
V Predictions Max            4692.262
V Predictions Min            663.6848
Log Pis Mean                 -0.73219234
Log Pis Std                  3.919111
Log Pis Max                  17.605663
Log Pis Min                  -12.339238
Policy mu Mean               0.03954054
Policy mu Std                0.8314859
Policy mu Max                3.2958665
Policy mu Min                -2.9667025
Policy log std Mean          -0.49031803
Policy log std Std           0.29305094
Policy log std Max           -0.020024002
Policy log std Min           -2.9287724
Z mean eval                  1.9496021
Z variance eval              0.044510566
total_rewards                [10015.98480885 10495.81370841 10140.98177341 10403.90129314
 10137.02504374 10282.53209493 10391.70131154 10253.12366187
 10221.95872426 10140.7134545 ]
total_rewards_mean           10248.373587464894
total_rewards_std            140.48920869017337
total_rewards_max            10495.81370841399
total_rewards_min            10015.98480885122
Number of train steps total  1224000
Number of env steps total    3674000
Number of rollouts total     0
Train Time (s)               142.796630657278
(Previous) Eval Time (s)     30.0409074886702
Sample Time (s)              9.810027651954442
Epoch Time (s)               182.64756579790264
Total Train Time (s)         56311.88376632845
Epoch                        305
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:29:51.998716 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #305 | Epoch Duration: 182.7304971218109
2020-01-13 19:29:51.998926 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #305 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9479434
Z variance train             0.044449616
KL Divergence                55.068058
KL Loss                      5.506806
QF Loss                      283.5732
VF Loss                      93.89816
Policy Loss                  -1412.7504
Q Predictions Mean           1408.8066
Q Predictions Std            1389.4794
Q Predictions Max            4640.8813
Q Predictions Min            637.5845
V Predictions Mean           1412.0256
V Predictions Std            1393.1846
V Predictions Max            4672.9487
V Predictions Min            646.17694
Log Pis Mean                 0.009065978
Log Pis Std                  3.6130774
Log Pis Max                  11.688173
Log Pis Min                  -6.775938
Policy mu Mean               0.10402808
Policy mu Std                0.8796857
Policy mu Max                2.7894628
Policy mu Min                -2.925557
Policy log std Mean          -0.5223893
Policy log std Std           0.3026087
Policy log std Max           -0.009440541
Policy log std Min           -2.771476
Z mean eval                  1.9754251
Z variance eval              0.059473835
total_rewards                [ 9923.79677644  9907.70354722 10335.47254953  9956.91016623
 10212.3856334  10225.48235786 10210.75999574 10120.0273304
 10217.92904537 10222.59919956]
total_rewards_mean           10133.306660174767
total_rewards_std            142.42093756143453
total_rewards_max            10335.472549534745
total_rewards_min            9907.703547222813
Number of train steps total  1228000
Number of env steps total    3686000
Number of rollouts total     0
Train Time (s)               151.91803389694542
(Previous) Eval Time (s)     30.836205870378762
Sample Time (s)              9.648265877738595
Epoch Time (s)               192.40250564506277
Total Train Time (s)         56504.38283601962
Epoch                        306
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:33:04.501638 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #306 | Epoch Duration: 192.5025451183319
2020-01-13 19:33:04.501853 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #306 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.977185
Z variance train             0.059086293
KL Divergence                53.740463
KL Loss                      5.3740463
QF Loss                      3757.4229
VF Loss                      422.024
Policy Loss                  -1475.6919
Q Predictions Mean           1473.1426
Q Predictions Std            1448.627
Q Predictions Max            4713.685
Q Predictions Min            639.32275
V Predictions Mean           1487.1404
V Predictions Std            1457.2327
V Predictions Max            4715.1963
V Predictions Min            660.461
Log Pis Mean                 0.30494615
Log Pis Std                  4.268143
Log Pis Max                  17.41763
Log Pis Min                  -6.687933
Policy mu Mean               0.079090714
Policy mu Std                0.92222065
Policy mu Max                3.0781019
Policy mu Min                -2.926547
Policy log std Mean          -0.534982
Policy log std Std           0.33481738
Policy log std Max           -0.04856792
Policy log std Min           -2.8997014
Z mean eval                  1.970965
Z variance eval              0.08527994
total_rewards                [10090.39491838 10255.51187469 10473.41943221 10319.32363429
 10383.3428625  10404.05117769  3895.17225555 10358.24374619
  9688.97233518 10114.85490741]
total_rewards_mean           9598.328714407833
total_rewards_std            1913.2054834347018
total_rewards_max            10473.419432209259
total_rewards_min            3895.1722555496112
Number of train steps total  1232000
Number of env steps total    3698000
Number of rollouts total     0
Train Time (s)               149.55985631700605
(Previous) Eval Time (s)     30.650550632737577
Sample Time (s)              10.183557145297527
Epoch Time (s)               190.39396409504116
Total Train Time (s)         56694.85675910069
Epoch                        307
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:36:14.978997 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #307 | Epoch Duration: 190.47698402404785
2020-01-13 19:36:14.979263 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #307 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9709127
Z variance train             0.08533685
KL Divergence                52.70983
KL Loss                      5.270983
QF Loss                      104.00148
VF Loss                      285.74173
Policy Loss                  -1422.0264
Q Predictions Mean           1418.0173
Q Predictions Std            1388.2671
Q Predictions Max            4708.3013
Q Predictions Min            657.88544
V Predictions Mean           1418.5936
V Predictions Std            1381.0974
V Predictions Max            4687.8687
V Predictions Min            656.8796
Log Pis Mean                 -0.12865993
Log Pis Std                  3.8750036
Log Pis Max                  14.599465
Log Pis Min                  -7.0456944
Policy mu Mean               0.057936814
Policy mu Std                0.9121146
Policy mu Max                3.872805
Policy mu Min                -2.5360327
Policy log std Mean          -0.50669676
Policy log std Std           0.28315616
Policy log std Max           0.041880786
Policy log std Min           -2.6474397
Z mean eval                  1.9592333
Z variance eval              0.04724838
total_rewards                [10367.55627702 10677.38049646 10294.00461308  3261.16081834
 10586.75403756 10066.35815923  9919.65833876 10360.66293446
 10474.93499714 10332.17956971]
total_rewards_mean           9634.06502417746
total_rewards_std            2134.815516056803
total_rewards_max            10677.38049646223
total_rewards_min            3261.1608183431817
Number of train steps total  1236000
Number of env steps total    3710000
Number of rollouts total     0
Train Time (s)               149.53391915094107
(Previous) Eval Time (s)     31.103215416893363
Sample Time (s)              9.95461133820936
Epoch Time (s)               190.5917459060438
Total Train Time (s)         56885.53171002725
Epoch                        308
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:39:25.659306 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #308 | Epoch Duration: 190.67984414100647
2020-01-13 19:39:25.659663 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #308 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9587781
Z variance train             0.047182903
KL Divergence                53.264263
KL Loss                      5.3264265
QF Loss                      269.21808
VF Loss                      59.97187
Policy Loss                  -1378.6902
Q Predictions Mean           1372.801
Q Predictions Std            1352.7596
Q Predictions Max            4725.59
Q Predictions Min            647.2299
V Predictions Mean           1380.8982
V Predictions Std            1355.6437
V Predictions Max            4718.748
V Predictions Min            648.5161
Log Pis Mean                 -0.32020265
Log Pis Std                  3.8436286
Log Pis Max                  15.860416
Log Pis Min                  -7.7748995
Policy mu Mean               0.078715414
Policy mu Std                0.8858569
Policy mu Max                2.976691
Policy mu Min                -3.6356468
Policy log std Mean          -0.5219094
Policy log std Std           0.32970232
Policy log std Max           -0.06759417
Policy log std Min           -3.061524
Z mean eval                  1.9563354
Z variance eval              0.037381247
total_rewards                [10016.48387624 10844.09138628 10670.36117896 10395.98149379
 10116.21410699 10271.63751579 10578.53219391 10475.46552452
 10594.81009871 10455.55449034]
total_rewards_mean           10441.913186553365
total_rewards_std            239.8881751979012
total_rewards_max            10844.091386275726
total_rewards_min            10016.483876236944
Number of train steps total  1240000
Number of env steps total    3722000
Number of rollouts total     0
Train Time (s)               148.7565554329194
(Previous) Eval Time (s)     30.824625874869525
Sample Time (s)              10.620954416226596
Epoch Time (s)               190.20213572401553
Total Train Time (s)         57076.05011898931
Epoch                        309
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:42:36.182561 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #309 | Epoch Duration: 190.52267003059387
2020-01-13 19:42:36.182924 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #309 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9549885
Z variance train             0.037505344
KL Divergence                55.061615
KL Loss                      5.5061617
QF Loss                      118.89389
VF Loss                      63.187107
Policy Loss                  -1295.8474
Q Predictions Mean           1290.6646
Q Predictions Std            1242.402
Q Predictions Max            4730.719
Q Predictions Min            645.199
V Predictions Mean           1297.6465
V Predictions Std            1240.4532
V Predictions Max            4714.4062
V Predictions Min            666.45667
Log Pis Mean                 -0.16420397
Log Pis Std                  4.2954044
Log Pis Max                  22.12551
Log Pis Min                  -7.99654
Policy mu Mean               0.08036953
Policy mu Std                0.9101517
Policy mu Max                3.519172
Policy mu Min                -3.1893477
Policy log std Mean          -0.5172804
Policy log std Std           0.31792864
Policy log std Max           -0.060070872
Policy log std Min           -2.9260614
Z mean eval                  1.9783485
Z variance eval              0.035636075
total_rewards                [10130.9194549  10290.33655429 10119.26135069 10404.41584245
 10541.86060524 10174.16994208 10318.92988084 10156.38388964
 10249.11551334  8712.73409523]
total_rewards_mean           10109.812712869783
total_rewards_std            482.47846225184736
total_rewards_max            10541.860605243693
total_rewards_min            8712.734095234762
Number of train steps total  1244000
Number of env steps total    3734000
Number of rollouts total     0
Train Time (s)               141.6624245136045
(Previous) Eval Time (s)     28.27976363617927
Sample Time (s)              9.972970927599818
Epoch Time (s)               179.91515907738358
Total Train Time (s)         57256.05355763016
Epoch                        310
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:45:36.189270 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #310 | Epoch Duration: 180.0061378479004
2020-01-13 19:45:36.189490 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9774281
Z variance train             0.03580928
KL Divergence                55.991722
KL Loss                      5.599172
QF Loss                      222.86911
VF Loss                      60.40903
Policy Loss                  -1294.8777
Q Predictions Mean           1292.7578
Q Predictions Std            1272.6072
Q Predictions Max            4727.8076
Q Predictions Min            640.28644
V Predictions Mean           1298.5806
V Predictions Std            1271.329
V Predictions Max            4706.3906
V Predictions Min            642.73334
Log Pis Mean                 -0.08111705
Log Pis Std                  4.2684455
Log Pis Max                  15.733564
Log Pis Min                  -10.929779
Policy mu Mean               0.11698375
Policy mu Std                0.9144408
Policy mu Max                2.8959532
Policy mu Min                -3.2192533
Policy log std Mean          -0.503941
Policy log std Std           0.27643886
Policy log std Max           0.118000746
Policy log std Min           -2.62639
Z mean eval                  1.9857569
Z variance eval              0.07671671
total_rewards                [ 9931.13746327 10183.18665726  8153.83802332  9834.12781296
 10370.67528602 10257.36166508 10328.47617053 10380.57383003
  9993.59910802  5410.72532093]
total_rewards_mean           9484.370133743705
total_rewards_std            1494.4308855733375
total_rewards_max            10380.573830029767
total_rewards_min            5410.725320931527
Number of train steps total  1248000
Number of env steps total    3746000
Number of rollouts total     0
Train Time (s)               140.87211858527735
(Previous) Eval Time (s)     29.73417088482529
Sample Time (s)              9.578353869263083
Epoch Time (s)               180.18464333936572
Total Train Time (s)         57436.32144126203
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:48:36.460946 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #311 | Epoch Duration: 180.27128267288208
2020-01-13 19:48:36.461175 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #311 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9870039
Z variance train             0.077266864
KL Divergence                53.987362
KL Loss                      5.3987365
QF Loss                      149.928
VF Loss                      66.14359
Policy Loss                  -1213.2681
Q Predictions Mean           1207.9465
Q Predictions Std            1235.5339
Q Predictions Max            4775.224
Q Predictions Min            651.5342
V Predictions Mean           1208.8232
V Predictions Std            1234.6891
V Predictions Max            4789.2046
V Predictions Min            647.04456
Log Pis Mean                 -0.65418434
Log Pis Std                  3.671301
Log Pis Max                  16.685957
Log Pis Min                  -6.9912076
Policy mu Mean               0.0680738
Policy mu Std                0.83660704
Policy mu Max                3.1879196
Policy mu Min                -2.7595537
Policy log std Mean          -0.48171762
Policy log std Std           0.28378445
Policy log std Max           -0.021194696
Policy log std Min           -3.1288247
Z mean eval                  1.9593832
Z variance eval              0.06956762
total_rewards                [10078.40834315 10274.63706616 10096.24056033 10447.75206247
 10402.05027244 10485.17284013 10749.13108771  5398.81127541
 10534.92620634 10361.20378284]
total_rewards_mean           9882.833349697738
total_rewards_std            1506.646066369255
total_rewards_max            10749.131087708582
total_rewards_min            5398.811275410003
Number of train steps total  1252000
Number of env steps total    3758000
Number of rollouts total     0
Train Time (s)               143.5942357648164
(Previous) Eval Time (s)     30.380069592036307
Sample Time (s)              9.409155587665737
Epoch Time (s)               183.38346094451845
Total Train Time (s)         57619.804035231005
Epoch                        312
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:51:39.948070 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #312 | Epoch Duration: 183.48670625686646
2020-01-13 19:51:39.948426 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #312 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.960838
Z variance train             0.06925408
KL Divergence                53.12061
KL Loss                      5.312061
QF Loss                      158.85997
VF Loss                      152.27739
Policy Loss                  -1400.8644
Q Predictions Mean           1397.5337
Q Predictions Std            1355.2135
Q Predictions Max            4668.548
Q Predictions Min            662.6412
V Predictions Mean           1395.8589
V Predictions Std            1347.4028
V Predictions Max            4625.8755
V Predictions Min            664.0575
Log Pis Mean                 -0.21889648
Log Pis Std                  4.3490376
Log Pis Max                  15.513492
Log Pis Min                  -6.6627197
Policy mu Mean               0.13059975
Policy mu Std                0.8927519
Policy mu Max                3.7581105
Policy mu Min                -2.8789682
Policy log std Mean          -0.51527184
Policy log std Std           0.304518
Policy log std Max           0.17437911
Policy log std Min           -2.6599593
Z mean eval                  1.9967629
Z variance eval              0.074996136
total_rewards                [ 9542.82305122  9850.75151486 10045.65267541  9979.90020588
  9713.64022604  9822.92155612  9835.11672052  9897.5008468
  9429.26411332  9558.80792615]
total_rewards_mean           9767.637883632302
total_rewards_std            191.1265748489254
total_rewards_max            10045.65267541319
total_rewards_min            9429.264113324496
Number of train steps total  1256000
Number of env steps total    3770000
Number of rollouts total     0
Train Time (s)               149.96420242683962
(Previous) Eval Time (s)     30.397642571944743
Sample Time (s)              10.208140375558287
Epoch Time (s)               190.56998537434265
Total Train Time (s)         57810.45401695091
Epoch                        313
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:54:50.601217 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #313 | Epoch Duration: 190.65252590179443
2020-01-13 19:54:50.601518 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #313 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9952968
Z variance train             0.07490201
KL Divergence                53.584633
KL Loss                      5.3584633
QF Loss                      187.06477
VF Loss                      104.08458
Policy Loss                  -1316.2911
Q Predictions Mean           1313.8169
Q Predictions Std            1290.8635
Q Predictions Max            4729.19
Q Predictions Min            653.4406
V Predictions Mean           1318.2042
V Predictions Std            1291.1233
V Predictions Max            4735.2935
V Predictions Min            658.6067
Log Pis Mean                 -0.37926644
Log Pis Std                  3.9771867
Log Pis Max                  17.376852
Log Pis Min                  -6.242144
Policy mu Mean               0.075750075
Policy mu Std                0.8571372
Policy mu Max                2.8067207
Policy mu Min                -3.134271
Policy log std Mean          -0.5082373
Policy log std Std           0.29189643
Policy log std Max           -0.056926936
Policy log std Min           -2.5087624
Z mean eval                  1.9821568
Z variance eval              0.053319078
total_rewards                [ 9661.88752309  9486.29680289 10476.04066873 10487.16663592
 10384.85046663 10253.2971522  10627.77252575  9956.48541096
 10411.42038959 10650.20319987]
total_rewards_mean           10239.542077562974
total_rewards_std            383.2290610837449
total_rewards_max            10650.20319986945
total_rewards_min            9486.296802889658
Number of train steps total  1260000
Number of env steps total    3782000
Number of rollouts total     0
Train Time (s)               149.69694950897247
(Previous) Eval Time (s)     30.11505017708987
Sample Time (s)              9.525804316159338
Epoch Time (s)               189.33780400222167
Total Train Time (s)         57999.8855330986
Epoch                        314
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:58:00.036252 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #314 | Epoch Duration: 189.4345383644104
2020-01-13 19:58:00.036463 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #314 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9832766
Z variance train             0.053484447
KL Divergence                52.87818
KL Loss                      5.2878184
QF Loss                      248.60564
VF Loss                      93.7928
Policy Loss                  -1579.9935
Q Predictions Mean           1574.3458
Q Predictions Std            1492.2877
Q Predictions Max            4700.6113
Q Predictions Min            666.8038
V Predictions Mean           1577.5167
V Predictions Std            1486.0334
V Predictions Max            4690.3174
V Predictions Min            669.72656
Log Pis Mean                 0.19358143
Log Pis Std                  4.206785
Log Pis Max                  18.436375
Log Pis Min                  -6.5450683
Policy mu Mean               0.038383912
Policy mu Std                0.93598497
Policy mu Max                3.1027548
Policy mu Min                -2.7433574
Policy log std Mean          -0.53558964
Policy log std Std           0.30440688
Policy log std Max           -0.07460636
Policy log std Min           -2.9036393
Z mean eval                  1.9682596
Z variance eval              0.08569966
total_rewards                [10126.39031362 10387.36874152 10389.86110946 10146.22564974
 10350.96450147 10329.75216788 10135.71532243 10222.49631797
 10421.90124482 10477.78240649]
total_rewards_mean           10298.845777538294
total_rewards_std            123.46141630365476
total_rewards_max            10477.782406485196
total_rewards_min            10126.39031361789
Number of train steps total  1264000
Number of env steps total    3794000
Number of rollouts total     0
Train Time (s)               150.54346124827862
(Previous) Eval Time (s)     31.11584965279326
Sample Time (s)              8.84050891501829
Epoch Time (s)               190.49981981609017
Total Train Time (s)         58190.470502276905
Epoch                        315
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:01:10.624889 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #315 | Epoch Duration: 190.58825421333313
2020-01-13 20:01:10.625125 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #315 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9666036
Z variance train             0.08515715
KL Divergence                53.643143
KL Loss                      5.3643146
QF Loss                      143.06412
VF Loss                      82.08212
Policy Loss                  -1426.5852
Q Predictions Mean           1426.4355
Q Predictions Std            1385.5884
Q Predictions Max            4684.652
Q Predictions Min            667.9313
V Predictions Mean           1427.3696
V Predictions Std            1386.5248
V Predictions Max            4700.2124
V Predictions Min            665.4323
Log Pis Mean                 -0.2243861
Log Pis Std                  3.9930017
Log Pis Max                  14.571959
Log Pis Min                  -7.1142344
Policy mu Mean               0.021140648
Policy mu Std                0.9026728
Policy mu Max                2.6314
Policy mu Min                -2.722731
Policy log std Mean          -0.515475
Policy log std Std           0.2984558
Policy log std Max           0.06362891
Policy log std Min           -3.1140792
Z mean eval                  1.9881512
Z variance eval              0.07981373
total_rewards                [10482.67311034 10410.5466975  10486.98088854 10668.4157625
 10779.80706443 10752.38868048 10664.57114168 10478.57280256
 10332.07063971 10473.55134346]
total_rewards_mean           10552.9578131198
total_rewards_std            143.95305044915895
total_rewards_max            10779.807064429406
total_rewards_min            10332.070639705786
Number of train steps total  1268000
Number of env steps total    3806000
Number of rollouts total     0
Train Time (s)               148.4737757500261
(Previous) Eval Time (s)     28.555155214853585
Sample Time (s)              10.191443760879338
Epoch Time (s)               187.22037472575903
Total Train Time (s)         58377.77173374826
Epoch                        316
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:04:17.929726 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #316 | Epoch Duration: 187.30444598197937
2020-01-13 20:04:17.929933 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #316 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.984815
Z variance train             0.08021014
KL Divergence                54.17093
KL Loss                      5.417093
QF Loss                      132.89302
VF Loss                      46.916588
Policy Loss                  -1262.823
Q Predictions Mean           1261.1702
Q Predictions Std            1263.2767
Q Predictions Max            4690.186
Q Predictions Min            657.1419
V Predictions Mean           1259.3708
V Predictions Std            1260.4583
V Predictions Max            4669.715
V Predictions Min            655.1214
Log Pis Mean                 -0.5764278
Log Pis Std                  3.7502775
Log Pis Max                  14.4911375
Log Pis Min                  -9.343962
Policy mu Mean               0.102063484
Policy mu Std                0.8208962
Policy mu Max                2.6683478
Policy mu Min                -2.561302
Policy log std Mean          -0.503161
Policy log std Std           0.28361583
Policy log std Max           0.09807086
Policy log std Min           -2.7021098
Z mean eval                  2.0061412
Z variance eval              0.0464307
total_rewards                [10133.13176805 10468.89623136 10179.59407718 10066.29794596
 10096.4242488    822.24748159 10584.24975045 10023.87800049
 10159.71847762 10434.87192213]
total_rewards_mean           9296.930990363717
total_rewards_std            2830.691740652454
total_rewards_max            10584.249750446335
total_rewards_min            822.2474815925873
Number of train steps total  1272000
Number of env steps total    3818000
Number of rollouts total     0
Train Time (s)               140.51465855212882
(Previous) Eval Time (s)     29.117581793107092
Sample Time (s)              9.7681267648004
Epoch Time (s)               179.4003671100363
Total Train Time (s)         58557.25653704163
Epoch                        317
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:07:17.418879 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #317 | Epoch Duration: 179.48879075050354
2020-01-13 20:07:17.419123 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #317 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0060368
Z variance train             0.04646003
KL Divergence                55.626648
KL Loss                      5.562665
QF Loss                      136.65251
VF Loss                      85.419815
Policy Loss                  -1405.8617
Q Predictions Mean           1403.5183
Q Predictions Std            1364.7181
Q Predictions Max            4829.102
Q Predictions Min            651.38617
V Predictions Mean           1409.8076
V Predictions Std            1368.1522
V Predictions Max            4829.244
V Predictions Min            649.13525
Log Pis Mean                 -0.21385169
Log Pis Std                  4.0039067
Log Pis Max                  17.000526
Log Pis Min                  -5.6778774
Policy mu Mean               0.03581182
Policy mu Std                0.9302414
Policy mu Max                3.0441442
Policy mu Min                -2.8577547
Policy log std Mean          -0.5062521
Policy log std Std           0.2904186
Policy log std Max           -0.013832748
Policy log std Min           -2.6489637
Z mean eval                  1.9812628
Z variance eval              0.06458595
total_rewards                [10483.68301309 10598.19356318 10224.32045355 10639.35577724
 10405.69114398 10421.02755386 10849.51246438 10732.58346398
 10397.70552638 10671.84243118]
total_rewards_mean           10542.391539083881
total_rewards_std            178.5317499967485
total_rewards_max            10849.512464382433
total_rewards_min            10224.32045355333
Number of train steps total  1276000
Number of env steps total    3830000
Number of rollouts total     0
Train Time (s)               141.30808824812993
(Previous) Eval Time (s)     29.78002478275448
Sample Time (s)              9.079459328204393
Epoch Time (s)               180.1675723590888
Total Train Time (s)         58737.50851320615
Epoch                        318
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:10:17.674106 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #318 | Epoch Duration: 180.25474572181702
2020-01-13 20:10:17.674344 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9835043
Z variance train             0.064583056
KL Divergence                54.38166
KL Loss                      5.438166
QF Loss                      538.9656
VF Loss                      49.373352
Policy Loss                  -1390.9683
Q Predictions Mean           1386.9934
Q Predictions Std            1332.7296
Q Predictions Max            4720.3784
Q Predictions Min            663.206
V Predictions Mean           1389.0972
V Predictions Std            1329.6527
V Predictions Max            4706.3086
V Predictions Min            664.4582
Log Pis Mean                 -0.13904487
Log Pis Std                  4.29558
Log Pis Max                  16.380077
Log Pis Min                  -7.2543335
Policy mu Mean               0.04606775
Policy mu Std                0.9101298
Policy mu Max                3.4086235
Policy mu Min                -3.3981504
Policy log std Mean          -0.513902
Policy log std Std           0.30749792
Policy log std Max           -0.06838852
Policy log std Min           -2.7192035
Z mean eval                  2.0138116
Z variance eval              0.05288105
total_rewards                [10482.72980688 10590.883078   10474.07851101  5257.95502053
 10680.59430699 10652.09668325 10371.55341414 10773.94795794
 10546.26497669 10627.56966279]
total_rewards_mean           10045.767341821182
total_rewards_std            1599.7093669498518
total_rewards_max            10773.94795794329
total_rewards_min            5257.9550205267815
Number of train steps total  1280000
Number of env steps total    3842000
Number of rollouts total     0
Train Time (s)               145.1534489998594
(Previous) Eval Time (s)     29.87615850986913
Sample Time (s)              9.685230319853872
Epoch Time (s)               184.7148378295824
Total Train Time (s)         58922.30727498792
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:13:22.476610 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #319 | Epoch Duration: 184.802081823349
2020-01-13 20:13:22.476862 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #319 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.012922
Z variance train             0.052926518
KL Divergence                54.574043
KL Loss                      5.4574046
QF Loss                      181.09561
VF Loss                      61.184258
Policy Loss                  -1290.8903
Q Predictions Mean           1288.3649
Q Predictions Std            1285.6814
Q Predictions Max            4672.6743
Q Predictions Min            654.5749
V Predictions Mean           1290.2119
V Predictions Std            1286.3021
V Predictions Max            4657.336
V Predictions Min            658.6433
Log Pis Mean                 -0.61035395
Log Pis Std                  3.7298033
Log Pis Max                  11.717473
Log Pis Min                  -8.753646
Policy mu Mean               0.029015502
Policy mu Std                0.8633216
Policy mu Max                2.7196133
Policy mu Min                -2.920732
Policy log std Mean          -0.49916127
Policy log std Std           0.27771828
Policy log std Max           -0.022460103
Policy log std Min           -2.678208
Z mean eval                  1.995404
Z variance eval              0.050213385
total_rewards                [10320.50895252 10289.97441309 10676.51703242 10727.09577026
 10598.28571683 10566.59538184 10503.54530097 10246.8798904
 10460.22098285 10032.98091668]
total_rewards_mean           10442.26043578714
total_rewards_std            205.81218199718325
total_rewards_max            10727.095770264214
total_rewards_min            10032.980916677567
Number of train steps total  1284000
Number of env steps total    3854000
Number of rollouts total     0
Train Time (s)               151.28637597803026
(Previous) Eval Time (s)     30.47715553129092
Sample Time (s)              10.331943227443844
Epoch Time (s)               192.09547473676503
Total Train Time (s)         59114.486057955306
Epoch                        320
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:16:34.658972 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #320 | Epoch Duration: 192.18194890022278
2020-01-13 20:16:34.659219 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #320 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9949089
Z variance train             0.05075894
KL Divergence                53.406857
KL Loss                      5.340686
QF Loss                      560.71484
VF Loss                      128.47209
Policy Loss                  -1290.7137
Q Predictions Mean           1287.9333
Q Predictions Std            1292.1871
Q Predictions Max            4722.074
Q Predictions Min            652.9879
V Predictions Mean           1290.2417
V Predictions Std            1284.2969
V Predictions Max            4679.9966
V Predictions Min            654.26154
Log Pis Mean                 -0.19203211
Log Pis Std                  4.1883545
Log Pis Max                  15.828536
Log Pis Min                  -9.941607
Policy mu Mean               0.10124555
Policy mu Std                0.88213104
Policy mu Max                3.2331004
Policy mu Min                -2.7582302
Policy log std Mean          -0.4976598
Policy log std Std           0.29464015
Policy log std Max           -0.016279101
Policy log std Min           -2.8866417
Z mean eval                  1.9844748
Z variance eval              0.06997968
total_rewards                [10532.54623804 10394.2068813  10102.65949861 10281.19090188
 10270.93318358  3419.97070351  6276.93032212 10425.0774567
 10066.74045743 10140.0837881 ]
total_rewards_mean           9191.033943127204
total_rewards_std            2267.610147373863
total_rewards_max            10532.546238043387
total_rewards_min            3419.9707035051956
Number of train steps total  1288000
Number of env steps total    3866000
Number of rollouts total     0
Train Time (s)               150.03697531670332
(Previous) Eval Time (s)     29.03545121802017
Sample Time (s)              10.215210437774658
Epoch Time (s)               189.28763697249815
Total Train Time (s)         59303.85855739238
Epoch                        321
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:19:44.039439 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #321 | Epoch Duration: 189.38002347946167
2020-01-13 20:19:44.039583 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #321 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9838432
Z variance train             0.07003413
KL Divergence                55.10443
KL Loss                      5.510443
QF Loss                      113.84952
VF Loss                      30.291912
Policy Loss                  -1354.4396
Q Predictions Mean           1353.9996
Q Predictions Std            1365.0468
Q Predictions Max            4730.437
Q Predictions Min            658.19244
V Predictions Mean           1352.3079
V Predictions Std            1359.5476
V Predictions Max            4710.7217
V Predictions Min            660.9846
Log Pis Mean                 -0.63407004
Log Pis Std                  3.8341594
Log Pis Max                  14.828291
Log Pis Min                  -8.300663
Policy mu Mean               0.07521692
Policy mu Std                0.87108755
Policy mu Max                3.0330803
Policy mu Min                -2.8433032
Policy log std Mean          -0.5087777
Policy log std Std           0.28645563
Policy log std Max           -0.0598855
Policy log std Min           -2.7535937
Z mean eval                  1.9884516
Z variance eval              0.108888015
total_rewards                [10189.09954009 10559.09956667 10417.97616306 10256.91238171
 10497.27489103 10229.02624642  5513.40705456 10539.82349774
 10445.10796637 10235.50317834]
total_rewards_mean           9888.323048600349
total_rewards_std            1464.1921132769435
total_rewards_max            10559.099566669967
total_rewards_min            5513.407054564172
Number of train steps total  1292000
Number of env steps total    3878000
Number of rollouts total     0
Train Time (s)               150.78981910971925
(Previous) Eval Time (s)     28.73392115533352
Sample Time (s)              9.674581471364945
Epoch Time (s)               189.1983217364177
Total Train Time (s)         59493.15059068054
Epoch                        322
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:22:53.335587 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #322 | Epoch Duration: 189.2958700656891
2020-01-13 20:22:53.335861 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #322 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9846723
Z variance train             0.108183086
KL Divergence                53.714634
KL Loss                      5.3714633
QF Loss                      3927.731
VF Loss                      43.93041
Policy Loss                  -1316.0326
Q Predictions Mean           1312.5745
Q Predictions Std            1311.8865
Q Predictions Max            4714.827
Q Predictions Min            644.6642
V Predictions Mean           1315.3616
V Predictions Std            1311.2404
V Predictions Max            4696.135
V Predictions Min            658.87946
Log Pis Mean                 -0.33034387
Log Pis Std                  3.8189092
Log Pis Max                  15.892519
Log Pis Min                  -7.2543716
Policy mu Mean               0.04722036
Policy mu Std                0.882489
Policy mu Max                3.215269
Policy mu Min                -3.2679603
Policy log std Mean          -0.5007004
Policy log std Std           0.29596752
Policy log std Max           -0.06338331
Policy log std Min           -2.7167063
Z mean eval                  1.9859508
Z variance eval              0.07994621
total_rewards                [10095.50198997 10469.94226894 10656.76534911 10791.14385103
 10671.89410395 10322.61646507 10518.27394682 10700.5200837
 10633.79384157 10666.44569268]
total_rewards_mean           10552.689759282583
total_rewards_std            198.30779607495933
total_rewards_max            10791.143851026767
total_rewards_min            10095.501989968228
Number of train steps total  1296000
Number of env steps total    3890000
Number of rollouts total     0
Train Time (s)               149.94074280373752
(Previous) Eval Time (s)     29.14592734305188
Sample Time (s)              10.0086934347637
Epoch Time (s)               189.0953635815531
Total Train Time (s)         59682.32833822584
Epoch                        323
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:26:02.517166 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #323 | Epoch Duration: 189.181134223938
2020-01-13 20:26:02.517385 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9845921
Z variance train             0.079872236
KL Divergence                53.014576
KL Loss                      5.301458
QF Loss                      140.85495
VF Loss                      39.801994
Policy Loss                  -1203.4431
Q Predictions Mean           1199.1138
Q Predictions Std            1192.064
Q Predictions Max            4679.5703
Q Predictions Min            651.0129
V Predictions Mean           1202.2289
V Predictions Std            1189.4437
V Predictions Max            4665.968
V Predictions Min            656.3907
Log Pis Mean                 -0.51932174
Log Pis Std                  3.5935469
Log Pis Max                  13.178597
Log Pis Min                  -10.543781
Policy mu Mean               0.08439372
Policy mu Std                0.8226594
Policy mu Max                3.0889456
Policy mu Min                -3.3334188
Policy log std Mean          -0.50804013
Policy log std Std           0.29317302
Policy log std Max           0.012125343
Policy log std Min           -3.0761347
Z mean eval                  1.9761549
Z variance eval              0.07781926
total_rewards                [10172.92503563 10648.97018526 10014.20875347 10433.18990302
 10427.62563721 10631.35024166 10823.09358175 10660.66518566
 10329.83130691 10771.95547613]
total_rewards_mean           10491.381530669441
total_rewards_std            249.89897088161402
total_rewards_max            10823.093581748888
total_rewards_min            10014.208753467852
Number of train steps total  1300000
Number of env steps total    3902000
Number of rollouts total     0
Train Time (s)               141.94550031702965
(Previous) Eval Time (s)     28.987215280067176
Sample Time (s)              9.039224557578564
Epoch Time (s)               179.9719401546754
Total Train Time (s)         59862.38405765686
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:29:02.576632 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #324 | Epoch Duration: 180.05907464027405
2020-01-13 20:29:02.576842 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #324 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9748195
Z variance train             0.07790401
KL Divergence                52.893276
KL Loss                      5.2893276
QF Loss                      250.00577
VF Loss                      126.309906
Policy Loss                  -1605.9525
Q Predictions Mean           1603.1871
Q Predictions Std            1505.1981
Q Predictions Max            4819.935
Q Predictions Min            658.5295
V Predictions Mean           1606.7424
V Predictions Std            1502.187
V Predictions Max            4792.7456
V Predictions Min            666.9824
Log Pis Mean                 0.10658426
Log Pis Std                  4.10572
Log Pis Max                  20.238094
Log Pis Min                  -6.2206006
Policy mu Mean               0.012903097
Policy mu Std                0.95541096
Policy mu Max                3.4324489
Policy mu Min                -3.5547748
Policy log std Mean          -0.5390549
Policy log std Std           0.29961318
Policy log std Max           -0.06871715
Policy log std Min           -2.7680311
Z mean eval                  1.956268
Z variance eval              0.1532866
total_rewards                [10037.43364222 10453.58161471 10463.33144735 10576.20483187
 10297.01336441 10437.13149725 10464.94523348 10648.22623038
 10548.68339534 10459.71483886]
total_rewards_mean           10438.626609586176
total_rewards_std            160.61007831816727
total_rewards_max            10648.22623037647
total_rewards_min            10037.433642219201
Number of train steps total  1304000
Number of env steps total    3914000
Number of rollouts total     0
Train Time (s)               140.79092407878488
(Previous) Eval Time (s)     28.716792659834027
Sample Time (s)              9.371912136208266
Epoch Time (s)               178.87962887482718
Total Train Time (s)         60041.3490942833
Epoch                        325
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:32:01.546137 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #325 | Epoch Duration: 178.96911191940308
2020-01-13 20:32:01.546508 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #325 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9607649
Z variance train             0.15300706
KL Divergence                49.365204
KL Loss                      4.9365206
QF Loss                      3953.117
VF Loss                      183.06601
Policy Loss                  -1296.2694
Q Predictions Mean           1297.1531
Q Predictions Std            1308.817
Q Predictions Max            4709.446
Q Predictions Min            656.9997
V Predictions Mean           1291.8618
V Predictions Std            1292.8856
V Predictions Max            4679.5137
V Predictions Min            648.4374
Log Pis Mean                 -0.43936846
Log Pis Std                  3.9277143
Log Pis Max                  13.506024
Log Pis Min                  -8.01189
Policy mu Mean               0.0941404
Policy mu Std                0.87230456
Policy mu Max                3.4029162
Policy mu Min                -2.8290756
Policy log std Mean          -0.4906865
Policy log std Std           0.26854
Policy log std Max           -0.08506793
Policy log std Min           -2.5283513
Z mean eval                  1.9871699
Z variance eval              0.1045535
total_rewards                [10163.83879199 10205.9044143  10406.27591565 10348.18869137
 10087.88057463 10497.17060601 10784.21638412 10559.55760835
 10454.97386811 10730.43541145]
total_rewards_mean           10423.844226598772
total_rewards_std            219.68949675307596
total_rewards_max            10784.216384116506
total_rewards_min            10087.880574633069
Number of train steps total  1308000
Number of env steps total    3926000
Number of rollouts total     0
Train Time (s)               147.03550689900294
(Previous) Eval Time (s)     30.938624194357544
Sample Time (s)              9.661501158494502
Epoch Time (s)               187.635632251855
Total Train Time (s)         60229.25997430598
Epoch                        326
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:35:09.459840 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #326 | Epoch Duration: 187.91307020187378
2020-01-13 20:35:09.460093 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #326 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9861339
Z variance train             0.10466645
KL Divergence                51.13998
KL Loss                      5.113998
QF Loss                      128.45679
VF Loss                      61.023766
Policy Loss                  -1304.8053
Q Predictions Mean           1300.29
Q Predictions Std            1285.667
Q Predictions Max            4601.8027
Q Predictions Min            645.88367
V Predictions Mean           1303.3225
V Predictions Std            1285.2697
V Predictions Max            4610.854
V Predictions Min            636.2886
Log Pis Mean                 -0.48374575
Log Pis Std                  3.7905636
Log Pis Max                  13.037333
Log Pis Min                  -5.7618756
Policy mu Mean               0.10663366
Policy mu Std                0.8555725
Policy mu Max                3.434463
Policy mu Min                -2.7942526
Policy log std Mean          -0.4950408
Policy log std Std           0.29258984
Policy log std Max           0.063813984
Policy log std Min           -2.6767642
Z mean eval                  1.9716097
Z variance eval              0.0883107
total_rewards                [10757.03871301 10512.64335413 10875.449611   10907.41168886
 10412.49723547 10097.33677542 10533.99240947 10646.26831973
 10783.90521203 10936.93606533]
total_rewards_mean           10646.347938444742
total_rewards_std            249.57120511404733
total_rewards_max            10936.936065327953
total_rewards_min            10097.336775423906
Number of train steps total  1312000
Number of env steps total    3938000
Number of rollouts total     0
Train Time (s)               150.51102870190516
(Previous) Eval Time (s)     29.519897148013115
Sample Time (s)              8.651158933527768
Epoch Time (s)               188.68208478344604
Total Train Time (s)         60418.02689579362
Epoch                        327
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:38:18.230161 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #327 | Epoch Duration: 188.76991200447083
2020-01-13 20:38:18.230359 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #327 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9708841
Z variance train             0.08834661
KL Divergence                51.904125
KL Loss                      5.1904125
QF Loss                      108.96845
VF Loss                      61.282356
Policy Loss                  -1355.3802
Q Predictions Mean           1352.8552
Q Predictions Std            1343.9869
Q Predictions Max            4780.9194
Q Predictions Min            661.6252
V Predictions Mean           1351.2297
V Predictions Std            1343.3427
V Predictions Max            4781.5474
V Predictions Min            671.9621
Log Pis Mean                 -0.30521247
Log Pis Std                  3.8564408
Log Pis Max                  17.52475
Log Pis Min                  -7.4159355
Policy mu Mean               0.06075744
Policy mu Std                0.86207443
Policy mu Max                3.1668997
Policy mu Min                -2.4029617
Policy log std Mean          -0.51515836
Policy log std Std           0.29312038
Policy log std Max           -0.08362499
Policy log std Min           -2.8757257
Z mean eval                  1.9810505
Z variance eval              0.076718576
total_rewards                [ 9757.74474496 10305.92568508 10314.79311032 10411.50019176
 10305.66413762 10359.49806082 10488.53295958 10282.26421874
 10266.41545007 10407.83732705]
total_rewards_mean           10290.017588600494
total_rewards_std            189.18738500244683
total_rewards_max            10488.532959581757
total_rewards_min            9757.744744963593
Number of train steps total  1316000
Number of env steps total    3950000
Number of rollouts total     0
Train Time (s)               149.28934235218912
(Previous) Eval Time (s)     30.55805087275803
Sample Time (s)              10.066528928466141
Epoch Time (s)               189.9139221534133
Total Train Time (s)         60608.02203481225
Epoch                        328
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:41:28.229100 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #328 | Epoch Duration: 189.99859237670898
2020-01-13 20:41:28.229310 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #328 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9786959
Z variance train             0.076612785
KL Divergence                52.737537
KL Loss                      5.2737536
QF Loss                      174.10211
VF Loss                      51.09137
Policy Loss                  -1490.2483
Q Predictions Mean           1487.6458
Q Predictions Std            1427.9781
Q Predictions Max            4819.867
Q Predictions Min            666.3027
V Predictions Mean           1490.061
V Predictions Std            1426.5437
V Predictions Max            4826.868
V Predictions Min            670.7615
Log Pis Mean                 -0.14755757
Log Pis Std                  3.835222
Log Pis Max                  13.318689
Log Pis Min                  -6.1344666
Policy mu Mean               0.055118855
Policy mu Std                0.9220761
Policy mu Max                2.6480248
Policy mu Min                -2.5393233
Policy log std Mean          -0.5179787
Policy log std Std           0.2930409
Policy log std Max           0.009802222
Policy log std Min           -2.4962618
Z mean eval                  1.9709879
Z variance eval              0.06690026
total_rewards                [10192.90244181 10767.75927609 10521.80291959 10101.50758276
 10904.4157727  10372.94624096 10143.24318368 10648.37096425
 10395.80068366 10019.54021688]
total_rewards_mean           10406.828928237097
total_rewards_std            284.4556683544572
total_rewards_max            10904.415772704408
total_rewards_min            10019.54021687698
Number of train steps total  1320000
Number of env steps total    3962000
Number of rollouts total     0
Train Time (s)               150.77222452312708
(Previous) Eval Time (s)     29.851565587799996
Sample Time (s)              10.111771497875452
Epoch Time (s)               190.73556160880253
Total Train Time (s)         60798.85823396826
Epoch                        329
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:44:39.069869 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #329 | Epoch Duration: 190.8403708934784
2020-01-13 20:44:39.070274 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #329 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9725721
Z variance train             0.066860676
KL Divergence                53.45334
KL Loss                      5.345334
QF Loss                      120.554016
VF Loss                      57.94384
Policy Loss                  -1485.6445
Q Predictions Mean           1479.8623
Q Predictions Std            1437.9978
Q Predictions Max            4722.4126
Q Predictions Min            668.52637
V Predictions Mean           1482.5215
V Predictions Std            1436.9747
V Predictions Max            4725.322
V Predictions Min            669.7424
Log Pis Mean                 0.00235416
Log Pis Std                  4.4588203
Log Pis Max                  17.059874
Log Pis Min                  -7.9080343
Policy mu Mean               -0.018987648
Policy mu Std                0.94506264
Policy mu Max                3.0985131
Policy mu Min                -3.0982523
Policy log std Mean          -0.5065258
Policy log std Std           0.3030489
Policy log std Max           0.008065581
Policy log std Min           -2.809468
Z mean eval                  2.0035071
Z variance eval              0.056082584
total_rewards                [10257.23495991 10579.24317877 10393.26572068 10621.57064552
 10731.55448373 10715.39218986 10417.23953095 10334.29518173
 10564.6849292  10791.62504248]
total_rewards_mean           10540.610586281271
total_rewards_std            172.7546639059725
total_rewards_max            10791.625042476942
total_rewards_min            10257.234959908195
Number of train steps total  1324000
Number of env steps total    3974000
Number of rollouts total     0
Train Time (s)               149.05086437799037
(Previous) Eval Time (s)     28.27040533022955
Sample Time (s)              10.187115254811943
Epoch Time (s)               187.50838496303186
Total Train Time (s)         60986.45600343868
Epoch                        330
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:47:46.671040 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #330 | Epoch Duration: 187.6004936695099
2020-01-13 20:47:46.671300 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #330 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0032706
Z variance train             0.056126613
KL Divergence                53.702793
KL Loss                      5.3702793
QF Loss                      101.550644
VF Loss                      29.164118
Policy Loss                  -1256.9653
Q Predictions Mean           1252.7958
Q Predictions Std            1228.0851
Q Predictions Max            4838.538
Q Predictions Min            663.729
V Predictions Mean           1257.2769
V Predictions Std            1226.6884
V Predictions Max            4818.625
V Predictions Min            677.5427
Log Pis Mean                 -0.80995095
Log Pis Std                  3.6702979
Log Pis Max                  18.92508
Log Pis Min                  -8.420797
Policy mu Mean               0.019354943
Policy mu Std                0.8278376
Policy mu Max                3.6228316
Policy mu Min                -3.195247
Policy log std Mean          -0.49035645
Policy log std Std           0.2672971
Policy log std Max           0.18614733
Policy log std Min           -3.027039
Z mean eval                  1.9844255
Z variance eval              0.049471878
total_rewards                [ 9921.87856912 10272.72906628  8250.35832896 10578.88720806
 10399.32062829  9926.16571713  9838.62875294 10300.72813457
  9771.71228647 10197.98047699]
total_rewards_mean           9945.838916880068
total_rewards_std            618.0780172616943
total_rewards_max            10578.88720805822
total_rewards_min            8250.358328960774
Number of train steps total  1328000
Number of env steps total    3986000
Number of rollouts total     0
Train Time (s)               141.11791412578896
(Previous) Eval Time (s)     29.06608045240864
Sample Time (s)              10.00084326369688
Epoch Time (s)               180.18483784189448
Total Train Time (s)         61166.71992294863
Epoch                        331
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:50:46.938518 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #331 | Epoch Duration: 180.26704120635986
2020-01-13 20:50:46.938730 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #331 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9833113
Z variance train             0.049360666
KL Divergence                53.92116
KL Loss                      5.392116
QF Loss                      137.16507
VF Loss                      125.48605
Policy Loss                  -1256.8207
Q Predictions Mean           1254.4004
Q Predictions Std            1258.3119
Q Predictions Max            4774.8306
Q Predictions Min            656.3727
V Predictions Mean           1263.1261
V Predictions Std            1257.7345
V Predictions Max            4807.5254
V Predictions Min            655.3337
Log Pis Mean                 -0.1864052
Log Pis Std                  4.1418276
Log Pis Max                  21.022013
Log Pis Min                  -7.647203
Policy mu Mean               0.053783093
Policy mu Std                0.8779518
Policy mu Max                3.2117195
Policy mu Min                -3.2357929
Policy log std Mean          -0.4938629
Policy log std Std           0.25190717
Policy log std Max           -0.034453362
Policy log std Min           -2.7319355
Z mean eval                  2.0316923
Z variance eval              0.0897738
total_rewards                [10116.23589683 10258.27745896 10327.60285331 10736.91631687
 10534.66178401 10231.62152005 10149.09894534 10541.76658366
 10620.23679233 10250.62678336]
total_rewards_mean           10376.704493471334
total_rewards_std            203.53999721571188
total_rewards_max            10736.916316869598
total_rewards_min            10116.235896828575
Number of train steps total  1332000
Number of env steps total    3998000
Number of rollouts total     0
Train Time (s)               141.00342077715322
(Previous) Eval Time (s)     28.873187070246786
Sample Time (s)              9.830109343864024
Epoch Time (s)               179.70671719126403
Total Train Time (s)         61346.50729631027
Epoch                        332
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:53:46.729484 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #332 | Epoch Duration: 179.7906036376953
2020-01-13 20:53:46.729680 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #332 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.029786
Z variance train             0.08955087
KL Divergence                51.705658
KL Loss                      5.170566
QF Loss                      198.55582
VF Loss                      64.58978
Policy Loss                  -1421.3373
Q Predictions Mean           1419.0946
Q Predictions Std            1371.4302
Q Predictions Max            4853.048
Q Predictions Min            673.5073
V Predictions Mean           1418.9972
V Predictions Std            1365.0765
V Predictions Max            4818.954
V Predictions Min            681.02496
Log Pis Mean                 -0.3695819
Log Pis Std                  3.765748
Log Pis Max                  16.111923
Log Pis Min                  -6.343268
Policy mu Mean               0.014995274
Policy mu Std                0.86209667
Policy mu Max                2.9937248
Policy mu Min                -3.2848897
Policy log std Mean          -0.48050928
Policy log std Std           0.29170382
Policy log std Max           -0.048410654
Policy log std Min           -2.9078135
Z mean eval                  1.9771907
Z variance eval              0.09458901
total_rewards                [ 9975.67997402 10281.7022648  10139.11667484 10327.66500248
 10058.93604353 10296.10534489 10202.0147022  10214.99528352
  9952.00510015 10189.30187926]
total_rewards_mean           10163.752226969362
total_rewards_std            124.43511184472442
total_rewards_max            10327.665002479882
total_rewards_min            9952.005100149512
Number of train steps total  1336000
Number of env steps total    4010000
Number of rollouts total     0
Train Time (s)               149.6138024670072
(Previous) Eval Time (s)     30.733065119944513
Sample Time (s)              10.06445683259517
Epoch Time (s)               190.41132441954687
Total Train Time (s)         61536.99907046417
Epoch                        333
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:56:57.225340 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #333 | Epoch Duration: 190.4955132007599
2020-01-13 20:56:57.225539 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #333 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9764189
Z variance train             0.09476351
KL Divergence                51.00971
KL Loss                      5.1009707
QF Loss                      400.8996
VF Loss                      152.91159
Policy Loss                  -1565.4774
Q Predictions Mean           1563.0842
Q Predictions Std            1500.4553
Q Predictions Max            4816.4927
Q Predictions Min            683.4568
V Predictions Mean           1571.9941
V Predictions Std            1501.7195
V Predictions Max            4805.8154
V Predictions Min            687.50635
Log Pis Mean                 0.40349832
Log Pis Std                  4.936291
Log Pis Max                  19.794752
Log Pis Min                  -6.125517
Policy mu Mean               0.009864891
Policy mu Std                0.9915701
Policy mu Max                3.375474
Policy mu Min                -3.5294836
Policy log std Mean          -0.52352643
Policy log std Std           0.33832252
Policy log std Max           -0.02777642
Policy log std Min           -3.1134071
Z mean eval                  1.9737183
Z variance eval              0.101745725
total_rewards                [10199.8017435  10708.86391291 10559.15774891 10509.9598956
 10474.27272946 10356.37960003 10794.65716604 10376.74586363
 10208.19436189 10647.71621288]
total_rewards_mean           10483.574923484706
total_rewards_std            191.0282398133441
total_rewards_max            10794.657166037681
total_rewards_min            10199.801743499323
Number of train steps total  1340000
Number of env steps total    4022000
Number of rollouts total     0
Train Time (s)               149.94453457416967
(Previous) Eval Time (s)     30.55029112799093
Sample Time (s)              10.637366646900773
Epoch Time (s)               191.13219234906137
Total Train Time (s)         61728.22292964533
Epoch                        334
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:00:08.453910 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #334 | Epoch Duration: 191.22818207740784
2020-01-13 21:00:08.454275 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #334 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9721308
Z variance train             0.102008425
KL Divergence                51.925278
KL Loss                      5.192528
QF Loss                      182.69904
VF Loss                      123.432625
Policy Loss                  -1312.886
Q Predictions Mean           1310.32
Q Predictions Std            1321.9391
Q Predictions Max            4637.584
Q Predictions Min            642.95374
V Predictions Mean           1317.439
V Predictions Std            1321.472
V Predictions Max            4656.317
V Predictions Min            652.8961
Log Pis Mean                 -0.93858266
Log Pis Std                  3.877562
Log Pis Max                  14.40332
Log Pis Min                  -6.7873974
Policy mu Mean               0.06588679
Policy mu Std                0.82959133
Policy mu Max                3.4153085
Policy mu Min                -3.0848565
Policy log std Mean          -0.47528553
Policy log std Std           0.2663807
Policy log std Max           0.13468033
Policy log std Min           -2.8583617
Z mean eval                  2.0032618
Z variance eval              0.14521825
total_rewards                [10156.31676884 10045.31475667 10438.77657756 10150.72259625
 10445.18833826 10526.55878672 10651.97220269 10784.45499351
 10051.21917189 10423.13017375]
total_rewards_mean           10367.365436612501
total_rewards_std            242.84020570404064
total_rewards_max            10784.45499351311
total_rewards_min            10045.314756671938
Number of train steps total  1344000
Number of env steps total    4034000
Number of rollouts total     0
Train Time (s)               149.4024872011505
(Previous) Eval Time (s)     30.108413808979094
Sample Time (s)              10.1553679802455
Epoch Time (s)               189.6662689903751
Total Train Time (s)         61917.97476460552
Epoch                        335
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:03:18.209029 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #335 | Epoch Duration: 189.75455617904663
2020-01-13 21:03:18.209261 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #335 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0043037
Z variance train             0.145435
KL Divergence                52.10098
KL Loss                      5.210098
QF Loss                      272.87476
VF Loss                      56.22842
Policy Loss                  -1323.0769
Q Predictions Mean           1322.9829
Q Predictions Std            1323.8248
Q Predictions Max            4772.8857
Q Predictions Min            652.23114
V Predictions Mean           1323.1924
V Predictions Std            1314.5901
V Predictions Max            4727.3115
V Predictions Min            675.0618
Log Pis Mean                 -0.03901741
Log Pis Std                  4.2728524
Log Pis Max                  19.087011
Log Pis Min                  -9.520573
Policy mu Mean               0.04814351
Policy mu Std                0.94077957
Policy mu Max                3.3096476
Policy mu Min                -3.074254
Policy log std Mean          -0.4671375
Policy log std Std           0.28334278
Policy log std Max           0.14264005
Policy log std Min           -2.8896055
Z mean eval                  1.9897099
Z variance eval              0.13125631
total_rewards                [10396.91681966 10370.83618614 10564.95680693 10439.31913542
 10627.08060319 10470.38856052 10491.7234208  10527.57812729
 10437.64757924 10390.23870982]
total_rewards_mean           10471.668594902007
total_rewards_std            78.08651544578167
total_rewards_max            10627.080603191409
total_rewards_min            10370.83618614412
Number of train steps total  1348000
Number of env steps total    4046000
Number of rollouts total     0
Train Time (s)               150.68661769619212
(Previous) Eval Time (s)     29.492754850070924
Sample Time (s)              10.482830653432757
Epoch Time (s)               190.6622031996958
Total Train Time (s)         62108.72397588007
Epoch                        336
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:06:28.964311 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #336 | Epoch Duration: 190.75488805770874
2020-01-13 21:06:28.964581 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #336 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9911108
Z variance train             0.13143837
KL Divergence                53.021706
KL Loss                      5.3021708
QF Loss                      3928.0078
VF Loss                      54.082794
Policy Loss                  -1435.9979
Q Predictions Mean           1435.3881
Q Predictions Std            1392.3792
Q Predictions Max            4798.731
Q Predictions Min            672.98804
V Predictions Mean           1438.1243
V Predictions Std            1391.2386
V Predictions Max            4797.7036
V Predictions Min            672.5139
Log Pis Mean                 -0.3354207
Log Pis Std                  3.5911098
Log Pis Max                  10.91102
Log Pis Min                  -7.832729
Policy mu Mean               0.053078894
Policy mu Std                0.8529348
Policy mu Max                2.93671
Policy mu Min                -2.4312146
Policy log std Mean          -0.52434593
Policy log std Std           0.3210501
Policy log std Max           -0.0872522
Policy log std Min           -2.8084002
Z mean eval                  2.0107484
Z variance eval              0.10181598
total_rewards                [10233.3916403  10513.05329574 10714.65811497 10782.51007462
 10453.01537941 10432.79489266 10528.00107382 10608.33385385
 10494.36304596 10395.72390631]
total_rewards_mean           10515.584527763694
total_rewards_std            149.9537673877425
total_rewards_max            10782.510074619964
total_rewards_min            10233.391640296668
Number of train steps total  1352000
Number of env steps total    4058000
Number of rollouts total     0
Train Time (s)               146.39615086000413
(Previous) Eval Time (s)     28.51686544297263
Sample Time (s)              10.399750422220677
Epoch Time (s)               185.31276672519743
Total Train Time (s)         62294.12967028888
Epoch                        337
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:09:34.371962 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #337 | Epoch Duration: 185.40715098381042
2020-01-13 21:09:34.372205 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #337 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0079398
Z variance train             0.10206815
KL Divergence                52.503784
KL Loss                      5.2503786
QF Loss                      123.898926
VF Loss                      97.3248
Policy Loss                  -1173.8777
Q Predictions Mean           1170.821
Q Predictions Std            1104.959
Q Predictions Max            4672.8013
Q Predictions Min            673.498
V Predictions Mean           1180.4641
V Predictions Std            1106.5513
V Predictions Max            4659.4624
V Predictions Min            681.81274
Log Pis Mean                 -0.6014862
Log Pis Std                  3.5696285
Log Pis Max                  17.301104
Log Pis Min                  -7.32356
Policy mu Mean               0.044044916
Policy mu Std                0.82260364
Policy mu Max                3.4136257
Policy mu Min                -2.9052758
Policy log std Mean          -0.48216105
Policy log std Std           0.29919365
Policy log std Max           0.30577654
Policy log std Min           -2.805446
Z mean eval                  1.9908078
Z variance eval              0.077097565
total_rewards                [10437.54695243 10903.1853385  10760.27757628 10790.01842547
 10790.32295526 10282.22254064 10691.44467161 10554.84049591
 10920.81835704 10868.04781977]
total_rewards_mean           10699.87251329147
total_rewards_std            200.68481710460833
total_rewards_max            10920.818357039005
total_rewards_min            10282.222540638133
Number of train steps total  1356000
Number of env steps total    4070000
Number of rollouts total     0
Train Time (s)               140.9350180691108
(Previous) Eval Time (s)     27.906229908112437
Sample Time (s)              9.496265274006873
Epoch Time (s)               178.33751325123012
Total Train Time (s)         62472.56097821705
Epoch                        338
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:12:32.806495 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #338 | Epoch Duration: 178.43410420417786
2020-01-13 21:12:32.806713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #338 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9909446
Z variance train             0.076813206
KL Divergence                52.782417
KL Loss                      5.2782416
QF Loss                      153.93315
VF Loss                      61.981712
Policy Loss                  -1378.1261
Q Predictions Mean           1373.5073
Q Predictions Std            1354.2126
Q Predictions Max            4784.6963
Q Predictions Min            674.28253
V Predictions Mean           1378.0486
V Predictions Std            1354.1156
V Predictions Max            4772.7344
V Predictions Min            679.28424
Log Pis Mean                 -0.4268121
Log Pis Std                  4.2357388
Log Pis Max                  23.052332
Log Pis Min                  -6.5572367
Policy mu Mean               0.025301069
Policy mu Std                0.87592554
Policy mu Max                3.8488798
Policy mu Min                -3.220888
Policy log std Mean          -0.4961882
Policy log std Std           0.2835759
Policy log std Max           -0.059632838
Policy log std Min           -2.805029
Z mean eval                  1.9856176
Z variance eval              0.12428813
total_rewards                [10238.57693594 10573.27006196 10853.56019778 10992.83840402
 10363.61926489 10593.56719052 10818.54055699 10380.59250651
 10477.35747724 10480.37849839]
total_rewards_mean           10577.230109424014
total_rewards_std            229.33350725108426
total_rewards_max            10992.838404018092
total_rewards_min            10238.576935942467
Number of train steps total  1360000
Number of env steps total    4082000
Number of rollouts total     0
Train Time (s)               141.6681850720197
(Previous) Eval Time (s)     29.343430230859667
Sample Time (s)              9.707026555668563
Epoch Time (s)               180.71864185854793
Total Train Time (s)         62653.396318024956
Epoch                        339
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:15:33.645327 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #339 | Epoch Duration: 180.83844876289368
2020-01-13 21:15:33.645523 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #339 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9852993
Z variance train             0.12442137
KL Divergence                51.83916
KL Loss                      5.183916
QF Loss                      71.24539
VF Loss                      104.52573
Policy Loss                  -1362.6525
Q Predictions Mean           1358.9333
Q Predictions Std            1321.0764
Q Predictions Max            4835.3306
Q Predictions Min            672.16675
V Predictions Mean           1365.5188
V Predictions Std            1326.5126
V Predictions Max            4834.8203
V Predictions Min            662.9735
Log Pis Mean                 -0.3065012
Log Pis Std                  4.164097
Log Pis Max                  21.200333
Log Pis Min                  -9.078645
Policy mu Mean               0.015887298
Policy mu Std                0.8875916
Policy mu Max                3.1052878
Policy mu Min                -3.2989485
Policy log std Mean          -0.49581718
Policy log std Std           0.2624283
Policy log std Max           0.14561355
Policy log std Min           -2.456537
Z mean eval                  2.0096107
Z variance eval              0.082512245
total_rewards                [10167.75646143 10447.09557502 10539.38975718 10846.9508914
 10775.48457344 10704.29574669 10430.1457225  10474.60931911
 10165.9412566  10558.74259152]
total_rewards_mean           10511.041189489904
total_rewards_std            217.2765030181033
total_rewards_max            10846.950891397542
total_rewards_min            10165.941256602364
Number of train steps total  1364000
Number of env steps total    4094000
Number of rollouts total     0
Train Time (s)               149.70033838460222
(Previous) Eval Time (s)     30.474881136789918
Sample Time (s)              10.34987280331552
Epoch Time (s)               190.52509232470766
Total Train Time (s)         62844.006782029755
Epoch                        340
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:18:44.259834 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #340 | Epoch Duration: 190.6141541004181
2020-01-13 21:18:44.260068 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.010182
Z variance train             0.08230197
KL Divergence                53.808666
KL Loss                      5.3808665
QF Loss                      172.3443
VF Loss                      60.033703
Policy Loss                  -1312.9385
Q Predictions Mean           1308.8904
Q Predictions Std            1291.2002
Q Predictions Max            4746.7334
Q Predictions Min            664.95044
V Predictions Mean           1314.4099
V Predictions Std            1292.2665
V Predictions Max            4760.982
V Predictions Min            670.8958
Log Pis Mean                 -0.24395707
Log Pis Std                  4.1369348
Log Pis Max                  17.797195
Log Pis Min                  -8.598968
Policy mu Mean               0.033750225
Policy mu Std                0.90601546
Policy mu Max                2.9976523
Policy mu Min                -2.7852945
Policy log std Mean          -0.50105834
Policy log std Std           0.29685935
Policy log std Max           -0.09969106
Policy log std Min           -2.9377751
Z mean eval                  1.9986817
Z variance eval              0.061191607
total_rewards                [10398.39273617 10749.15494001 10577.13777446 10571.57373857
 10668.61323164 10764.06365405 10773.29350936 10670.89760823
 10848.48821534 10416.89481043]
total_rewards_mean           10643.851021825809
total_rewards_std            143.857558190102
total_rewards_max            10848.488215336516
total_rewards_min            10398.39273617018
Number of train steps total  1368000
Number of env steps total    4106000
Number of rollouts total     0
Train Time (s)               149.6126804011874
(Previous) Eval Time (s)     30.357043681200594
Sample Time (s)              10.314369174651802
Epoch Time (s)               190.28409325703979
Total Train Time (s)         63034.36979457131
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:21:54.627577 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #341 | Epoch Duration: 190.36730289459229
2020-01-13 21:21:54.627938 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9928119
Z variance train             0.06112799
KL Divergence                53.961628
KL Loss                      5.396163
QF Loss                      96.46376
VF Loss                      120.07602
Policy Loss                  -1225.7872
Q Predictions Mean           1225.662
Q Predictions Std            1185.7682
Q Predictions Max            4839.433
Q Predictions Min            669.25854
V Predictions Mean           1233.1252
V Predictions Std            1188.3481
V Predictions Max            4847.6147
V Predictions Min            673.005
Log Pis Mean                 -0.75611925
Log Pis Std                  3.0027037
Log Pis Max                  10.529897
Log Pis Min                  -6.4889703
Policy mu Mean               0.030943274
Policy mu Std                0.79136056
Policy mu Max                2.3283272
Policy mu Min                -2.695687
Policy log std Mean          -0.47207752
Policy log std Std           0.27377185
Policy log std Max           0.0059931874
Policy log std Min           -3.0728762
Z mean eval                  2.000417
Z variance eval              0.115915656
total_rewards                [10610.02345639 10756.07338426 10922.7039564  10896.53693086
 10664.09020318 10801.15518731 10960.30686636 10305.19755641
 10847.69012901 10667.04067694]
total_rewards_mean           10743.081834712277
total_rewards_std            184.10665010609495
total_rewards_max            10960.306866363111
total_rewards_min            10305.197556414023
Number of train steps total  1372000
Number of env steps total    4118000
Number of rollouts total     0
Train Time (s)               149.1622853120789
(Previous) Eval Time (s)     30.96615575859323
Sample Time (s)              10.211637142114341
Epoch Time (s)               190.34007821278647
Total Train Time (s)         63224.79319064785
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:25:05.054399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #342 | Epoch Duration: 190.4262433052063
2020-01-13 21:25:05.054618 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #342 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0002456
Z variance train             0.115729734
KL Divergence                52.06887
KL Loss                      5.2068872
QF Loss                      110.87608
VF Loss                      99.06207
Policy Loss                  -1273.4762
Q Predictions Mean           1269.2855
Q Predictions Std            1250.4515
Q Predictions Max            4724.75
Q Predictions Min            645.8376
V Predictions Mean           1270.032
V Predictions Std            1246.2616
V Predictions Max            4699.505
V Predictions Min            644.4574
Log Pis Mean                 -0.45738798
Log Pis Std                  3.7063227
Log Pis Max                  14.901492
Log Pis Min                  -8.186193
Policy mu Mean               0.054176416
Policy mu Std                0.8661774
Policy mu Max                2.693334
Policy mu Min                -2.87558
Policy log std Mean          -0.5044467
Policy log std Std           0.25662094
Policy log std Max           -0.009828955
Policy log std Min           -2.3602977
Z mean eval                  1.9971097
Z variance eval              0.10290382
total_rewards                [ 9909.88197688 10582.92249096 10564.7579396  10572.34198121
 10676.2145271  10177.75239049 10913.45238805 10344.40202862
 10701.52549557 10720.54021692]
total_rewards_mean           10516.379143540049
total_rewards_std            279.4921841836546
total_rewards_max            10913.452388051963
total_rewards_min            9909.881976879664
Number of train steps total  1376000
Number of env steps total    4130000
Number of rollouts total     0
Train Time (s)               149.6482914169319
(Previous) Eval Time (s)     30.523970800917596
Sample Time (s)              10.666718378663063
Epoch Time (s)               190.83898059651256
Total Train Time (s)         63415.71377485804
Epoch                        343
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:28:15.978172 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #343 | Epoch Duration: 190.92337560653687
2020-01-13 21:28:15.978379 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #343 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9954135
Z variance train             0.10275446
KL Divergence                53.30563
KL Loss                      5.330563
QF Loss                      125.86748
VF Loss                      62.206734
Policy Loss                  -1325.341
Q Predictions Mean           1321.104
Q Predictions Std            1285.2078
Q Predictions Max            4786.459
Q Predictions Min            676.7396
V Predictions Mean           1323.1418
V Predictions Std            1280.5492
V Predictions Max            4751.151
V Predictions Min            675.415
Log Pis Mean                 -0.47036982
Log Pis Std                  3.7501936
Log Pis Max                  14.49879
Log Pis Min                  -6.42801
Policy mu Mean               0.017983444
Policy mu Std                0.8823685
Policy mu Max                2.9714768
Policy mu Min                -3.3426027
Policy log std Mean          -0.48732436
Policy log std Std           0.28507566
Policy log std Max           0.120657384
Policy log std Min           -2.831013
Z mean eval                  1.9759457
Z variance eval              0.09855422
total_rewards                [ 9888.93185173 10712.3099351  10555.49380278 10097.30807785
 10563.89430397 10595.16266823 10981.7042739  10741.43674429
 10673.74639294 10267.39644304]
total_rewards_mean           10507.738449384022
total_rewards_std            311.58989857806483
total_rewards_max            10981.704273897778
total_rewards_min            9888.931851727688
Number of train steps total  1380000
Number of env steps total    4142000
Number of rollouts total     0
Train Time (s)               142.98796129785478
(Previous) Eval Time (s)     29.41604722896591
Sample Time (s)              10.153122921008617
Epoch Time (s)               182.5571314478293
Total Train Time (s)         63598.363981449045
Epoch                        344
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:31:18.632167 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #344 | Epoch Duration: 182.653635263443
2020-01-13 21:31:18.632372 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #344 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9716715
Z variance train             0.09887113
KL Divergence                52.997604
KL Loss                      5.2997603
QF Loss                      262.9268
VF Loss                      40.500397
Policy Loss                  -1132.8912
Q Predictions Mean           1130.8995
Q Predictions Std            1092.0576
Q Predictions Max            4732.147
Q Predictions Min            657.3497
V Predictions Mean           1136.4836
V Predictions Std            1092.0868
V Predictions Max            4739.351
V Predictions Min            665.93463
Log Pis Mean                 -1.0874019
Log Pis Std                  3.3281648
Log Pis Max                  12.284637
Log Pis Min                  -7.3332133
Policy mu Mean               0.074538186
Policy mu Std                0.77962404
Policy mu Max                2.7520623
Policy mu Min                -2.417348
Policy log std Mean          -0.46688446
Policy log std Std           0.2592096
Policy log std Max           -0.045663893
Policy log std Min           -2.8894653
Z mean eval                  1.9713547
Z variance eval              0.08031214
total_rewards                [ 9957.27561057 10296.01715941 10266.56332044 10662.42185968
 10091.26477612 10221.53649346 10297.64394108 10459.85022607
 10282.55006313 10300.31868371]
total_rewards_mean           10283.544213367215
total_rewards_std            179.67323676631204
total_rewards_max            10662.421859679538
total_rewards_min            9957.27561056599
Number of train steps total  1384000
Number of env steps total    4154000
Number of rollouts total     0
Train Time (s)               141.14114463701844
(Previous) Eval Time (s)     28.348848085850477
Sample Time (s)              9.808257071767002
Epoch Time (s)               179.29824979463592
Total Train Time (s)         63777.74420958711
Epoch                        345
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:34:18.016808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #345 | Epoch Duration: 179.38427305221558
2020-01-13 21:34:18.017083 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9716498
Z variance train             0.080336094
KL Divergence                52.02044
KL Loss                      5.202044
QF Loss                      8702.421
VF Loss                      54.953064
Policy Loss                  -1381.2764
Q Predictions Mean           1381.2437
Q Predictions Std            1322.9889
Q Predictions Max            4812.035
Q Predictions Min            681.7002
V Predictions Mean           1379.6101
V Predictions Std            1316.8057
V Predictions Max            4788.9653
V Predictions Min            688.0174
Log Pis Mean                 -0.064727776
Log Pis Std                  4.5148306
Log Pis Max                  25.895103
Log Pis Min                  -7.444206
Policy mu Mean               -0.024759417
Policy mu Std                0.9208811
Policy mu Max                3.7046149
Policy mu Min                -3.7646697
Policy log std Mean          -0.493034
Policy log std Std           0.29074448
Policy log std Max           0.11545199
Policy log std Min           -2.994935
Z mean eval                  2.0258007
Z variance eval              0.17276561
total_rewards                [10034.23988474 10839.78446909 10598.37715898 11080.66188107
 10631.59690255 10771.37018014 10515.793976   10645.38607866
 10358.52146196 10288.80481283]
total_rewards_mean           10576.453680600953
total_rewards_std            282.4440241797132
total_rewards_max            11080.661881067354
total_rewards_min            10034.239884738845
Number of train steps total  1388000
Number of env steps total    4166000
Number of rollouts total     0
Train Time (s)               144.62128286017105
(Previous) Eval Time (s)     29.478697899729013
Sample Time (s)              9.801515975035727
Epoch Time (s)               183.9014967349358
Total Train Time (s)         63961.73709927546
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:37:22.015319 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #346 | Epoch Duration: 183.998046875
2020-01-13 21:37:22.015613 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #346 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.026013
Z variance train             0.17271939
KL Divergence                50.62664
KL Loss                      5.062664
QF Loss                      271.23947
VF Loss                      56.239944
Policy Loss                  -1322.9486
Q Predictions Mean           1322.0043
Q Predictions Std            1332.3802
Q Predictions Max            4942.9165
Q Predictions Min            706.61365
V Predictions Mean           1320.4827
V Predictions Std            1326.2058
V Predictions Max            4928.0767
V Predictions Min            706.63824
Log Pis Mean                 -0.6601542
Log Pis Std                  3.9742792
Log Pis Max                  25.193268
Log Pis Min                  -7.056314
Policy mu Mean               0.07380188
Policy mu Std                0.84540236
Policy mu Max                3.8056552
Policy mu Min                -2.8954372
Policy log std Mean          -0.4659796
Policy log std Std           0.27205822
Policy log std Max           -0.032022536
Policy log std Min           -2.7763424
Z mean eval                  2.0244946
Z variance eval              0.102808475
total_rewards                [10394.15112871 10545.70067921 10490.22769332 10004.78779677
 10614.14170491 10690.55720613 10454.610348   10247.26111889
 10354.53493721 10448.90227159]
total_rewards_mean           10424.48748847379
total_rewards_std            184.5671607711461
total_rewards_max            10690.557206129573
total_rewards_min            10004.787796772818
Number of train steps total  1392000
Number of env steps total    4178000
Number of rollouts total     0
Train Time (s)               151.19928327202797
(Previous) Eval Time (s)     30.239139419049025
Sample Time (s)              10.366878409404308
Epoch Time (s)               191.8053011004813
Total Train Time (s)         64153.659835281316
Epoch                        347
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:40:33.943689 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #347 | Epoch Duration: 191.9278380870819
2020-01-13 21:40:33.944023 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #347 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0229197
Z variance train             0.10283576
KL Divergence                52.26537
KL Loss                      5.226537
QF Loss                      189.05264
VF Loss                      54.220406
Policy Loss                  -1525.1824
Q Predictions Mean           1522.1882
Q Predictions Std            1464.9285
Q Predictions Max            4847.2563
Q Predictions Min            685.73804
V Predictions Mean           1524.5046
V Predictions Std            1459.5198
V Predictions Max            4829.598
V Predictions Min            685.0439
Log Pis Mean                 0.17888658
Log Pis Std                  4.4349275
Log Pis Max                  14.2602
Log Pis Min                  -6.250697
Policy mu Mean               0.075178176
Policy mu Std                0.93749326
Policy mu Max                3.896623
Policy mu Min                -2.712526
Policy log std Mean          -0.49745747
Policy log std Std           0.3078536
Policy log std Max           0.06701383
Policy log std Min           -2.9833086
Z mean eval                  1.9873798
Z variance eval              0.1079316
total_rewards                [10457.57954362 10346.0222588  10542.05655721 10307.19411899
 10380.41789045 10809.01363973 10383.82785111 10993.36966199
 10394.05145069 10893.89406501]
total_rewards_mean           10550.742703760612
total_rewards_std            239.11917810578862
total_rewards_max            10993.36966199455
total_rewards_min            10307.194118991765
Number of train steps total  1396000
Number of env steps total    4190000
Number of rollouts total     0
Train Time (s)               150.16924670897424
(Previous) Eval Time (s)     29.99330830667168
Sample Time (s)              9.207860049791634
Epoch Time (s)               189.37041506543756
Total Train Time (s)         64343.11055297358
Epoch                        348
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:43:43.395819 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #348 | Epoch Duration: 189.45161843299866
2020-01-13 21:43:43.395956 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #348 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9835182
Z variance train             0.107888535
KL Divergence                52.56874
KL Loss                      5.256874
QF Loss                      213.86685
VF Loss                      227.82465
Policy Loss                  -1434.6312
Q Predictions Mean           1433.7356
Q Predictions Std            1398.2327
Q Predictions Max            4767.111
Q Predictions Min            682.9113
V Predictions Mean           1447.8799
V Predictions Std            1399.6833
V Predictions Max            4787.3115
V Predictions Min            700.1727
Log Pis Mean                 -0.50393826
Log Pis Std                  3.9982517
Log Pis Max                  21.491554
Log Pis Min                  -6.80113
Policy mu Mean               0.045931324
Policy mu Std                0.8852189
Policy mu Max                2.5821822
Policy mu Min                -3.1986988
Policy log std Mean          -0.49121734
Policy log std Std           0.31469882
Policy log std Max           0.07517791
Policy log std Min           -2.7521384
Z mean eval                  2.0074062
Z variance eval              0.11164594
total_rewards                [10723.45790522 10926.44954221 10555.34395097 10478.33828838
 10601.82432367  5171.01605275 10424.65295953 10796.18274179
 10592.92159371 10368.01641594]
total_rewards_mean           10063.82037741683
total_rewards_std            1638.9231764673993
total_rewards_max            10926.449542206676
total_rewards_min            5171.016052745156
Number of train steps total  1400000
Number of env steps total    4202000
Number of rollouts total     0
Train Time (s)               149.6371402181685
(Previous) Eval Time (s)     31.396435011178255
Sample Time (s)              9.338573121465743
Epoch Time (s)               190.3721483508125
Total Train Time (s)         64533.56824850943
Epoch                        349
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:46:53.857842 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #349 | Epoch Duration: 190.46175980567932
2020-01-13 21:46:53.858045 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #349 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0037801
Z variance train             0.11227556
KL Divergence                52.575146
KL Loss                      5.2575145
QF Loss                      4273.756
VF Loss                      23.559372
Policy Loss                  -1239.9281
Q Predictions Mean           1239.6221
Q Predictions Std            1244.7435
Q Predictions Max            4821.956
Q Predictions Min            696.1725
V Predictions Mean           1238.8701
V Predictions Std            1243.0544
V Predictions Max            4810.403
V Predictions Min            696.5613
Log Pis Mean                 -0.60885096
Log Pis Std                  3.5926754
Log Pis Max                  14.326355
Log Pis Min                  -6.9333315
Policy mu Mean               0.11483232
Policy mu Std                0.84114283
Policy mu Max                2.9085157
Policy mu Min                -2.44947
Policy log std Mean          -0.48048759
Policy log std Std           0.25799122
Policy log std Max           0.1109457
Policy log std Min           -2.7745833
Z mean eval                  1.982885
Z variance eval              0.07445922
total_rewards                [10579.94068742 11023.16214503 10494.16701216 10882.57312356
 10596.93039896 10835.62114242 10868.84590145 10826.06356369
 10843.98080781 10782.13048126]
total_rewards_mean           10773.341526375154
total_rewards_std            155.45149287247327
total_rewards_max            11023.162145032857
total_rewards_min            10494.16701215802
Number of train steps total  1404000
Number of env steps total    4214000
Number of rollouts total     0
Train Time (s)               149.1033154898323
(Previous) Eval Time (s)     30.455348547082394
Sample Time (s)              10.254772880114615
Epoch Time (s)               189.81343691702932
Total Train Time (s)         64723.46356424969
Epoch                        350
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:50:03.756747 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #350 | Epoch Duration: 189.8985414505005
2020-01-13 21:50:03.756992 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #350 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9816002
Z variance train             0.07449238
KL Divergence                52.324326
KL Loss                      5.232433
QF Loss                      4233.1914
VF Loss                      153.58327
Policy Loss                  -1370.2943
Q Predictions Mean           1368.009
Q Predictions Std            1314.7048
Q Predictions Max            4804.5986
Q Predictions Min            701.487
V Predictions Mean           1378.4634
V Predictions Std            1318.1675
V Predictions Max            4806.3457
V Predictions Min            710.2733
Log Pis Mean                 -0.13213938
Log Pis Std                  4.121512
Log Pis Max                  14.630278
Log Pis Min                  -6.734261
Policy mu Mean               0.10198346
Policy mu Std                0.90710896
Policy mu Max                3.6260889
Policy mu Min                -2.9057875
Policy log std Mean          -0.48445788
Policy log std Std           0.27395827
Policy log std Max           -0.06621188
Policy log std Min           -2.5253954
Z mean eval                  1.9952539
Z variance eval              0.094497696
total_rewards                [10547.40317515 10857.0995248  10625.23682095 10324.75125321
 10689.82361716 10906.26503326 10457.79184691 10533.91921699
 10342.32084162 10700.58811844]
total_rewards_mean           10598.519944846841
total_rewards_std            186.60556140252098
total_rewards_max            10906.265033255477
total_rewards_min            10324.751253207574
Number of train steps total  1408000
Number of env steps total    4226000
Number of rollouts total     0
Train Time (s)               141.23000111198053
(Previous) Eval Time (s)     29.547384027857333
Sample Time (s)              10.477182086091489
Epoch Time (s)               181.25456722592935
Total Train Time (s)         64904.79734899104
Epoch                        351
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:53:05.094200 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #351 | Epoch Duration: 181.33704662322998
2020-01-13 21:53:05.094395 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #351 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.997516
Z variance train             0.09459143
KL Divergence                53.207733
KL Loss                      5.3207736
QF Loss                      142.6088
VF Loss                      95.31777
Policy Loss                  -1561.678
Q Predictions Mean           1556.6361
Q Predictions Std            1490.0516
Q Predictions Max            4812.2295
Q Predictions Min            691.96063
V Predictions Mean           1560.8882
V Predictions Std            1488.2538
V Predictions Max            4780.8467
V Predictions Min            696.175
Log Pis Mean                 0.45922616
Log Pis Std                  4.6256137
Log Pis Max                  21.658382
Log Pis Min                  -7.46311
Policy mu Mean               0.029350542
Policy mu Std                0.95991755
Policy mu Max                3.1164591
Policy mu Min                -2.9140296
Policy log std Mean          -0.50943977
Policy log std Std           0.32721695
Policy log std Max           -0.031148314
Policy log std Min           -3.1102505
Z mean eval                  1.9859841
Z variance eval              0.09189136
total_rewards                [10119.07522485  9834.46974046 10656.99791387 10425.45406169
 10627.2013847  10005.47653824 10376.23916916 10224.30648179
 10241.61789783 10505.34856854]
total_rewards_mean           10301.618698113214
total_rewards_std            253.68000844076306
total_rewards_max            10656.99791387363
total_rewards_min            9834.469740460707
Number of train steps total  1412000
Number of env steps total    4238000
Number of rollouts total     0
Train Time (s)               140.99696816504002
(Previous) Eval Time (s)     29.708532768767327
Sample Time (s)              9.818175571970642
Epoch Time (s)               180.52367650577798
Total Train Time (s)         65085.4104187917
Epoch                        352
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:56:05.715365 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #352 | Epoch Duration: 180.62080907821655
2020-01-13 21:56:05.715617 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #352 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9857671
Z variance train             0.09167483
KL Divergence                52.41665
KL Loss                      5.241665
QF Loss                      171.33124
VF Loss                      53.075047
Policy Loss                  -1415.6906
Q Predictions Mean           1413.3335
Q Predictions Std            1353.2091
Q Predictions Max            4894.7275
Q Predictions Min            693.5689
V Predictions Mean           1417.0896
V Predictions Std            1353.2876
V Predictions Max            4898.601
V Predictions Min            690.7427
Log Pis Mean                 -0.07052719
Log Pis Std                  3.9988604
Log Pis Max                  23.867403
Log Pis Min                  -6.092908
Policy mu Mean               0.04874595
Policy mu Std                0.90994954
Policy mu Max                3.5522294
Policy mu Min                -2.8745103
Policy log std Mean          -0.48407212
Policy log std Std           0.27124536
Policy log std Max           0.01814276
Policy log std Min           -2.9304204
Z mean eval                  1.9824976
Z variance eval              0.085683785
total_rewards                [10392.73585082  9631.70578501 10957.12038378 10323.26635436
 10611.24338415 10583.87380728 10561.08214777 10950.12497762
 10826.07863577 10417.67494823]
total_rewards_mean           10525.490627479143
total_rewards_std            365.78609439679553
total_rewards_max            10957.120383777366
total_rewards_min            9631.705785006121
Number of train steps total  1416000
Number of env steps total    4250000
Number of rollouts total     0
Train Time (s)               145.36386009817943
(Previous) Eval Time (s)     29.50706442911178
Sample Time (s)              9.789417202584445
Epoch Time (s)               184.66034172987565
Total Train Time (s)         65270.16155195562
Epoch                        353
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:59:10.466307 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #353 | Epoch Duration: 184.7505009174347
2020-01-13 21:59:10.466546 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #353 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9866054
Z variance train             0.08593187
KL Divergence                53.925556
KL Loss                      5.3925557
QF Loss                      97.88965
VF Loss                      71.888985
Policy Loss                  -1470.2101
Q Predictions Mean           1466.919
Q Predictions Std            1429.6058
Q Predictions Max            4842.487
Q Predictions Min            672.78815
V Predictions Mean           1468.0839
V Predictions Std            1421.8406
V Predictions Max            4824.8145
V Predictions Min            684.5094
Log Pis Mean                 0.098899156
Log Pis Std                  4.6332045
Log Pis Max                  22.77581
Log Pis Min                  -6.856198
Policy mu Mean               0.10273874
Policy mu Std                0.9438638
Policy mu Max                3.254593
Policy mu Min                -3.0401165
Policy log std Mean          -0.51756316
Policy log std Std           0.30629626
Policy log std Max           -0.04017639
Policy log std Min           -3.1851683
Z mean eval                  1.9890184
Z variance eval              0.071091205
total_rewards                [10209.00786079 10385.42201706 10490.21921145 10313.02991158
 10585.21963683 10403.57047361 10488.84399548 10239.94795554
 10434.04535593 10149.21171701]
total_rewards_mean           10369.851813529307
total_rewards_std            132.35841851208517
total_rewards_max            10585.219636833486
total_rewards_min            10149.211717007984
Number of train steps total  1420000
Number of env steps total    4262000
Number of rollouts total     0
Train Time (s)               151.18227776465937
(Previous) Eval Time (s)     29.87619478488341
Sample Time (s)              10.336764588486403
Epoch Time (s)               191.3952371380292
Total Train Time (s)         65461.65410681907
Epoch                        354
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:02:21.964126 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #354 | Epoch Duration: 191.49740505218506
2020-01-13 22:02:21.964449 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #354 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9894476
Z variance train             0.07142007
KL Divergence                52.3864
KL Loss                      5.23864
QF Loss                      207.33597
VF Loss                      104.031334
Policy Loss                  -1265.8188
Q Predictions Mean           1259.9438
Q Predictions Std            1184.3916
Q Predictions Max            4795.8994
Q Predictions Min            710.31647
V Predictions Mean           1264.6345
V Predictions Std            1182.3754
V Predictions Max            4779.703
V Predictions Min            709.3092
Log Pis Mean                 -0.17696294
Log Pis Std                  4.124646
Log Pis Max                  17.264545
Log Pis Min                  -10.88627
Policy mu Mean               0.09579847
Policy mu Std                0.89591527
Policy mu Max                3.2568583
Policy mu Min                -3.319118
Policy log std Mean          -0.46987045
Policy log std Std           0.2973435
Policy log std Max           -0.02099824
Policy log std Min           -2.7337692
Z mean eval                  1.9884212
Z variance eval              0.06604248
total_rewards                [10338.49266677 10536.8911184  10787.97691751 10838.98952596
 10663.01910249 10867.52544746 10429.40111804 10722.57065087
 10421.92072396 10509.35964112]
total_rewards_mean           10611.614691257428
total_rewards_std            179.74087995926465
total_rewards_max            10867.525447457798
total_rewards_min            10338.492666765618
Number of train steps total  1424000
Number of env steps total    4274000
Number of rollouts total     0
Train Time (s)               150.14983138721436
(Previous) Eval Time (s)     30.442956273909658
Sample Time (s)              9.938887943979353
Epoch Time (s)               190.53167560510337
Total Train Time (s)         65652.26620833203
Epoch                        355
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:05:32.580986 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #355 | Epoch Duration: 190.61630606651306
2020-01-13 22:05:32.581423 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #355 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9840848
Z variance train             0.06601684
KL Divergence                53.445934
KL Loss                      5.3445935
QF Loss                      130.39644
VF Loss                      68.40306
Policy Loss                  -1353.934
Q Predictions Mean           1351.3313
Q Predictions Std            1306.7971
Q Predictions Max            4744.046
Q Predictions Min            691.66327
V Predictions Mean           1358.373
V Predictions Std            1309.3468
V Predictions Max            4728.351
V Predictions Min            710.95654
Log Pis Mean                 -0.15901521
Log Pis Std                  4.1808257
Log Pis Max                  17.710855
Log Pis Min                  -6.6383295
Policy mu Mean               0.11549906
Policy mu Std                0.8880487
Policy mu Max                2.631744
Policy mu Min                -2.6827722
Policy log std Mean          -0.47326782
Policy log std Std           0.29097992
Policy log std Max           0.13157809
Policy log std Min           -3.2339902
Z mean eval                  2.0117655
Z variance eval              0.082003236
total_rewards                [10211.38973396  9693.85672778 10354.51795606 10299.71253044
 10310.4423995  10592.82439638 10051.97027276  9723.05188703
  9981.40839382  9519.02904861]
total_rewards_mean           10073.820334634005
total_rewards_std            325.3183987333265
total_rewards_max            10592.824396384254
total_rewards_min            9519.029048611745
Number of train steps total  1428000
Number of env steps total    4286000
Number of rollouts total     0
Train Time (s)               151.26953306188807
(Previous) Eval Time (s)     29.98400437971577
Sample Time (s)              8.454313330352306
Epoch Time (s)               189.70785077195615
Total Train Time (s)         65842.05838499917
Epoch                        356
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:08:42.376305 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #356 | Epoch Duration: 189.79453563690186
2020-01-13 22:08:42.376528 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #356 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0118995
Z variance train             0.082164794
KL Divergence                52.277348
KL Loss                      5.227735
QF Loss                      113.6405
VF Loss                      62.34428
Policy Loss                  -1313.331
Q Predictions Mean           1309.8838
Q Predictions Std            1237.301
Q Predictions Max            4764.6787
Q Predictions Min            683.76227
V Predictions Mean           1312.8862
V Predictions Std            1234.1866
V Predictions Max            4756.797
V Predictions Min            684.0059
Log Pis Mean                 -0.21656737
Log Pis Std                  3.7555966
Log Pis Max                  14.837553
Log Pis Min                  -8.053038
Policy mu Mean               0.13480073
Policy mu Std                0.9055056
Policy mu Max                3.3283854
Policy mu Min                -4.025802
Policy log std Mean          -0.48239663
Policy log std Std           0.27167448
Policy log std Max           0.01712823
Policy log std Min           -2.8222241
Z mean eval                  1.9979582
Z variance eval              0.05378126
total_rewards                [10310.76430955 10828.00894375 10462.56553934 10742.7621445
 10766.67410423 10870.15160477 10860.28543828 10433.03779237
 10557.28042504 10986.19274703]
total_rewards_mean           10681.772304886501
total_rewards_std            213.4020525105622
total_rewards_max            10986.192747034904
total_rewards_min            10310.764309552476
Number of train steps total  1432000
Number of env steps total    4298000
Number of rollouts total     0
Train Time (s)               149.62848852714524
(Previous) Eval Time (s)     27.5146562079899
Sample Time (s)              10.280552342999727
Epoch Time (s)               187.42369707813486
Total Train Time (s)         66029.56563826557
Epoch                        357
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:11:49.887127 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #357 | Epoch Duration: 187.5104353427887
2020-01-13 22:11:49.887365 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #357 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0007405
Z variance train             0.053796083
KL Divergence                53.834076
KL Loss                      5.3834076
QF Loss                      240.40056
VF Loss                      48.724808
Policy Loss                  -1405.5746
Q Predictions Mean           1401.6357
Q Predictions Std            1349.2677
Q Predictions Max            4762.924
Q Predictions Min            687.4417
V Predictions Mean           1404.1831
V Predictions Std            1345.1045
V Predictions Max            4734.9873
V Predictions Min            696.37695
Log Pis Mean                 -0.07392048
Log Pis Std                  4.6378055
Log Pis Max                  21.327868
Log Pis Min                  -6.88095
Policy mu Mean               0.057355415
Policy mu Std                0.9417503
Policy mu Max                4.0325127
Policy mu Min                -2.8241746
Policy log std Mean          -0.47495046
Policy log std Std           0.29621655
Policy log std Max           0.03369671
Policy log std Min           -3.003601
Z mean eval                  2.0135753
Z variance eval              0.08916329
total_rewards                [10096.17364085 10211.78817027  9775.61036432 10425.01532071
 10143.31731383  5118.34287793 10542.2715648   9574.07206392
  9837.42789155 10206.87422001]
total_rewards_mean           9593.089342819152
total_rewards_std            1517.4038783524147
total_rewards_max            10542.271564802588
total_rewards_min            5118.342877931451
Number of train steps total  1436000
Number of env steps total    4310000
Number of rollouts total     0
Train Time (s)               141.09559237211943
(Previous) Eval Time (s)     29.761827445123345
Sample Time (s)              9.933281776029617
Epoch Time (s)               180.7907015932724
Total Train Time (s)         66210.43959189393
Epoch                        358
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:14:50.766237 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #358 | Epoch Duration: 180.8787031173706
2020-01-13 22:14:50.766477 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #358 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0131967
Z variance train             0.089561105
KL Divergence                53.465733
KL Loss                      5.3465734
QF Loss                      180.13046
VF Loss                      59.986187
Policy Loss                  -1463.9359
Q Predictions Mean           1463.8372
Q Predictions Std            1412.6797
Q Predictions Max            4862.339
Q Predictions Min            716.326
V Predictions Mean           1463.3672
V Predictions Std            1407.1926
V Predictions Max            4864.9087
V Predictions Min            715.35046
Log Pis Mean                 0.27567804
Log Pis Std                  4.5567274
Log Pis Max                  19.892948
Log Pis Min                  -7.675296
Policy mu Mean               0.09708547
Policy mu Std                0.94788486
Policy mu Max                3.4289727
Policy mu Min                -3.01435
Policy log std Mean          -0.4819479
Policy log std Std           0.28072754
Policy log std Max           -0.085941866
Policy log std Min           -2.9451904
Z mean eval                  2.0028
Z variance eval              0.054500055
total_rewards                [10737.86151867 10799.62970556 10938.4200561  10878.09382828
 10882.18107238 10782.88473682 10691.774192   10734.5419005
 10836.71058277 10788.10767059]
total_rewards_mean           10807.020526368684
total_rewards_std            72.91128280801364
total_rewards_max            10938.420056104356
total_rewards_min            10691.774192004224
Number of train steps total  1440000
Number of env steps total    4322000
Number of rollouts total     0
Train Time (s)               140.80049841711298
(Previous) Eval Time (s)     29.609927905723453
Sample Time (s)              9.860321003943682
Epoch Time (s)               180.2707473267801
Total Train Time (s)         66390.79378608661
Epoch                        359
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:17:51.124086 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #359 | Epoch Duration: 180.35744261741638
2020-01-13 22:17:51.124285 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #359 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0027843
Z variance train             0.054676592
KL Divergence                54.890892
KL Loss                      5.4890895
QF Loss                      4742.1875
VF Loss                      40.921074
Policy Loss                  -1448.4774
Q Predictions Mean           1447.685
Q Predictions Std            1365.7314
Q Predictions Max            4807.309
Q Predictions Min            738.3711
V Predictions Mean           1448.8312
V Predictions Std            1363.6754
V Predictions Max            4830.6284
V Predictions Min            733.97797
Log Pis Mean                 0.3761528
Log Pis Std                  4.1867714
Log Pis Max                  20.891327
Log Pis Min                  -7.398173
Policy mu Mean               0.15939707
Policy mu Std                0.97332144
Policy mu Max                3.1012478
Policy mu Min                -2.8230138
Policy log std Mean          -0.48760477
Policy log std Std           0.29230735
Policy log std Max           -0.06435454
Policy log std Min           -2.74521
Z mean eval                  1.9968545
Z variance eval              0.07678363
total_rewards                [ 9970.10453929 10214.31121283  9978.65360562 10077.20453981
  9934.89501575 10113.98115616  9968.71260044  9941.08826683
  9763.28805035  9945.69016621]
total_rewards_mean           9990.792915328582
total_rewards_std            115.3488195521636
total_rewards_max            10214.31121283281
total_rewards_min            9763.288050347617
Number of train steps total  1444000
Number of env steps total    4334000
Number of rollouts total     0
Train Time (s)               147.72308153565973
(Previous) Eval Time (s)     29.97387367906049
Sample Time (s)              9.964387093205005
Epoch Time (s)               187.66134230792522
Total Train Time (s)         66578.54294150695
Epoch                        360
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:20:58.876880 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #360 | Epoch Duration: 187.752450466156
2020-01-13 22:20:58.877067 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #360 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9989948
Z variance train             0.07671017
KL Divergence                54.090904
KL Loss                      5.4090905
QF Loss                      220.39711
VF Loss                      79.08295
Policy Loss                  -1504.7812
Q Predictions Mean           1498.8539
Q Predictions Std            1367.356
Q Predictions Max            4775.2246
Q Predictions Min            756.4621
V Predictions Mean           1504.1643
V Predictions Std            1367.5618
V Predictions Max            4766.572
V Predictions Min            759.841
Log Pis Mean                 1.6944773
Log Pis Std                  4.500086
Log Pis Max                  17.002466
Log Pis Min                  -6.2375593
Policy mu Mean               0.19690625
Policy mu Std                1.1302003
Policy mu Max                3.4990857
Policy mu Min                -2.738154
Policy log std Mean          -0.54406095
Policy log std Std           0.3217321
Policy log std Max           -0.06745279
Policy log std Min           -2.922066
Z mean eval                  2.0179818
Z variance eval              0.09636121
total_rewards                [10223.81733856 10988.2921001  10890.80449012 10250.39976324
  4547.39716662 11018.32303481 10668.49178703 10799.22640333
 11046.93717917 10810.21833718]
total_rewards_mean           10124.39076001538
total_rewards_std            1879.7433955574886
total_rewards_max            11046.93717916987
total_rewards_min            4547.39716661628
Number of train steps total  1448000
Number of env steps total    4346000
Number of rollouts total     0
Train Time (s)               149.6413243287243
(Previous) Eval Time (s)     30.31966778682545
Sample Time (s)              10.59110044222325
Epoch Time (s)               190.552092557773
Total Train Time (s)         66769.17934111133
Epoch                        361
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:24:09.523083 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #361 | Epoch Duration: 190.6458718776703
2020-01-13 22:24:09.523461 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #361 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0173788
Z variance train             0.09665529
KL Divergence                54.09205
KL Loss                      5.409205
QF Loss                      296.77863
VF Loss                      58.57448
Policy Loss                  -1485.019
Q Predictions Mean           1475.9028
Q Predictions Std            1234.2539
Q Predictions Max            4809.309
Q Predictions Min            794.8678
V Predictions Mean           1485.5112
V Predictions Std            1230.158
V Predictions Max            4791.5996
V Predictions Min            818.2105
Log Pis Mean                 2.6176698
Log Pis Std                  4.1283493
Log Pis Max                  15.649406
Log Pis Min                  -6.801079
Policy mu Mean               0.16953857
Policy mu Std                1.2219747
Policy mu Max                2.8023202
Policy mu Min                -3.2941284
Policy log std Mean          -0.5718061
Policy log std Std           0.27244157
Policy log std Max           0.09377569
Policy log std Min           -2.980372
Z mean eval                  2.0616326
Z variance eval              0.0989476
total_rewards                [10289.3952871  10638.26295068 10673.37670179 10657.3536294
 10801.31524684 10636.24504831 10851.70104532 11016.59897459
 10755.17279181 11099.02339797]
total_rewards_mean           10741.844507379265
total_rewards_std            213.83799440801187
total_rewards_max            11099.02339797034
total_rewards_min            10289.395287098569
Number of train steps total  1452000
Number of env steps total    4358000
Number of rollouts total     0
Train Time (s)               149.45665967091918
(Previous) Eval Time (s)     29.475054626353085
Sample Time (s)              10.281821503303945
Epoch Time (s)               189.2135358005762
Total Train Time (s)         66958.48469543923
Epoch                        362
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:27:18.831723 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #362 | Epoch Duration: 189.3079297542572
2020-01-13 22:27:18.832031 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #362 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0589416
Z variance train             0.09944816
KL Divergence                56.688927
KL Loss                      5.668893
QF Loss                      651.344
VF Loss                      108.29052
Policy Loss                  -1760.1353
Q Predictions Mean           1746.3181
Q Predictions Std            1345.4105
Q Predictions Max            4894.8345
Q Predictions Min            952.65375
V Predictions Mean           1758.9841
V Predictions Std            1337.0002
V Predictions Max            4881.457
V Predictions Min            991.85004
Log Pis Mean                 4.2939835
Log Pis Std                  4.6961427
Log Pis Max                  20.770866
Log Pis Min                  -5.5119467
Policy mu Mean               0.17919533
Policy mu Std                1.384417
Policy mu Max                2.7627027
Policy mu Min                -2.5313046
Policy log std Mean          -0.61863863
Policy log std Std           0.28277722
Policy log std Max           -0.07004538
Policy log std Min           -2.770638
Z mean eval                  2.172025
Z variance eval              0.09108369
total_rewards                [ 9847.07592028 10397.47013288 10119.80344316  9692.12709381
 10123.20912429  9677.81594407 10157.57648804  4294.21596938
 10454.3754392  10606.32141259]
total_rewards_mean           9536.99909676931
total_rewards_std            1772.5878260650438
total_rewards_max            10606.321412589992
total_rewards_min            4294.215969377268
Number of train steps total  1456000
Number of env steps total    4370000
Number of rollouts total     0
Train Time (s)               151.86141803488135
(Previous) Eval Time (s)     29.84672755515203
Sample Time (s)              10.079560341313481
Epoch Time (s)               191.78770593134686
Total Train Time (s)         67150.36129560508
Epoch                        363
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:30:30.709453 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #363 | Epoch Duration: 191.87713360786438
2020-01-13 22:30:30.709805 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #363 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1686187
Z variance train             0.09152125
KL Divergence                59.436882
KL Loss                      5.9436884
QF Loss                      11262.835
VF Loss                      392.97678
Policy Loss                  -1862.8141
Q Predictions Mean           1846.9246
Q Predictions Std            1210.9772
Q Predictions Max            4825.181
Q Predictions Min            1143.6619
V Predictions Mean           1873.2874
V Predictions Std            1210.1659
V Predictions Max            4828.0293
V Predictions Min            1143.7572
Log Pis Mean                 5.287178
Log Pis Std                  4.6050444
Log Pis Max                  19.646967
Log Pis Min                  -4.7921352
Policy mu Mean               0.11760086
Policy mu Std                1.4898396
Policy mu Max                3.5750499
Policy mu Min                -3.258622
Policy log std Mean          -0.63630074
Policy log std Std           0.2612801
Policy log std Max           -0.05317211
Policy log std Min           -3.046749
Z mean eval                  2.2029014
Z variance eval              0.060773678
total_rewards                [10464.0586464  10723.29576885 10789.73589719 10682.1873211
 10706.90133645  8575.56813786 10694.13598795  1663.20676191
 10602.04426866 10707.54566738]
total_rewards_mean           9560.867979375767
total_rewards_std            2706.9344335655874
total_rewards_max            10789.735897188317
total_rewards_min            1663.206761907187
Number of train steps total  1460000
Number of env steps total    4382000
Number of rollouts total     0
Train Time (s)               150.3668878832832
(Previous) Eval Time (s)     29.64360012114048
Sample Time (s)              10.263813830912113
Epoch Time (s)               190.2743018353358
Total Train Time (s)         67340.71363692125
Epoch                        364
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:33:41.065542 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #364 | Epoch Duration: 190.35552716255188
2020-01-13 22:33:41.065757 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #364 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2053995
Z variance train             0.06106294
KL Divergence                64.332275
KL Loss                      6.4332275
QF Loss                      987.10236
VF Loss                      245.4009
Policy Loss                  -2090.3884
Q Predictions Mean           2072.0342
Q Predictions Std            1140.9739
Q Predictions Max            4951.2544
Q Predictions Min            1393.1864
V Predictions Mean           2081.4421
V Predictions Std            1127.2281
V Predictions Max            4962.516
V Predictions Min            1390.3119
Log Pis Mean                 4.790477
Log Pis Std                  4.132112
Log Pis Max                  15.231778
Log Pis Min                  -5.226897
Policy mu Mean               0.05050075
Policy mu Std                1.4504672
Policy mu Max                3.3520608
Policy mu Min                -2.6764338
Policy log std Mean          -0.6217061
Policy log std Std           0.23330022
Policy log std Max           0.07526389
Policy log std Min           -2.9865026
Z mean eval                  2.2717357
Z variance eval              0.0992412
total_rewards                [10645.61248203 11126.4579152  11149.05691268 10755.63131171
 10800.39317675 10307.20279273 10624.09928761 10624.13681259
 10542.70742129 11101.86823592]
total_rewards_mean           10767.716634851304
total_rewards_std            265.67639988256883
total_rewards_max            11149.056912681099
total_rewards_min            10307.20279272596
Number of train steps total  1464000
Number of env steps total    4394000
Number of rollouts total     0
Train Time (s)               141.09763834206387
(Previous) Eval Time (s)     28.75948868598789
Sample Time (s)              9.887343716342002
Epoch Time (s)               179.74447074439377
Total Train Time (s)         67520.54291172791
Epoch                        365
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:36:40.900242 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #365 | Epoch Duration: 179.83424472808838
2020-01-13 22:36:40.900597 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #365 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2764757
Z variance train             0.09896789
KL Divergence                66.91759
KL Loss                      6.6917586
QF Loss                      627.01666
VF Loss                      234.45505
Policy Loss                  -2186.129
Q Predictions Mean           2170.6436
Q Predictions Std            1042.5579
Q Predictions Max            4992.127
Q Predictions Min            1574.2463
V Predictions Mean           2182.731
V Predictions Std            1029.6956
V Predictions Max            4954.395
V Predictions Min            1571.5435
Log Pis Mean                 4.6072416
Log Pis Std                  4.199114
Log Pis Max                  15.754386
Log Pis Min                  -6.10729
Policy mu Mean               0.04300187
Policy mu Std                1.4341052
Policy mu Max                3.0606372
Policy mu Min                -2.972875
Policy log std Mean          -0.6331118
Policy log std Std           0.2526612
Policy log std Max           -0.06508744
Policy log std Min           -2.795297
Z mean eval                  2.3205726
Z variance eval              0.13751972
total_rewards                [10862.00098421 10869.27285154 10914.38162152 10518.94551257
 10576.79373804 11096.0541581  10566.47834322 10694.17848355
 10904.46735823 10949.35402674]
total_rewards_mean           10795.192707771846
total_rewards_std            183.55005893128245
total_rewards_max            11096.054158098485
total_rewards_min            10518.945512568582
Number of train steps total  1468000
Number of env steps total    4406000
Number of rollouts total     0
Train Time (s)               141.60053439205512
(Previous) Eval Time (s)     29.16251777810976
Sample Time (s)              9.54252719739452
Epoch Time (s)               180.3055793675594
Total Train Time (s)         67700.92722165212
Epoch                        366
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:39:41.287614 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #366 | Epoch Duration: 180.3868224620819
2020-01-13 22:39:41.287810 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.313764
Z variance train             0.13718043
KL Divergence                67.95638
KL Loss                      6.7956386
QF Loss                      26199.043
VF Loss                      212.60475
Policy Loss                  -2216.9346
Q Predictions Mean           2203.4546
Q Predictions Std            959.50476
Q Predictions Max            4983.918
Q Predictions Min            1667.299
V Predictions Mean           2225.335
V Predictions Std            954.41046
V Predictions Max            4992.3735
V Predictions Min            1716.0746
Log Pis Mean                 4.6014957
Log Pis Std                  4.503877
Log Pis Max                  16.180279
Log Pis Min                  -5.3789153
Policy mu Mean               -0.00460881
Policy mu Std                1.4330282
Policy mu Max                3.037134
Policy mu Min                -2.8429742
Policy log std Mean          -0.6351704
Policy log std Std           0.27151978
Policy log std Max           -0.14453584
Policy log std Min           -3.1344264
Z mean eval                  2.2928145
Z variance eval              0.11999081
total_rewards                [10303.20524963 10606.17667059 10428.34388884 10559.97742628
 10695.66702083 10626.47261942 10436.22858219 10589.03249391
  6318.47610252 10441.20432358]
total_rewards_mean           10100.478437778465
total_rewards_std            1265.5999480184944
total_rewards_max            10695.667020827588
total_rewards_min            6318.476102520406
Number of train steps total  1472000
Number of env steps total    4418000
Number of rollouts total     0
Train Time (s)               149.14043685002252
(Previous) Eval Time (s)     31.084309219848365
Sample Time (s)              9.159217814914882
Epoch Time (s)               189.38396388478577
Total Train Time (s)         67890.39639112307
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:42:50.761209 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #367 | Epoch Duration: 189.47323966026306
2020-01-13 22:42:50.761438 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.291502
Z variance train             0.12006278
KL Divergence                69.37809
KL Loss                      6.937809
QF Loss                      945.64386
VF Loss                      138.66583
Policy Loss                  -2384.2974
Q Predictions Mean           2368.3096
Q Predictions Std            950.7467
Q Predictions Max            4976.7046
Q Predictions Min            1802.8633
V Predictions Mean           2386.4067
V Predictions Std            946.61316
V Predictions Max            4972.038
V Predictions Min            1820.5099
Log Pis Mean                 4.321783
Log Pis Std                  4.136193
Log Pis Max                  17.906292
Log Pis Min                  -6.121992
Policy mu Mean               -0.039547488
Policy mu Std                1.4058648
Policy mu Max                3.372119
Policy mu Min                -3.7160606
Policy log std Mean          -0.6135761
Policy log std Std           0.24723639
Policy log std Max           -0.08762038
Policy log std Min           -3.0337772
Z mean eval                  2.3569152
Z variance eval              0.10875615
total_rewards                [10047.43128857 10102.62563051  9927.13065663 10142.22227986
 10213.15580734 10440.50571878 10179.33409396 10128.10424713
 10230.86366947 10540.69769691]
total_rewards_mean           10195.207108916235
total_rewards_std            170.57691718142223
total_rewards_max            10540.697696914169
total_rewards_min            9927.13065662679
Number of train steps total  1476000
Number of env steps total    4430000
Number of rollouts total     0
Train Time (s)               149.91696538822725
(Previous) Eval Time (s)     29.76576565671712
Sample Time (s)              9.580883647315204
Epoch Time (s)               189.26361469225958
Total Train Time (s)         68079.7413472049
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:46:00.110680 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #368 | Epoch Duration: 189.349050283432
2020-01-13 22:46:00.111004 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #368 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3542848
Z variance train             0.109225795
KL Divergence                70.05272
KL Loss                      7.005272
QF Loss                      844.46967
VF Loss                      130.51663
Policy Loss                  -2458.368
Q Predictions Mean           2435.4382
Q Predictions Std            888.924
Q Predictions Max            5006.219
Q Predictions Min            1912.3622
V Predictions Mean           2457.8154
V Predictions Std            877.20984
V Predictions Max            4992.256
V Predictions Min            1960.1205
Log Pis Mean                 5.4017057
Log Pis Std                  4.7255287
Log Pis Max                  17.881893
Log Pis Min                  -4.8180456
Policy mu Mean               0.14022334
Policy mu Std                1.517941
Policy mu Max                3.5228837
Policy mu Min                -3.249898
Policy log std Mean          -0.6402351
Policy log std Std           0.24381341
Policy log std Max           -0.0012803078
Policy log std Min           -2.8927422
Z mean eval                  2.5504107
Z variance eval              0.21327928
total_rewards                [10057.71150894 10624.35755713 10426.34262541 10516.19143298
 10564.95993269 10444.62325485 10670.86371756 10174.93392428
 10435.3313568  10365.5073519 ]
total_rewards_mean           10428.082266253568
total_rewards_std            181.5127886756717
total_rewards_max            10670.863717560858
total_rewards_min            10057.711508935878
Number of train steps total  1480000
Number of env steps total    4442000
Number of rollouts total     0
Train Time (s)               148.37356232805178
(Previous) Eval Time (s)     30.786536283325404
Sample Time (s)              10.572975679300725
Epoch Time (s)               189.7330742906779
Total Train Time (s)         68269.57186266547
Epoch                        369
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:49:09.944759 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #369 | Epoch Duration: 189.833557844162
2020-01-13 22:49:09.944980 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #369 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5510468
Z variance train             0.21217537
KL Divergence                75.152245
KL Loss                      7.5152245
QF Loss                      2521.0068
VF Loss                      1000.15454
Policy Loss                  -2836.7168
Q Predictions Mean           2809.4595
Q Predictions Std            894.17926
Q Predictions Max            5079.83
Q Predictions Min            2244.054
V Predictions Mean           2857.5083
V Predictions Std            899.6556
V Predictions Max            5143.8657
V Predictions Min            2280.2134
Log Pis Mean                 5.91826
Log Pis Std                  4.4837146
Log Pis Max                  19.108856
Log Pis Min                  -3.6303053
Policy mu Mean               0.07874145
Policy mu Std                1.5550189
Policy mu Max                4.145036
Policy mu Min                -2.8446481
Policy log std Mean          -0.67715114
Policy log std Std           0.2558239
Policy log std Max           0.20583403
Policy log std Min           -2.8964481
Z mean eval                  2.6163523
Z variance eval              0.22116156
total_rewards                [10032.41309489 10735.01990191 10162.70868287 10418.0712506
 10334.92283032 10685.28045233 10570.57905674 10418.62494625
 10365.7886548  10153.48656494]
total_rewards_mean           10387.689543565946
total_rewards_std            218.970340664979
total_rewards_max            10735.019901913533
total_rewards_min            10032.41309489466
Number of train steps total  1484000
Number of env steps total    4454000
Number of rollouts total     0
Train Time (s)               150.65812539309263
(Previous) Eval Time (s)     30.126556816045195
Sample Time (s)              10.462215225212276
Epoch Time (s)               191.2468974343501
Total Train Time (s)         68460.90742236283
Epoch                        370
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:52:21.284505 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #370 | Epoch Duration: 191.33936190605164
2020-01-13 22:52:21.284728 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #370 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6182044
Z variance train             0.22070667
KL Divergence                77.98443
KL Loss                      7.798443
QF Loss                      938.0119
VF Loss                      321.40817
Policy Loss                  -2913.1438
Q Predictions Mean           2893.2014
Q Predictions Std            743.5246
Q Predictions Max            5059.4556
Q Predictions Min            2458.1877
V Predictions Mean           2901.4307
V Predictions Std            729.5758
V Predictions Max            5038.14
V Predictions Min            2465.7227
Log Pis Mean                 5.1747284
Log Pis Std                  4.427306
Log Pis Max                  16.948696
Log Pis Min                  -7.087265
Policy mu Mean               -0.03518849
Policy mu Std                1.4922451
Policy mu Max                3.606641
Policy mu Min                -2.977138
Policy log std Mean          -0.65138704
Policy log std Std           0.2377646
Policy log std Max           -0.099236846
Policy log std Min           -3.0054002
Z mean eval                  2.562292
Z variance eval              0.48191515
total_rewards                [ 9909.1049538  10135.33875405 10070.0049043  10286.66734607
 10263.75088844 10106.58998567 10097.78687818 10256.27903227
 10108.09651393 10184.90987556]
total_rewards_mean           10141.85291322745
total_rewards_std            106.99464580865134
total_rewards_max            10286.6673460662
total_rewards_min            9909.104953799026
Number of train steps total  1488000
Number of env steps total    4466000
Number of rollouts total     0
Train Time (s)               145.99731964292005
(Previous) Eval Time (s)     28.09471032395959
Sample Time (s)              9.965607891324908
Epoch Time (s)               184.05763785820454
Total Train Time (s)         68645.05215732055
Epoch                        371
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:55:25.433533 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #371 | Epoch Duration: 184.14863681793213
2020-01-13 22:55:25.433742 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5641456
Z variance train             0.482862
KL Divergence                79.90216
KL Loss                      7.9902163
QF Loss                      1564.1548
VF Loss                      329.72586
Policy Loss                  -2952.1914
Q Predictions Mean           2928.7434
Q Predictions Std            716.8307
Q Predictions Max            5080.6963
Q Predictions Min            2511.058
V Predictions Mean           2940.3472
V Predictions Std            698.73285
V Predictions Max            5021.2256
V Predictions Min            2531.3586
Log Pis Mean                 5.6014333
Log Pis Std                  4.736099
Log Pis Max                  26.65911
Log Pis Min                  -4.695644
Policy mu Mean               0.10441377
Policy mu Std                1.5324638
Policy mu Max                4.513492
Policy mu Min                -2.967128
Policy log std Mean          -0.6802638
Policy log std Std           0.2552314
Policy log std Max           -0.023609042
Policy log std Min           -2.953216
Z mean eval                  2.5965
Z variance eval              0.37018904
total_rewards                [10169.93574146 10717.12012901 10480.88313105 10744.79337281
 10772.10469795 10920.37883553 10826.46284481 10606.31968985
 10729.6714571  10647.11391921]
total_rewards_mean           10661.478381877789
total_rewards_std            199.6629204506155
total_rewards_max            10920.378835532354
total_rewards_min            10169.935741459338
Number of train steps total  1492000
Number of env steps total    4478000
Number of rollouts total     0
Train Time (s)               141.1555265118368
(Previous) Eval Time (s)     29.90799042582512
Sample Time (s)              9.301299468614161
Epoch Time (s)               180.36481640627608
Total Train Time (s)         68825.50029276963
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:58:25.886269 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #372 | Epoch Duration: 180.45235896110535
2020-01-13 22:58:25.886539 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #372 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.59517
Z variance train             0.37119913
KL Divergence                80.209755
KL Loss                      8.020976
QF Loss                      632.75323
VF Loss                      255.75238
Policy Loss                  -3054.0422
Q Predictions Mean           3034.0732
Q Predictions Std            697.0987
Q Predictions Max            5013.3804
Q Predictions Min            2573.0828
V Predictions Mean           3052.5696
V Predictions Std            677.3388
V Predictions Max            4992.1274
V Predictions Min            2591.7815
Log Pis Mean                 5.5929356
Log Pis Std                  4.3160243
Log Pis Max                  19.684229
Log Pis Min                  -3.9837892
Policy mu Mean               -0.06581167
Policy mu Std                1.5041801
Policy mu Max                3.380526
Policy mu Min                -2.9700813
Policy log std Mean          -0.6822097
Policy log std Std           0.2487652
Policy log std Max           -0.14485323
Policy log std Min           -3.0755777
Z mean eval                  2.6136925
Z variance eval              0.30624682
total_rewards                [ 9957.5280615  10692.47571211 10598.65293369  3760.84219856
 10448.39486359 10847.24213613 10684.41894089  3986.63219638
 10703.35208679 10760.91686591]
total_rewards_mean           9244.045599554931
total_rewards_std            2695.8065357569403
total_rewards_max            10847.242136125647
total_rewards_min            3760.8421985554946
Number of train steps total  1496000
Number of env steps total    4490000
Number of rollouts total     0
Train Time (s)               142.16114694066346
(Previous) Eval Time (s)     29.078589329030365
Sample Time (s)              9.436464886646718
Epoch Time (s)               180.67620115634054
Total Train Time (s)         69006.26067736745
Epoch                        373
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:01:26.653360 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #373 | Epoch Duration: 180.76651167869568
2020-01-13 23:01:26.653847 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #373 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6178136
Z variance train             0.30588013
KL Divergence                80.82532
KL Loss                      8.082532
QF Loss                      2399.5562
VF Loss                      498.08966
Policy Loss                  -3149.18
Q Predictions Mean           3129.0317
Q Predictions Std            697.01715
Q Predictions Max            5573.021
Q Predictions Min            2653.0525
V Predictions Mean           3132.033
V Predictions Std            671.4902
V Predictions Max            5074.105
V Predictions Min            2682.0369
Log Pis Mean                 6.1702356
Log Pis Std                  4.8757486
Log Pis Max                  19.683922
Log Pis Min                  -4.0215964
Policy mu Mean               -0.045075014
Policy mu Std                1.5869987
Policy mu Max                3.8604474
Policy mu Min                -3.415931
Policy log std Mean          -0.68983334
Policy log std Std           0.2673008
Policy log std Max           0.1937027
Policy log std Min           -2.7317855
Z mean eval                  2.7064877
Z variance eval              0.26088983
total_rewards                [ -307.17320369  9324.06477423 10074.93509459 10307.09271162
 10094.88495958 10176.91677637  9899.02700657  9713.95486246
  9952.1207414  10546.74825723]
total_rewards_mean           8978.25719803721
total_rewards_std            3111.0864934344736
total_rewards_max            10546.748257226376
total_rewards_min            -307.173203694507
Number of train steps total  1500000
Number of env steps total    4502000
Number of rollouts total     0
Train Time (s)               150.9646335951984
(Previous) Eval Time (s)     30.10184458224103
Sample Time (s)              10.151459851302207
Epoch Time (s)               191.21793802874163
Total Train Time (s)         69197.56161908619
Epoch                        374
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:04:37.957424 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #374 | Epoch Duration: 191.30328679084778
2020-01-13 23:04:37.957681 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.705343
Z variance train             0.26061895
KL Divergence                84.163666
KL Loss                      8.416367
QF Loss                      1752.6345
VF Loss                      563.28754
Policy Loss                  -3295.1167
Q Predictions Mean           3257.4917
Q Predictions Std            574.6375
Q Predictions Max            5071.1514
Q Predictions Min            2844.8901
V Predictions Mean           3287.6416
V Predictions Std            554.48615
V Predictions Max            5064.7344
V Predictions Min            2849.295
Log Pis Mean                 6.548559
Log Pis Std                  5.8359094
Log Pis Max                  26.062014
Log Pis Min                  -5.3708158
Policy mu Mean               0.08091111
Policy mu Std                1.6364521
Policy mu Max                5.4694033
Policy mu Min                -4.1480665
Policy log std Mean          -0.69960994
Policy log std Std           0.25740305
Policy log std Max           0.29793334
Policy log std Min           -2.6658192
Z mean eval                  2.8772664
Z variance eval              0.23609352
total_rewards                [-457.79441518 -620.20420224 -294.91813991 -198.95441928 -479.68583222
 -291.80214594 -267.66034519 -399.15798362 -391.10672202 -431.02893205]
total_rewards_mean           -383.23131376585684
total_rewards_std            117.08659415225092
total_rewards_max            -198.95441928283464
total_rewards_min            -620.2042022427962
Number of train steps total  1504000
Number of env steps total    4514000
Number of rollouts total     0
Train Time (s)               149.82056031981483
(Previous) Eval Time (s)     29.066696147900075
Sample Time (s)              10.17219119053334
Epoch Time (s)               189.05944765824825
Total Train Time (s)         69386.7014855165
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:07:47.098951 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #375 | Epoch Duration: 189.14109826087952
2020-01-13 23:07:47.099103 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.8761585
Z variance train             0.23595853
KL Divergence                90.973495
KL Loss                      9.09735
QF Loss                      1502.0826
VF Loss                      597.027
Policy Loss                  -3649.177
Q Predictions Mean           3604.8364
Q Predictions Std            491.38074
Q Predictions Max            5106.35
Q Predictions Min            3035.3247
V Predictions Mean           3652.7827
V Predictions Std            477.179
V Predictions Max            5095.2573
V Predictions Min            3097.7285
Log Pis Mean                 7.5963783
Log Pis Std                  5.369193
Log Pis Max                  22.03049
Log Pis Min                  -4.346387
Policy mu Mean               0.0041660964
Policy mu Std                1.7019247
Policy mu Max                3.62929
Policy mu Min                -3.7196827
Policy log std Mean          -0.7283556
Policy log std Std           0.24530676
Policy log std Max           -0.13288522
Policy log std Min           -2.1133623
Z mean eval                  2.8536403
Z variance eval              0.2571517
total_rewards                [-500.13049914 -526.40561246 -526.33974863 -532.5381143  -531.66400986
 -520.79519831 -432.57248835 -523.02747527 -539.0687134  -529.86407499]
total_rewards_mean           -516.2405934707821
total_rewards_std            29.56725715319009
total_rewards_max            -432.57248835305444
total_rewards_min            -539.0687133976243
Number of train steps total  1508000
Number of env steps total    4526000
Number of rollouts total     0
Train Time (s)               149.57393515575677
(Previous) Eval Time (s)     31.665171498898417
Sample Time (s)              10.146349024958909
Epoch Time (s)               191.3854556796141
Total Train Time (s)         69578.17109024525
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:10:58.572878 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #376 | Epoch Duration: 191.473650932312
2020-01-13 23:10:58.573089 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.8503482
Z variance train             0.25804314
KL Divergence                94.82086
KL Loss                      9.482086
QF Loss                      97229.45
VF Loss                      447.41827
Policy Loss                  -3599.261
Q Predictions Mean           3583.591
Q Predictions Std            392.5174
Q Predictions Max            5078.907
Q Predictions Min            3311.6887
V Predictions Mean           3603.3855
V Predictions Std            379.34158
V Predictions Max            5016.702
V Predictions Min            3343.4014
Log Pis Mean                 5.3709855
Log Pis Std                  4.660467
Log Pis Max                  26.976812
Log Pis Min                  -3.6511638
Policy mu Mean               0.001242573
Policy mu Std                1.4795618
Policy mu Max                3.7785373
Policy mu Min                -3.9114823
Policy log std Mean          -0.719464
Policy log std Std           0.26574826
Policy log std Max           0.15968764
Policy log std Min           -2.7664924
Z mean eval                  2.670134
Z variance eval              0.31441382
total_rewards                [-346.54593749 8886.8075694  9414.29442978 9896.60179485 9474.23798045
 9745.9013546  9646.67159479 7070.3210054  9007.959244   -384.0809021 ]
total_rewards_mean           7241.216813368104
total_rewards_std            3878.10828315271
total_rewards_max            9896.601794854272
total_rewards_min            -384.08090210436995
Number of train steps total  1512000
Number of env steps total    4538000
Number of rollouts total     0
Train Time (s)               150.6218322138302
(Previous) Eval Time (s)     30.640555180143565
Sample Time (s)              10.76179212750867
Epoch Time (s)               192.02417952148244
Total Train Time (s)         69770.28419978125
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:14:10.691544 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #377 | Epoch Duration: 192.11798810958862
2020-01-13 23:14:10.691931 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6709187
Z variance train             0.31448406
KL Divergence                90.86107
KL Loss                      9.086107
QF Loss                      22204.555
VF Loss                      178.29309
Policy Loss                  -3291.3333
Q Predictions Mean           3290.701
Q Predictions Std            640.5549
Q Predictions Max            5798.1704
Q Predictions Min            2922.9805
V Predictions Mean           3293.8867
V Predictions Std            638.9725
V Predictions Max            6095.1562
V Predictions Min            2918.1018
Log Pis Mean                 3.4825833
Log Pis Std                  3.8933175
Log Pis Max                  23.535187
Log Pis Min                  -6.1084166
Policy mu Mean               0.004003542
Policy mu Std                1.2915531
Policy mu Max                5.1471252
Policy mu Min                -4.442689
Policy log std Mean          -0.6428778
Policy log std Std           0.25949755
Policy log std Max           0.21287394
Policy log std Min           -2.6683528
Z mean eval                  2.6997418
Z variance eval              0.31962413
total_rewards                [-459.48910782 -449.826488   -442.76630727 -459.18572076 -199.20300409
 -462.80380725  355.2059076  7972.22752737 2772.47517437 -462.26692102]
total_rewards_mean           816.4367253147005
total_rewards_std            2568.87990880599
total_rewards_max            7972.227527373057
total_rewards_min            -462.8038072467786
Number of train steps total  1516000
Number of env steps total    4550000
Number of rollouts total     0
Train Time (s)               142.79871465964243
(Previous) Eval Time (s)     28.52481837524101
Sample Time (s)              10.229162016417831
Epoch Time (s)               181.55269505130127
Total Train Time (s)         69951.91738057416
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:17:12.327895 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #378 | Epoch Duration: 181.6357719898224
2020-01-13 23:17:12.328103 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6994176
Z variance train             0.3196207
KL Divergence                84.488525
KL Loss                      8.448853
QF Loss                      50717.727
VF Loss                      222.07103
Policy Loss                  -2864.2302
Q Predictions Mean           2862.706
Q Predictions Std            672.43506
Q Predictions Max            4881.3384
Q Predictions Min            2491.3516
V Predictions Mean           2874.6218
V Predictions Std            673.93
V Predictions Max            4892.2456
V Predictions Min            2508.1145
Log Pis Mean                 2.212335
Log Pis Std                  3.6154156
Log Pis Max                  20.110062
Log Pis Min                  -5.295395
Policy mu Mean               -0.0068295375
Policy mu Std                1.1614605
Policy mu Max                3.6816497
Policy mu Min                -2.9201372
Policy log std Mean          -0.5968795
Policy log std Std           0.25339255
Policy log std Max           -0.016845644
Policy log std Min           -2.5975027
Z mean eval                  2.7212913
Z variance eval              0.3070526
total_rewards                [9126.35660863 7900.97903847 9011.69024744 8477.27516582 8074.47177527
 7998.57115349 8454.07535368 8423.03462578 8627.4283286  7945.85159366]
total_rewards_mean           8403.973389084409
total_rewards_std            410.50423581427964
total_rewards_max            9126.356608634218
total_rewards_min            7900.979038465612
Number of train steps total  1520000
Number of env steps total    4562000
Number of rollouts total     0
Train Time (s)               142.12516393512487
(Previous) Eval Time (s)     29.555963597260416
Sample Time (s)              8.350843756925315
Epoch Time (s)               180.0319712893106
Total Train Time (s)         70132.03834231012
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:20:12.453062 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #379 | Epoch Duration: 180.12478303909302
2020-01-13 23:20:12.453340 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.7199512
Z variance train             0.30720538
KL Divergence                78.72606
KL Loss                      7.872606
QF Loss                      347.28738
VF Loss                      128.6484
Policy Loss                  -2461.5742
Q Predictions Mean           2460.5112
Q Predictions Std            758.48126
Q Predictions Max            4713.126
Q Predictions Min            2091.4453
V Predictions Mean           2465.0757
V Predictions Std            753.04224
V Predictions Max            4703.5024
V Predictions Min            2081.617
Log Pis Mean                 1.28477
Log Pis Std                  3.8474417
Log Pis Max                  14.437017
Log Pis Min                  -9.066641
Policy mu Mean               0.005275868
Policy mu Std                1.0962936
Policy mu Max                3.0127745
Policy mu Min                -2.909778
Policy log std Mean          -0.54028153
Policy log std Std           0.2204523
Policy log std Max           0.19225705
Policy log std Min           -2.0465508
Z mean eval                  2.652033
Z variance eval              0.40477958
total_rewards                [8740.30018592 8940.72254898 9624.80275591 9393.33536318  952.21236911
 8831.25205951 9275.4352618  8856.61330859 9203.06169889 9537.74312179]
total_rewards_mean           8335.547867366902
total_rewards_std            2478.371850639105
total_rewards_max            9624.802755906956
total_rewards_min            952.212369108341
Number of train steps total  1524000
Number of env steps total    4574000
Number of rollouts total     0
Train Time (s)               144.68098449986428
(Previous) Eval Time (s)     30.171129742171615
Sample Time (s)              10.076060620136559
Epoch Time (s)               184.92817486217245
Total Train Time (s)         70317.06015516212
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:23:17.479420 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #380 | Epoch Duration: 185.02589106559753
2020-01-13 23:23:17.479818 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #380 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6530411
Z variance train             0.40364677
KL Divergence                75.1527
KL Loss                      7.51527
QF Loss                      252.41382
VF Loss                      196.724
Policy Loss                  -2272.7622
Q Predictions Mean           2270.863
Q Predictions Std            908.1254
Q Predictions Max            4791.3804
Q Predictions Min            1700.4918
V Predictions Mean           2265.128
V Predictions Std            898.59204
V Predictions Max            4766.3896
V Predictions Min            1764.9044
Log Pis Mean                 1.2189486
Log Pis Std                  3.9478216
Log Pis Max                  17.425938
Log Pis Min                  -10.200525
Policy mu Mean               0.006941819
Policy mu Std                1.0634522
Policy mu Max                2.552792
Policy mu Min                -2.7375245
Policy log std Mean          -0.5173529
Policy log std Std           0.23713696
Policy log std Max           -0.000608623
Policy log std Min           -2.7296371
Z mean eval                  2.6032271
Z variance eval              0.26819295
total_rewards                [ 9395.08574829 10085.78984519 10325.21584261 10160.2408654
 10145.90064918  9498.72618085 10070.67497073  9545.72616282
  9752.33440048  9541.54234947]
total_rewards_mean           9852.123701501554
total_rewards_std            322.72177033122244
total_rewards_max            10325.215842612275
total_rewards_min            9395.085748290154
Number of train steps total  1528000
Number of env steps total    4586000
Number of rollouts total     0
Train Time (s)               151.75052756024525
(Previous) Eval Time (s)     29.329756259918213
Sample Time (s)              10.137114271521568
Epoch Time (s)               191.21739809168503
Total Train Time (s)         70508.35516199237
Epoch                        381
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:26:28.777751 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #381 | Epoch Duration: 191.29765367507935
2020-01-13 23:26:28.777936 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6014514
Z variance train             0.26921648
KL Divergence                73.23281
KL Loss                      7.3232813
QF Loss                      438.7682
VF Loss                      165.85782
Policy Loss                  -2121.248
Q Predictions Mean           2114.4385
Q Predictions Std            996.2096
Q Predictions Max            4700.7505
Q Predictions Min            1580.3992
V Predictions Mean           2114.6665
V Predictions Std            985.8472
V Predictions Max            4644.2563
V Predictions Min            1584.8062
Log Pis Mean                 0.8169148
Log Pis Std                  4.185431
Log Pis Max                  18.89362
Log Pis Min                  -7.4787188
Policy mu Mean               0.09702421
Policy mu Std                1.0442238
Policy mu Max                3.6397002
Policy mu Min                -3.1274865
Policy log std Mean          -0.5345116
Policy log std Std           0.2725688
Policy log std Max           -0.03943622
Policy log std Min           -2.784284
Z mean eval                  2.6206155
Z variance eval              0.35424712
total_rewards                [10455.00866557  4533.99018592 10340.31983439  9901.28712943
 10139.49565846  9755.25579474  9940.25698692 10526.17791882
  9814.70679067  9697.99501094]
total_rewards_mean           9510.449397585744
total_rewards_std            1682.2185307521615
total_rewards_max            10526.177918817959
total_rewards_min            4533.990185919695
Number of train steps total  1532000
Number of env steps total    4598000
Number of rollouts total     0
Train Time (s)               150.9112477377057
(Previous) Eval Time (s)     30.139550059102476
Sample Time (s)              10.054668348282576
Epoch Time (s)               191.10546614509076
Total Train Time (s)         70699.54196097702
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:29:39.968705 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #382 | Epoch Duration: 191.19062495231628
2020-01-13 23:29:39.968905 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #382 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6192682
Z variance train             0.35484472
KL Divergence                69.73495
KL Loss                      6.973495
QF Loss                      16398.91
VF Loss                      74.83017
Policy Loss                  -2007.1862
Q Predictions Mean           2004.96
Q Predictions Std            1101.8242
Q Predictions Max            4688.4214
Q Predictions Min            1333.1239
V Predictions Mean           2004.2715
V Predictions Std            1096.9849
V Predictions Max            4689.9775
V Predictions Min            1349.3975
Log Pis Mean                 0.73538506
Log Pis Std                  3.6291845
Log Pis Max                  15.03303
Log Pis Min                  -6.3788433
Policy mu Mean               -0.014694241
Policy mu Std                1.0052751
Policy mu Max                2.8023767
Policy mu Min                -2.4926558
Policy log std Mean          -0.5077959
Policy log std Std           0.2764722
Policy log std Max           -0.07149705
Policy log std Min           -2.8315372
Z mean eval                  2.5503376
Z variance eval              0.24684572
total_rewards                [10231.05386186 10108.14829164 10403.50193    10251.41555942
 10441.94112496 10395.11283757  5524.60693315 10370.76990548
 10378.31868192 10240.2465203 ]
total_rewards_mean           9834.511564630291
total_rewards_std            1440.0043146543285
total_rewards_max            10441.941124960998
total_rewards_min            5524.606933152771
Number of train steps total  1536000
Number of env steps total    4610000
Number of rollouts total     0
Train Time (s)               150.87188993487507
(Previous) Eval Time (s)     30.19546562200412
Sample Time (s)              9.596994577441365
Epoch Time (s)               190.66435013432056
Total Train Time (s)         70890.3007816025
Epoch                        383
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:32:50.731366 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #383 | Epoch Duration: 190.76230835914612
2020-01-13 23:32:50.731581 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #383 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5503724
Z variance train             0.24767959
KL Divergence                67.19769
KL Loss                      6.7197695
QF Loss                      211.10802
VF Loss                      154.1726
Policy Loss                  -1808.455
Q Predictions Mean           1805.7124
Q Predictions Std            1060.6653
Q Predictions Max            4681.9194
Q Predictions Min            1276.7627
V Predictions Mean           1803.6301
V Predictions Std            1052.8757
V Predictions Max            4660.776
V Predictions Min            1278.7137
Log Pis Mean                 0.25536054
Log Pis Std                  3.7203293
Log Pis Max                  14.289117
Log Pis Min                  -7.8627195
Policy mu Mean               0.093675375
Policy mu Std                0.98710114
Policy mu Max                2.6808913
Policy mu Min                -3.2246022
Policy log std Mean          -0.48152217
Policy log std Std           0.2571169
Policy log std Max           -0.04695213
Policy log std Min           -2.5073566
Z mean eval                  2.4577632
Z variance eval              0.24034241
total_rewards                [10351.0650904  10509.83727677 10415.97492629 10301.50450385
 10588.64913097 10338.6909492  10096.77106201 10183.77443169
 10231.31494347 10615.66319845]
total_rewards_mean           10363.32455130856
total_rewards_std            162.47411222181685
total_rewards_max            10615.663198449414
total_rewards_min            10096.771062012393
Number of train steps total  1540000
Number of env steps total    4622000
Number of rollouts total     0
Train Time (s)               150.4712534751743
(Previous) Eval Time (s)     29.08857473684475
Sample Time (s)              9.697402994148433
Epoch Time (s)               189.2572312061675
Total Train Time (s)         71079.64027218381
Epoch                        384
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:36:00.074718 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #384 | Epoch Duration: 189.34298753738403
2020-01-13 23:36:00.074912 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #384 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.455421
Z variance train             0.24008045
KL Divergence                67.01255
KL Loss                      6.7012553
QF Loss                      297.3496
VF Loss                      58.97547
Policy Loss                  -1700.251
Q Predictions Mean           1697.4904
Q Predictions Std            1070.3451
Q Predictions Max            4634.426
Q Predictions Min            1162.6807
V Predictions Mean           1702.7031
V Predictions Std            1069.9645
V Predictions Max            4626.956
V Predictions Min            1158.391
Log Pis Mean                 0.10741103
Log Pis Std                  3.9493108
Log Pis Max                  13.3951435
Log Pis Min                  -7.1377983
Policy mu Mean               0.029762916
Policy mu Std                0.95051205
Policy mu Max                2.7514632
Policy mu Min                -2.934938
Policy log std Mean          -0.49330345
Policy log std Std           0.28757122
Policy log std Max           0.073194176
Policy log std Min           -2.8805451
Z mean eval                  2.3851235
Z variance eval              0.26184958
total_rewards                [10385.19706488 10536.78434486 10098.03019293  6832.15452936
 10442.67725529 10262.71802962 10433.7467399  10609.36979637
  4623.94953439  5734.2244928 ]
total_rewards_mean           8995.885198038375
total_rewards_std            2198.2291665398925
total_rewards_max            10609.369796370816
total_rewards_min            4623.949534389539
Number of train steps total  1544000
Number of env steps total    4634000
Number of rollouts total     0
Train Time (s)               142.23114715423435
(Previous) Eval Time (s)     29.680570079013705
Sample Time (s)              9.969118554145098
Epoch Time (s)               181.88083578739315
Total Train Time (s)         71261.60058571538
Epoch                        385
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:39:02.040130 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #385 | Epoch Duration: 181.9650523662567
2020-01-13 23:39:02.040380 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #385 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3844135
Z variance train             0.26191455
KL Divergence                65.78156
KL Loss                      6.5781565
QF Loss                      255.11469
VF Loss                      65.08613
Policy Loss                  -1641.718
Q Predictions Mean           1639.862
Q Predictions Std            1146.9366
Q Predictions Max            4694.385
Q Predictions Min            1048.8722
V Predictions Mean           1643.0149
V Predictions Std            1141.1821
V Predictions Max            4669.8843
V Predictions Min            1061.2948
Log Pis Mean                 -0.15287781
Log Pis Std                  3.7461169
Log Pis Max                  13.42171
Log Pis Min                  -8.945791
Policy mu Mean               0.12193027
Policy mu Std                0.9537219
Policy mu Max                3.8080068
Policy mu Min                -3.3134332
Policy log std Mean          -0.46422946
Policy log std Std           0.24793091
Policy log std Max           0.1766068
Policy log std Min           -2.6677828
Z mean eval                  2.289312
Z variance eval              0.30034232
total_rewards                [10367.10933115 10592.1691588  10450.2475435  10530.06967828
 10639.95567318 10220.62417887 10397.70220346 10219.87957856
 10671.29538914 10141.35745923]
total_rewards_mean           10423.041019416447
total_rewards_std            177.43873343065476
total_rewards_max            10671.29538913589
total_rewards_min            10141.357459232608
Number of train steps total  1548000
Number of env steps total    4646000
Number of rollouts total     0
Train Time (s)               141.72415392193943
(Previous) Eval Time (s)     29.802561979740858
Sample Time (s)              9.765096118208021
Epoch Time (s)               181.2918120198883
Total Train Time (s)         71442.97928059148
Epoch                        386
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:42:03.423177 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #386 | Epoch Duration: 181.38261604309082
2020-01-13 23:42:03.423476 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #386 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2868648
Z variance train             0.3011405
KL Divergence                64.002235
KL Loss                      6.4002237
QF Loss                      206.7583
VF Loss                      73.55342
Policy Loss                  -1672.1119
Q Predictions Mean           1669.8232
Q Predictions Std            1239.6454
Q Predictions Max            4647.718
Q Predictions Min            991.7823
V Predictions Mean           1675.0701
V Predictions Std            1240.8401
V Predictions Max            4655.0034
V Predictions Min            1009.36365
Log Pis Mean                 0.3533061
Log Pis Std                  4.4759583
Log Pis Max                  16.888054
Log Pis Min                  -8.132887
Policy mu Mean               0.23158248
Policy mu Std                0.961525
Policy mu Max                2.973708
Policy mu Min                -2.5730176
Policy log std Mean          -0.46273825
Policy log std Std           0.27161554
Policy log std Max           -0.04496491
Policy log std Min           -2.616859
Z mean eval                  2.2869675
Z variance eval              0.22825451
total_rewards                [10331.73144125 10264.53056269  5143.38491937   238.02349294
  9942.47687768 10522.71912548 10244.90163847 10352.29276295
 10237.4046648  10566.05737611]
total_rewards_mean           8784.352286172081
total_rewards_std            3242.25750083562
total_rewards_max            10566.057376110166
total_rewards_min            238.02349293671477
Number of train steps total  1552000
Number of env steps total    4658000
Number of rollouts total     0
Train Time (s)               148.50911592226475
(Previous) Eval Time (s)     30.014760128688067
Sample Time (s)              8.908301945310086
Epoch Time (s)               187.4321779962629
Total Train Time (s)         71630.4968815581
Epoch                        387
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:45:10.945091 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #387 | Epoch Duration: 187.52144980430603
2020-01-13 23:45:10.945302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2896233
Z variance train             0.22911067
KL Divergence                63.50104
KL Loss                      6.3501043
QF Loss                      226.18541
VF Loss                      78.749344
Policy Loss                  -1618.5862
Q Predictions Mean           1613.7732
Q Predictions Std            1214.8707
Q Predictions Max            4782.5654
Q Predictions Min            960.8616
V Predictions Mean           1622.2726
V Predictions Std            1211.3203
V Predictions Max            4750.744
V Predictions Min            966.1615
Log Pis Mean                 -0.030197747
Log Pis Std                  3.9759047
Log Pis Max                  13.070795
Log Pis Min                  -7.3662806
Policy mu Mean               0.083566464
Policy mu Std                0.95561916
Policy mu Max                3.4476335
Policy mu Min                -2.6638954
Policy log std Mean          -0.464775
Policy log std Std           0.284746
Policy log std Max           0.10125762
Policy log std Min           -2.6779754
Z mean eval                  2.2281091
Z variance eval              0.16353081
total_rewards                [10528.41624793 10699.76257887 10537.97079055 10525.30775337
 10522.54377277 10818.9103926  10334.99794208 10844.11891281
 10643.54632402 10617.45164189]
total_rewards_mean           10607.30263568987
total_rewards_std            144.883497649272
total_rewards_max            10844.118912807378
total_rewards_min            10334.99794208328
Number of train steps total  1556000
Number of env steps total    4670000
Number of rollouts total     0
Train Time (s)               150.81499386020005
(Previous) Eval Time (s)     30.39314506482333
Sample Time (s)              10.595635353587568
Epoch Time (s)               191.80377427861094
Total Train Time (s)         71822.64340237109
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:48:23.100839 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #388 | Epoch Duration: 192.15538239479065
2020-01-13 23:48:23.101036 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #388 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2283173
Z variance train             0.16312529
KL Divergence                63.564156
KL Loss                      6.3564157
QF Loss                      187.50421
VF Loss                      57.805565
Policy Loss                  -1467.641
Q Predictions Mean           1465.3613
Q Predictions Std            1139.6692
Q Predictions Max            4715.136
Q Predictions Min            927.5031
V Predictions Mean           1468.737
V Predictions Std            1138.1732
V Predictions Max            4701.1904
V Predictions Min            925.1309
Log Pis Mean                 -0.1841288
Log Pis Std                  4.278549
Log Pis Max                  23.24645
Log Pis Min                  -7.587143
Policy mu Mean               0.08452952
Policy mu Std                0.916285
Policy mu Max                3.315526
Policy mu Min                -3.4473715
Policy log std Mean          -0.44497547
Policy log std Std           0.27403376
Policy log std Max           0.018427312
Policy log std Min           -2.7096505
Z mean eval                  2.2074895
Z variance eval              0.07945659
total_rewards                [10285.99717425 10642.32323636 10768.5923864  10514.6218093
 10629.64057906 10878.5852831  10945.46292812 10639.13613457
 10586.37978408 10893.51033519]
total_rewards_mean           10678.424965043201
total_rewards_std            189.81452274911047
total_rewards_max            10945.462928120704
total_rewards_min            10285.997174247026
Number of train steps total  1560000
Number of env steps total    4682000
Number of rollouts total     0
Train Time (s)               149.98406535573304
(Previous) Eval Time (s)     29.921703823376447
Sample Time (s)              10.444473636802286
Epoch Time (s)               190.35024281591177
Total Train Time (s)         72013.08466694923
Epoch                        389
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:51:33.547786 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #389 | Epoch Duration: 190.4465789794922
2020-01-13 23:51:33.548107 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #389 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2080007
Z variance train             0.07937275
KL Divergence                63.3493
KL Loss                      6.33493
QF Loss                      7168.792
VF Loss                      63.516705
Policy Loss                  -1384.4232
Q Predictions Mean           1382.1716
Q Predictions Std            1110.2786
Q Predictions Max            4660.685
Q Predictions Min            889.943
V Predictions Mean           1379.6051
V Predictions Std            1106.4728
V Predictions Max            4656.764
V Predictions Min            884.6697
Log Pis Mean                 -0.16958788
Log Pis Std                  3.9097066
Log Pis Max                  14.451799
Log Pis Min                  -6.780238
Policy mu Mean               0.10633769
Policy mu Std                0.91592246
Policy mu Max                3.2505534
Policy mu Min                -2.813091
Policy log std Mean          -0.4486178
Policy log std Std           0.27175975
Policy log std Max           0.17706984
Policy log std Min           -2.6784933
Z mean eval                  2.2237518
Z variance eval              0.06975131
total_rewards                [ 9905.85833753 10661.75665223 10576.89020472 10559.36151011
 10604.97402782 10441.57705625 10560.24908414 10486.76054669
 10696.60552767 10393.92672581]
total_rewards_mean           10488.795967296828
total_rewards_std            213.42291670472287
total_rewards_max            10696.605527669995
total_rewards_min            9905.858337526102
Number of train steps total  1564000
Number of env steps total    4694000
Number of rollouts total     0
Train Time (s)               152.0835411301814
(Previous) Eval Time (s)     30.156269383151084
Sample Time (s)              10.32005313737318
Epoch Time (s)               192.55986365070567
Total Train Time (s)         72205.84379228437
Epoch                        390
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:54:46.311374 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #390 | Epoch Duration: 192.7630569934845
2020-01-13 23:54:46.311693 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #390 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2233593
Z variance train             0.06978612
KL Divergence                63.838043
KL Loss                      6.3838043
QF Loss                      6747.819
VF Loss                      54.16436
Policy Loss                  -1470.1991
Q Predictions Mean           1467.7634
Q Predictions Std            1216.411
Q Predictions Max            4748.3765
Q Predictions Min            860.6857
V Predictions Mean           1468.9629
V Predictions Std            1213.5692
V Predictions Max            4734.294
V Predictions Min            842.24634
Log Pis Mean                 -0.24056047
Log Pis Std                  3.823734
Log Pis Max                  13.562925
Log Pis Min                  -7.567049
Policy mu Mean               0.048870485
Policy mu Std                0.9276548
Policy mu Max                2.8384542
Policy mu Min                -3.2365441
Policy log std Mean          -0.44480452
Policy log std Std           0.27729335
Policy log std Max           0.11731374
Policy log std Min           -2.689402
Z mean eval                  2.2043574
Z variance eval              0.057137795
total_rewards                [10061.0945295  10585.31829887 10552.62149391 10360.35342673
  9990.15853592 10640.85359131 10611.22733354 10822.22298049
  9953.58168995 10292.62273008]
total_rewards_mean           10387.005461030081
total_rewards_std            288.4554170116471
total_rewards_max            10822.222980486598
total_rewards_min            9953.581689945584
Number of train steps total  1568000
Number of env steps total    4706000
Number of rollouts total     0
Train Time (s)               148.6035119779408
(Previous) Eval Time (s)     29.46631154883653
Sample Time (s)              10.173214759677649
Epoch Time (s)               188.24303828645498
Total Train Time (s)         72394.16790972976
Epoch                        391
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:57:54.639641 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #391 | Epoch Duration: 188.3277690410614
2020-01-13 23:57:54.639840 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #391 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.205547
Z variance train             0.05704282
KL Divergence                64.05601
KL Loss                      6.405601
QF Loss                      183.84564
VF Loss                      362.3777
Policy Loss                  -1293.8258
Q Predictions Mean           1291.5779
Q Predictions Std            1081.8799
Q Predictions Max            4688.367
Q Predictions Min            822.74426
V Predictions Mean           1292.1436
V Predictions Std            1070.1371
V Predictions Max            4705.1304
V Predictions Min            831.9583
Log Pis Mean                 -0.6068323
Log Pis Std                  3.695311
Log Pis Max                  17.139904
Log Pis Min                  -9.460669
Policy mu Mean               0.13067469
Policy mu Std                0.8318569
Policy mu Max                3.636878
Policy mu Min                -3.713439
Policy log std Mean          -0.4298357
Policy log std Std           0.25917315
Policy log std Max           0.15978491
Policy log std Min           -2.582684
Z mean eval                  2.2071116
Z variance eval              0.09200687
total_rewards                [10266.38288985 10748.46432537 10766.06396306 10532.40952836
 10403.47766825 10743.72704128 10895.19801913 10688.5186926
 10895.78673179 10699.74713513]
total_rewards_mean           10663.977599482874
total_rewards_std            193.9720628865822
total_rewards_max            10895.786731791457
total_rewards_min            10266.382889845956
Number of train steps total  1572000
Number of env steps total    4718000
Number of rollouts total     0
Train Time (s)               141.39732742402703
(Previous) Eval Time (s)     29.935332017950714
Sample Time (s)              9.73982434719801
Epoch Time (s)               181.07248378917575
Total Train Time (s)         72575.33952093543
Epoch                        392
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:00:55.815444 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #392 | Epoch Duration: 181.17545986175537
2020-01-14 00:00:55.815641 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #392 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2055626
Z variance train             0.091814615
KL Divergence                64.22212
KL Loss                      6.422212
QF Loss                      262.71124
VF Loss                      158.11821
Policy Loss                  -1348.1522
Q Predictions Mean           1343.3995
Q Predictions Std            1176.278
Q Predictions Max            4698.399
Q Predictions Min            824.69336
V Predictions Mean           1346.9812
V Predictions Std            1177.2667
V Predictions Max            4681.9097
V Predictions Min            825.6949
Log Pis Mean                 -0.25126964
Log Pis Std                  4.437459
Log Pis Max                  18.501387
Log Pis Min                  -6.54712
Policy mu Mean               0.08995233
Policy mu Std                0.91223526
Policy mu Max                3.457302
Policy mu Min                -2.9259245
Policy log std Mean          -0.42872858
Policy log std Std           0.26454765
Policy log std Max           0.15154159
Policy log std Min           -2.6798143
Z mean eval                  2.2160487
Z variance eval              0.093041524
total_rewards                [10409.34524917 10654.30275265 10871.37363801 10488.89501498
 10840.52029771 10387.76271111 10711.2894441  10381.80130456
 10692.31162351 10538.52533088]
total_rewards_mean           10597.612736668805
total_rewards_std            173.326358077939
total_rewards_max            10871.373638010471
total_rewards_min            10381.801304558552
Number of train steps total  1576000
Number of env steps total    4730000
Number of rollouts total     0
Train Time (s)               141.3968004048802
(Previous) Eval Time (s)     29.172512374818325
Sample Time (s)              9.218463520053774
Epoch Time (s)               179.7877762997523
Total Train Time (s)         72755.24357475154
Epoch                        393
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:03:55.725319 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #393 | Epoch Duration: 179.90950560569763
2020-01-14 00:03:55.725609 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #393 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.213595
Z variance train             0.09309636
KL Divergence                63.233253
KL Loss                      6.3233256
QF Loss                      173.97101
VF Loss                      89.2092
Policy Loss                  -1445.8173
Q Predictions Mean           1445.1221
Q Predictions Std            1261.9858
Q Predictions Max            4800.217
Q Predictions Min            789.2241
V Predictions Mean           1448.4385
V Predictions Std            1262.8956
V Predictions Max            4827.8296
V Predictions Min            789.2538
Log Pis Mean                 -0.5418497
Log Pis Std                  3.9792092
Log Pis Max                  12.590109
Log Pis Min                  -8.243819
Policy mu Mean               0.044996705
Policy mu Std                0.87033105
Policy mu Max                2.9113595
Policy mu Min                -2.9689476
Policy log std Mean          -0.4693896
Policy log std Std           0.28403786
Policy log std Max           0.029907286
Policy log std Min           -2.7035713
Z mean eval                  2.1778016
Z variance eval              0.073853664
total_rewards                [10122.83140983 10619.0001038  10994.59867004 10876.83603024
 11012.91761448 10828.42874595 10438.69116854 10674.10905904
 10797.33702635 10838.85807561]
total_rewards_mean           10720.360790388833
total_rewards_std            258.01519124211745
total_rewards_max            11012.917614481947
total_rewards_min            10122.831409827215
Number of train steps total  1580000
Number of env steps total    4742000
Number of rollouts total     0
Train Time (s)               150.85508693382144
(Previous) Eval Time (s)     30.089921398088336
Sample Time (s)              9.38354688603431
Epoch Time (s)               190.32855521794409
Total Train Time (s)         72945.65923494333
Epoch                        394
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:07:06.148499 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #394 | Epoch Duration: 190.4224886894226
2020-01-14 00:07:06.148949 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #394 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1775506
Z variance train             0.07376878
KL Divergence                62.013943
KL Loss                      6.2013946
QF Loss                      254.9664
VF Loss                      86.29842
Policy Loss                  -1297.2681
Q Predictions Mean           1294.9199
Q Predictions Std            1168.4065
Q Predictions Max            4757.9424
Q Predictions Min            778.6782
V Predictions Mean           1297.5149
V Predictions Std            1162.812
V Predictions Max            4753.6333
V Predictions Min            796.1989
Log Pis Mean                 -0.86271435
Log Pis Std                  3.8524938
Log Pis Max                  14.452904
Log Pis Min                  -8.923112
Policy mu Mean               0.093516566
Policy mu Std                0.84165806
Policy mu Max                2.7760735
Policy mu Min                -2.8923712
Policy log std Mean          -0.44370675
Policy log std Std           0.25828856
Policy log std Max           0.066578865
Policy log std Min           -2.7952907
Z mean eval                  2.178503
Z variance eval              0.11467817
total_rewards                [10118.02462252  9940.38905052  9804.1058516  10300.61276584
  9668.27373601 10724.5037892  10353.45610028  9716.07096376
 10236.27981874 10671.7080172 ]
total_rewards_mean           10153.342471567139
total_rewards_std            354.7677372129817
total_rewards_max            10724.503789200528
total_rewards_min            9668.273736007659
Number of train steps total  1584000
Number of env steps total    4754000
Number of rollouts total     0
Train Time (s)               150.03171206824481
(Previous) Eval Time (s)     30.295365426223725
Sample Time (s)              10.061596950050443
Epoch Time (s)               190.38867444451898
Total Train Time (s)         73136.136734562
Epoch                        395
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:10:16.628134 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #395 | Epoch Duration: 190.4789400100708
2020-01-14 00:10:16.628370 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #395 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1783175
Z variance train             0.11469774
KL Divergence                60.918247
KL Loss                      6.091825
QF Loss                      237.2555
VF Loss                      43.859314
Policy Loss                  -1453.632
Q Predictions Mean           1453.434
Q Predictions Std            1345.316
Q Predictions Max            4798.0747
Q Predictions Min            763.62494
V Predictions Mean           1453.9791
V Predictions Std            1342.2966
V Predictions Max            4785.2876
V Predictions Min            758.3905
Log Pis Mean                 -0.2076458
Log Pis Std                  4.1432314
Log Pis Max                  16.901207
Log Pis Min                  -7.268941
Policy mu Mean               0.094379656
Policy mu Std                0.89163417
Policy mu Max                3.028244
Policy mu Min                -2.958107
Policy log std Mean          -0.43911847
Policy log std Std           0.27239773
Policy log std Max           0.09856266
Policy log std Min           -2.4460092
Z mean eval                  2.1529868
Z variance eval              0.149461
total_rewards                [10000.07167133 10371.31378621 11033.44742925 10458.62717225
 10784.2284769  10609.54027297 10273.89958856 10795.8164066
 10555.16164217 10683.13060718]
total_rewards_mean           10556.523705341273
total_rewards_std            280.85767221610047
total_rewards_max            11033.447429247364
total_rewards_min            10000.071671329588
Number of train steps total  1588000
Number of env steps total    4766000
Number of rollouts total     0
Train Time (s)               149.80465780571103
(Previous) Eval Time (s)     30.907563293818384
Sample Time (s)              9.495234850794077
Epoch Time (s)               190.2074559503235
Total Train Time (s)         73326.42395317508
Epoch                        396
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:13:26.919998 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #396 | Epoch Duration: 190.29140710830688
2020-01-14 00:13:26.920279 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #396 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.156057
Z variance train             0.15006523
KL Divergence                60.401917
KL Loss                      6.0401917
QF Loss                      115.74031
VF Loss                      38.14003
Policy Loss                  -1335.6012
Q Predictions Mean           1334.16
Q Predictions Std            1254.7522
Q Predictions Max            4812.0273
Q Predictions Min            764.2786
V Predictions Mean           1334.3081
V Predictions Std            1253.1594
V Predictions Max            4801.2886
V Predictions Min            761.894
Log Pis Mean                 -0.7067534
Log Pis Std                  3.6539826
Log Pis Max                  14.405063
Log Pis Min                  -6.929966
Policy mu Mean               0.08242143
Policy mu Std                0.82340306
Policy mu Max                3.140565
Policy mu Min                -2.7724428
Policy log std Mean          -0.41968563
Policy log std Std           0.2625324
Policy log std Max           -0.01709634
Policy log std Min           -2.7536314
Z mean eval                  2.146853
Z variance eval              0.107028104
total_rewards                [10026.51563116 10520.17411738 10633.09127422 10390.8387214
 10444.77876181 10306.93410919 10311.46195228 10105.86759492
 10637.2898465  10355.40539307]
total_rewards_mean           10373.235740193162
total_rewards_std            190.91857236669978
total_rewards_max            10637.289846503034
total_rewards_min            10026.515631160164
Number of train steps total  1592000
Number of env steps total    4778000
Number of rollouts total     0
Train Time (s)               151.36820992501453
(Previous) Eval Time (s)     29.44387432280928
Sample Time (s)              10.4026831923984
Epoch Time (s)               191.2147674402222
Total Train Time (s)         73517.72551656468
Epoch                        397
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:16:38.226046 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #397 | Epoch Duration: 191.30557870864868
2020-01-14 00:16:38.226306 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #397 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.147181
Z variance train             0.10715828
KL Divergence                61.20811
KL Loss                      6.120811
QF Loss                      117.23113
VF Loss                      83.624664
Policy Loss                  -1269.0951
Q Predictions Mean           1264.4778
Q Predictions Std            1152.6085
Q Predictions Max            4837.078
Q Predictions Min            649.9493
V Predictions Mean           1270.4141
V Predictions Std            1149.0911
V Predictions Max            4802.8423
V Predictions Min            682.5962
Log Pis Mean                 -0.6245029
Log Pis Std                  3.821157
Log Pis Max                  16.87044
Log Pis Min                  -7.1229906
Policy mu Mean               0.11471689
Policy mu Std                0.8525581
Policy mu Max                3.0612912
Policy mu Min                -3.3081095
Policy log std Mean          -0.43027225
Policy log std Std           0.24298224
Policy log std Max           0.13758552
Policy log std Min           -2.1357079
Z mean eval                  2.1693647
Z variance eval              0.14862102
total_rewards                [10612.56845106 10447.28467403 10909.65207376 10650.84932015
 10699.6923079  10950.00416466 10801.76340644 10776.98671731
 10822.16703663 10695.82190897]
total_rewards_mean           10736.679006090464
total_rewards_std            140.76674396030862
total_rewards_max            10950.004164662609
total_rewards_min            10447.284674030838
Number of train steps total  1596000
Number of env steps total    4790000
Number of rollouts total     0
Train Time (s)               146.6875137402676
(Previous) Eval Time (s)     29.314119735267013
Sample Time (s)              10.11814616061747
Epoch Time (s)               186.1197796361521
Total Train Time (s)         73703.92283977894
Epoch                        398
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:19:44.426624 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #398 | Epoch Duration: 186.2001142501831
2020-01-14 00:19:44.426837 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #398 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1684296
Z variance train             0.14908893
KL Divergence                60.539005
KL Loss                      6.0539007
QF Loss                      181.81154
VF Loss                      73.44434
Policy Loss                  -1430.8346
Q Predictions Mean           1429.1998
Q Predictions Std            1334.7755
Q Predictions Max            4752.2983
Q Predictions Min            713.8017
V Predictions Mean           1429.7153
V Predictions Std            1329.4038
V Predictions Max            4754.4336
V Predictions Min            716.3978
Log Pis Mean                 -0.42070806
Log Pis Std                  4.2642374
Log Pis Max                  16.181015
Log Pis Min                  -8.308363
Policy mu Mean               0.09881469
Policy mu Std                0.8715933
Policy mu Max                4.00822
Policy mu Min                -3.0128055
Policy log std Mean          -0.46581808
Policy log std Std           0.2844673
Policy log std Max           0.108540535
Policy log std Min           -2.720757
Z mean eval                  2.1729186
Z variance eval              0.169788
total_rewards                [10804.01429888 11161.7899945  10635.92097989 10997.87230003
 10636.6798926   3516.49894095 11316.73361534 10646.84368348
 10762.07521419 10635.96086037]
total_rewards_mean           10111.43897802394
total_rewards_std            2210.2194331484875
total_rewards_max            11316.733615340887
total_rewards_min            3516.4989409529862
Number of train steps total  1600000
Number of env steps total    4802000
Number of rollouts total     0
Train Time (s)               142.27582145202905
(Previous) Eval Time (s)     29.3435773588717
Sample Time (s)              9.235566752031446
Epoch Time (s)               180.8549655629322
Total Train Time (s)         73884.86455868371
Epoch                        399
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:22:45.372738 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #399 | Epoch Duration: 180.94574809074402
2020-01-14 00:22:45.372939 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1720881
Z variance train             0.16997252
KL Divergence                60.73785
KL Loss                      6.0737853
QF Loss                      158.37775
VF Loss                      54.576008
Policy Loss                  -1377.537
Q Predictions Mean           1375.429
Q Predictions Std            1325.1725
Q Predictions Max            4812.1147
Q Predictions Min            703.0716
V Predictions Mean           1375.5651
V Predictions Std            1322.3258
V Predictions Max            4803.6025
V Predictions Min            696.7709
Log Pis Mean                 -0.4875871
Log Pis Std                  4.290404
Log Pis Max                  18.254305
Log Pis Min                  -7.362028
Policy mu Mean               0.12941396
Policy mu Std                0.8636473
Policy mu Max                3.2062318
Policy mu Min                -3.8430665
Policy log std Mean          -0.45143524
Policy log std Std           0.28704113
Policy log std Max           0.01011461
Policy log std Min           -2.6655245
Z mean eval                  2.1594107
Z variance eval              0.10502215
total_rewards                [10622.30389434 10697.55941876 10767.1451852  10826.98397264
 10749.96348517 10862.31829719 10947.5031537  11003.53068944
 10791.61262964 10595.26756337]
total_rewards_mean           10786.418828944854
total_rewards_std            123.93059899837742
total_rewards_max            11003.53068944127
total_rewards_min            10595.267563367135
Number of train steps total  1604000
Number of env steps total    4814000
Number of rollouts total     0
Train Time (s)               143.34895763080567
(Previous) Eval Time (s)     30.093408051878214
Sample Time (s)              10.150773474946618
Epoch Time (s)               183.5931391576305
Total Train Time (s)         74068.54061891558
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:25:49.054204 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #400 | Epoch Duration: 183.68103075027466
2020-01-14 00:25:49.054553 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #400 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1633523
Z variance train             0.10529754
KL Divergence                62.088184
KL Loss                      6.2088184
QF Loss                      163.77264
VF Loss                      84.75156
Policy Loss                  -1529.9958
Q Predictions Mean           1526.9739
Q Predictions Std            1421.2139
Q Predictions Max            4800.7095
Q Predictions Min            709.87244
V Predictions Mean           1526.4214
V Predictions Std            1414.5453
V Predictions Max            4797.9316
V Predictions Min            711.9455
Log Pis Mean                 -0.18822199
Log Pis Std                  4.3323174
Log Pis Max                  14.816378
Log Pis Min                  -6.830343
Policy mu Mean               0.07810222
Policy mu Std                0.88719857
Policy mu Max                2.7437685
Policy mu Min                -3.3373487
Policy log std Mean          -0.4763298
Policy log std Std           0.29759553
Policy log std Max           0.04365021
Policy log std Min           -2.8524203
Z mean eval                  2.148768
Z variance eval              0.06987879
total_rewards                [10804.44644848 10937.87561731 10957.24042314 11001.294435
 10911.34653239 10960.97720204 10697.05460196 11155.07695768
 11101.84197703 10757.15355387]
total_rewards_mean           10928.4307748904
total_rewards_std            136.84382534347478
total_rewards_max            11155.076957679643
total_rewards_min            10697.05460195803
Number of train steps total  1608000
Number of env steps total    4826000
Number of rollouts total     0
Train Time (s)               151.59627715032548
(Previous) Eval Time (s)     30.68960709962994
Sample Time (s)              8.001809436362237
Epoch Time (s)               190.28769368631765
Total Train Time (s)         74258.90662112553
Epoch                        401
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:28:59.422829 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #401 | Epoch Duration: 190.36810278892517
2020-01-14 00:28:59.422999 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #401 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1513846
Z variance train             0.06956442
KL Divergence                63.922855
KL Loss                      6.392286
QF Loss                      176.63806
VF Loss                      78.78972
Policy Loss                  -1431.4226
Q Predictions Mean           1424.8805
Q Predictions Std            1350.602
Q Predictions Max            4786.6587
Q Predictions Min            723.773
V Predictions Mean           1426.3328
V Predictions Std            1348.0957
V Predictions Max            4757.6865
V Predictions Min            740.55664
Log Pis Mean                 -0.2888012
Log Pis Std                  4.3895802
Log Pis Max                  16.477043
Log Pis Min                  -7.7345095
Policy mu Mean               0.05216011
Policy mu Std                0.86189264
Policy mu Max                2.9916255
Policy mu Min                -3.064727
Policy log std Mean          -0.47619137
Policy log std Std           0.2887746
Policy log std Max           -0.018660367
Policy log std Min           -3.122126
Z mean eval                  2.2114964
Z variance eval              0.07346866
total_rewards                [ 2801.17695448  7908.84437802  9689.54477042 10379.07689885
 10881.47910718 10890.56282194 10872.86912989 10479.33886406
 10880.66737226 10610.27937241]
total_rewards_mean           9539.383966952217
total_rewards_std            2408.8209828766517
total_rewards_max            10890.562821941732
total_rewards_min            2801.1769544841927
Number of train steps total  1612000
Number of env steps total    4838000
Number of rollouts total     0
Train Time (s)               150.21821032697335
(Previous) Eval Time (s)     30.868986004032195
Sample Time (s)              10.125950280111283
Epoch Time (s)               191.21314661111683
Total Train Time (s)         74450.20125081856
Epoch                        402
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:32:10.721995 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #402 | Epoch Duration: 191.29885506629944
2020-01-14 00:32:10.722206 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2184958
Z variance train             0.07381328
KL Divergence                64.15558
KL Loss                      6.415558
QF Loss                      166.71803
VF Loss                      96.15329
Policy Loss                  -1345.1759
Q Predictions Mean           1342.8986
Q Predictions Std            1259.2146
Q Predictions Max            4887.542
Q Predictions Min            710.4874
V Predictions Mean           1345.3137
V Predictions Std            1252.7667
V Predictions Max            4861.1387
V Predictions Min            724.36176
Log Pis Mean                 -0.57060117
Log Pis Std                  3.762314
Log Pis Max                  16.131706
Log Pis Min                  -7.881884
Policy mu Mean               0.087202944
Policy mu Std                0.8713506
Policy mu Max                3.6104083
Policy mu Min                -2.7409418
Policy log std Mean          -0.4590396
Policy log std Std           0.28950158
Policy log std Max           -0.007062018
Policy log std Min           -3.2120798
Z mean eval                  2.1520085
Z variance eval              0.07533212
total_rewards                [10350.34241146 10494.49841689 10331.09348188 10914.91123146
 10609.5971074  10755.38669797 10901.26074204  5119.38976318
 10585.06916968 10413.72754185]
total_rewards_mean           10047.527656380875
total_rewards_std            1654.6808296904223
total_rewards_max            10914.911231463255
total_rewards_min            5119.389763181861
Number of train steps total  1616000
Number of env steps total    4850000
Number of rollouts total     0
Train Time (s)               149.65775975119323
(Previous) Eval Time (s)     29.9680382469669
Sample Time (s)              9.21773427259177
Epoch Time (s)               188.8435322707519
Total Train Time (s)         74639.13751260983
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:35:19.663232 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #403 | Epoch Duration: 188.94084215164185
2020-01-14 00:35:19.663569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #403 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1526453
Z variance train             0.07582973
KL Divergence                63.207924
KL Loss                      6.3207927
QF Loss                      232.14728
VF Loss                      71.04547
Policy Loss                  -1525.8574
Q Predictions Mean           1522.7407
Q Predictions Std            1430.9849
Q Predictions Max            4825.8994
Q Predictions Min            733.3086
V Predictions Mean           1527.307
V Predictions Std            1434.1014
V Predictions Max            4833.9907
V Predictions Min            736.8785
Log Pis Mean                 -0.23623839
Log Pis Std                  4.1882153
Log Pis Max                  14.320777
Log Pis Min                  -8.651923
Policy mu Mean               0.09283531
Policy mu Std                0.91560984
Policy mu Max                2.80755
Policy mu Min                -3.1410298
Policy log std Mean          -0.47165155
Policy log std Std           0.3161622
Policy log std Max           0.06696069
Policy log std Min           -3.027585
Z mean eval                  2.1730037
Z variance eval              0.06798612
total_rewards                [10650.26244482 10931.25158887 11007.79381907 11126.60659772
 11047.14919383 10771.43454838 11148.19767499 11154.73626905
 11147.70043204 10993.73112283]
total_rewards_mean           10997.886369159287
total_rewards_std            162.8845584493834
total_rewards_max            11154.736269045909
total_rewards_min            10650.262444817135
Number of train steps total  1620000
Number of env steps total    4862000
Number of rollouts total     0
Train Time (s)               150.60835672775283
(Previous) Eval Time (s)     29.780178328976035
Sample Time (s)              10.499064464122057
Epoch Time (s)               190.88759952085093
Total Train Time (s)         74830.11015981482
Epoch                        404
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:38:30.640893 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #404 | Epoch Duration: 190.97709774971008
2020-01-14 00:38:30.641275 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #404 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.173223
Z variance train             0.06804798
KL Divergence                63.920673
KL Loss                      6.3920674
QF Loss                      167.8089
VF Loss                      59.33467
Policy Loss                  -1313.3711
Q Predictions Mean           1308.1136
Q Predictions Std            1222.2888
Q Predictions Max            4828.1953
Q Predictions Min            738.9835
V Predictions Mean           1313.1095
V Predictions Std            1222.5336
V Predictions Max            4835.88
V Predictions Min            743.8149
Log Pis Mean                 -0.4519642
Log Pis Std                  4.074102
Log Pis Max                  15.649597
Log Pis Min                  -8.479979
Policy mu Mean               0.15634352
Policy mu Std                0.83676475
Policy mu Max                3.2867646
Policy mu Min                -2.8152509
Policy log std Mean          -0.44265422
Policy log std Std           0.28006792
Policy log std Max           -0.026701987
Policy log std Min           -3.0051212
Z mean eval                  2.1939828
Z variance eval              0.13471553
total_rewards                [ 9870.17344825  9804.64418004 10191.79740759  9637.77708488
 10097.58467667  9889.66061772 10402.48655538 10435.56648827
  9641.53259256 10490.67938029]
total_rewards_mean           10046.190243165333
total_rewards_std            307.30301135819343
total_rewards_max            10490.679380289095
total_rewards_min            9637.77708487866
Number of train steps total  1624000
Number of env steps total    4874000
Number of rollouts total     0
Train Time (s)               144.23613695800304
(Previous) Eval Time (s)     29.480133056640625
Sample Time (s)              9.035765691660345
Epoch Time (s)               182.752035706304
Total Train Time (s)         75012.94908346422
Epoch                        405
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:41:33.486729 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #405 | Epoch Duration: 182.84524631500244
2020-01-14 00:41:33.487044 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #405 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.194383
Z variance train             0.1351169
KL Divergence                62.625805
KL Loss                      6.2625804
QF Loss                      164.57973
VF Loss                      57.10408
Policy Loss                  -1260.4474
Q Predictions Mean           1256.29
Q Predictions Std            1164.6716
Q Predictions Max            4843.93
Q Predictions Min            633.80566
V Predictions Mean           1260.467
V Predictions Std            1162.294
V Predictions Max            4839.578
V Predictions Min            634.58734
Log Pis Mean                 -0.70497406
Log Pis Std                  3.88498
Log Pis Max                  14.535854
Log Pis Min                  -7.0955515
Policy mu Mean               0.10420334
Policy mu Std                0.821186
Policy mu Max                3.225862
Policy mu Min                -2.6940145
Policy log std Mean          -0.45983306
Policy log std Std           0.26128194
Policy log std Max           0.46855378
Policy log std Min           -2.5475192
Z mean eval                  2.143784
Z variance eval              0.0780925
total_rewards                [10713.10342596 10800.20598331 10910.34627707 10667.58745957
 10828.06963155 10143.21801274 10643.82492188 10841.78346487
 10754.36959533 11021.40087523]
total_rewards_mean           10732.390964751517
total_rewards_std            223.81646490060194
total_rewards_max            11021.400875226263
total_rewards_min            10143.21801274302
Number of train steps total  1628000
Number of env steps total    4886000
Number of rollouts total     0
Train Time (s)               141.49246480874717
(Previous) Eval Time (s)     29.671142135281116
Sample Time (s)              9.675611065234989
Epoch Time (s)               180.83921800926328
Total Train Time (s)         75193.87110782182
Epoch                        406
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:44:34.409082 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #406 | Epoch Duration: 180.92176222801208
2020-01-14 00:44:34.409281 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #406 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1442468
Z variance train             0.078281686
KL Divergence                62.863796
KL Loss                      6.28638
QF Loss                      4887.234
VF Loss                      56.475136
Policy Loss                  -1340.3901
Q Predictions Mean           1341.0902
Q Predictions Std            1286.6826
Q Predictions Max            4848.311
Q Predictions Min            692.7742
V Predictions Mean           1343.514
V Predictions Std            1285.547
V Predictions Max            4837.0933
V Predictions Min            701.9223
Log Pis Mean                 -0.72573686
Log Pis Std                  3.3940587
Log Pis Max                  11.97411
Log Pis Min                  -7.116168
Policy mu Mean               0.15304066
Policy mu Std                0.8421289
Policy mu Max                3.107053
Policy mu Min                -2.6936882
Policy log std Mean          -0.45002213
Policy log std Std           0.27620482
Policy log std Max           0.063878894
Policy log std Min           -2.7507038
Z mean eval                  2.1592293
Z variance eval              0.10086571
total_rewards                [10677.60106962 10772.94772399 10803.2226345  10571.51607694
 10243.80516057 10887.33143279 10630.86880617 10570.00856083
 10531.84695287 10537.93102082]
total_rewards_mean           10622.707943910018
total_rewards_std            171.0762954528262
total_rewards_max            10887.331432791772
total_rewards_min            10243.805160566291
Number of train steps total  1632000
Number of env steps total    4898000
Number of rollouts total     0
Train Time (s)               144.91837149579078
(Previous) Eval Time (s)     30.613097237888724
Sample Time (s)              9.55124267237261
Epoch Time (s)               185.0827114060521
Total Train Time (s)         75379.03315661335
Epoch                        407
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:47:39.575422 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #407 | Epoch Duration: 185.16599225997925
2020-01-14 00:47:39.575623 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1603622
Z variance train             0.10078038
KL Divergence                63.776794
KL Loss                      6.3776793
QF Loss                      125.83009
VF Loss                      52.845993
Policy Loss                  -1283.9316
Q Predictions Mean           1281.0532
Q Predictions Std            1221.6602
Q Predictions Max            4888.177
Q Predictions Min            723.1533
V Predictions Mean           1285.3088
V Predictions Std            1224.0778
V Predictions Max            4912.617
V Predictions Min            730.2335
Log Pis Mean                 -0.71404016
Log Pis Std                  3.6091752
Log Pis Max                  11.829792
Log Pis Min                  -6.550174
Policy mu Mean               0.13146013
Policy mu Std                0.8294927
Policy mu Max                2.6182427
Policy mu Min                -2.4466505
Policy log std Mean          -0.466104
Policy log std Std           0.2548197
Policy log std Max           -0.0508911
Policy log std Min           -2.6858213
Z mean eval                  2.1442099
Z variance eval              0.10755211
total_rewards                [10755.7542916  10621.10923939 11177.88357993 10797.01756595
 10856.02027923 10860.22617839 10924.0399791   6413.03277941
 11041.67057893 11166.20216243]
total_rewards_mean           10461.295663436047
total_rewards_std            1359.7683506175845
total_rewards_max            11177.88357992784
total_rewards_min            6413.032779413083
Number of train steps total  1636000
Number of env steps total    4910000
Number of rollouts total     0
Train Time (s)               152.51472429698333
(Previous) Eval Time (s)     29.40596942882985
Sample Time (s)              10.117505042813718
Epoch Time (s)               192.0381987686269
Total Train Time (s)         75571.15701562911
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:50:51.704750 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #408 | Epoch Duration: 192.1289598941803
2020-01-14 00:50:51.705036 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #408 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.145806
Z variance train             0.106917575
KL Divergence                62.544502
KL Loss                      6.2544503
QF Loss                      213.0179
VF Loss                      111.888115
Policy Loss                  -1443.125
Q Predictions Mean           1438.0295
Q Predictions Std            1355.3221
Q Predictions Max            4861.151
Q Predictions Min            717.0104
V Predictions Mean           1439.2566
V Predictions Std            1352.394
V Predictions Max            4846.7485
V Predictions Min            737.7775
Log Pis Mean                 -0.17814729
Log Pis Std                  4.443618
Log Pis Max                  14.60902
Log Pis Min                  -6.9765916
Policy mu Mean               0.09814867
Policy mu Std                0.89994144
Policy mu Max                3.207757
Policy mu Min                -2.7949066
Policy log std Mean          -0.48923782
Policy log std Std           0.30566624
Policy log std Max           -0.04226899
Policy log std Min           -2.9390395
Z mean eval                  2.1623716
Z variance eval              0.046946324
total_rewards                [10944.97533734 10934.49464805 10832.29219521 10961.1197464
 11039.89427246 11109.33657326 10800.50571154 11020.02969387
 10883.96891809 11240.48897987]
total_rewards_mean           10976.71060760977
total_rewards_std            125.130191785552
total_rewards_max            11240.488979871649
total_rewards_min            10800.505711537975
Number of train steps total  1640000
Number of env steps total    4922000
Number of rollouts total     0
Train Time (s)               151.33433318231255
(Previous) Eval Time (s)     29.15768810501322
Sample Time (s)              9.98542804736644
Epoch Time (s)               190.4774493346922
Total Train Time (s)         75761.71441632556
Epoch                        409
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:54:02.266234 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #409 | Epoch Duration: 190.5610249042511
2020-01-14 00:54:02.266435 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #409 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1636367
Z variance train             0.047538158
KL Divergence                64.0214
KL Loss                      6.40214
QF Loss                      315.14893
VF Loss                      40.838295
Policy Loss                  -1319.9696
Q Predictions Mean           1312.8771
Q Predictions Std            1275.4376
Q Predictions Max            4847.168
Q Predictions Min            508.87122
V Predictions Mean           1319.721
V Predictions Std            1273.3627
V Predictions Max            4852.314
V Predictions Min            520.2607
Log Pis Mean                 -0.62401795
Log Pis Std                  4.002331
Log Pis Max                  17.856966
Log Pis Min                  -7.0488586
Policy mu Mean               0.12880635
Policy mu Std                0.8608475
Policy mu Max                3.7991018
Policy mu Min                -3.1269782
Policy log std Mean          -0.47884354
Policy log std Std           0.27431968
Policy log std Max           -0.06597847
Policy log std Min           -2.7811446
Z mean eval                  2.1630838
Z variance eval              0.04041282
total_rewards                [10612.51122257 11081.16202943 10883.90080394 11184.27339312
 10907.40608706 11060.1212231  10813.80190773 10911.43612309
 10500.59120308 10536.23723634]
total_rewards_mean           10849.144122945498
total_rewards_std            222.66165126024342
total_rewards_max            11184.273393120335
total_rewards_min            10500.591203075399
Number of train steps total  1644000
Number of env steps total    4934000
Number of rollouts total     0
Train Time (s)               152.00089874770492
(Previous) Eval Time (s)     31.144922392908484
Sample Time (s)              10.23048403300345
Epoch Time (s)               193.37630517361686
Total Train Time (s)         75955.18515097164
Epoch                        410
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:57:15.741365 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #410 | Epoch Duration: 193.47477650642395
2020-01-14 00:57:15.741575 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #410 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1643317
Z variance train             0.040302895
KL Divergence                63.833668
KL Loss                      6.383367
QF Loss                      4795.652
VF Loss                      198.20424
Policy Loss                  -1393.8188
Q Predictions Mean           1389.9707
Q Predictions Std            1334.7441
Q Predictions Max            4761.5225
Q Predictions Min            497.49835
V Predictions Mean           1388.328
V Predictions Std            1327.5687
V Predictions Max            4739.301
V Predictions Min            510.6148
Log Pis Mean                 -0.0075104088
Log Pis Std                  4.7178473
Log Pis Max                  24.323391
Log Pis Min                  -7.1900826
Policy mu Mean               0.11722889
Policy mu Std                0.9249292
Policy mu Max                5.022963
Policy mu Min                -3.4014611
Policy log std Mean          -0.48715726
Policy log std Std           0.30174482
Policy log std Max           0.07354188
Policy log std Min           -3.0305567
Z mean eval                  2.1886823
Z variance eval              0.051995516
total_rewards                [10677.74167589 10822.64551045 11158.48243066 10757.77408543
 11011.43509572  9626.66291959 10376.31804082 10683.18540925
 10885.13392577 10688.551405  ]
total_rewards_mean           10668.793049857068
total_rewards_std            400.97946206699527
total_rewards_max            11158.482430656491
total_rewards_min            9626.66291959315
Number of train steps total  1648000
Number of env steps total    4946000
Number of rollouts total     0
Train Time (s)               151.60488577000797
(Previous) Eval Time (s)     28.087037179153413
Sample Time (s)              9.719364150427282
Epoch Time (s)               189.41128709958866
Total Train Time (s)         76144.67733254516
Epoch                        411
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:00:25.238346 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #411 | Epoch Duration: 189.49662899971008
2020-01-14 01:00:25.238484 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #411 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1878564
Z variance train             0.05193147
KL Divergence                63.841816
KL Loss                      6.3841815
QF Loss                      104.38439
VF Loss                      84.935616
Policy Loss                  -1374.1476
Q Predictions Mean           1371.324
Q Predictions Std            1351.8646
Q Predictions Max            4860.6035
Q Predictions Min            701.96326
V Predictions Mean           1371.5298
V Predictions Std            1345.5034
V Predictions Max            4870.335
V Predictions Min            714.69385
Log Pis Mean                 -0.54965985
Log Pis Std                  4.18756
Log Pis Max                  18.260359
Log Pis Min                  -7.383788
Policy mu Mean               0.030683016
Policy mu Std                0.870063
Policy mu Max                2.782611
Policy mu Min                -3.149963
Policy log std Mean          -0.4651257
Policy log std Std           0.2787378
Policy log std Max           -0.0037499666
Policy log std Min           -3.1658387
Z mean eval                  2.1597388
Z variance eval              0.060587786
total_rewards                [11165.85978861 11019.41940588 11093.90308567 11263.83435793
 10672.30036281 11227.39530893 10994.21927659 10915.46051368
 11029.7634449  11090.99271683]
total_rewards_mean           11047.314826180562
total_rewards_std            161.04892746442553
total_rewards_max            11263.834357925825
total_rewards_min            10672.300362806378
Number of train steps total  1652000
Number of env steps total    4958000
Number of rollouts total     0
Train Time (s)               141.22421054821461
(Previous) Eval Time (s)     29.435807213187218
Sample Time (s)              9.618036224972457
Epoch Time (s)               180.2780539863743
Total Train Time (s)         76325.04535601521
Epoch                        412
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:03:25.611106 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #412 | Epoch Duration: 180.37250518798828
2020-01-14 01:03:25.611336 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #412 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.153221
Z variance train             0.060359497
KL Divergence                61.174656
KL Loss                      6.1174655
QF Loss                      91.60149
VF Loss                      30.138515
Policy Loss                  -1293.7992
Q Predictions Mean           1293.5236
Q Predictions Std            1271.5553
Q Predictions Max            4774.5693
Q Predictions Min            711.5584
V Predictions Mean           1294.4572
V Predictions Std            1270.1342
V Predictions Max            4772.905
V Predictions Min            714.2286
Log Pis Mean                 -0.76736397
Log Pis Std                  3.9356792
Log Pis Max                  14.719633
Log Pis Min                  -6.9411907
Policy mu Mean               0.09861949
Policy mu Std                0.8089905
Policy mu Max                2.7569933
Policy mu Min                -2.5577767
Policy log std Mean          -0.43896517
Policy log std Std           0.27234647
Policy log std Max           -0.087818295
Policy log std Min           -3.149591
Z mean eval                  2.1282506
Z variance eval              0.09147829
total_rewards                [ 2927.40418891 11144.84637279 11278.16061753 11222.22769985
 10843.72878767 10498.47126432 11325.72178068  5262.08054521
 11328.07814454  9603.57981918]
total_rewards_mean           9543.429922068233
total_rewards_std            2818.899942607153
total_rewards_max            11328.07814453926
total_rewards_min            2927.4041889080318
Number of train steps total  1656000
Number of env steps total    4970000
Number of rollouts total     0
Train Time (s)               141.70312822889537
(Previous) Eval Time (s)     28.667046851012856
Sample Time (s)              9.319258688017726
Epoch Time (s)               179.68943376792595
Total Train Time (s)         76504.8179789409
Epoch                        413
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:06:25.389276 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #413 | Epoch Duration: 179.77772402763367
2020-01-14 01:06:25.389567 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1268113
Z variance train             0.0916278
KL Divergence                59.83889
KL Loss                      5.983889
QF Loss                      155.00098
VF Loss                      67.79796
Policy Loss                  -1441.4227
Q Predictions Mean           1440.2948
Q Predictions Std            1394.0754
Q Predictions Max            4913.8647
Q Predictions Min            717.8056
V Predictions Mean           1441.2422
V Predictions Std            1395.306
V Predictions Max            4923.6953
V Predictions Min            725.8858
Log Pis Mean                 -0.22303413
Log Pis Std                  4.3190303
Log Pis Max                  14.383923
Log Pis Min                  -7.69355
Policy mu Mean               0.11641366
Policy mu Std                0.88403386
Policy mu Max                2.8601131
Policy mu Min                -2.822669
Policy log std Mean          -0.48169065
Policy log std Std           0.31572497
Policy log std Max           0.014514685
Policy log std Min           -3.2666101
Z mean eval                  2.15389
Z variance eval              0.0738034
total_rewards                [10734.96070337 10999.51578246 10829.8765496  11277.29199502
 11302.46283941 11032.80451716 10239.19243801 10547.98323697
 10380.94273768 11102.92249474]
total_rewards_mean           10844.795329443028
total_rewards_std            347.0916513588817
total_rewards_max            11302.462839405513
total_rewards_min            10239.192438014996
Number of train steps total  1660000
Number of env steps total    4982000
Number of rollouts total     0
Train Time (s)               148.2855996848084
(Previous) Eval Time (s)     28.96353119891137
Sample Time (s)              9.386873858515173
Epoch Time (s)               186.63600474223495
Total Train Time (s)         76691.53917667875
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:09:32.114668 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #414 | Epoch Duration: 186.7249050140381
2020-01-14 01:09:32.114931 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #414 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1535506
Z variance train             0.07402763
KL Divergence                58.887543
KL Loss                      5.8887544
QF Loss                      151.30301
VF Loss                      98.23858
Policy Loss                  -1244.6484
Q Predictions Mean           1243.2529
Q Predictions Std            1202.669
Q Predictions Max            4916.0195
Q Predictions Min            524.4237
V Predictions Mean           1249.7083
V Predictions Std            1207.7222
V Predictions Max            4906.3857
V Predictions Min            529.0353
Log Pis Mean                 -0.9676186
Log Pis Std                  3.8605897
Log Pis Max                  18.542093
Log Pis Min                  -7.5940943
Policy mu Mean               0.0379134
Policy mu Std                0.831556
Policy mu Max                2.7481046
Policy mu Min                -3.0489235
Policy log std Mean          -0.43252337
Policy log std Std           0.2518703
Policy log std Max           -0.05473423
Policy log std Min           -2.9869602
Z mean eval                  2.1579263
Z variance eval              0.08151627
total_rewards                [10037.51192212 10328.14178677 10475.56670758 10360.97235322
 10745.10855579 10350.60064306 10288.43246094 10443.49543727
 10797.14933355  2382.30948724]
total_rewards_mean           9620.928868753888
total_rewards_std            2421.8019025212116
total_rewards_max            10797.149333548496
total_rewards_min            2382.309487244994
Number of train steps total  1664000
Number of env steps total    4994000
Number of rollouts total     0
Train Time (s)               152.2316867429763
(Previous) Eval Time (s)     30.550877165049314
Sample Time (s)              10.098543733824044
Epoch Time (s)               192.88110764184967
Total Train Time (s)         76884.51536573097
Epoch                        415
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:12:45.096065 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #415 | Epoch Duration: 192.98095726966858
2020-01-14 01:12:45.096377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.158486
Z variance train             0.0817322
KL Divergence                59.026203
KL Loss                      5.9026203
QF Loss                      105.503876
VF Loss                      35.02312
Policy Loss                  -1451.358
Q Predictions Mean           1449.705
Q Predictions Std            1408.4031
Q Predictions Max            4905.6206
Q Predictions Min            523.64343
V Predictions Mean           1449.7329
V Predictions Std            1404.9254
V Predictions Max            4889.886
V Predictions Min            540.6254
Log Pis Mean                 -0.6126414
Log Pis Std                  3.8139203
Log Pis Max                  14.5660715
Log Pis Min                  -8.649044
Policy mu Mean               0.1480046
Policy mu Std                0.85329354
Policy mu Max                2.6605408
Policy mu Min                -2.4353716
Policy log std Mean          -0.45673552
Policy log std Std           0.27513
Policy log std Max           0.025611877
Policy log std Min           -2.7794697
Z mean eval                  2.1701584
Z variance eval              0.10476418
total_rewards                [10630.52526079 10367.93201173 10774.48627212 11279.66735047
 10577.99492086 10418.94345798 10693.81701486 10614.00628885
 10850.73825283 10956.35935892]
total_rewards_mean           10716.44701894293
total_rewards_std            253.7137352241112
total_rewards_max            11279.667350467695
total_rewards_min            10367.932011732923
Number of train steps total  1668000
Number of env steps total    5006000
Number of rollouts total     0
Train Time (s)               151.81260487018153
(Previous) Eval Time (s)     30.31918539572507
Sample Time (s)              10.056748802773654
Epoch Time (s)               192.18853906868026
Total Train Time (s)         77076.80405499972
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:15:57.390033 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #416 | Epoch Duration: 192.29344296455383
2020-01-14 01:15:57.390361 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #416 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1701932
Z variance train             0.10491202
KL Divergence                59.437477
KL Loss                      5.943748
QF Loss                      1384.1189
VF Loss                      73.80251
Policy Loss                  -1274.5647
Q Predictions Mean           1272.8475
Q Predictions Std            1242.08
Q Predictions Max            4864.849
Q Predictions Min            687.9165
V Predictions Mean           1273.8331
V Predictions Std            1239.9495
V Predictions Max            4834.9233
V Predictions Min            697.0584
Log Pis Mean                 -0.35354802
Log Pis Std                  3.7962673
Log Pis Max                  16.787102
Log Pis Min                  -6.167962
Policy mu Mean               0.12296154
Policy mu Std                0.8300491
Policy mu Max                2.6841135
Policy mu Min                -2.3762543
Policy log std Mean          -0.46695256
Policy log std Std           0.26363102
Policy log std Max           -0.08804542
Policy log std Min           -2.5871928
Z mean eval                  2.1468241
Z variance eval              0.07864343
total_rewards                [10664.52080827 10851.5377463  10911.42901988 10858.55174246
 11103.75374883 10867.27325576 10754.98819365 11250.59600864
 10996.80830009 10896.75522943]
total_rewards_mean           10915.621405330076
total_rewards_std            159.0981860300034
total_rewards_max            11250.596008635019
total_rewards_min            10664.520808273635
Number of train steps total  1672000
Number of env steps total    5018000
Number of rollouts total     0
Train Time (s)               152.8507269588299
(Previous) Eval Time (s)     29.980469711124897
Sample Time (s)              9.978347653988749
Epoch Time (s)               192.80954432394356
Total Train Time (s)         77270.09299127432
Epoch                        417
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:19:10.683032 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #417 | Epoch Duration: 193.29246163368225
2020-01-14 01:19:10.683399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #417 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.147559
Z variance train             0.078412764
KL Divergence                59.592834
KL Loss                      5.9592834
QF Loss                      102.56743
VF Loss                      83.60509
Policy Loss                  -1319.0657
Q Predictions Mean           1319.2761
Q Predictions Std            1311.251
Q Predictions Max            4946.1523
Q Predictions Min            526.71136
V Predictions Mean           1315.9915
V Predictions Std            1304.3525
V Predictions Max            4917.618
V Predictions Min            534.1667
Log Pis Mean                 -0.5686754
Log Pis Std                  3.5879872
Log Pis Max                  11.633821
Log Pis Min                  -5.5802555
Policy mu Mean               0.101070195
Policy mu Std                0.8309507
Policy mu Max                2.6871467
Policy mu Min                -2.8901258
Policy log std Mean          -0.45119634
Policy log std Std           0.26748288
Policy log std Max           -0.038736552
Policy log std Min           -2.9054906
Z mean eval                  2.2002928
Z variance eval              0.07375677
total_rewards                [10779.27193794  4886.17387463 10890.17728943 10751.35881265
 11072.19865658 10313.2259813  10648.84545955 10783.03397722
 10674.74173376 10462.10960793]
total_rewards_mean           10126.113733098575
total_rewards_std            1758.0408453852945
total_rewards_max            11072.198656583303
total_rewards_min            4886.173874626379
Number of train steps total  1676000
Number of env steps total    5030000
Number of rollouts total     0
Train Time (s)               150.43648746423423
(Previous) Eval Time (s)     27.447414603084326
Sample Time (s)              10.22050186432898
Epoch Time (s)               188.10440393164754
Total Train Time (s)         77458.27781041479
Epoch                        418
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:22:18.869760 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #418 | Epoch Duration: 188.18617224693298
2020-01-14 01:22:18.869894 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #418 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1997132
Z variance train             0.07359685
KL Divergence                60.21559
KL Loss                      6.0215592
QF Loss                      59.210667
VF Loss                      27.973719
Policy Loss                  -1210.7775
Q Predictions Mean           1208.7202
Q Predictions Std            1185.6627
Q Predictions Max            4925.733
Q Predictions Min            716.6775
V Predictions Mean           1209.3745
V Predictions Std            1184.8193
V Predictions Max            4923.749
V Predictions Min            709.7122
Log Pis Mean                 -0.8801606
Log Pis Std                  3.7776673
Log Pis Max                  21.639977
Log Pis Min                  -8.31611
Policy mu Mean               0.04915786
Policy mu Std                0.8024191
Policy mu Max                3.740834
Policy mu Min                -3.2045453
Policy log std Mean          -0.45654145
Policy log std Std           0.23887071
Policy log std Max           0.15013099
Policy log std Min           -2.3271894
Z mean eval                  2.1568923
Z variance eval              0.07403515
total_rewards                [10558.27835932 11274.03436379 10911.58308537 11165.66045869
 11080.56571564 10781.03973225 11293.1453884  11174.53856396
 11145.76047306 11347.73056594]
total_rewards_mean           11073.233670642036
total_rewards_std            237.66301732244258
total_rewards_max            11347.730565942835
total_rewards_min            10558.278359321766
Number of train steps total  1680000
Number of env steps total    5042000
Number of rollouts total     0
Train Time (s)               141.9925695778802
(Previous) Eval Time (s)     28.837026461958885
Sample Time (s)              9.557479234877974
Epoch Time (s)               180.38707527471706
Total Train Time (s)         77638.74316200754
Epoch                        419
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:25:19.339976 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #419 | Epoch Duration: 180.4699728488922
2020-01-14 01:25:19.340189 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #419 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1574535
Z variance train             0.07382781
KL Divergence                61.80639
KL Loss                      6.180639
QF Loss                      171.8843
VF Loss                      51.301746
Policy Loss                  -1281.4856
Q Predictions Mean           1281.229
Q Predictions Std            1259.8322
Q Predictions Max            4928.5854
Q Predictions Min            702.72815
V Predictions Mean           1283.99
V Predictions Std            1259.6918
V Predictions Max            4929.0454
V Predictions Min            704.60944
Log Pis Mean                 -0.88962436
Log Pis Std                  3.8893876
Log Pis Max                  14.229957
Log Pis Min                  -8.174867
Policy mu Mean               0.055543598
Policy mu Std                0.80891967
Policy mu Max                2.6364038
Policy mu Min                -2.5606937
Policy log std Mean          -0.47405085
Policy log std Std           0.257751
Policy log std Max           -0.10298839
Policy log std Min           -2.5736208
Z mean eval                  2.1342628
Z variance eval              0.057791293
total_rewards                [10916.59130768 10555.35752872 10224.97233999 11064.41113757
  9883.20709453 11432.66297317 11200.08625504 11017.71069664
 11137.93572493 10847.81594241]
total_rewards_mean           10828.075100066397
total_rewards_std            450.6503040458945
total_rewards_max            11432.662973169956
total_rewards_min            9883.207094526279
Number of train steps total  1684000
Number of env steps total    5054000
Number of rollouts total     0
Train Time (s)               141.6551666231826
(Previous) Eval Time (s)     29.690892028156668
Sample Time (s)              10.110810628160834
Epoch Time (s)               181.4568692795001
Total Train Time (s)         77820.28642531112
Epoch                        420
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:28:20.887824 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #420 | Epoch Duration: 181.54748606681824
2020-01-14 01:28:20.888048 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1356425
Z variance train             0.05780537
KL Divergence                60.884125
KL Loss                      6.088413
QF Loss                      123.768364
VF Loss                      43.932213
Policy Loss                  -1278.7313
Q Predictions Mean           1273.8568
Q Predictions Std            1265.0919
Q Predictions Max            4827.679
Q Predictions Min            441.18597
V Predictions Mean           1276.5579
V Predictions Std            1258.3752
V Predictions Max            4801.752
V Predictions Min            453.22348
Log Pis Mean                 -0.61637664
Log Pis Std                  3.8259244
Log Pis Max                  17.439491
Log Pis Min                  -7.9480505
Policy mu Mean               0.10771358
Policy mu Std                0.863561
Policy mu Max                3.311995
Policy mu Min                -2.7994363
Policy log std Mean          -0.46141413
Policy log std Std           0.2802381
Policy log std Max           0.06761086
Policy log std Min           -2.9066548
Z mean eval                  2.144239
Z variance eval              0.04308609
total_rewards                [11063.18024407 11210.82723349 11300.12954732 11396.12465242
 11252.99151357 10652.67778968 11396.14797898 11227.71336302
 11326.44636709 11184.33274618]
total_rewards_mean           11201.057143581967
total_rewards_std            206.19466864243748
total_rewards_max            11396.147978980469
total_rewards_min            10652.677789681193
Number of train steps total  1688000
Number of env steps total    5066000
Number of rollouts total     0
Train Time (s)               149.55487728025764
(Previous) Eval Time (s)     30.519681703299284
Sample Time (s)              9.469184270594269
Epoch Time (s)               189.5437432541512
Total Train Time (s)         78009.91086813575
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:31:30.516475 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #421 | Epoch Duration: 189.6282720565796
2020-01-14 01:31:30.516675 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #421 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.142936
Z variance train             0.043056242
KL Divergence                61.90579
KL Loss                      6.190579
QF Loss                      226.3121
VF Loss                      93.31846
Policy Loss                  -1400.1232
Q Predictions Mean           1394.3433
Q Predictions Std            1370.154
Q Predictions Max            4929.4
Q Predictions Min            458.6863
V Predictions Mean           1394.8821
V Predictions Std            1363.4595
V Predictions Max            4909.5117
V Predictions Min            470.19754
Log Pis Mean                 -0.3702909
Log Pis Std                  4.279883
Log Pis Max                  14.241041
Log Pis Min                  -6.573271
Policy mu Mean               0.15473075
Policy mu Std                0.86661553
Policy mu Max                2.6635792
Policy mu Min                -2.6882658
Policy log std Mean          -0.486817
Policy log std Std           0.31116277
Policy log std Max           -0.053080916
Policy log std Min           -3.0603242
Z mean eval                  2.144688
Z variance eval              0.06772201
total_rewards                [10646.32706341 10742.65541563 10920.96662002 10819.22996186
 10866.10735754 10679.21286742 10771.56818907 10382.91917323
 11177.89077709 10489.20043246]
total_rewards_mean           10749.607785772876
total_rewards_std            212.04599583290798
total_rewards_max            11177.89077709338
total_rewards_min            10382.91917322975
Number of train steps total  1692000
Number of env steps total    5078000
Number of rollouts total     0
Train Time (s)               150.6056455769576
(Previous) Eval Time (s)     28.10443121008575
Sample Time (s)              10.645512415096164
Epoch Time (s)               189.35558920213953
Total Train Time (s)         78199.35397991259
Epoch                        422
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:34:39.966489 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #422 | Epoch Duration: 189.4496169090271
2020-01-14 01:34:39.966751 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #422 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1447423
Z variance train             0.06747916
KL Divergence                62.259365
KL Loss                      6.2259364
QF Loss                      229.2892
VF Loss                      104.30377
Policy Loss                  -1416.6075
Q Predictions Mean           1416.3315
Q Predictions Std            1409.8799
Q Predictions Max            4952.698
Q Predictions Min            477.45547
V Predictions Mean           1411.8536
V Predictions Std            1401.0559
V Predictions Max            4925.63
V Predictions Min            485.37268
Log Pis Mean                 -0.24948597
Log Pis Std                  4.421714
Log Pis Max                  17.316168
Log Pis Min                  -6.854705
Policy mu Mean               0.07908984
Policy mu Std                0.8895316
Policy mu Max                3.5226972
Policy mu Min                -3.2262874
Policy log std Mean          -0.49036372
Policy log std Std           0.28150865
Policy log std Max           0.1368084
Policy log std Min           -2.836052
Z mean eval                  2.1381848
Z variance eval              0.047726803
total_rewards                [11161.96190228 10919.02513615 10998.44044035 11162.65742364
 11201.75143917 11080.62704333 11235.02976315 10846.26767851
 11294.03697999 11255.78745505]
total_rewards_mean           11115.55852616025
total_rewards_std            142.71393544220658
total_rewards_max            11294.036979986151
total_rewards_min            10846.267678505681
Number of train steps total  1696000
Number of env steps total    5090000
Number of rollouts total     0
Train Time (s)               150.98395374882966
(Previous) Eval Time (s)     30.422949084080756
Sample Time (s)              10.587904330343008
Epoch Time (s)               191.99480716325343
Total Train Time (s)         78391.43616416445
Epoch                        423
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:37:52.050549 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #423 | Epoch Duration: 192.0835816860199
2020-01-14 01:37:52.050772 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #423 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1408029
Z variance train             0.048009075
KL Divergence                62.727077
KL Loss                      6.272708
QF Loss                      66.294556
VF Loss                      44.86223
Policy Loss                  -1101.9658
Q Predictions Mean           1099.7979
Q Predictions Std            1072.4066
Q Predictions Max            4887.96
Q Predictions Min            491.1753
V Predictions Mean           1097.0858
V Predictions Std            1069.7681
V Predictions Max            4878.5757
V Predictions Min            498.07736
Log Pis Mean                 -1.1173558
Log Pis Std                  3.1631875
Log Pis Max                  13.207127
Log Pis Min                  -6.6812944
Policy mu Mean               0.10910332
Policy mu Std                0.7420045
Policy mu Max                2.7636456
Policy mu Min                -2.6991844
Policy log std Mean          -0.483724
Policy log std Std           0.24241948
Policy log std Max           -0.07491043
Policy log std Min           -3.0022984
Z mean eval                  2.158227
Z variance eval              0.09395021
total_rewards                [11051.43262013 11405.63771527 11156.44268332 10908.20496383
 11045.4730271  11060.12589196 11004.40170774 11310.08482246
 10822.96918266 10992.61342603]
total_rewards_mean           11075.738604050013
total_rewards_std            166.12462606237418
total_rewards_max            11405.637715267345
total_rewards_min            10822.96918266245
Number of train steps total  1700000
Number of env steps total    5102000
Number of rollouts total     0
Train Time (s)               152.095715503674
(Previous) Eval Time (s)     30.74066466698423
Sample Time (s)              10.238247680477798
Epoch Time (s)               193.07462785113603
Total Train Time (s)         78584.59115584474
Epoch                        424
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:41:05.210004 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #424 | Epoch Duration: 193.15904831886292
2020-01-14 01:41:05.210267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #424 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1568112
Z variance train             0.09432672
KL Divergence                61.37699
KL Loss                      6.137699
QF Loss                      146.95782
VF Loss                      46.850704
Policy Loss                  -1459.3099
Q Predictions Mean           1457.4027
Q Predictions Std            1443.2367
Q Predictions Max            4883.93
Q Predictions Min            503.5698
V Predictions Mean           1462.4576
V Predictions Std            1440.5837
V Predictions Max            4888.721
V Predictions Min            503.96924
Log Pis Mean                 -0.048047394
Log Pis Std                  4.118926
Log Pis Max                  17.212263
Log Pis Min                  -11.496179
Policy mu Mean               0.092838086
Policy mu Std                0.8894077
Policy mu Max                3.7468414
Policy mu Min                -3.034052
Policy log std Mean          -0.4857348
Policy log std Std           0.2779797
Policy log std Max           0.117008924
Policy log std Min           -2.7452846
Z mean eval                  2.13442
Z variance eval              0.06708516
total_rewards                [10576.80352345  3566.76686008 10483.31662918 10613.80328096
 11081.04264244 10692.53816776 10716.2511896  10617.33994472
 10394.24620812 10578.07919274]
total_rewards_mean           9932.018763904925
total_rewards_std            2128.7394906989293
total_rewards_max            11081.042642441376
total_rewards_min            3566.7668600795982
Number of train steps total  1704000
Number of env steps total    5114000
Number of rollouts total     0
Train Time (s)               147.77123500173911
(Previous) Eval Time (s)     29.098167751915753
Sample Time (s)              10.220941225066781
Epoch Time (s)               187.09034397872165
Total Train Time (s)         78771.78759395517
Epoch                        425
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:44:12.410626 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #425 | Epoch Duration: 187.20019483566284
2020-01-14 01:44:12.410823 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1333375
Z variance train             0.06696265
KL Divergence                62.385
KL Loss                      6.2385
QF Loss                      81.88557
VF Loss                      72.68932
Policy Loss                  -1338.9722
Q Predictions Mean           1339.2135
Q Predictions Std            1285.0902
Q Predictions Max            4933.104
Q Predictions Min            671.0337
V Predictions Mean           1342.4026
V Predictions Std            1284.1971
V Predictions Max            4958.081
V Predictions Min            667.41
Log Pis Mean                 -0.6218649
Log Pis Std                  3.7659223
Log Pis Max                  18.958654
Log Pis Min                  -8.297427
Policy mu Mean               0.11123783
Policy mu Std                0.81857586
Policy mu Max                3.1759357
Policy mu Min                -3.6886864
Policy log std Mean          -0.4842135
Policy log std Std           0.28618178
Policy log std Max           0.010415554
Policy log std Min           -2.7164848
Z mean eval                  2.1165173
Z variance eval              0.06374883
total_rewards                [10581.3931267  10771.44458643  6200.06244625 11226.23536502
 11056.98487284 10808.80721264 10947.63697306 10976.03240797
 11322.63451112 11148.52861971]
total_rewards_mean           10503.976012174486
total_rewards_std            1450.0664245165783
total_rewards_max            11322.634511122678
total_rewards_min            6200.062446251501
Number of train steps total  1708000
Number of env steps total    5126000
Number of rollouts total     0
Train Time (s)               142.60703722201288
(Previous) Eval Time (s)     28.59862940898165
Sample Time (s)              9.547428958583623
Epoch Time (s)               180.75309558957815
Total Train Time (s)         78952.6432962697
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:47:13.271263 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #426 | Epoch Duration: 180.8602225780487
2020-01-14 01:47:13.271585 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #426 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.116858
Z variance train             0.06374734
KL Divergence                62.31818
KL Loss                      6.231818
QF Loss                      344.18372
VF Loss                      146.64847
Policy Loss                  -1446.2855
Q Predictions Mean           1442.238
Q Predictions Std            1374.9082
Q Predictions Max            4890.1655
Q Predictions Min            651.4652
V Predictions Mean           1442.3197
V Predictions Std            1367.9607
V Predictions Max            4870.818
V Predictions Min            665.5639
Log Pis Mean                 -0.12575206
Log Pis Std                  4.2594676
Log Pis Max                  16.717356
Log Pis Min                  -7.751476
Policy mu Mean               0.07675857
Policy mu Std                0.8947286
Policy mu Max                3.8975072
Policy mu Min                -2.6520252
Policy log std Mean          -0.51293284
Policy log std Std           0.29391462
Policy log std Max           -0.009244442
Policy log std Min           -2.8139062
Z mean eval                  2.1256654
Z variance eval              0.056381147
total_rewards                [10301.60047191 11316.84384509 10849.49706297 11090.95551122
 10482.87595445 10782.12487407 11085.3952807  10789.20053606
 10710.26983957 11043.89285577]
total_rewards_mean           10845.265623180625
total_rewards_std            288.4674078612154
total_rewards_max            11316.843845087085
total_rewards_min            10301.600471911626
Number of train steps total  1712000
Number of env steps total    5138000
Number of rollouts total     0
Train Time (s)               143.45153055898845
(Previous) Eval Time (s)     29.30603435030207
Sample Time (s)              9.250296051613986
Epoch Time (s)               182.0078609609045
Total Train Time (s)         79134.72899691062
Epoch                        427
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:50:15.369778 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #427 | Epoch Duration: 182.0979471206665
2020-01-14 01:50:15.370140 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #427 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.125566
Z variance train             0.05648639
KL Divergence                60.943333
KL Loss                      6.094333
QF Loss                      4815.868
VF Loss                      81.74333
Policy Loss                  -1321.3477
Q Predictions Mean           1319.7146
Q Predictions Std            1281.8491
Q Predictions Max            4878.3447
Q Predictions Min            711.3227
V Predictions Mean           1326.6292
V Predictions Std            1281.7731
V Predictions Max            4906.7393
V Predictions Min            722.4486
Log Pis Mean                 -0.803403
Log Pis Std                  4.062287
Log Pis Max                  16.323414
Log Pis Min                  -8.555369
Policy mu Mean               0.080239296
Policy mu Std                0.83765453
Policy mu Max                3.3893948
Policy mu Min                -2.827874
Policy log std Mean          -0.47440776
Policy log std Std           0.2748533
Policy log std Max           -0.0068227053
Policy log std Min           -2.9660096
Z mean eval                  2.1450055
Z variance eval              0.083713904
total_rewards                [10769.86614209  8876.65930144 10757.49256037 10615.60624671
 10800.39244506 10508.59407563 11019.40625582 10797.5979581
 10849.72620896 10867.77918044]
total_rewards_mean           10586.312037460875
total_rewards_std            584.7614156468969
total_rewards_max            11019.40625581645
total_rewards_min            8876.659301439162
Number of train steps total  1716000
Number of env steps total    5150000
Number of rollouts total     0
Train Time (s)               151.21112901205197
(Previous) Eval Time (s)     31.355330058839172
Sample Time (s)              10.143805803731084
Epoch Time (s)               192.71026487462223
Total Train Time (s)         79327.53448942024
Epoch                        428
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:53:28.176409 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #428 | Epoch Duration: 192.80592560768127
2020-01-14 01:53:28.176741 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #428 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1426325
Z variance train             0.083653435
KL Divergence                60.984528
KL Loss                      6.098453
QF Loss                      181.48645
VF Loss                      96.17854
Policy Loss                  -1366.1414
Q Predictions Mean           1365.6377
Q Predictions Std            1346.3276
Q Predictions Max            4927.158
Q Predictions Min            706.791
V Predictions Mean           1369.6715
V Predictions Std            1350.4705
V Predictions Max            4952.9917
V Predictions Min            703.98956
Log Pis Mean                 -0.52616554
Log Pis Std                  4.0060873
Log Pis Max                  14.453087
Log Pis Min                  -7.329511
Policy mu Mean               0.05729778
Policy mu Std                0.84665304
Policy mu Max                2.9712312
Policy mu Min                -2.7331939
Policy log std Mean          -0.46844092
Policy log std Std           0.29677117
Policy log std Max           -0.03219658
Policy log std Min           -3.1278667
Z mean eval                  2.1404536
Z variance eval              0.052986793
total_rewards                [10832.01823589 11177.66486033 11037.19546048 11085.56315779
 11102.78606684 11348.22728177 11239.39463965 11125.99280344
 11095.65637069 11100.04204063]
total_rewards_mean           11114.454091751168
total_rewards_std            127.14542351176259
total_rewards_max            11348.227281770163
total_rewards_min            10832.018235888603
Number of train steps total  1720000
Number of env steps total    5162000
Number of rollouts total     0
Train Time (s)               150.45341456402093
(Previous) Eval Time (s)     29.84765963628888
Sample Time (s)              8.331661060918123
Epoch Time (s)               188.63273526122794
Total Train Time (s)         79516.25298388442
Epoch                        429
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:56:36.900524 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #429 | Epoch Duration: 188.72358989715576
2020-01-14 01:56:36.900697 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #429 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.140837
Z variance train             0.052976977
KL Divergence                61.16655
KL Loss                      6.116655
QF Loss                      208.40125
VF Loss                      92.674385
Policy Loss                  -1461.1216
Q Predictions Mean           1458.2247
Q Predictions Std            1431.4854
Q Predictions Max            4973.5127
Q Predictions Min            527.6478
V Predictions Mean           1458.5106
V Predictions Std            1422.1602
V Predictions Max            4926.8574
V Predictions Min            544.9794
Log Pis Mean                 -0.20203778
Log Pis Std                  3.996147
Log Pis Max                  12.157892
Log Pis Min                  -7.3283234
Policy mu Mean               0.11770367
Policy mu Std                0.8847886
Policy mu Max                2.6672323
Policy mu Min                -2.4968607
Policy log std Mean          -0.5084459
Policy log std Std           0.30394444
Policy log std Max           0.005400002
Policy log std Min           -3.1192317
Z mean eval                  2.1304688
Z variance eval              0.06461865
total_rewards                [10674.78279067 10951.78978306 10858.7561435  10938.04107991
 10783.07713279 10452.98703148 11042.76325671 10853.0749523
 11006.89754266 11092.27302308]
total_rewards_mean           10865.444273615447
total_rewards_std            181.40645763266608
total_rewards_max            11092.273023081812
total_rewards_min            10452.98703148213
Number of train steps total  1724000
Number of env steps total    5174000
Number of rollouts total     0
Train Time (s)               150.13441405026242
(Previous) Eval Time (s)     28.672893502749503
Sample Time (s)              10.02223731437698
Epoch Time (s)               188.8295448673889
Total Train Time (s)         79705.16644577822
Epoch                        430
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:59:45.815523 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #430 | Epoch Duration: 188.9146912097931
2020-01-14 01:59:45.815708 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #430 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1305747
Z variance train             0.06408564
KL Divergence                61.94977
KL Loss                      6.1949773
QF Loss                      413.62976
VF Loss                      77.87106
Policy Loss                  -1603.6157
Q Predictions Mean           1598.3594
Q Predictions Std            1515.1241
Q Predictions Max            4994.747
Q Predictions Min            695.83813
V Predictions Mean           1606.9075
V Predictions Std            1520.6263
V Predictions Max            4998.3315
V Predictions Min            701.96204
Log Pis Mean                 -0.050677843
Log Pis Std                  4.6147666
Log Pis Max                  17.940014
Log Pis Min                  -7.1834764
Policy mu Mean               0.053112324
Policy mu Std                0.93291914
Policy mu Max                3.2020102
Policy mu Min                -3.125488
Policy log std Mean          -0.4983859
Policy log std Std           0.3073302
Policy log std Max           -0.004909873
Policy log std Min           -2.7611802
Z mean eval                  2.145302
Z variance eval              0.04874771
total_rewards                [10301.46270691 10844.08419458 11284.10685084 10432.21389035
 11289.85416068  9776.9839166  10691.62323556 10449.0362392
 10783.2023391  10914.54983788]
total_rewards_mean           10676.71173716885
total_rewards_std            436.2284806893971
total_rewards_max            11289.854160680969
total_rewards_min            9776.983916599436
Number of train steps total  1728000
Number of env steps total    5186000
Number of rollouts total     0
Train Time (s)               151.05942807067186
(Previous) Eval Time (s)     29.06564031308517
Sample Time (s)              10.560034450143576
Epoch Time (s)               190.6851028339006
Total Train Time (s)         79896.12928046007
Epoch                        431
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:02:56.785502 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #431 | Epoch Duration: 190.9696352481842
2020-01-14 02:02:56.785823 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #431 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1453245
Z variance train             0.048806198
KL Divergence                63.084187
KL Loss                      6.3084188
QF Loss                      4839.04
VF Loss                      30.418484
Policy Loss                  -1287.3049
Q Predictions Mean           1284.6122
Q Predictions Std            1262.3276
Q Predictions Max            4944.9165
Q Predictions Min            417.00427
V Predictions Mean           1288.0413
V Predictions Std            1263.375
V Predictions Max            4941.379
V Predictions Min            422.49423
Log Pis Mean                 -0.54860425
Log Pis Std                  4.0620885
Log Pis Max                  13.913623
Log Pis Min                  -7.626996
Policy mu Mean               0.0981658
Policy mu Std                0.86007404
Policy mu Max                2.8353825
Policy mu Min                -2.5862513
Policy log std Mean          -0.44907296
Policy log std Std           0.28355512
Policy log std Max           -0.025830865
Policy log std Min           -2.8044198
Z mean eval                  2.1361854
Z variance eval              0.08244545
total_rewards                [10838.66122357 11314.31483346 11071.44500333 11118.69376531
 10945.17606231 11141.15698584 11435.20179566 11164.95960725
 10819.90734899 10868.93704039]
total_rewards_mean           11071.845366610663
total_rewards_std            195.3338533886526
total_rewards_max            11435.201795660338
total_rewards_min            10819.907348994513
Number of train steps total  1732000
Number of env steps total    5198000
Number of rollouts total     0
Train Time (s)               145.2658533770591
(Previous) Eval Time (s)     29.540972713846713
Sample Time (s)              10.528022384271026
Epoch Time (s)               185.33484847517684
Total Train Time (s)         80081.54850973841
Epoch                        432
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:06:02.207463 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #432 | Epoch Duration: 185.421400308609
2020-01-14 02:06:02.207686 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #432 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1389985
Z variance train             0.08367027
KL Divergence                61.35061
KL Loss                      6.135061
QF Loss                      274.24823
VF Loss                      52.556973
Policy Loss                  -1409.4299
Q Predictions Mean           1401.2098
Q Predictions Std            1367.7595
Q Predictions Max            4995.7637
Q Predictions Min            437.75696
V Predictions Mean           1410.1013
V Predictions Std            1364.8677
V Predictions Max            4978.745
V Predictions Min            440.6796
Log Pis Mean                 -0.29689163
Log Pis Std                  4.0964837
Log Pis Max                  16.487644
Log Pis Min                  -5.8834057
Policy mu Mean               0.09961921
Policy mu Std                0.88787216
Policy mu Max                2.7760928
Policy mu Min                -3.1111622
Policy log std Mean          -0.48721233
Policy log std Std           0.32638773
Policy log std Max           0.19803047
Policy log std Min           -2.7403936
Z mean eval                  2.1708686
Z variance eval              0.1014048
total_rewards                [10977.69467754 10446.53591888 10619.61846248 10672.73370684
 11046.21190407 10987.02803085 11115.86920609 10835.8838302
  9235.10537451 11106.26096153]
total_rewards_mean           10704.294207297824
total_rewards_std            534.1350233837403
total_rewards_max            11115.869206087156
total_rewards_min            9235.105374507313
Number of train steps total  1736000
Number of env steps total    5210000
Number of rollouts total     0
Train Time (s)               142.39748364500701
(Previous) Eval Time (s)     28.70996086206287
Sample Time (s)              9.568607551045716
Epoch Time (s)               180.6760520581156
Total Train Time (s)         80262.31234093942
Epoch                        433
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:09:02.975700 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #433 | Epoch Duration: 180.76785945892334
2020-01-14 02:09:02.975904 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #433 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1678836
Z variance train             0.101551235
KL Divergence                61.120815
KL Loss                      6.1120815
QF Loss                      616.6173
VF Loss                      84.05438
Policy Loss                  -1539.3961
Q Predictions Mean           1534.4619
Q Predictions Std            1464.9846
Q Predictions Max            4966.1567
Q Predictions Min            699.6487
V Predictions Mean           1537.9629
V Predictions Std            1467.4132
V Predictions Max            4951.91
V Predictions Min            702.6892
Log Pis Mean                 -0.179454
Log Pis Std                  4.485191
Log Pis Max                  20.730412
Log Pis Min                  -5.853877
Policy mu Mean               0.056857735
Policy mu Std                0.87117493
Policy mu Max                2.8701553
Policy mu Min                -2.5117261
Policy log std Mean          -0.50255275
Policy log std Std           0.31701592
Policy log std Max           -0.016417444
Policy log std Min           -3.1205933
Z mean eval                  2.1107774
Z variance eval              0.08021165
total_rewards                [10521.57357767 11430.26092234 11148.07662241 11329.55623314
 11364.78321864 11409.90795212 11320.40662703 11421.93751526
 10423.04101797 11274.45217763]
total_rewards_mean           11164.399586422822
total_rewards_std            355.5652856539215
total_rewards_max            11430.260922342395
total_rewards_min            10423.04101797456
Number of train steps total  1740000
Number of env steps total    5222000
Number of rollouts total     0
Train Time (s)               144.79108861694112
(Previous) Eval Time (s)     29.888839405030012
Sample Time (s)              9.573512346949428
Epoch Time (s)               184.25344036892056
Total Train Time (s)         80446.64603334712
Epoch                        434
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:12:07.313989 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #434 | Epoch Duration: 184.33793425559998
2020-01-14 02:12:07.314191 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #434 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1048288
Z variance train             0.08019511
KL Divergence                60.078163
KL Loss                      6.0078163
QF Loss                      82.48373
VF Loss                      72.984375
Policy Loss                  -1215.3997
Q Predictions Mean           1216.6113
Q Predictions Std            1207.5061
Q Predictions Max            4861.9917
Q Predictions Min            652.8018
V Predictions Mean           1220.7522
V Predictions Std            1206.2461
V Predictions Max            4860.509
V Predictions Min            641.9077
Log Pis Mean                 -0.8989291
Log Pis Std                  3.4849396
Log Pis Max                  12.689011
Log Pis Min                  -7.3099623
Policy mu Mean               0.021929184
Policy mu Std                0.8038256
Policy mu Max                2.5235462
Policy mu Min                -2.8981543
Policy log std Mean          -0.45354232
Policy log std Std           0.25289047
Policy log std Max           0.070424855
Policy log std Min           -2.7022123
Z mean eval                  2.1201327
Z variance eval              0.059388675
total_rewards                [10861.17491704 11234.53325459 11403.77041911 11167.12674037
 10655.30480434 10898.00029682 11251.58988443 11595.89009497
 11391.8227948  11370.79414837]
total_rewards_mean           11183.00073548453
total_rewards_std            277.3016504741342
total_rewards_max            11595.89009496502
total_rewards_min            10655.304804344516
Number of train steps total  1744000
Number of env steps total    5234000
Number of rollouts total     0
Train Time (s)               152.79930304270238
(Previous) Eval Time (s)     29.869703449774534
Sample Time (s)              10.022733470890671
Epoch Time (s)               192.69173996336758
Total Train Time (s)         80639.4159603063
Epoch                        435
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:15:20.088221 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #435 | Epoch Duration: 192.7738618850708
2020-01-14 02:15:20.088414 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1207964
Z variance train             0.059449166
KL Divergence                61.671867
KL Loss                      6.1671867
QF Loss                      135.57854
VF Loss                      96.25619
Policy Loss                  -1216.116
Q Predictions Mean           1214.8356
Q Predictions Std            1182.2567
Q Predictions Max            4974.5215
Q Predictions Min            440.35883
V Predictions Mean           1216.1455
V Predictions Std            1178.2263
V Predictions Max            4972.0635
V Predictions Min            441.60895
Log Pis Mean                 -1.0607821
Log Pis Std                  3.912776
Log Pis Max                  18.339632
Log Pis Min                  -9.822341
Policy mu Mean               0.056395333
Policy mu Std                0.8038165
Policy mu Max                4.087719
Policy mu Min                -3.6697688
Policy log std Mean          -0.46278355
Policy log std Std           0.27120888
Policy log std Max           0.119865894
Policy log std Min           -3.03106
Z mean eval                  2.109972
Z variance eval              0.104364775
total_rewards                [10867.51381092 10661.38649598 10652.91790753 10987.46642219
 11141.91816937 11060.91294579 10955.79174354 11228.85218474
 11051.08224097 11072.27979302]
total_rewards_mean           10968.012171403729
total_rewards_std            181.27745670140501
total_rewards_max            11228.852184737392
total_rewards_min            10652.917907534265
Number of train steps total  1748000
Number of env steps total    5246000
Number of rollouts total     0
Train Time (s)               151.98528376594186
(Previous) Eval Time (s)     28.909249784890562
Sample Time (s)              10.088590546511114
Epoch Time (s)               190.98312409734353
Total Train Time (s)         80830.48550914507
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:18:31.162560 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #436 | Epoch Duration: 191.07398915290833
2020-01-14 02:18:31.162829 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1113498
Z variance train             0.10445304
KL Divergence                59.74516
KL Loss                      5.974516
QF Loss                      85.42856
VF Loss                      40.281055
Policy Loss                  -1274.5216
Q Predictions Mean           1269.7219
Q Predictions Std            1245.9993
Q Predictions Max            4955.6016
Q Predictions Min            432.00452
V Predictions Mean           1271.8887
V Predictions Std            1243.1619
V Predictions Max            4910.993
V Predictions Min            434.07523
Log Pis Mean                 -0.9338958
Log Pis Std                  3.5321202
Log Pis Max                  12.114036
Log Pis Min                  -6.627158
Policy mu Mean               0.039473843
Policy mu Std                0.8082048
Policy mu Max                2.4792702
Policy mu Min                -3.0324683
Policy log std Mean          -0.46873686
Policy log std Std           0.25312746
Policy log std Max           0.084129095
Policy log std Min           -2.5890586
Z mean eval                  2.1114423
Z variance eval              0.080626905
total_rewards                [ 6920.16428784 11366.03359403 11116.81316129 11071.47815052
 11206.0480061  11116.28466627 10848.74978508 11263.30349415
 11106.04180486 10777.24406643]
total_rewards_mean           10679.216101657166
total_rewards_std            1264.0340070099037
total_rewards_max            11366.033594030905
total_rewards_min            6920.164287838005
Number of train steps total  1752000
Number of env steps total    5258000
Number of rollouts total     0
Train Time (s)               151.03267738316208
(Previous) Eval Time (s)     31.36331609264016
Sample Time (s)              10.11957575334236
Epoch Time (s)               192.5155692291446
Total Train Time (s)         81023.08736266103
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:21:43.769087 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #437 | Epoch Duration: 192.60607242584229
2020-01-14 02:21:43.769331 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #437 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1107874
Z variance train             0.079955176
KL Divergence                59.8403
KL Loss                      5.9840302
QF Loss                      194.38266
VF Loss                      50.71934
Policy Loss                  -1284.1334
Q Predictions Mean           1279.9359
Q Predictions Std            1261.0822
Q Predictions Max            4953.218
Q Predictions Min            695.9471
V Predictions Mean           1283.3306
V Predictions Std            1255.9366
V Predictions Max            4923.317
V Predictions Min            718.8308
Log Pis Mean                 -0.63413155
Log Pis Std                  4.197094
Log Pis Max                  13.682426
Log Pis Min                  -7.1379976
Policy mu Mean               0.14424983
Policy mu Std                0.8572132
Policy mu Max                3.0755785
Policy mu Min                -3.1324258
Policy log std Mean          -0.4796096
Policy log std Std           0.3089523
Policy log std Max           -0.027416945
Policy log std Min           -2.9094248
Z mean eval                  2.1340358
Z variance eval              0.09145546
total_rewards                [10742.85803617 11193.65607277 11034.97399369 10951.93400253
  9869.67873273 11010.49663602 11453.64607878 11191.73624001
 11004.01421798 10995.73828254]
total_rewards_mean           10944.873229324507
total_rewards_std            399.63692888555425
total_rewards_max            11453.646078776932
total_rewards_min            9869.67873273244
Number of train steps total  1756000
Number of env steps total    5270000
Number of rollouts total     0
Train Time (s)               151.32894580904394
(Previous) Eval Time (s)     30.18461380060762
Sample Time (s)              10.274389527738094
Epoch Time (s)               191.78794913738966
Total Train Time (s)         81214.96476860577
Epoch                        438
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:24:55.651985 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #438 | Epoch Duration: 191.88248944282532
2020-01-14 02:24:55.652217 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #438 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1352048
Z variance train             0.0916208
KL Divergence                60.549927
KL Loss                      6.0549927
QF Loss                      168.4657
VF Loss                      205.59764
Policy Loss                  -1280.9939
Q Predictions Mean           1277.4343
Q Predictions Std            1269.0463
Q Predictions Max            4960.226
Q Predictions Min            723.0982
V Predictions Mean           1277.0415
V Predictions Std            1260.0349
V Predictions Max            4954.7466
V Predictions Min            720.3906
Log Pis Mean                 -0.8295355
Log Pis Std                  3.7729692
Log Pis Max                  14.038946
Log Pis Min                  -7.429285
Policy mu Mean               0.10561224
Policy mu Std                0.81431407
Policy mu Max                2.7223125
Policy mu Min                -2.7612638
Policy log std Mean          -0.47211277
Policy log std Std           0.25855526
Policy log std Max           0.21369886
Policy log std Min           -2.5530362
Z mean eval                  2.1361113
Z variance eval              0.06256351
total_rewards                [  980.55125347 11092.11529362  2659.15476657 11219.07420462
 11069.46014337 10944.941891   11330.2805563  10890.02190649
 11231.55592096  9028.16122001]
total_rewards_mean           9044.531715640396
total_rewards_std            3685.753272643119
total_rewards_max            11330.280556296992
total_rewards_min            980.5512534699379
Number of train steps total  1760000
Number of env steps total    5282000
Number of rollouts total     0
Train Time (s)               141.8500260268338
(Previous) Eval Time (s)     29.735499274916947
Sample Time (s)              9.865619894117117
Epoch Time (s)               181.45114519586787
Total Train Time (s)         81396.50115306256
Epoch                        439
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:27:57.192038 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #439 | Epoch Duration: 181.53968811035156
2020-01-14 02:27:57.192257 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1360407
Z variance train             0.062535055
KL Divergence                62.418774
KL Loss                      6.2418776
QF Loss                      218.31628
VF Loss                      65.54916
Policy Loss                  -1415.7695
Q Predictions Mean           1411.5748
Q Predictions Std            1384.4281
Q Predictions Max            4905.087
Q Predictions Min            675.3094
V Predictions Mean           1416.6919
V Predictions Std            1383.9089
V Predictions Max            4914.454
V Predictions Min            680.12756
Log Pis Mean                 -0.24830814
Log Pis Std                  4.195934
Log Pis Max                  18.379303
Log Pis Min                  -7.794304
Policy mu Mean               0.10732287
Policy mu Std                0.8889996
Policy mu Max                2.973449
Policy mu Min                -3.35174
Policy log std Mean          -0.49869737
Policy log std Std           0.29898268
Policy log std Max           0.030207574
Policy log std Min           -2.8489957
Z mean eval                  2.1115599
Z variance eval              0.052081823
total_rewards                [10911.94956042 11331.62057182 11239.56754913 11016.68157711
 11340.25886383  2838.21155827 10964.76857783 11327.05037857
 11329.03774385 10937.75017845]
total_rewards_mean           10323.689655927486
total_rewards_std            2501.0467787822367
total_rewards_max            11340.258863826644
total_rewards_min            2838.2115582683855
Number of train steps total  1764000
Number of env steps total    5294000
Number of rollouts total     0
Train Time (s)               143.06470012897626
(Previous) Eval Time (s)     29.41694623604417
Sample Time (s)              10.048764710314572
Epoch Time (s)               182.530411075335
Total Train Time (s)         81579.12463081675
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:30:59.819821 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #440 | Epoch Duration: 182.62741112709045
2020-01-14 02:30:59.820017 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #440 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1117961
Z variance train             0.052211635
KL Divergence                62.057175
KL Loss                      6.2057176
QF Loss                      4710.629
VF Loss                      45.267956
Policy Loss                  -1361.0232
Q Predictions Mean           1359.7908
Q Predictions Std            1373.7422
Q Predictions Max            4998.729
Q Predictions Min            423.54626
V Predictions Mean           1360.2574
V Predictions Std            1370.5092
V Predictions Max            4998.31
V Predictions Min            430.08316
Log Pis Mean                 -0.72960246
Log Pis Std                  3.6449413
Log Pis Max                  12.6895485
Log Pis Min                  -7.9038987
Policy mu Mean               0.058415744
Policy mu Std                0.80856204
Policy mu Max                3.913423
Policy mu Min                -2.2995956
Policy log std Mean          -0.46072245
Policy log std Std           0.27871376
Policy log std Max           0.053816438
Policy log std Min           -2.7577605
Z mean eval                  2.128765
Z variance eval              0.041861318
total_rewards                [10989.11413506 11213.44820189 11033.82631669 11029.91841036
 11323.32877891 11371.02384204 11415.93681962 11163.22438221
 11149.91755523 10926.99856769]
total_rewards_mean           11161.67370096969
total_rewards_std            159.99513181849844
total_rewards_max            11415.936819621444
total_rewards_min            10926.998567687202
Number of train steps total  1768000
Number of env steps total    5306000
Number of rollouts total     0
Train Time (s)               145.94278716715053
(Previous) Eval Time (s)     30.297127165831625
Sample Time (s)              7.429162620101124
Epoch Time (s)               183.66907695308328
Total Train Time (s)         81762.87367878202
Epoch                        441
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:34:03.573643 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #441 | Epoch Duration: 183.75346732139587
2020-01-14 02:34:03.573856 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #441 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.129747
Z variance train             0.042093504
KL Divergence                62.376022
KL Loss                      6.237602
QF Loss                      184.30711
VF Loss                      152.59326
Policy Loss                  -1409.549
Q Predictions Mean           1407.591
Q Predictions Std            1381.283
Q Predictions Max            4924.927
Q Predictions Min            414.49518
V Predictions Mean           1411.5303
V Predictions Std            1386.7947
V Predictions Max            4936.597
V Predictions Min            410.1275
Log Pis Mean                 0.14442833
Log Pis Std                  4.4794354
Log Pis Max                  16.147923
Log Pis Min                  -6.00416
Policy mu Mean               0.12645857
Policy mu Std                0.8882585
Policy mu Max                3.1469228
Policy mu Min                -3.1219945
Policy log std Mean          -0.49769998
Policy log std Std           0.3144079
Policy log std Max           0.19750166
Policy log std Min           -3.0429099
Z mean eval                  2.0894384
Z variance eval              0.08988936
total_rewards                [11070.50040028 11053.32477931 10836.43314258 11106.29427754
 11247.97457626 10929.45128035 10933.99425441 10614.6719403
 11200.69355746 10646.25655251]
total_rewards_mean           10963.959476099928
total_rewards_std            204.3508135998743
total_rewards_max            11247.974576261526
total_rewards_min            10614.671940297541
Number of train steps total  1772000
Number of env steps total    5318000
Number of rollouts total     0
Train Time (s)               152.24119520094246
(Previous) Eval Time (s)     30.539794789161533
Sample Time (s)              10.612975128926337
Epoch Time (s)               193.39396511903033
Total Train Time (s)         81956.35084784543
Epoch                        442
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:37:17.055552 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #442 | Epoch Duration: 193.48152828216553
2020-01-14 02:37:17.055780 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #442 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0869641
Z variance train             0.09012554
KL Divergence                59.592064
KL Loss                      5.9592066
QF Loss                      120.14689
VF Loss                      62.880707
Policy Loss                  -1419.403
Q Predictions Mean           1418.0913
Q Predictions Std            1389.3546
Q Predictions Max            4964.529
Q Predictions Min            677.3181
V Predictions Mean           1422.1533
V Predictions Std            1385.9583
V Predictions Max            4955.7427
V Predictions Min            704.3214
Log Pis Mean                 -0.46312144
Log Pis Std                  4.0120296
Log Pis Max                  17.163343
Log Pis Min                  -6.4192514
Policy mu Mean               0.06802481
Policy mu Std                0.85337204
Policy mu Max                3.6921337
Policy mu Min                -3.1085088
Policy log std Mean          -0.51648676
Policy log std Std           0.30825943
Policy log std Max           0.070866704
Policy log std Min           -3.090026
Z mean eval                  2.1276627
Z variance eval              0.10865612
total_rewards                [10195.6458288  10869.38808277 11450.67689868 11085.90070705
 10709.14058417 10824.05763499 11192.3177392  10766.85221901
 11000.05184658 10922.57279854]
total_rewards_mean           10901.660433977637
total_rewards_std            314.7571908735982
total_rewards_max            11450.676898679445
total_rewards_min            10195.645828795527
Number of train steps total  1776000
Number of env steps total    5330000
Number of rollouts total     0
Train Time (s)               151.41635644901544
(Previous) Eval Time (s)     29.765449231956154
Sample Time (s)              9.306401292327791
Epoch Time (s)               190.48820697329938
Total Train Time (s)         82146.91587258363
Epoch                        443
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:40:27.628431 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #443 | Epoch Duration: 190.57248830795288
2020-01-14 02:40:27.628627 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1271882
Z variance train             0.10878235
KL Divergence                59.67393
KL Loss                      5.9673934
QF Loss                      334.3869
VF Loss                      44.59683
Policy Loss                  -1500.3676
Q Predictions Mean           1500.8679
Q Predictions Std            1472.0808
Q Predictions Max            4984.173
Q Predictions Min            691.6423
V Predictions Mean           1499.9408
V Predictions Std            1469.9458
V Predictions Max            4968.199
V Predictions Min            674.1518
Log Pis Mean                 -0.4075588
Log Pis Std                  4.258618
Log Pis Max                  18.615936
Log Pis Min                  -7.5618486
Policy mu Mean               0.097917706
Policy mu Std                0.87188804
Policy mu Max                3.1226604
Policy mu Min                -3.4603155
Policy log std Mean          -0.5034227
Policy log std Std           0.30838692
Policy log std Max           0.033517838
Policy log std Min           -3.0216558
Z mean eval                  2.1054661
Z variance eval              0.08086006
total_rewards                [10750.81066023 11084.12073469 11184.5656738  11015.18477025
 11149.04846998 11146.674585   11351.07260865 11120.96896115
 11235.31506037 11128.29681339]
total_rewards_mean           11116.60583375116
total_rewards_std            148.64221539046807
total_rewards_max            11351.072608649634
total_rewards_min            10750.810660231415
Number of train steps total  1780000
Number of env steps total    5342000
Number of rollouts total     0
Train Time (s)               152.51907703001052
(Previous) Eval Time (s)     30.396217196714133
Sample Time (s)              10.07749417796731
Epoch Time (s)               192.99278840469196
Total Train Time (s)         82339.99787693657
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:43:40.715652 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #444 | Epoch Duration: 193.0868628025055
2020-01-14 02:43:40.715896 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #444 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1078312
Z variance train             0.08099737
KL Divergence                60.197422
KL Loss                      6.0197425
QF Loss                      107.619316
VF Loss                      70.491234
Policy Loss                  -1578.12
Q Predictions Mean           1574.6577
Q Predictions Std            1536.6964
Q Predictions Max            4964.2544
Q Predictions Min            715.33325
V Predictions Mean           1579.1411
V Predictions Std            1534.473
V Predictions Max            4964.4893
V Predictions Min            717.4728
Log Pis Mean                 -0.22722088
Log Pis Std                  4.1586585
Log Pis Max                  17.45351
Log Pis Min                  -7.4361744
Policy mu Mean               0.07141533
Policy mu Std                0.8904292
Policy mu Max                2.9002185
Policy mu Min                -2.596487
Policy log std Mean          -0.51415217
Policy log std Std           0.3050095
Policy log std Max           0.08893943
Policy log std Min           -3.0804052
Z mean eval                  2.1088183
Z variance eval              0.06951641
total_rewards                [10998.01554048 11197.34138467 11262.27757783 11078.17623428
 11109.10248514 11198.67403925 10637.1888579  11094.9022873
 11539.12782159 10456.04232663]
total_rewards_mean           11057.084855506766
total_rewards_std            293.22749834856387
total_rewards_max            11539.127821586979
total_rewards_min            10456.042326625931
Number of train steps total  1784000
Number of env steps total    5354000
Number of rollouts total     0
Train Time (s)               150.94650593120605
(Previous) Eval Time (s)     28.6195126818493
Sample Time (s)              9.551478903740644
Epoch Time (s)               189.117497516796
Total Train Time (s)         82529.25419515604
Epoch                        445
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:46:49.976500 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #445 | Epoch Duration: 189.26044130325317
2020-01-14 02:46:49.976703 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.110355
Z variance train             0.06968708
KL Divergence                60.686584
KL Loss                      6.0686584
QF Loss                      188.50479
VF Loss                      53.639046
Policy Loss                  -1324.8699
Q Predictions Mean           1324.8535
Q Predictions Std            1304.4893
Q Predictions Max            4923.726
Q Predictions Min            478.92453
V Predictions Mean           1326.8756
V Predictions Std            1303.4048
V Predictions Max            4928.749
V Predictions Min            481.54987
Log Pis Mean                 -1.0316781
Log Pis Std                  3.731281
Log Pis Max                  12.763652
Log Pis Min                  -6.865387
Policy mu Mean               0.09884542
Policy mu Std                0.7968571
Policy mu Max                2.7866426
Policy mu Min                -2.6348836
Policy log std Mean          -0.47298703
Policy log std Std           0.29103738
Policy log std Max           0.15270114
Policy log std Min           -2.9629254
Z mean eval                  2.1186645
Z variance eval              0.098839894
total_rewards                [ 8551.25488769 10668.46858259 10344.62551075 10791.37440249
 10459.99189717 10626.11646443 10064.14870182 10439.09646954
 10635.07297069 10772.10011341]
total_rewards_mean           10335.225000058905
total_rewards_std            629.8401565902811
total_rewards_max            10791.374402491916
total_rewards_min            8551.254887685134
Number of train steps total  1788000
Number of env steps total    5366000
Number of rollouts total     0
Train Time (s)               143.3236726950854
(Previous) Eval Time (s)     29.253929799888283
Sample Time (s)              9.845264132134616
Epoch Time (s)               182.4228666271083
Total Train Time (s)         82711.76146453712
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:49:52.488350 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #446 | Epoch Duration: 182.51149320602417
2020-01-14 02:49:52.488570 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #446 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1172342
Z variance train             0.09866176
KL Divergence                59.626095
KL Loss                      5.96261
QF Loss                      100.8369
VF Loss                      49.855827
Policy Loss                  -1220.6989
Q Predictions Mean           1219.6907
Q Predictions Std            1145.3112
Q Predictions Max            4976.2407
Q Predictions Min            707.4329
V Predictions Mean           1221.4171
V Predictions Std            1145.6676
V Predictions Max            5007.1904
V Predictions Min            711.70917
Log Pis Mean                 -1.075571
Log Pis Std                  3.5556724
Log Pis Max                  12.134401
Log Pis Min                  -7.9816875
Policy mu Mean               0.115803055
Policy mu Std                0.76802135
Policy mu Max                3.1575959
Policy mu Min                -2.467706
Policy log std Mean          -0.46297467
Policy log std Std           0.27006844
Policy log std Max           0.03518486
Policy log std Min           -2.8638606
Z mean eval                  2.110591
Z variance eval              0.14021823
total_rewards                [10676.07636811 10816.98822774 10705.57259613 10981.44633658
 11134.70081027 10619.2940085  11087.9254691  11097.3119676
 10877.64938872 10934.51557016]
total_rewards_mean           10893.148074290846
total_rewards_std            176.3003041440239
total_rewards_max            11134.700810273336
total_rewards_min            10619.294008503788
Number of train steps total  1792000
Number of env steps total    5378000
Number of rollouts total     0
Train Time (s)               142.36551945330575
(Previous) Eval Time (s)     29.62457216018811
Sample Time (s)              9.43336172029376
Epoch Time (s)               181.42345333378762
Total Train Time (s)         82893.2664034823
Epoch                        447
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:52:53.997810 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #447 | Epoch Duration: 181.50907468795776
2020-01-14 02:52:53.998056 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #447 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.115007
Z variance train             0.14104094
KL Divergence                59.0465
KL Loss                      5.90465
QF Loss                      226.74031
VF Loss                      109.65702
Policy Loss                  -1342.5251
Q Predictions Mean           1339.2739
Q Predictions Std            1347.6605
Q Predictions Max            4999.799
Q Predictions Min            490.5914
V Predictions Mean           1334.42
V Predictions Std            1344.0499
V Predictions Max            4999.5957
V Predictions Min            478.10162
Log Pis Mean                 -0.6606827
Log Pis Std                  3.9200308
Log Pis Max                  14.751026
Log Pis Min                  -8.8361225
Policy mu Mean               0.13763218
Policy mu Std                0.8378256
Policy mu Max                3.528186
Policy mu Min                -3.8503666
Policy log std Mean          -0.4841535
Policy log std Std           0.28490365
Policy log std Max           0.014517307
Policy log std Min           -3.0815327
Z mean eval                  2.1245081
Z variance eval              0.160255
total_rewards                [11281.80890627 11547.24890162  2202.70538465 11504.75448303
 11024.34807646 11318.19399126 11325.30669121 11290.11532467
 11151.48252656 11259.42467322]
total_rewards_mean           10390.538895894757
total_rewards_std            2733.015158940199
total_rewards_max            11547.24890161774
total_rewards_min            2202.7053846513486
Number of train steps total  1796000
Number of env steps total    5390000
Number of rollouts total     0
Train Time (s)               149.86494449106976
(Previous) Eval Time (s)     31.01487485691905
Sample Time (s)              10.064090935979038
Epoch Time (s)               190.94391028396785
Total Train Time (s)         83084.28656865377
Epoch                        448
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:56:05.023850 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #448 | Epoch Duration: 191.025630235672
2020-01-14 02:56:05.024085 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1236026
Z variance train             0.15877691
KL Divergence                58.66066
KL Loss                      5.866066
QF Loss                      137.42857
VF Loss                      130.0539
Policy Loss                  -1429.3258
Q Predictions Mean           1426.1572
Q Predictions Std            1384.0967
Q Predictions Max            4954.588
Q Predictions Min            658.5675
V Predictions Mean           1429.8208
V Predictions Std            1384.7728
V Predictions Max            4936.921
V Predictions Min            660.2268
Log Pis Mean                 -0.23501748
Log Pis Std                  4.243076
Log Pis Max                  19.188667
Log Pis Min                  -7.038478
Policy mu Mean               0.13894853
Policy mu Std                0.86933714
Policy mu Max                3.7483952
Policy mu Min                -3.0364716
Policy log std Mean          -0.49468556
Policy log std Std           0.3003473
Policy log std Max           0.1353625
Policy log std Min           -2.8852544
Z mean eval                  2.0861893
Z variance eval              0.17809646
total_rewards                [10709.12472845 10666.95573191 11129.39539415 10544.23585781
 10710.20867067 10575.63614863 10766.07773124 10710.20058196
 10774.91745553 10713.40980517]
total_rewards_mean           10730.01621055154
total_rewards_std            150.54623170710894
total_rewards_max            11129.395394145467
total_rewards_min            10544.235857809608
Number of train steps total  1800000
Number of env steps total    5402000
Number of rollouts total     0
Train Time (s)               151.36574372509494
(Previous) Eval Time (s)     30.25814093928784
Sample Time (s)              10.5627918606624
Epoch Time (s)               192.1866765250452
Total Train Time (s)         83276.55927532911
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:59:17.303934 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #449 | Epoch Duration: 192.2795286178589
2020-01-14 02:59:17.304503 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #449 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0848818
Z variance train             0.17794415
KL Divergence                55.72728
KL Loss                      5.572728
QF Loss                      287.49442
VF Loss                      78.25706
Policy Loss                  -1277.0242
Q Predictions Mean           1278.7356
Q Predictions Std            1279.1211
Q Predictions Max            5021.333
Q Predictions Min            500.33832
V Predictions Mean           1282.5605
V Predictions Std            1275.0734
V Predictions Max            5013.913
V Predictions Min            504.20294
Log Pis Mean                 -0.76141316
Log Pis Std                  3.872295
Log Pis Max                  15.671509
Log Pis Min                  -7.4766126
Policy mu Mean               0.02511601
Policy mu Std                0.8601875
Policy mu Max                2.7323081
Policy mu Min                -3.1490579
Policy log std Mean          -0.4318266
Policy log std Std           0.2569117
Policy log std Max           0.23944539
Policy log std Min           -2.3426018
Z mean eval                  2.092453
Z variance eval              0.13977769
total_rewards                [10815.19657226 10877.12863348 10544.59313532 10420.82130037
 10792.66699477 10671.18115295 10920.84447829 10804.66366088
 11098.80218663 10535.69690905]
total_rewards_mean           10748.159502400822
total_rewards_std            194.6089975769157
total_rewards_max            11098.802186625855
total_rewards_min            10420.821300373393
Number of train steps total  1804000
Number of env steps total    5414000
Number of rollouts total     0
Train Time (s)               150.83265728410333
(Previous) Eval Time (s)     29.692186371888965
Sample Time (s)              10.45087673375383
Epoch Time (s)               190.97572038974613
Total Train Time (s)         83467.6887523979
Epoch                        450
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:02:28.440755 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #450 | Epoch Duration: 191.13590097427368
2020-01-14 03:02:28.441098 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #450 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.090282
Z variance train             0.1395975
KL Divergence                55.769154
KL Loss                      5.5769153
QF Loss                      164.24776
VF Loss                      74.59721
Policy Loss                  -1376.1318
Q Predictions Mean           1372.568
Q Predictions Std            1333.435
Q Predictions Max            4924.8623
Q Predictions Min            488.3516
V Predictions Mean           1379.9373
V Predictions Std            1330.3805
V Predictions Max            4932.9175
V Predictions Min            507.21664
Log Pis Mean                 -0.105181254
Log Pis Std                  4.614986
Log Pis Max                  19.999245
Log Pis Min                  -6.4394884
Policy mu Mean               0.09665813
Policy mu Std                0.9370176
Policy mu Max                3.257814
Policy mu Min                -3.072477
Policy log std Mean          -0.47654453
Policy log std Std           0.26201645
Policy log std Max           -0.06620324
Policy log std Min           -2.8156528
Z mean eval                  2.0912104
Z variance eval              0.12511915
total_rewards                [10939.59710278 11001.92331665 10726.14417953 10440.30976382
 10491.57624663 10232.2735595  10035.83026467 10359.73680736
 10672.24597054 10926.91255706]
total_rewards_mean           10582.654976855043
total_rewards_std            308.27860930198335
total_rewards_max            11001.923316653068
total_rewards_min            10035.830264666936
Number of train steps total  1808000
Number of env steps total    5426000
Number of rollouts total     0
Train Time (s)               151.85166151775047
(Previous) Eval Time (s)     29.81110622640699
Sample Time (s)              10.428688076790422
Epoch Time (s)               192.09145582094789
Total Train Time (s)         83659.86784113711
Epoch                        451
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:05:40.624495 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #451 | Epoch Duration: 192.18314623832703
2020-01-14 03:05:40.624721 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #451 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0929036
Z variance train             0.12471972
KL Divergence                56.370636
KL Loss                      5.6370635
QF Loss                      256.58783
VF Loss                      48.406227
Policy Loss                  -1340.9568
Q Predictions Mean           1338.0054
Q Predictions Std            1333.9467
Q Predictions Max            5009.164
Q Predictions Min            731.6321
V Predictions Mean           1340.6201
V Predictions Std            1332.079
V Predictions Max            5015.502
V Predictions Min            737.5541
Log Pis Mean                 -0.649596
Log Pis Std                  3.680516
Log Pis Max                  13.448915
Log Pis Min                  -7.886731
Policy mu Mean               0.06733935
Policy mu Std                0.86163163
Policy mu Max                2.923733
Policy mu Min                -2.7320435
Policy log std Mean          -0.44842216
Policy log std Std           0.2713685
Policy log std Max           0.04030478
Policy log std Min           -2.9815116
Z mean eval                  2.0900302
Z variance eval              0.12211977
total_rewards                [10587.9261915  10722.35670877 10737.73952857 11163.88173922
 11259.42216044 10986.35605312 11021.60708918 11084.04985536
 10721.78516339 11252.42937298]
total_rewards_mean           10953.755386252777
total_rewards_std            231.79389549382302
total_rewards_max            11259.422160437565
total_rewards_min            10587.92619150207
Number of train steps total  1812000
Number of env steps total    5438000
Number of rollouts total     0
Train Time (s)               147.35548098525032
(Previous) Eval Time (s)     29.98309645615518
Sample Time (s)              10.249027582351118
Epoch Time (s)               187.58760502375662
Total Train Time (s)         83847.53484715521
Epoch                        452
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:08:48.302026 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #452 | Epoch Duration: 187.67713713645935
2020-01-14 03:08:48.302413 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #452 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0901814
Z variance train             0.12184055
KL Divergence                55.930164
KL Loss                      5.5930166
QF Loss                      4573.421
VF Loss                      34.86099
Policy Loss                  -1254.5476
Q Predictions Mean           1252.1265
Q Predictions Std            1221.0859
Q Predictions Max            4973.1763
Q Predictions Min            524.7982
V Predictions Mean           1254.9807
V Predictions Std            1218.2598
V Predictions Max            4964.5615
V Predictions Min            539.59863
Log Pis Mean                 -0.77843136
Log Pis Std                  3.8650024
Log Pis Max                  17.59894
Log Pis Min                  -8.205399
Policy mu Mean               0.08842936
Policy mu Std                0.80893934
Policy mu Max                3.1269588
Policy mu Min                -3.5696857
Policy log std Mean          -0.44836172
Policy log std Std           0.2785403
Policy log std Max           0.10100758
Policy log std Min           -2.919982
Z mean eval                  2.0774999
Z variance eval              0.10576371
total_rewards                [10684.40748681 10762.76994424 11221.5009646  11386.64175615
 11294.97975644 11363.41018565 11525.27546182 10700.43588101
 11235.02551424 11074.45123896]
total_rewards_mean           11124.889818991669
total_rewards_std            290.5115421168316
total_rewards_max            11525.275461824653
total_rewards_min            10684.407486809123
Number of train steps total  1816000
Number of env steps total    5450000
Number of rollouts total     0
Train Time (s)               142.3405144950375
(Previous) Eval Time (s)     28.75628999294713
Sample Time (s)              9.725696329493076
Epoch Time (s)               180.8225008174777
Total Train Time (s)         84028.47016147058
Epoch                        453
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:11:49.237339 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #453 | Epoch Duration: 180.93459105491638
2020-01-14 03:11:49.237639 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0808668
Z variance train             0.10598093
KL Divergence                56.24907
KL Loss                      5.624907
QF Loss                      403.94614
VF Loss                      229.89612
Policy Loss                  -1439.6365
Q Predictions Mean           1434.0128
Q Predictions Std            1411.8402
Q Predictions Max            5119.8174
Q Predictions Min            573.34393
V Predictions Mean           1429.1354
V Predictions Std            1403.1016
V Predictions Max            5079.364
V Predictions Min            569.0478
Log Pis Mean                 -0.29613858
Log Pis Std                  4.252376
Log Pis Max                  18.399883
Log Pis Min                  -6.6845636
Policy mu Mean               0.106568485
Policy mu Std                0.90474725
Policy mu Max                3.2306905
Policy mu Min                -3.118316
Policy log std Mean          -0.4583877
Policy log std Std           0.2973131
Policy log std Max           0.015163183
Policy log std Min           -2.9127045
Z mean eval                  2.0739462
Z variance eval              0.08642788
total_rewards                [10569.62998539 11180.10167861 10943.84193251 10955.46486093
 11196.33383011 11372.78455067 11036.35687666 10419.75444876
 11046.20299163 11165.60460183]
total_rewards_mean           10988.60757571127
total_rewards_std            276.8710556957357
total_rewards_max            11372.78455066987
total_rewards_min            10419.754448760188
Number of train steps total  1820000
Number of env steps total    5462000
Number of rollouts total     0
Train Time (s)               143.91062330501154
(Previous) Eval Time (s)     30.49871622538194
Sample Time (s)              8.43972898600623
Epoch Time (s)               182.8490685163997
Total Train Time (s)         84211.45474899653
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:14:52.225537 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #454 | Epoch Duration: 182.98769068717957
2020-01-14 03:14:52.225749 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #454 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0749726
Z variance train             0.08612652
KL Divergence                57.552784
KL Loss                      5.7552786
QF Loss                      176.58948
VF Loss                      113.57388
Policy Loss                  -1443.3317
Q Predictions Mean           1439.0963
Q Predictions Std            1411.8434
Q Predictions Max            4963.275
Q Predictions Min            627.52325
V Predictions Mean           1443.073
V Predictions Std            1408.5579
V Predictions Max            4954.6685
V Predictions Min            635.36676
Log Pis Mean                 -0.16934763
Log Pis Std                  4.411834
Log Pis Max                  14.463474
Log Pis Min                  -5.83696
Policy mu Mean               0.09396541
Policy mu Std                0.90370065
Policy mu Max                3.024071
Policy mu Min                -3.4398506
Policy log std Mean          -0.5019787
Policy log std Std           0.32122716
Policy log std Max           0.048992515
Policy log std Min           -3.1929185
Z mean eval                  2.103763
Z variance eval              0.11673584
total_rewards                [10655.68751282  9770.61301071 10165.98455812 10550.49112934
 10773.75185526 10658.03286586 10595.97786607 10608.0598863
 10048.13238825  9879.42118196]
total_rewards_mean           10370.615225468835
total_rewards_std            348.29025470716795
total_rewards_max            10773.751855256658
total_rewards_min            9770.613010713456
Number of train steps total  1824000
Number of env steps total    5474000
Number of rollouts total     0
Train Time (s)               152.84131094114855
(Previous) Eval Time (s)     30.482124025002122
Sample Time (s)              10.123673752415925
Epoch Time (s)               193.4471087185666
Total Train Time (s)         84404.9852809161
Epoch                        455
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:18:05.761720 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #455 | Epoch Duration: 193.5357437133789
2020-01-14 03:18:05.762036 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1017156
Z variance train             0.1156853
KL Divergence                57.320732
KL Loss                      5.7320733
QF Loss                      174.98595
VF Loss                      64.72547
Policy Loss                  -1264.5743
Q Predictions Mean           1264.9521
Q Predictions Std            1248.1794
Q Predictions Max            4978.4365
Q Predictions Min            708.195
V Predictions Mean           1268.4948
V Predictions Std            1244.5012
V Predictions Max            5001.093
V Predictions Min            722.098
Log Pis Mean                 -1.0413947
Log Pis Std                  3.9876769
Log Pis Max                  13.851736
Log Pis Min                  -9.662328
Policy mu Mean               0.06364375
Policy mu Std                0.79896855
Policy mu Max                2.8026743
Policy mu Min                -2.7093759
Policy log std Mean          -0.44910428
Policy log std Std           0.2555487
Policy log std Max           0.12325835
Policy log std Min           -2.9779782
Z mean eval                  2.0857446
Z variance eval              0.12357479
total_rewards                [11191.37551361 11324.07754013 11279.31070998 11128.75761638
 11200.82302449 11221.88173747 10772.53813115 10886.33534397
 11220.90340239 10926.85932632]
total_rewards_mean           11115.2862345868
total_rewards_std            176.5509831716023
total_rewards_max            11324.077540126256
total_rewards_min            10772.538131147208
Number of train steps total  1828000
Number of env steps total    5486000
Number of rollouts total     0
Train Time (s)               151.0854327501729
(Previous) Eval Time (s)     30.03729478502646
Sample Time (s)              9.549690743442625
Epoch Time (s)               190.672418278642
Total Train Time (s)         84595.74766837247
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:21:16.527918 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #456 | Epoch Duration: 190.7656900882721
2020-01-14 03:21:16.528162 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0837903
Z variance train             0.123518184
KL Divergence                58.451607
KL Loss                      5.845161
QF Loss                      124.41028
VF Loss                      62.422295
Policy Loss                  -1201.2477
Q Predictions Mean           1195.3281
Q Predictions Std            1153.7705
Q Predictions Max            4974.977
Q Predictions Min            705.47656
V Predictions Mean           1197.7937
V Predictions Std            1152.299
V Predictions Max            4922.5493
V Predictions Min            687.03
Log Pis Mean                 -0.68429863
Log Pis Std                  4.3224015
Log Pis Max                  24.162355
Log Pis Min                  -8.435557
Policy mu Mean               0.104101814
Policy mu Std                0.8251874
Policy mu Max                4.424952
Policy mu Min                -4.5633445
Policy log std Mean          -0.48253784
Policy log std Std           0.29420623
Policy log std Max           0.07617986
Policy log std Min           -2.9260035
Z mean eval                  2.1008883
Z variance eval              0.110988095
total_rewards                [10738.64019608 10978.26718031 11151.25724167 10934.93074904
 11040.46868001 10619.62818109  4647.36138225 11124.81762082
 10927.55294156 11142.95589139]
total_rewards_mean           10330.588006421298
total_rewards_std            1901.5354873278745
total_rewards_max            11151.257241673762
total_rewards_min            4647.3613822526195
Number of train steps total  1832000
Number of env steps total    5498000
Number of rollouts total     0
Train Time (s)               150.71997636090964
(Previous) Eval Time (s)     30.79857248160988
Sample Time (s)              9.637341497000307
Epoch Time (s)               191.15589033951983
Total Train Time (s)         84786.98718269961
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:24:27.771929 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #457 | Epoch Duration: 191.24361109733582
2020-01-14 03:24:27.772134 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #457 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1005797
Z variance train             0.11098887
KL Divergence                59.0577
KL Loss                      5.9057703
QF Loss                      195.37842
VF Loss                      48.567566
Policy Loss                  -1415.6624
Q Predictions Mean           1413.864
Q Predictions Std            1393.0261
Q Predictions Max            5000.543
Q Predictions Min            525.1854
V Predictions Mean           1416.2297
V Predictions Std            1393.1793
V Predictions Max            4997.3896
V Predictions Min            528.6338
Log Pis Mean                 -0.5425285
Log Pis Std                  4.039318
Log Pis Max                  15.1185255
Log Pis Min                  -10.116962
Policy mu Mean               0.09377891
Policy mu Std                0.8361449
Policy mu Max                2.7687526
Policy mu Min                -3.0428085
Policy log std Mean          -0.48699486
Policy log std Std           0.27835342
Policy log std Max           -0.025191545
Policy log std Min           -2.920282
Z mean eval                  2.1017969
Z variance eval              0.09972888
total_rewards                [10826.23927057 10934.10090676 11453.85947273 11281.41836217
 11060.01081997 10955.13027326 11147.07593314 11385.51659321
 11473.50312408 11285.74917583]
total_rewards_mean           11180.260393172519
total_rewards_std            218.29083084712963
total_rewards_max            11473.503124084746
total_rewards_min            10826.239270570786
Number of train steps total  1836000
Number of env steps total    5510000
Number of rollouts total     0
Train Time (s)               151.9525461019948
(Previous) Eval Time (s)     28.747058493085206
Sample Time (s)              10.516908262390643
Epoch Time (s)               191.21651285747066
Total Train Time (s)         84978.28466808423
Epoch                        458
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:27:39.074471 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #458 | Epoch Duration: 191.30218267440796
2020-01-14 03:27:39.074730 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #458 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1047256
Z variance train             0.100049935
KL Divergence                58.922337
KL Loss                      5.892234
QF Loss                      276.23035
VF Loss                      93.489746
Policy Loss                  -1370.047
Q Predictions Mean           1368.6832
Q Predictions Std            1339.9058
Q Predictions Max            4938.886
Q Predictions Min            541.38153
V Predictions Mean           1364.8375
V Predictions Std            1333.4679
V Predictions Max            4920.846
V Predictions Min            549.75903
Log Pis Mean                 -0.29319414
Log Pis Std                  3.9525745
Log Pis Max                  16.633677
Log Pis Min                  -7.121316
Policy mu Mean               0.06466508
Policy mu Std                0.8731486
Policy mu Max                2.7753434
Policy mu Min                -3.1723647
Policy log std Mean          -0.48919213
Policy log std Std           0.26811352
Policy log std Max           -0.093431234
Policy log std Min           -3.0290637
Z mean eval                  2.0942078
Z variance eval              0.1729311
total_rewards                [11227.85942181 11048.9967615  11443.00447941 11114.39728201
  3847.28945432 11499.84148405 11173.20460341 11412.1071346
 11236.26998445 11258.12044402]
total_rewards_mean           10526.109104956708
total_rewards_std            2230.5005257859125
total_rewards_max            11499.841484053743
total_rewards_min            3847.289454316548
Number of train steps total  1840000
Number of env steps total    5522000
Number of rollouts total     0
Train Time (s)               144.53017462138087
(Previous) Eval Time (s)     29.533755565062165
Sample Time (s)              10.608046242501587
Epoch Time (s)               184.67197642894462
Total Train Time (s)         85163.03731578495
Epoch                        459
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:30:43.831675 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #459 | Epoch Duration: 184.75676560401917
2020-01-14 03:30:43.831897 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #459 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0957952
Z variance train             0.1726341
KL Divergence                58.823154
KL Loss                      5.8823156
QF Loss                      115.32407
VF Loss                      82.06823
Policy Loss                  -1385.9313
Q Predictions Mean           1384.4905
Q Predictions Std            1366.8448
Q Predictions Max            4953.514
Q Predictions Min            706.0278
V Predictions Mean           1384.6597
V Predictions Std            1358.5193
V Predictions Max            4907.056
V Predictions Min            736.8963
Log Pis Mean                 -0.6061034
Log Pis Std                  4.0646524
Log Pis Max                  18.64148
Log Pis Min                  -8.417721
Policy mu Mean               0.049904916
Policy mu Std                0.86123407
Policy mu Max                3.3046882
Policy mu Min                -3.0792465
Policy log std Mean          -0.48094964
Policy log std Std           0.27910712
Policy log std Max           0.022693038
Policy log std Min           -2.686637
Z mean eval                  2.1151829
Z variance eval              0.09480465
total_rewards                [10760.00951637 10548.57081577 10860.74147325 10307.39668213
 10775.67015751  1297.46258342 10517.57206479 11041.94929502
  5648.30169621 11194.13345764]
total_rewards_mean           9295.180774209328
total_rewards_std            3078.9414625190934
total_rewards_max            11194.133457641623
total_rewards_min            1297.462583417798
Number of train steps total  1844000
Number of env steps total    5534000
Number of rollouts total     0
Train Time (s)               142.27512578805909
(Previous) Eval Time (s)     29.450884588062763
Sample Time (s)              9.163622420746833
Epoch Time (s)               180.88963279686868
Total Train Time (s)         85344.00584387034
Epoch                        460
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:33:44.804033 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #460 | Epoch Duration: 180.97197198867798
2020-01-14 03:33:44.804243 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1153073
Z variance train             0.094690844
KL Divergence                59.893623
KL Loss                      5.9893622
QF Loss                      207.43521
VF Loss                      114.32761
Policy Loss                  -1399.3857
Q Predictions Mean           1398.7524
Q Predictions Std            1379.2832
Q Predictions Max            5049.44
Q Predictions Min            733.1893
V Predictions Mean           1399.596
V Predictions Std            1376.3865
V Predictions Max            5032.8364
V Predictions Min            732.1129
Log Pis Mean                 -0.29982665
Log Pis Std                  3.9923143
Log Pis Max                  14.141496
Log Pis Min                  -6.8002167
Policy mu Mean               0.10310275
Policy mu Std                0.89196205
Policy mu Max                3.1187239
Policy mu Min                -2.7641857
Policy log std Mean          -0.47933587
Policy log std Std           0.2699532
Policy log std Max           0.14373922
Policy log std Min           -2.8318467
Z mean eval                  2.091583
Z variance eval              0.08524465
total_rewards                [10685.27910645 11182.50881581 10914.14192303 11021.45503631
 11207.2083044   5058.3970075  10676.12098933 10915.21143823
 11060.23654534 10898.36226018]
total_rewards_mean           10361.892142658717
total_rewards_std            1775.950479259565
total_rewards_max            11207.208304402124
total_rewards_min            5058.397007502455
Number of train steps total  1848000
Number of env steps total    5546000
Number of rollouts total     0
Train Time (s)               145.30298159923404
(Previous) Eval Time (s)     30.49813284026459
Sample Time (s)              9.526910652872175
Epoch Time (s)               185.3280250923708
Total Train Time (s)         85529.55497277761
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:36:50.356804 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #461 | Epoch Duration: 185.55239510536194
2020-01-14 03:36:50.357046 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #461 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0921383
Z variance train             0.085367575
KL Divergence                59.719563
KL Loss                      5.9719563
QF Loss                      5017.119
VF Loss                      133.31299
Policy Loss                  -1461.284
Q Predictions Mean           1459.4398
Q Predictions Std            1398.6356
Q Predictions Max            4958.7104
Q Predictions Min            713.5767
V Predictions Mean           1469.2952
V Predictions Std            1400.7421
V Predictions Max            4972.246
V Predictions Min            740.8939
Log Pis Mean                 -0.4499905
Log Pis Std                  4.194314
Log Pis Max                  17.636623
Log Pis Min                  -7.111897
Policy mu Mean               0.118271194
Policy mu Std                0.8565018
Policy mu Max                3.4797318
Policy mu Min                -2.8962107
Policy log std Mean          -0.49584213
Policy log std Std           0.28221664
Policy log std Max           0.04866016
Policy log std Min           -2.9317248
Z mean eval                  2.0954785
Z variance eval              0.09370828
total_rewards                [10686.46116666 10694.02879384 10799.41863949 10898.12542552
 10734.23224934 10578.63513875 10889.65160642 10519.25970297
 10772.88949323 10898.12191751]
total_rewards_mean           10747.0824133733
total_rewards_std            125.01616079152478
total_rewards_max            10898.125425520857
total_rewards_min            10519.25970296558
Number of train steps total  1852000
Number of env steps total    5558000
Number of rollouts total     0
Train Time (s)               152.4825547169894
(Previous) Eval Time (s)     29.77317899186164
Sample Time (s)              9.940639053005725
Epoch Time (s)               192.19637276185676
Total Train Time (s)         85721.86154517066
Epoch                        462
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:40:02.667892 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #462 | Epoch Duration: 192.31066226959229
2020-01-14 03:40:02.668145 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0956302
Z variance train             0.093200155
KL Divergence                59.744087
KL Loss                      5.9744086
QF Loss                      132.50713
VF Loss                      43.973385
Policy Loss                  -1360.5527
Q Predictions Mean           1356.3242
Q Predictions Std            1315.0151
Q Predictions Max            4967.627
Q Predictions Min            721.6371
V Predictions Mean           1357.9845
V Predictions Std            1315.3655
V Predictions Max            4965.008
V Predictions Min            725.24866
Log Pis Mean                 -0.6739263
Log Pis Std                  4.0701656
Log Pis Max                  16.140173
Log Pis Min                  -8.550779
Policy mu Mean               0.099884115
Policy mu Std                0.81734985
Policy mu Max                2.8892782
Policy mu Min                -2.5350122
Policy log std Mean          -0.5068895
Policy log std Std           0.29719436
Policy log std Max           0.1159215
Policy log std Min           -2.950049
Z mean eval                  2.1521246
Z variance eval              0.09305672
total_rewards                [11410.01746665 11503.95908688 11386.07771293 11384.69933127
 11599.48376621 11459.25228787 11379.64013501 11251.61706943
 11550.46558079 11346.59562638]
total_rewards_mean           11427.180806341688
total_rewards_std            97.55837355222705
total_rewards_max            11599.483766209385
total_rewards_min            11251.617069427079
Number of train steps total  1856000
Number of env steps total    5570000
Number of rollouts total     0
Train Time (s)               151.60739772906527
(Previous) Eval Time (s)     29.504832949955016
Sample Time (s)              10.183615301270038
Epoch Time (s)               191.29584598029032
Total Train Time (s)         85913.2461788156
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:43:14.059527 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #463 | Epoch Duration: 191.39119935035706
2020-01-14 03:43:14.059787 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #463 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1446414
Z variance train             0.09188267
KL Divergence                60.320793
KL Loss                      6.032079
QF Loss                      99.25294
VF Loss                      215.38489
Policy Loss                  -1393.2253
Q Predictions Mean           1393.8389
Q Predictions Std            1360.265
Q Predictions Max            4951.4653
Q Predictions Min            722.831
V Predictions Mean           1401.17
V Predictions Std            1361.9833
V Predictions Max            4959.5977
V Predictions Min            737.46075
Log Pis Mean                 -0.45952746
Log Pis Std                  4.0370555
Log Pis Max                  18.128296
Log Pis Min                  -8.55434
Policy mu Mean               0.07857252
Policy mu Std                0.8543313
Policy mu Max                3.406582
Policy mu Min                -3.0738394
Policy log std Mean          -0.48563066
Policy log std Std           0.27394706
Policy log std Max           0.064175904
Policy log std Min           -2.8864207
Z mean eval                  2.1163232
Z variance eval              0.1315727
total_rewards                [10980.61403482 11068.00612497 11077.14776961 11201.88665085
 11302.81644016 11410.21341529 11001.5065933  11443.94547236
 11287.15270111 10994.40636164]
total_rewards_mean           11176.76955641287
total_rewards_std            166.96902209812694
total_rewards_max            11443.945472363952
total_rewards_min            10980.614034822931
Number of train steps total  1860000
Number of env steps total    5582000
Number of rollouts total     0
Train Time (s)               151.49875516304746
(Previous) Eval Time (s)     31.370230632368475
Sample Time (s)              9.79557808674872
Epoch Time (s)               192.66456388216466
Total Train Time (s)         86106.00180881191
Epoch                        464
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:46:26.820487 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #464 | Epoch Duration: 192.7604649066925
2020-01-14 03:46:26.820800 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1171582
Z variance train             0.13170105
KL Divergence                59.639454
KL Loss                      5.9639454
QF Loss                      211.98828
VF Loss                      47.357616
Policy Loss                  -1338.3066
Q Predictions Mean           1336.6616
Q Predictions Std            1286.3502
Q Predictions Max            5001.9863
Q Predictions Min            736.5022
V Predictions Mean           1334.27
V Predictions Std            1284.1931
V Predictions Max            4993.9863
V Predictions Min            736.5562
Log Pis Mean                 -0.79874516
Log Pis Std                  3.8399074
Log Pis Max                  14.198141
Log Pis Min                  -7.74602
Policy mu Mean               0.01475022
Policy mu Std                0.8271823
Policy mu Max                2.9085789
Policy mu Min                -3.425562
Policy log std Mean          -0.47774804
Policy log std Std           0.28674898
Policy log std Max           -0.043691516
Policy log std Min           -2.8590965
Z mean eval                  2.1310866
Z variance eval              0.08238615
total_rewards                [8003.55343438 7565.40008926 8686.83276951 7545.00174589 6905.82727073
 8166.05654948 7475.89045465 6777.00861161 7626.33975378 7098.75216677]
total_rewards_mean           7585.066284606886
total_rewards_std            556.1483272767518
total_rewards_max            8686.832769508614
total_rewards_min            6777.008611614392
Number of train steps total  1864000
Number of env steps total    5594000
Number of rollouts total     0
Train Time (s)               151.22440344793722
(Previous) Eval Time (s)     29.706094967201352
Sample Time (s)              10.087075853254646
Epoch Time (s)               191.01757426839322
Total Train Time (s)         86297.10808192939
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:49:37.931226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #465 | Epoch Duration: 191.11021161079407
2020-01-14 03:49:37.931433 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #465 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1284935
Z variance train             0.082920976
KL Divergence                61.324486
KL Loss                      6.1324487
QF Loss                      5111.3945
VF Loss                      47.085075
Policy Loss                  -1315.2493
Q Predictions Mean           1311.693
Q Predictions Std            1279.7417
Q Predictions Max            5048.827
Q Predictions Min            738.2123
V Predictions Mean           1313.7253
V Predictions Std            1276.2617
V Predictions Max            5020.454
V Predictions Min            742.8388
Log Pis Mean                 -0.5866982
Log Pis Std                  4.039268
Log Pis Max                  15.898028
Log Pis Min                  -7.6037235
Policy mu Mean               0.061500724
Policy mu Std                0.85053635
Policy mu Max                3.2147682
Policy mu Min                -2.7655394
Policy log std Mean          -0.4657501
Policy log std Std           0.28230023
Policy log std Max           0.21741307
Policy log std Min           -3.096261
Z mean eval                  2.0922701
Z variance eval              0.1391849
total_rewards                [11080.84347933 11328.55060833 11424.07813411 11189.49959971
 11288.74977989 11242.48827726 11699.4775366  11088.18899284
 11347.12830715 10692.48480272]
total_rewards_mean           11238.148951795461
total_rewards_std            248.46953152028078
total_rewards_max            11699.477536602042
total_rewards_min            10692.484802724393
Number of train steps total  1868000
Number of env steps total    5606000
Number of rollouts total     0
Train Time (s)               143.00994083518162
(Previous) Eval Time (s)     29.556169941090047
Sample Time (s)              8.459607698954642
Epoch Time (s)               181.0257184752263
Total Train Time (s)         86478.21474956861
Epoch                        466
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:52:39.046859 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #466 | Epoch Duration: 181.11524558067322
2020-01-14 03:52:39.047158 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0885398
Z variance train             0.13907042
KL Divergence                59.987396
KL Loss                      5.9987397
QF Loss                      4876.298
VF Loss                      81.6127
Policy Loss                  -1406.7484
Q Predictions Mean           1407.1104
Q Predictions Std            1357.1007
Q Predictions Max            4985.1826
Q Predictions Min            739.9437
V Predictions Mean           1400.0017
V Predictions Std            1352.904
V Predictions Max            4971.1016
V Predictions Min            740.97906
Log Pis Mean                 -0.3045722
Log Pis Std                  4.001276
Log Pis Max                  12.882696
Log Pis Min                  -7.4830337
Policy mu Mean               0.10746449
Policy mu Std                0.8682573
Policy mu Max                2.6538317
Policy mu Min                -2.4829998
Policy log std Mean          -0.47726583
Policy log std Std           0.2897711
Policy log std Max           0.10441029
Policy log std Min           -3.0534186
Z mean eval                  2.1267905
Z variance eval              0.065835014
total_rewards                [10166.27461932 10364.81865199 10325.51559016 10456.10855024
 10538.15387633 10560.4966563  10461.23289575 10519.75381261
 10501.71039911 10490.09732348]
total_rewards_mean           10438.416237528903
total_rewards_std            114.54342008570619
total_rewards_max            10560.49665629528
total_rewards_min            10166.274619324176
Number of train steps total  1872000
Number of env steps total    5618000
Number of rollouts total     0
Train Time (s)               142.47558784205467
(Previous) Eval Time (s)     29.649645023047924
Sample Time (s)              8.478507629130036
Epoch Time (s)               180.60374049423262
Total Train Time (s)         86658.90244960971
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:55:39.739051 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #467 | Epoch Duration: 180.69163060188293
2020-01-14 03:55:39.739270 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #467 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1205938
Z variance train             0.06555839
KL Divergence                61.699203
KL Loss                      6.1699204
QF Loss                      215.71046
VF Loss                      319.129
Policy Loss                  -1454.8907
Q Predictions Mean           1457.081
Q Predictions Std            1417.7634
Q Predictions Max            5110.6494
Q Predictions Min            738.61523
V Predictions Mean           1467.5027
V Predictions Std            1418.4565
V Predictions Max            5120.642
V Predictions Min            744.3934
Log Pis Mean                 -0.33538193
Log Pis Std                  4.1840143
Log Pis Max                  15.632111
Log Pis Min                  -7.6646805
Policy mu Mean               0.043101247
Policy mu Std                0.8892824
Policy mu Max                2.8184466
Policy mu Min                -3.301128
Policy log std Mean          -0.46795
Policy log std Std           0.2932818
Policy log std Max           0.073313594
Policy log std Min           -2.7616515
Z mean eval                  2.1428971
Z variance eval              0.07004948
total_rewards                [10973.37675392  2097.94372228 11436.29550566 11187.2670302
 11414.32856655 11348.42423873 11349.22943467 11219.78902603
 11292.00788786 11514.94102425]
total_rewards_mean           10383.360319014435
total_rewards_std            2765.5751916447703
total_rewards_max            11514.94102424601
total_rewards_min            2097.9437222763268
Number of train steps total  1876000
Number of env steps total    5630000
Number of rollouts total     0
Train Time (s)               148.09809136483818
(Previous) Eval Time (s)     30.650238094851375
Sample Time (s)              9.492913572117686
Epoch Time (s)               188.24124303180724
Total Train Time (s)         86847.23414520221
Epoch                        468
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:58:48.076378 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #468 | Epoch Duration: 188.33693051338196
2020-01-14 03:58:48.076736 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #468 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1407905
Z variance train             0.07017212
KL Divergence                60.68413
KL Loss                      6.0684133
QF Loss                      100.96073
VF Loss                      57.961464
Policy Loss                  -1338.3446
Q Predictions Mean           1335.8179
Q Predictions Std            1293.3511
Q Predictions Max            5107.22
Q Predictions Min            737.82245
V Predictions Mean           1338.2749
V Predictions Std            1289.0691
V Predictions Max            5086.5874
V Predictions Min            743.9423
Log Pis Mean                 -0.6752298
Log Pis Std                  3.8901062
Log Pis Max                  14.082521
Log Pis Min                  -6.4612203
Policy mu Mean               -0.0013921354
Policy mu Std                0.844097
Policy mu Max                3.042657
Policy mu Min                -4.235207
Policy log std Mean          -0.46885702
Policy log std Std           0.28586334
Policy log std Max           0.08737874
Policy log std Min           -2.653949
Z mean eval                  2.1440656
Z variance eval              0.08759193
total_rewards                [10465.14255375 10569.26812515 10443.07112834 10229.17219893
 10503.29512213 10472.8032425  10430.99467777 10083.084716
 10589.15064744 10355.04416774]
total_rewards_mean           10414.102657973694
total_rewards_std            147.34612873616632
total_rewards_max            10589.150647436465
total_rewards_min            10083.084716000358
Number of train steps total  1880000
Number of env steps total    5642000
Number of rollouts total     0
Train Time (s)               151.57628671405837
(Previous) Eval Time (s)     29.916129536926746
Sample Time (s)              10.451886906754225
Epoch Time (s)               191.94430315773934
Total Train Time (s)         87039.28678534972
Epoch                        469
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:02:00.133366 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #469 | Epoch Duration: 192.05639123916626
2020-01-14 04:02:00.133605 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1432781
Z variance train             0.0878336
KL Divergence                60.4731
KL Loss                      6.04731
QF Loss                      277.90833
VF Loss                      196.62108
Policy Loss                  -1388.9067
Q Predictions Mean           1387.9036
Q Predictions Std            1365.6951
Q Predictions Max            5072.0166
Q Predictions Min            745.12146
V Predictions Mean           1382.312
V Predictions Std            1359.0707
V Predictions Max            5041.482
V Predictions Min            739.6686
Log Pis Mean                 -0.83573294
Log Pis Std                  3.8914247
Log Pis Max                  15.802219
Log Pis Min                  -7.155707
Policy mu Mean               0.068698786
Policy mu Std                0.8125778
Policy mu Max                2.6093717
Policy mu Min                -2.6358864
Policy log std Mean          -0.4689661
Policy log std Std           0.30062518
Policy log std Max           0.23684049
Policy log std Min           -3.2472155
Z mean eval                  2.110973
Z variance eval              0.09888246
total_rewards                [10645.15810033 11082.69916463 10960.35277312 10963.53991633
 11249.83212743 10983.754645   10904.62103311 11079.80517583
 10784.01389895 10993.54039458]
total_rewards_mean           10964.731722932065
total_rewards_std            157.49679089840936
total_rewards_max            11249.832127432881
total_rewards_min            10645.158100334833
Number of train steps total  1884000
Number of env steps total    5654000
Number of rollouts total     0
Train Time (s)               152.2379343137145
(Previous) Eval Time (s)     28.183385564945638
Sample Time (s)              10.377601006999612
Epoch Time (s)               190.79892088565975
Total Train Time (s)         87230.16507867817
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:05:11.016060 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #470 | Epoch Duration: 190.8822979927063
2020-01-14 04:05:11.016255 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1125796
Z variance train             0.098990574
KL Divergence                60.34201
KL Loss                      6.034201
QF Loss                      4776.7812
VF Loss                      43.105434
Policy Loss                  -1384.8547
Q Predictions Mean           1384.8132
Q Predictions Std            1379.1385
Q Predictions Max            5070.041
Q Predictions Min            713.27167
V Predictions Mean           1388.4171
V Predictions Std            1377.2784
V Predictions Max            5064.4834
V Predictions Min            721.0644
Log Pis Mean                 -0.63869786
Log Pis Std                  3.790088
Log Pis Max                  12.999065
Log Pis Min                  -6.883112
Policy mu Mean               0.053901676
Policy mu Std                0.83795416
Policy mu Max                3.0536525
Policy mu Min                -2.675533
Policy log std Mean          -0.47674116
Policy log std Std           0.28937858
Policy log std Max           0.20301294
Policy log std Min           -2.9694796
Z mean eval                  2.0867405
Z variance eval              0.12715527
total_rewards                [10823.34641129 10979.17188493 10759.16451346 10703.87294886
 11063.91286973 11165.30178959  2329.0347569  11000.97717676
 10924.9854746  10959.82542973]
total_rewards_mean           10070.959325585516
total_rewards_std            2583.9980152712515
total_rewards_max            11165.301789593994
total_rewards_min            2329.034756896922
Number of train steps total  1888000
Number of env steps total    5666000
Number of rollouts total     0
Train Time (s)               153.89299308415502
(Previous) Eval Time (s)     30.120384368579835
Sample Time (s)              10.336200223769993
Epoch Time (s)               194.34957767650485
Total Train Time (s)         87424.59827985615
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:08:25.458513 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #471 | Epoch Duration: 194.44208979606628
2020-01-14 04:08:25.458923 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #471 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.083238
Z variance train             0.12598646
KL Divergence                59.88634
KL Loss                      5.988634
QF Loss                      138.50311
VF Loss                      63.9969
Policy Loss                  -1442.7611
Q Predictions Mean           1441.0051
Q Predictions Std            1410.6332
Q Predictions Max            5011.1743
Q Predictions Min            730.3482
V Predictions Mean           1443.9408
V Predictions Std            1408.062
V Predictions Max            4991.4194
V Predictions Min            737.1257
Log Pis Mean                 -0.3662981
Log Pis Std                  4.2472014
Log Pis Max                  14.810839
Log Pis Min                  -7.354745
Policy mu Mean               0.083788894
Policy mu Std                0.8896601
Policy mu Max                3.3855958
Policy mu Min                -2.9628067
Policy log std Mean          -0.48778638
Policy log std Std           0.3098928
Policy log std Max           0.06795037
Policy log std Min           -3.0921354
Z mean eval                  2.1123931
Z variance eval              0.11296685
total_rewards                [11047.67603826 11368.90961681 11308.79243938 11298.60868812
 11365.6145187  11529.06409613 11238.4751918  11207.01778311
 11497.30004355 11284.63031943]
total_rewards_mean           11314.608873529582
total_rewards_std            132.1859001483839
total_rewards_max            11529.064096126616
total_rewards_min            11047.676038264106
Number of train steps total  1892000
Number of env steps total    5678000
Number of rollouts total     0
Train Time (s)               150.50093385810032
(Previous) Eval Time (s)     28.9532885462977
Sample Time (s)              9.369652968365699
Epoch Time (s)               188.82387537276372
Total Train Time (s)         87613.50811606133
Epoch                        472
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:11:34.369757 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #472 | Epoch Duration: 188.9104723930359
2020-01-14 04:11:34.370026 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #472 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1102824
Z variance train             0.11191271
KL Divergence                61.128735
KL Loss                      6.1128736
QF Loss                      159.12497
VF Loss                      46.915543
Policy Loss                  -1424.4385
Q Predictions Mean           1420.4734
Q Predictions Std            1382.4532
Q Predictions Max            4973.528
Q Predictions Min            716.9059
V Predictions Mean           1424.4373
V Predictions Std            1380.5642
V Predictions Max            4975.4585
V Predictions Min            716.91614
Log Pis Mean                 -0.54593945
Log Pis Std                  3.944977
Log Pis Max                  13.457107
Log Pis Min                  -6.47379
Policy mu Mean               0.05454443
Policy mu Std                0.84387547
Policy mu Max                3.1259708
Policy mu Min                -2.668724
Policy log std Mean          -0.488778
Policy log std Std           0.28062493
Policy log std Max           0.08089447
Policy log std Min           -3.125128
Z mean eval                  2.1408367
Z variance eval              0.06936483
total_rewards                [10933.69015816 10939.18040349 10850.88381342 10880.864246
 11232.33628511   715.46379084 10723.99158071 11085.63169186
 10784.54742708 10921.07395901]
total_rewards_mean           9906.766335567518
total_rewards_std            3066.8347572897433
total_rewards_max            11232.336285112606
total_rewards_min            715.463790836787
Number of train steps total  1896000
Number of env steps total    5690000
Number of rollouts total     0
Train Time (s)               143.27747010206804
(Previous) Eval Time (s)     28.861712319310755
Sample Time (s)              9.555632366333157
Epoch Time (s)               181.69481478771195
Total Train Time (s)         87795.28217124101
Epoch                        473
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:14:36.148149 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #473 | Epoch Duration: 181.77795124053955
2020-01-14 04:14:36.148355 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.141766
Z variance train             0.0690618
KL Divergence                63.524963
KL Loss                      6.3524966
QF Loss                      117.3347
VF Loss                      126.37182
Policy Loss                  -1534.8379
Q Predictions Mean           1533.8086
Q Predictions Std            1525.3353
Q Predictions Max            5051.8574
Q Predictions Min            734.0443
V Predictions Mean           1529.0724
V Predictions Std            1515.5328
V Predictions Max            5005.9893
V Predictions Min            735.01807
Log Pis Mean                 -0.62004143
Log Pis Std                  3.6174402
Log Pis Max                  12.404019
Log Pis Min                  -9.171884
Policy mu Mean               0.063075
Policy mu Std                0.8595783
Policy mu Max                2.875007
Policy mu Min                -2.4905303
Policy log std Mean          -0.4857534
Policy log std Std           0.29623112
Policy log std Max           0.29051852
Policy log std Min           -2.981104
Z mean eval                  2.1280723
Z variance eval              0.041414768
total_rewards                [10190.67138053 10948.84527274 11071.90672816 10788.76826041
 10846.2478005  10682.04941127 10419.6642613  10481.37965518
 10549.2986473  10910.39997928]
total_rewards_mean           10688.923139667266
total_rewards_std            261.0325144258503
total_rewards_max            11071.906728163343
total_rewards_min            10190.671380529717
Number of train steps total  1900000
Number of env steps total    5702000
Number of rollouts total     0
Train Time (s)               143.22935410775244
(Previous) Eval Time (s)     29.956560792401433
Sample Time (s)              9.84667794033885
Epoch Time (s)               183.03259284049273
Total Train Time (s)         87978.63017398585
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:17:39.500897 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #474 | Epoch Duration: 183.35238909721375
2020-01-14 04:17:39.501087 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.127735
Z variance train             0.041425068
KL Divergence                63.395447
KL Loss                      6.339545
QF Loss                      134.2647
VF Loss                      48.318344
Policy Loss                  -1356.1315
Q Predictions Mean           1352.4915
Q Predictions Std            1349.7393
Q Predictions Max            5074.557
Q Predictions Min            700.47327
V Predictions Mean           1359.5945
V Predictions Std            1348.0669
V Predictions Max            5060.015
V Predictions Min            711.28925
Log Pis Mean                 -0.5414914
Log Pis Std                  3.818487
Log Pis Max                  13.769917
Log Pis Min                  -7.1524353
Policy mu Mean               0.06566694
Policy mu Std                0.85817313
Policy mu Max                2.8908212
Policy mu Min                -2.6943061
Policy log std Mean          -0.48810896
Policy log std Std           0.27973273
Policy log std Max           0.33602774
Policy log std Min           -2.728881
Z mean eval                  2.1211557
Z variance eval              0.08289571
total_rewards                [10085.78399644 10430.41407684 10389.88853644 10260.22450129
 10216.10936182 10033.89790342 10108.83376798 10110.98160721
 10480.00672725 10392.66005495]
total_rewards_mean           10250.880053362696
total_rewards_std            154.7706138189869
total_rewards_max            10480.006727247652
total_rewards_min            10033.897903415298
Number of train steps total  1904000
Number of env steps total    5714000
Number of rollouts total     0
Train Time (s)               151.2231898540631
(Previous) Eval Time (s)     30.99200876383111
Sample Time (s)              9.834145294968039
Epoch Time (s)               192.04934391286224
Total Train Time (s)         88170.76298627444
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:20:51.638131 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #475 | Epoch Duration: 192.13690090179443
2020-01-14 04:20:51.638310 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.12394
Z variance train             0.081279054
KL Divergence                63.172165
KL Loss                      6.3172164
QF Loss                      146.68701
VF Loss                      166.10002
Policy Loss                  -1291.6924
Q Predictions Mean           1291.4286
Q Predictions Std            1288.0835
Q Predictions Max            5052.5293
Q Predictions Min            732.5635
V Predictions Mean           1285.0928
V Predictions Std            1279.7739
V Predictions Max            4976.494
V Predictions Min            732.8709
Log Pis Mean                 -0.8824874
Log Pis Std                  3.7504885
Log Pis Max                  16.72842
Log Pis Min                  -6.2773237
Policy mu Mean               0.076436676
Policy mu Std                0.79976416
Policy mu Max                2.857961
Policy mu Min                -2.883376
Policy log std Mean          -0.44881108
Policy log std Std           0.29342723
Policy log std Max           0.07434404
Policy log std Min           -3.1131792
Z mean eval                  2.1143367
Z variance eval              0.095442496
total_rewards                [10888.14838375 10396.67213328 11231.12700573 11118.43828403
 10721.36246904 10186.35632712 11081.43456246 10474.12917885
  2740.95908482 10358.36224968]
total_rewards_mean           9919.698967876764
total_rewards_std            2417.017622370313
total_rewards_max            11231.127005731743
total_rewards_min            2740.9590848194157
Number of train steps total  1908000
Number of env steps total    5726000
Number of rollouts total     0
Train Time (s)               151.78971059108153
(Previous) Eval Time (s)     30.39930642209947
Sample Time (s)              9.929277308750898
Epoch Time (s)               192.1182943219319
Total Train Time (s)         88362.96769320592
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:24:03.847866 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #476 | Epoch Duration: 192.20941638946533
2020-01-14 04:24:03.848069 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #476 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1162424
Z variance train             0.09470092
KL Divergence                61.75524
KL Loss                      6.175524
QF Loss                      140.06418
VF Loss                      67.2308
Policy Loss                  -1297.503
Q Predictions Mean           1295.7632
Q Predictions Std            1290.2529
Q Predictions Max            5010.934
Q Predictions Min            720.7741
V Predictions Mean           1301.3579
V Predictions Std            1290.9196
V Predictions Max            5027.2935
V Predictions Min            725.2285
Log Pis Mean                 -1.1745628
Log Pis Std                  3.557996
Log Pis Max                  12.291736
Log Pis Min                  -7.9343314
Policy mu Mean               0.02654998
Policy mu Std                0.7753471
Policy mu Max                2.571555
Policy mu Min                -2.394999
Policy log std Mean          -0.45429406
Policy log std Std           0.2598646
Policy log std Max           0.29063225
Policy log std Min           -3.0122147
Z mean eval                  2.1301036
Z variance eval              0.08569386
total_rewards                [10468.86156499 10455.16685413  7329.73204669 10226.2061265
  8459.98743101 10258.99169807 10041.30820073 10741.86058673
 10423.05618369 10249.7979291 ]
total_rewards_mean           9865.49686216302
total_rewards_std            1032.4607351054688
total_rewards_max            10741.860586729887
total_rewards_min            7329.732046685391
Number of train steps total  1912000
Number of env steps total    5738000
Number of rollouts total     0
Train Time (s)               150.43789019994438
(Previous) Eval Time (s)     29.832357761915773
Sample Time (s)              9.900757787749171
Epoch Time (s)               190.17100574960932
Total Train Time (s)         88553.22022129782
Epoch                        477
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:27:14.105731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #477 | Epoch Duration: 190.25750875473022
2020-01-14 04:27:14.105939 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #477 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1315513
Z variance train             0.08591998
KL Divergence                62.079075
KL Loss                      6.2079077
QF Loss                      283.2798
VF Loss                      136.45203
Policy Loss                  -1397.1752
Q Predictions Mean           1394.9097
Q Predictions Std            1380.121
Q Predictions Max            5070.303
Q Predictions Min            722.01166
V Predictions Mean           1400.9761
V Predictions Std            1375.8411
V Predictions Max            5068.315
V Predictions Min            717.41547
Log Pis Mean                 -0.5553447
Log Pis Std                  4.2822194
Log Pis Max                  15.559675
Log Pis Min                  -5.8117666
Policy mu Mean               0.12046216
Policy mu Std                0.8519216
Policy mu Max                3.922567
Policy mu Min                -4.0854335
Policy log std Mean          -0.4695339
Policy log std Std           0.31971893
Policy log std Max           0.13412845
Policy log std Min           -2.8267906
Z mean eval                  2.1847308
Z variance eval              0.0919535
total_rewards                [10800.38565535 11096.4412859  10585.0096119  10538.14527758
 10814.88313228 10527.27183075 10729.24054296 10559.55223026
 10832.5900417  11238.91343823]
total_rewards_mean           10772.243304689999
total_rewards_std            229.36724171970292
total_rewards_max            11238.913438226233
total_rewards_min            10527.271830746464
Number of train steps total  1916000
Number of env steps total    5750000
Number of rollouts total     0
Train Time (s)               151.4558731680736
(Previous) Eval Time (s)     30.834554749075323
Sample Time (s)              10.290553854778409
Epoch Time (s)               192.58098177192733
Total Train Time (s)         88745.89243124845
Epoch                        478
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:30:26.783672 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #478 | Epoch Duration: 192.6775414943695
2020-01-14 04:30:26.784039 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #478 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1857958
Z variance train             0.09240762
KL Divergence                59.4019
KL Loss                      5.9401903
QF Loss                      266.17245
VF Loss                      56.58692
Policy Loss                  -1331.1497
Q Predictions Mean           1327.6582
Q Predictions Std            1326.6708
Q Predictions Max            5098.0156
Q Predictions Min            715.9412
V Predictions Mean           1327.5277
V Predictions Std            1319.5803
V Predictions Max            5074.3696
V Predictions Min            705.6069
Log Pis Mean                 -0.41405097
Log Pis Std                  4.4652915
Log Pis Max                  20.66754
Log Pis Min                  -7.149726
Policy mu Mean               0.06523406
Policy mu Std                0.8645386
Policy mu Max                2.9226608
Policy mu Min                -3.0379121
Policy log std Mean          -0.46040884
Policy log std Std           0.26904327
Policy log std Max           0.25288075
Policy log std Min           -2.9065003
Z mean eval                  2.1088421
Z variance eval              0.128062
total_rewards                [10932.15435951 11476.95130053  9012.31847505 10964.16882253
 10451.9471888  10652.41094361 11366.32375633 10967.50935909
 11156.93076547 10008.43926062]
total_rewards_mean           10698.915423153114
total_rewards_std            695.8431436041434
total_rewards_max            11476.95130053103
total_rewards_min            9012.318475045065
Number of train steps total  1920000
Number of env steps total    5762000
Number of rollouts total     0
Train Time (s)               147.24049365893006
(Previous) Eval Time (s)     28.10804573399946
Sample Time (s)              9.885710360016674
Epoch Time (s)               185.2342497529462
Total Train Time (s)         88931.21083958726
Epoch                        479
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:33:32.106040 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #479 | Epoch Duration: 185.3217408657074
2020-01-14 04:33:32.106280 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #479 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1090233
Z variance train             0.12799546
KL Divergence                57.66475
KL Loss                      5.766475
QF Loss                      264.4082
VF Loss                      81.10093
Policy Loss                  -1478.692
Q Predictions Mean           1476.7888
Q Predictions Std            1460.122
Q Predictions Max            4986.0146
Q Predictions Min            728.6828
V Predictions Mean           1476.1412
V Predictions Std            1453.6713
V Predictions Max            4957.4175
V Predictions Min            730.767
Log Pis Mean                 -0.3946906
Log Pis Std                  4.1986594
Log Pis Max                  14.873614
Log Pis Min                  -8.562341
Policy mu Mean               0.10105697
Policy mu Std                0.8672818
Policy mu Max                3.6677203
Policy mu Min                -3.192677
Policy log std Mean          -0.46773484
Policy log std Std           0.2936066
Policy log std Max           -0.07478908
Policy log std Min           -3.0930486
Z mean eval                  2.0972362
Z variance eval              0.12527034
total_rewards                [11079.37804944 11351.63012873  5715.52739566 10935.65225136
 11037.18608101 11366.27760076  5544.7217177  11076.46830471
 11139.13749817 11193.67760127]
total_rewards_mean           10043.965662881476
total_rewards_std            2210.8378571123817
total_rewards_max            11366.277600759191
total_rewards_min            5544.721717703219
Number of train steps total  1924000
Number of env steps total    5774000
Number of rollouts total     0
Train Time (s)               142.66922865482047
(Previous) Eval Time (s)     29.794661925174296
Sample Time (s)              10.050240504089743
Epoch Time (s)               182.5141310840845
Total Train Time (s)         89113.81227404997
Epoch                        480
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:36:34.713566 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #480 | Epoch Duration: 182.60710430145264
2020-01-14 04:36:34.713923 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #480 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0962503
Z variance train             0.124646686
KL Divergence                57.827965
KL Loss                      5.7827964
QF Loss                      103.11183
VF Loss                      37.149975
Policy Loss                  -1345.3066
Q Predictions Mean           1341.2587
Q Predictions Std            1297.7034
Q Predictions Max            4969.2153
Q Predictions Min            710.76544
V Predictions Mean           1344.3689
V Predictions Std            1294.3823
V Predictions Max            4978.821
V Predictions Min            706.3626
Log Pis Mean                 -0.5995576
Log Pis Std                  4.0807343
Log Pis Max                  13.095041
Log Pis Min                  -6.9233823
Policy mu Mean               0.080064185
Policy mu Std                0.8324749
Policy mu Max                3.1853888
Policy mu Min                -3.3157725
Policy log std Mean          -0.4619286
Policy log std Std           0.29114473
Policy log std Max           0.022152066
Policy log std Min           -2.7340164
Z mean eval                  2.1058576
Z variance eval              0.14161366
total_rewards                [10783.32222072  9358.04961816 10841.96093439 10604.59789949
 10883.04015338 11080.84319343 11220.98003061 11149.22002746
 11109.90348867 10819.3912897 ]
total_rewards_mean           10785.13088560099
total_rewards_std            509.7641044452184
total_rewards_max            11220.980030605282
total_rewards_min            9358.049618157027
Number of train steps total  1928000
Number of env steps total    5786000
Number of rollouts total     0
Train Time (s)               143.66955497534946
(Previous) Eval Time (s)     30.02943367185071
Sample Time (s)              9.846015794668347
Epoch Time (s)               183.5450044418685
Total Train Time (s)         89297.43786186958
Epoch                        481
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:39:38.342556 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #481 | Epoch Duration: 183.62840509414673
2020-01-14 04:39:38.342740 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #481 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1059961
Z variance train             0.14125957
KL Divergence                56.599136
KL Loss                      5.6599135
QF Loss                      101.52204
VF Loss                      53.013363
Policy Loss                  -1399.4768
Q Predictions Mean           1394.47
Q Predictions Std            1404.7887
Q Predictions Max            4979.0586
Q Predictions Min            704.4097
V Predictions Mean           1399.5126
V Predictions Std            1404.0469
V Predictions Max            4968.857
V Predictions Min            704.68567
Log Pis Mean                 -0.44845623
Log Pis Std                  4.06875
Log Pis Max                  14.177126
Log Pis Min                  -6.6722207
Policy mu Mean               0.08214722
Policy mu Std                0.83828247
Policy mu Max                3.1238117
Policy mu Min                -2.349691
Policy log std Mean          -0.48140565
Policy log std Std           0.31017104
Policy log std Max           0.19728303
Policy log std Min           -3.299411
Z mean eval                  2.108047
Z variance eval              0.11836137
total_rewards                [10809.04700125 11135.13368147 10999.73348715 11283.6966876
  7979.85403488 11158.38959388 11086.63218142 11162.51625527
 11277.15382925 11434.48687322]
total_rewards_mean           10832.664362538333
total_rewards_std            964.4207876121087
total_rewards_max            11434.486873222508
total_rewards_min            7979.854034877218
Number of train steps total  1932000
Number of env steps total    5798000
Number of rollouts total     0
Train Time (s)               153.46068597305566
(Previous) Eval Time (s)     29.8947045058012
Sample Time (s)              9.289972093887627
Epoch Time (s)               192.6453625727445
Total Train Time (s)         89490.15904905368
Epoch                        482
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:42:51.068158 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #482 | Epoch Duration: 192.725266456604
2020-01-14 04:42:51.068333 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #482 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1060846
Z variance train             0.11820992
KL Divergence                57.370407
KL Loss                      5.737041
QF Loss                      76.172775
VF Loss                      90.789215
Policy Loss                  -1350.116
Q Predictions Mean           1347.5144
Q Predictions Std            1317.5142
Q Predictions Max            4936.154
Q Predictions Min            717.2135
V Predictions Mean           1344.6428
V Predictions Std            1313.1173
V Predictions Max            4911.9
V Predictions Min            715.95074
Log Pis Mean                 -0.9734442
Log Pis Std                  3.9145663
Log Pis Max                  19.720387
Log Pis Min                  -9.226549
Policy mu Mean               0.046424985
Policy mu Std                0.80045176
Policy mu Max                3.3029165
Policy mu Min                -3.4085732
Policy log std Mean          -0.46394205
Policy log std Std           0.2713219
Policy log std Max           0.1150617
Policy log std Min           -3.020816
Z mean eval                  2.1063366
Z variance eval              0.079151265
total_rewards                [10945.37805216 10781.09814352 10854.63944905 10996.02503988
 10923.93084345 10780.56376593 10190.9849146  10635.61691454
 10161.87891049 10032.61713628]
total_rewards_mean           10630.273316990006
total_rewards_std            344.17505040560536
total_rewards_max            10996.025039877894
total_rewards_min            10032.617136276163
Number of train steps total  1936000
Number of env steps total    5810000
Number of rollouts total     0
Train Time (s)               151.88677726034075
(Previous) Eval Time (s)     30.380293439142406
Sample Time (s)              9.416036795824766
Epoch Time (s)               191.68310749530792
Total Train Time (s)         89681.93931615632
Epoch                        483
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:46:02.853765 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #483 | Epoch Duration: 191.7852921485901
2020-01-14 04:46:02.853973 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #483 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1068022
Z variance train             0.07882132
KL Divergence                58.54566
KL Loss                      5.854566
QF Loss                      5247.84
VF Loss                      145.91783
Policy Loss                  -1520.0388
Q Predictions Mean           1518.4854
Q Predictions Std            1514.3936
Q Predictions Max            5080.806
Q Predictions Min            726.44916
V Predictions Mean           1518.017
V Predictions Std            1510.8356
V Predictions Max            5070.849
V Predictions Min            727.4196
Log Pis Mean                 -0.21399453
Log Pis Std                  4.203485
Log Pis Max                  15.717712
Log Pis Min                  -6.140353
Policy mu Mean               0.077645324
Policy mu Std                0.9055293
Policy mu Max                3.364754
Policy mu Min                -2.6921556
Policy log std Mean          -0.4660287
Policy log std Std           0.27535993
Policy log std Max           0.013541698
Policy log std Min           -2.869847
Z mean eval                  2.1102858
Z variance eval              0.09484654
total_rewards                [11132.68701342  3892.25705826 11682.01371216  3114.45062333
 11268.79043421 11236.69349545 11209.47381797 10891.90795602
 10729.77182881 11577.72876755]
total_rewards_mean           9673.577470718335
total_rewards_std            3101.3111590903122
total_rewards_max            11682.01371216056
total_rewards_min            3114.4506233319034
Number of train steps total  1940000
Number of env steps total    5822000
Number of rollouts total     0
Train Time (s)               151.31943090772256
(Previous) Eval Time (s)     29.61619758605957
Sample Time (s)              9.851630117744207
Epoch Time (s)               190.78725861152634
Total Train Time (s)         89872.80829690583
Epoch                        484
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:49:13.726652 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #484 | Epoch Duration: 190.87253427505493
2020-01-14 04:49:13.726831 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #484 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1100929
Z variance train             0.09492361
KL Divergence                58.239655
KL Loss                      5.8239655
QF Loss                      96.60827
VF Loss                      56.89059
Policy Loss                  -1314.4897
Q Predictions Mean           1313.4583
Q Predictions Std            1276.3785
Q Predictions Max            4990.793
Q Predictions Min            725.1475
V Predictions Mean           1316.021
V Predictions Std            1274.9542
V Predictions Max            4985.231
V Predictions Min            724.45337
Log Pis Mean                 -0.80347
Log Pis Std                  3.8456593
Log Pis Max                  13.206736
Log Pis Min                  -6.687187
Policy mu Mean               0.07048363
Policy mu Std                0.82286286
Policy mu Max                3.0341642
Policy mu Min                -2.9782372
Policy log std Mean          -0.45917892
Policy log std Std           0.26058036
Policy log std Max           0.025761962
Policy log std Min           -2.5218577
Z mean eval                  2.1360483
Z variance eval              0.07795696
total_rewards                [ 7380.81363528 10371.63467804 10438.30665392  8376.18793453
 10616.92057498 11038.40523148 10909.15678789  2443.24416634
 10018.06501137 10719.06582522]
total_rewards_mean           9231.180049904398
total_rewards_std            2526.334695919153
total_rewards_max            11038.40523147614
total_rewards_min            2443.244166335733
Number of train steps total  1944000
Number of env steps total    5834000
Number of rollouts total     0
Train Time (s)               150.8857778669335
(Previous) Eval Time (s)     30.895365796983242
Sample Time (s)              10.693401597905904
Epoch Time (s)               192.47454526182264
Total Train Time (s)         90065.36570943054
Epoch                        485
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:52:26.289167 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #485 | Epoch Duration: 192.56218695640564
2020-01-14 04:52:26.289368 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #485 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1356359
Z variance train             0.0778601
KL Divergence                58.845783
KL Loss                      5.884578
QF Loss                      187.7171
VF Loss                      47.582405
Policy Loss                  -1409.5533
Q Predictions Mean           1407.8243
Q Predictions Std            1380.59
Q Predictions Max            5036.294
Q Predictions Min            712.744
V Predictions Mean           1408.149
V Predictions Std            1376.5603
V Predictions Max            5025.734
V Predictions Min            724.87714
Log Pis Mean                 -0.7127408
Log Pis Std                  4.154989
Log Pis Max                  15.429586
Log Pis Min                  -8.121728
Policy mu Mean               0.05300137
Policy mu Std                0.85175204
Policy mu Max                3.1564639
Policy mu Min                -2.6927607
Policy log std Mean          -0.46611515
Policy log std Std           0.29800558
Policy log std Max           0.013328731
Policy log std Min           -2.828333
Z mean eval                  2.152063
Z variance eval              0.13227649
total_rewards                [11383.11076253 11321.48220563 11421.91517186 11422.11167522
 11439.26573177 11175.36547176 11285.83828629 11188.93158865
 11353.4983772  11140.73612519]
total_rewards_mean           11313.225539609182
total_rewards_std            105.39773212543037
total_rewards_max            11439.265731765565
total_rewards_min            11140.73612519117
Number of train steps total  1948000
Number of env steps total    5846000
Number of rollouts total     0
Train Time (s)               144.4445025571622
(Previous) Eval Time (s)     29.44740773923695
Sample Time (s)              10.50466374726966
Epoch Time (s)               184.3965740436688
Total Train Time (s)         90249.85750171589
Epoch                        486
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:55:30.786402 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #486 | Epoch Duration: 184.4968581199646
2020-01-14 04:55:30.786695 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #486 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.156234
Z variance train             0.13263074
KL Divergence                59.943497
KL Loss                      5.99435
QF Loss                      129.27904
VF Loss                      53.997334
Policy Loss                  -1401.7721
Q Predictions Mean           1399.2854
Q Predictions Std            1373.1741
Q Predictions Max            5080.757
Q Predictions Min            722.1922
V Predictions Mean           1402.469
V Predictions Std            1372.3486
V Predictions Max            5066.464
V Predictions Min            725.7883
Log Pis Mean                 -0.36818418
Log Pis Std                  4.3983865
Log Pis Max                  18.733297
Log Pis Min                  -10.744108
Policy mu Mean               0.11410374
Policy mu Std                0.86277175
Policy mu Max                3.417994
Policy mu Min                -2.9054015
Policy log std Mean          -0.46419933
Policy log std Std           0.30219284
Policy log std Max           0.05861646
Policy log std Min           -3.1905885
Z mean eval                  2.1424801
Z variance eval              0.109485805
total_rewards                [10585.69660812 11788.71582227 10924.10662455 10843.91114442
 11234.29168447 10760.40612426 10944.22326171   984.91739959
 10995.50264408 11048.01821987]
total_rewards_mean           10010.978953335018
total_rewards_std            3024.265720940121
total_rewards_max            11788.715822271803
total_rewards_min            984.9173995911895
Number of train steps total  1952000
Number of env steps total    5858000
Number of rollouts total     0
Train Time (s)               142.89994772803038
(Previous) Eval Time (s)     29.327468452975154
Sample Time (s)              9.612890377640724
Epoch Time (s)               181.84030655864626
Total Train Time (s)         90431.7753923242
Epoch                        487
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:58:32.706446 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #487 | Epoch Duration: 181.91958212852478
2020-01-14 04:58:32.706593 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.142614
Z variance train             0.109198645
KL Divergence                59.573387
KL Loss                      5.957339
QF Loss                      94.34151
VF Loss                      62.56178
Policy Loss                  -1430.9792
Q Predictions Mean           1428.7052
Q Predictions Std            1410.7307
Q Predictions Max            5017.6367
Q Predictions Min            748.2594
V Predictions Mean           1427.5647
V Predictions Std            1409.311
V Predictions Max            5010.446
V Predictions Min            744.9766
Log Pis Mean                 -0.47543913
Log Pis Std                  3.989237
Log Pis Max                  13.563425
Log Pis Min                  -6.0176272
Policy mu Mean               0.065908216
Policy mu Std                0.8547027
Policy mu Max                2.9644856
Policy mu Min                -3.5558848
Policy log std Mean          -0.4528853
Policy log std Std           0.26909432
Policy log std Max           0.22480726
Policy log std Min           -2.7659063
Z mean eval                  2.1620274
Z variance eval              0.119598314
total_rewards                [11073.44708568 11240.91384095 11583.3973283  11084.60000668
 10980.55627016 11196.92581043 11380.35762957 11230.29479241
 11197.36481813 11433.8894249 ]
total_rewards_mean           11240.17470072073
total_rewards_std            172.67977414673194
total_rewards_max            11583.397328302015
total_rewards_min            10980.55627016059
Number of train steps total  1956000
Number of env steps total    5870000
Number of rollouts total     0
Train Time (s)               146.65646414179355
(Previous) Eval Time (s)     30.202757082879543
Sample Time (s)              8.52665035519749
Epoch Time (s)               185.38587157987058
Total Train Time (s)         90617.25103427237
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:01:38.187645 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #488 | Epoch Duration: 185.48092246055603
2020-01-14 05:01:38.187875 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #488 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1622133
Z variance train             0.11930271
KL Divergence                58.131294
KL Loss                      5.8131294
QF Loss                      109.72714
VF Loss                      102.22571
Policy Loss                  -1485.8098
Q Predictions Mean           1484.1094
Q Predictions Std            1440.4681
Q Predictions Max            4915.124
Q Predictions Min            717.61237
V Predictions Mean           1490.7405
V Predictions Std            1439.8109
V Predictions Max            4936.266
V Predictions Min            726.37695
Log Pis Mean                 -0.18423992
Log Pis Std                  4.8644943
Log Pis Max                  29.269302
Log Pis Min                  -9.239847
Policy mu Mean               0.027580587
Policy mu Std                0.9208648
Policy mu Max                4.2612467
Policy mu Min                -5.769239
Policy log std Mean          -0.4810095
Policy log std Std           0.32118878
Policy log std Max           0.1384598
Policy log std Min           -3.2820735
Z mean eval                  2.1685565
Z variance eval              0.1502659
total_rewards                [11161.88333851 11003.09760188 10676.86653896 11132.800235
 10816.07016125 10298.79471657 10413.43247528 10670.69559469
 11187.29898191 11362.69583259]
total_rewards_mean           10872.363547663008
total_rewards_std            336.1558224909119
total_rewards_max            11362.69583258646
total_rewards_min            10298.794716570632
Number of train steps total  1960000
Number of env steps total    5882000
Number of rollouts total     0
Train Time (s)               153.72585299797356
(Previous) Eval Time (s)     29.952487042173743
Sample Time (s)              10.06362486584112
Epoch Time (s)               193.74196490598843
Total Train Time (s)         90811.07169579435
Epoch                        489
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:04:52.012914 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #489 | Epoch Duration: 193.82488536834717
2020-01-14 05:04:52.013102 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #489 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.16993
Z variance train             0.14991318
KL Divergence                58.547836
KL Loss                      5.8547835
QF Loss                      185.49493
VF Loss                      48.938705
Policy Loss                  -1529.9231
Q Predictions Mean           1525.9287
Q Predictions Std            1490.2505
Q Predictions Max            5058.5186
Q Predictions Min            737.2793
V Predictions Mean           1531.6316
V Predictions Std            1488.4912
V Predictions Max            5057.7476
V Predictions Min            745.8305
Log Pis Mean                 -0.05549229
Log Pis Std                  4.8359423
Log Pis Max                  28.627996
Log Pis Min                  -6.359226
Policy mu Mean               0.057201594
Policy mu Std                0.9322842
Policy mu Max                3.6323125
Policy mu Min                -3.5417585
Policy log std Mean          -0.46361735
Policy log std Std           0.28524476
Policy log std Max           0.052870274
Policy log std Min           -2.7448957
Z mean eval                  2.1114664
Z variance eval              0.1354879
total_rewards                [11233.8673071  11084.98209798 11429.19774839 11200.84903332
 11278.18747701 11273.45969992 11376.93962495 11154.28525339
 11219.07197759 11469.1460358 ]
total_rewards_mean           11271.998625543465
total_rewards_std            115.23056327336207
total_rewards_max            11469.146035801432
total_rewards_min            11084.982097977807
Number of train steps total  1964000
Number of env steps total    5894000
Number of rollouts total     0
Train Time (s)               151.99087442830205
(Previous) Eval Time (s)     29.795732994098216
Sample Time (s)              10.24039021320641
Epoch Time (s)               192.02699763560668
Total Train Time (s)         91003.18210813124
Epoch                        490
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:08:04.129130 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #490 | Epoch Duration: 192.11584448814392
2020-01-14 05:08:04.129516 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #490 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.112353
Z variance train             0.1350944
KL Divergence                58.60568
KL Loss                      5.860568
QF Loss                      300.76694
VF Loss                      81.498764
Policy Loss                  -1533.8073
Q Predictions Mean           1530.7139
Q Predictions Std            1478.4193
Q Predictions Max            5050.4233
Q Predictions Min            729.31775
V Predictions Mean           1535.5594
V Predictions Std            1476.953
V Predictions Max            5039.677
V Predictions Min            737.839
Log Pis Mean                 -0.09724745
Log Pis Std                  5.028794
Log Pis Max                  31.827663
Log Pis Min                  -6.777867
Policy mu Mean               0.093718804
Policy mu Std                0.931128
Policy mu Max                4.357952
Policy mu Min                -5.2590985
Policy log std Mean          -0.49065247
Policy log std Std           0.33077735
Policy log std Max           0.047018886
Policy log std Min           -3.0283136
Z mean eval                  2.1835413
Z variance eval              0.19422725
total_rewards                [10217.32213518  9623.9268741  10881.45063848 10587.22806936
 11182.96212432 10123.9557427  10660.59049988 10421.87283565
  5510.85491263 10441.75682502]
total_rewards_mean           9965.192065731846
total_rewards_std            1538.669218405883
total_rewards_max            11182.962124324169
total_rewards_min            5510.85491263343
Number of train steps total  1968000
Number of env steps total    5906000
Number of rollouts total     0
Train Time (s)               153.33923351578414
(Previous) Eval Time (s)     29.336880368180573
Sample Time (s)              10.43514662515372
Epoch Time (s)               193.11126050911844
Total Train Time (s)         91196.40693791956
Epoch                        491
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:11:17.358617 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #491 | Epoch Duration: 193.22882223129272
2020-01-14 05:11:17.358835 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #491 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1832743
Z variance train             0.19297305
KL Divergence                57.281685
KL Loss                      5.7281685
QF Loss                      158.3764
VF Loss                      76.127174
Policy Loss                  -1290.2572
Q Predictions Mean           1285.9951
Q Predictions Std            1254.9962
Q Predictions Max            4948.5347
Q Predictions Min            723.5224
V Predictions Mean           1293.1372
V Predictions Std            1253.9286
V Predictions Max            4937.924
V Predictions Min            731.24023
Log Pis Mean                 -0.6821885
Log Pis Std                  4.06871
Log Pis Max                  18.872324
Log Pis Min                  -8.746095
Policy mu Mean               0.07859155
Policy mu Std                0.8540459
Policy mu Max                3.6245701
Policy mu Min                -3.034459
Policy log std Mean          -0.45575538
Policy log std Std           0.28026
Policy log std Max           -0.023455024
Policy log std Min           -2.6254697
Z mean eval                  2.1406796
Z variance eval              0.10821962
total_rewards                [ 4804.20782334  9385.93960219 10584.91897476 10240.74417008
 10040.16416142 10304.14223591  9711.52652263  9766.84367364
 10063.55723511 10466.64044683]
total_rewards_mean           9536.868484591221
total_rewards_std            1614.9920674724679
total_rewards_max            10584.918974761582
total_rewards_min            4804.207823336701
Number of train steps total  1972000
Number of env steps total    5918000
Number of rollouts total     0
Train Time (s)               152.26971403323114
(Previous) Eval Time (s)     28.63059864519164
Sample Time (s)              10.102183288428932
Epoch Time (s)               191.0024959668517
Total Train Time (s)         91387.49545309087
Epoch                        492
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:14:28.451315 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #492 | Epoch Duration: 191.0922074317932
2020-01-14 05:14:28.451578 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.136404
Z variance train             0.10765096
KL Divergence                58.998554
KL Loss                      5.8998556
QF Loss                      178.00827
VF Loss                      113.959145
Policy Loss                  -1477.3094
Q Predictions Mean           1475.2981
Q Predictions Std            1410.1123
Q Predictions Max            5023.721
Q Predictions Min            720.6914
V Predictions Mean           1485.0869
V Predictions Std            1411.3479
V Predictions Max            5049.9526
V Predictions Min            739.15
Log Pis Mean                 -0.31185213
Log Pis Std                  4.106222
Log Pis Max                  14.710249
Log Pis Min                  -8.027925
Policy mu Mean               0.010056584
Policy mu Std                0.88285464
Policy mu Max                3.4285278
Policy mu Min                -2.9881434
Policy log std Mean          -0.4701922
Policy log std Std           0.28102827
Policy log std Max           -0.06514627
Policy log std Min           -2.9467146
Z mean eval                  2.119094
Z variance eval              0.10262855
total_rewards                [10813.27824581 11119.58933983 11356.74194279 11302.64714476
 11591.33926531 11278.45856807 11441.36216514 10970.06035178
 10678.08387979 11297.59860671]
total_rewards_mean           11184.915950999775
total_rewards_std            272.25003318218734
total_rewards_max            11591.339265310333
total_rewards_min            10678.083879785954
Number of train steps total  1976000
Number of env steps total    5930000
Number of rollouts total     0
Train Time (s)               143.25778025202453
(Previous) Eval Time (s)     29.24628405086696
Sample Time (s)              9.743802811484784
Epoch Time (s)               182.24786711437628
Total Train Time (s)         91569.83370788395
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:17:30.794447 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #493 | Epoch Duration: 182.3427073955536
2020-01-14 05:17:30.794642 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #493 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.120951
Z variance train             0.10236273
KL Divergence                59.662323
KL Loss                      5.9662323
QF Loss                      475.07877
VF Loss                      219.36734
Policy Loss                  -1473.3292
Q Predictions Mean           1468.6758
Q Predictions Std            1435.682
Q Predictions Max            5023.6963
Q Predictions Min            669.36176
V Predictions Mean           1468.4309
V Predictions Std            1427.5583
V Predictions Max            5000.606
V Predictions Min            627.9375
Log Pis Mean                 -0.054800384
Log Pis Std                  4.638253
Log Pis Max                  19.34476
Log Pis Min                  -7.531438
Policy mu Mean               0.07624329
Policy mu Std                0.9130111
Policy mu Max                3.8188128
Policy mu Min                -3.1589925
Policy log std Mean          -0.47167265
Policy log std Std           0.31134835
Policy log std Max           0.039541006
Policy log std Min           -3.2163467
Z mean eval                  2.134134
Z variance eval              0.0850279
total_rewards                [11309.07775662 11419.16219281 11250.40044171 11381.0071336
 11247.25586597  9430.65928215 11159.63249576 11102.87078096
 11338.92017441 11208.18921255]
total_rewards_mean           11084.717533653362
total_rewards_std            559.0673064637288
total_rewards_max            11419.162192809832
total_rewards_min            9430.659282152108
Number of train steps total  1980000
Number of env steps total    5942000
Number of rollouts total     0
Train Time (s)               142.63338233996183
(Previous) Eval Time (s)     29.083361503202468
Sample Time (s)              9.896879048086703
Epoch Time (s)               181.613622891251
Total Train Time (s)         91751.52798821544
Epoch                        494
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:20:32.493393 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #494 | Epoch Duration: 181.69860553741455
2020-01-14 05:20:32.493589 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #494 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1327057
Z variance train             0.08480348
KL Divergence                60.58617
KL Loss                      6.058617
QF Loss                      128.4396
VF Loss                      136.84625
Policy Loss                  -1478.1406
Q Predictions Mean           1474.0459
Q Predictions Std            1419.32
Q Predictions Max            4989.7656
Q Predictions Min            737.54083
V Predictions Mean           1480.4238
V Predictions Std            1420.7307
V Predictions Max            4999.0835
V Predictions Min            739.08417
Log Pis Mean                 -0.44414467
Log Pis Std                  4.400413
Log Pis Max                  18.043713
Log Pis Min                  -9.2871
Policy mu Mean               0.00063044205
Policy mu Std                0.8751181
Policy mu Max                3.5788763
Policy mu Min                -3.3653197
Policy log std Mean          -0.47117212
Policy log std Std           0.29095408
Policy log std Max           -0.01202786
Policy log std Min           -2.930522
Z mean eval                  2.1453176
Z variance eval              0.082794055
total_rewards                [10972.58656467 11230.1163321   2738.98633286 11604.19242222
 11048.7580545  11347.5310494  11233.69131733 11140.43213971
 10843.99137126 11285.86016055]
total_rewards_mean           10344.614574458148
total_rewards_std            2543.0560841990355
total_rewards_max            11604.192422216014
total_rewards_min            2738.986332859064
Number of train steps total  1984000
Number of env steps total    5954000
Number of rollouts total     0
Train Time (s)               150.88035727711394
(Previous) Eval Time (s)     30.160039184149355
Sample Time (s)              9.857846179511398
Epoch Time (s)               190.8982426407747
Total Train Time (s)         91942.52018967876
Epoch                        495
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:23:43.491398 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #495 | Epoch Duration: 190.99765014648438
2020-01-14 05:23:43.491635 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #495 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.143024
Z variance train             0.08250492
KL Divergence                62.837425
KL Loss                      6.2837424
QF Loss                      4790.834
VF Loss                      26.736279
Policy Loss                  -1426.5532
Q Predictions Mean           1422.8727
Q Predictions Std            1381.8188
Q Predictions Max            5076.6787
Q Predictions Min            734.3315
V Predictions Mean           1426.685
V Predictions Std            1381.1993
V Predictions Max            5090.118
V Predictions Min            738.8605
Log Pis Mean                 -0.7015412
Log Pis Std                  3.8529615
Log Pis Max                  14.114105
Log Pis Min                  -6.148721
Policy mu Mean               0.003662318
Policy mu Std                0.8790499
Policy mu Max                3.2654355
Policy mu Min                -2.7134516
Policy log std Mean          -0.46855152
Policy log std Std           0.29612342
Policy log std Max           0.07047224
Policy log std Min           -2.667282
Z mean eval                  2.1440578
Z variance eval              0.10572376
total_rewards                [11124.24446459 11023.45035709 11288.99180856 11701.81180936
 11472.48804427  7253.13165049 11192.40855956 11395.34857195
 11532.70051891 11204.06294104]
total_rewards_mean           10918.863872582368
total_rewards_std            1237.2231985412384
total_rewards_max            11701.81180936114
total_rewards_min            7253.131650492241
Number of train steps total  1988000
Number of env steps total    5966000
Number of rollouts total     0
Train Time (s)               152.58008102793247
(Previous) Eval Time (s)     30.59078486962244
Sample Time (s)              10.508151879534125
Epoch Time (s)               193.67901777708903
Total Train Time (s)         92136.29182069656
Epoch                        496
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:26:57.268133 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #496 | Epoch Duration: 193.77632665634155
2020-01-14 05:26:57.268388 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #496 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1517315
Z variance train             0.1049221
KL Divergence                61.894875
KL Loss                      6.1894875
QF Loss                      104.60406
VF Loss                      340.03317
Policy Loss                  -1432.0944
Q Predictions Mean           1426.7699
Q Predictions Std            1386.4164
Q Predictions Max            5074.843
Q Predictions Min            737.3763
V Predictions Mean           1421.9939
V Predictions Std            1373.4755
V Predictions Max            4997.967
V Predictions Min            739.7139
Log Pis Mean                 -0.28092673
Log Pis Std                  4.5347767
Log Pis Max                  29.131985
Log Pis Min                  -5.807774
Policy mu Mean               0.012069392
Policy mu Std                0.9112159
Policy mu Max                3.2807276
Policy mu Min                -3.8578882
Policy log std Mean          -0.4773539
Policy log std Std           0.2852834
Policy log std Max           0.049178004
Policy log std Min           -3.221151
Z mean eval                  2.1483846
Z variance eval              0.09321658
total_rewards                [ 6304.2308061  11083.81641655 11104.70123382 11363.32061497
 11501.25834666 11214.57633884 11272.99342389 10664.08841445
 11499.94335042 11388.71712159]
total_rewards_mean           10739.764606729052
total_rewards_std            1496.9543221125903
total_rewards_max            11501.258346663612
total_rewards_min            6304.230806099521
Number of train steps total  1992000
Number of env steps total    5978000
Number of rollouts total     0
Train Time (s)               150.9633439388126
(Previous) Eval Time (s)     29.395722917746753
Sample Time (s)              10.324281387962401
Epoch Time (s)               190.68334824452177
Total Train Time (s)         92327.3001747611
Epoch                        497
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:30:08.280817 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #497 | Epoch Duration: 191.01226711273193
2020-01-14 05:30:08.281033 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #497 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1497912
Z variance train             0.09353965
KL Divergence                61.46358
KL Loss                      6.146358
QF Loss                      206.03372
VF Loss                      48.02376
Policy Loss                  -1451.6288
Q Predictions Mean           1450.8794
Q Predictions Std            1442.4653
Q Predictions Max            5059.45
Q Predictions Min            -22.405596
V Predictions Mean           1449.8982
V Predictions Std            1439.4008
V Predictions Max            5053.4287
V Predictions Min            -80.61693
Log Pis Mean                 -0.25019526
Log Pis Std                  4.4830465
Log Pis Max                  17.349035
Log Pis Min                  -6.343895
Policy mu Mean               0.054257438
Policy mu Std                0.87657785
Policy mu Max                2.7362013
Policy mu Min                -2.5578003
Policy log std Mean          -0.48727012
Policy log std Std           0.31276467
Policy log std Max           0.021839023
Policy log std Min           -3.2711859
Z mean eval                  2.1425633
Z variance eval              0.059727795
total_rewards                [10723.78622776 10917.04108368 11064.62094291 11412.38573505
 10932.22734471 11290.97698847 10972.09078031 11164.87448822
 11362.62614833 11209.31730239]
total_rewards_mean           11104.994704182192
total_rewards_std            209.69261551380316
total_rewards_max            11412.385735050248
total_rewards_min            10723.78622776195
Number of train steps total  1996000
Number of env steps total    5990000
Number of rollouts total     0
Train Time (s)               153.24806797783822
(Previous) Eval Time (s)     30.02572112623602
Sample Time (s)              10.078639307525009
Epoch Time (s)               193.35242841159925
Total Train Time (s)         92520.74668155191
Epoch                        498
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:33:21.731954 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #498 | Epoch Duration: 193.45076966285706
2020-01-14 05:33:21.732150 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #498 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1423457
Z variance train             0.05970251
KL Divergence                62.637436
KL Loss                      6.263744
QF Loss                      4866.364
VF Loss                      54.39515
Policy Loss                  -1511.0806
Q Predictions Mean           1507.6213
Q Predictions Std            1455.0864
Q Predictions Max            5073.775
Q Predictions Min            738.9828
V Predictions Mean           1507.4634
V Predictions Std            1449.8015
V Predictions Max            5069.547
V Predictions Min            734.77527
Log Pis Mean                 -0.41744167
Log Pis Std                  4.31202
Log Pis Max                  16.572372
Log Pis Min                  -7.192309
Policy mu Mean               0.05841714
Policy mu Std                0.89312685
Policy mu Max                2.721928
Policy mu Min                -2.6695695
Policy log std Mean          -0.47630394
Policy log std Std           0.29420537
Policy log std Max           -0.043611348
Policy log std Min           -2.910474
Z mean eval                  2.167766
Z variance eval              0.12520024
total_rewards                [10978.36519194 11062.57191079  3783.19666985 11209.95755798
 11157.41035028 11196.15283972 11220.76997085 10856.7645619
 11225.40239422 11317.86030789]
total_rewards_mean           10400.845175540706
total_rewards_std            2209.6425478977617
total_rewards_max            11317.860307888515
total_rewards_min            3783.1966698458555
Number of train steps total  2000000
Number of env steps total    6002000
Number of rollouts total     0
Train Time (s)               149.51601683022454
(Previous) Eval Time (s)     29.342461102176458
Sample Time (s)              10.199011146090925
Epoch Time (s)               189.05748907849193
Total Train Time (s)         92709.88965266664
Epoch                        499
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:36:30.881175 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #499 | Epoch Duration: 189.14885663986206
2020-01-14 05:36:30.881490 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #499 | Started Training: True
2020-01-14 05:36:32.145682 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Variant:
2020-01-14 05:36:32.146259 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] {
  "env_name": "Humanoid-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20_seed56",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
